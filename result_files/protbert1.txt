{'CNNType': 'Musite',
 'CV_Repeats': 5,
 'CreateFigures': False,
 'Experiment Name': 'Prottrans embeddings - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'aminoAcid': ['Hydroxylation-K'],
 'batch_size': 512,
 'crossValidation': True,
 'data_sample_mode': ['oversample'],
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'protBert',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'learning_rate': 0.004684927881340591,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3147146522,
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'weight_decay': 4.506776933725176}
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.698
[2,     1] loss: 0.690
[3,     1] loss: 0.682
[4,     1] loss: 0.657
[5,     1] loss: 0.638
[6,     1] loss: 0.585
[7,     1] loss: 0.566
[8,     1] loss: 0.523
[9,     1] loss: 0.501
[10,     1] loss: 0.457
[11,     1] loss: 0.440
[12,     1] loss: 0.458
[13,     1] loss: 0.451
[14,     1] loss: 0.350
[15,     1] loss: 0.422
[16,     1] loss: 0.366
[17,     1] loss: 0.317
[18,     1] loss: 0.280
[19,     1] loss: 0.313
[20,     1] loss: 0.234
[21,     1] loss: 0.291
[22,     1] loss: 0.269
[23,     1] loss: 0.217
[24,     1] loss: 0.298
[25,     1] loss: 0.279
[26,     1] loss: 0.182
[27,     1] loss: 0.195
[28,     1] loss: 0.261
[29,     1] loss: 0.163
[30,     1] loss: 0.152
[31,     1] loss: 0.208
[32,     1] loss: 0.151
[33,     1] loss: 0.139
[34,     1] loss: 0.160
[35,     1] loss: 0.139
[36,     1] loss: 0.107
[37,     1] loss: 0.099
[38,     1] loss: 0.144
[39,     1] loss: 0.100
[40,     1] loss: 0.154
[41,     1] loss: 0.115
[42,     1] loss: 0.130
[43,     1] loss: 0.114
[44,     1] loss: 0.099
[45,     1] loss: 0.101
[46,     1] loss: 0.111
[47,     1] loss: 0.104
[48,     1] loss: 0.132
[49,     1] loss: 0.055
[50,     1] loss: 0.089
[51,     1] loss: 0.077
[52,     1] loss: 0.132
[53,     1] loss: 0.090
[54,     1] loss: 0.064
[55,     1] loss: 0.077
[56,     1] loss: 0.078
[57,     1] loss: 0.112
[58,     1] loss: 0.089
[59,     1] loss: 0.058
[60,     1] loss: 0.087
[61,     1] loss: 0.050
[62,     1] loss: 0.071
[63,     1] loss: 0.049
[64,     1] loss: 0.047
[65,     1] loss: 0.056
[66,     1] loss: 0.142
[67,     1] loss: 0.081
Early stopping applied (best metric=0.13781283795833588)
Finished Training
Total time taken: 11.336894035339355
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.688
[2,     1] loss: 0.691
[3,     1] loss: 0.675
[4,     1] loss: 0.645
[5,     1] loss: 0.617
[6,     1] loss: 0.564
[7,     1] loss: 0.507
[8,     1] loss: 0.468
[9,     1] loss: 0.387
[10,     1] loss: 0.369
[11,     1] loss: 0.313
[12,     1] loss: 0.329
[13,     1] loss: 0.319
[14,     1] loss: 0.258
[15,     1] loss: 0.321
[16,     1] loss: 0.230
[17,     1] loss: 0.278
[18,     1] loss: 0.302
[19,     1] loss: 0.296
[20,     1] loss: 0.257
[21,     1] loss: 0.249
[22,     1] loss: 0.260
[23,     1] loss: 0.255
[24,     1] loss: 0.226
[25,     1] loss: 0.215
[26,     1] loss: 0.243
[27,     1] loss: 0.216
[28,     1] loss: 0.219
[29,     1] loss: 0.229
[30,     1] loss: 0.240
[31,     1] loss: 0.200
[32,     1] loss: 0.203
[33,     1] loss: 0.230
[34,     1] loss: 0.199
[35,     1] loss: 0.173
[36,     1] loss: 0.179
[37,     1] loss: 0.094
[38,     1] loss: 0.201
[39,     1] loss: 0.225
[40,     1] loss: 0.184
[41,     1] loss: 0.220
[42,     1] loss: 0.174
[43,     1] loss: 0.093
[44,     1] loss: 0.231
[45,     1] loss: 0.140
[46,     1] loss: 0.130
[47,     1] loss: 0.148
[48,     1] loss: 0.133
[49,     1] loss: 0.152
[50,     1] loss: 0.178
[51,     1] loss: 0.137
[52,     1] loss: 0.176
[53,     1] loss: 0.138
[54,     1] loss: 0.196
[55,     1] loss: 0.170
Early stopping applied (best metric=0.49033719301223755)
Finished Training
Total time taken: 6.79166316986084
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.691
[2,     1] loss: 0.691
[3,     1] loss: 0.670
[4,     1] loss: 0.635
[5,     1] loss: 0.591
[6,     1] loss: 0.561
[7,     1] loss: 0.527
[8,     1] loss: 0.479
[9,     1] loss: 0.425
[10,     1] loss: 0.413
[11,     1] loss: 0.349
[12,     1] loss: 0.328
[13,     1] loss: 0.320
[14,     1] loss: 0.295
[15,     1] loss: 0.268
[16,     1] loss: 0.252
[17,     1] loss: 0.315
[18,     1] loss: 0.233
[19,     1] loss: 0.260
[20,     1] loss: 0.262
[21,     1] loss: 0.198
[22,     1] loss: 0.238
[23,     1] loss: 0.180
[24,     1] loss: 0.157
[25,     1] loss: 0.168
[26,     1] loss: 0.150
[27,     1] loss: 0.141
[28,     1] loss: 0.148
[29,     1] loss: 0.147
[30,     1] loss: 0.113
[31,     1] loss: 0.095
[32,     1] loss: 0.110
[33,     1] loss: 0.113
[34,     1] loss: 0.145
[35,     1] loss: 0.077
[36,     1] loss: 0.080
[37,     1] loss: 0.055
[38,     1] loss: 0.092
[39,     1] loss: 0.154
[40,     1] loss: 0.103
[41,     1] loss: 0.069
[42,     1] loss: 0.052
[43,     1] loss: 0.133
[44,     1] loss: 0.082
[45,     1] loss: 0.091
[46,     1] loss: 0.074
[47,     1] loss: 0.105
[48,     1] loss: 0.061
[49,     1] loss: 0.117
[50,     1] loss: 0.088
[51,     1] loss: 0.105
[52,     1] loss: 0.097
[53,     1] loss: 0.061
[54,     1] loss: 0.060
[55,     1] loss: 0.081
[56,     1] loss: 0.064
[57,     1] loss: 0.071
[58,     1] loss: 0.072
[59,     1] loss: 0.105
Early stopping applied (best metric=0.41659629344940186)
Finished Training
Total time taken: 7.423033952713013
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.693
[2,     1] loss: 0.691
[3,     1] loss: 0.686
[4,     1] loss: 0.656
[5,     1] loss: 0.635
[6,     1] loss: 0.608
[7,     1] loss: 0.574
[8,     1] loss: 0.521
[9,     1] loss: 0.461
[10,     1] loss: 0.442
[11,     1] loss: 0.422
[12,     1] loss: 0.344
[13,     1] loss: 0.356
[14,     1] loss: 0.463
[15,     1] loss: 0.381
[16,     1] loss: 0.401
[17,     1] loss: 0.298
[18,     1] loss: 0.293
[19,     1] loss: 0.331
[20,     1] loss: 0.215
[21,     1] loss: 0.298
[22,     1] loss: 0.239
[23,     1] loss: 0.226
[24,     1] loss: 0.319
[25,     1] loss: 0.194
[26,     1] loss: 0.184
[27,     1] loss: 0.216
[28,     1] loss: 0.222
[29,     1] loss: 0.159
[30,     1] loss: 0.155
[31,     1] loss: 0.183
[32,     1] loss: 0.163
[33,     1] loss: 0.187
[34,     1] loss: 0.106
[35,     1] loss: 0.145
[36,     1] loss: 0.094
[37,     1] loss: 0.104
[38,     1] loss: 0.112
[39,     1] loss: 0.119
[40,     1] loss: 0.124
[41,     1] loss: 0.113
[42,     1] loss: 0.126
[43,     1] loss: 0.123
[44,     1] loss: 0.065
[45,     1] loss: 0.139
[46,     1] loss: 0.126
[47,     1] loss: 0.088
[48,     1] loss: 0.091
[49,     1] loss: 0.078
[50,     1] loss: 0.207
[51,     1] loss: 0.177
[52,     1] loss: 0.128
[53,     1] loss: 0.155
[54,     1] loss: 0.233
[55,     1] loss: 0.123
[56,     1] loss: 0.139
[57,     1] loss: 0.199
[58,     1] loss: 0.113
[59,     1] loss: 0.140
[60,     1] loss: 0.129
Early stopping applied (best metric=0.30856195092201233)
Finished Training
Total time taken: 7.0670013427734375
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.703
[2,     1] loss: 0.692
[3,     1] loss: 0.690
[4,     1] loss: 0.689
[5,     1] loss: 0.676
[6,     1] loss: 0.651
[7,     1] loss: 0.616
[8,     1] loss: 0.594
[9,     1] loss: 0.564
[10,     1] loss: 0.536
[11,     1] loss: 0.506
[12,     1] loss: 0.486
[13,     1] loss: 0.475
[14,     1] loss: 0.469
[15,     1] loss: 0.443
[16,     1] loss: 0.454
[17,     1] loss: 0.417
[18,     1] loss: 0.411
[19,     1] loss: 0.417
[20,     1] loss: 0.409
[21,     1] loss: 0.360
[22,     1] loss: 0.367
[23,     1] loss: 0.366
[24,     1] loss: 0.324
[25,     1] loss: 0.391
[26,     1] loss: 0.333
[27,     1] loss: 0.302
[28,     1] loss: 0.267
[29,     1] loss: 0.302
[30,     1] loss: 0.248
[31,     1] loss: 0.311
[32,     1] loss: 0.277
[33,     1] loss: 0.240
[34,     1] loss: 0.230
[35,     1] loss: 0.202
[36,     1] loss: 0.198
[37,     1] loss: 0.225
[38,     1] loss: 0.147
[39,     1] loss: 0.237
[40,     1] loss: 0.188
[41,     1] loss: 0.248
[42,     1] loss: 0.144
[43,     1] loss: 0.262
[44,     1] loss: 0.135
[45,     1] loss: 0.172
[46,     1] loss: 0.173
[47,     1] loss: 0.276
[48,     1] loss: 0.175
[49,     1] loss: 0.240
[50,     1] loss: 0.178
[51,     1] loss: 0.221
[52,     1] loss: 0.258
[53,     1] loss: 0.225
[54,     1] loss: 0.237
[55,     1] loss: 0.188
[56,     1] loss: 0.233
[57,     1] loss: 0.155
[58,     1] loss: 0.138
[59,     1] loss: 0.161
[60,     1] loss: 0.159
[61,     1] loss: 0.139
[62,     1] loss: 0.184
[63,     1] loss: 0.115
[64,     1] loss: 0.128
[65,     1] loss: 0.223
[66,     1] loss: 0.109
[67,     1] loss: 0.232
[68,     1] loss: 0.092
[69,     1] loss: 0.184
[70,     1] loss: 0.150
[71,     1] loss: 0.192
[72,     1] loss: 0.132
[73,     1] loss: 0.154
[74,     1] loss: 0.138
[75,     1] loss: 0.147
[76,     1] loss: 0.149
[77,     1] loss: 0.132
Early stopping applied (best metric=0.17854483425617218)
Finished Training
Total time taken: 9.709403038024902
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.696
[2,     1] loss: 0.691
[3,     1] loss: 0.668
[4,     1] loss: 0.626
[5,     1] loss: 0.572
[6,     1] loss: 0.535
[7,     1] loss: 0.502
[8,     1] loss: 0.459
[9,     1] loss: 0.492
[10,     1] loss: 0.407
[11,     1] loss: 0.435
[12,     1] loss: 0.381
[13,     1] loss: 0.405
[14,     1] loss: 0.355
[15,     1] loss: 0.328
[16,     1] loss: 0.312
[17,     1] loss: 0.303
[18,     1] loss: 0.246
[19,     1] loss: 0.260
[20,     1] loss: 0.260
[21,     1] loss: 0.336
[22,     1] loss: 0.247
[23,     1] loss: 0.256
[24,     1] loss: 0.231
[25,     1] loss: 0.235
[26,     1] loss: 0.212
[27,     1] loss: 0.183
[28,     1] loss: 0.134
[29,     1] loss: 0.256
[30,     1] loss: 0.178
[31,     1] loss: 0.198
[32,     1] loss: 0.181
[33,     1] loss: 0.265
[34,     1] loss: 0.127
[35,     1] loss: 0.140
[36,     1] loss: 0.162
[37,     1] loss: 0.153
[38,     1] loss: 0.156
[39,     1] loss: 0.121
[40,     1] loss: 0.161
[41,     1] loss: 0.165
[42,     1] loss: 0.149
[43,     1] loss: 0.127
[44,     1] loss: 0.158
[45,     1] loss: 0.139
[46,     1] loss: 0.155
[47,     1] loss: 0.181
[48,     1] loss: 0.130
[49,     1] loss: 0.165
[50,     1] loss: 0.145
[51,     1] loss: 0.130
[52,     1] loss: 0.187
[53,     1] loss: 0.148
[54,     1] loss: 0.188
[55,     1] loss: 0.103
[56,     1] loss: 0.135
[57,     1] loss: 0.182
[58,     1] loss: 0.080
[59,     1] loss: 0.104
[60,     1] loss: 0.081
[61,     1] loss: 0.094
Early stopping applied (best metric=0.35399195551872253)
Finished Training
Total time taken: 7.764096975326538
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.695
[2,     1] loss: 0.688
[3,     1] loss: 0.694
[4,     1] loss: 0.678
[5,     1] loss: 0.656
[6,     1] loss: 0.622
[7,     1] loss: 0.575
[8,     1] loss: 0.549
[9,     1] loss: 0.537
[10,     1] loss: 0.447
[11,     1] loss: 0.431
[12,     1] loss: 0.411
[13,     1] loss: 0.381
[14,     1] loss: 0.349
[15,     1] loss: 0.370
[16,     1] loss: 0.400
[17,     1] loss: 0.302
[18,     1] loss: 0.237
[19,     1] loss: 0.322
[20,     1] loss: 0.238
[21,     1] loss: 0.254
[22,     1] loss: 0.213
[23,     1] loss: 0.254
[24,     1] loss: 0.195
[25,     1] loss: 0.197
[26,     1] loss: 0.215
[27,     1] loss: 0.267
[28,     1] loss: 0.184
[29,     1] loss: 0.218
[30,     1] loss: 0.189
[31,     1] loss: 0.163
[32,     1] loss: 0.115
[33,     1] loss: 0.114
[34,     1] loss: 0.121
[35,     1] loss: 0.126
[36,     1] loss: 0.141
[37,     1] loss: 0.140
[38,     1] loss: 0.127
[39,     1] loss: 0.209
[40,     1] loss: 0.106
[41,     1] loss: 0.136
[42,     1] loss: 0.102
[43,     1] loss: 0.156
[44,     1] loss: 0.114
[45,     1] loss: 0.115
[46,     1] loss: 0.086
[47,     1] loss: 0.108
[48,     1] loss: 0.096
[49,     1] loss: 0.089
[50,     1] loss: 0.081
[51,     1] loss: 0.128
[52,     1] loss: 0.085
[53,     1] loss: 0.096
[54,     1] loss: 0.047
[55,     1] loss: 0.070
[56,     1] loss: 0.068
[57,     1] loss: 0.054
[58,     1] loss: 0.098
[59,     1] loss: 0.096
[60,     1] loss: 0.097
[61,     1] loss: 0.206
Early stopping applied (best metric=0.35448288917541504)
Finished Training
Total time taken: 7.905075788497925
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.696
[2,     1] loss: 0.694
[3,     1] loss: 0.677
[4,     1] loss: 0.648
[5,     1] loss: 0.617
[6,     1] loss: 0.569
[7,     1] loss: 0.530
[8,     1] loss: 0.500
[9,     1] loss: 0.456
[10,     1] loss: 0.422
[11,     1] loss: 0.358
[12,     1] loss: 0.348
[13,     1] loss: 0.312
[14,     1] loss: 0.305
[15,     1] loss: 0.293
[16,     1] loss: 0.305
[17,     1] loss: 0.255
[18,     1] loss: 0.203
[19,     1] loss: 0.203
[20,     1] loss: 0.181
[21,     1] loss: 0.178
[22,     1] loss: 0.230
[23,     1] loss: 0.207
[24,     1] loss: 0.144
[25,     1] loss: 0.161
[26,     1] loss: 0.154
[27,     1] loss: 0.198
[28,     1] loss: 0.155
[29,     1] loss: 0.165
[30,     1] loss: 0.142
[31,     1] loss: 0.175
[32,     1] loss: 0.124
[33,     1] loss: 0.158
[34,     1] loss: 0.149
[35,     1] loss: 0.123
[36,     1] loss: 0.114
[37,     1] loss: 0.149
[38,     1] loss: 0.173
[39,     1] loss: 0.120
[40,     1] loss: 0.165
[41,     1] loss: 0.160
[42,     1] loss: 0.096
[43,     1] loss: 0.128
[44,     1] loss: 0.092
[45,     1] loss: 0.098
[46,     1] loss: 0.163
[47,     1] loss: 0.189
[48,     1] loss: 0.140
[49,     1] loss: 0.174
[50,     1] loss: 0.093
[51,     1] loss: 0.120
[52,     1] loss: 0.106
[53,     1] loss: 0.196
[54,     1] loss: 0.122
[55,     1] loss: 0.087
[56,     1] loss: 0.134
[57,     1] loss: 0.111
[58,     1] loss: 0.119
Early stopping applied (best metric=0.4241659641265869)
Finished Training
Total time taken: 7.349446058273315
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.695
[2,     1] loss: 0.693
[3,     1] loss: 0.666
[4,     1] loss: 0.628
[5,     1] loss: 0.582
[6,     1] loss: 0.566
[7,     1] loss: 0.501
[8,     1] loss: 0.431
[9,     1] loss: 0.425
[10,     1] loss: 0.373
[11,     1] loss: 0.381
[12,     1] loss: 0.326
[13,     1] loss: 0.333
[14,     1] loss: 0.321
[15,     1] loss: 0.362
[16,     1] loss: 0.362
[17,     1] loss: 0.388
[18,     1] loss: 0.322
[19,     1] loss: 0.337
[20,     1] loss: 0.270
[21,     1] loss: 0.364
[22,     1] loss: 0.307
[23,     1] loss: 0.299
[24,     1] loss: 0.296
[25,     1] loss: 0.243
[26,     1] loss: 0.274
[27,     1] loss: 0.230
[28,     1] loss: 0.278
[29,     1] loss: 0.273
[30,     1] loss: 0.205
[31,     1] loss: 0.224
[32,     1] loss: 0.202
[33,     1] loss: 0.208
[34,     1] loss: 0.154
[35,     1] loss: 0.231
[36,     1] loss: 0.120
[37,     1] loss: 0.166
[38,     1] loss: 0.117
[39,     1] loss: 0.182
[40,     1] loss: 0.081
[41,     1] loss: 0.103
[42,     1] loss: 0.093
[43,     1] loss: 0.094
[44,     1] loss: 0.123
[45,     1] loss: 0.105
[46,     1] loss: 0.067
[47,     1] loss: 0.089
[48,     1] loss: 0.094
[49,     1] loss: 0.101
[50,     1] loss: 0.091
[51,     1] loss: 0.127
[52,     1] loss: 0.057
[53,     1] loss: 0.100
[54,     1] loss: 0.097
[55,     1] loss: 0.063
[56,     1] loss: 0.089
[57,     1] loss: 0.058
[58,     1] loss: 0.112
[59,     1] loss: 0.053
[60,     1] loss: 0.060
[61,     1] loss: 0.111
[62,     1] loss: 0.069
[63,     1] loss: 0.068
[64,     1] loss: 0.070
[65,     1] loss: 0.049
[66,     1] loss: 0.076
[67,     1] loss: 0.083
[68,     1] loss: 0.102
[69,     1] loss: 0.075
[70,     1] loss: 0.070
Early stopping applied (best metric=0.30267125368118286)
Finished Training
Total time taken: 8.828033685684204
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.690
[2,     1] loss: 0.690
[3,     1] loss: 0.658
[4,     1] loss: 0.615
[5,     1] loss: 0.579
[6,     1] loss: 0.519
[7,     1] loss: 0.439
[8,     1] loss: 0.442
[9,     1] loss: 0.383
[10,     1] loss: 0.343
[11,     1] loss: 0.279
[12,     1] loss: 0.343
[13,     1] loss: 0.242
[14,     1] loss: 0.225
[15,     1] loss: 0.213
[16,     1] loss: 0.195
[17,     1] loss: 0.198
[18,     1] loss: 0.165
[19,     1] loss: 0.172
[20,     1] loss: 0.135
[21,     1] loss: 0.199
[22,     1] loss: 0.246
[23,     1] loss: 0.186
[24,     1] loss: 0.171
[25,     1] loss: 0.130
[26,     1] loss: 0.137
[27,     1] loss: 0.111
[28,     1] loss: 0.087
[29,     1] loss: 0.132
[30,     1] loss: 0.134
[31,     1] loss: 0.108
[32,     1] loss: 0.096
[33,     1] loss: 0.067
[34,     1] loss: 0.096
[35,     1] loss: 0.069
[36,     1] loss: 0.087
[37,     1] loss: 0.074
[38,     1] loss: 0.099
[39,     1] loss: 0.111
[40,     1] loss: 0.074
[41,     1] loss: 0.093
[42,     1] loss: 0.053
[43,     1] loss: 0.106
[44,     1] loss: 0.089
[45,     1] loss: 0.083
[46,     1] loss: 0.068
[47,     1] loss: 0.076
[48,     1] loss: 0.092
[49,     1] loss: 0.070
[50,     1] loss: 0.063
[51,     1] loss: 0.054
[52,     1] loss: 0.106
[53,     1] loss: 0.041
[54,     1] loss: 0.053
[55,     1] loss: 0.060
[56,     1] loss: 0.031
Early stopping applied (best metric=0.4622929096221924)
Finished Training
Total time taken: 6.937141180038452
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.694
[2,     1] loss: 0.699
[3,     1] loss: 0.684
[4,     1] loss: 0.662
[5,     1] loss: 0.640
[6,     1] loss: 0.580
[7,     1] loss: 0.566
[8,     1] loss: 0.530
[9,     1] loss: 0.508
[10,     1] loss: 0.451
[11,     1] loss: 0.420
[12,     1] loss: 0.374
[13,     1] loss: 0.356
[14,     1] loss: 0.384
[15,     1] loss: 0.346
[16,     1] loss: 0.278
[17,     1] loss: 0.292
[18,     1] loss: 0.313
[19,     1] loss: 0.267
[20,     1] loss: 0.281
[21,     1] loss: 0.271
[22,     1] loss: 0.288
[23,     1] loss: 0.228
[24,     1] loss: 0.271
[25,     1] loss: 0.209
[26,     1] loss: 0.251
[27,     1] loss: 0.219
[28,     1] loss: 0.245
[29,     1] loss: 0.226
[30,     1] loss: 0.264
[31,     1] loss: 0.201
[32,     1] loss: 0.233
[33,     1] loss: 0.156
[34,     1] loss: 0.176
[35,     1] loss: 0.195
[36,     1] loss: 0.205
[37,     1] loss: 0.184
[38,     1] loss: 0.175
[39,     1] loss: 0.153
[40,     1] loss: 0.109
[41,     1] loss: 0.132
[42,     1] loss: 0.161
[43,     1] loss: 0.092
[44,     1] loss: 0.100
[45,     1] loss: 0.111
[46,     1] loss: 0.195
[47,     1] loss: 0.133
[48,     1] loss: 0.087
[49,     1] loss: 0.097
[50,     1] loss: 0.062
[51,     1] loss: 0.095
[52,     1] loss: 0.079
[53,     1] loss: 0.076
[54,     1] loss: 0.106
[55,     1] loss: 0.092
[56,     1] loss: 0.135
[57,     1] loss: 0.056
[58,     1] loss: 0.054
[59,     1] loss: 0.083
[60,     1] loss: 0.090
Early stopping applied (best metric=0.3613381087779999)
Finished Training
Total time taken: 6.8300087451934814
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.694
[2,     1] loss: 0.689
[3,     1] loss: 0.666
[4,     1] loss: 0.621
[5,     1] loss: 0.576
[6,     1] loss: 0.548
[7,     1] loss: 0.491
[8,     1] loss: 0.426
[9,     1] loss: 0.355
[10,     1] loss: 0.333
[11,     1] loss: 0.280
[12,     1] loss: 0.250
[13,     1] loss: 0.230
[14,     1] loss: 0.247
[15,     1] loss: 0.269
[16,     1] loss: 0.188
[17,     1] loss: 0.260
[18,     1] loss: 0.189
[19,     1] loss: 0.128
[20,     1] loss: 0.133
[21,     1] loss: 0.228
[22,     1] loss: 0.174
[23,     1] loss: 0.175
[24,     1] loss: 0.157
[25,     1] loss: 0.176
[26,     1] loss: 0.181
[27,     1] loss: 0.161
[28,     1] loss: 0.133
[29,     1] loss: 0.121
[30,     1] loss: 0.150
[31,     1] loss: 0.127
[32,     1] loss: 0.084
[33,     1] loss: 0.118
[34,     1] loss: 0.093
[35,     1] loss: 0.089
[36,     1] loss: 0.142
[37,     1] loss: 0.141
[38,     1] loss: 0.121
[39,     1] loss: 0.282
[40,     1] loss: 0.169
[41,     1] loss: 0.276
[42,     1] loss: 0.213
[43,     1] loss: 0.239
[44,     1] loss: 0.162
[45,     1] loss: 0.278
[46,     1] loss: 0.191
[47,     1] loss: 0.133
[48,     1] loss: 0.144
[49,     1] loss: 0.208
[50,     1] loss: 0.208
[51,     1] loss: 0.149
[52,     1] loss: 0.158
[53,     1] loss: 0.133
[54,     1] loss: 0.107
[55,     1] loss: 0.116
Early stopping applied (best metric=0.5063332915306091)
Finished Training
Total time taken: 6.196996688842773
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.699
[2,     1] loss: 0.695
[3,     1] loss: 0.685
[4,     1] loss: 0.662
[5,     1] loss: 0.644
[6,     1] loss: 0.627
[7,     1] loss: 0.554
[8,     1] loss: 0.559
[9,     1] loss: 0.529
[10,     1] loss: 0.497
[11,     1] loss: 0.497
[12,     1] loss: 0.460
[13,     1] loss: 0.436
[14,     1] loss: 0.407
[15,     1] loss: 0.395
[16,     1] loss: 0.397
[17,     1] loss: 0.382
[18,     1] loss: 0.377
[19,     1] loss: 0.327
[20,     1] loss: 0.308
[21,     1] loss: 0.285
[22,     1] loss: 0.240
[23,     1] loss: 0.206
[24,     1] loss: 0.250
[25,     1] loss: 0.263
[26,     1] loss: 0.259
[27,     1] loss: 0.222
[28,     1] loss: 0.293
[29,     1] loss: 0.194
[30,     1] loss: 0.165
[31,     1] loss: 0.184
[32,     1] loss: 0.158
[33,     1] loss: 0.136
[34,     1] loss: 0.211
[35,     1] loss: 0.133
[36,     1] loss: 0.174
[37,     1] loss: 0.153
[38,     1] loss: 0.144
[39,     1] loss: 0.119
[40,     1] loss: 0.128
[41,     1] loss: 0.129
[42,     1] loss: 0.178
[43,     1] loss: 0.123
[44,     1] loss: 0.109
[45,     1] loss: 0.174
[46,     1] loss: 0.131
[47,     1] loss: 0.141
[48,     1] loss: 0.133
[49,     1] loss: 0.112
[50,     1] loss: 0.143
[51,     1] loss: 0.133
[52,     1] loss: 0.269
[53,     1] loss: 0.140
[54,     1] loss: 0.223
[55,     1] loss: 0.221
[56,     1] loss: 0.183
[57,     1] loss: 0.133
[58,     1] loss: 0.160
[59,     1] loss: 0.221
[60,     1] loss: 0.121
[61,     1] loss: 0.183
[62,     1] loss: 0.177
[63,     1] loss: 0.183
[64,     1] loss: 0.144
[65,     1] loss: 0.164
[66,     1] loss: 0.247
[67,     1] loss: 0.142
[68,     1] loss: 0.161
[69,     1] loss: 0.183
Early stopping applied (best metric=0.4469297528266907)
Finished Training
Total time taken: 7.79201078414917
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.696
[2,     1] loss: 0.696
[3,     1] loss: 0.668
[4,     1] loss: 0.632
[5,     1] loss: 0.600
[6,     1] loss: 0.552
[7,     1] loss: 0.527
[8,     1] loss: 0.504
[9,     1] loss: 0.471
[10,     1] loss: 0.401
[11,     1] loss: 0.440
[12,     1] loss: 0.407
[13,     1] loss: 0.369
[14,     1] loss: 0.460
[15,     1] loss: 0.403
[16,     1] loss: 0.325
[17,     1] loss: 0.311
[18,     1] loss: 0.291
[19,     1] loss: 0.318
[20,     1] loss: 0.279
[21,     1] loss: 0.320
[22,     1] loss: 0.251
[23,     1] loss: 0.244
[24,     1] loss: 0.237
[25,     1] loss: 0.220
[26,     1] loss: 0.210
[27,     1] loss: 0.226
[28,     1] loss: 0.140
[29,     1] loss: 0.210
[30,     1] loss: 0.166
[31,     1] loss: 0.135
[32,     1] loss: 0.164
[33,     1] loss: 0.179
[34,     1] loss: 0.179
[35,     1] loss: 0.114
[36,     1] loss: 0.126
[37,     1] loss: 0.140
[38,     1] loss: 0.134
[39,     1] loss: 0.146
[40,     1] loss: 0.093
[41,     1] loss: 0.166
[42,     1] loss: 0.129
[43,     1] loss: 0.104
[44,     1] loss: 0.095
[45,     1] loss: 0.108
[46,     1] loss: 0.110
[47,     1] loss: 0.068
[48,     1] loss: 0.093
[49,     1] loss: 0.138
[50,     1] loss: 0.396
[51,     1] loss: 0.170
[52,     1] loss: 0.189
[53,     1] loss: 0.211
[54,     1] loss: 0.147
[55,     1] loss: 0.119
[56,     1] loss: 0.129
[57,     1] loss: 0.139
[58,     1] loss: 0.148
[59,     1] loss: 0.164
[60,     1] loss: 0.118
[61,     1] loss: 0.108
[62,     1] loss: 0.126
[63,     1] loss: 0.101
Early stopping applied (best metric=0.41207006573677063)
Finished Training
Total time taken: 7.096689939498901
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.693
[2,     1] loss: 0.682
[3,     1] loss: 0.660
[4,     1] loss: 0.609
[5,     1] loss: 0.587
[6,     1] loss: 0.521
[7,     1] loss: 0.497
[8,     1] loss: 0.496
[9,     1] loss: 0.398
[10,     1] loss: 0.395
[11,     1] loss: 0.378
[12,     1] loss: 0.341
[13,     1] loss: 0.381
[14,     1] loss: 0.296
[15,     1] loss: 0.336
[16,     1] loss: 0.249
[17,     1] loss: 0.252
[18,     1] loss: 0.242
[19,     1] loss: 0.273
[20,     1] loss: 0.228
[21,     1] loss: 0.221
[22,     1] loss: 0.235
[23,     1] loss: 0.157
[24,     1] loss: 0.215
[25,     1] loss: 0.148
[26,     1] loss: 0.140
[27,     1] loss: 0.135
[28,     1] loss: 0.157
[29,     1] loss: 0.154
[30,     1] loss: 0.116
[31,     1] loss: 0.176
[32,     1] loss: 0.138
[33,     1] loss: 0.132
[34,     1] loss: 0.125
[35,     1] loss: 0.118
[36,     1] loss: 0.158
[37,     1] loss: 0.116
[38,     1] loss: 0.143
[39,     1] loss: 0.117
[40,     1] loss: 0.097
[41,     1] loss: 0.097
[42,     1] loss: 0.109
[43,     1] loss: 0.162
[44,     1] loss: 0.112
[45,     1] loss: 0.085
[46,     1] loss: 0.115
[47,     1] loss: 0.077
[48,     1] loss: 0.087
[49,     1] loss: 0.072
[50,     1] loss: 0.078
[51,     1] loss: 0.054
[52,     1] loss: 0.086
[53,     1] loss: 0.045
[54,     1] loss: 0.080
[55,     1] loss: 0.087
[56,     1] loss: 0.089
[57,     1] loss: 0.067
[58,     1] loss: 0.066
[59,     1] loss: 0.201
[60,     1] loss: 0.107
[61,     1] loss: 0.086
[62,     1] loss: 0.070
[63,     1] loss: 0.136
Early stopping applied (best metric=0.23783628642559052)
Finished Training
Total time taken: 7.0840020179748535
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.695
[2,     1] loss: 0.685
[3,     1] loss: 0.657
[4,     1] loss: 0.618
[5,     1] loss: 0.582
[6,     1] loss: 0.565
[7,     1] loss: 0.485
[8,     1] loss: 0.436
[9,     1] loss: 0.436
[10,     1] loss: 0.443
[11,     1] loss: 0.400
[12,     1] loss: 0.404
[13,     1] loss: 0.320
[14,     1] loss: 0.364
[15,     1] loss: 0.284
[16,     1] loss: 0.387
[17,     1] loss: 0.352
[18,     1] loss: 0.288
[19,     1] loss: 0.301
[20,     1] loss: 0.271
[21,     1] loss: 0.265
[22,     1] loss: 0.304
[23,     1] loss: 0.256
[24,     1] loss: 0.245
[25,     1] loss: 0.226
[26,     1] loss: 0.237
[27,     1] loss: 0.212
[28,     1] loss: 0.206
[29,     1] loss: 0.139
[30,     1] loss: 0.206
[31,     1] loss: 0.197
[32,     1] loss: 0.136
[33,     1] loss: 0.156
[34,     1] loss: 0.122
[35,     1] loss: 0.154
[36,     1] loss: 0.154
[37,     1] loss: 0.146
[38,     1] loss: 0.105
[39,     1] loss: 0.196
[40,     1] loss: 0.117
[41,     1] loss: 0.351
[42,     1] loss: 0.092
[43,     1] loss: 0.232
[44,     1] loss: 0.135
[45,     1] loss: 0.157
[46,     1] loss: 0.165
[47,     1] loss: 0.225
[48,     1] loss: 0.160
[49,     1] loss: 0.146
[50,     1] loss: 0.146
[51,     1] loss: 0.135
[52,     1] loss: 0.129
[53,     1] loss: 0.146
[54,     1] loss: 0.095
[55,     1] loss: 0.113
[56,     1] loss: 0.092
[57,     1] loss: 0.080
[58,     1] loss: 0.095
[59,     1] loss: 0.080
[60,     1] loss: 0.101
[61,     1] loss: 0.151
[62,     1] loss: 0.125
[63,     1] loss: 0.075
[64,     1] loss: 0.095
[65,     1] loss: 0.148
Early stopping applied (best metric=0.2749617099761963)
Finished Training
Total time taken: 7.322011947631836
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.693
[2,     1] loss: 0.689
[3,     1] loss: 0.662
[4,     1] loss: 0.624
[5,     1] loss: 0.569
[6,     1] loss: 0.558
[7,     1] loss: 0.492
[8,     1] loss: 0.458
[9,     1] loss: 0.433
[10,     1] loss: 0.419
[11,     1] loss: 0.365
[12,     1] loss: 0.349
[13,     1] loss: 0.310
[14,     1] loss: 0.245
[15,     1] loss: 0.234
[16,     1] loss: 0.266
[17,     1] loss: 0.248
[18,     1] loss: 0.232
[19,     1] loss: 0.267
[20,     1] loss: 0.239
[21,     1] loss: 0.366
[22,     1] loss: 0.315
[23,     1] loss: 0.191
[24,     1] loss: 0.215
[25,     1] loss: 0.228
[26,     1] loss: 0.218
[27,     1] loss: 0.217
[28,     1] loss: 0.202
[29,     1] loss: 0.146
[30,     1] loss: 0.238
[31,     1] loss: 0.172
[32,     1] loss: 0.187
[33,     1] loss: 0.202
[34,     1] loss: 0.201
[35,     1] loss: 0.166
[36,     1] loss: 0.187
[37,     1] loss: 0.156
[38,     1] loss: 0.187
[39,     1] loss: 0.163
[40,     1] loss: 0.129
[41,     1] loss: 0.102
[42,     1] loss: 0.115
[43,     1] loss: 0.134
[44,     1] loss: 0.145
[45,     1] loss: 0.128
[46,     1] loss: 0.096
[47,     1] loss: 0.147
[48,     1] loss: 0.106
[49,     1] loss: 0.164
[50,     1] loss: 0.115
[51,     1] loss: 0.173
[52,     1] loss: 0.187
[53,     1] loss: 0.136
[54,     1] loss: 0.104
[55,     1] loss: 0.112
[56,     1] loss: 0.133
[57,     1] loss: 0.100
[58,     1] loss: 0.086
[59,     1] loss: 0.117
[60,     1] loss: 0.104
Early stopping applied (best metric=0.3050748407840729)
Finished Training
Total time taken: 6.795000314712524
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.697
[2,     1] loss: 0.691
[3,     1] loss: 0.685
[4,     1] loss: 0.690
[5,     1] loss: 0.672
[6,     1] loss: 0.672
[7,     1] loss: 0.640
[8,     1] loss: 0.606
[9,     1] loss: 0.545
[10,     1] loss: 0.509
[11,     1] loss: 0.472
[12,     1] loss: 0.414
[13,     1] loss: 0.407
[14,     1] loss: 0.391
[15,     1] loss: 0.323
[16,     1] loss: 0.319
[17,     1] loss: 0.379
[18,     1] loss: 0.249
[19,     1] loss: 0.224
[20,     1] loss: 0.277
[21,     1] loss: 0.312
[22,     1] loss: 0.264
[23,     1] loss: 0.273
[24,     1] loss: 0.259
[25,     1] loss: 0.218
[26,     1] loss: 0.257
[27,     1] loss: 0.209
[28,     1] loss: 0.228
[29,     1] loss: 0.184
[30,     1] loss: 0.194
[31,     1] loss: 0.227
[32,     1] loss: 0.220
[33,     1] loss: 0.234
[34,     1] loss: 0.169
[35,     1] loss: 0.187
[36,     1] loss: 0.150
[37,     1] loss: 0.153
[38,     1] loss: 0.124
[39,     1] loss: 0.192
[40,     1] loss: 0.115
[41,     1] loss: 0.110
[42,     1] loss: 0.158
[43,     1] loss: 0.118
[44,     1] loss: 0.186
[45,     1] loss: 0.129
[46,     1] loss: 0.174
[47,     1] loss: 0.137
[48,     1] loss: 0.115
[49,     1] loss: 0.099
[50,     1] loss: 0.153
[51,     1] loss: 0.099
[52,     1] loss: 0.097
[53,     1] loss: 0.114
[54,     1] loss: 0.148
[55,     1] loss: 0.101
[56,     1] loss: 0.107
[57,     1] loss: 0.112
[58,     1] loss: 0.061
[59,     1] loss: 0.122
[60,     1] loss: 0.120
[61,     1] loss: 0.145
[62,     1] loss: 0.121
[63,     1] loss: 0.127
[64,     1] loss: 0.079
[65,     1] loss: 0.076
[66,     1] loss: 0.074
[67,     1] loss: 0.109
Early stopping applied (best metric=0.31782469153404236)
Finished Training
Total time taken: 7.848009347915649
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.691
[2,     1] loss: 0.691
[3,     1] loss: 0.661
[4,     1] loss: 0.625
[5,     1] loss: 0.576
[6,     1] loss: 0.545
[7,     1] loss: 0.461
[8,     1] loss: 0.384
[9,     1] loss: 0.368
[10,     1] loss: 0.363
[11,     1] loss: 0.384
[12,     1] loss: 0.267
[13,     1] loss: 0.217
[14,     1] loss: 0.266
[15,     1] loss: 0.288
[16,     1] loss: 0.338
[17,     1] loss: 0.275
[18,     1] loss: 0.253
[19,     1] loss: 0.235
[20,     1] loss: 0.181
[21,     1] loss: 0.234
[22,     1] loss: 0.195
[23,     1] loss: 0.180
[24,     1] loss: 0.183
[25,     1] loss: 0.236
[26,     1] loss: 0.215
[27,     1] loss: 0.179
[28,     1] loss: 0.200
[29,     1] loss: 0.191
[30,     1] loss: 0.188
[31,     1] loss: 0.157
[32,     1] loss: 0.118
[33,     1] loss: 0.141
[34,     1] loss: 0.155
[35,     1] loss: 0.164
[36,     1] loss: 0.164
[37,     1] loss: 0.118
[38,     1] loss: 0.107
[39,     1] loss: 0.113
[40,     1] loss: 0.116
[41,     1] loss: 0.125
[42,     1] loss: 0.215
[43,     1] loss: 0.119
[44,     1] loss: 0.123
[45,     1] loss: 0.363
[46,     1] loss: 0.236
[47,     1] loss: 0.327
[48,     1] loss: 0.278
[49,     1] loss: 0.317
[50,     1] loss: 0.275
[51,     1] loss: 0.207
[52,     1] loss: 0.198
[53,     1] loss: 0.188
[54,     1] loss: 0.221
[55,     1] loss: 0.220
[56,     1] loss: 0.219
[57,     1] loss: 0.242
[58,     1] loss: 0.182
Early stopping applied (best metric=0.34603220224380493)
Finished Training
Total time taken: 7.175870418548584
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.696
[2,     1] loss: 0.696
[3,     1] loss: 0.675
[4,     1] loss: 0.639
[5,     1] loss: 0.625
[6,     1] loss: 0.576
[7,     1] loss: 0.507
[8,     1] loss: 0.492
[9,     1] loss: 0.419
[10,     1] loss: 0.408
[11,     1] loss: 0.341
[12,     1] loss: 0.369
[13,     1] loss: 0.274
[14,     1] loss: 0.289
[15,     1] loss: 0.330
[16,     1] loss: 0.294
[17,     1] loss: 0.264
[18,     1] loss: 0.217
[19,     1] loss: 0.262
[20,     1] loss: 0.261
[21,     1] loss: 0.324
[22,     1] loss: 0.267
[23,     1] loss: 0.267
[24,     1] loss: 0.221
[25,     1] loss: 0.280
[26,     1] loss: 0.300
[27,     1] loss: 0.235
[28,     1] loss: 0.215
[29,     1] loss: 0.258
[30,     1] loss: 0.211
[31,     1] loss: 0.241
[32,     1] loss: 0.213
[33,     1] loss: 0.226
[34,     1] loss: 0.216
[35,     1] loss: 0.202
[36,     1] loss: 0.203
[37,     1] loss: 0.233
[38,     1] loss: 0.192
[39,     1] loss: 0.206
[40,     1] loss: 0.198
[41,     1] loss: 0.182
[42,     1] loss: 0.136
[43,     1] loss: 0.158
[44,     1] loss: 0.125
[45,     1] loss: 0.174
[46,     1] loss: 0.146
[47,     1] loss: 0.134
[48,     1] loss: 0.078
[49,     1] loss: 0.091
[50,     1] loss: 0.135
[51,     1] loss: 0.113
[52,     1] loss: 0.131
[53,     1] loss: 0.109
[54,     1] loss: 0.252
[55,     1] loss: 0.129
[56,     1] loss: 0.234
[57,     1] loss: 0.160
[58,     1] loss: 0.116
[59,     1] loss: 0.191
[60,     1] loss: 0.113
[61,     1] loss: 0.189
[62,     1] loss: 0.146
[63,     1] loss: 0.122
[64,     1] loss: 0.157
[65,     1] loss: 0.133
[66,     1] loss: 0.118
[67,     1] loss: 0.109
[68,     1] loss: 0.125
[69,     1] loss: 0.074
[70,     1] loss: 0.140
[71,     1] loss: 0.111
[72,     1] loss: 0.051
[73,     1] loss: 0.131
[74,     1] loss: 0.103
[75,     1] loss: 0.102
[76,     1] loss: 0.094
[77,     1] loss: 0.077
[78,     1] loss: 0.110
[79,     1] loss: 0.064
[80,     1] loss: 0.090
[81,     1] loss: 0.051
Early stopping applied (best metric=0.24475690722465515)
Finished Training
Total time taken: 9.532148361206055
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.694
[2,     1] loss: 0.689
[3,     1] loss: 0.670
[4,     1] loss: 0.627
[5,     1] loss: 0.558
[6,     1] loss: 0.524
[7,     1] loss: 0.528
[8,     1] loss: 0.424
[9,     1] loss: 0.407
[10,     1] loss: 0.407
[11,     1] loss: 0.427
[12,     1] loss: 0.344
[13,     1] loss: 0.369
[14,     1] loss: 0.338
[15,     1] loss: 0.363
[16,     1] loss: 0.354
[17,     1] loss: 0.297
[18,     1] loss: 0.356
[19,     1] loss: 0.325
[20,     1] loss: 0.384
[21,     1] loss: 0.314
[22,     1] loss: 0.356
[23,     1] loss: 0.306
[24,     1] loss: 0.283
[25,     1] loss: 0.328
[26,     1] loss: 0.325
[27,     1] loss: 0.283
[28,     1] loss: 0.235
[29,     1] loss: 0.321
[30,     1] loss: 0.212
[31,     1] loss: 0.245
[32,     1] loss: 0.344
[33,     1] loss: 0.194
[34,     1] loss: 0.238
[35,     1] loss: 0.158
[36,     1] loss: 0.171
[37,     1] loss: 0.168
[38,     1] loss: 0.173
[39,     1] loss: 0.120
[40,     1] loss: 0.112
[41,     1] loss: 0.123
[42,     1] loss: 0.078
[43,     1] loss: 0.078
[44,     1] loss: 0.094
[45,     1] loss: 0.084
[46,     1] loss: 0.161
[47,     1] loss: 0.127
[48,     1] loss: 0.135
[49,     1] loss: 0.104
[50,     1] loss: 0.082
[51,     1] loss: 0.101
[52,     1] loss: 0.076
[53,     1] loss: 0.092
[54,     1] loss: 0.161
[55,     1] loss: 0.090
Early stopping applied (best metric=0.4896431863307953)
Finished Training
Total time taken: 7.254999160766602
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.697
[2,     1] loss: 0.695
[3,     1] loss: 0.683
[4,     1] loss: 0.663
[5,     1] loss: 0.634
[6,     1] loss: 0.630
[7,     1] loss: 0.578
[8,     1] loss: 0.534
[9,     1] loss: 0.518
[10,     1] loss: 0.507
[11,     1] loss: 0.456
[12,     1] loss: 0.407
[13,     1] loss: 0.391
[14,     1] loss: 0.416
[15,     1] loss: 0.385
[16,     1] loss: 0.333
[17,     1] loss: 0.361
[18,     1] loss: 0.267
[19,     1] loss: 0.341
[20,     1] loss: 0.364
[21,     1] loss: 0.270
[22,     1] loss: 0.345
[23,     1] loss: 0.246
[24,     1] loss: 0.227
[25,     1] loss: 0.253
[26,     1] loss: 0.223
[27,     1] loss: 0.194
[28,     1] loss: 0.277
[29,     1] loss: 0.262
[30,     1] loss: 0.234
[31,     1] loss: 0.231
[32,     1] loss: 0.202
[33,     1] loss: 0.243
[34,     1] loss: 0.161
[35,     1] loss: 0.198
[36,     1] loss: 0.232
[37,     1] loss: 0.209
[38,     1] loss: 0.255
[39,     1] loss: 0.171
[40,     1] loss: 0.200
[41,     1] loss: 0.160
[42,     1] loss: 0.163
[43,     1] loss: 0.112
[44,     1] loss: 0.131
[45,     1] loss: 0.140
[46,     1] loss: 0.107
[47,     1] loss: 0.114
[48,     1] loss: 0.135
[49,     1] loss: 0.102
[50,     1] loss: 0.141
[51,     1] loss: 0.142
[52,     1] loss: 0.107
[53,     1] loss: 0.116
[54,     1] loss: 0.065
[55,     1] loss: 0.126
[56,     1] loss: 0.084
[57,     1] loss: 0.084
[58,     1] loss: 0.122
[59,     1] loss: 0.070
[60,     1] loss: 0.159
[61,     1] loss: 0.100
[62,     1] loss: 0.160
[63,     1] loss: 0.093
[64,     1] loss: 0.128
[65,     1] loss: 0.099
[66,     1] loss: 0.099
[67,     1] loss: 0.104
[68,     1] loss: 0.112
[69,     1] loss: 0.082
[70,     1] loss: 0.100
[71,     1] loss: 0.100
[72,     1] loss: 0.076
[73,     1] loss: 0.081
[74,     1] loss: 0.058
[75,     1] loss: 0.127
[76,     1] loss: 0.054
[77,     1] loss: 0.081
[78,     1] loss: 0.079
[79,     1] loss: 0.123
[80,     1] loss: 0.117
[81,     1] loss: 0.141
[82,     1] loss: 0.085
[83,     1] loss: 0.039
Early stopping applied (best metric=0.22960786521434784)
Finished Training
Total time taken: 10.074999332427979
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.691
[2,     1] loss: 0.693
[3,     1] loss: 0.669
[4,     1] loss: 0.618
[5,     1] loss: 0.565
[6,     1] loss: 0.501
[7,     1] loss: 0.444
[8,     1] loss: 0.411
[9,     1] loss: 0.372
[10,     1] loss: 0.276
[11,     1] loss: 0.321
[12,     1] loss: 0.273
[13,     1] loss: 0.223
[14,     1] loss: 0.255
[15,     1] loss: 0.267
[16,     1] loss: 0.306
[17,     1] loss: 0.226
[18,     1] loss: 0.214
[19,     1] loss: 0.168
[20,     1] loss: 0.202
[21,     1] loss: 0.164
[22,     1] loss: 0.192
[23,     1] loss: 0.125
[24,     1] loss: 0.161
[25,     1] loss: 0.170
[26,     1] loss: 0.129
[27,     1] loss: 0.144
[28,     1] loss: 0.139
[29,     1] loss: 0.156
[30,     1] loss: 0.167
[31,     1] loss: 0.150
[32,     1] loss: 0.166
[33,     1] loss: 0.147
[34,     1] loss: 0.090
[35,     1] loss: 0.110
[36,     1] loss: 0.124
[37,     1] loss: 0.110
[38,     1] loss: 0.097
[39,     1] loss: 0.105
[40,     1] loss: 0.075
[41,     1] loss: 0.109
[42,     1] loss: 0.091
[43,     1] loss: 0.086
[44,     1] loss: 0.085
[45,     1] loss: 0.094
[46,     1] loss: 0.109
[47,     1] loss: 0.088
[48,     1] loss: 0.095
[49,     1] loss: 0.084
[50,     1] loss: 0.131
[51,     1] loss: 0.083
[52,     1] loss: 0.058
[53,     1] loss: 0.062
[54,     1] loss: 0.090
[55,     1] loss: 0.093
[56,     1] loss: 0.173
[57,     1] loss: 0.098
Early stopping applied (best metric=0.460860937833786)
Finished Training
Total time taken: 6.636686086654663
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.693
[2,     1] loss: 0.680
[3,     1] loss: 0.646
[4,     1] loss: 0.590
[5,     1] loss: 0.547
[6,     1] loss: 0.488
[7,     1] loss: 0.468
[8,     1] loss: 0.401
[9,     1] loss: 0.421
[10,     1] loss: 0.376
[11,     1] loss: 0.321
[12,     1] loss: 0.367
[13,     1] loss: 0.416
[14,     1] loss: 0.342
[15,     1] loss: 0.325
[16,     1] loss: 0.245
[17,     1] loss: 0.316
[18,     1] loss: 0.231
[19,     1] loss: 0.298
[20,     1] loss: 0.306
[21,     1] loss: 0.248
[22,     1] loss: 0.219
[23,     1] loss: 0.248
[24,     1] loss: 0.242
[25,     1] loss: 0.169
[26,     1] loss: 0.178
[27,     1] loss: 0.181
[28,     1] loss: 0.172
[29,     1] loss: 0.155
[30,     1] loss: 0.155
[31,     1] loss: 0.141
[32,     1] loss: 0.132
[33,     1] loss: 0.180
[34,     1] loss: 0.125
[35,     1] loss: 0.120
[36,     1] loss: 0.129
[37,     1] loss: 0.106
[38,     1] loss: 0.116
[39,     1] loss: 0.115
[40,     1] loss: 0.165
[41,     1] loss: 0.185
[42,     1] loss: 0.100
[43,     1] loss: 0.215
[44,     1] loss: 0.179
[45,     1] loss: 0.114
[46,     1] loss: 0.160
[47,     1] loss: 0.168
[48,     1] loss: 0.124
[49,     1] loss: 0.121
[50,     1] loss: 0.105
[51,     1] loss: 0.139
[52,     1] loss: 0.101
[53,     1] loss: 0.098
[54,     1] loss: 0.095
[55,     1] loss: 0.072
[56,     1] loss: 0.109
[57,     1] loss: 0.079
[58,     1] loss: 0.122
[59,     1] loss: 0.103
[60,     1] loss: 0.161
[61,     1] loss: 0.082
[62,     1] loss: 0.219
Early stopping applied (best metric=0.362839937210083)
Finished Training
Total time taken: 7.343999147415161
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.691
[2,     1] loss: 0.692
[3,     1] loss: 0.669
[4,     1] loss: 0.639
[5,     1] loss: 0.594
[6,     1] loss: 0.562
[7,     1] loss: 0.503
[8,     1] loss: 0.447
[9,     1] loss: 0.422
[10,     1] loss: 0.407
[11,     1] loss: 0.362
[12,     1] loss: 0.310
[13,     1] loss: 0.280
[14,     1] loss: 0.277
[15,     1] loss: 0.249
[16,     1] loss: 0.259
[17,     1] loss: 0.218
[18,     1] loss: 0.275
[19,     1] loss: 0.248
[20,     1] loss: 0.329
[21,     1] loss: 0.305
[22,     1] loss: 0.230
[23,     1] loss: 0.227
[24,     1] loss: 0.182
[25,     1] loss: 0.213
[26,     1] loss: 0.182
[27,     1] loss: 0.168
[28,     1] loss: 0.173
[29,     1] loss: 0.195
[30,     1] loss: 0.134
[31,     1] loss: 0.127
[32,     1] loss: 0.119
[33,     1] loss: 0.103
[34,     1] loss: 0.096
[35,     1] loss: 0.062
[36,     1] loss: 0.101
[37,     1] loss: 0.118
[38,     1] loss: 0.093
[39,     1] loss: 0.225
[40,     1] loss: 0.143
[41,     1] loss: 0.231
[42,     1] loss: 0.251
[43,     1] loss: 0.174
[44,     1] loss: 0.150
[45,     1] loss: 0.279
[46,     1] loss: 0.103
[47,     1] loss: 0.136
[48,     1] loss: 0.167
[49,     1] loss: 0.244
[50,     1] loss: 0.196
[51,     1] loss: 0.141
[52,     1] loss: 0.114
[53,     1] loss: 0.126
[54,     1] loss: 0.123
[55,     1] loss: 0.130
[56,     1] loss: 0.082
[57,     1] loss: 0.086
[58,     1] loss: 0.104
[59,     1] loss: 0.092
[60,     1] loss: 0.089
Early stopping applied (best metric=0.31935155391693115)
Finished Training
Total time taken: 6.80600118637085
{'Hydroxylation-K Validation Accuracy': 0.8361879432624113, 'Hydroxylation-K Validation Sensitivity': 0.8142222222222222, 'Hydroxylation-K Validation Specificity': 0.8421052631578947, 'Hydroxylation-K Validation Precision': 0.5862297898180251, 'Hydroxylation-K AUC ROC': 0.837906432748538, 'Hydroxylation-K AUC PR': 0.6064412086513433, 'Hydroxylation-K MCC': 0.5905629042768329, 'Hydroxylation-K F1': 0.6746897212241804, 'Validation Loss (Hydroxylation-K)': 0.3497967767715454, 'Validation Loss (total)': 0.3497967767715454, 'TimeToTrain': 7.716048908233643}
{'CNNType': 'Musite',
 'CV_Repeats': 5,
 'CreateFigures': False,
 'Experiment Name': 'Prottrans embeddings - local',
 'FCType': 'Adapt',
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 32,
 'LSTM_layers': 1,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'aminoAcid': ['Hydroxylation-K'],
 'batch_size': 512,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 5,
 'data_sample_mode': ['oversample'],
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'protBert',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004684927881340591,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2596545613,
 'sample_weights': [1.0],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'weight_decay': 4.506776933725176}
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.693
[2,     1] loss: 0.695
[3,     1] loss: 0.681
[4,     1] loss: 0.655
[5,     1] loss: 0.616
[6,     1] loss: 0.589
[7,     1] loss: 0.513
[8,     1] loss: 0.489
[9,     1] loss: 0.416
[10,     1] loss: 0.397
[11,     1] loss: 0.426
[12,     1] loss: 0.342
[13,     1] loss: 0.299
[14,     1] loss: 0.390
[15,     1] loss: 0.286
[16,     1] loss: 0.306
[17,     1] loss: 0.334
[18,     1] loss: 0.234
[19,     1] loss: 0.253
[20,     1] loss: 0.192
[21,     1] loss: 0.234
[22,     1] loss: 0.209
[23,     1] loss: 0.160
[24,     1] loss: 0.160
[25,     1] loss: 0.179
[26,     1] loss: 0.153
[27,     1] loss: 0.157
[28,     1] loss: 0.195
[29,     1] loss: 0.141
[30,     1] loss: 0.160
[31,     1] loss: 0.137
[32,     1] loss: 0.144
[33,     1] loss: 0.135
[34,     1] loss: 0.106
[35,     1] loss: 0.103
[36,     1] loss: 0.175
[37,     1] loss: 0.149
[38,     1] loss: 0.335
[39,     1] loss: 0.136
[40,     1] loss: 0.139
[41,     1] loss: 0.311
[42,     1] loss: 0.208
[43,     1] loss: 0.143
[44,     1] loss: 0.188
[45,     1] loss: 0.236
[46,     1] loss: 0.122
[47,     1] loss: 0.161
[48,     1] loss: 0.157
[49,     1] loss: 0.138
[50,     1] loss: 0.093
[51,     1] loss: 0.111
[52,     1] loss: 0.126
[53,     1] loss: 0.112
[54,     1] loss: 0.137
[55,     1] loss: 0.090
[56,     1] loss: 0.083
[57,     1] loss: 0.106
[58,     1] loss: 0.073
[59,     1] loss: 0.104
[60,     1] loss: 0.074
[61,     1] loss: 0.085
[62,     1] loss: 0.067
[63,     1] loss: 0.123
[64,     1] loss: 0.127
[65,     1] loss: 0.091
[66,     1] loss: 0.092
[67,     1] loss: 0.115
[68,     1] loss: 0.045
[69,     1] loss: 0.111
[70,     1] loss: 0.058
[71,     1] loss: 0.099
[72,     1] loss: 0.077
[73,     1] loss: 0.063
[74,     1] loss: 0.089
[75,     1] loss: 0.061
[76,     1] loss: 0.077
[77,     1] loss: 0.084
[78,     1] loss: 0.050
[79,     1] loss: 0.077
[80,     1] loss: 0.062
[81,     1] loss: 0.064
[82,     1] loss: 0.120
[83,     1] loss: 0.105
[84,     1] loss: 0.072
[85,     1] loss: 0.093
[86,     1] loss: 0.090
[87,     1] loss: 0.097
[88,     1] loss: 0.085
[89,     1] loss: 0.065
[90,     1] loss: 0.051
[91,     1] loss: 0.063
[92,     1] loss: 0.056
[93,     1] loss: 0.066
[94,     1] loss: 0.089
[95,     1] loss: 0.123
[96,     1] loss: 0.047
[97,     1] loss: 0.138
[98,     1] loss: 0.060
[99,     1] loss: 0.073
[100,     1] loss: 0.075
Early stopping applied (best metric=0.33928346633911133)
Finished Training
Total time taken: 12.720999717712402
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.694
[2,     1] loss: 0.695
[3,     1] loss: 0.673
[4,     1] loss: 0.642
[5,     1] loss: 0.586
[6,     1] loss: 0.582
[7,     1] loss: 0.524
[8,     1] loss: 0.465
[9,     1] loss: 0.428
[10,     1] loss: 0.429
[11,     1] loss: 0.395
[12,     1] loss: 0.338
[13,     1] loss: 0.275
[14,     1] loss: 0.254
[15,     1] loss: 0.275
[16,     1] loss: 0.258
[17,     1] loss: 0.206
[18,     1] loss: 0.213
[19,     1] loss: 0.296
[20,     1] loss: 0.220
[21,     1] loss: 0.215
[22,     1] loss: 0.312
[23,     1] loss: 0.191
[24,     1] loss: 0.183
[25,     1] loss: 0.198
[26,     1] loss: 0.323
[27,     1] loss: 0.218
[28,     1] loss: 0.254
[29,     1] loss: 0.188
[30,     1] loss: 0.171
[31,     1] loss: 0.254
[32,     1] loss: 0.192
[33,     1] loss: 0.231
[34,     1] loss: 0.182
[35,     1] loss: 0.163
[36,     1] loss: 0.155
[37,     1] loss: 0.165
[38,     1] loss: 0.172
[39,     1] loss: 0.111
[40,     1] loss: 0.149
[41,     1] loss: 0.180
[42,     1] loss: 0.094
[43,     1] loss: 0.104
[44,     1] loss: 0.119
[45,     1] loss: 0.160
[46,     1] loss: 0.131
[47,     1] loss: 0.083
[48,     1] loss: 0.107
[49,     1] loss: 0.089
[50,     1] loss: 0.112
[51,     1] loss: 0.125
[52,     1] loss: 0.070
[53,     1] loss: 0.113
[54,     1] loss: 0.143
[55,     1] loss: 0.069
[56,     1] loss: 0.095
[57,     1] loss: 0.118
[58,     1] loss: 0.119
[59,     1] loss: 0.126
[60,     1] loss: 0.088
[61,     1] loss: 0.110
Early stopping applied (best metric=0.2712059020996094)
Finished Training
Total time taken: 7.705003261566162
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.694
[2,     1] loss: 0.687
[3,     1] loss: 0.663
[4,     1] loss: 0.641
[5,     1] loss: 0.581
[6,     1] loss: 0.545
[7,     1] loss: 0.480
[8,     1] loss: 0.442
[9,     1] loss: 0.427
[10,     1] loss: 0.365
[11,     1] loss: 0.346
[12,     1] loss: 0.318
[13,     1] loss: 0.302
[14,     1] loss: 0.312
[15,     1] loss: 0.272
[16,     1] loss: 0.319
[17,     1] loss: 0.433
[18,     1] loss: 0.223
[19,     1] loss: 0.376
[20,     1] loss: 0.343
[21,     1] loss: 0.291
[22,     1] loss: 0.350
[23,     1] loss: 0.339
[24,     1] loss: 0.301
[25,     1] loss: 0.291
[26,     1] loss: 0.278
[27,     1] loss: 0.259
[28,     1] loss: 0.321
[29,     1] loss: 0.274
[30,     1] loss: 0.350
[31,     1] loss: 0.303
[32,     1] loss: 0.298
[33,     1] loss: 0.295
[34,     1] loss: 0.233
[35,     1] loss: 0.315
[36,     1] loss: 0.286
[37,     1] loss: 0.275
[38,     1] loss: 0.306
[39,     1] loss: 0.255
[40,     1] loss: 0.254
[41,     1] loss: 0.259
[42,     1] loss: 0.210
[43,     1] loss: 0.243
[44,     1] loss: 0.247
[45,     1] loss: 0.255
[46,     1] loss: 0.349
[47,     1] loss: 0.246
[48,     1] loss: 0.271
[49,     1] loss: 0.308
[50,     1] loss: 0.234
[51,     1] loss: 0.379
[52,     1] loss: 0.224
[53,     1] loss: 0.262
[54,     1] loss: 0.295
[55,     1] loss: 0.274
[56,     1] loss: 0.267
[57,     1] loss: 0.223
[58,     1] loss: 0.197
[59,     1] loss: 0.176
[60,     1] loss: 0.208
[61,     1] loss: 0.251
[62,     1] loss: 0.211
[63,     1] loss: 0.159
[64,     1] loss: 0.207
[65,     1] loss: 0.158
[66,     1] loss: 0.158
[67,     1] loss: 0.137
[68,     1] loss: 0.086
[69,     1] loss: 0.166
[70,     1] loss: 0.112
[71,     1] loss: 0.152
[72,     1] loss: 0.125
[73,     1] loss: 0.104
[74,     1] loss: 0.084
[75,     1] loss: 0.085
[76,     1] loss: 0.181
[77,     1] loss: 0.245
[78,     1] loss: 0.188
[79,     1] loss: 0.103
[80,     1] loss: 0.286
[81,     1] loss: 0.110
[82,     1] loss: 0.175
[83,     1] loss: 0.237
[84,     1] loss: 0.199
[85,     1] loss: 0.166
[86,     1] loss: 0.195
[87,     1] loss: 0.171
[88,     1] loss: 0.132
[89,     1] loss: 0.158
[90,     1] loss: 0.129
[91,     1] loss: 0.121
[92,     1] loss: 0.126
[93,     1] loss: 0.117
[94,     1] loss: 0.102
[95,     1] loss: 0.129
[96,     1] loss: 0.078
[97,     1] loss: 0.082
[98,     1] loss: 0.059
[99,     1] loss: 0.075
[100,     1] loss: 0.083
[101,     1] loss: 0.097
Early stopping applied (best metric=0.431555837392807)
Finished Training
Total time taken: 12.939006090164185
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.698
[2,     1] loss: 0.697
[3,     1] loss: 0.668
[4,     1] loss: 0.635
[5,     1] loss: 0.588
[6,     1] loss: 0.545
[7,     1] loss: 0.483
[8,     1] loss: 0.427
[9,     1] loss: 0.390
[10,     1] loss: 0.340
[11,     1] loss: 0.319
[12,     1] loss: 0.252
[13,     1] loss: 0.273
[14,     1] loss: 0.345
[15,     1] loss: 0.263
[16,     1] loss: 0.300
[17,     1] loss: 0.232
[18,     1] loss: 0.236
[19,     1] loss: 0.283
[20,     1] loss: 0.164
[21,     1] loss: 0.236
[22,     1] loss: 0.238
[23,     1] loss: 0.170
[24,     1] loss: 0.268
[25,     1] loss: 0.219
[26,     1] loss: 0.238
[27,     1] loss: 0.237
[28,     1] loss: 0.268
[29,     1] loss: 0.224
[30,     1] loss: 0.189
[31,     1] loss: 0.223
[32,     1] loss: 0.184
[33,     1] loss: 0.193
[34,     1] loss: 0.163
[35,     1] loss: 0.189
[36,     1] loss: 0.158
[37,     1] loss: 0.158
[38,     1] loss: 0.159
[39,     1] loss: 0.219
[40,     1] loss: 0.158
[41,     1] loss: 0.213
[42,     1] loss: 0.165
[43,     1] loss: 0.140
[44,     1] loss: 0.149
[45,     1] loss: 0.106
[46,     1] loss: 0.165
[47,     1] loss: 0.134
[48,     1] loss: 0.127
[49,     1] loss: 0.135
[50,     1] loss: 0.165
[51,     1] loss: 0.128
[52,     1] loss: 0.168
[53,     1] loss: 0.207
[54,     1] loss: 0.125
[55,     1] loss: 0.133
[56,     1] loss: 0.135
[57,     1] loss: 0.106
Early stopping applied (best metric=0.41411861777305603)
Finished Training
Total time taken: 7.638998508453369
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.695
[2,     1] loss: 0.695
[3,     1] loss: 0.685
[4,     1] loss: 0.648
[5,     1] loss: 0.613
[6,     1] loss: 0.556
[7,     1] loss: 0.528
[8,     1] loss: 0.484
[9,     1] loss: 0.416
[10,     1] loss: 0.384
[11,     1] loss: 0.315
[12,     1] loss: 0.341
[13,     1] loss: 0.251
[14,     1] loss: 0.253
[15,     1] loss: 0.247
[16,     1] loss: 0.251
[17,     1] loss: 0.284
[18,     1] loss: 0.297
[19,     1] loss: 0.199
[20,     1] loss: 0.187
[21,     1] loss: 0.224
[22,     1] loss: 0.201
[23,     1] loss: 0.187
[24,     1] loss: 0.182
[25,     1] loss: 0.174
[26,     1] loss: 0.218
[27,     1] loss: 0.236
[28,     1] loss: 0.210
[29,     1] loss: 0.208
[30,     1] loss: 0.217
[31,     1] loss: 0.171
[32,     1] loss: 0.169
[33,     1] loss: 0.205
[34,     1] loss: 0.250
[35,     1] loss: 0.182
[36,     1] loss: 0.166
[37,     1] loss: 0.215
[38,     1] loss: 0.157
[39,     1] loss: 0.199
[40,     1] loss: 0.183
[41,     1] loss: 0.210
[42,     1] loss: 0.186
[43,     1] loss: 0.183
[44,     1] loss: 0.191
[45,     1] loss: 0.147
[46,     1] loss: 0.152
[47,     1] loss: 0.147
[48,     1] loss: 0.160
[49,     1] loss: 0.174
[50,     1] loss: 0.177
[51,     1] loss: 0.242
[52,     1] loss: 0.116
[53,     1] loss: 0.191
[54,     1] loss: 0.140
[55,     1] loss: 0.127
[56,     1] loss: 0.146
[57,     1] loss: 0.155
[58,     1] loss: 0.135
[59,     1] loss: 0.099
Early stopping applied (best metric=0.43292704224586487)
Finished Training
Total time taken: 8.123999834060669
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.692
[2,     1] loss: 0.689
[3,     1] loss: 0.666
[4,     1] loss: 0.623
[5,     1] loss: 0.574
[6,     1] loss: 0.510
[7,     1] loss: 0.461
[8,     1] loss: 0.413
[9,     1] loss: 0.430
[10,     1] loss: 0.322
[11,     1] loss: 0.349
[12,     1] loss: 0.295
[13,     1] loss: 0.366
[14,     1] loss: 0.516
[15,     1] loss: 0.231
[16,     1] loss: 0.279
[17,     1] loss: 0.294
[18,     1] loss: 0.319
[19,     1] loss: 0.219
[20,     1] loss: 0.214
[21,     1] loss: 0.195
[22,     1] loss: 0.223
[23,     1] loss: 0.261
[24,     1] loss: 0.174
[25,     1] loss: 0.181
[26,     1] loss: 0.167
[27,     1] loss: 0.244
[28,     1] loss: 0.174
[29,     1] loss: 0.175
[30,     1] loss: 0.167
[31,     1] loss: 0.125
[32,     1] loss: 0.205
[33,     1] loss: 0.182
[34,     1] loss: 0.193
[35,     1] loss: 0.152
[36,     1] loss: 0.205
[37,     1] loss: 0.155
[38,     1] loss: 0.162
[39,     1] loss: 0.162
[40,     1] loss: 0.152
[41,     1] loss: 0.141
[42,     1] loss: 0.135
[43,     1] loss: 0.128
[44,     1] loss: 0.155
[45,     1] loss: 0.164
[46,     1] loss: 0.107
[47,     1] loss: 0.141
[48,     1] loss: 0.125
[49,     1] loss: 0.125
[50,     1] loss: 0.150
[51,     1] loss: 0.147
[52,     1] loss: 0.141
[53,     1] loss: 0.157
[54,     1] loss: 0.167
[55,     1] loss: 0.106
[56,     1] loss: 0.157
[57,     1] loss: 0.102
[58,     1] loss: 0.159
[59,     1] loss: 0.167
[60,     1] loss: 0.098
[61,     1] loss: 0.204
[62,     1] loss: 0.151
[63,     1] loss: 0.161
[64,     1] loss: 0.190
Early stopping applied (best metric=0.3246225118637085)
Finished Training
Total time taken: 8.327001571655273
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.691
[2,     1] loss: 0.689
[3,     1] loss: 0.671
[4,     1] loss: 0.633
[5,     1] loss: 0.576
[6,     1] loss: 0.571
[7,     1] loss: 0.501
[8,     1] loss: 0.463
[9,     1] loss: 0.432
[10,     1] loss: 0.419
[11,     1] loss: 0.348
[12,     1] loss: 0.333
[13,     1] loss: 0.290
[14,     1] loss: 0.371
[15,     1] loss: 0.293
[16,     1] loss: 0.268
[17,     1] loss: 0.285
[18,     1] loss: 0.241
[19,     1] loss: 0.267
[20,     1] loss: 0.153
[21,     1] loss: 0.313
[22,     1] loss: 0.282
[23,     1] loss: 0.230
[24,     1] loss: 0.184
[25,     1] loss: 0.246
[26,     1] loss: 0.190
[27,     1] loss: 0.193
[28,     1] loss: 0.202
[29,     1] loss: 0.177
[30,     1] loss: 0.172
[31,     1] loss: 0.137
[32,     1] loss: 0.159
[33,     1] loss: 0.192
[34,     1] loss: 0.171
[35,     1] loss: 0.170
[36,     1] loss: 0.123
[37,     1] loss: 0.127
[38,     1] loss: 0.116
[39,     1] loss: 0.171
[40,     1] loss: 0.130
[41,     1] loss: 0.200
[42,     1] loss: 0.141
[43,     1] loss: 0.119
[44,     1] loss: 0.168
[45,     1] loss: 0.125
[46,     1] loss: 0.148
[47,     1] loss: 0.142
[48,     1] loss: 0.123
[49,     1] loss: 0.116
[50,     1] loss: 0.115
[51,     1] loss: 0.123
[52,     1] loss: 0.084
[53,     1] loss: 0.119
[54,     1] loss: 0.088
[55,     1] loss: 0.073
[56,     1] loss: 0.083
[57,     1] loss: 0.097
[58,     1] loss: 0.140
[59,     1] loss: 0.071
[60,     1] loss: 0.089
Early stopping applied (best metric=0.30660122632980347)
Finished Training
Total time taken: 8.108999490737915
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.696
[2,     1] loss: 0.689
[3,     1] loss: 0.666
[4,     1] loss: 0.620
[5,     1] loss: 0.599
[6,     1] loss: 0.543
[7,     1] loss: 0.542
[8,     1] loss: 0.500
[9,     1] loss: 0.464
[10,     1] loss: 0.422
[11,     1] loss: 0.406
[12,     1] loss: 0.389
[13,     1] loss: 0.360
[14,     1] loss: 0.321
[15,     1] loss: 0.287
[16,     1] loss: 0.288
[17,     1] loss: 0.245
[18,     1] loss: 0.267
[19,     1] loss: 0.205
[20,     1] loss: 0.201
[21,     1] loss: 0.203
[22,     1] loss: 0.215
[23,     1] loss: 0.229
[24,     1] loss: 0.209
[25,     1] loss: 0.188
[26,     1] loss: 0.166
[27,     1] loss: 0.120
[28,     1] loss: 0.153
[29,     1] loss: 0.140
[30,     1] loss: 0.164
[31,     1] loss: 0.122
[32,     1] loss: 0.108
[33,     1] loss: 0.141
[34,     1] loss: 0.156
[35,     1] loss: 0.117
[36,     1] loss: 0.086
[37,     1] loss: 0.130
[38,     1] loss: 0.109
[39,     1] loss: 0.080
[40,     1] loss: 0.148
[41,     1] loss: 0.112
[42,     1] loss: 0.123
[43,     1] loss: 0.088
[44,     1] loss: 0.090
[45,     1] loss: 0.082
[46,     1] loss: 0.094
[47,     1] loss: 0.071
[48,     1] loss: 0.084
[49,     1] loss: 0.066
[50,     1] loss: 0.069
[51,     1] loss: 0.076
[52,     1] loss: 0.090
[53,     1] loss: 0.067
[54,     1] loss: 0.042
[55,     1] loss: 0.067
[56,     1] loss: 0.088
[57,     1] loss: 0.054
[58,     1] loss: 0.050
[59,     1] loss: 0.089
[60,     1] loss: 0.150
[61,     1] loss: 0.233
[62,     1] loss: 0.392
[63,     1] loss: 0.239
Early stopping applied (best metric=0.4402799606323242)
Finished Training
Total time taken: 8.207006931304932
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.693
[2,     1] loss: 0.686
[3,     1] loss: 0.667
[4,     1] loss: 0.620
[5,     1] loss: 0.576
[6,     1] loss: 0.512
[7,     1] loss: 0.507
[8,     1] loss: 0.464
[9,     1] loss: 0.421
[10,     1] loss: 0.364
[11,     1] loss: 0.327
[12,     1] loss: 0.332
[13,     1] loss: 0.393
[14,     1] loss: 0.368
[15,     1] loss: 0.331
[16,     1] loss: 0.335
[17,     1] loss: 0.283
[18,     1] loss: 0.315
[19,     1] loss: 0.241
[20,     1] loss: 0.243
[21,     1] loss: 0.253
[22,     1] loss: 0.277
[23,     1] loss: 0.285
[24,     1] loss: 0.286
[25,     1] loss: 0.195
[26,     1] loss: 0.261
[27,     1] loss: 0.208
[28,     1] loss: 0.186
[29,     1] loss: 0.159
[30,     1] loss: 0.194
[31,     1] loss: 0.170
[32,     1] loss: 0.140
[33,     1] loss: 0.170
[34,     1] loss: 0.198
[35,     1] loss: 0.095
[36,     1] loss: 0.109
[37,     1] loss: 0.081
[38,     1] loss: 0.049
[39,     1] loss: 0.162
[40,     1] loss: 0.080
[41,     1] loss: 0.068
[42,     1] loss: 0.062
[43,     1] loss: 0.113
[44,     1] loss: 0.062
[45,     1] loss: 0.092
[46,     1] loss: 0.064
[47,     1] loss: 0.102
[48,     1] loss: 0.332
[49,     1] loss: 0.185
[50,     1] loss: 0.259
[51,     1] loss: 0.133
[52,     1] loss: 0.136
[53,     1] loss: 0.138
[54,     1] loss: 0.182
[55,     1] loss: 0.121
[56,     1] loss: 0.169
Early stopping applied (best metric=0.4511924088001251)
Finished Training
Total time taken: 7.580000162124634
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.695
[2,     1] loss: 0.688
[3,     1] loss: 0.666
[4,     1] loss: 0.632
[5,     1] loss: 0.584
[6,     1] loss: 0.555
[7,     1] loss: 0.526
[8,     1] loss: 0.484
[9,     1] loss: 0.448
[10,     1] loss: 0.384
[11,     1] loss: 0.361
[12,     1] loss: 0.316
[13,     1] loss: 0.261
[14,     1] loss: 0.285
[15,     1] loss: 0.229
[16,     1] loss: 0.390
[17,     1] loss: 0.268
[18,     1] loss: 0.265
[19,     1] loss: 0.238
[20,     1] loss: 0.260
[21,     1] loss: 0.246
[22,     1] loss: 0.217
[23,     1] loss: 0.263
[24,     1] loss: 0.191
[25,     1] loss: 0.196
[26,     1] loss: 0.165
[27,     1] loss: 0.210
[28,     1] loss: 0.181
[29,     1] loss: 0.159
[30,     1] loss: 0.208
[31,     1] loss: 0.168
[32,     1] loss: 0.130
[33,     1] loss: 0.184
[34,     1] loss: 0.134
[35,     1] loss: 0.151
[36,     1] loss: 0.183
[37,     1] loss: 0.108
[38,     1] loss: 0.205
[39,     1] loss: 0.151
[40,     1] loss: 0.230
[41,     1] loss: 0.117
[42,     1] loss: 0.079
[43,     1] loss: 0.098
[44,     1] loss: 0.086
[45,     1] loss: 0.124
[46,     1] loss: 0.136
[47,     1] loss: 0.093
[48,     1] loss: 0.127
[49,     1] loss: 0.107
[50,     1] loss: 0.114
[51,     1] loss: 0.093
[52,     1] loss: 0.095
[53,     1] loss: 0.065
[54,     1] loss: 0.090
[55,     1] loss: 0.070
[56,     1] loss: 0.089
[57,     1] loss: 0.115
[58,     1] loss: 0.047
[59,     1] loss: 0.135
Early stopping applied (best metric=0.3417126536369324)
Finished Training
Total time taken: 8.489001274108887
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.692
[2,     1] loss: 0.689
[3,     1] loss: 0.669
[4,     1] loss: 0.637
[5,     1] loss: 0.582
[6,     1] loss: 0.514
[7,     1] loss: 0.450
[8,     1] loss: 0.496
[9,     1] loss: 0.423
[10,     1] loss: 0.353
[11,     1] loss: 0.320
[12,     1] loss: 0.368
[13,     1] loss: 0.284
[14,     1] loss: 0.327
[15,     1] loss: 0.258
[16,     1] loss: 0.312
[17,     1] loss: 0.316
[18,     1] loss: 0.254
[19,     1] loss: 0.267
[20,     1] loss: 0.237
[21,     1] loss: 0.282
[22,     1] loss: 0.315
[23,     1] loss: 0.428
[24,     1] loss: 0.326
[25,     1] loss: 0.333
[26,     1] loss: 0.365
[27,     1] loss: 0.315
[28,     1] loss: 0.235
[29,     1] loss: 0.283
[30,     1] loss: 0.274
[31,     1] loss: 0.305
[32,     1] loss: 0.271
[33,     1] loss: 0.219
[34,     1] loss: 0.234
[35,     1] loss: 0.263
[36,     1] loss: 0.198
[37,     1] loss: 0.235
[38,     1] loss: 0.291
[39,     1] loss: 0.144
[40,     1] loss: 0.227
[41,     1] loss: 0.199
[42,     1] loss: 0.257
[43,     1] loss: 0.234
[44,     1] loss: 0.216
[45,     1] loss: 0.221
[46,     1] loss: 0.151
[47,     1] loss: 0.186
[48,     1] loss: 0.189
[49,     1] loss: 0.208
[50,     1] loss: 0.197
[51,     1] loss: 0.189
[52,     1] loss: 0.181
[53,     1] loss: 0.162
[54,     1] loss: 0.150
[55,     1] loss: 0.106
[56,     1] loss: 0.153
[57,     1] loss: 0.125
[58,     1] loss: 0.109
[59,     1] loss: 0.099
[60,     1] loss: 0.149
[61,     1] loss: 0.164
[62,     1] loss: 0.141
[63,     1] loss: 0.104
[64,     1] loss: 0.211
[65,     1] loss: 0.233
[66,     1] loss: 0.116
Early stopping applied (best metric=0.15250825881958008)
Finished Training
Total time taken: 9.322713136672974
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.692
[2,     1] loss: 0.690
[3,     1] loss: 0.681
[4,     1] loss: 0.636
[5,     1] loss: 0.590
[6,     1] loss: 0.539
[7,     1] loss: 0.512
[8,     1] loss: 0.467
[9,     1] loss: 0.422
[10,     1] loss: 0.389
[11,     1] loss: 0.339
[12,     1] loss: 0.316
[13,     1] loss: 0.328
[14,     1] loss: 0.365
[15,     1] loss: 0.323
[16,     1] loss: 0.253
[17,     1] loss: 0.287
[18,     1] loss: 0.223
[19,     1] loss: 0.236
[20,     1] loss: 0.238
[21,     1] loss: 0.190
[22,     1] loss: 0.193
[23,     1] loss: 0.195
[24,     1] loss: 0.192
[25,     1] loss: 0.185
[26,     1] loss: 0.211
[27,     1] loss: 0.166
[28,     1] loss: 0.172
[29,     1] loss: 0.208
[30,     1] loss: 0.152
[31,     1] loss: 0.169
[32,     1] loss: 0.159
[33,     1] loss: 0.145
[34,     1] loss: 0.140
[35,     1] loss: 0.171
[36,     1] loss: 0.128
[37,     1] loss: 0.129
[38,     1] loss: 0.125
[39,     1] loss: 0.156
[40,     1] loss: 0.251
[41,     1] loss: 0.119
[42,     1] loss: 0.151
[43,     1] loss: 0.163
[44,     1] loss: 0.130
[45,     1] loss: 0.101
[46,     1] loss: 0.146
[47,     1] loss: 0.128
[48,     1] loss: 0.146
[49,     1] loss: 0.168
[50,     1] loss: 0.162
[51,     1] loss: 0.112
[52,     1] loss: 0.186
[53,     1] loss: 0.093
[54,     1] loss: 0.150
[55,     1] loss: 0.133
[56,     1] loss: 0.097
Early stopping applied (best metric=0.41599446535110474)
Finished Training
Total time taken: 8.016518831253052
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.690
[2,     1] loss: 0.686
[3,     1] loss: 0.693
[4,     1] loss: 0.663
[5,     1] loss: 0.638
[6,     1] loss: 0.591
[7,     1] loss: 0.580
[8,     1] loss: 0.500
[9,     1] loss: 0.499
[10,     1] loss: 0.459
[11,     1] loss: 0.489
[12,     1] loss: 0.468
[13,     1] loss: 0.374
[14,     1] loss: 0.441
[15,     1] loss: 0.404
[16,     1] loss: 0.447
[17,     1] loss: 0.409
[18,     1] loss: 0.314
[19,     1] loss: 0.385
[20,     1] loss: 0.335
[21,     1] loss: 0.313
[22,     1] loss: 0.252
[23,     1] loss: 0.257
[24,     1] loss: 0.244
[25,     1] loss: 0.262
[26,     1] loss: 0.241
[27,     1] loss: 0.231
[28,     1] loss: 0.187
[29,     1] loss: 0.213
[30,     1] loss: 0.146
[31,     1] loss: 0.168
[32,     1] loss: 0.171
[33,     1] loss: 0.156
[34,     1] loss: 0.158
[35,     1] loss: 0.175
[36,     1] loss: 0.158
[37,     1] loss: 0.209
[38,     1] loss: 0.241
[39,     1] loss: 0.166
[40,     1] loss: 0.158
[41,     1] loss: 0.158
[42,     1] loss: 0.136
[43,     1] loss: 0.150
[44,     1] loss: 0.212
[45,     1] loss: 0.094
[46,     1] loss: 0.177
[47,     1] loss: 0.141
[48,     1] loss: 0.144
[49,     1] loss: 0.119
[50,     1] loss: 0.103
[51,     1] loss: 0.153
[52,     1] loss: 0.154
[53,     1] loss: 0.187
[54,     1] loss: 0.105
[55,     1] loss: 0.106
[56,     1] loss: 0.168
[57,     1] loss: 0.098
[58,     1] loss: 0.133
[59,     1] loss: 0.132
[60,     1] loss: 0.112
[61,     1] loss: 0.107
[62,     1] loss: 0.080
[63,     1] loss: 0.088
[64,     1] loss: 0.083
[65,     1] loss: 0.060
[66,     1] loss: 0.059
[67,     1] loss: 0.109
Early stopping applied (best metric=0.40839776396751404)
Finished Training
Total time taken: 9.252999305725098
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.689
[2,     1] loss: 0.688
[3,     1] loss: 0.679
[4,     1] loss: 0.643
[5,     1] loss: 0.594
[6,     1] loss: 0.546
[7,     1] loss: 0.488
[8,     1] loss: 0.467
[9,     1] loss: 0.398
[10,     1] loss: 0.444
[11,     1] loss: 0.383
[12,     1] loss: 0.324
[13,     1] loss: 0.481
[14,     1] loss: 0.309
[15,     1] loss: 0.352
[16,     1] loss: 0.360
[17,     1] loss: 0.350
[18,     1] loss: 0.275
[19,     1] loss: 0.386
[20,     1] loss: 0.271
[21,     1] loss: 0.294
[22,     1] loss: 0.260
[23,     1] loss: 0.276
[24,     1] loss: 0.272
[25,     1] loss: 0.217
[26,     1] loss: 0.233
[27,     1] loss: 0.218
[28,     1] loss: 0.234
[29,     1] loss: 0.215
[30,     1] loss: 0.175
[31,     1] loss: 0.175
[32,     1] loss: 0.202
[33,     1] loss: 0.202
[34,     1] loss: 0.156
[35,     1] loss: 0.139
[36,     1] loss: 0.219
[37,     1] loss: 0.134
[38,     1] loss: 0.139
[39,     1] loss: 0.142
[40,     1] loss: 0.129
[41,     1] loss: 0.233
[42,     1] loss: 0.171
[43,     1] loss: 0.149
[44,     1] loss: 0.140
[45,     1] loss: 0.142
[46,     1] loss: 0.141
[47,     1] loss: 0.186
[48,     1] loss: 0.160
[49,     1] loss: 0.150
[50,     1] loss: 0.178
[51,     1] loss: 0.182
[52,     1] loss: 0.115
[53,     1] loss: 0.155
[54,     1] loss: 0.126
[55,     1] loss: 0.157
[56,     1] loss: 0.093
[57,     1] loss: 0.087
[58,     1] loss: 0.094
[59,     1] loss: 0.131
[60,     1] loss: 0.113
[61,     1] loss: 0.195
[62,     1] loss: 0.264
[63,     1] loss: 0.170
[64,     1] loss: 0.140
[65,     1] loss: 0.120
[66,     1] loss: 0.135
[67,     1] loss: 0.135
[68,     1] loss: 0.123
[69,     1] loss: 0.124
[70,     1] loss: 0.140
[71,     1] loss: 0.106
[72,     1] loss: 0.127
[73,     1] loss: 0.126
[74,     1] loss: 0.105
[75,     1] loss: 0.061
[76,     1] loss: 0.108
[77,     1] loss: 0.084
[78,     1] loss: 0.123
[79,     1] loss: 0.107
[80,     1] loss: 0.150
[81,     1] loss: 0.059
[82,     1] loss: 0.066
[83,     1] loss: 0.090
[84,     1] loss: 0.101
[85,     1] loss: 0.097
[86,     1] loss: 0.058
[87,     1] loss: 0.087
[88,     1] loss: 0.062
[89,     1] loss: 0.080
[90,     1] loss: 0.098
[91,     1] loss: 0.065
[92,     1] loss: 0.159
[93,     1] loss: 0.156
[94,     1] loss: 0.254
[95,     1] loss: 0.094
[96,     1] loss: 0.131
[97,     1] loss: 0.176
[98,     1] loss: 0.093
[99,     1] loss: 0.113
[100,     1] loss: 0.156
[101,     1] loss: 0.081
[102,     1] loss: 0.124
[103,     1] loss: 0.117
[104,     1] loss: 0.071
[105,     1] loss: 0.113
[106,     1] loss: 0.064
[107,     1] loss: 0.069
[108,     1] loss: 0.078
[109,     1] loss: 0.068
[110,     1] loss: 0.057
[111,     1] loss: 0.072
[112,     1] loss: 0.045
[113,     1] loss: 0.045
[114,     1] loss: 0.036
[115,     1] loss: 0.099
[116,     1] loss: 0.048
[117,     1] loss: 0.086
[118,     1] loss: 0.098
[119,     1] loss: 0.061
Early stopping applied (best metric=0.12653778493404388)
Finished Training
Total time taken: 16.32699966430664
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.698
[2,     1] loss: 0.698
[3,     1] loss: 0.685
[4,     1] loss: 0.657
[5,     1] loss: 0.626
[6,     1] loss: 0.600
[7,     1] loss: 0.553
[8,     1] loss: 0.513
[9,     1] loss: 0.449
[10,     1] loss: 0.425
[11,     1] loss: 0.432
[12,     1] loss: 0.347
[13,     1] loss: 0.375
[14,     1] loss: 0.325
[15,     1] loss: 0.297
[16,     1] loss: 0.351
[17,     1] loss: 0.370
[18,     1] loss: 0.302
[19,     1] loss: 0.254
[20,     1] loss: 0.274
[21,     1] loss: 0.286
[22,     1] loss: 0.319
[23,     1] loss: 0.279
[24,     1] loss: 0.264
[25,     1] loss: 0.284
[26,     1] loss: 0.247
[27,     1] loss: 0.198
[28,     1] loss: 0.259
[29,     1] loss: 0.204
[30,     1] loss: 0.256
[31,     1] loss: 0.177
[32,     1] loss: 0.204
[33,     1] loss: 0.159
[34,     1] loss: 0.213
[35,     1] loss: 0.181
[36,     1] loss: 0.215
[37,     1] loss: 0.198
[38,     1] loss: 0.145
[39,     1] loss: 0.182
[40,     1] loss: 0.147
[41,     1] loss: 0.122
[42,     1] loss: 0.138
[43,     1] loss: 0.152
[44,     1] loss: 0.134
[45,     1] loss: 0.212
[46,     1] loss: 0.119
[47,     1] loss: 0.120
[48,     1] loss: 0.169
[49,     1] loss: 0.153
[50,     1] loss: 0.182
[51,     1] loss: 0.126
[52,     1] loss: 0.096
[53,     1] loss: 0.128
[54,     1] loss: 0.097
[55,     1] loss: 0.078
[56,     1] loss: 0.111
[57,     1] loss: 0.082
[58,     1] loss: 0.081
[59,     1] loss: 0.126
[60,     1] loss: 0.045
[61,     1] loss: 0.083
[62,     1] loss: 0.112
[63,     1] loss: 0.042
[64,     1] loss: 0.074
[65,     1] loss: 0.071
[66,     1] loss: 0.100
[67,     1] loss: 0.140
[68,     1] loss: 0.153
[69,     1] loss: 0.042
[70,     1] loss: 0.318
[71,     1] loss: 0.118
Early stopping applied (best metric=0.13038955628871918)
Finished Training
Total time taken: 9.487001180648804
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.696
[2,     1] loss: 0.691
[3,     1] loss: 0.677
[4,     1] loss: 0.638
[5,     1] loss: 0.591
[6,     1] loss: 0.529
[7,     1] loss: 0.498
[8,     1] loss: 0.471
[9,     1] loss: 0.403
[10,     1] loss: 0.361
[11,     1] loss: 0.408
[12,     1] loss: 0.381
[13,     1] loss: 0.344
[14,     1] loss: 0.344
[15,     1] loss: 0.345
[16,     1] loss: 0.293
[17,     1] loss: 0.257
[18,     1] loss: 0.284
[19,     1] loss: 0.292
[20,     1] loss: 0.325
[21,     1] loss: 0.229
[22,     1] loss: 0.258
[23,     1] loss: 0.302
[24,     1] loss: 0.225
[25,     1] loss: 0.197
[26,     1] loss: 0.195
[27,     1] loss: 0.221
[28,     1] loss: 0.256
[29,     1] loss: 0.234
[30,     1] loss: 0.223
[31,     1] loss: 0.277
[32,     1] loss: 0.169
[33,     1] loss: 0.230
[34,     1] loss: 0.152
[35,     1] loss: 0.199
[36,     1] loss: 0.235
[37,     1] loss: 0.141
[38,     1] loss: 0.237
[39,     1] loss: 0.252
[40,     1] loss: 0.197
[41,     1] loss: 0.218
[42,     1] loss: 0.351
[43,     1] loss: 0.144
[44,     1] loss: 0.192
[45,     1] loss: 0.221
[46,     1] loss: 0.274
[47,     1] loss: 0.243
[48,     1] loss: 0.192
[49,     1] loss: 0.179
[50,     1] loss: 0.163
[51,     1] loss: 0.165
[52,     1] loss: 0.174
[53,     1] loss: 0.149
[54,     1] loss: 0.143
[55,     1] loss: 0.117
[56,     1] loss: 0.109
[57,     1] loss: 0.099
[58,     1] loss: 0.087
[59,     1] loss: 0.067
[60,     1] loss: 0.079
[61,     1] loss: 0.137
[62,     1] loss: 0.086
[63,     1] loss: 0.048
[64,     1] loss: 0.078
[65,     1] loss: 0.216
[66,     1] loss: 0.130
[67,     1] loss: 0.173
[68,     1] loss: 0.116
[69,     1] loss: 0.076
[70,     1] loss: 0.123
[71,     1] loss: 0.124
[72,     1] loss: 0.072
[73,     1] loss: 0.089
[74,     1] loss: 0.111
[75,     1] loss: 0.093
[76,     1] loss: 0.106
[77,     1] loss: 0.086
[78,     1] loss: 0.095
[79,     1] loss: 0.049
[80,     1] loss: 0.163
[81,     1] loss: 0.082
[82,     1] loss: 0.055
[83,     1] loss: 0.117
[84,     1] loss: 0.056
[85,     1] loss: 0.065
[86,     1] loss: 0.080
[87,     1] loss: 0.060
[88,     1] loss: 0.054
[89,     1] loss: 0.098
[90,     1] loss: 0.057
[91,     1] loss: 0.154
Early stopping applied (best metric=0.3426459729671478)
Finished Training
Total time taken: 13.701998710632324
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.689
[2,     1] loss: 0.704
[3,     1] loss: 0.687
[4,     1] loss: 0.640
[5,     1] loss: 0.631
[6,     1] loss: 0.594
[7,     1] loss: 0.537
[8,     1] loss: 0.543
[9,     1] loss: 0.516
[10,     1] loss: 0.439
[11,     1] loss: 0.463
[12,     1] loss: 0.429
[13,     1] loss: 0.410
[14,     1] loss: 0.365
[15,     1] loss: 0.400
[16,     1] loss: 0.345
[17,     1] loss: 0.333
[18,     1] loss: 0.275
[19,     1] loss: 0.329
[20,     1] loss: 0.299
[21,     1] loss: 0.339
[22,     1] loss: 0.334
[23,     1] loss: 0.249
[24,     1] loss: 0.295
[25,     1] loss: 0.269
[26,     1] loss: 0.291
[27,     1] loss: 0.276
[28,     1] loss: 0.245
[29,     1] loss: 0.301
[30,     1] loss: 0.196
[31,     1] loss: 0.215
[32,     1] loss: 0.223
[33,     1] loss: 0.197
[34,     1] loss: 0.235
[35,     1] loss: 0.206
[36,     1] loss: 0.189
[37,     1] loss: 0.209
[38,     1] loss: 0.168
[39,     1] loss: 0.206
[40,     1] loss: 0.208
[41,     1] loss: 0.210
[42,     1] loss: 0.196
[43,     1] loss: 0.173
[44,     1] loss: 0.250
[45,     1] loss: 0.191
[46,     1] loss: 0.144
[47,     1] loss: 0.176
[48,     1] loss: 0.191
[49,     1] loss: 0.207
[50,     1] loss: 0.209
[51,     1] loss: 0.141
[52,     1] loss: 0.175
[53,     1] loss: 0.184
[54,     1] loss: 0.171
[55,     1] loss: 0.128
[56,     1] loss: 0.193
[57,     1] loss: 0.129
[58,     1] loss: 0.090
[59,     1] loss: 0.155
[60,     1] loss: 0.065
[61,     1] loss: 0.156
[62,     1] loss: 0.164
[63,     1] loss: 0.094
[64,     1] loss: 0.144
Early stopping applied (best metric=0.4318692088127136)
Finished Training
Total time taken: 9.29134726524353
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.696
[2,     1] loss: 0.697
[3,     1] loss: 0.674
[4,     1] loss: 0.635
[5,     1] loss: 0.619
[6,     1] loss: 0.569
[7,     1] loss: 0.517
[8,     1] loss: 0.512
[9,     1] loss: 0.434
[10,     1] loss: 0.414
[11,     1] loss: 0.442
[12,     1] loss: 0.342
[13,     1] loss: 0.307
[14,     1] loss: 0.320
[15,     1] loss: 0.296
[16,     1] loss: 0.272
[17,     1] loss: 0.250
[18,     1] loss: 0.197
[19,     1] loss: 0.221
[20,     1] loss: 0.268
[21,     1] loss: 0.223
[22,     1] loss: 0.139
[23,     1] loss: 0.211
[24,     1] loss: 0.211
[25,     1] loss: 0.173
[26,     1] loss: 0.202
[27,     1] loss: 0.192
[28,     1] loss: 0.197
[29,     1] loss: 0.189
[30,     1] loss: 0.168
[31,     1] loss: 0.107
[32,     1] loss: 0.165
[33,     1] loss: 0.152
[34,     1] loss: 0.158
[35,     1] loss: 0.113
[36,     1] loss: 0.134
[37,     1] loss: 0.110
[38,     1] loss: 0.148
[39,     1] loss: 0.145
[40,     1] loss: 0.181
[41,     1] loss: 0.115
[42,     1] loss: 0.164
[43,     1] loss: 0.118
[44,     1] loss: 0.164
[45,     1] loss: 0.104
[46,     1] loss: 0.147
[47,     1] loss: 0.146
[48,     1] loss: 0.172
[49,     1] loss: 0.148
[50,     1] loss: 0.110
[51,     1] loss: 0.093
[52,     1] loss: 0.116
[53,     1] loss: 0.106
[54,     1] loss: 0.157
[55,     1] loss: 0.164
[56,     1] loss: 0.113
[57,     1] loss: 0.077
[58,     1] loss: 0.094
Early stopping applied (best metric=0.40420329570770264)
Finished Training
Total time taken: 8.13585376739502
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.693
[2,     1] loss: 0.692
[3,     1] loss: 0.672
[4,     1] loss: 0.616
[5,     1] loss: 0.585
[6,     1] loss: 0.524
[7,     1] loss: 0.473
[8,     1] loss: 0.436
[9,     1] loss: 0.430
[10,     1] loss: 0.360
[11,     1] loss: 0.345
[12,     1] loss: 0.330
[13,     1] loss: 0.307
[14,     1] loss: 0.297
[15,     1] loss: 0.263
[16,     1] loss: 0.277
[17,     1] loss: 0.237
[18,     1] loss: 0.348
[19,     1] loss: 0.251
[20,     1] loss: 0.244
[21,     1] loss: 0.230
[22,     1] loss: 0.206
[23,     1] loss: 0.213
[24,     1] loss: 0.251
[25,     1] loss: 0.276
[26,     1] loss: 0.185
[27,     1] loss: 0.215
[28,     1] loss: 0.301
[29,     1] loss: 0.194
[30,     1] loss: 0.202
[31,     1] loss: 0.150
[32,     1] loss: 0.153
[33,     1] loss: 0.118
[34,     1] loss: 0.131
[35,     1] loss: 0.119
[36,     1] loss: 0.141
[37,     1] loss: 0.091
[38,     1] loss: 0.137
[39,     1] loss: 0.136
[40,     1] loss: 0.157
[41,     1] loss: 0.155
[42,     1] loss: 0.135
[43,     1] loss: 0.173
[44,     1] loss: 0.150
[45,     1] loss: 0.160
[46,     1] loss: 0.094
[47,     1] loss: 0.139
[48,     1] loss: 0.140
[49,     1] loss: 0.117
[50,     1] loss: 0.112
[51,     1] loss: 0.076
[52,     1] loss: 0.110
[53,     1] loss: 0.078
[54,     1] loss: 0.119
[55,     1] loss: 0.058
[56,     1] loss: 0.055
[57,     1] loss: 0.072
[58,     1] loss: 0.119
[59,     1] loss: 0.086
[60,     1] loss: 0.095
Early stopping applied (best metric=0.3693297803401947)
Finished Training
Total time taken: 8.30345106124878
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.694
[2,     1] loss: 0.697
[3,     1] loss: 0.678
[4,     1] loss: 0.662
[5,     1] loss: 0.643
[6,     1] loss: 0.600
[7,     1] loss: 0.562
[8,     1] loss: 0.523
[9,     1] loss: 0.480
[10,     1] loss: 0.463
[11,     1] loss: 0.408
[12,     1] loss: 0.396
[13,     1] loss: 0.359
[14,     1] loss: 0.395
[15,     1] loss: 0.309
[16,     1] loss: 0.320
[17,     1] loss: 0.405
[18,     1] loss: 0.271
[19,     1] loss: 0.316
[20,     1] loss: 0.391
[21,     1] loss: 0.278
[22,     1] loss: 0.326
[23,     1] loss: 0.249
[24,     1] loss: 0.293
[25,     1] loss: 0.265
[26,     1] loss: 0.297
[27,     1] loss: 0.330
[28,     1] loss: 0.259
[29,     1] loss: 0.245
[30,     1] loss: 0.269
[31,     1] loss: 0.277
[32,     1] loss: 0.285
[33,     1] loss: 0.266
[34,     1] loss: 0.288
[35,     1] loss: 0.289
[36,     1] loss: 0.234
[37,     1] loss: 0.222
[38,     1] loss: 0.227
[39,     1] loss: 0.264
[40,     1] loss: 0.222
[41,     1] loss: 0.188
[42,     1] loss: 0.190
[43,     1] loss: 0.174
[44,     1] loss: 0.164
[45,     1] loss: 0.188
[46,     1] loss: 0.180
[47,     1] loss: 0.150
[48,     1] loss: 0.150
[49,     1] loss: 0.111
[50,     1] loss: 0.098
[51,     1] loss: 0.132
[52,     1] loss: 0.113
[53,     1] loss: 0.115
[54,     1] loss: 0.170
[55,     1] loss: 0.107
[56,     1] loss: 0.130
[57,     1] loss: 0.145
[58,     1] loss: 0.100
Early stopping applied (best metric=0.40080127120018005)
Finished Training
Total time taken: 7.950383901596069
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.695
[2,     1] loss: 0.694
[3,     1] loss: 0.680
[4,     1] loss: 0.656
[5,     1] loss: 0.629
[6,     1] loss: 0.597
[7,     1] loss: 0.529
[8,     1] loss: 0.483
[9,     1] loss: 0.418
[10,     1] loss: 0.415
[11,     1] loss: 0.365
[12,     1] loss: 0.351
[13,     1] loss: 0.330
[14,     1] loss: 0.358
[15,     1] loss: 0.324
[16,     1] loss: 0.337
[17,     1] loss: 0.291
[18,     1] loss: 0.300
[19,     1] loss: 0.209
[20,     1] loss: 0.231
[21,     1] loss: 0.258
[22,     1] loss: 0.216
[23,     1] loss: 0.248
[24,     1] loss: 0.185
[25,     1] loss: 0.175
[26,     1] loss: 0.174
[27,     1] loss: 0.192
[28,     1] loss: 0.150
[29,     1] loss: 0.228
[30,     1] loss: 0.189
[31,     1] loss: 0.342
[32,     1] loss: 0.205
[33,     1] loss: 0.222
[34,     1] loss: 0.244
[35,     1] loss: 0.177
[36,     1] loss: 0.161
[37,     1] loss: 0.203
[38,     1] loss: 0.197
[39,     1] loss: 0.149
[40,     1] loss: 0.169
[41,     1] loss: 0.251
[42,     1] loss: 0.189
[43,     1] loss: 0.150
[44,     1] loss: 0.149
[45,     1] loss: 0.146
[46,     1] loss: 0.176
[47,     1] loss: 0.151
[48,     1] loss: 0.137
[49,     1] loss: 0.120
[50,     1] loss: 0.118
[51,     1] loss: 0.140
[52,     1] loss: 0.104
[53,     1] loss: 0.116
[54,     1] loss: 0.084
[55,     1] loss: 0.183
[56,     1] loss: 0.129
Early stopping applied (best metric=0.507079005241394)
Finished Training
Total time taken: 7.7662436962127686
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.694
[2,     1] loss: 0.690
[3,     1] loss: 0.675
[4,     1] loss: 0.639
[5,     1] loss: 0.603
[6,     1] loss: 0.578
[7,     1] loss: 0.513
[8,     1] loss: 0.482
[9,     1] loss: 0.418
[10,     1] loss: 0.352
[11,     1] loss: 0.371
[12,     1] loss: 0.344
[13,     1] loss: 0.347
[14,     1] loss: 0.297
[15,     1] loss: 0.308
[16,     1] loss: 0.286
[17,     1] loss: 0.320
[18,     1] loss: 0.286
[19,     1] loss: 0.277
[20,     1] loss: 0.292
[21,     1] loss: 0.246
[22,     1] loss: 0.208
[23,     1] loss: 0.201
[24,     1] loss: 0.205
[25,     1] loss: 0.247
[26,     1] loss: 0.170
[27,     1] loss: 0.161
[28,     1] loss: 0.205
[29,     1] loss: 0.173
[30,     1] loss: 0.189
[31,     1] loss: 0.212
[32,     1] loss: 0.160
[33,     1] loss: 0.157
[34,     1] loss: 0.192
[35,     1] loss: 0.137
[36,     1] loss: 0.139
[37,     1] loss: 0.108
[38,     1] loss: 0.122
[39,     1] loss: 0.148
[40,     1] loss: 0.126
[41,     1] loss: 0.097
[42,     1] loss: 0.110
[43,     1] loss: 0.064
[44,     1] loss: 0.129
[45,     1] loss: 0.077
[46,     1] loss: 0.104
[47,     1] loss: 0.064
[48,     1] loss: 0.117
[49,     1] loss: 0.078
[50,     1] loss: 0.062
[51,     1] loss: 0.115
[52,     1] loss: 0.082
[53,     1] loss: 0.145
[54,     1] loss: 0.103
[55,     1] loss: 0.094
[56,     1] loss: 0.121
[57,     1] loss: 0.147
[58,     1] loss: 0.105
[59,     1] loss: 0.103
[60,     1] loss: 0.086
[61,     1] loss: 0.102
[62,     1] loss: 0.055
[63,     1] loss: 0.125
[64,     1] loss: 0.089
Early stopping applied (best metric=0.3336428105831146)
Finished Training
Total time taken: 8.991568088531494
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.694
[2,     1] loss: 0.685
[3,     1] loss: 0.682
[4,     1] loss: 0.648
[5,     1] loss: 0.606
[6,     1] loss: 0.566
[7,     1] loss: 0.521
[8,     1] loss: 0.479
[9,     1] loss: 0.465
[10,     1] loss: 0.413
[11,     1] loss: 0.461
[12,     1] loss: 0.389
[13,     1] loss: 0.372
[14,     1] loss: 0.324
[15,     1] loss: 0.355
[16,     1] loss: 0.347
[17,     1] loss: 0.301
[18,     1] loss: 0.262
[19,     1] loss: 0.273
[20,     1] loss: 0.228
[21,     1] loss: 0.283
[22,     1] loss: 0.236
[23,     1] loss: 0.284
[24,     1] loss: 0.234
[25,     1] loss: 0.211
[26,     1] loss: 0.216
[27,     1] loss: 0.227
[28,     1] loss: 0.303
[29,     1] loss: 0.243
[30,     1] loss: 0.242
[31,     1] loss: 0.219
[32,     1] loss: 0.217
[33,     1] loss: 0.214
[34,     1] loss: 0.189
[35,     1] loss: 0.179
[36,     1] loss: 0.148
[37,     1] loss: 0.263
[38,     1] loss: 0.132
[39,     1] loss: 0.202
[40,     1] loss: 0.128
[41,     1] loss: 0.170
[42,     1] loss: 0.128
[43,     1] loss: 0.081
[44,     1] loss: 0.134
[45,     1] loss: 0.084
[46,     1] loss: 0.094
[47,     1] loss: 0.060
[48,     1] loss: 0.086
[49,     1] loss: 0.090
[50,     1] loss: 0.073
[51,     1] loss: 0.083
[52,     1] loss: 0.064
[53,     1] loss: 0.045
[54,     1] loss: 0.085
[55,     1] loss: 0.054
[56,     1] loss: 0.164
[57,     1] loss: 0.061
[58,     1] loss: 0.132
[59,     1] loss: 0.095
[60,     1] loss: 0.085
[61,     1] loss: 0.081
[62,     1] loss: 0.081
[63,     1] loss: 0.088
[64,     1] loss: 0.055
[65,     1] loss: 0.077
[66,     1] loss: 0.037
[67,     1] loss: 0.106
[68,     1] loss: 0.061
Early stopping applied (best metric=0.3912747800350189)
Finished Training
Total time taken: 9.450469732284546
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.695
[2,     1] loss: 0.684
[3,     1] loss: 0.680
[4,     1] loss: 0.664
[5,     1] loss: 0.632
[6,     1] loss: 0.594
[7,     1] loss: 0.576
[8,     1] loss: 0.546
[9,     1] loss: 0.485
[10,     1] loss: 0.443
[11,     1] loss: 0.383
[12,     1] loss: 0.362
[13,     1] loss: 0.342
[14,     1] loss: 0.328
[15,     1] loss: 0.316
[16,     1] loss: 0.370
[17,     1] loss: 0.321
[18,     1] loss: 0.334
[19,     1] loss: 0.272
[20,     1] loss: 0.330
[21,     1] loss: 0.353
[22,     1] loss: 0.281
[23,     1] loss: 0.277
[24,     1] loss: 0.338
[25,     1] loss: 0.242
[26,     1] loss: 0.282
[27,     1] loss: 0.265
[28,     1] loss: 0.258
[29,     1] loss: 0.212
[30,     1] loss: 0.241
[31,     1] loss: 0.223
[32,     1] loss: 0.223
[33,     1] loss: 0.178
[34,     1] loss: 0.207
[35,     1] loss: 0.246
[36,     1] loss: 0.189
[37,     1] loss: 0.239
[38,     1] loss: 0.111
[39,     1] loss: 0.124
[40,     1] loss: 0.143
[41,     1] loss: 0.177
[42,     1] loss: 0.131
[43,     1] loss: 0.153
[44,     1] loss: 0.132
[45,     1] loss: 0.151
[46,     1] loss: 0.095
[47,     1] loss: 0.094
[48,     1] loss: 0.107
[49,     1] loss: 0.124
[50,     1] loss: 0.102
[51,     1] loss: 0.117
[52,     1] loss: 0.144
[53,     1] loss: 0.089
[54,     1] loss: 0.088
[55,     1] loss: 0.064
[56,     1] loss: 0.182
[57,     1] loss: 0.090
[58,     1] loss: 0.091
[59,     1] loss: 0.059
[60,     1] loss: 0.089
[61,     1] loss: 0.070
Early stopping applied (best metric=0.3516184985637665)
Finished Training
Total time taken: 8.620256423950195
(48, 33, 1024)
(190, 33, 1024)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/embeddings (238 samples)
[1,     1] loss: 0.697
[2,     1] loss: 0.693
[3,     1] loss: 0.673
[4,     1] loss: 0.637
[5,     1] loss: 0.604
[6,     1] loss: 0.557
[7,     1] loss: 0.544
[8,     1] loss: 0.458
[9,     1] loss: 0.435
[10,     1] loss: 0.412
[11,     1] loss: 0.403
[12,     1] loss: 0.321
[13,     1] loss: 0.309
[14,     1] loss: 0.341
[15,     1] loss: 0.279
[16,     1] loss: 0.263
[17,     1] loss: 0.321
[18,     1] loss: 0.285
[19,     1] loss: 0.222
[20,     1] loss: 0.213
[21,     1] loss: 0.187
[22,     1] loss: 0.154
[23,     1] loss: 0.195
[24,     1] loss: 0.240
[25,     1] loss: 0.188
[26,     1] loss: 0.138
[27,     1] loss: 0.146
[28,     1] loss: 0.241
[29,     1] loss: 0.177
[30,     1] loss: 0.185
[31,     1] loss: 0.138
[32,     1] loss: 0.118
[33,     1] loss: 0.142
[34,     1] loss: 0.227
[35,     1] loss: 0.141
[36,     1] loss: 0.185
[37,     1] loss: 0.143
[38,     1] loss: 0.203
[39,     1] loss: 0.199
[40,     1] loss: 0.132
[41,     1] loss: 0.147
[42,     1] loss: 0.180
[43,     1] loss: 0.166
[44,     1] loss: 0.128
[45,     1] loss: 0.125
[46,     1] loss: 0.101
[47,     1] loss: 0.100
[48,     1] loss: 0.075
[49,     1] loss: 0.127
[50,     1] loss: 0.167
[51,     1] loss: 0.118
[52,     1] loss: 0.133
[53,     1] loss: 0.101
[54,     1] loss: 0.132
[55,     1] loss: 0.077
[56,     1] loss: 0.120
Early stopping applied (best metric=0.4308810532093048)
Finished Training
Total time taken: 7.830404996871948
results!
{'gpu_mode': True, 'epochs': 200, 'batch_size': 512, 'learning_rate': 0.004684927881340591, 'test_data_ratio': 0.2, 'data_sample_mode': ['oversample'], 'crossValidation': True, 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'folds': 5, 'earlyStopping': True, 'ValidationMetric': 'Validation Loss (total)', 'earlyStoppingPatience': 50, 'CV_Repeats': 5, 'Experiment Name': 'Prottrans embeddings - local', 'weight_decay': 4.506776933725176, 'embeddingType': 'protBert', 'LSTM_layers': 1, 'LSTM_hidden_size': 32, 'LSTM_dropout': 0, 'UseUncertaintyBasedLoss': False, 'useLrWeight': False, 'CreateFigures': False, 'CNNType': 'Musite', 'FCType': 'Adapt', 'aminoAcid': ['Hydroxylation-K'], 'random_state': 2596545638, 'current_CV_Repeat': 5, 'layerToSplitOn': 'FC', 'sample_weights': [1.0], 'currentFold': 4}
{'Hydroxylation-K Validation Accuracy': 0.8419503546099291, 'Hydroxylation-K Validation Sensitivity': 0.8217777777777778, 'Hydroxylation-K Validation Specificity': 0.8473684210526315, 'Hydroxylation-K Validation Precision': 0.5902271988417499, 'Hydroxylation-K AUC ROC': 0.838561403508772, 'Hydroxylation-K AUC PR': 0.6205626845572054, 'Hydroxylation-K MCC': 0.6000388561057335, 'Hydroxylation-K F1': 0.6807706919766889, 'Validation Loss (Hydroxylation-K)': 0.35802692532539365, 'Validation Loss (total)': 0.35802692532539365, 'TimeToTrain': 9.291529064178468}
{'Hydroxylation-K Validation Accuracy': 0.05709274347969857, 'Hydroxylation-K Validation Sensitivity': 0.11575836902790226, 'Hydroxylation-K Validation Specificity': 0.06218178455595536, 'Hydroxylation-K Validation Precision': 0.11632672246773679, 'Hydroxylation-K AUC ROC': 0.07490591014876709, 'Hydroxylation-K AUC PR': 0.14648718142342587, 'Hydroxylation-K MCC': 0.13107078201885983, 'Hydroxylation-K F1': 0.10036439199156906, 'Validation Loss (Hydroxylation-K)': 0.0987652100384909, 'Validation Loss (total)': 0.0987652100384909, 'TimeToTrain': 2.2221315624034768}
