{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0070882041281757615,
 'learning_rate_Methylation-K': 0.003962670848264754,
 'learning_rate_Methylation-R': 0.006174554433516501,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4169279842541929,
 'loss_weight_Methylation-R': 0.2950831158475019,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1971850402,
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.310206511290325,
 'weight_decay_Methylation-K': 4.356505046491349,
 'weight_decay_Methylation-R': 8.458297726890349}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.387
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.387
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.387
Early stopping applied (best metric=0.44482335448265076)
Finished Training
Total time taken: 53.46211624145508
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.387
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
Early stopping applied (best metric=0.4460715353488922)
Finished Training
Total time taken: 49.782721757888794
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.401
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.384
[7,     7] loss: 1.361
[8,     7] loss: 1.343
[9,     7] loss: 1.326
[10,     7] loss: 1.316
[11,     7] loss: 1.285
[12,     7] loss: 1.326
[13,     7] loss: 1.308
[14,     7] loss: 1.297
[15,     7] loss: 1.287
[16,     7] loss: 1.300
[17,     7] loss: 1.274
[18,     7] loss: 1.291
[19,     7] loss: 1.284
[20,     7] loss: 1.277
[21,     7] loss: 1.379
[22,     7] loss: 1.382
[23,     7] loss: 1.378
[24,     7] loss: 1.362
[25,     7] loss: 1.371
[26,     7] loss: 1.356
[27,     7] loss: 1.346
[28,     7] loss: 1.377
[29,     7] loss: 1.387
[30,     7] loss: 1.387
[31,     7] loss: 1.387
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.43720579147338867)
Finished Training
Total time taken: 51.29211640357971
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.387
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
Early stopping applied (best metric=0.44539615511894226)
Finished Training
Total time taken: 70.62314534187317
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.387
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.4455060362815857)
Finished Training
Total time taken: 48.99051260948181
{'Methylation-R Validation Accuracy': 0.08466048019389166, 'Methylation-R Validation Sensitivity': 1.0, 'Methylation-R Validation Specificity': 0.0, 'Methylation-R Validation Precision': 0.08466048019389166, 'Methylation-R AUC ROC': 0.606667706569263, 'Methylation-R AUC PR': 0.24374766906342896, 'Methylation-R MCC': 0.0, 'Methylation-R F1': 0.15610503065657413, 'Validation Loss (Methylation-R)': 0.42941704392433167, 'Methylation-K Validation Accuracy': 0.09784008327442427, 'Methylation-K Validation Sensitivity': 1.0, 'Methylation-K Validation Specificity': 0.0, 'Methylation-K Validation Precision': 0.09784008327442427, 'Methylation-K AUC ROC': 0.4605115504660306, 'Methylation-K AUC PR': 0.1805765054072981, 'Methylation-K MCC': 0.0, 'Methylation-K F1': 0.17824104586382167, 'Validation Loss (Methylation-K)': 0.4438005745410919, 'Validation Loss (total)': 0.8732176065444947, 'TimeToTrain': 54.83012247085571}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00998479878343785,
 'learning_rate_Methylation-K': 0.0018882696908332022,
 'learning_rate_Methylation-R': 0.005459249960606558,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.04427079647021199,
 'loss_weight_Methylation-R': 0.9881502851170871,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3562697908,
 'sample_weights': [0.2950831158475019, 0.4169279842541929],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.717035884771901,
 'weight_decay_Methylation-K': 6.409419602819915,
 'weight_decay_Methylation-R': 6.824380980247497}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.386
[3,     7] loss: 1.380
[4,     7] loss: 1.338
[5,     7] loss: 1.325
[6,     7] loss: 1.318
[7,     7] loss: 1.308
[8,     7] loss: 1.331
[9,     7] loss: 1.374
[10,     7] loss: 1.345
[11,     7] loss: 1.329
[12,     7] loss: 1.330
[13,     7] loss: 1.327
[14,     7] loss: 1.305
[15,     7] loss: 1.317
[16,     7] loss: 1.293
[17,     7] loss: 1.278
[18,     7] loss: 1.295
[19,     7] loss: 1.298
[20,     7] loss: 1.319
[21,     7] loss: 1.377
[22,     7] loss: 1.364
[23,     7] loss: 1.334
[24,     7] loss: 1.329
[25,     7] loss: 1.303
[26,     7] loss: 1.302
[27,     7] loss: 1.297
[28,     7] loss: 1.287
[29,     7] loss: 1.281
[30,     7] loss: 1.313
[31,     7] loss: 1.303
[32,     7] loss: 1.297
[33,     7] loss: 1.320
[34,     7] loss: 1.300
[35,     7] loss: 1.291
[36,     7] loss: 1.295
[37,     7] loss: 1.311
[38,     7] loss: 1.287
[39,     7] loss: 1.362
[40,     7] loss: 1.364
[41,     7] loss: 1.349
[42,     7] loss: 1.375
[43,     7] loss: 1.344
[44,     7] loss: 1.312
[45,     7] loss: 1.310
[46,     7] loss: 1.287
[47,     7] loss: 1.311
[48,     7] loss: 1.346
[49,     7] loss: 1.345
[50,     7] loss: 1.315
[51,     7] loss: 1.297
[52,     7] loss: 1.299
Early stopping applied (best metric=0.4360053241252899)
Finished Training
Total time taken: 46.89612102508545
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.378
[9,     7] loss: 1.368
[10,     7] loss: 1.345
[11,     7] loss: 1.374
[12,     7] loss: 1.359
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
Early stopping applied (best metric=0.43659597635269165)
Finished Training
Total time taken: 57.48639440536499
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.387
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.387
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.387
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.387
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.44153842329978943)
Finished Training
Total time taken: 47.48594284057617
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.400
[2,     7] loss: 1.388
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.369
[11,     7] loss: 1.352
[12,     7] loss: 1.328
[13,     7] loss: 1.323
[14,     7] loss: 1.317
[15,     7] loss: 1.313
[16,     7] loss: 1.309
[17,     7] loss: 1.313
[18,     7] loss: 1.372
[19,     7] loss: 1.363
[20,     7] loss: 1.363
[21,     7] loss: 1.325
[22,     7] loss: 1.319
[23,     7] loss: 1.289
[24,     7] loss: 1.331
[25,     7] loss: 1.314
[26,     7] loss: 1.310
[27,     7] loss: 1.307
[28,     7] loss: 1.400
[29,     7] loss: 1.383
[30,     7] loss: 1.365
[31,     7] loss: 1.364
[32,     7] loss: 1.340
[33,     7] loss: 1.332
[34,     7] loss: 1.328
[35,     7] loss: 1.340
[36,     7] loss: 1.319
[37,     7] loss: 1.309
[38,     7] loss: 1.327
[39,     7] loss: 1.336
[40,     7] loss: 1.329
[41,     7] loss: 1.312
[42,     7] loss: 1.316
[43,     7] loss: 1.303
[44,     7] loss: 1.359
[45,     7] loss: 1.367
[46,     7] loss: 1.359
[47,     7] loss: 1.359
[48,     7] loss: 1.348
[49,     7] loss: 1.329
[50,     7] loss: 1.336
[51,     7] loss: 1.436
[52,     7] loss: 1.388
[53,     7] loss: 1.387
[54,     7] loss: 1.387
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
Early stopping applied (best metric=0.4354088008403778)
Finished Training
Total time taken: 68.48581004142761
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.387
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.387
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.44345781207084656)
Finished Training
Total time taken: 45.16806745529175
{'Methylation-R Validation Accuracy': 0.14878896177520343, 'Methylation-R Validation Sensitivity': 0.9718832891246685, 'Methylation-R Validation Specificity': 0.07266257668711656, 'Methylation-R Validation Precision': 0.08992745831669195, 'Methylation-R AUC ROC': 0.6806408103084237, 'Methylation-R AUC PR': 0.22387261223904723, 'Methylation-R MCC': 0.026098776432151537, 'Methylation-R F1': 0.1642033872608142, 'Validation Loss (Methylation-R)': 0.4088076651096344, 'Methylation-K Validation Accuracy': 0.1600167960370127, 'Methylation-K Validation Sensitivity': 0.921898597626753, 'Methylation-K Validation Specificity': 0.07739293236601918, 'Methylation-K Validation Precision': 0.09773800127897025, 'Methylation-K AUC ROC': 0.4850912636668767, 'Methylation-K AUC PR': 0.09499716734866129, 'Methylation-K MCC': -0.00043212085115391854, 'Methylation-K F1': 0.17616319139026076, 'Validation Loss (Methylation-K)': 0.4386012673377991, 'Validation Loss (total)': 0.847408938407898, 'TimeToTrain': 53.104467153549194}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006784021815627685,
 'learning_rate_Methylation-K': 0.005863610797306871,
 'learning_rate_Methylation-R': 0.008958140427436971,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.25470393449023504,
 'loss_weight_Methylation-R': 0.6437955403511516,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2157227229,
 'sample_weights': [0.9881502851170871, 0.04427079647021199],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.039113524149931,
 'weight_decay_Methylation-K': 7.250157092367452,
 'weight_decay_Methylation-R': 6.568532471491578}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.385
[8,     7] loss: 1.360
[9,     7] loss: 1.338
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032008727455237512,
 'learning_rate_Methylation-K': 0.006541712482679809,
 'learning_rate_Methylation-R': 0.0006190812345623613,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8654615088483788,
 'loss_weight_Methylation-R': 0.4446977479373229,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2164322822,
 'sample_weights': [0.6437955403511516, 0.25470393449023504],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2066258145088093,
 'weight_decay_Methylation-K': 4.289107711269974,
 'weight_decay_Methylation-R': 7.756797486330035}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.388
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.385
[6,     7] loss: 1.379
[7,     7] loss: 1.357
[8,     7] loss: 1.334
[9,     7] loss: 1.318
[10,     7] loss: 1.309
[11,     7] loss: 1.312
[12,     7] loss: 1.297
[13,     7] loss: 1.295
[14,     7] loss: 1.290
[15,     7] loss: 1.283
[16,     7] loss: 1.270
[17,     7] loss: 1.264
[18,     7] loss: 1.241
[19,     7] loss: 1.242
[20,     7] loss: 1.259
[21,     7] loss: 1.257
[22,     7] loss: 1.260
[23,     7] loss: 1.229
[24,     7] loss: 1.238
[25,     7] loss: 1.221
[26,     7] loss: 1.221
[27,     7] loss: 1.208
[28,     7] loss: 1.202
[29,     7] loss: 1.196
[30,     7] loss: 1.202
[31,     7] loss: 1.184
[32,     7] loss: 1.195
[33,     7] loss: 1.182
[34,     7] loss: 1.172
[35,     7] loss: 1.154
[36,     7] loss: 1.144
[37,     7] loss: 1.136
[38,     7] loss: 1.156
[39,     7] loss: 1.115
[40,     7] loss: 1.114
[41,     7] loss: 1.093
[42,     7] loss: 1.115
[43,     7] loss: 1.099
[44,     7] loss: 1.111
[45,     7] loss: 1.096
[46,     7] loss: 1.065
[47,     7] loss: 1.084
[48,     7] loss: 1.058
[49,     7] loss: 1.048
[50,     7] loss: 1.039
[51,     7] loss: 1.037
Early stopping applied (best metric=0.43358302116394043)
Finished Training
Total time taken: 50.78914165496826
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.383
[3,     7] loss: 1.369
[4,     7] loss: 1.341
[5,     7] loss: 1.323
[6,     7] loss: 1.319
[7,     7] loss: 1.305
[8,     7] loss: 1.303
[9,     7] loss: 1.285
[10,     7] loss: 1.295
[11,     7] loss: 1.283
[12,     7] loss: 1.264
[13,     7] loss: 1.253
[14,     7] loss: 1.253
[15,     7] loss: 1.244
[16,     7] loss: 1.230
[17,     7] loss: 1.227
[18,     7] loss: 1.219
[19,     7] loss: 1.220
[20,     7] loss: 1.218
[21,     7] loss: 1.210
[22,     7] loss: 1.215
[23,     7] loss: 1.215
[24,     7] loss: 1.186
[25,     7] loss: 1.173
[26,     7] loss: 1.177
[27,     7] loss: 1.176
[28,     7] loss: 1.165
[29,     7] loss: 1.131
[30,     7] loss: 1.139
[31,     7] loss: 1.120
[32,     7] loss: 1.103
[33,     7] loss: 1.124
[34,     7] loss: 1.112
[35,     7] loss: 1.116
[36,     7] loss: 1.072
[37,     7] loss: 1.075
[38,     7] loss: 1.074
[39,     7] loss: 1.081
[40,     7] loss: 1.087
[41,     7] loss: 1.064
[42,     7] loss: 1.043
[43,     7] loss: 1.048
[44,     7] loss: 1.048
[45,     7] loss: 1.044
[46,     7] loss: 1.041
[47,     7] loss: 1.035
[48,     7] loss: 1.030
[49,     7] loss: 1.019
[50,     7] loss: 1.040
[51,     7] loss: 1.022
Early stopping applied (best metric=0.4506213963031769)
Finished Training
Total time taken: 49.16948580741882
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.385
[6,     7] loss: 1.383
[7,     7] loss: 1.370
[8,     7] loss: 1.346
[9,     7] loss: 1.336
[10,     7] loss: 1.328
[11,     7] loss: 1.306
[12,     7] loss: 1.301
[13,     7] loss: 1.297
[14,     7] loss: 1.286
[15,     7] loss: 1.268
[16,     7] loss: 1.270
[17,     7] loss: 1.253
[18,     7] loss: 1.255
[19,     7] loss: 1.254
[20,     7] loss: 1.244
[21,     7] loss: 1.239
[22,     7] loss: 1.243
[23,     7] loss: 1.236
[24,     7] loss: 1.232
[25,     7] loss: 1.224
[26,     7] loss: 1.234
[27,     7] loss: 1.218
[28,     7] loss: 1.216
[29,     7] loss: 1.204
[30,     7] loss: 1.214
[31,     7] loss: 1.199
[32,     7] loss: 1.197
[33,     7] loss: 1.197
[34,     7] loss: 1.173
[35,     7] loss: 1.165
[36,     7] loss: 1.168
[37,     7] loss: 1.186
[38,     7] loss: 1.151
[39,     7] loss: 1.141
[40,     7] loss: 1.131
[41,     7] loss: 1.129
[42,     7] loss: 1.141
[43,     7] loss: 1.131
[44,     7] loss: 1.108
[45,     7] loss: 1.098
[46,     7] loss: 1.070
[47,     7] loss: 1.083
[48,     7] loss: 1.072
[49,     7] loss: 1.063
[50,     7] loss: 1.052
[51,     7] loss: 1.058
Early stopping applied (best metric=0.44376885890960693)
Finished Training
Total time taken: 51.31876754760742
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.385
[3,     7] loss: 1.381
[4,     7] loss: 1.370
[5,     7] loss: 1.346
[6,     7] loss: 1.334
[7,     7] loss: 1.324
[8,     7] loss: 1.320
[9,     7] loss: 1.318
[10,     7] loss: 1.306
[11,     7] loss: 1.292
[12,     7] loss: 1.295
[13,     7] loss: 1.282
[14,     7] loss: 1.269
[15,     7] loss: 1.275
[16,     7] loss: 1.267
[17,     7] loss: 1.261
[18,     7] loss: 1.248
[19,     7] loss: 1.245
[20,     7] loss: 1.230
[21,     7] loss: 1.241
[22,     7] loss: 1.227
[23,     7] loss: 1.220
[24,     7] loss: 1.216
[25,     7] loss: 1.227
[26,     7] loss: 1.209
[27,     7] loss: 1.199
[28,     7] loss: 1.192
[29,     7] loss: 1.197
[30,     7] loss: 1.194
[31,     7] loss: 1.198
[32,     7] loss: 1.230
[33,     7] loss: 1.222
[34,     7] loss: 1.187
[35,     7] loss: 1.182
[36,     7] loss: 1.164
[37,     7] loss: 1.176
[38,     7] loss: 1.171
[39,     7] loss: 1.143
[40,     7] loss: 1.163
[41,     7] loss: 1.143
[42,     7] loss: 1.152
[43,     7] loss: 1.146
[44,     7] loss: 1.123
[45,     7] loss: 1.150
[46,     7] loss: 1.130
[47,     7] loss: 1.120
[48,     7] loss: 1.127
[49,     7] loss: 1.117
[50,     7] loss: 1.104
[51,     7] loss: 1.112
Early stopping applied (best metric=0.4520614445209503)
Finished Training
Total time taken: 48.06421089172363
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.390
[2,     7] loss: 1.385
[3,     7] loss: 1.377
[4,     7] loss: 1.354
[5,     7] loss: 1.336
[6,     7] loss: 1.334
[7,     7] loss: 1.325
[8,     7] loss: 1.308
[9,     7] loss: 1.308
[10,     7] loss: 1.317
[11,     7] loss: 1.307
[12,     7] loss: 1.289
[13,     7] loss: 1.275
[14,     7] loss: 1.277
[15,     7] loss: 1.268
[16,     7] loss: 1.251
[17,     7] loss: 1.253
[18,     7] loss: 1.251
[19,     7] loss: 1.250
[20,     7] loss: 1.238
[21,     7] loss: 1.243
[22,     7] loss: 1.243
[23,     7] loss: 1.225
[24,     7] loss: 1.219
[25,     7] loss: 1.220
[26,     7] loss: 1.214
[27,     7] loss: 1.204
[28,     7] loss: 1.214
[29,     7] loss: 1.205
[30,     7] loss: 1.188
[31,     7] loss: 1.196
[32,     7] loss: 1.200
[33,     7] loss: 1.192
[34,     7] loss: 1.184
[35,     7] loss: 1.163
[36,     7] loss: 1.172
[37,     7] loss: 1.166
[38,     7] loss: 1.155
[39,     7] loss: 1.136
[40,     7] loss: 1.149
[41,     7] loss: 1.132
[42,     7] loss: 1.129
[43,     7] loss: 1.107
[44,     7] loss: 1.110
[45,     7] loss: 1.096
[46,     7] loss: 1.088
[47,     7] loss: 1.083
[48,     7] loss: 1.096
[49,     7] loss: 1.081
[50,     7] loss: 1.060
[51,     7] loss: 1.071
[52,     7] loss: 1.069
Early stopping applied (best metric=0.4537559449672699)
Finished Training
Total time taken: 47.46845078468323
{'Methylation-R Validation Accuracy': 0.42456136008749185, 'Methylation-R Validation Sensitivity': 0.7654608797348185, 'Methylation-R Validation Specificity': 0.3930306748466258, 'Methylation-R Validation Precision': 0.12419323224417696, 'Methylation-R AUC ROC': 0.6770670560072015, 'Methylation-R AUC PR': 0.22237188540112302, 'Methylation-R MCC': 0.09719094368379959, 'Methylation-R F1': 0.20422652115255108, 'Validation Loss (Methylation-R)': 0.42673309445381163, 'Methylation-K Validation Accuracy': 0.5013906686629934, 'Methylation-K Validation Sensitivity': 0.5029697041712391, 'Methylation-K Validation Specificity': 0.5012106252645477, 'Methylation-K Validation Precision': 0.09969451501300851, 'Methylation-K AUC ROC': 0.4805490179662392, 'Methylation-K AUC PR': 0.09578977276309464, 'Methylation-K MCC': 0.0032099846080731235, 'Methylation-K F1': 0.14411705265644736, 'Validation Loss (Methylation-K)': 0.4467581331729889, 'Validation Loss (total)': 0.8734912157058716, 'TimeToTrain': 49.36201133728027}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007263470637402448,
 'learning_rate_Methylation-K': 0.006210936082022395,
 'learning_rate_Methylation-R': 0.008917370181233293,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.682469746245586,
 'loss_weight_Methylation-R': 0.7661122566415983,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1256416905,
 'sample_weights': [0.4446977479373229, 0.8654615088483788],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7435531533419302,
 'weight_decay_Methylation-K': 6.89911578536233,
 'weight_decay_Methylation-R': 8.478177401584006}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.380
[14,     7] loss: 1.366
[15,     7] loss: 1.357
[16,     7] loss: 1.328
[17,     7] loss: 1.312
[18,     7] loss: 1.309
[19,     7] loss: 1.291
[20,     7] loss: 1.280
[21,     7] loss: 1.259
[22,     7] loss: 1.246
[23,     7] loss: 1.278
[24,     7] loss: 1.254
[25,     7] loss: 1.246
[26,     7] loss: 1.240
[27,     7] loss: 1.223
[28,     7] loss: 1.237
[29,     7] loss: 1.238
[30,     7] loss: 1.231
[31,     7] loss: 1.202
[32,     7] loss: 1.227
[33,     7] loss: 1.207
[34,     7] loss: 1.208
[35,     7] loss: 1.186
[36,     7] loss: 1.177
[37,     7] loss: 1.195
[38,     7] loss: 1.217
[39,     7] loss: 1.225
[40,     7] loss: 1.169
[41,     7] loss: 1.157
[42,     7] loss: 1.138
[43,     7] loss: 1.163
[44,     7] loss: 1.175
[45,     7] loss: 1.152
[46,     7] loss: 1.147
[47,     7] loss: 1.131
[48,     7] loss: 1.138
[49,     7] loss: 1.107
[50,     7] loss: 1.122
[51,     7] loss: 1.120
[52,     7] loss: 1.204
[53,     7] loss: 1.157
[54,     7] loss: 1.118
[55,     7] loss: 1.090
[56,     7] loss: 1.101
[57,     7] loss: 1.094
[58,     7] loss: 1.118
[59,     7] loss: 1.096
[60,     7] loss: 1.086
[61,     7] loss: 1.085
[62,     7] loss: 1.110
[63,     7] loss: 1.090
[64,     7] loss: 1.072
[65,     7] loss: 1.087
[66,     7] loss: 1.171
[67,     7] loss: 1.126
[68,     7] loss: 1.086
[69,     7] loss: 1.071
[70,     7] loss: 1.087
[71,     7] loss: 1.061
[72,     7] loss: 1.073
[73,     7] loss: 1.109
[74,     7] loss: 1.082
[75,     7] loss: 1.123
[76,     7] loss: 1.093
[77,     7] loss: 1.080
[78,     7] loss: 1.059
[79,     7] loss: 1.086
[80,     7] loss: 1.073
[81,     7] loss: 1.074
[82,     7] loss: 1.070
[83,     7] loss: 1.093
[84,     7] loss: 1.106
[85,     7] loss: 1.074
[86,     7] loss: 1.078
[87,     7] loss: 1.068
[88,     7] loss: 1.053
[89,     7] loss: 1.042
Early stopping applied (best metric=0.38005053997039795)
Finished Training
Total time taken: 75.05341076850891
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.387
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.4433036148548126)
Finished Training
Total time taken: 38.137413024902344
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.385
[3,     7] loss: 1.385
[4,     7] loss: 1.382
[5,     7] loss: 1.354
[6,     7] loss: 1.330
[7,     7] loss: 1.328
[8,     7] loss: 1.312
[9,     7] loss: 1.312
[10,     7] loss: 1.303
[11,     7] loss: 1.286
[12,     7] loss: 1.273
[13,     7] loss: 1.277
[14,     7] loss: 1.275
[15,     7] loss: 1.269
[16,     7] loss: 1.249
[17,     7] loss: 1.237
[18,     7] loss: 1.232
[19,     7] loss: 1.225
[20,     7] loss: 1.245
[21,     7] loss: 1.252
[22,     7] loss: 1.231
[23,     7] loss: 1.223
[24,     7] loss: 1.219
[25,     7] loss: 1.233
[26,     7] loss: 1.197
[27,     7] loss: 1.199
[28,     7] loss: 1.202
[29,     7] loss: 1.189
[30,     7] loss: 1.195
[31,     7] loss: 1.205
[32,     7] loss: 1.189
[33,     7] loss: 1.207
[34,     7] loss: 1.208
[35,     7] loss: 1.172
[36,     7] loss: 1.194
[37,     7] loss: 1.204
[38,     7] loss: 1.188
[39,     7] loss: 1.164
[40,     7] loss: 1.206
[41,     7] loss: 1.208
[42,     7] loss: 1.184
[43,     7] loss: 1.165
[44,     7] loss: 1.191
[45,     7] loss: 1.166
[46,     7] loss: 1.157
[47,     7] loss: 1.260
[48,     7] loss: 1.226
[49,     7] loss: 1.183
[50,     7] loss: 1.161
[51,     7] loss: 1.164
[52,     7] loss: 1.171
[53,     7] loss: 1.169
[54,     7] loss: 1.189
[55,     7] loss: 1.171
[56,     7] loss: 1.148
[57,     7] loss: 1.127
[58,     7] loss: 1.137
[59,     7] loss: 1.123
[60,     7] loss: 1.137
[61,     7] loss: 1.136
[62,     7] loss: 1.125
[63,     7] loss: 1.110
[64,     7] loss: 1.131
[65,     7] loss: 1.150
[66,     7] loss: 1.107
[67,     7] loss: 1.114
[68,     7] loss: 1.083
[69,     7] loss: 1.149
[70,     7] loss: 1.139
[71,     7] loss: 1.125
[72,     7] loss: 1.104
[73,     7] loss: 1.087
[74,     7] loss: 1.097
[75,     7] loss: 1.096
[76,     7] loss: 1.104
[77,     7] loss: 1.104
[78,     7] loss: 1.103
[79,     7] loss: 1.122
[80,     7] loss: 1.132
[81,     7] loss: 1.111
[82,     7] loss: 1.122
[83,     7] loss: 1.106
[84,     7] loss: 1.072
[85,     7] loss: 1.094
[86,     7] loss: 1.139
[87,     7] loss: 1.101
[88,     7] loss: 1.100
[89,     7] loss: 1.065
[90,     7] loss: 1.072
[91,     7] loss: 1.098
[92,     7] loss: 1.090
[93,     7] loss: 1.084
[94,     7] loss: 1.046
[95,     7] loss: 1.051
[96,     7] loss: 1.106
[97,     7] loss: 1.145
[98,     7] loss: 1.157
[99,     7] loss: 1.088
[100,     7] loss: 1.075
[101,     7] loss: 1.067
[102,     7] loss: 1.150
[103,     7] loss: 1.091
[104,     7] loss: 1.073
[105,     7] loss: 1.095
[106,     7] loss: 1.091
[107,     7] loss: 1.046
[108,     7] loss: 1.086
[109,     7] loss: 1.103
Early stopping applied (best metric=0.37390437722206116)
Finished Training
Total time taken: 88.17505407333374
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.4460844397544861)
Finished Training
Total time taken: 52.093127965927124
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.379
[14,     7] loss: 1.345
[15,     7] loss: 1.339
[16,     7] loss: 1.318
[17,     7] loss: 1.315
[18,     7] loss: 1.306
[19,     7] loss: 1.293
[20,     7] loss: 1.301
[21,     7] loss: 1.270
[22,     7] loss: 1.275
[23,     7] loss: 1.264
[24,     7] loss: 1.251
[25,     7] loss: 1.252
[26,     7] loss: 1.247
[27,     7] loss: 1.243
[28,     7] loss: 1.236
[29,     7] loss: 1.232
[30,     7] loss: 1.231
[31,     7] loss: 1.232
[32,     7] loss: 1.268
[33,     7] loss: 1.224
[34,     7] loss: 1.219
[35,     7] loss: 1.220
[36,     7] loss: 1.234
[37,     7] loss: 1.241
[38,     7] loss: 1.223
[39,     7] loss: 1.202
[40,     7] loss: 1.233
[41,     7] loss: 1.221
[42,     7] loss: 1.207
[43,     7] loss: 1.205
[44,     7] loss: 1.222
[45,     7] loss: 1.214
[46,     7] loss: 1.199
[47,     7] loss: 1.210
[48,     7] loss: 1.195
[49,     7] loss: 1.187
[50,     7] loss: 1.195
[51,     7] loss: 1.174
[52,     7] loss: 1.214
[53,     7] loss: 1.216
[54,     7] loss: 1.179
[55,     7] loss: 1.179
[56,     7] loss: 1.168
[57,     7] loss: 1.170
[58,     7] loss: 1.147
[59,     7] loss: 1.143
[60,     7] loss: 1.128
[61,     7] loss: 1.180
[62,     7] loss: 1.169
[63,     7] loss: 1.134
[64,     7] loss: 1.133
[65,     7] loss: 1.122
[66,     7] loss: 1.115
[67,     7] loss: 1.119
[68,     7] loss: 1.110
[69,     7] loss: 1.140
[70,     7] loss: 1.129
[71,     7] loss: 1.125
[72,     7] loss: 1.108
[73,     7] loss: 1.092
[74,     7] loss: 1.102
[75,     7] loss: 1.127
[76,     7] loss: 1.107
[77,     7] loss: 1.088
[78,     7] loss: 1.155
[79,     7] loss: 1.173
[80,     7] loss: 1.119
[81,     7] loss: 1.091
[82,     7] loss: 1.110
[83,     7] loss: 1.076
[84,     7] loss: 1.088
[85,     7] loss: 1.081
[86,     7] loss: 1.094
[87,     7] loss: 1.093
[88,     7] loss: 1.067
[89,     7] loss: 1.091
[90,     7] loss: 1.058
[91,     7] loss: 1.097
[92,     7] loss: 1.066
[93,     7] loss: 1.070
[94,     7] loss: 1.067
[95,     7] loss: 1.089
[96,     7] loss: 1.064
[97,     7] loss: 1.099
[98,     7] loss: 1.092
[99,     7] loss: 1.061
Early stopping applied (best metric=0.40088096261024475)
Finished Training
Total time taken: 92.11464023590088
{'Methylation-R Validation Accuracy': 0.38206544549880167, 'Methylation-R Validation Sensitivity': 0.9010226115872496, 'Methylation-R Validation Specificity': 0.3340613496932515, 'Methylation-R Validation Precision': 0.12356716292551014, 'Methylation-R AUC ROC': 0.6944147717819116, 'Methylation-R AUC PR': 0.2547368230149941, 'Methylation-R MCC': 0.1317477073315839, 'Methylation-R F1': 0.21436353114046663, 'Validation Loss (Methylation-R)': 0.35567216873168944, 'Methylation-K Validation Accuracy': 0.30967687780606656, 'Methylation-K Validation Sensitivity': 0.8871186227431903, 'Methylation-K Validation Specificity': 0.24704849821781605, 'Methylation-K Validation Precision': 0.11734991966376135, 'Methylation-K AUC ROC': 0.5908842634891853, 'Methylation-K AUC PR': 0.13014283155100317, 'Methylation-K MCC': 0.08173231775719246, 'Methylation-K F1': 0.20606142921082243, 'Validation Loss (Methylation-K)': 0.4088447868824005, 'Validation Loss (total)': 0.7645169496536255, 'TimeToTrain': 69.1147292137146}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0067475707282475175,
 'learning_rate_Methylation-K': 0.0047969693298891974,
 'learning_rate_Methylation-R': 0.005850295163682264,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.437400419928821,
 'loss_weight_Methylation-R': 0.6096286996606468,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4189814234,
 'sample_weights': [0.7661122566415983, 0.682469746245586],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1056065235776136,
 'weight_decay_Methylation-K': 0.8755863518403539,
 'weight_decay_Methylation-R': 9.802331735504467}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.387
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004208315024527547,
 'learning_rate_Methylation-K': 0.007454709645713452,
 'learning_rate_Methylation-R': 0.002595202593957298,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6253448886812407,
 'loss_weight_Methylation-R': 0.7017040270729878,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3033057814,
 'sample_weights': [0.6096286996606468, 0.437400419928821],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1365860475294705,
 'weight_decay_Methylation-K': 7.789244427099607,
 'weight_decay_Methylation-R': 0.48889622462060633}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.399
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.382
[9,     7] loss: 1.366
[10,     7] loss: 1.348
[11,     7] loss: 1.324
[12,     7] loss: 1.303
[13,     7] loss: 1.305
[14,     7] loss: 1.290
[15,     7] loss: 1.269
[16,     7] loss: 1.266
[17,     7] loss: 1.259
[18,     7] loss: 1.256
[19,     7] loss: 1.251
[20,     7] loss: 1.225
[21,     7] loss: 1.220
[22,     7] loss: 1.231
[23,     7] loss: 1.225
[24,     7] loss: 1.211
[25,     7] loss: 1.203
[26,     7] loss: 1.193
[27,     7] loss: 1.248
[28,     7] loss: 1.188
[29,     7] loss: 1.164
[30,     7] loss: 1.192
[31,     7] loss: 1.143
[32,     7] loss: 1.111
[33,     7] loss: 1.112
[34,     7] loss: 1.126
[35,     7] loss: 1.117
[36,     7] loss: 1.092
[37,     7] loss: 1.118
[38,     7] loss: 1.129
[39,     7] loss: 1.127
[40,     7] loss: 1.138
[41,     7] loss: 1.093
[42,     7] loss: 1.094
[43,     7] loss: 1.072
[44,     7] loss: 1.106
[45,     7] loss: 1.133
[46,     7] loss: 1.089
[47,     7] loss: 1.083
[48,     7] loss: 1.088
[49,     7] loss: 1.092
[50,     7] loss: 1.054
[51,     7] loss: 1.063
[52,     7] loss: 1.087
[53,     7] loss: 1.092
[54,     7] loss: 1.093
[55,     7] loss: 1.085
[56,     7] loss: 1.067
[57,     7] loss: 1.059
[58,     7] loss: 1.070
[59,     7] loss: 1.163
[60,     7] loss: 1.140
[61,     7] loss: 1.097
[62,     7] loss: 1.053
[63,     7] loss: 1.075
[64,     7] loss: 1.076
[65,     7] loss: 1.069
[66,     7] loss: 1.066
[67,     7] loss: 1.047
[68,     7] loss: 1.063
[69,     7] loss: 1.057
[70,     7] loss: 1.034
[71,     7] loss: 1.048
[72,     7] loss: 1.051
[73,     7] loss: 1.075
[74,     7] loss: 1.080
[75,     7] loss: 1.051
[76,     7] loss: 1.044
Early stopping applied (best metric=0.4187867045402527)
Finished Training
Total time taken: 70.21865916252136
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.401
[2,     7] loss: 1.387
[3,     7] loss: 1.384
[4,     7] loss: 1.370
[5,     7] loss: 1.330
[6,     7] loss: 1.323
[7,     7] loss: 1.320
[8,     7] loss: 1.302
[9,     7] loss: 1.293
[10,     7] loss: 1.287
[11,     7] loss: 1.272
[12,     7] loss: 1.255
[13,     7] loss: 1.248
[14,     7] loss: 1.234
[15,     7] loss: 1.275
[16,     7] loss: 1.245
[17,     7] loss: 1.224
[18,     7] loss: 1.221
[19,     7] loss: 1.216
[20,     7] loss: 1.195
[21,     7] loss: 1.199
[22,     7] loss: 1.205
[23,     7] loss: 1.210
[24,     7] loss: 1.199
[25,     7] loss: 1.163
[26,     7] loss: 1.156
[27,     7] loss: 1.163
[28,     7] loss: 1.157
[29,     7] loss: 1.181
[30,     7] loss: 1.155
[31,     7] loss: 1.136
[32,     7] loss: 1.091
[33,     7] loss: 1.110
[34,     7] loss: 1.114
[35,     7] loss: 1.108
[36,     7] loss: 1.134
[37,     7] loss: 1.113
[38,     7] loss: 1.105
[39,     7] loss: 1.110
[40,     7] loss: 1.096
[41,     7] loss: 1.060
[42,     7] loss: 1.135
[43,     7] loss: 1.074
[44,     7] loss: 1.077
[45,     7] loss: 1.058
[46,     7] loss: 1.113
[47,     7] loss: 1.120
[48,     7] loss: 1.137
[49,     7] loss: 1.064
[50,     7] loss: 1.080
[51,     7] loss: 1.054
[52,     7] loss: 1.092
Early stopping applied (best metric=0.4381520450115204)
Finished Training
Total time taken: 46.65448307991028
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.384
[3,     7] loss: 1.368
[4,     7] loss: 1.335
[5,     7] loss: 1.328
[6,     7] loss: 1.319
[7,     7] loss: 1.309
[8,     7] loss: 1.299
[9,     7] loss: 1.288
[10,     7] loss: 1.278
[11,     7] loss: 1.274
[12,     7] loss: 1.254
[13,     7] loss: 1.256
[14,     7] loss: 1.232
[15,     7] loss: 1.247
[16,     7] loss: 1.234
[17,     7] loss: 1.262
[18,     7] loss: 1.238
[19,     7] loss: 1.225
[20,     7] loss: 1.219
[21,     7] loss: 1.209
[22,     7] loss: 1.194
[23,     7] loss: 1.205
[24,     7] loss: 1.210
[25,     7] loss: 1.194
[26,     7] loss: 1.176
[27,     7] loss: 1.197
[28,     7] loss: 1.207
[29,     7] loss: 1.186
[30,     7] loss: 1.162
[31,     7] loss: 1.140
[32,     7] loss: 1.155
[33,     7] loss: 1.126
[34,     7] loss: 1.124
[35,     7] loss: 1.154
[36,     7] loss: 1.140
[37,     7] loss: 1.115
[38,     7] loss: 1.161
[39,     7] loss: 1.119
[40,     7] loss: 1.119
[41,     7] loss: 1.082
[42,     7] loss: 1.114
[43,     7] loss: 1.100
[44,     7] loss: 1.101
[45,     7] loss: 1.097
[46,     7] loss: 1.097
[47,     7] loss: 1.095
[48,     7] loss: 1.145
[49,     7] loss: 1.089
[50,     7] loss: 1.096
[51,     7] loss: 1.082
[52,     7] loss: 1.092
[53,     7] loss: 1.055
[54,     7] loss: 1.173
[55,     7] loss: 1.148
[56,     7] loss: 1.097
[57,     7] loss: 1.114
[58,     7] loss: 1.086
[59,     7] loss: 1.046
[60,     7] loss: 1.072
[61,     7] loss: 1.138
[62,     7] loss: 1.110
[63,     7] loss: 1.093
[64,     7] loss: 1.042
[65,     7] loss: 1.110
[66,     7] loss: 1.104
[67,     7] loss: 1.052
[68,     7] loss: 1.033
[69,     7] loss: 1.038
[70,     7] loss: 1.262
[71,     7] loss: 1.206
[72,     7] loss: 1.167
[73,     7] loss: 1.137
[74,     7] loss: 1.094
[75,     7] loss: 1.090
[76,     7] loss: 1.075
[77,     7] loss: 1.067
[78,     7] loss: 1.096
[79,     7] loss: 1.104
[80,     7] loss: 1.076
[81,     7] loss: 1.066
[82,     7] loss: 1.055
[83,     7] loss: 1.036
[84,     7] loss: 1.030
[85,     7] loss: 1.139
Early stopping applied (best metric=0.3793274760246277)
Finished Training
Total time taken: 78.01612949371338
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.384
[3,     7] loss: 1.370
[4,     7] loss: 1.342
[5,     7] loss: 1.333
[6,     7] loss: 1.323
[7,     7] loss: 1.319
[8,     7] loss: 1.302
[9,     7] loss: 1.281
[10,     7] loss: 1.285
[11,     7] loss: 1.270
[12,     7] loss: 1.272
[13,     7] loss: 1.260
[14,     7] loss: 1.255
[15,     7] loss: 1.241
[16,     7] loss: 1.242
[17,     7] loss: 1.244
[18,     7] loss: 1.226
[19,     7] loss: 1.241
[20,     7] loss: 1.224
[21,     7] loss: 1.238
[22,     7] loss: 1.201
[23,     7] loss: 1.209
[24,     7] loss: 1.217
[25,     7] loss: 1.200
[26,     7] loss: 1.211
[27,     7] loss: 1.193
[28,     7] loss: 1.160
[29,     7] loss: 1.166
[30,     7] loss: 1.147
[31,     7] loss: 1.165
[32,     7] loss: 1.149
[33,     7] loss: 1.153
[34,     7] loss: 1.121
[35,     7] loss: 1.109
[36,     7] loss: 1.143
[37,     7] loss: 1.139
[38,     7] loss: 1.126
[39,     7] loss: 1.164
[40,     7] loss: 1.169
[41,     7] loss: 1.128
[42,     7] loss: 1.085
[43,     7] loss: 1.071
[44,     7] loss: 1.080
[45,     7] loss: 1.052
[46,     7] loss: 1.104
[47,     7] loss: 1.167
[48,     7] loss: 1.115
[49,     7] loss: 1.113
[50,     7] loss: 1.062
[51,     7] loss: 1.087
[52,     7] loss: 1.075
Early stopping applied (best metric=0.4282187521457672)
Finished Training
Total time taken: 47.840354442596436
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.389
[2,     7] loss: 1.377
[3,     7] loss: 1.350
[4,     7] loss: 1.325
[5,     7] loss: 1.323
[6,     7] loss: 1.315
[7,     7] loss: 1.300
[8,     7] loss: 1.292
[9,     7] loss: 1.297
[10,     7] loss: 1.277
[11,     7] loss: 1.261
[12,     7] loss: 1.263
[13,     7] loss: 1.245
[14,     7] loss: 1.244
[15,     7] loss: 1.243
[16,     7] loss: 1.217
[17,     7] loss: 1.223
[18,     7] loss: 1.216
[19,     7] loss: 1.196
[20,     7] loss: 1.214
[21,     7] loss: 1.211
[22,     7] loss: 1.177
[23,     7] loss: 1.175
[24,     7] loss: 1.158
[25,     7] loss: 1.144
[26,     7] loss: 1.159
[27,     7] loss: 1.123
[28,     7] loss: 1.118
[29,     7] loss: 1.123
[30,     7] loss: 1.121
[31,     7] loss: 1.091
[32,     7] loss: 1.151
[33,     7] loss: 1.126
[34,     7] loss: 1.106
[35,     7] loss: 1.084
[36,     7] loss: 1.089
[37,     7] loss: 1.100
[38,     7] loss: 1.132
[39,     7] loss: 1.104
[40,     7] loss: 1.073
[41,     7] loss: 1.064
[42,     7] loss: 1.059
[43,     7] loss: 1.060
[44,     7] loss: 1.106
[45,     7] loss: 1.081
[46,     7] loss: 1.094
[47,     7] loss: 1.068
[48,     7] loss: 1.076
[49,     7] loss: 1.067
[50,     7] loss: 1.053
[51,     7] loss: 1.081
[52,     7] loss: 1.058
[53,     7] loss: 1.060
[54,     7] loss: 1.111
[55,     7] loss: 1.083
[56,     7] loss: 1.074
[57,     7] loss: 1.078
[58,     7] loss: 1.086
[59,     7] loss: 1.091
[60,     7] loss: 1.126
[61,     7] loss: 1.042
[62,     7] loss: 1.041
[63,     7] loss: 1.060
[64,     7] loss: 1.055
[65,     7] loss: 1.178
[66,     7] loss: 1.097
[67,     7] loss: 1.068
[68,     7] loss: 1.075
[69,     7] loss: 1.041
[70,     7] loss: 1.061
[71,     7] loss: 1.091
Early stopping applied (best metric=0.44591787457466125)
Finished Training
Total time taken: 64.94548654556274
{'Methylation-R Validation Accuracy': 0.40605734572242574, 'Methylation-R Validation Sensitivity': 0.88721189512507, 'Methylation-R Validation Specificity': 0.36154601226993865, 'Methylation-R Validation Precision': 0.13074770286980542, 'Methylation-R AUC ROC': 0.7542952866299741, 'Methylation-R AUC PR': 0.3147052698531426, 'Methylation-R MCC': 0.14430641552846854, 'Methylation-R F1': 0.22350081382252457, 'Validation Loss (Methylation-R)': 0.3450916886329651, 'Methylation-K Validation Accuracy': 0.3920268891743661, 'Methylation-K Validation Sensitivity': 0.7865081861412252, 'Methylation-K Validation Specificity': 0.349232382575035, 'Methylation-K Validation Precision': 0.1247398620543899, 'Methylation-K AUC ROC': 0.5865990267290918, 'Methylation-K AUC PR': 0.1358893588352145, 'Methylation-K MCC': 0.08336822537440144, 'Methylation-K F1': 0.2106914371667622, 'Validation Loss (Methylation-K)': 0.42208057045936587, 'Validation Loss (total)': 0.7671722650527955, 'TimeToTrain': 61.53502254486084}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00014289882450332805,
 'learning_rate_Methylation-K': 0.007861807252362397,
 'learning_rate_Methylation-R': 0.002501382373602519,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.49618765801701703,
 'loss_weight_Methylation-R': 0.5802580172897281,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1157680707,
 'sample_weights': [0.7017040270729878, 0.6253448886812407],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.564243899207976,
 'weight_decay_Methylation-K': 0.674134813158721,
 'weight_decay_Methylation-R': 7.244772598056511}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.385
[5,     7] loss: 1.384
[6,     7] loss: 1.384
[7,     7] loss: 1.382
[8,     7] loss: 1.376
[9,     7] loss: 1.371
[10,     7] loss: 1.362
[11,     7] loss: 1.351
[12,     7] loss: 1.344
[13,     7] loss: 1.327
[14,     7] loss: 1.323
[15,     7] loss: 1.313
[16,     7] loss: 1.305
[17,     7] loss: 1.291
[18,     7] loss: 1.281
[19,     7] loss: 1.270
[20,     7] loss: 1.252
[21,     7] loss: 1.244
[22,     7] loss: 1.246
[23,     7] loss: 1.228
[24,     7] loss: 1.221
[25,     7] loss: 1.218
[26,     7] loss: 1.216
[27,     7] loss: 1.203
[28,     7] loss: 1.200
[29,     7] loss: 1.185
[30,     7] loss: 1.181
[31,     7] loss: 1.189
[32,     7] loss: 1.180
[33,     7] loss: 1.165
[34,     7] loss: 1.163
[35,     7] loss: 1.166
[36,     7] loss: 1.146
[37,     7] loss: 1.156
[38,     7] loss: 1.146
[39,     7] loss: 1.154
[40,     7] loss: 1.134
[41,     7] loss: 1.140
[42,     7] loss: 1.125
[43,     7] loss: 1.120
[44,     7] loss: 1.128
[45,     7] loss: 1.131
[46,     7] loss: 1.108
[47,     7] loss: 1.122
[48,     7] loss: 1.118
[49,     7] loss: 1.103
[50,     7] loss: 1.119
[51,     7] loss: 1.101
Early stopping applied (best metric=0.4380585849285126)
Finished Training
Total time taken: 45.74433255195618
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.397
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.385
[5,     7] loss: 1.384
[6,     7] loss: 1.380
[7,     7] loss: 1.374
[8,     7] loss: 1.364
[9,     7] loss: 1.355
[10,     7] loss: 1.350
[11,     7] loss: 1.333
[12,     7] loss: 1.335
[13,     7] loss: 1.324
[14,     7] loss: 1.319
[15,     7] loss: 1.307
[16,     7] loss: 1.311
[17,     7] loss: 1.303
[18,     7] loss: 1.294
[19,     7] loss: 1.294
[20,     7] loss: 1.290
[21,     7] loss: 1.277
[22,     7] loss: 1.266
[23,     7] loss: 1.271
[24,     7] loss: 1.262
[25,     7] loss: 1.268
[26,     7] loss: 1.264
[27,     7] loss: 1.254
[28,     7] loss: 1.258
[29,     7] loss: 1.249
[30,     7] loss: 1.242
[31,     7] loss: 1.232
[32,     7] loss: 1.227
[33,     7] loss: 1.229
[34,     7] loss: 1.214
[35,     7] loss: 1.209
[36,     7] loss: 1.212
[37,     7] loss: 1.206
[38,     7] loss: 1.206
[39,     7] loss: 1.184
[40,     7] loss: 1.175
[41,     7] loss: 1.183
[42,     7] loss: 1.163
[43,     7] loss: 1.172
[44,     7] loss: 1.152
[45,     7] loss: 1.151
[46,     7] loss: 1.154
[47,     7] loss: 1.151
[48,     7] loss: 1.145
[49,     7] loss: 1.140
[50,     7] loss: 1.142
[51,     7] loss: 1.142
Early stopping applied (best metric=0.44344472885131836)
Finished Training
Total time taken: 47.65239596366882
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.385
[4,     7] loss: 1.384
[5,     7] loss: 1.382
[6,     7] loss: 1.378
[7,     7] loss: 1.373
[8,     7] loss: 1.364
[9,     7] loss: 1.355
[10,     7] loss: 1.344
[11,     7] loss: 1.337
[12,     7] loss: 1.331
[13,     7] loss: 1.322
[14,     7] loss: 1.312
[15,     7] loss: 1.303
[16,     7] loss: 1.303
[17,     7] loss: 1.289
[18,     7] loss: 1.286
[19,     7] loss: 1.276
[20,     7] loss: 1.267
[21,     7] loss: 1.251
[22,     7] loss: 1.242
[23,     7] loss: 1.226
[24,     7] loss: 1.220
[25,     7] loss: 1.204
[26,     7] loss: 1.213
[27,     7] loss: 1.189
[28,     7] loss: 1.194
[29,     7] loss: 1.172
[30,     7] loss: 1.174
[31,     7] loss: 1.171
[32,     7] loss: 1.154
[33,     7] loss: 1.166
[34,     7] loss: 1.151
[35,     7] loss: 1.157
[36,     7] loss: 1.153
[37,     7] loss: 1.149
[38,     7] loss: 1.150
[39,     7] loss: 1.132
[40,     7] loss: 1.125
[41,     7] loss: 1.110
[42,     7] loss: 1.123
[43,     7] loss: 1.121
[44,     7] loss: 1.117
[45,     7] loss: 1.115
[46,     7] loss: 1.113
[47,     7] loss: 1.102
[48,     7] loss: 1.083
[49,     7] loss: 1.106
[50,     7] loss: 1.097
[51,     7] loss: 1.073
[52,     7] loss: 1.075
[53,     7] loss: 1.072
[54,     7] loss: 1.072
Early stopping applied (best metric=0.44709572196006775)
Finished Training
Total time taken: 51.245086669921875
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.385
[4,     7] loss: 1.383
[5,     7] loss: 1.380
[6,     7] loss: 1.374
[7,     7] loss: 1.367
[8,     7] loss: 1.359
[9,     7] loss: 1.349
[10,     7] loss: 1.339
[11,     7] loss: 1.333
[12,     7] loss: 1.327
[13,     7] loss: 1.323
[14,     7] loss: 1.317
[15,     7] loss: 1.308
[16,     7] loss: 1.316
[17,     7] loss: 1.301
[18,     7] loss: 1.297
[19,     7] loss: 1.288
[20,     7] loss: 1.278
[21,     7] loss: 1.274
[22,     7] loss: 1.266
[23,     7] loss: 1.261
[24,     7] loss: 1.248
[25,     7] loss: 1.230
[26,     7] loss: 1.221
[27,     7] loss: 1.221
[28,     7] loss: 1.215
[29,     7] loss: 1.193
[30,     7] loss: 1.196
[31,     7] loss: 1.200
[32,     7] loss: 1.182
[33,     7] loss: 1.180
[34,     7] loss: 1.167
[35,     7] loss: 1.166
[36,     7] loss: 1.172
[37,     7] loss: 1.164
[38,     7] loss: 1.153
[39,     7] loss: 1.150
[40,     7] loss: 1.139
[41,     7] loss: 1.139
[42,     7] loss: 1.132
[43,     7] loss: 1.124
[44,     7] loss: 1.115
[45,     7] loss: 1.121
[46,     7] loss: 1.108
[47,     7] loss: 1.114
[48,     7] loss: 1.116
[49,     7] loss: 1.110
[50,     7] loss: 1.108
[51,     7] loss: 1.107
Early stopping applied (best metric=0.44821393489837646)
Finished Training
Total time taken: 46.93071889877319
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.394
[2,     7] loss: 1.386
[3,     7] loss: 1.385
[4,     7] loss: 1.384
[5,     7] loss: 1.381
[6,     7] loss: 1.376
[7,     7] loss: 1.370
[8,     7] loss: 1.364
[9,     7] loss: 1.356
[10,     7] loss: 1.342
[11,     7] loss: 1.334
[12,     7] loss: 1.329
[13,     7] loss: 1.321
[14,     7] loss: 1.306
[15,     7] loss: 1.304
[16,     7] loss: 1.293
[17,     7] loss: 1.288
[18,     7] loss: 1.274
[19,     7] loss: 1.262
[20,     7] loss: 1.257
[21,     7] loss: 1.236
[22,     7] loss: 1.238
[23,     7] loss: 1.213
[24,     7] loss: 1.206
[25,     7] loss: 1.211
[26,     7] loss: 1.180
[27,     7] loss: 1.185
[28,     7] loss: 1.181
[29,     7] loss: 1.178
[30,     7] loss: 1.183
[31,     7] loss: 1.163
[32,     7] loss: 1.170
[33,     7] loss: 1.164
[34,     7] loss: 1.149
[35,     7] loss: 1.157
[36,     7] loss: 1.154
[37,     7] loss: 1.147
[38,     7] loss: 1.132
[39,     7] loss: 1.128
[40,     7] loss: 1.135
[41,     7] loss: 1.110
[42,     7] loss: 1.120
[43,     7] loss: 1.130
[44,     7] loss: 1.101
[45,     7] loss: 1.116
[46,     7] loss: 1.102
[47,     7] loss: 1.105
[48,     7] loss: 1.095
[49,     7] loss: 1.087
[50,     7] loss: 1.101
[51,     7] loss: 1.076
[52,     7] loss: 1.073
Early stopping applied (best metric=0.4504850208759308)
Finished Training
Total time taken: 48.26085448265076
{'Methylation-R Validation Accuracy': 0.29959219304717644, 'Methylation-R Validation Sensitivity': 0.850777966824127, 'Methylation-R Validation Specificity': 0.24858895705521472, 'Methylation-R Validation Precision': 0.12197607826077773, 'Methylation-R AUC ROC': 0.6613856494738366, 'Methylation-R AUC PR': 0.21502907184027498, 'Methylation-R MCC': 0.07724013955026807, 'Methylation-R F1': 0.19415358314838324, 'Validation Loss (Methylation-R)': 0.4285664916038513, 'Methylation-K Validation Accuracy': 0.35806473210854856, 'Methylation-K Validation Sensitivity': 0.6593430583805723, 'Methylation-K Validation Specificity': 0.32536756645651654, 'Methylation-K Validation Precision': 0.09989371548631183, 'Methylation-K AUC ROC': 0.4895443015485425, 'Methylation-K AUC PR': 0.09818037244262792, 'Methylation-K MCC': -0.007806455493887262, 'Methylation-K F1': 0.1505080888545144, 'Validation Loss (Methylation-K)': 0.4454595983028412, 'Validation Loss (total)': 0.874026072025299, 'TimeToTrain': 47.96667771339416}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008655148513407361,
 'learning_rate_Methylation-K': 0.00544313683978798,
 'learning_rate_Methylation-R': 0.0038567881007159324,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2277233547361765,
 'loss_weight_Methylation-R': 0.7436185170980713,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3292556175,
 'sample_weights': [0.5802580172897281, 0.49618765801701703],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.495606298927768,
 'weight_decay_Methylation-K': 8.045078055005229,
 'weight_decay_Methylation-R': 1.5039325526771152}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.385
[4,     7] loss: 1.357
[5,     7] loss: 1.327
[6,     7] loss: 1.326
[7,     7] loss: 1.299
[8,     7] loss: 1.301
[9,     7] loss: 1.314
[10,     7] loss: 1.331
[11,     7] loss: 1.295
[12,     7] loss: 1.323
[13,     7] loss: 1.331
[14,     7] loss: 1.304
[15,     7] loss: 1.285
[16,     7] loss: 1.286
[17,     7] loss: 1.305
[18,     7] loss: 1.307
[19,     7] loss: 1.286
[20,     7] loss: 1.272
[21,     7] loss: 1.284
[22,     7] loss: 1.301
[23,     7] loss: 1.279
[24,     7] loss: 1.268
[25,     7] loss: 1.330
[26,     7] loss: 1.355
[27,     7] loss: 1.356
[28,     7] loss: 1.348
[29,     7] loss: 1.338
[30,     7] loss: 1.309
[31,     7] loss: 1.305
[32,     7] loss: 1.272
[33,     7] loss: 1.356
[34,     7] loss: 1.367
[35,     7] loss: 1.359
[36,     7] loss: 1.318
[37,     7] loss: 1.281
[38,     7] loss: 1.319
[39,     7] loss: 1.291
[40,     7] loss: 1.286
[41,     7] loss: 1.379
[42,     7] loss: 1.320
[43,     7] loss: 1.299
[44,     7] loss: 1.286
[45,     7] loss: 1.306
[46,     7] loss: 1.281
[47,     7] loss: 1.272
[48,     7] loss: 1.310
[49,     7] loss: 1.337
[50,     7] loss: 1.297
[51,     7] loss: 1.331
[52,     7] loss: 1.311
[53,     7] loss: 1.299
[54,     7] loss: 1.276
[55,     7] loss: 1.289
[56,     7] loss: 1.275
[57,     7] loss: 1.418
[58,     7] loss: 1.389
[59,     7] loss: 1.387
[60,     7] loss: 1.386
[61,     7] loss: 1.387
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.387
[89,     7] loss: 1.386
[90,     7] loss: 1.386
Early stopping applied (best metric=0.4057473838329315)
Finished Training
Total time taken: 84.2520580291748
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.387
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.4392169415950775)
Finished Training
Total time taken: 47.61478042602539
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.385
[3,     7] loss: 1.363
[4,     7] loss: 1.345
[5,     7] loss: 1.327
[6,     7] loss: 1.321
[7,     7] loss: 1.307
[8,     7] loss: 1.298
[9,     7] loss: 1.340
[10,     7] loss: 1.381
[11,     7] loss: 1.365
[12,     7] loss: 1.386
[13,     7] loss: 1.384
[14,     7] loss: 1.376
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.387
[19,     7] loss: 1.387
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.4416305124759674)
Finished Training
Total time taken: 48.19324469566345
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.384
[5,     7] loss: 1.363
[6,     7] loss: 1.332
[7,     7] loss: 1.303
[8,     7] loss: 1.316
[9,     7] loss: 1.349
[10,     7] loss: 1.425
[11,     7] loss: 1.387
[12,     7] loss: 1.387
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.384
[24,     7] loss: 1.368
[25,     7] loss: 1.360
[26,     7] loss: 1.334
[27,     7] loss: 1.354
[28,     7] loss: 1.348
[29,     7] loss: 1.335
[30,     7] loss: 1.317
[31,     7] loss: 1.324
[32,     7] loss: 1.306
[33,     7] loss: 1.398
[34,     7] loss: 1.373
[35,     7] loss: 1.379
[36,     7] loss: 1.386
[37,     7] loss: 1.384
[38,     7] loss: 1.377
[39,     7] loss: 1.374
[40,     7] loss: 1.369
[41,     7] loss: 1.336
[42,     7] loss: 1.322
[43,     7] loss: 1.308
[44,     7] loss: 1.324
[45,     7] loss: 1.313
[46,     7] loss: 1.310
[47,     7] loss: 1.314
[48,     7] loss: 1.307
[49,     7] loss: 1.286
[50,     7] loss: 1.297
[51,     7] loss: 1.313
[52,     7] loss: 1.298
Early stopping applied (best metric=0.4340951144695282)
Finished Training
Total time taken: 47.33799695968628
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.365
[6,     7] loss: 1.341
[7,     7] loss: 1.319
[8,     7] loss: 1.327
[9,     7] loss: 1.343
[10,     7] loss: 1.302
[11,     7] loss: 1.342
[12,     7] loss: 1.317
[13,     7] loss: 1.388
[14,     7] loss: 1.376
[15,     7] loss: 1.344
[16,     7] loss: 1.330
[17,     7] loss: 1.352
[18,     7] loss: 1.389
[19,     7] loss: 1.378
[20,     7] loss: 1.336
[21,     7] loss: 1.337
[22,     7] loss: 1.336
[23,     7] loss: 1.337
[24,     7] loss: 1.320
[25,     7] loss: 1.308
[26,     7] loss: 1.303
[27,     7] loss: 1.362
[28,     7] loss: 1.323
[29,     7] loss: 1.304
[30,     7] loss: 1.296
[31,     7] loss: 1.356
[32,     7] loss: 1.329
[33,     7] loss: 1.311
[34,     7] loss: 1.297
[35,     7] loss: 1.291
[36,     7] loss: 1.319
[37,     7] loss: 1.320
[38,     7] loss: 1.290
[39,     7] loss: 1.288
[40,     7] loss: 1.300
[41,     7] loss: 1.308
[42,     7] loss: 1.330
[43,     7] loss: 1.294
[44,     7] loss: 1.282
[45,     7] loss: 1.296
[46,     7] loss: 1.385
[47,     7] loss: 1.388
[48,     7] loss: 1.386
[49,     7] loss: 1.384
[50,     7] loss: 1.367
[51,     7] loss: 1.343
[52,     7] loss: 1.340
[53,     7] loss: 1.317
[54,     7] loss: 1.318
[55,     7] loss: 1.358
[56,     7] loss: 1.334
[57,     7] loss: 1.318
[58,     7] loss: 1.307
[59,     7] loss: 1.315
[60,     7] loss: 1.306
[61,     7] loss: 1.304
[62,     7] loss: 1.302
[63,     7] loss: 1.340
[64,     7] loss: 1.405
[65,     7] loss: 1.397
[66,     7] loss: 1.392
[67,     7] loss: 1.390
[68,     7] loss: 1.388
[69,     7] loss: 1.387
[70,     7] loss: 1.387
[71,     7] loss: 1.387
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.386
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
[95,     7] loss: 1.386
[96,     7] loss: 1.386
[97,     7] loss: 1.386
[98,     7] loss: 1.386
[99,     7] loss: 1.386
[100,     7] loss: 1.386
[101,     7] loss: 1.386
[102,     7] loss: 1.386
[103,     7] loss: 1.386
[104,     7] loss: 1.386
[105,     7] loss: 1.386
[106,     7] loss: 1.386
[107,     7] loss: 1.386
[108,     7] loss: 1.386
[109,     7] loss: 1.386
[110,     7] loss: 1.386
[111,     7] loss: 1.386
[112,     7] loss: 1.387
[113,     7] loss: 1.386
Early stopping applied (best metric=0.4072839021682739)
Finished Training
Total time taken: 102.40655755996704
{'Methylation-R Validation Accuracy': 0.09043329529735426, 'Methylation-R Validation Sensitivity': 0.9992038917715521, 'Methylation-R Validation Specificity': 0.006380368098159509, 'Methylation-R Validation Precision': 0.0850988848807618, 'Methylation-R AUC ROC': 0.6871684342892921, 'Methylation-R AUC PR': 0.22940524389478692, 'Methylation-R MCC': 0.01477532108975329, 'Methylation-R F1': 0.15683978574270876, 'Validation Loss (Methylation-R)': 0.3840491771697998, 'Methylation-K Validation Accuracy': 0.10704591033072751, 'Methylation-K Validation Sensitivity': 0.9900729495038455, 'Methylation-K Validation Specificity': 0.01128060212333844, 'Methylation-K Validation Precision': 0.09796054906103725, 'Methylation-K AUC ROC': 0.4782339312094893, 'Methylation-K AUC PR': 0.09556004235320496, 'Methylation-K MCC': 0.003784070263486472, 'Methylation-K F1': 0.17828002370625914, 'Validation Loss (Methylation-K)': 0.42559477090835574, 'Validation Loss (total)': 0.8096439719200135, 'TimeToTrain': 65.96092753410339}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0044691845748008234,
 'learning_rate_Methylation-K': 0.0002875200743245455,
 'learning_rate_Methylation-R': 0.009504709146490951,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5456354441206358,
 'loss_weight_Methylation-R': 0.8643919580091716,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3946559071,
 'sample_weights': [0.7436185170980713, 0.2277233547361765],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.612184127846197,
 'weight_decay_Methylation-K': 3.680016162020927,
 'weight_decay_Methylation-R': 6.042068209425636}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.365
[4,     7] loss: 1.342
[5,     7] loss: 1.326
[6,     7] loss: 1.298
[7,     7] loss: 1.280
[8,     7] loss: 1.297
[9,     7] loss: 1.267
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006491891138001715,
 'learning_rate_Methylation-K': 0.00809786593149887,
 'learning_rate_Methylation-R': 0.0046792089558586845,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.33228707869967317,
 'loss_weight_Methylation-R': 0.03162707712495223,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2086151894,
 'sample_weights': [0.8643919580091716, 0.5456354441206358],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.116192121953537,
 'weight_decay_Methylation-K': 3.16945584967209,
 'weight_decay_Methylation-R': 7.605435210455012}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.373
[8,     7] loss: 1.346
[9,     7] loss: 1.332
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00505724049229935,
 'learning_rate_Methylation-K': 0.002886669593717233,
 'learning_rate_Methylation-R': 0.0022837991494655593,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9716501627998304,
 'loss_weight_Methylation-R': 0.1770765247442101,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3446825105,
 'sample_weights': [0.03162707712495223, 0.33228707869967317],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.293744707975416,
 'weight_decay_Methylation-K': 0.15690487579081536,
 'weight_decay_Methylation-R': 0.00296917281459419}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.386
[3,     7] loss: 1.384
[4,     7] loss: 1.367
[5,     7] loss: 1.331
[6,     7] loss: 1.309
[7,     7] loss: 1.302
[8,     7] loss: 1.316
[9,     7] loss: 1.302
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004226849235420366,
 'learning_rate_Methylation-K': 0.009906464049471294,
 'learning_rate_Methylation-R': 0.0064977370649402354,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2617185642219148,
 'loss_weight_Methylation-R': 0.25841102193114224,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1523524182,
 'sample_weights': [0.1770765247442101, 0.9716501627998304],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.403673780910147,
 'weight_decay_Methylation-K': 3.390327331882297,
 'weight_decay_Methylation-R': 4.380510135406176}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.383
[3,     7] loss: 1.363
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005879665955493146,
 'learning_rate_Methylation-K': 0.0007016152739644552,
 'learning_rate_Methylation-R': 0.00013843744200425632,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5527842818325187,
 'loss_weight_Methylation-R': 0.5481641218143685,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2054511430,
 'sample_weights': [0.25841102193114224, 0.2617185642219148],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.858379750242088,
 'weight_decay_Methylation-K': 2.875743908906353,
 'weight_decay_Methylation-R': 1.201690985291447}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008738529289392442,
 'learning_rate_Methylation-K': 0.007342110103351677,
 'learning_rate_Methylation-R': 0.00046788535148931435,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.11623698792193307,
 'loss_weight_Methylation-R': 0.9461613489540598,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3745869210,
 'sample_weights': [0.5481641218143685, 0.5527842818325187],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.660699045326183,
 'weight_decay_Methylation-K': 6.353196682331595,
 'weight_decay_Methylation-R': 0.09271304457696083}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.386
[3,     7] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005784728164149512,
 'learning_rate_Methylation-K': 0.0033108320637431367,
 'learning_rate_Methylation-R': 0.0024334206877904803,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1556969385601539,
 'loss_weight_Methylation-R': 0.9299067200617753,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1803965243,
 'sample_weights': [0.9461613489540598, 0.11623698792193307],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.701375406522054,
 'weight_decay_Methylation-K': 1.4229808336496719,
 'weight_decay_Methylation-R': 2.0085356052665517}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008326352804520456,
 'learning_rate_Methylation-K': 0.0033848851026462485,
 'learning_rate_Methylation-R': 0.009409015369071605,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.040299565907233326,
 'loss_weight_Methylation-R': 0.4666950695386642,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3067156362,
 'sample_weights': [0.9299067200617753, 0.1556969385601539],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.515004604821435,
 'weight_decay_Methylation-K': 1.879421610039359,
 'weight_decay_Methylation-R': 2.7728540599314355}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00894404373557982,
 'learning_rate_Methylation-K': 0.0020893506790694186,
 'learning_rate_Methylation-R': 0.009001942235697618,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8418103147151813,
 'loss_weight_Methylation-R': 0.6673807730231391,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1951088936,
 'sample_weights': [0.4666950695386642, 0.040299565907233326],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.686457150203408,
 'weight_decay_Methylation-K': 4.411515448282447,
 'weight_decay_Methylation-R': 1.2923790776139576}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.371
[6,     7] loss: 1.339
[7,     7] loss: 1.330
[8,     7] loss: 1.319
[9,     7] loss: 1.307
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002937436080359755,
 'learning_rate_Methylation-K': 0.00406346121149083,
 'learning_rate_Methylation-R': 0.000699941272967972,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6367955750557676,
 'loss_weight_Methylation-R': 0.6947795893944875,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3038284870,
 'sample_weights': [0.6673807730231391, 0.8418103147151813],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8443835060433895,
 'weight_decay_Methylation-K': 7.2934289433948365,
 'weight_decay_Methylation-R': 2.648632812445787}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.369
[3,     7] loss: 1.332
[4,     7] loss: 1.320
[5,     7] loss: 1.314
[6,     7] loss: 1.310
[7,     7] loss: 1.288
[8,     7] loss: 1.268
[9,     7] loss: 1.268
[10,     7] loss: 1.264
[11,     7] loss: 1.250
[12,     7] loss: 1.241
[13,     7] loss: 1.234
[14,     7] loss: 1.225
[15,     7] loss: 1.236
[16,     7] loss: 1.255
[17,     7] loss: 1.235
[18,     7] loss: 1.217
[19,     7] loss: 1.226
[20,     7] loss: 1.189
[21,     7] loss: 1.192
[22,     7] loss: 1.219
[23,     7] loss: 1.221
[24,     7] loss: 1.185
[25,     7] loss: 1.178
[26,     7] loss: 1.169
[27,     7] loss: 1.158
[28,     7] loss: 1.144
[29,     7] loss: 1.114
[30,     7] loss: 1.127
[31,     7] loss: 1.142
[32,     7] loss: 1.152
[33,     7] loss: 1.152
[34,     7] loss: 1.104
[35,     7] loss: 1.144
[36,     7] loss: 1.129
[37,     7] loss: 1.119
[38,     7] loss: 1.091
[39,     7] loss: 1.076
[40,     7] loss: 1.116
[41,     7] loss: 1.097
[42,     7] loss: 1.080
[43,     7] loss: 1.100
[44,     7] loss: 1.082
[45,     7] loss: 1.070
[46,     7] loss: 1.069
[47,     7] loss: 1.072
[48,     7] loss: 1.056
[49,     7] loss: 1.068
[50,     7] loss: 1.034
[51,     7] loss: 1.035
[52,     7] loss: 1.074
[53,     7] loss: 1.074
[54,     7] loss: 1.085
[55,     7] loss: 1.070
[56,     7] loss: 1.108
[57,     7] loss: 1.065
[58,     7] loss: 1.047
[59,     7] loss: 1.044
[60,     7] loss: 1.053
[61,     7] loss: 1.048
[62,     7] loss: 1.054
[63,     7] loss: 1.052
[64,     7] loss: 1.035
[65,     7] loss: 1.011
[66,     7] loss: 1.088
[67,     7] loss: 1.055
[68,     7] loss: 1.033
[69,     7] loss: 1.013
[70,     7] loss: 1.030
[71,     7] loss: 1.015
[72,     7] loss: 1.043
[73,     7] loss: 1.059
[74,     7] loss: 1.037
[75,     7] loss: 1.016
[76,     7] loss: 1.047
[77,     7] loss: 1.025
[78,     7] loss: 1.045
[79,     7] loss: 1.037
Early stopping applied (best metric=0.39691734313964844)
Finished Training
Total time taken: 72.76714301109314
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.385
[3,     7] loss: 1.375
[4,     7] loss: 1.346
[5,     7] loss: 1.328
[6,     7] loss: 1.320
[7,     7] loss: 1.309
[8,     7] loss: 1.294
[9,     7] loss: 1.278
[10,     7] loss: 1.263
[11,     7] loss: 1.267
[12,     7] loss: 1.251
[13,     7] loss: 1.255
[14,     7] loss: 1.248
[15,     7] loss: 1.229
[16,     7] loss: 1.226
[17,     7] loss: 1.215
[18,     7] loss: 1.205
[19,     7] loss: 1.211
[20,     7] loss: 1.218
[21,     7] loss: 1.207
[22,     7] loss: 1.194
[23,     7] loss: 1.197
[24,     7] loss: 1.185
[25,     7] loss: 1.195
[26,     7] loss: 1.167
[27,     7] loss: 1.168
[28,     7] loss: 1.166
[29,     7] loss: 1.157
[30,     7] loss: 1.204
[31,     7] loss: 1.161
[32,     7] loss: 1.128
[33,     7] loss: 1.109
[34,     7] loss: 1.131
[35,     7] loss: 1.149
[36,     7] loss: 1.115
[37,     7] loss: 1.108
[38,     7] loss: 1.103
[39,     7] loss: 1.076
[40,     7] loss: 1.139
[41,     7] loss: 1.117
[42,     7] loss: 1.116
[43,     7] loss: 1.093
[44,     7] loss: 1.061
[45,     7] loss: 1.067
[46,     7] loss: 1.075
[47,     7] loss: 1.085
[48,     7] loss: 1.072
[49,     7] loss: 1.055
[50,     7] loss: 1.075
[51,     7] loss: 1.073
[52,     7] loss: 1.066
[53,     7] loss: 1.062
[54,     7] loss: 1.076
[55,     7] loss: 1.046
[56,     7] loss: 1.027
[57,     7] loss: 1.131
[58,     7] loss: 1.089
[59,     7] loss: 1.055
[60,     7] loss: 1.053
[61,     7] loss: 1.047
[62,     7] loss: 1.098
[63,     7] loss: 1.055
[64,     7] loss: 1.026
[65,     7] loss: 1.098
[66,     7] loss: 1.141
[67,     7] loss: 1.079
[68,     7] loss: 1.070
[69,     7] loss: 1.059
[70,     7] loss: 1.047
[71,     7] loss: 1.122
[72,     7] loss: 1.084
[73,     7] loss: 1.073
[74,     7] loss: 1.043
[75,     7] loss: 1.054
[76,     7] loss: 1.053
[77,     7] loss: 1.074
[78,     7] loss: 1.056
[79,     7] loss: 1.037
[80,     7] loss: 1.075
[81,     7] loss: 1.072
[82,     7] loss: 1.032
[83,     7] loss: 1.037
[84,     7] loss: 1.029
[85,     7] loss: 1.034
[86,     7] loss: 1.068
[87,     7] loss: 1.058
Early stopping applied (best metric=0.3771352469921112)
Finished Training
Total time taken: 80.95286393165588
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.383
[4,     7] loss: 1.366
[5,     7] loss: 1.335
[6,     7] loss: 1.315
[7,     7] loss: 1.327
[8,     7] loss: 1.303
[9,     7] loss: 1.293
[10,     7] loss: 1.285
[11,     7] loss: 1.281
[12,     7] loss: 1.258
[13,     7] loss: 1.238
[14,     7] loss: 1.262
[15,     7] loss: 1.244
[16,     7] loss: 1.245
[17,     7] loss: 1.234
[18,     7] loss: 1.218
[19,     7] loss: 1.216
[20,     7] loss: 1.224
[21,     7] loss: 1.227
[22,     7] loss: 1.217
[23,     7] loss: 1.206
[24,     7] loss: 1.200
[25,     7] loss: 1.196
[26,     7] loss: 1.189
[27,     7] loss: 1.187
[28,     7] loss: 1.180
[29,     7] loss: 1.197
[30,     7] loss: 1.210
[31,     7] loss: 1.205
[32,     7] loss: 1.178
[33,     7] loss: 1.157
[34,     7] loss: 1.155
[35,     7] loss: 1.147
[36,     7] loss: 1.132
[37,     7] loss: 1.125
[38,     7] loss: 1.132
[39,     7] loss: 1.117
[40,     7] loss: 1.118
[41,     7] loss: 1.134
[42,     7] loss: 1.115
[43,     7] loss: 1.085
[44,     7] loss: 1.087
[45,     7] loss: 1.195
[46,     7] loss: 1.155
[47,     7] loss: 1.117
[48,     7] loss: 1.083
[49,     7] loss: 1.106
[50,     7] loss: 1.083
[51,     7] loss: 1.068
[52,     7] loss: 1.097
[53,     7] loss: 1.133
[54,     7] loss: 1.109
[55,     7] loss: 1.106
[56,     7] loss: 1.058
[57,     7] loss: 1.100
[58,     7] loss: 1.071
[59,     7] loss: 1.094
[60,     7] loss: 1.116
[61,     7] loss: 1.082
[62,     7] loss: 1.067
[63,     7] loss: 1.071
[64,     7] loss: 1.089
[65,     7] loss: 1.123
[66,     7] loss: 1.094
[67,     7] loss: 1.071
[68,     7] loss: 1.102
[69,     7] loss: 1.097
[70,     7] loss: 1.077
[71,     7] loss: 1.038
[72,     7] loss: 1.085
[73,     7] loss: 1.093
[74,     7] loss: 1.103
[75,     7] loss: 1.068
[76,     7] loss: 1.036
[77,     7] loss: 1.078
[78,     7] loss: 1.072
[79,     7] loss: 1.059
[80,     7] loss: 1.046
[81,     7] loss: 1.084
[82,     7] loss: 1.073
[83,     7] loss: 1.047
[84,     7] loss: 1.046
[85,     7] loss: 1.060
[86,     7] loss: 1.064
[87,     7] loss: 1.072
[88,     7] loss: 1.037
[89,     7] loss: 1.107
[90,     7] loss: 1.148
[91,     7] loss: 1.210
[92,     7] loss: 1.156
[93,     7] loss: 1.114
[94,     7] loss: 1.055
[95,     7] loss: 1.017
[96,     7] loss: 1.042
[97,     7] loss: 1.084
[98,     7] loss: 1.060
[99,     7] loss: 1.043
[100,     7] loss: 1.073
[101,     7] loss: 1.057
[102,     7] loss: 1.057
[103,     7] loss: 1.051
[104,     7] loss: 1.127
[105,     7] loss: 1.134
[106,     7] loss: 1.083
[107,     7] loss: 1.040
[108,     7] loss: 1.047
[109,     7] loss: 1.070
[110,     7] loss: 1.069
[111,     7] loss: 1.033
[112,     7] loss: 1.103
[113,     7] loss: 1.063
[114,     7] loss: 1.046
[115,     7] loss: 1.075
[116,     7] loss: 1.082
[117,     7] loss: 1.048
[118,     7] loss: 1.018
[119,     7] loss: 1.102
[120,     7] loss: 1.086
[121,     7] loss: 1.057
[122,     7] loss: 1.051
[123,     7] loss: 1.034
[124,     7] loss: 1.093
[125,     7] loss: 1.072
[126,     7] loss: 1.093
[127,     7] loss: 1.032
[128,     7] loss: 1.016
[129,     7] loss: 1.031
[130,     7] loss: 1.070
[131,     7] loss: 1.087
[132,     7] loss: 1.061
[133,     7] loss: 1.028
[134,     7] loss: 1.060
[135,     7] loss: 1.070
[136,     7] loss: 1.026
[137,     7] loss: 1.061
[138,     7] loss: 1.063
[139,     7] loss: 1.061
[140,     7] loss: 1.069
[141,     7] loss: 1.019
[142,     7] loss: 1.043
[143,     7] loss: 1.070
[144,     7] loss: 1.082
[145,     7] loss: 1.039
[146,     7] loss: 1.057
[147,     7] loss: 1.025
[148,     7] loss: 1.028
[149,     7] loss: 1.029
[150,     7] loss: 1.051
[151,     7] loss: 1.096
[152,     7] loss: 1.061
[153,     7] loss: 1.050
[154,     7] loss: 1.065
[155,     7] loss: 1.027
[156,     7] loss: 1.048
[157,     7] loss: 1.020
[158,     7] loss: 1.051
[159,     7] loss: 1.045
[160,     7] loss: 1.098
[161,     7] loss: 1.065
[162,     7] loss: 1.053
[163,     7] loss: 1.023
[164,     7] loss: 1.029
[165,     7] loss: 1.030
Early stopping applied (best metric=0.3445044755935669)
Finished Training
Total time taken: 156.3112256526947
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.379
[3,     7] loss: 1.340
[4,     7] loss: 1.329
[5,     7] loss: 1.304
[6,     7] loss: 1.297
[7,     7] loss: 1.282
[8,     7] loss: 1.269
[9,     7] loss: 1.270
[10,     7] loss: 1.256
[11,     7] loss: 1.262
[12,     7] loss: 1.251
[13,     7] loss: 1.235
[14,     7] loss: 1.259
[15,     7] loss: 1.254
[16,     7] loss: 1.246
[17,     7] loss: 1.219
[18,     7] loss: 1.213
[19,     7] loss: 1.212
[20,     7] loss: 1.201
[21,     7] loss: 1.185
[22,     7] loss: 1.187
[23,     7] loss: 1.176
[24,     7] loss: 1.174
[25,     7] loss: 1.161
[26,     7] loss: 1.177
[27,     7] loss: 1.160
[28,     7] loss: 1.144
[29,     7] loss: 1.176
[30,     7] loss: 1.156
[31,     7] loss: 1.127
[32,     7] loss: 1.127
[33,     7] loss: 1.132
[34,     7] loss: 1.123
[35,     7] loss: 1.116
[36,     7] loss: 1.106
[37,     7] loss: 1.093
[38,     7] loss: 1.101
[39,     7] loss: 1.103
[40,     7] loss: 1.103
[41,     7] loss: 1.121
[42,     7] loss: 1.075
[43,     7] loss: 1.060
[44,     7] loss: 1.059
[45,     7] loss: 1.099
[46,     7] loss: 1.063
[47,     7] loss: 1.097
[48,     7] loss: 1.117
[49,     7] loss: 1.092
[50,     7] loss: 1.102
[51,     7] loss: 1.080
[52,     7] loss: 1.051
[53,     7] loss: 1.094
[54,     7] loss: 1.080
[55,     7] loss: 1.097
[56,     7] loss: 1.081
[57,     7] loss: 1.060
[58,     7] loss: 1.085
[59,     7] loss: 1.067
[60,     7] loss: 1.075
[61,     7] loss: 1.091
[62,     7] loss: 1.077
[63,     7] loss: 1.117
[64,     7] loss: 1.091
[65,     7] loss: 1.094
[66,     7] loss: 1.094
[67,     7] loss: 1.093
[68,     7] loss: 1.097
[69,     7] loss: 1.101
[70,     7] loss: 1.114
[71,     7] loss: 1.070
[72,     7] loss: 1.058
[73,     7] loss: 1.091
[74,     7] loss: 1.127
[75,     7] loss: 1.095
[76,     7] loss: 1.082
[77,     7] loss: 1.047
[78,     7] loss: 1.054
[79,     7] loss: 1.035
[80,     7] loss: 1.076
[81,     7] loss: 1.124
[82,     7] loss: 1.083
[83,     7] loss: 1.074
[84,     7] loss: 1.083
[85,     7] loss: 1.074
[86,     7] loss: 1.048
[87,     7] loss: 1.042
[88,     7] loss: 1.074
[89,     7] loss: 1.071
[90,     7] loss: 1.056
[91,     7] loss: 1.078
[92,     7] loss: 1.039
[93,     7] loss: 1.109
[94,     7] loss: 1.063
[95,     7] loss: 1.057
[96,     7] loss: 1.085
[97,     7] loss: 1.047
[98,     7] loss: 1.044
[99,     7] loss: 1.088
[100,     7] loss: 1.139
[101,     7] loss: 1.088
[102,     7] loss: 1.069
[103,     7] loss: 1.092
[104,     7] loss: 1.054
[105,     7] loss: 1.055
[106,     7] loss: 1.094
[107,     7] loss: 1.064
[108,     7] loss: 1.071
[109,     7] loss: 1.058
[110,     7] loss: 1.038
[111,     7] loss: 1.065
[112,     7] loss: 1.076
[113,     7] loss: 1.072
[114,     7] loss: 1.045
[115,     7] loss: 1.033
[116,     7] loss: 1.043
[117,     7] loss: 1.044
[118,     7] loss: 1.147
[119,     7] loss: 1.175
[120,     7] loss: 1.122
[121,     7] loss: 1.087
[122,     7] loss: 1.066
[123,     7] loss: 1.063
[124,     7] loss: 1.064
[125,     7] loss: 1.039
[126,     7] loss: 1.035
[127,     7] loss: 1.052
[128,     7] loss: 1.066
[129,     7] loss: 1.024
[130,     7] loss: 1.088
[131,     7] loss: 1.093
[132,     7] loss: 1.062
[133,     7] loss: 1.029
[134,     7] loss: 1.073
[135,     7] loss: 1.082
[136,     7] loss: 1.043
[137,     7] loss: 1.030
[138,     7] loss: 1.084
[139,     7] loss: 1.132
[140,     7] loss: 1.091
[141,     7] loss: 1.096
[142,     7] loss: 1.063
[143,     7] loss: 1.047
[144,     7] loss: 1.053
[145,     7] loss: 1.055
[146,     7] loss: 1.048
[147,     7] loss: 1.048
[148,     7] loss: 1.037
[149,     7] loss: 1.006
[150,     7] loss: 1.032
[151,     7] loss: 1.119
[152,     7] loss: 1.125
[153,     7] loss: 1.077
[154,     7] loss: 1.071
[155,     7] loss: 1.042
[156,     7] loss: 1.016
[157,     7] loss: 1.100
[158,     7] loss: 1.123
[159,     7] loss: 1.110
[160,     7] loss: 1.066
[161,     7] loss: 1.053
[162,     7] loss: 1.028
[163,     7] loss: 1.069
[164,     7] loss: 1.054
[165,     7] loss: 1.052
[166,     7] loss: 1.067
[167,     7] loss: 1.039
[168,     7] loss: 1.074
[169,     7] loss: 1.091
[170,     7] loss: 1.097
[171,     7] loss: 1.076
[172,     7] loss: 1.044
[173,     7] loss: 1.020
[174,     7] loss: 1.018
[175,     7] loss: 1.106
[176,     7] loss: 1.050
[177,     7] loss: 1.086
[178,     7] loss: 1.112
[179,     7] loss: 1.115
[180,     7] loss: 1.067
[181,     7] loss: 1.041
[182,     7] loss: 1.038
[183,     7] loss: 1.037
[184,     7] loss: 1.065
[185,     7] loss: 1.055
[186,     7] loss: 1.048
[187,     7] loss: 1.034
[188,     7] loss: 1.013
[189,     7] loss: 1.025
[190,     7] loss: 1.031
[191,     7] loss: 1.067
[192,     7] loss: 1.077
[193,     7] loss: 1.034
[194,     7] loss: 1.028
[195,     7] loss: 1.082
[196,     7] loss: 1.090
[197,     7] loss: 1.052
[198,     7] loss: 1.041
[199,     7] loss: 1.039
[200,     7] loss: 1.027
Finished Training
Total time taken: 194.85077452659607
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.385
[5,     7] loss: 1.371
[6,     7] loss: 1.344
[7,     7] loss: 1.324
[8,     7] loss: 1.316
[9,     7] loss: 1.309
[10,     7] loss: 1.307
[11,     7] loss: 1.287
[12,     7] loss: 1.284
[13,     7] loss: 1.271
[14,     7] loss: 1.253
[15,     7] loss: 1.244
[16,     7] loss: 1.251
[17,     7] loss: 1.239
[18,     7] loss: 1.233
[19,     7] loss: 1.229
[20,     7] loss: 1.234
[21,     7] loss: 1.217
[22,     7] loss: 1.206
[23,     7] loss: 1.190
[24,     7] loss: 1.184
[25,     7] loss: 1.194
[26,     7] loss: 1.177
[27,     7] loss: 1.166
[28,     7] loss: 1.153
[29,     7] loss: 1.123
[30,     7] loss: 1.131
[31,     7] loss: 1.124
[32,     7] loss: 1.106
[33,     7] loss: 1.119
[34,     7] loss: 1.110
[35,     7] loss: 1.089
[36,     7] loss: 1.126
[37,     7] loss: 1.122
[38,     7] loss: 1.098
[39,     7] loss: 1.097
[40,     7] loss: 1.070
[41,     7] loss: 1.069
[42,     7] loss: 1.119
[43,     7] loss: 1.100
[44,     7] loss: 1.078
[45,     7] loss: 1.069
[46,     7] loss: 1.074
[47,     7] loss: 1.055
[48,     7] loss: 1.066
[49,     7] loss: 1.073
[50,     7] loss: 1.079
[51,     7] loss: 1.075
[52,     7] loss: 1.068
[53,     7] loss: 1.055
[54,     7] loss: 1.083
[55,     7] loss: 1.077
[56,     7] loss: 1.053
[57,     7] loss: 1.081
[58,     7] loss: 1.083
[59,     7] loss: 1.081
[60,     7] loss: 1.049
[61,     7] loss: 1.098
[62,     7] loss: 1.062
[63,     7] loss: 1.056
[64,     7] loss: 1.035
[65,     7] loss: 1.076
[66,     7] loss: 1.066
[67,     7] loss: 1.065
[68,     7] loss: 1.053
[69,     7] loss: 1.044
[70,     7] loss: 1.043
[71,     7] loss: 1.046
[72,     7] loss: 1.046
[73,     7] loss: 1.065
[74,     7] loss: 1.065
[75,     7] loss: 1.060
[76,     7] loss: 1.060
[77,     7] loss: 1.063
[78,     7] loss: 1.029
[79,     7] loss: 1.022
[80,     7] loss: 1.095
[81,     7] loss: 1.108
[82,     7] loss: 1.082
[83,     7] loss: 1.027
[84,     7] loss: 1.036
[85,     7] loss: 1.018
[86,     7] loss: 1.026
[87,     7] loss: 1.066
[88,     7] loss: 1.041
[89,     7] loss: 1.034
[90,     7] loss: 1.032
[91,     7] loss: 1.060
[92,     7] loss: 1.050
[93,     7] loss: 1.065
[94,     7] loss: 1.013
[95,     7] loss: 1.035
[96,     7] loss: 1.091
[97,     7] loss: 1.048
[98,     7] loss: 1.056
[99,     7] loss: 1.048
[100,     7] loss: 1.037
Early stopping applied (best metric=0.43672648072242737)
Finished Training
Total time taken: 91.48680996894836
{'Methylation-R Validation Accuracy': 0.6300222327311458, 'Methylation-R Validation Sensitivity': 0.7959845850902315, 'Methylation-R Validation Specificity': 0.6146748466257669, 'Methylation-R Validation Precision': 0.1672745338051308, 'Methylation-R AUC ROC': 0.7973202561135365, 'Methylation-R AUC PR': 0.35365387436550333, 'Methylation-R MCC': 0.2384397492302919, 'Methylation-R F1': 0.27412348017599564, 'Validation Loss (Methylation-R)': 0.31482542157173155, 'Methylation-K Validation Accuracy': 0.5260874771339688, 'Methylation-K Validation Sensitivity': 0.7712260689047788, 'Methylation-K Validation Specificity': 0.4994982332900654, 'Methylation-K Validation Precision': 0.1451709569289529, 'Methylation-K AUC ROC': 0.7052551985839702, 'Methylation-K AUC PR': 0.20321706748631213, 'Methylation-K MCC': 0.1648467751829179, 'Methylation-K F1': 0.24317558603022849, 'Validation Loss (Methylation-K)': 0.38119451999664306, 'Validation Loss (total)': 0.6960199356079102, 'TimeToTrain': 119.27376341819763}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008008357873252667,
 'learning_rate_Methylation-K': 0.009344690049091208,
 'learning_rate_Methylation-R': 0.008381376288728388,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6742604980674191,
 'loss_weight_Methylation-R': 0.19158512129059035,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1253895213,
 'sample_weights': [0.6947795893944875, 0.6367955750557676],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.868345811093715,
 'weight_decay_Methylation-K': 4.46804731694141,
 'weight_decay_Methylation-R': 8.61802714864436}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022792487164206648,
 'learning_rate_Methylation-K': 0.004630429117314606,
 'learning_rate_Methylation-R': 0.005422133919775385,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.31426260308544707,
 'loss_weight_Methylation-R': 0.8313509568168902,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 655312595,
 'sample_weights': [0.19158512129059035, 0.6742604980674191],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.844741383766092,
 'weight_decay_Methylation-K': 4.023977635003591,
 'weight_decay_Methylation-R': 8.407965988831105}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.378
[3,     7] loss: 1.347
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006803598394311419,
 'learning_rate_Methylation-K': 0.0007522666827156896,
 'learning_rate_Methylation-R': 0.009336799324754392,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8353427702111638,
 'loss_weight_Methylation-R': 0.16745734276251617,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 352058390,
 'sample_weights': [0.8313509568168902, 0.31426260308544707],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.9016797231146176,
 'weight_decay_Methylation-K': 0.28864792776706283,
 'weight_decay_Methylation-R': 2.09898417794941}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.382
[9,     7] loss: 1.347
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008213410958645893,
 'learning_rate_Methylation-K': 0.005605780684205433,
 'learning_rate_Methylation-R': 0.00012395439121915225,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8838458980784214,
 'loss_weight_Methylation-R': 0.0699970852913297,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4268374107,
 'sample_weights': [0.16745734276251617, 0.8353427702111638],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.798554933638925,
 'weight_decay_Methylation-K': 2.957708755519187,
 'weight_decay_Methylation-R': 2.6672727932092313}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.396
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.387
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.387
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.387
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.387
[37,     7] loss: 1.387
[38,     7] loss: 1.386
[39,     7] loss: 1.387
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.387
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.44194531440734863)
Finished Training
Total time taken: 46.31673765182495
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.388
[3,     7] loss: 1.387
[4,     7] loss: 1.385
[5,     7] loss: 1.350
[6,     7] loss: 1.337
[7,     7] loss: 1.325
[8,     7] loss: 1.307
[9,     7] loss: 1.308
[10,     7] loss: 1.342
[11,     7] loss: 1.302
[12,     7] loss: 1.282
[13,     7] loss: 1.287
[14,     7] loss: 1.258
[15,     7] loss: 1.327
[16,     7] loss: 1.394
[17,     7] loss: 1.361
[18,     7] loss: 1.331
[19,     7] loss: 1.335
[20,     7] loss: 1.317
[21,     7] loss: 1.330
[22,     7] loss: 1.380
[23,     7] loss: 1.387
[24,     7] loss: 1.380
[25,     7] loss: 1.356
[26,     7] loss: 1.355
[27,     7] loss: 1.332
[28,     7] loss: 1.317
[29,     7] loss: 1.338
[30,     7] loss: 1.311
[31,     7] loss: 1.320
[32,     7] loss: 1.296
[33,     7] loss: 1.299
[34,     7] loss: 1.316
[35,     7] loss: 1.356
[36,     7] loss: 1.396
[37,     7] loss: 1.389
[38,     7] loss: 1.386
[39,     7] loss: 1.387
[40,     7] loss: 1.385
[41,     7] loss: 1.383
[42,     7] loss: 1.369
[43,     7] loss: 1.355
[44,     7] loss: 1.340
[45,     7] loss: 1.316
[46,     7] loss: 1.307
[47,     7] loss: 1.297
[48,     7] loss: 1.292
[49,     7] loss: 1.298
[50,     7] loss: 1.398
[51,     7] loss: 1.389
[52,     7] loss: 1.388
[53,     7] loss: 1.387
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.383
[64,     7] loss: 1.373
Early stopping applied (best metric=0.4259677231311798)
Finished Training
Total time taken: 60.51557993888855
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.383
[2,     7] loss: 1.373
[3,     7] loss: 1.334
[4,     7] loss: 1.314
[5,     7] loss: 1.312
[6,     7] loss: 1.321
[7,     7] loss: 1.308
[8,     7] loss: 1.331
[9,     7] loss: 1.370
[10,     7] loss: 1.378
[11,     7] loss: 1.363
[12,     7] loss: 1.348
[13,     7] loss: 1.333
[14,     7] loss: 1.310
[15,     7] loss: 1.406
[16,     7] loss: 1.387
[17,     7] loss: 1.387
[18,     7] loss: 1.386
[19,     7] loss: 1.387
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.387
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
Early stopping applied (best metric=0.4279524087905884)
Finished Training
Total time taken: 51.4431414604187
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.384
[5,     7] loss: 1.358
[6,     7] loss: 1.345
[7,     7] loss: 1.333
[8,     7] loss: 1.350
[9,     7] loss: 1.331
[10,     7] loss: 1.322
[11,     7] loss: 1.337
[12,     7] loss: 1.363
[13,     7] loss: 1.330
[14,     7] loss: 1.312
[15,     7] loss: 1.300
[16,     7] loss: 1.365
[17,     7] loss: 1.351
[18,     7] loss: 1.346
[19,     7] loss: 1.326
[20,     7] loss: 1.304
[21,     7] loss: 1.327
[22,     7] loss: 1.299
[23,     7] loss: 1.292
[24,     7] loss: 1.280
[25,     7] loss: 1.306
[26,     7] loss: 1.304
[27,     7] loss: 1.301
[28,     7] loss: 1.315
[29,     7] loss: 1.294
[30,     7] loss: 1.291
[31,     7] loss: 1.286
[32,     7] loss: 1.334
[33,     7] loss: 1.311
[34,     7] loss: 1.296
[35,     7] loss: 1.320
[36,     7] loss: 1.289
[37,     7] loss: 1.288
[38,     7] loss: 1.316
[39,     7] loss: 1.291
[40,     7] loss: 1.306
[41,     7] loss: 1.321
[42,     7] loss: 1.370
[43,     7] loss: 1.354
[44,     7] loss: 1.335
[45,     7] loss: 1.320
[46,     7] loss: 1.315
[47,     7] loss: 1.299
[48,     7] loss: 1.305
[49,     7] loss: 1.364
[50,     7] loss: 1.351
[51,     7] loss: 1.346
[52,     7] loss: 1.380
[53,     7] loss: 1.380
[54,     7] loss: 1.333
[55,     7] loss: 1.356
[56,     7] loss: 1.331
[57,     7] loss: 1.312
[58,     7] loss: 1.320
[59,     7] loss: 1.365
[60,     7] loss: 1.322
[61,     7] loss: 1.306
[62,     7] loss: 1.289
[63,     7] loss: 1.291
[64,     7] loss: 1.281
[65,     7] loss: 1.291
[66,     7] loss: 1.297
[67,     7] loss: 1.283
[68,     7] loss: 1.284
[69,     7] loss: 1.302
[70,     7] loss: 1.308
[71,     7] loss: 1.308
[72,     7] loss: 1.288
[73,     7] loss: 1.293
[74,     7] loss: 1.289
[75,     7] loss: 1.362
[76,     7] loss: 1.386
[77,     7] loss: 1.385
[78,     7] loss: 1.383
[79,     7] loss: 1.372
[80,     7] loss: 1.375
[81,     7] loss: 1.371
[82,     7] loss: 1.364
[83,     7] loss: 1.357
[84,     7] loss: 1.362
[85,     7] loss: 1.368
[86,     7] loss: 1.358
[87,     7] loss: 1.341
[88,     7] loss: 1.349
[89,     7] loss: 1.341
[90,     7] loss: 1.335
[91,     7] loss: 1.324
[92,     7] loss: 1.376
[93,     7] loss: 1.394
[94,     7] loss: 1.389
[95,     7] loss: 1.387
[96,     7] loss: 1.387
[97,     7] loss: 1.387
[98,     7] loss: 1.387
[99,     7] loss: 1.386
[100,     7] loss: 1.386
[101,     7] loss: 1.386
[102,     7] loss: 1.386
[103,     7] loss: 1.386
[104,     7] loss: 1.386
[105,     7] loss: 1.386
[106,     7] loss: 1.386
[107,     7] loss: 1.387
[108,     7] loss: 1.386
[109,     7] loss: 1.386
[110,     7] loss: 1.386
[111,     7] loss: 1.386
[112,     7] loss: 1.386
[113,     7] loss: 1.386
[114,     7] loss: 1.386
[115,     7] loss: 1.386
[116,     7] loss: 1.386
[117,     7] loss: 1.386
[118,     7] loss: 1.386
[119,     7] loss: 1.386
[120,     7] loss: 1.386
[121,     7] loss: 1.386
[122,     7] loss: 1.386
[123,     7] loss: 1.386
[124,     7] loss: 1.386
[125,     7] loss: 1.387
[126,     7] loss: 1.386
[127,     7] loss: 1.386
[128,     7] loss: 1.386
[129,     7] loss: 1.386
[130,     7] loss: 1.386
[131,     7] loss: 1.386
[132,     7] loss: 1.386
[133,     7] loss: 1.386
[134,     7] loss: 1.386
[135,     7] loss: 1.386
[136,     7] loss: 1.386
[137,     7] loss: 1.386
[138,     7] loss: 1.386
[139,     7] loss: 1.386
[140,     7] loss: 1.386
[141,     7] loss: 1.386
[142,     7] loss: 1.386
Early stopping applied (best metric=0.4213920831680298)
Finished Training
Total time taken: 130.58797669410706
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.368
[4,     7] loss: 1.341
[5,     7] loss: 1.330
[6,     7] loss: 1.316
[7,     7] loss: 1.324
[8,     7] loss: 1.373
[9,     7] loss: 1.373
[10,     7] loss: 1.364
[11,     7] loss: 1.346
[12,     7] loss: 1.321
[13,     7] loss: 1.342
[14,     7] loss: 1.378
[15,     7] loss: 1.384
[16,     7] loss: 1.379
[17,     7] loss: 1.355
[18,     7] loss: 1.342
[19,     7] loss: 1.317
[20,     7] loss: 1.297
[21,     7] loss: 1.307
[22,     7] loss: 1.289
[23,     7] loss: 1.283
[24,     7] loss: 1.307
[25,     7] loss: 1.356
[26,     7] loss: 1.334
[27,     7] loss: 1.330
[28,     7] loss: 1.297
[29,     7] loss: 1.318
[30,     7] loss: 1.335
[31,     7] loss: 1.316
[32,     7] loss: 1.308
[33,     7] loss: 1.306
[34,     7] loss: 1.309
[35,     7] loss: 1.309
[36,     7] loss: 1.294
[37,     7] loss: 1.357
[38,     7] loss: 1.325
[39,     7] loss: 1.315
[40,     7] loss: 1.298
[41,     7] loss: 1.295
[42,     7] loss: 1.328
[43,     7] loss: 1.335
[44,     7] loss: 1.306
[45,     7] loss: 1.320
[46,     7] loss: 1.330
[47,     7] loss: 1.323
[48,     7] loss: 1.309
[49,     7] loss: 1.343
[50,     7] loss: 1.350
[51,     7] loss: 1.381
[52,     7] loss: 1.379
Early stopping applied (best metric=0.43038931488990784)
Finished Training
Total time taken: 46.8806893825531
{'Methylation-R Validation Accuracy': 0.127360390346632, 'Methylation-R Validation Sensitivity': 0.9883289124668435, 'Methylation-R Validation Specificity': 0.04773006134969325, 'Methylation-R Validation Precision': 0.08803395416388232, 'Methylation-R AUC ROC': 0.6490377056808323, 'Methylation-R AUC PR': 0.28764583653590803, 'Methylation-R MCC': 0.03011241886993003, 'Methylation-R F1': 0.16157755269099394, 'Validation Loss (Methylation-R)': 0.38578317165374754, 'Methylation-K Validation Accuracy': 0.14948159071662842, 'Methylation-K Validation Sensitivity': 0.9467098166127292, 'Methylation-K Validation Specificity': 0.06302363678914112, 'Methylation-K Validation Precision': 0.09898886594598236, 'Methylation-K AUC ROC': 0.5020995623874076, 'Methylation-K AUC PR': 0.15938705569162473, 'Methylation-K MCC': 0.006763222310517182, 'Methylation-K F1': 0.17903090512736514, 'Validation Loss (Methylation-K)': 0.4295293688774109, 'Validation Loss (total)': 0.8153125405311584, 'TimeToTrain': 67.14882502555847}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006372137193124812,
 'learning_rate_Methylation-K': 0.005407402829209765,
 'learning_rate_Methylation-R': 0.0035564473638767954,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.31606710296958707,
 'loss_weight_Methylation-R': 0.33474128639125555,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1002321488,
 'sample_weights': [0.0699970852913297, 0.8838458980784214],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.6496504682637187,
 'weight_decay_Methylation-K': 9.13294811274249,
 'weight_decay_Methylation-R': 4.624543402997907}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008467157838801719,
 'learning_rate_Methylation-K': 0.003171894197324395,
 'learning_rate_Methylation-R': 0.009604679527821484,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7254673449932174,
 'loss_weight_Methylation-R': 0.5527244160163485,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1999580715,
 'sample_weights': [0.33474128639125555, 0.31606710296958707],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.964587313887516,
 'weight_decay_Methylation-K': 4.628471564031185,
 'weight_decay_Methylation-R': 0.3787567818758386}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.388
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.383
[8,     7] loss: 1.367
[9,     7] loss: 1.349
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0039020541980741737,
 'learning_rate_Methylation-K': 0.0001683021242931172,
 'learning_rate_Methylation-R': 0.009106554854416485,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5477064432873096,
 'loss_weight_Methylation-R': 0.2758822820651144,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1804181337,
 'sample_weights': [0.5527244160163485, 0.7254673449932174],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7416615108921951,
 'weight_decay_Methylation-K': 4.47971231627338,
 'weight_decay_Methylation-R': 6.628881738704823}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006237350695326115,
 'learning_rate_Methylation-K': 0.008288649956983384,
 'learning_rate_Methylation-R': 0.0015437727877031762,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8130104059938382,
 'loss_weight_Methylation-R': 0.8493159541614159,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1001083996,
 'sample_weights': [0.2758822820651144, 0.5477064432873096],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.971441071417031,
 'weight_decay_Methylation-K': 7.65326474156999,
 'weight_decay_Methylation-R': 9.969958846713487}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.384
[3,     7] loss: 1.376
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007528463132899777,
 'learning_rate_Methylation-K': 0.0067015289477875654,
 'learning_rate_Methylation-R': 0.003679791184418896,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.798987358581988,
 'loss_weight_Methylation-R': 0.9722695252726408,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1937805314,
 'sample_weights': [0.8493159541614159, 0.8130104059938382],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.974706078767584,
 'weight_decay_Methylation-K': 8.62009652327905,
 'weight_decay_Methylation-R': 9.972948235395268}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008561002670596866,
 'learning_rate_Methylation-K': 0.004764747026670825,
 'learning_rate_Methylation-R': 0.0008384870744513517,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6828005112512219,
 'loss_weight_Methylation-R': 0.005011969832160151,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4146252620,
 'sample_weights': [0.9722695252726408, 0.798987358581988],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.839347344361701,
 'weight_decay_Methylation-K': 1.044395014936366,
 'weight_decay_Methylation-R': 2.4052091235733046}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006973257715920417,
 'learning_rate_Methylation-K': 0.006146225569325564,
 'learning_rate_Methylation-R': 0.008382570185338369,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8774115705153342,
 'loss_weight_Methylation-R': 0.3461346140567997,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 839080338,
 'sample_weights': [0.005011969832160151, 0.6828005112512219],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.794682352635582,
 'weight_decay_Methylation-K': 7.52803557289856,
 'weight_decay_Methylation-R': 6.641937147780003}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.376
[9,     7] loss: 1.336
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00928773361007125,
 'learning_rate_Methylation-K': 0.0012616875868500118,
 'learning_rate_Methylation-R': 0.005918419523942821,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3754189621618999,
 'loss_weight_Methylation-R': 0.8944080646966481,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3372194830,
 'sample_weights': [0.3461346140567997, 0.8774115705153342],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.250869194742107,
 'weight_decay_Methylation-K': 3.1767127609762666,
 'weight_decay_Methylation-R': 4.882773160800804}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.365
[6,     7] loss: 1.339
[7,     7] loss: 1.314
[8,     7] loss: 1.303
[9,     7] loss: 1.294
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004657567472933811,
 'learning_rate_Methylation-K': 0.005151335231496698,
 'learning_rate_Methylation-R': 0.009161042795664806,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9643905250230664,
 'loss_weight_Methylation-R': 0.8277345820733226,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1362204976,
 'sample_weights': [0.8944080646966481, 0.3754189621618999],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.4385846958401705,
 'weight_decay_Methylation-K': 5.7281693838506795,
 'weight_decay_Methylation-R': 8.017020916595152}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009789247080779207,
 'learning_rate_Methylation-K': 0.0005706403571305572,
 'learning_rate_Methylation-R': 0.00938590985320362,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07482869901807646,
 'loss_weight_Methylation-R': 0.8010244027779875,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1398316186,
 'sample_weights': [0.8277345820733226, 0.9643905250230664],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.842492091833272,
 'weight_decay_Methylation-K': 6.899450825162318,
 'weight_decay_Methylation-R': 8.53572644952314}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.388
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.387
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.387
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.387
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.387
[66,     7] loss: 1.386
[67,     7] loss: 1.386
Early stopping applied (best metric=0.4463687539100647)
Finished Training
Total time taken: 62.646286487579346
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.370
[9,     7] loss: 1.359
[10,     7] loss: 1.325
[11,     7] loss: 1.362
[12,     7] loss: 1.386
[13,     7] loss: 1.387
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.385
[17,     7] loss: 1.377
[18,     7] loss: 1.389
[19,     7] loss: 1.387
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.387
[36,     7] loss: 1.386
[37,     7] loss: 1.387
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
Early stopping applied (best metric=0.4432525634765625)
Finished Training
Total time taken: 51.90748882293701
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.387
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.386
Early stopping applied (best metric=0.4457986652851105)
Finished Training
Total time taken: 79.57620930671692
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.387
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
Early stopping applied (best metric=0.44482478499412537)
Finished Training
Total time taken: 63.76063060760498
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.385
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.378
[5,     7] loss: 1.346
[6,     7] loss: 1.337
[7,     7] loss: 1.323
[8,     7] loss: 1.335
[9,     7] loss: 1.312
[10,     7] loss: 1.294
[11,     7] loss: 1.338
[12,     7] loss: 1.362
[13,     7] loss: 1.329
[14,     7] loss: 1.320
[15,     7] loss: 1.308
[16,     7] loss: 1.305
[17,     7] loss: 1.297
[18,     7] loss: 1.297
[19,     7] loss: 1.306
[20,     7] loss: 1.311
[21,     7] loss: 1.305
[22,     7] loss: 1.295
[23,     7] loss: 1.279
[24,     7] loss: 1.283
[25,     7] loss: 1.324
[26,     7] loss: 1.285
[27,     7] loss: 1.352
[28,     7] loss: 1.382
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.43673986196517944)
Finished Training
Total time taken: 48.512269020080566
{'Methylation-R Validation Accuracy': 0.08466048019389166, 'Methylation-R Validation Sensitivity': 1.0, 'Methylation-R Validation Specificity': 0.0, 'Methylation-R Validation Precision': 0.08466048019389166, 'Methylation-R AUC ROC': 0.5720305203275468, 'Methylation-R AUC PR': 0.4161920862863581, 'Methylation-R MCC': 0.0, 'Methylation-R F1': 0.15610503065657413, 'Validation Loss (Methylation-R)': 0.42890735268592833, 'Methylation-K Validation Accuracy': 0.09784008327442427, 'Methylation-K Validation Sensitivity': 1.0, 'Methylation-K Validation Specificity': 0.0, 'Methylation-K Validation Precision': 0.09784008327442427, 'Methylation-K AUC ROC': 0.49447280530022697, 'Methylation-K AUC PR': 0.3675316707824737, 'Methylation-K MCC': 0.0, 'Methylation-K F1': 0.17824104586382167, 'Validation Loss (Methylation-K)': 0.4433969259262085, 'Validation Loss (total)': 0.8723042726516723, 'TimeToTrain': 61.28057684898376}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006823868351227543,
 'learning_rate_Methylation-K': 1.4356230320225222e-05,
 'learning_rate_Methylation-R': 0.005837943947626345,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.03289918973994891,
 'loss_weight_Methylation-R': 0.8972424620897284,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1174737076,
 'sample_weights': [0.8010244027779875, 0.07482869901807646],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.096336685288751,
 'weight_decay_Methylation-K': 7.4686777155116255,
 'weight_decay_Methylation-R': 5.9344538413623615}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.371
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008501611871157376,
 'learning_rate_Methylation-K': 0.00494131541228753,
 'learning_rate_Methylation-R': 0.0040176266597439034,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.10980979746307024,
 'loss_weight_Methylation-R': 0.9299486070194954,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3529605855,
 'sample_weights': [0.8972424620897284, 0.03289918973994891],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8542729456255147,
 'weight_decay_Methylation-K': 5.782665394900519,
 'weight_decay_Methylation-R': 5.369414196761998}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00810763081579377,
 'learning_rate_Methylation-K': 0.0005706853475528003,
 'learning_rate_Methylation-R': 0.00964263799600172,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3061792978773219,
 'loss_weight_Methylation-R': 0.9444276732636891,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1521934587,
 'sample_weights': [0.9299486070194954, 0.10980979746307024],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2430417868755006,
 'weight_decay_Methylation-K': 7.536142825419157,
 'weight_decay_Methylation-R': 6.6549657762967085}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.383
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.387
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003435822386474223,
 'learning_rate_Methylation-K': 0.0045364318691427895,
 'learning_rate_Methylation-R': 0.00524939727404032,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2631683390834751,
 'loss_weight_Methylation-R': 0.012270661911169668,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 225518743,
 'sample_weights': [0.9444276732636891, 0.3061792978773219],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.157182733563207,
 'weight_decay_Methylation-K': 6.2881665741269375,
 'weight_decay_Methylation-R': 8.999740946911508}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.376
[3,     7] loss: 1.342
[4,     7] loss: 1.331
[5,     7] loss: 1.324
[6,     7] loss: 1.300
[7,     7] loss: 1.272
[8,     7] loss: 1.261
[9,     7] loss: 1.244
[10,     7] loss: 1.216
[11,     7] loss: 1.228
[12,     7] loss: 1.220
[13,     7] loss: 1.205
[14,     7] loss: 1.200
[15,     7] loss: 1.197
[16,     7] loss: 1.191
[17,     7] loss: 1.177
[18,     7] loss: 1.186
[19,     7] loss: 1.171
[20,     7] loss: 1.166
[21,     7] loss: 1.289
[22,     7] loss: 1.260
[23,     7] loss: 1.227
[24,     7] loss: 1.221
[25,     7] loss: 1.208
[26,     7] loss: 1.179
[27,     7] loss: 1.198
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008947775217872078,
 'learning_rate_Methylation-K': 0.0007885579065587555,
 'learning_rate_Methylation-R': 0.00802533249934577,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.22200741084183853,
 'loss_weight_Methylation-R': 0.3764095692948234,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 912041752,
 'sample_weights': [0.012270661911169668, 0.2631683390834751],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.421093162537769,
 'weight_decay_Methylation-K': 7.7459651854701,
 'weight_decay_Methylation-R': 8.872210795512283}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.387
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.387
[88,     7] loss: 1.386
[89,     7] loss: 1.386
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
[95,     7] loss: 1.386
[96,     7] loss: 1.386
[97,     7] loss: 1.386
[98,     7] loss: 1.386
[99,     7] loss: 1.386
[100,     7] loss: 1.386
[101,     7] loss: 1.386
[102,     7] loss: 1.386
[103,     7] loss: 1.386
[104,     7] loss: 1.386
[105,     7] loss: 1.386
[106,     7] loss: 1.386
[107,     7] loss: 1.386
[108,     7] loss: 1.386
[109,     7] loss: 1.386
[110,     7] loss: 1.386
[111,     7] loss: 1.386
[112,     7] loss: 1.386
[113,     7] loss: 1.386
[114,     7] loss: 1.386
[115,     7] loss: 1.386
[116,     7] loss: 1.386
[117,     7] loss: 1.386
[118,     7] loss: 1.386
[119,     7] loss: 1.386
[120,     7] loss: 1.386
[121,     7] loss: 1.386
[122,     7] loss: 1.386
[123,     7] loss: 1.386
[124,     7] loss: 1.386
[125,     7] loss: 1.386
[126,     7] loss: 1.386
[127,     7] loss: 1.386
[128,     7] loss: 1.386
[129,     7] loss: 1.386
[130,     7] loss: 1.386
[131,     7] loss: 1.386
[132,     7] loss: 1.386
[133,     7] loss: 1.386
Early stopping applied (best metric=0.445253849029541)
Finished Training
Total time taken: 123.18717312812805
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
Early stopping applied (best metric=0.4457709491252899)
Finished Training
Total time taken: 52.44680118560791
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.386
[3,     7] loss: 1.385
[4,     7] loss: 1.360
[5,     7] loss: 1.339
[6,     7] loss: 1.328
[7,     7] loss: 1.326
[8,     7] loss: 1.321
[9,     7] loss: 1.299
[10,     7] loss: 1.297
[11,     7] loss: 1.326
[12,     7] loss: 1.300
[13,     7] loss: 1.302
[14,     7] loss: 1.280
[15,     7] loss: 1.320
[16,     7] loss: 1.339
[17,     7] loss: 1.325
[18,     7] loss: 1.318
[19,     7] loss: 1.301
[20,     7] loss: 1.312
[21,     7] loss: 1.388
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
Early stopping applied (best metric=0.4414968192577362)
Finished Training
Total time taken: 60.16070795059204
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.44384926557540894)
Finished Training
Total time taken: 49.03603649139404
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.358
[6,     7] loss: 1.337
[7,     7] loss: 1.327
[8,     7] loss: 1.308
[9,     7] loss: 1.329
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.379
[15,     7] loss: 1.384
[16,     7] loss: 1.380
[17,     7] loss: 1.382
[18,     7] loss: 1.387
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
Early stopping applied (best metric=0.43736472725868225)
Finished Training
Total time taken: 60.67249798774719
{'Methylation-R Validation Accuracy': 0.18856883598903992, 'Methylation-R Validation Sensitivity': 0.9541114058355438, 'Methylation-R Validation Specificity': 0.11776687116564417, 'Methylation-R Validation Precision': 0.09727666238914448, 'Methylation-R AUC ROC': 0.6246064738134572, 'Methylation-R AUC PR': 0.2760781828136751, 'Methylation-R MCC': 0.04029858720179844, 'Methylation-R F1': 0.17447157006004127, 'Validation Loss (Methylation-R)': 0.39882235527038573, 'Methylation-K Validation Accuracy': 0.20433221881754682, 'Methylation-K Validation Sensitivity': 0.8651564185544768, 'Methylation-K Validation Specificity': 0.13267025509010064, 'Methylation-K Validation Precision': 0.09726835521912151, 'Methylation-K AUC ROC': 0.48355324520191784, 'Methylation-K AUC PR': 0.18367322707859524, 'Methylation-K MCC': -0.0013675324003883296, 'Methylation-K F1': 0.1720075601581002, 'Validation Loss (Methylation-K)': 0.44274712204933164, 'Validation Loss (total)': 0.8415694832801819, 'TimeToTrain': 69.10064334869385}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007647163963658323,
 'learning_rate_Methylation-K': 0.0006342697002440841,
 'learning_rate_Methylation-R': 0.007397977886299897,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.31237874360653145,
 'loss_weight_Methylation-R': 0.03765965115863851,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3895242785,
 'sample_weights': [0.3764095692948234, 0.22200741084183853],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.60264352545309,
 'weight_decay_Methylation-K': 9.10423008458683,
 'weight_decay_Methylation-R': 8.520060279690577}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017012009655518819,
 'learning_rate_Methylation-K': 0.004109211197055633,
 'learning_rate_Methylation-R': 0.006530546718770886,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7811636490188163,
 'loss_weight_Methylation-R': 0.24546679815446165,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2813906360,
 'sample_weights': [0.03765965115863851, 0.31237874360653145],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.010811447955252351,
 'weight_decay_Methylation-K': 6.799962857000926,
 'weight_decay_Methylation-R': 0.8696051872581179}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.382
[3,     7] loss: 1.362
[4,     7] loss: 1.328
[5,     7] loss: 1.322
[6,     7] loss: 1.319
[7,     7] loss: 1.308
[8,     7] loss: 1.291
[9,     7] loss: 1.289
[10,     7] loss: 1.289
[11,     7] loss: 1.274
[12,     7] loss: 1.268
[13,     7] loss: 1.251
[14,     7] loss: 1.264
[15,     7] loss: 1.253
[16,     7] loss: 1.241
[17,     7] loss: 1.220
[18,     7] loss: 1.207
[19,     7] loss: 1.177
[20,     7] loss: 1.191
[21,     7] loss: 1.168
[22,     7] loss: 1.183
[23,     7] loss: 1.174
[24,     7] loss: 1.160
[25,     7] loss: 1.150
[26,     7] loss: 1.156
[27,     7] loss: 1.149
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008992228189032489,
 'learning_rate_Methylation-K': 0.009585192167311364,
 'learning_rate_Methylation-R': 0.0011516663888017332,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7421916040439422,
 'loss_weight_Methylation-R': 0.36210497438122213,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 272926254,
 'sample_weights': [0.24546679815446165, 0.7811636490188163],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.45745801365864,
 'weight_decay_Methylation-K': 4.634393813497144,
 'weight_decay_Methylation-R': 4.488263429522511}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007638182554085365,
 'learning_rate_Methylation-K': 0.0022340250886322896,
 'learning_rate_Methylation-R': 0.00010650372812766196,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6682203314537047,
 'loss_weight_Methylation-R': 0.24107831333318605,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3629803160,
 'sample_weights': [0.36210497438122213, 0.7421916040439422],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.996423033429556,
 'weight_decay_Methylation-K': 2.8863044213524667,
 'weight_decay_Methylation-R': 8.144417788498147}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.373
[7,     7] loss: 1.381
[8,     7] loss: 1.354
[9,     7] loss: 1.325
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006784315433975948,
 'learning_rate_Methylation-K': 0.0026790340215959428,
 'learning_rate_Methylation-R': 0.0008962301315628522,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.004641036762722622,
 'loss_weight_Methylation-R': 0.5252995021831482,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 32667835,
 'sample_weights': [0.24107831333318605, 0.6682203314537047],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.451509659406144,
 'weight_decay_Methylation-K': 6.687966951413918,
 'weight_decay_Methylation-R': 7.315112549913218}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008991190188267733,
 'learning_rate_Methylation-K': 0.006097277337461837,
 'learning_rate_Methylation-R': 0.0063948834931824615,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.018797566137223595,
 'loss_weight_Methylation-R': 0.9877048082307303,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1395112733,
 'sample_weights': [0.5252995021831482, 0.004641036762722622],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.580569858790902,
 'weight_decay_Methylation-K': 2.5933657651932,
 'weight_decay_Methylation-R': 8.945272327036697}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.372
[8,     7] loss: 1.351
[9,     7] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009649991773129193,
 'learning_rate_Methylation-K': 0.0023677167069694706,
 'learning_rate_Methylation-R': 0.0023634878447025974,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2733085950485434,
 'loss_weight_Methylation-R': 0.9660796387228546,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 631907737,
 'sample_weights': [0.9877048082307303, 0.018797566137223595],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.970038913740787,
 'weight_decay_Methylation-K': 7.223037389273564,
 'weight_decay_Methylation-R': 0.7257476094666178}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.364
[6,     7] loss: 1.345
[7,     7] loss: 1.337
[8,     7] loss: 1.321
[9,     7] loss: 1.320
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0077656626364756565,
 'learning_rate_Methylation-K': 0.0018387517806048984,
 'learning_rate_Methylation-R': 0.005126970293334223,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3690033264931678,
 'loss_weight_Methylation-R': 0.41944953014700936,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1852900491,
 'sample_weights': [0.9660796387228546, 0.2733085950485434],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.1510196000849575,
 'weight_decay_Methylation-K': 8.890924512132202,
 'weight_decay_Methylation-R': 8.138180610755967}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009281244243366037,
 'learning_rate_Methylation-K': 0.000987187516675957,
 'learning_rate_Methylation-R': 0.008635826876157248,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2069041618427176,
 'loss_weight_Methylation-R': 0.8571143818130781,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2318992282,
 'sample_weights': [0.41944953014700936, 0.3690033264931678],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.93851904830879,
 'weight_decay_Methylation-K': 6.768974651680069,
 'weight_decay_Methylation-R': 8.213576964965037}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.377
[7,     7] loss: 1.351
[8,     7] loss: 1.338
[9,     7] loss: 1.319
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009934400156354314,
 'learning_rate_Methylation-K': 0.00013182323141942387,
 'learning_rate_Methylation-R': 0.00882604971223332,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.11039207111497407,
 'loss_weight_Methylation-R': 0.46453419173473404,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3786952397,
 'sample_weights': [0.8571143818130781, 0.2069041618427176],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.613386600293899,
 'weight_decay_Methylation-K': 8.086334650492086,
 'weight_decay_Methylation-R': 7.904215683697124}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.387
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004938355020517512,
 'learning_rate_Methylation-K': 0.009304871826206733,
 'learning_rate_Methylation-R': 0.008103441310092916,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3258532345256084,
 'loss_weight_Methylation-R': 0.9161988192134217,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1167006425,
 'sample_weights': [0.46453419173473404, 0.11039207111497407],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.0498035052021748,
 'weight_decay_Methylation-K': 6.4514717276517395,
 'weight_decay_Methylation-R': 7.241427016201335}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009058263143946319,
 'learning_rate_Methylation-K': 0.006028357892935236,
 'learning_rate_Methylation-R': 0.008869863161826993,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5379371040223148,
 'loss_weight_Methylation-R': 0.7510298986670417,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 683636628,
 'sample_weights': [0.9161988192134217, 0.3258532345256084],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1501541447461534,
 'weight_decay_Methylation-K': 6.602231596927692,
 'weight_decay_Methylation-R': 5.291668449719731}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.380
[12,     7] loss: 1.366
[13,     7] loss: 1.336
[14,     7] loss: 1.320
[15,     7] loss: 1.315
[16,     7] loss: 1.305
[17,     7] loss: 1.299
[18,     7] loss: 1.264
[19,     7] loss: 1.258
[20,     7] loss: 1.287
[21,     7] loss: 1.268
[22,     7] loss: 1.275
[23,     7] loss: 1.261
[24,     7] loss: 1.245
[25,     7] loss: 1.262
[26,     7] loss: 1.270
[27,     7] loss: 1.263
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004288111846412816,
 'learning_rate_Methylation-K': 0.0042048271537141356,
 'learning_rate_Methylation-R': 0.0014549975875564423,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7866554670156173,
 'loss_weight_Methylation-R': 0.15578983477843644,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3388991471,
 'sample_weights': [0.7510298986670417, 0.5379371040223148],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.829834804571035,
 'weight_decay_Methylation-K': 7.47378063976706,
 'weight_decay_Methylation-R': 4.421003498515672}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.397
[2,     7] loss: 1.386
[3,     7] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009598755812347058,
 'learning_rate_Methylation-K': 0.002511423626292811,
 'learning_rate_Methylation-R': 0.0016644902697762376,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.010598673861920212,
 'loss_weight_Methylation-R': 0.9965522559957748,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 283551894,
 'sample_weights': [0.15578983477843644, 0.7866554670156173],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.655423585888221,
 'weight_decay_Methylation-K': 4.210808289843294,
 'weight_decay_Methylation-R': 4.679999178645865}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.375
[6,     7] loss: 1.340
[7,     7] loss: 1.329
[8,     7] loss: 1.308
[9,     7] loss: 1.317
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007761913113081622,
 'learning_rate_Methylation-K': 0.002258139566295714,
 'learning_rate_Methylation-R': 0.00973610781674533,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.0792352448185935,
 'loss_weight_Methylation-R': 0.4744973396322825,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2369207415,
 'sample_weights': [0.9965522559957748, 0.010598673861920212],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.404276501380957,
 'weight_decay_Methylation-K': 5.278199378049731,
 'weight_decay_Methylation-R': 6.904738024510359}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009829998832781794,
 'learning_rate_Methylation-K': 0.004610926113726521,
 'learning_rate_Methylation-R': 0.006010924346063292,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.23353232987988698,
 'loss_weight_Methylation-R': 0.8071196239697194,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2482194085,
 'sample_weights': [0.4744973396322825, 0.0792352448185935],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.105481480519966,
 'weight_decay_Methylation-K': 6.273047972775095,
 'weight_decay_Methylation-R': 7.8851117520312775}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.381
[9,     7] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0068676200435237485,
 'learning_rate_Methylation-K': 7.401963039794081e-05,
 'learning_rate_Methylation-R': 0.009438720362538547,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.21519862764740222,
 'loss_weight_Methylation-R': 0.5483591479724864,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3990903615,
 'sample_weights': [0.8071196239697194, 0.23353232987988698],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.050642690167923,
 'weight_decay_Methylation-K': 9.900514649521691,
 'weight_decay_Methylation-R': 7.437862400543894}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00962151122279767,
 'learning_rate_Methylation-K': 0.0010488124668416368,
 'learning_rate_Methylation-R': 0.00464203644637821,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.18310311187988884,
 'loss_weight_Methylation-R': 0.8181411623607878,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3051453925,
 'sample_weights': [0.5483591479724864, 0.21519862764740222],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.180280996039471,
 'weight_decay_Methylation-K': 7.209060622864948,
 'weight_decay_Methylation-R': 6.7940351327839394}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032298466833386138,
 'learning_rate_Methylation-K': 0.008325928049820599,
 'learning_rate_Methylation-R': 0.004414351136406299,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7408110237781259,
 'loss_weight_Methylation-R': 0.5358504645463583,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1183084893,
 'sample_weights': [0.8181411623607878, 0.18310311187988884],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.584243215569556,
 'weight_decay_Methylation-K': 1.8820105807992815,
 'weight_decay_Methylation-R': 9.002068550764582}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.385
[3,     7] loss: 1.365
[4,     7] loss: 1.338
[5,     7] loss: 1.314
[6,     7] loss: 1.308
[7,     7] loss: 1.291
[8,     7] loss: 1.286
[9,     7] loss: 1.262
[10,     7] loss: 1.266
[11,     7] loss: 1.269
[12,     7] loss: 1.284
[13,     7] loss: 1.241
[14,     7] loss: 1.236
[15,     7] loss: 1.255
[16,     7] loss: 1.233
[17,     7] loss: 1.229
[18,     7] loss: 1.238
[19,     7] loss: 1.242
[20,     7] loss: 1.230
[21,     7] loss: 1.242
[22,     7] loss: 1.233
[23,     7] loss: 1.220
[24,     7] loss: 1.280
[25,     7] loss: 1.230
[26,     7] loss: 1.237
[27,     7] loss: 1.229
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0083660276406346,
 'learning_rate_Methylation-K': 0.0002287508027787274,
 'learning_rate_Methylation-R': 0.009792932827477552,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5335821353197828,
 'loss_weight_Methylation-R': 0.2797331236671452,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 860556208,
 'sample_weights': [0.5358504645463583, 0.7408110237781259],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.808577101344481,
 'weight_decay_Methylation-K': 5.286028632438718,
 'weight_decay_Methylation-R': 8.333886403750222}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00911627670906515,
 'learning_rate_Methylation-K': 0.0029006069114468473,
 'learning_rate_Methylation-R': 0.008936832705581843,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07747088021306155,
 'loss_weight_Methylation-R': 0.5881276253727791,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 168128625,
 'sample_weights': [0.2797331236671452, 0.5335821353197828],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.180667296085167,
 'weight_decay_Methylation-K': 9.253262028284615,
 'weight_decay_Methylation-R': 9.809932202530419}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.383
[5,     7] loss: 1.353
[6,     7] loss: 1.327
[7,     7] loss: 1.340
[8,     7] loss: 1.318
[9,     7] loss: 1.328
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006959233833823023,
 'learning_rate_Methylation-K': 0.0023387355448454003,
 'learning_rate_Methylation-R': 0.004378022678912693,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9639262921895608,
 'loss_weight_Methylation-R': 0.351886024312558,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 908681754,
 'sample_weights': [0.5881276253727791, 0.07747088021306155],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.104632278370097,
 'weight_decay_Methylation-K': 3.546793373930299,
 'weight_decay_Methylation-R': 3.7198825700992892}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.385
[5,     7] loss: 1.361
[6,     7] loss: 1.339
[7,     7] loss: 1.318
[8,     7] loss: 1.302
[9,     7] loss: 1.307
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007911900739278322,
 'learning_rate_Methylation-K': 0.0016054130919051983,
 'learning_rate_Methylation-R': 0.005887774274186087,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.19178145597339405,
 'loss_weight_Methylation-R': 0.37934820240533523,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1990917277,
 'sample_weights': [0.351886024312558, 0.9639262921895608],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.431659621813628,
 'weight_decay_Methylation-K': 7.0233936440492215,
 'weight_decay_Methylation-R': 9.313225088200978}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.385
[3,     7] loss: 1.371
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00968568994007622,
 'learning_rate_Methylation-K': 0.000647278838083003,
 'learning_rate_Methylation-R': 0.004669641793287364,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07204078647564253,
 'loss_weight_Methylation-R': 0.8758679824987762,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 544209681,
 'sample_weights': [0.37934820240533523, 0.19178145597339405],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.34194681375349,
 'weight_decay_Methylation-K': 7.135293146518712,
 'weight_decay_Methylation-R': 9.103898297941125}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0034890522086959714,
 'learning_rate_Methylation-K': 0.0071849755833487865,
 'learning_rate_Methylation-R': 0.003174588933931205,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6612298858282685,
 'loss_weight_Methylation-R': 0.140787424730196,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3697100723,
 'sample_weights': [0.8758679824987762, 0.07204078647564253],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.266273426512948,
 'weight_decay_Methylation-K': 3.2751940152615258,
 'weight_decay_Methylation-R': 1.9731090239671096}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.363
[3,     7] loss: 1.339
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009304403861863533,
 'learning_rate_Methylation-K': 0.003163787701245502,
 'learning_rate_Methylation-R': 0.0009584192595704617,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.796872840607857,
 'loss_weight_Methylation-R': 0.15897843123037642,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2811880327,
 'sample_weights': [0.140787424730196, 0.6612298858282685],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.867611391841737,
 'weight_decay_Methylation-K': 6.660707684209777,
 'weight_decay_Methylation-R': 3.8040390500331354}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.385
[3,     7] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007677820013780667,
 'learning_rate_Methylation-K': 0.0044016738404349404,
 'learning_rate_Methylation-R': 0.004321329267676335,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.37207262914791855,
 'loss_weight_Methylation-R': 0.2475238331645179,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1958438040,
 'sample_weights': [0.15897843123037642, 0.796872840607857],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.124001411397485,
 'weight_decay_Methylation-K': 2.505667453908762,
 'weight_decay_Methylation-R': 6.740752574420505}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.363
[6,     7] loss: 1.349
[7,     7] loss: 1.331
[8,     7] loss: 1.362
[9,     7] loss: 1.326
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0040249542134047755,
 'learning_rate_Methylation-K': 0.0033518486870827017,
 'learning_rate_Methylation-R': 0.00722696781396495,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2896859606055501,
 'loss_weight_Methylation-R': 0.34734810342414724,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1640535567,
 'sample_weights': [0.2475238331645179, 0.37207262914791855],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.5454708615197665,
 'weight_decay_Methylation-K': 5.093171382552661,
 'weight_decay_Methylation-R': 8.28064380604554}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.381
[3,     7] loss: 1.347
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008540892785867319,
 'learning_rate_Methylation-K': 0.002188699398712729,
 'learning_rate_Methylation-R': 0.0065454553812695935,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4768568389150376,
 'loss_weight_Methylation-R': 0.38775877377828993,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 669017329,
 'sample_weights': [0.34734810342414724, 0.2896859606055501],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.004818332494715,
 'weight_decay_Methylation-K': 3.734619065804497,
 'weight_decay_Methylation-R': 9.5850925163038}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004105683408998272,
 'learning_rate_Methylation-K': 0.006565948984116797,
 'learning_rate_Methylation-R': 0.00041796759198093974,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8783441655166683,
 'loss_weight_Methylation-R': 0.707971840347895,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3754602981,
 'sample_weights': [0.38775877377828993, 0.4768568389150376],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9032586820673973,
 'weight_decay_Methylation-K': 3.036205367550255,
 'weight_decay_Methylation-R': 5.270907185295121}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006945217603760198,
 'learning_rate_Methylation-K': 0.004906942659742157,
 'learning_rate_Methylation-R': 0.00525495951659543,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7290646344135527,
 'loss_weight_Methylation-R': 0.3712913403611483,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2408094361,
 'sample_weights': [0.707971840347895, 0.8783441655166683],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.686469038798721,
 'weight_decay_Methylation-K': 4.582190152428236,
 'weight_decay_Methylation-R': 8.970681673010118}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001912532237791007,
 'learning_rate_Methylation-K': 0.007135808896672993,
 'learning_rate_Methylation-R': 0.002934451970760839,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8189725694590336,
 'loss_weight_Methylation-R': 0.23887487650382636,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3772499752,
 'sample_weights': [0.3712913403611483, 0.7290646344135527],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.475013818893905,
 'weight_decay_Methylation-K': 5.439149843308187,
 'weight_decay_Methylation-R': 7.742078547839105}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.382
[3,     7] loss: 1.359
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009125746734407539,
 'learning_rate_Methylation-K': 0.008347228407447851,
 'learning_rate_Methylation-R': 0.008358066934721029,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8805677459948326,
 'loss_weight_Methylation-R': 0.48062508086170863,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1282970087,
 'sample_weights': [0.23887487650382636, 0.8189725694590336],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9818466789960122,
 'weight_decay_Methylation-K': 7.219538397158834,
 'weight_decay_Methylation-R': 9.881987519221346}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.387
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.387
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00928773195863643,
 'learning_rate_Methylation-K': 0.0036488300856957058,
 'learning_rate_Methylation-R': 0.0004627582976164928,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07680367718383604,
 'loss_weight_Methylation-R': 0.5195634548350248,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3321530447,
 'sample_weights': [0.48062508086170863, 0.8805677459948326],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2548309419295545,
 'weight_decay_Methylation-K': 0.3835972028160084,
 'weight_decay_Methylation-R': 0.4050383872230967}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.385
[8,     7] loss: 1.384
[9,     7] loss: 1.372
[10,     7] loss: 1.350
[11,     7] loss: 1.336
[12,     7] loss: 1.317
[13,     7] loss: 1.323
[14,     7] loss: 1.308
[15,     7] loss: 1.294
[16,     7] loss: 1.294
[17,     7] loss: 1.281
[18,     7] loss: 1.284
[19,     7] loss: 1.276
[20,     7] loss: 1.275
[21,     7] loss: 1.270
[22,     7] loss: 1.260
[23,     7] loss: 1.253
[24,     7] loss: 1.257
[25,     7] loss: 1.237
[26,     7] loss: 1.230
[27,     7] loss: 1.219
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009870268403055882,
 'learning_rate_Methylation-K': 0.0036655331868013907,
 'learning_rate_Methylation-R': 0.008991891237623936,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.017557295829760955,
 'loss_weight_Methylation-R': 0.7737564749097993,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3477129106,
 'sample_weights': [0.5195634548350248, 0.07680367718383604],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.1949804109045195,
 'weight_decay_Methylation-K': 5.050153708589115,
 'weight_decay_Methylation-R': 9.109494900730251}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.383
[6,     7] loss: 1.359
[7,     7] loss: 1.353
[8,     7] loss: 1.330
[9,     7] loss: 1.328
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0076843147427640614,
 'learning_rate_Methylation-K': 0.008551435440314293,
 'learning_rate_Methylation-R': 0.0014441637400299328,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7058548221433243,
 'loss_weight_Methylation-R': 0.21447694206075538,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1146577123,
 'sample_weights': [0.7737564749097993, 0.017557295829760955],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.3539129064964812,
 'weight_decay_Methylation-K': 3.398335376404896,
 'weight_decay_Methylation-R': 8.354568238487659}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.382
[8,     7] loss: 1.373
[9,     7] loss: 1.356
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002667351589798565,
 'learning_rate_Methylation-K': 0.00919009754464363,
 'learning_rate_Methylation-R': 0.00224178835325811,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7452427413585894,
 'loss_weight_Methylation-R': 0.7449621875959762,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3351692441,
 'sample_weights': [0.21447694206075538, 0.7058548221433243],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9992250939600065,
 'weight_decay_Methylation-K': 6.42423053094412,
 'weight_decay_Methylation-R': 7.433582790794243}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008703614588276516,
 'learning_rate_Methylation-K': 0.001661223266058179,
 'learning_rate_Methylation-R': 0.0072385855330468225,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.22825009563421708,
 'loss_weight_Methylation-R': 0.9514957022763404,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 334373109,
 'sample_weights': [0.7449621875959762, 0.7452427413585894],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.86896476026557,
 'weight_decay_Methylation-K': 7.507501600254188,
 'weight_decay_Methylation-R': 4.010380762334705}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.384
[6,     7] loss: 1.354
[7,     7] loss: 1.343
[8,     7] loss: 1.323
[9,     7] loss: 1.318
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006632186498951058,
 'learning_rate_Methylation-K': 0.0038980841419366885,
 'learning_rate_Methylation-R': 0.00439505842670126,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.10440904238354093,
 'loss_weight_Methylation-R': 0.9026099181792278,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3025839103,
 'sample_weights': [0.9514957022763404, 0.22825009563421708],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.019003770469006,
 'weight_decay_Methylation-K': 6.943914502910783,
 'weight_decay_Methylation-R': 6.735613616068701}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017796521557821344,
 'learning_rate_Methylation-K': 0.006512459539141724,
 'learning_rate_Methylation-R': 0.0023353052897515277,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.80756463782672,
 'loss_weight_Methylation-R': 0.20341666168378897,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3755987087,
 'sample_weights': [0.9026099181792278, 0.10440904238354093],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.4763858974496713,
 'weight_decay_Methylation-K': 1.1549512895448286,
 'weight_decay_Methylation-R': 9.744823072319878}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.384
[3,     7] loss: 1.371
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032000860809959235,
 'learning_rate_Methylation-K': 0.00526045343641999,
 'learning_rate_Methylation-R': 0.0031942946819374872,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8979162233020614,
 'loss_weight_Methylation-R': 0.04820619837229001,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1028586245,
 'sample_weights': [0.20341666168378897, 0.80756463782672],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.202831867871933,
 'weight_decay_Methylation-K': 3.8411849942177287,
 'weight_decay_Methylation-R': 3.6260933894655007}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.384
[3,     7] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009173623284988698,
 'learning_rate_Methylation-K': 0.00032809933582969423,
 'learning_rate_Methylation-R': 0.006481964504252666,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6467313258557326,
 'loss_weight_Methylation-R': 0.7391281161960211,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1902565865,
 'sample_weights': [0.04820619837229001, 0.8979162233020614],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.013930214856389,
 'weight_decay_Methylation-K': 8.325936605354219,
 'weight_decay_Methylation-R': 9.672865153000863}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.387
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028067700815948495,
 'learning_rate_Methylation-K': 0.0023616238914272464,
 'learning_rate_Methylation-R': 0.003360958836693482,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5339557652412134,
 'loss_weight_Methylation-R': 0.013410048021432251,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 259616573,
 'sample_weights': [0.7391281161960211, 0.6467313258557326],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.147962749533148,
 'weight_decay_Methylation-K': 7.827824510624634,
 'weight_decay_Methylation-R': 9.301770484558538}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.384
[3,     7] loss: 1.374
[4,     7] loss: 1.338
[5,     7] loss: 1.321
[6,     7] loss: 1.302
[7,     7] loss: 1.315
[8,     7] loss: 1.300
[9,     7] loss: 1.278
[10,     7] loss: 1.265
[11,     7] loss: 1.255
[12,     7] loss: 1.261
[13,     7] loss: 1.246
[14,     7] loss: 1.264
[15,     7] loss: 1.259
[16,     7] loss: 1.246
[17,     7] loss: 1.241
[18,     7] loss: 1.245
[19,     7] loss: 1.226
[20,     7] loss: 1.241
[21,     7] loss: 1.220
[22,     7] loss: 1.224
[23,     7] loss: 1.248
[24,     7] loss: 1.215
[25,     7] loss: 1.208
[26,     7] loss: 1.209
[27,     7] loss: 1.198
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005452932292827701,
 'learning_rate_Methylation-K': 0.0005165078462098482,
 'learning_rate_Methylation-R': 0.008023887846398842,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.018016838020283938,
 'loss_weight_Methylation-R': 0.19583272100944837,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 88020896,
 'sample_weights': [0.013410048021432251, 0.5339557652412134],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.660086754940181,
 'weight_decay_Methylation-K': 0.5378477917399171,
 'weight_decay_Methylation-R': 4.2489639315184995}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.385
[3,     7] loss: 1.378
[4,     7] loss: 1.346
[5,     7] loss: 1.328
[6,     7] loss: 1.308
[7,     7] loss: 1.295
[8,     7] loss: 1.289
[9,     7] loss: 1.266
[10,     7] loss: 1.276
[11,     7] loss: 1.262
[12,     7] loss: 1.258
[13,     7] loss: 1.251
[14,     7] loss: 1.234
[15,     7] loss: 1.268
[16,     7] loss: 1.250
[17,     7] loss: 1.264
[18,     7] loss: 1.266
[19,     7] loss: 1.243
[20,     7] loss: 1.238
[21,     7] loss: 1.232
[22,     7] loss: 1.237
[23,     7] loss: 1.242
[24,     7] loss: 1.214
[25,     7] loss: 1.287
[26,     7] loss: 1.302
[27,     7] loss: 1.260
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009502924548646598,
 'learning_rate_Methylation-K': 0.0014895459358140147,
 'learning_rate_Methylation-R': 0.008124904840825394,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07961431462045185,
 'loss_weight_Methylation-R': 0.33812388618925604,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2327565064,
 'sample_weights': [0.19583272100944837, 0.018016838020283938],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.383772487298035,
 'weight_decay_Methylation-K': 7.568677972444232,
 'weight_decay_Methylation-R': 7.117719318471531}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009721351040399064,
 'learning_rate_Methylation-K': 0.0010166539790345402,
 'learning_rate_Methylation-R': 0.008180307402387612,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.17609720004847057,
 'loss_weight_Methylation-R': 0.6158641937189221,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 307967906,
 'sample_weights': [0.33812388618925604, 0.07961431462045185],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6305449870878985,
 'weight_decay_Methylation-K': 7.810266358659694,
 'weight_decay_Methylation-R': 9.012772044558133}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.387
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.387
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005393681848879576,
 'learning_rate_Methylation-K': 0.0015469893125943128,
 'learning_rate_Methylation-R': 0.009497224239148089,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.06722899679839522,
 'loss_weight_Methylation-R': 0.92143839724031,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 552673424,
 'sample_weights': [0.6158641937189221, 0.17609720004847057],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.75813812507223,
 'weight_decay_Methylation-K': 6.0006955433759925,
 'weight_decay_Methylation-R': 9.710488179761885}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.379
[3,     7] loss: 1.344
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007870961800869753,
 'learning_rate_Methylation-K': 0.0076224336179303055,
 'learning_rate_Methylation-R': 0.0009663505803131109,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9211792037662113,
 'loss_weight_Methylation-R': 0.2596905162754881,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3033945654,
 'sample_weights': [0.92143839724031, 0.06722899679839522],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.811811338081778,
 'weight_decay_Methylation-K': 2.1704244058605244,
 'weight_decay_Methylation-R': 0.64505956698207}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.385
[6,     7] loss: 1.357
[7,     7] loss: 1.343
[8,     7] loss: 1.337
[9,     7] loss: 1.317
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009872345663162845,
 'learning_rate_Methylation-K': 0.0026979437645376263,
 'learning_rate_Methylation-R': 0.006176812038114676,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.0015022313041486574,
 'loss_weight_Methylation-R': 0.8965699377825431,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 891237680,
 'sample_weights': [0.2596905162754881, 0.9211792037662113],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.249103927264313,
 'weight_decay_Methylation-K': 2.4599534237695386,
 'weight_decay_Methylation-R': 6.610721129552104}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.374
[11,     7] loss: 1.346
[12,     7] loss: 1.388
[13,     7] loss: 1.393
[14,     7] loss: 1.387
[15,     7] loss: 1.387
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.387
[21,     7] loss: 1.387
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00819413955303972,
 'learning_rate_Methylation-K': 0.00642333766044533,
 'learning_rate_Methylation-R': 0.0034838762344067426,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9079956124883956,
 'loss_weight_Methylation-R': 0.26493786630483984,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3611711830,
 'sample_weights': [0.8965699377825431, 0.0015022313041486574],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.512771704754912,
 'weight_decay_Methylation-K': 3.829840645094905,
 'weight_decay_Methylation-R': 3.8785718504042572}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004669841625095002,
 'learning_rate_Methylation-K': 0.008458691335471247,
 'learning_rate_Methylation-R': 0.006915515722529796,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7313221932503853,
 'loss_weight_Methylation-R': 0.7929213930246504,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 272778313,
 'sample_weights': [0.26493786630483984, 0.9079956124883956],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.668604712983399,
 'weight_decay_Methylation-K': 8.212511489494226,
 'weight_decay_Methylation-R': 5.642782812213143}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.384
[3,     7] loss: 1.369
[4,     7] loss: 1.335
[5,     7] loss: 1.322
[6,     7] loss: 1.309
[7,     7] loss: 1.306
[8,     7] loss: 1.305
[9,     7] loss: 1.297
[10,     7] loss: 1.286
[11,     7] loss: 1.266
[12,     7] loss: 1.286
[13,     7] loss: 1.275
[14,     7] loss: 1.266
[15,     7] loss: 1.270
[16,     7] loss: 1.277
[17,     7] loss: 1.266
[18,     7] loss: 1.257
[19,     7] loss: 1.301
[20,     7] loss: 1.281
[21,     7] loss: 1.264
[22,     7] loss: 1.262
[23,     7] loss: 1.259
[24,     7] loss: 1.235
[25,     7] loss: 1.309
[26,     7] loss: 1.346
[27,     7] loss: 1.328
[28,     7] loss: 1.321
[29,     7] loss: 1.326
[30,     7] loss: 1.312
[31,     7] loss: 1.313
[32,     7] loss: 1.317
[33,     7] loss: 1.306
[34,     7] loss: 1.310
[35,     7] loss: 1.302
[36,     7] loss: 1.316
[37,     7] loss: 1.304
[38,     7] loss: 1.298
[39,     7] loss: 1.305
[40,     7] loss: 1.304
[41,     7] loss: 1.296
[42,     7] loss: 1.288
[43,     7] loss: 1.297
[44,     7] loss: 1.289
[45,     7] loss: 1.316
[46,     7] loss: 1.403
[47,     7] loss: 1.391
[48,     7] loss: 1.390
[49,     7] loss: 1.387
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.387
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
Early stopping applied (best metric=0.41142013669013977)
Finished Training
Total time taken: 70.57581949234009
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.371
[4,     7] loss: 1.337
[5,     7] loss: 1.313
[6,     7] loss: 1.315
[7,     7] loss: 1.289
[8,     7] loss: 1.290
[9,     7] loss: 1.285
[10,     7] loss: 1.313
[11,     7] loss: 1.342
[12,     7] loss: 1.340
[13,     7] loss: 1.321
[14,     7] loss: 1.282
[15,     7] loss: 1.285
[16,     7] loss: 1.274
[17,     7] loss: 1.256
[18,     7] loss: 1.343
[19,     7] loss: 1.301
[20,     7] loss: 1.279
[21,     7] loss: 1.276
[22,     7] loss: 1.290
[23,     7] loss: 1.289
[24,     7] loss: 1.274
[25,     7] loss: 1.285
[26,     7] loss: 1.274
[27,     7] loss: 1.269
[28,     7] loss: 1.273
[29,     7] loss: 1.268
[30,     7] loss: 1.279
[31,     7] loss: 1.269
[32,     7] loss: 1.258
[33,     7] loss: 1.276
[34,     7] loss: 1.267
[35,     7] loss: 1.255
[36,     7] loss: 1.236
[37,     7] loss: 1.329
[38,     7] loss: 1.320
[39,     7] loss: 1.303
[40,     7] loss: 1.282
[41,     7] loss: 1.280
[42,     7] loss: 1.276
[43,     7] loss: 1.283
[44,     7] loss: 1.286
[45,     7] loss: 1.277
[46,     7] loss: 1.277
[47,     7] loss: 1.271
[48,     7] loss: 1.267
[49,     7] loss: 1.289
[50,     7] loss: 1.268
[51,     7] loss: 1.250
[52,     7] loss: 1.290
[53,     7] loss: 1.305
[54,     7] loss: 1.280
[55,     7] loss: 1.270
[56,     7] loss: 1.249
[57,     7] loss: 1.304
[58,     7] loss: 1.314
[59,     7] loss: 1.289
[60,     7] loss: 1.266
[61,     7] loss: 1.279
[62,     7] loss: 1.275
[63,     7] loss: 1.270
[64,     7] loss: 1.267
[65,     7] loss: 1.257
[66,     7] loss: 1.246
[67,     7] loss: 1.255
[68,     7] loss: 1.243
[69,     7] loss: 1.251
[70,     7] loss: 1.235
[71,     7] loss: 1.258
[72,     7] loss: 1.283
[73,     7] loss: 1.290
[74,     7] loss: 1.295
[75,     7] loss: 1.243
[76,     7] loss: 1.229
[77,     7] loss: 1.260
[78,     7] loss: 1.254
[79,     7] loss: 1.217
[80,     7] loss: 1.214
[81,     7] loss: 1.232
[82,     7] loss: 1.228
[83,     7] loss: 1.215
[84,     7] loss: 1.198
[85,     7] loss: 1.238
[86,     7] loss: 1.232
[87,     7] loss: 1.240
[88,     7] loss: 1.228
[89,     7] loss: 1.318
[90,     7] loss: 1.356
[91,     7] loss: 1.359
[92,     7] loss: 1.337
[93,     7] loss: 1.363
[94,     7] loss: 1.351
[95,     7] loss: 1.336
[96,     7] loss: 1.320
[97,     7] loss: 1.298
[98,     7] loss: 1.281
[99,     7] loss: 1.289
[100,     7] loss: 1.273
[101,     7] loss: 1.258
[102,     7] loss: 1.247
[103,     7] loss: 1.245
[104,     7] loss: 1.253
[105,     7] loss: 1.227
[106,     7] loss: 1.284
[107,     7] loss: 1.256
[108,     7] loss: 1.227
[109,     7] loss: 1.217
[110,     7] loss: 1.230
[111,     7] loss: 1.239
[112,     7] loss: 1.226
[113,     7] loss: 1.227
[114,     7] loss: 1.224
[115,     7] loss: 1.231
[116,     7] loss: 1.211
[117,     7] loss: 1.203
[118,     7] loss: 1.233
[119,     7] loss: 1.228
[120,     7] loss: 1.204
[121,     7] loss: 1.229
[122,     7] loss: 1.228
Early stopping applied (best metric=0.4275470972061157)
Finished Training
Total time taken: 116.715092420578
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.386
[3,     7] loss: 1.383
[4,     7] loss: 1.361
[5,     7] loss: 1.338
[6,     7] loss: 1.310
[7,     7] loss: 1.309
[8,     7] loss: 1.305
[9,     7] loss: 1.281
[10,     7] loss: 1.277
[11,     7] loss: 1.256
[12,     7] loss: 1.270
[13,     7] loss: 1.268
[14,     7] loss: 1.336
[15,     7] loss: 1.383
[16,     7] loss: 1.385
[17,     7] loss: 1.385
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.385
[22,     7] loss: 1.382
[23,     7] loss: 1.369
[24,     7] loss: 1.365
[25,     7] loss: 1.341
[26,     7] loss: 1.324
[27,     7] loss: 1.300
[28,     7] loss: 1.292
[29,     7] loss: 1.294
[30,     7] loss: 1.281
[31,     7] loss: 1.290
[32,     7] loss: 1.310
[33,     7] loss: 1.294
[34,     7] loss: 1.298
[35,     7] loss: 1.295
[36,     7] loss: 1.294
[37,     7] loss: 1.280
[38,     7] loss: 1.273
[39,     7] loss: 1.265
[40,     7] loss: 1.268
[41,     7] loss: 1.276
[42,     7] loss: 1.296
[43,     7] loss: 1.313
[44,     7] loss: 1.275
[45,     7] loss: 1.266
[46,     7] loss: 1.269
[47,     7] loss: 1.270
[48,     7] loss: 1.311
[49,     7] loss: 1.332
[50,     7] loss: 1.313
[51,     7] loss: 1.276
[52,     7] loss: 1.270
[53,     7] loss: 1.267
[54,     7] loss: 1.292
[55,     7] loss: 1.275
[56,     7] loss: 1.281
[57,     7] loss: 1.268
[58,     7] loss: 1.279
[59,     7] loss: 1.267
[60,     7] loss: 1.285
[61,     7] loss: 1.284
[62,     7] loss: 1.262
[63,     7] loss: 1.280
[64,     7] loss: 1.272
Early stopping applied (best metric=0.4326721429824829)
Finished Training
Total time taken: 58.18530559539795
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.381
[6,     7] loss: 1.347
[7,     7] loss: 1.328
[8,     7] loss: 1.308
[9,     7] loss: 1.291
[10,     7] loss: 1.299
[11,     7] loss: 1.290
[12,     7] loss: 1.293
[13,     7] loss: 1.290
[14,     7] loss: 1.271
[15,     7] loss: 1.295
[16,     7] loss: 1.272
[17,     7] loss: 1.278
[18,     7] loss: 1.253
[19,     7] loss: 1.245
[20,     7] loss: 1.305
[21,     7] loss: 1.435
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
Early stopping applied (best metric=0.4472043514251709)
Finished Training
Total time taken: 76.50116968154907
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.396
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.372
[6,     7] loss: 1.352
[7,     7] loss: 1.342
[8,     7] loss: 1.327
[9,     7] loss: 1.315
[10,     7] loss: 1.305
[11,     7] loss: 1.295
[12,     7] loss: 1.278
[13,     7] loss: 1.275
[14,     7] loss: 1.334
[15,     7] loss: 1.305
[16,     7] loss: 1.303
[17,     7] loss: 1.284
[18,     7] loss: 1.302
[19,     7] loss: 1.296
[20,     7] loss: 1.276
[21,     7] loss: 1.272
[22,     7] loss: 1.267
[23,     7] loss: 1.262
[24,     7] loss: 1.290
[25,     7] loss: 1.274
[26,     7] loss: 1.272
[27,     7] loss: 1.267
[28,     7] loss: 1.258
[29,     7] loss: 1.274
[30,     7] loss: 1.325
[31,     7] loss: 1.308
[32,     7] loss: 1.273
[33,     7] loss: 1.287
[34,     7] loss: 1.280
[35,     7] loss: 1.267
[36,     7] loss: 1.270
[37,     7] loss: 1.264
[38,     7] loss: 1.262
[39,     7] loss: 1.254
[40,     7] loss: 1.263
[41,     7] loss: 1.259
[42,     7] loss: 1.260
[43,     7] loss: 1.265
[44,     7] loss: 1.261
[45,     7] loss: 1.260
[46,     7] loss: 1.267
[47,     7] loss: 1.280
[48,     7] loss: 1.244
[49,     7] loss: 1.264
[50,     7] loss: 1.266
[51,     7] loss: 1.264
[52,     7] loss: 1.258
[53,     7] loss: 1.264
[54,     7] loss: 1.234
[55,     7] loss: 1.242
[56,     7] loss: 1.254
[57,     7] loss: 1.245
[58,     7] loss: 1.290
[59,     7] loss: 1.259
[60,     7] loss: 1.257
[61,     7] loss: 1.244
[62,     7] loss: 1.237
[63,     7] loss: 1.281
[64,     7] loss: 1.294
[65,     7] loss: 1.267
[66,     7] loss: 1.274
[67,     7] loss: 1.257
[68,     7] loss: 1.237
[69,     7] loss: 1.241
[70,     7] loss: 1.248
[71,     7] loss: 1.272
[72,     7] loss: 1.236
[73,     7] loss: 1.239
[74,     7] loss: 1.247
[75,     7] loss: 1.365
[76,     7] loss: 1.372
[77,     7] loss: 1.370
[78,     7] loss: 1.364
[79,     7] loss: 1.363
[80,     7] loss: 1.362
[81,     7] loss: 1.363
[82,     7] loss: 1.381
[83,     7] loss: 1.364
[84,     7] loss: 1.352
[85,     7] loss: 1.358
[86,     7] loss: 1.347
[87,     7] loss: 1.338
[88,     7] loss: 1.341
[89,     7] loss: 1.328
[90,     7] loss: 1.351
[91,     7] loss: 1.356
[92,     7] loss: 1.349
[93,     7] loss: 1.336
[94,     7] loss: 1.341
[95,     7] loss: 1.329
[96,     7] loss: 1.320
[97,     7] loss: 1.331
[98,     7] loss: 1.329
[99,     7] loss: 1.336
[100,     7] loss: 1.338
[101,     7] loss: 1.327
[102,     7] loss: 1.323
Early stopping applied (best metric=0.42038866877555847)
Finished Training
Total time taken: 89.77079272270203
{'Methylation-R Validation Accuracy': 0.3135328763969947, 'Methylation-R Validation Sensitivity': 0.9432124728319261, 'Methylation-R Validation Specificity': 0.25528834355828217, 'Methylation-R Validation Precision': 0.11010056815457323, 'Methylation-R AUC ROC': 0.7334824689460414, 'Methylation-R AUC PR': 0.36932798983444715, 'Methylation-R MCC': 0.11703996764379657, 'Methylation-R F1': 0.1961549775693128, 'Validation Loss (Methylation-R)': 0.34876789450645446, 'Methylation-K Validation Accuracy': 0.29932942135427765, 'Methylation-K Validation Sensitivity': 0.8243256655972376, 'Methylation-K Validation Specificity': 0.24239007240888363, 'Methylation-K Validation Precision': 0.10765164550738458, 'Methylation-K AUC ROC': 0.5566034921645514, 'Methylation-K AUC PR': 0.20666642076830333, 'Methylation-K MCC': 0.0411332204524292, 'Methylation-K F1': 0.18908254002507088, 'Validation Loss (Methylation-K)': 0.42784647941589354, 'Validation Loss (total)': 0.7766143679618835, 'TimeToTrain': 82.34963598251343}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009379705202242803,
 'learning_rate_Methylation-K': 0.005119097073254836,
 'learning_rate_Methylation-R': 0.009814736415651469,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.14752595320515197,
 'loss_weight_Methylation-R': 0.7122768181480696,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4272253388,
 'sample_weights': [0.7929213930246504, 0.7313221932503853],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7430364065044204,
 'weight_decay_Methylation-K': 6.917531080008859,
 'weight_decay_Methylation-R': 8.647859037627455}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007344171244168158,
 'learning_rate_Methylation-K': 0.00455489531401005,
 'learning_rate_Methylation-R': 0.003975571510487767,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3072770967685714,
 'loss_weight_Methylation-R': 0.15940602024241254,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3026782648,
 'sample_weights': [0.7122768181480696, 0.14752595320515197],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.8727580283571,
 'weight_decay_Methylation-K': 9.197772477250199,
 'weight_decay_Methylation-R': 4.1607138288317955}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.383
[8,     7] loss: 1.360
[9,     7] loss: 1.328
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008389851036133253,
 'learning_rate_Methylation-K': 0.006687143271605968,
 'learning_rate_Methylation-R': 0.00862609432933548,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5716043734691402,
 'loss_weight_Methylation-R': 0.08850403524080819,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2566666182,
 'sample_weights': [0.15940602024241254, 0.3072770967685714],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.828807028959937,
 'weight_decay_Methylation-K': 5.870888979795227,
 'weight_decay_Methylation-R': 9.152627764307343}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002872555350165964,
 'learning_rate_Methylation-K': 0.0028621792225541204,
 'learning_rate_Methylation-R': 0.001682984795790755,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6733459981934162,
 'loss_weight_Methylation-R': 0.48491609300796545,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 206848595,
 'sample_weights': [0.08850403524080819, 0.5716043734691402],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5863314751774045,
 'weight_decay_Methylation-K': 5.751845906225081,
 'weight_decay_Methylation-R': 8.810661594561589}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008117906609925162,
 'learning_rate_Methylation-K': 0.004384583571891186,
 'learning_rate_Methylation-R': 0.009746193819574069,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5847909517261732,
 'loss_weight_Methylation-R': 0.8579056183299779,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1110795019,
 'sample_weights': [0.48491609300796545, 0.6733459981934162],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.22940651302955106,
 'weight_decay_Methylation-K': 6.794766739922352,
 'weight_decay_Methylation-R': 8.227405129874045}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004766899495865587,
 'learning_rate_Methylation-K': 0.0076557564611606,
 'learning_rate_Methylation-R': 0.002816689107295732,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8189035647454753,
 'loss_weight_Methylation-R': 0.10596170005142277,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1970888715,
 'sample_weights': [0.8579056183299779, 0.5847909517261732],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.148369782038479,
 'weight_decay_Methylation-K': 1.7314208984874435,
 'weight_decay_Methylation-R': 6.830676065999252}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.385
[3,     7] loss: 1.377
[4,     7] loss: 1.343
[5,     7] loss: 1.332
[6,     7] loss: 1.306
[7,     7] loss: 1.284
[8,     7] loss: 1.293
[9,     7] loss: 1.264
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009909884745238256,
 'learning_rate_Methylation-K': 0.002213207350505762,
 'learning_rate_Methylation-R': 0.007971688806048498,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3023508887607047,
 'loss_weight_Methylation-R': 0.33591339206522125,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3543534769,
 'sample_weights': [0.10596170005142277, 0.8189035647454753],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6246200366644556,
 'weight_decay_Methylation-K': 6.431224897026661,
 'weight_decay_Methylation-R': 7.7903138250433885}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0076519020782819195,
 'learning_rate_Methylation-K': 0.0036492395464542858,
 'learning_rate_Methylation-R': 0.004761920486358818,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2425988671197491,
 'loss_weight_Methylation-R': 0.725607635848146,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2228656878,
 'sample_weights': [0.33591339206522125, 0.3023508887607047],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9154507501501394,
 'weight_decay_Methylation-K': 5.234012475823596,
 'weight_decay_Methylation-R': 9.07040200736946}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.387
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.386
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
[95,     7] loss: 1.386
[96,     7] loss: 1.386
[97,     7] loss: 1.386
[98,     7] loss: 1.386
[99,     7] loss: 1.386
[100,     7] loss: 1.386
[101,     7] loss: 1.386
[102,     7] loss: 1.386
[103,     7] loss: 1.386
[104,     7] loss: 1.386
[105,     7] loss: 1.386
[106,     7] loss: 1.386
[107,     7] loss: 1.386
[108,     7] loss: 1.386
[109,     7] loss: 1.386
[110,     7] loss: 1.386
[111,     7] loss: 1.386
[112,     7] loss: 1.386
[113,     7] loss: 1.386
[114,     7] loss: 1.386
[115,     7] loss: 1.386
[116,     7] loss: 1.386
[117,     7] loss: 1.386
[118,     7] loss: 1.386
[119,     7] loss: 1.386
[120,     7] loss: 1.386
Early stopping applied (best metric=0.4451504349708557)
Finished Training
Total time taken: 104.24560165405273
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.384
[13,     7] loss: 1.363
[14,     7] loss: 1.344
[15,     7] loss: 1.320
[16,     7] loss: 1.312
[17,     7] loss: 1.318
[18,     7] loss: 1.290
[19,     7] loss: 1.278
[20,     7] loss: 1.274
[21,     7] loss: 1.282
[22,     7] loss: 1.269
[23,     7] loss: 1.273
[24,     7] loss: 1.273
[25,     7] loss: 1.254
[26,     7] loss: 1.263
[27,     7] loss: 1.242
[28,     7] loss: 1.243
[29,     7] loss: 1.243
[30,     7] loss: 1.238
[31,     7] loss: 1.249
[32,     7] loss: 1.225
[33,     7] loss: 1.239
[34,     7] loss: 1.241
[35,     7] loss: 1.238
[36,     7] loss: 1.242
[37,     7] loss: 1.255
[38,     7] loss: 1.225
[39,     7] loss: 1.190
[40,     7] loss: 1.169
[41,     7] loss: 1.205
[42,     7] loss: 1.202
[43,     7] loss: 1.180
[44,     7] loss: 1.185
[45,     7] loss: 1.175
[46,     7] loss: 1.159
[47,     7] loss: 1.153
[48,     7] loss: 1.168
[49,     7] loss: 1.130
[50,     7] loss: 1.206
[51,     7] loss: 1.171
[52,     7] loss: 1.148
[53,     7] loss: 1.113
[54,     7] loss: 1.106
[55,     7] loss: 1.133
[56,     7] loss: 1.145
[57,     7] loss: 1.163
[58,     7] loss: 1.161
[59,     7] loss: 1.132
[60,     7] loss: 1.115
[61,     7] loss: 1.094
[62,     7] loss: 1.137
[63,     7] loss: 1.144
[64,     7] loss: 1.112
[65,     7] loss: 1.099
[66,     7] loss: 1.094
[67,     7] loss: 1.115
[68,     7] loss: 1.118
[69,     7] loss: 1.109
[70,     7] loss: 1.114
[71,     7] loss: 1.124
[72,     7] loss: 1.137
[73,     7] loss: 1.104
[74,     7] loss: 1.103
[75,     7] loss: 1.090
[76,     7] loss: 1.090
[77,     7] loss: 1.069
[78,     7] loss: 1.079
[79,     7] loss: 1.098
[80,     7] loss: 1.101
[81,     7] loss: 1.169
[82,     7] loss: 1.117
[83,     7] loss: 1.117
[84,     7] loss: 1.079
[85,     7] loss: 1.057
[86,     7] loss: 1.103
Early stopping applied (best metric=0.3976548910140991)
Finished Training
Total time taken: 76.92717170715332
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.385
[10,     7] loss: 1.367
[11,     7] loss: 1.364
[12,     7] loss: 1.354
[13,     7] loss: 1.346
[14,     7] loss: 1.328
[15,     7] loss: 1.319
[16,     7] loss: 1.303
[17,     7] loss: 1.299
[18,     7] loss: 1.281
[19,     7] loss: 1.291
[20,     7] loss: 1.294
[21,     7] loss: 1.260
[22,     7] loss: 1.280
[23,     7] loss: 1.274
[24,     7] loss: 1.255
[25,     7] loss: 1.248
[26,     7] loss: 1.240
[27,     7] loss: 1.225
[28,     7] loss: 1.240
[29,     7] loss: 1.245
[30,     7] loss: 1.236
[31,     7] loss: 1.202
[32,     7] loss: 1.221
[33,     7] loss: 1.209
[34,     7] loss: 1.196
[35,     7] loss: 1.182
[36,     7] loss: 1.202
[37,     7] loss: 1.174
[38,     7] loss: 1.169
[39,     7] loss: 1.167
[40,     7] loss: 1.138
[41,     7] loss: 1.148
[42,     7] loss: 1.139
[43,     7] loss: 1.150
[44,     7] loss: 1.128
[45,     7] loss: 1.133
[46,     7] loss: 1.156
[47,     7] loss: 1.127
[48,     7] loss: 1.135
[49,     7] loss: 1.121
[50,     7] loss: 1.121
[51,     7] loss: 1.120
[52,     7] loss: 1.100
[53,     7] loss: 1.115
[54,     7] loss: 1.112
[55,     7] loss: 1.119
[56,     7] loss: 1.125
[57,     7] loss: 1.091
[58,     7] loss: 1.103
[59,     7] loss: 1.103
[60,     7] loss: 1.142
[61,     7] loss: 1.155
[62,     7] loss: 1.119
[63,     7] loss: 1.099
[64,     7] loss: 1.076
[65,     7] loss: 1.091
[66,     7] loss: 1.080
[67,     7] loss: 1.109
[68,     7] loss: 1.168
[69,     7] loss: 1.117
[70,     7] loss: 1.081
[71,     7] loss: 1.087
[72,     7] loss: 1.084
[73,     7] loss: 1.057
[74,     7] loss: 1.223
[75,     7] loss: 1.237
[76,     7] loss: 1.178
[77,     7] loss: 1.143
[78,     7] loss: 1.142
[79,     7] loss: 1.117
[80,     7] loss: 1.114
[81,     7] loss: 1.110
[82,     7] loss: 1.110
[83,     7] loss: 1.091
[84,     7] loss: 1.079
[85,     7] loss: 1.064
[86,     7] loss: 1.073
[87,     7] loss: 1.112
[88,     7] loss: 1.108
[89,     7] loss: 1.106
[90,     7] loss: 1.104
[91,     7] loss: 1.091
[92,     7] loss: 1.074
[93,     7] loss: 1.096
[94,     7] loss: 1.087
[95,     7] loss: 1.073
[96,     7] loss: 1.079
[97,     7] loss: 1.104
Early stopping applied (best metric=0.4211481213569641)
Finished Training
Total time taken: 86.42115926742554
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.4399645924568176)
Finished Training
Total time taken: 47.2331109046936
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.44433918595314026)
Finished Training
Total time taken: 46.553699016571045
{'Methylation-R Validation Accuracy': 0.27089138765121423, 'Methylation-R Validation Sensitivity': 0.936604774535809, 'Methylation-R Validation Specificity': 0.20932515337423313, 'Methylation-R Validation Precision': 0.10846670686005552, 'Methylation-R AUC ROC': 0.6682945859129645, 'Methylation-R AUC PR': 0.30378527279898576, 'Methylation-R MCC': 0.08296366790759868, 'Methylation-R F1': 0.19162842053483117, 'Validation Loss (Methylation-R)': 0.38318435549736024, 'Methylation-K Validation Accuracy': 0.24839428996712984, 'Methylation-K Validation Sensitivity': 0.9014023732470334, 'Methylation-K Validation Specificity': 0.17758015445822609, 'Methylation-K Validation Precision': 0.11083828450693088, 'Methylation-K AUC ROC': 0.5488662475416044, 'Methylation-K AUC PR': 0.20377751728713597, 'Methylation-K MCC': 0.04852856070984061, 'Methylation-K F1': 0.1954067554331919, 'Validation Loss (Methylation-K)': 0.42965144515037534, 'Validation Loss (total)': 0.8128358006477356, 'TimeToTrain': 72.27614850997925}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009970129864642803,
 'learning_rate_Methylation-K': 0.0009699742998052555,
 'learning_rate_Methylation-R': 0.008906819497124104,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.020093761612554578,
 'loss_weight_Methylation-R': 0.6776468409284554,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1906084880,
 'sample_weights': [0.725607635848146, 0.2425988671197491],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2305988930910878,
 'weight_decay_Methylation-K': 6.795398160835288,
 'weight_decay_Methylation-R': 6.406360346416228}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007684593346264399,
 'learning_rate_Methylation-K': 0.008965273891437935,
 'learning_rate_Methylation-R': 0.008242969040085353,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9490135046085727,
 'loss_weight_Methylation-R': 0.3900923427571861,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 725962115,
 'sample_weights': [0.6776468409284554, 0.020093761612554578],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6146489913461304,
 'weight_decay_Methylation-K': 8.417054061960098,
 'weight_decay_Methylation-R': 9.405223772332175}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009213609585647509,
 'learning_rate_Methylation-K': 0.008976364706337229,
 'learning_rate_Methylation-R': 0.007638440759022457,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6183791966961869,
 'loss_weight_Methylation-R': 0.4168360052132846,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2879369244,
 'sample_weights': [0.3900923427571861, 0.9490135046085727],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1401419596614704,
 'weight_decay_Methylation-K': 6.348086081300467,
 'weight_decay_Methylation-R': 9.877946729661163}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002015194763670592,
 'learning_rate_Methylation-K': 0.0016694195393583608,
 'learning_rate_Methylation-R': 0.0064397261309808934,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2129150719692862,
 'loss_weight_Methylation-R': 0.272297313340469,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2352041336,
 'sample_weights': [0.4168360052132846, 0.6183791966961869],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.9738979703690305,
 'weight_decay_Methylation-K': 1.128910375411487,
 'weight_decay_Methylation-R': 3.930317739182214}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.377
[3,     7] loss: 1.351
[4,     7] loss: 1.321
[5,     7] loss: 1.309
[6,     7] loss: 1.287
[7,     7] loss: 1.291
[8,     7] loss: 1.280
[9,     7] loss: 1.263
[10,     7] loss: 1.256
[11,     7] loss: 1.249
[12,     7] loss: 1.254
[13,     7] loss: 1.239
[14,     7] loss: 1.226
[15,     7] loss: 1.232
[16,     7] loss: 1.230
[17,     7] loss: 1.255
[18,     7] loss: 1.260
[19,     7] loss: 1.240
[20,     7] loss: 1.215
[21,     7] loss: 1.208
[22,     7] loss: 1.215
[23,     7] loss: 1.211
[24,     7] loss: 1.208
[25,     7] loss: 1.178
[26,     7] loss: 1.167
[27,     7] loss: 1.132
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005285422005527107,
 'learning_rate_Methylation-K': 0.0036352328801459097,
 'learning_rate_Methylation-R': 0.006583479528701151,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6948017544236109,
 'loss_weight_Methylation-R': 0.03896431576283449,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2049942943,
 'sample_weights': [0.272297313340469, 0.2129150719692862],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.086709085767373,
 'weight_decay_Methylation-K': 4.497852731012996,
 'weight_decay_Methylation-R': 6.561646817093813}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009631223859257377,
 'learning_rate_Methylation-K': 0.005899527517443267,
 'learning_rate_Methylation-R': 0.0047956604342357665,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.861879354913123,
 'loss_weight_Methylation-R': 0.4287618853072894,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2106230616,
 'sample_weights': [0.03896431576283449, 0.6948017544236109],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9258888096344648,
 'weight_decay_Methylation-K': 7.939198634081521,
 'weight_decay_Methylation-R': 7.006894815989618}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005675700681018296,
 'learning_rate_Methylation-K': 0.001632320723384441,
 'learning_rate_Methylation-R': 0.004436424292404558,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5242473635584625,
 'loss_weight_Methylation-R': 0.46247742680828413,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1692049394,
 'sample_weights': [0.4287618853072894, 0.861879354913123],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8573382253354591,
 'weight_decay_Methylation-K': 3.8927215515572775,
 'weight_decay_Methylation-R': 6.068830502035282}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.384
[3,     7] loss: 1.376
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007151564193847755,
 'learning_rate_Methylation-K': 0.0010695238755629713,
 'learning_rate_Methylation-R': 0.008357243413207947,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.29625567544101794,
 'loss_weight_Methylation-R': 0.5214188501804831,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2009893962,
 'sample_weights': [0.46247742680828413, 0.5242473635584625],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.518833229743604,
 'weight_decay_Methylation-K': 8.91355449193543,
 'weight_decay_Methylation-R': 8.40019832270667}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.385
[10,     7] loss: 1.379
[11,     7] loss: 1.351
[12,     7] loss: 1.333
[13,     7] loss: 1.326
[14,     7] loss: 1.305
[15,     7] loss: 1.307
[16,     7] loss: 1.305
[17,     7] loss: 1.298
[18,     7] loss: 1.290
[19,     7] loss: 1.273
[20,     7] loss: 1.259
[21,     7] loss: 1.262
[22,     7] loss: 1.267
[23,     7] loss: 1.257
[24,     7] loss: 1.250
[25,     7] loss: 1.241
[26,     7] loss: 1.232
[27,     7] loss: 1.235
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007486921104632478,
 'learning_rate_Methylation-K': 0.005170887714846101,
 'learning_rate_Methylation-R': 0.0079715270123582,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6538287140006671,
 'loss_weight_Methylation-R': 0.6321441311619023,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4023544715,
 'sample_weights': [0.5214188501804831, 0.29625567544101794],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.5731295972779327,
 'weight_decay_Methylation-K': 9.844890917132702,
 'weight_decay_Methylation-R': 7.992745347657362}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.378
[8,     7] loss: 1.361
[9,     7] loss: 1.334
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009218614778578754,
 'learning_rate_Methylation-K': 0.0007652074543182615,
 'learning_rate_Methylation-R': 0.007551318696941206,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.10935955921127188,
 'loss_weight_Methylation-R': 0.5668616581571663,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 640718524,
 'sample_weights': [0.6321441311619023, 0.6538287140006671],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.150747025034776,
 'weight_decay_Methylation-K': 8.52896279674277,
 'weight_decay_Methylation-R': 9.482542877692197}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00735945662193614,
 'learning_rate_Methylation-K': 0.004572208076466375,
 'learning_rate_Methylation-R': 0.00044451017504027737,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9958376734753481,
 'loss_weight_Methylation-R': 0.16454806495297541,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 856114511,
 'sample_weights': [0.5668616581571663, 0.10935955921127188],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.853602480197669,
 'weight_decay_Methylation-K': 3.437378551507861,
 'weight_decay_Methylation-R': 3.053212035995194}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.370
[7,     7] loss: 1.342
[8,     7] loss: 1.327
[9,     7] loss: 1.322
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009293414009624435,
 'learning_rate_Methylation-K': 0.0014948313859022501,
 'learning_rate_Methylation-R': 0.009729982041348829,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.06575461644643044,
 'loss_weight_Methylation-R': 0.6968393336112284,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2311744571,
 'sample_weights': [0.16454806495297541, 0.9958376734753481],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.052521102711687,
 'weight_decay_Methylation-K': 8.02716824555836,
 'weight_decay_Methylation-R': 5.942513645265343}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.380
[7,     7] loss: 1.376
[8,     7] loss: 1.364
[9,     7] loss: 1.340
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0042976845611715254,
 'learning_rate_Methylation-K': 0.0062843320163335,
 'learning_rate_Methylation-R': 0.00817692634479414,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.26468594790742606,
 'loss_weight_Methylation-R': 0.17274114241697536,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3873557785,
 'sample_weights': [0.6968393336112284, 0.06575461644643044],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.309709616172061,
 'weight_decay_Methylation-K': 3.076699686000568,
 'weight_decay_Methylation-R': 4.492159407230379}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.383
[4,     7] loss: 1.367
[5,     7] loss: 1.341
[6,     7] loss: 1.328
[7,     7] loss: 1.313
[8,     7] loss: 1.291
[9,     7] loss: 1.294
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006927949685372839,
 'learning_rate_Methylation-K': 0.005266315422871789,
 'learning_rate_Methylation-R': 0.001386461333185299,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5831623209216847,
 'loss_weight_Methylation-R': 0.9575406366994329,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1605909247,
 'sample_weights': [0.17274114241697536, 0.26468594790742606],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.384936616823504,
 'weight_decay_Methylation-K': 8.415375499277461,
 'weight_decay_Methylation-R': 0.48002418972775696}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.384
[9,     7] loss: 1.374
[10,     7] loss: 1.338
[11,     7] loss: 1.331
[12,     7] loss: 1.324
[13,     7] loss: 1.314
[14,     7] loss: 1.309
[15,     7] loss: 1.299
[16,     7] loss: 1.293
[17,     7] loss: 1.286
[18,     7] loss: 1.274
[19,     7] loss: 1.278
[20,     7] loss: 1.281
[21,     7] loss: 1.263
[22,     7] loss: 1.251
[23,     7] loss: 1.262
[24,     7] loss: 1.250
[25,     7] loss: 1.228
[26,     7] loss: 1.215
[27,     7] loss: 1.237
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005646258710139295,
 'learning_rate_Methylation-K': 0.007494651139160249,
 'learning_rate_Methylation-R': 0.005417452634397024,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3598408758752002,
 'loss_weight_Methylation-R': 0.43993545512431653,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1906913391,
 'sample_weights': [0.9575406366994329, 0.5831623209216847],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.932738973437124,
 'weight_decay_Methylation-K': 3.235668138197502,
 'weight_decay_Methylation-R': 8.114046324990627}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004836811378477063,
 'learning_rate_Methylation-K': 0.006356158229627548,
 'learning_rate_Methylation-R': 0.0006632980992830138,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7998462811163644,
 'loss_weight_Methylation-R': 0.5710225400502507,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1526059362,
 'sample_weights': [0.43993545512431653, 0.3598408758752002],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.964116662346603,
 'weight_decay_Methylation-K': 9.41510247094642,
 'weight_decay_Methylation-R': 1.130356709101179}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.385
[3,     7] loss: 1.379
[4,     7] loss: 1.348
[5,     7] loss: 1.333
[6,     7] loss: 1.320
[7,     7] loss: 1.305
[8,     7] loss: 1.280
[9,     7] loss: 1.266
[10,     7] loss: 1.285
[11,     7] loss: 1.260
[12,     7] loss: 1.259
[13,     7] loss: 1.250
[14,     7] loss: 1.240
[15,     7] loss: 1.247
[16,     7] loss: 1.286
[17,     7] loss: 1.248
[18,     7] loss: 1.242
[19,     7] loss: 1.282
[20,     7] loss: 1.259
[21,     7] loss: 1.247
[22,     7] loss: 1.244
[23,     7] loss: 1.258
[24,     7] loss: 1.223
[25,     7] loss: 1.278
[26,     7] loss: 1.288
[27,     7] loss: 1.254
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008580571945014336,
 'learning_rate_Methylation-K': 0.007473753624761159,
 'learning_rate_Methylation-R': 0.0069547524725415925,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9786194312772147,
 'loss_weight_Methylation-R': 0.6517080790839027,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2078894045,
 'sample_weights': [0.5710225400502507, 0.7998462811163644],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.760841248354116,
 'weight_decay_Methylation-K': 5.102693422320502,
 'weight_decay_Methylation-R': 9.871988868992611}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009782632625923444,
 'learning_rate_Methylation-K': 0.0021676026733677537,
 'learning_rate_Methylation-R': 0.006901106804741002,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.13061514462127413,
 'loss_weight_Methylation-R': 0.9424188862269305,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3729987061,
 'sample_weights': [0.6517080790839027, 0.9786194312772147],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.7351703093375646,
 'weight_decay_Methylation-K': 7.22954101505884,
 'weight_decay_Methylation-R': 6.718988719757163}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.387
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009307830514352185,
 'learning_rate_Methylation-K': 0.0005267585212285128,
 'learning_rate_Methylation-R': 0.009886153110265866,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.22855035189868902,
 'loss_weight_Methylation-R': 0.8008734395845033,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2621921841,
 'sample_weights': [0.9424188862269305, 0.13061514462127413],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.538369502331645,
 'weight_decay_Methylation-K': 3.516673429265363,
 'weight_decay_Methylation-R': 8.298780390923952}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 9.840518794364695e-05,
 'learning_rate_Methylation-K': 0.001734244934291672,
 'learning_rate_Methylation-R': 0.009710768083042578,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9579343064906812,
 'loss_weight_Methylation-R': 0.8575375107803231,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2908572725,
 'sample_weights': [0.8008734395845033, 0.22855035189868902],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.648603629465003,
 'weight_decay_Methylation-K': 2.8724342340381117,
 'weight_decay_Methylation-R': 0.4464085163692193}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.388
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.387
[6,     7] loss: 1.385
[7,     7] loss: 1.383
[8,     7] loss: 1.383
[9,     7] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004564751313471018,
 'learning_rate_Methylation-K': 0.00883242187454217,
 'learning_rate_Methylation-R': 0.003952625084314389,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4619233511793174,
 'loss_weight_Methylation-R': 0.6042681789863745,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2348686382,
 'sample_weights': [0.8575375107803231, 0.9579343064906812],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.259059707923525,
 'weight_decay_Methylation-K': 6.2182455297475565,
 'weight_decay_Methylation-R': 0.1369575330536994}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.384
[3,     7] loss: 1.368
[4,     7] loss: 1.339
[5,     7] loss: 1.328
[6,     7] loss: 1.320
[7,     7] loss: 1.308
[8,     7] loss: 1.309
[9,     7] loss: 1.274
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0029847295876413472,
 'learning_rate_Methylation-K': 0.007284236820594988,
 'learning_rate_Methylation-R': 0.008019463253557244,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6311863229807156,
 'loss_weight_Methylation-R': 0.584958651163189,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3085560163,
 'sample_weights': [0.6042681789863745, 0.4619233511793174],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.420325680048814,
 'weight_decay_Methylation-K': 8.999614246733787,
 'weight_decay_Methylation-R': 4.951259133330496}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.385
[3,     7] loss: 1.368
[4,     7] loss: 1.348
[5,     7] loss: 1.329
[6,     7] loss: 1.319
[7,     7] loss: 1.306
[8,     7] loss: 1.289
[9,     7] loss: 1.277
[10,     7] loss: 1.268
[11,     7] loss: 1.265
[12,     7] loss: 1.252
[13,     7] loss: 1.249
[14,     7] loss: 1.251
[15,     7] loss: 1.239
[16,     7] loss: 1.254
[17,     7] loss: 1.247
[18,     7] loss: 1.243
[19,     7] loss: 1.229
[20,     7] loss: 1.257
[21,     7] loss: 1.275
[22,     7] loss: 1.274
[23,     7] loss: 1.263
[24,     7] loss: 1.244
[25,     7] loss: 1.248
[26,     7] loss: 1.241
[27,     7] loss: 1.246
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008640157299847679,
 'learning_rate_Methylation-K': 0.0003288476299131152,
 'learning_rate_Methylation-R': 0.009843338013618324,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1546092304455295,
 'loss_weight_Methylation-R': 0.42096806424355737,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2184393194,
 'sample_weights': [0.584958651163189, 0.6311863229807156],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.461037665670457,
 'weight_decay_Methylation-K': 6.473196902626651,
 'weight_decay_Methylation-R': 9.443017096907937}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.387
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.387
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.387
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.44090721011161804)
Finished Training
Total time taken: 45.800578117370605
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.385
[9,     7] loss: 1.368
[10,     7] loss: 1.354
[11,     7] loss: 1.329
[12,     7] loss: 1.313
[13,     7] loss: 1.302
[14,     7] loss: 1.304
[15,     7] loss: 1.296
[16,     7] loss: 1.294
[17,     7] loss: 1.293
[18,     7] loss: 1.303
[19,     7] loss: 1.288
[20,     7] loss: 1.282
[21,     7] loss: 1.292
[22,     7] loss: 1.375
[23,     7] loss: 1.366
[24,     7] loss: 1.317
[25,     7] loss: 1.302
[26,     7] loss: 1.309
[27,     7] loss: 1.284
[28,     7] loss: 1.283
[29,     7] loss: 1.277
[30,     7] loss: 1.303
[31,     7] loss: 1.287
[32,     7] loss: 1.290
[33,     7] loss: 1.288
[34,     7] loss: 1.291
[35,     7] loss: 1.273
[36,     7] loss: 1.339
[37,     7] loss: 1.307
[38,     7] loss: 1.291
[39,     7] loss: 1.274
[40,     7] loss: 1.285
[41,     7] loss: 1.289
[42,     7] loss: 1.272
[43,     7] loss: 1.268
[44,     7] loss: 1.306
[45,     7] loss: 1.291
[46,     7] loss: 1.268
[47,     7] loss: 1.275
[48,     7] loss: 1.261
[49,     7] loss: 1.286
[50,     7] loss: 1.279
[51,     7] loss: 1.282
[52,     7] loss: 1.266
[53,     7] loss: 1.261
[54,     7] loss: 1.272
[55,     7] loss: 1.260
[56,     7] loss: 1.248
[57,     7] loss: 1.265
[58,     7] loss: 1.265
[59,     7] loss: 1.263
[60,     7] loss: 1.265
[61,     7] loss: 1.243
[62,     7] loss: 1.273
[63,     7] loss: 1.280
[64,     7] loss: 1.268
[65,     7] loss: 1.253
[66,     7] loss: 1.278
[67,     7] loss: 1.239
[68,     7] loss: 1.269
[69,     7] loss: 1.259
[70,     7] loss: 1.258
[71,     7] loss: 1.251
Early stopping applied (best metric=0.43898576498031616)
Finished Training
Total time taken: 65.0167760848999
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.387
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.387
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.386
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.387
[93,     7] loss: 1.386
Early stopping applied (best metric=0.44583144783973694)
Finished Training
Total time taken: 84.03388047218323
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.387
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.387
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
Early stopping applied (best metric=0.4440735876560211)
Finished Training
Total time taken: 50.37836670875549
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.383
[5,     7] loss: 1.357
[6,     7] loss: 1.337
[7,     7] loss: 1.318
[8,     7] loss: 1.310
[9,     7] loss: 1.289
[10,     7] loss: 1.286
[11,     7] loss: 1.281
[12,     7] loss: 1.311
[13,     7] loss: 1.290
[14,     7] loss: 1.288
[15,     7] loss: 1.262
[16,     7] loss: 1.264
[17,     7] loss: 1.262
[18,     7] loss: 1.275
[19,     7] loss: 1.261
[20,     7] loss: 1.262
[21,     7] loss: 1.263
[22,     7] loss: 1.278
[23,     7] loss: 1.271
[24,     7] loss: 1.249
[25,     7] loss: 1.319
[26,     7] loss: 1.287
[27,     7] loss: 1.254
[28,     7] loss: 1.269
[29,     7] loss: 1.271
[30,     7] loss: 1.254
[31,     7] loss: 1.247
[32,     7] loss: 1.274
[33,     7] loss: 1.252
[34,     7] loss: 1.269
[35,     7] loss: 1.240
[36,     7] loss: 1.235
[37,     7] loss: 1.364
[38,     7] loss: 1.351
[39,     7] loss: 1.325
[40,     7] loss: 1.327
[41,     7] loss: 1.312
[42,     7] loss: 1.327
[43,     7] loss: 1.342
[44,     7] loss: 1.304
[45,     7] loss: 1.279
[46,     7] loss: 1.298
[47,     7] loss: 1.283
[48,     7] loss: 1.286
[49,     7] loss: 1.276
[50,     7] loss: 1.287
[51,     7] loss: 1.296
[52,     7] loss: 1.271
[53,     7] loss: 1.273
[54,     7] loss: 1.262
[55,     7] loss: 1.253
[56,     7] loss: 1.263
[57,     7] loss: 1.263
[58,     7] loss: 1.252
[59,     7] loss: 1.251
[60,     7] loss: 1.248
[61,     7] loss: 1.251
[62,     7] loss: 1.255
[63,     7] loss: 1.258
[64,     7] loss: 1.244
[65,     7] loss: 1.258
[66,     7] loss: 1.274
[67,     7] loss: 1.259
[68,     7] loss: 1.256
[69,     7] loss: 1.277
[70,     7] loss: 1.262
[71,     7] loss: 1.253
[72,     7] loss: 1.250
[73,     7] loss: 1.257
[74,     7] loss: 1.268
[75,     7] loss: 1.258
[76,     7] loss: 1.254
[77,     7] loss: 1.257
[78,     7] loss: 1.248
[79,     7] loss: 1.254
[80,     7] loss: 1.310
[81,     7] loss: 1.287
[82,     7] loss: 1.301
[83,     7] loss: 1.290
[84,     7] loss: 1.265
[85,     7] loss: 1.264
[86,     7] loss: 1.280
[87,     7] loss: 1.274
[88,     7] loss: 1.261
[89,     7] loss: 1.264
Early stopping applied (best metric=0.42734405398368835)
Finished Training
Total time taken: 89.59384942054749
{'Methylation-R Validation Accuracy': 0.2016062329555873, 'Methylation-R Validation Sensitivity': 0.9614961903050926, 'Methylation-R Validation Specificity': 0.1313128834355828, 'Methylation-R Validation Precision': 0.09637175696760156, 'Methylation-R AUC ROC': 0.660885536372354, 'Methylation-R AUC PR': 0.309385095737461, 'Methylation-R MCC': 0.057386141022415356, 'Methylation-R F1': 0.17425954322319895, 'Validation Loss (Methylation-R)': 0.3849956691265106, 'Methylation-K Validation Accuracy': 0.21591644193390364, 'Methylation-K Validation Sensitivity': 0.8663614483656842, 'Methylation-K Validation Specificity': 0.14536450999286962, 'Methylation-K Validation Precision': 0.09937192415822349, 'Methylation-K AUC ROC': 0.5060350252098468, 'Methylation-K AUC PR': 0.1892354173287174, 'Methylation-K MCC': 0.007520173512855019, 'Methylation-K F1': 0.17742775402583066, 'Validation Loss (Methylation-K)': 0.43942841291427615, 'Validation Loss (total)': 0.8244240760803223, 'TimeToTrain': 66.96469016075135}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004205096339496893,
 'learning_rate_Methylation-K': 0.0005402262976574734,
 'learning_rate_Methylation-R': 0.009175059499841168,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.17672803590527705,
 'loss_weight_Methylation-R': 0.3911774539468347,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 766419077,
 'sample_weights': [0.42096806424355737, 0.1546092304455295],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.9033222014345887,
 'weight_decay_Methylation-K': 4.852075952405674,
 'weight_decay_Methylation-R': 8.714127222369967}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.386
[3,     7] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0034272810472563823,
 'learning_rate_Methylation-K': 0.005465529827265472,
 'learning_rate_Methylation-R': 0.001460635408054473,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8291398754074277,
 'loss_weight_Methylation-R': 0.2800464278585598,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3334399317,
 'sample_weights': [0.3911774539468347, 0.17672803590527705],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7389142767083297,
 'weight_decay_Methylation-K': 5.1590218290775764,
 'weight_decay_Methylation-R': 7.06561583920806}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003136931137480592,
 'learning_rate_Methylation-K': 0.0038320393249170904,
 'learning_rate_Methylation-R': 0.0025578145624549557,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3933672952931805,
 'loss_weight_Methylation-R': 0.7133515182830237,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 136646162,
 'sample_weights': [0.2800464278585598, 0.8291398754074277],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.4235868134630705,
 'weight_decay_Methylation-K': 4.460864362226335,
 'weight_decay_Methylation-R': 3.0080286531980187}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.385
[3,     7] loss: 1.381
[4,     7] loss: 1.354
[5,     7] loss: 1.334
[6,     7] loss: 1.326
[7,     7] loss: 1.295
[8,     7] loss: 1.283
[9,     7] loss: 1.268
[10,     7] loss: 1.271
[11,     7] loss: 1.255
[12,     7] loss: 1.263
[13,     7] loss: 1.252
[14,     7] loss: 1.226
[15,     7] loss: 1.233
[16,     7] loss: 1.237
[17,     7] loss: 1.219
[18,     7] loss: 1.244
[19,     7] loss: 1.221
[20,     7] loss: 1.214
[21,     7] loss: 1.205
[22,     7] loss: 1.206
[23,     7] loss: 1.171
[24,     7] loss: 1.177
[25,     7] loss: 1.172
[26,     7] loss: 1.150
[27,     7] loss: 1.167
[28,     7] loss: 1.151
[29,     7] loss: 1.153
[30,     7] loss: 1.151
[31,     7] loss: 1.124
[32,     7] loss: 1.110
[33,     7] loss: 1.116
[34,     7] loss: 1.108
[35,     7] loss: 1.118
[36,     7] loss: 1.108
[37,     7] loss: 1.121
[38,     7] loss: 1.097
[39,     7] loss: 1.122
[40,     7] loss: 1.095
[41,     7] loss: 1.079
[42,     7] loss: 1.167
[43,     7] loss: 1.217
[44,     7] loss: 1.151
[45,     7] loss: 1.136
[46,     7] loss: 1.100
[47,     7] loss: 1.071
[48,     7] loss: 1.096
[49,     7] loss: 1.124
[50,     7] loss: 1.136
[51,     7] loss: 1.102
[52,     7] loss: 1.096
[53,     7] loss: 1.092
[54,     7] loss: 1.086
[55,     7] loss: 1.068
[56,     7] loss: 1.188
[57,     7] loss: 1.187
[58,     7] loss: 1.146
[59,     7] loss: 1.127
[60,     7] loss: 1.081
[61,     7] loss: 1.091
[62,     7] loss: 1.108
[63,     7] loss: 1.115
[64,     7] loss: 1.099
[65,     7] loss: 1.093
[66,     7] loss: 1.090
[67,     7] loss: 1.101
[68,     7] loss: 1.089
[69,     7] loss: 1.085
[70,     7] loss: 1.074
[71,     7] loss: 1.072
[72,     7] loss: 1.090
[73,     7] loss: 1.069
[74,     7] loss: 1.056
[75,     7] loss: 1.092
[76,     7] loss: 1.068
[77,     7] loss: 1.066
[78,     7] loss: 1.048
[79,     7] loss: 1.075
[80,     7] loss: 1.093
[81,     7] loss: 1.099
[82,     7] loss: 1.068
[83,     7] loss: 1.080
[84,     7] loss: 1.069
[85,     7] loss: 1.086
[86,     7] loss: 1.085
[87,     7] loss: 1.067
[88,     7] loss: 1.049
[89,     7] loss: 1.054
[90,     7] loss: 1.075
[91,     7] loss: 1.056
[92,     7] loss: 1.077
[93,     7] loss: 1.070
[94,     7] loss: 1.046
[95,     7] loss: 1.034
[96,     7] loss: 1.083
[97,     7] loss: 1.065
[98,     7] loss: 1.080
[99,     7] loss: 1.049
[100,     7] loss: 1.061
[101,     7] loss: 1.074
[102,     7] loss: 1.046
[103,     7] loss: 1.050
[104,     7] loss: 1.073
[105,     7] loss: 1.054
Early stopping applied (best metric=0.40146225690841675)
Finished Training
Total time taken: 103.09210681915283
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.371
[3,     7] loss: 1.340
[4,     7] loss: 1.320
[5,     7] loss: 1.296
[6,     7] loss: 1.299
[7,     7] loss: 1.298
[8,     7] loss: 1.275
[9,     7] loss: 1.268
[10,     7] loss: 1.254
[11,     7] loss: 1.244
[12,     7] loss: 1.256
[13,     7] loss: 1.271
[14,     7] loss: 1.247
[15,     7] loss: 1.230
[16,     7] loss: 1.226
[17,     7] loss: 1.223
[18,     7] loss: 1.223
[19,     7] loss: 1.196
[20,     7] loss: 1.192
[21,     7] loss: 1.179
[22,     7] loss: 1.201
[23,     7] loss: 1.182
[24,     7] loss: 1.139
[25,     7] loss: 1.158
[26,     7] loss: 1.141
[27,     7] loss: 1.138
[28,     7] loss: 1.121
[29,     7] loss: 1.131
[30,     7] loss: 1.124
[31,     7] loss: 1.166
[32,     7] loss: 1.129
[33,     7] loss: 1.143
[34,     7] loss: 1.131
[35,     7] loss: 1.129
[36,     7] loss: 1.105
[37,     7] loss: 1.082
[38,     7] loss: 1.109
[39,     7] loss: 1.105
[40,     7] loss: 1.084
[41,     7] loss: 1.084
[42,     7] loss: 1.142
[43,     7] loss: 1.109
[44,     7] loss: 1.110
[45,     7] loss: 1.083
[46,     7] loss: 1.102
[47,     7] loss: 1.099
[48,     7] loss: 1.079
[49,     7] loss: 1.094
[50,     7] loss: 1.093
[51,     7] loss: 1.083
[52,     7] loss: 1.206
[53,     7] loss: 1.159
[54,     7] loss: 1.141
[55,     7] loss: 1.107
[56,     7] loss: 1.114
[57,     7] loss: 1.112
[58,     7] loss: 1.080
[59,     7] loss: 1.077
[60,     7] loss: 1.095
[61,     7] loss: 1.119
[62,     7] loss: 1.096
[63,     7] loss: 1.087
[64,     7] loss: 1.094
[65,     7] loss: 1.076
[66,     7] loss: 1.070
[67,     7] loss: 1.098
[68,     7] loss: 1.090
[69,     7] loss: 1.107
[70,     7] loss: 1.171
[71,     7] loss: 1.140
[72,     7] loss: 1.105
[73,     7] loss: 1.062
[74,     7] loss: 1.093
[75,     7] loss: 1.108
[76,     7] loss: 1.111
[77,     7] loss: 1.105
[78,     7] loss: 1.062
[79,     7] loss: 1.077
[80,     7] loss: 1.073
[81,     7] loss: 1.113
[82,     7] loss: 1.085
[83,     7] loss: 1.061
Early stopping applied (best metric=0.4301781952381134)
Finished Training
Total time taken: 79.27062892913818
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.398
[2,     7] loss: 1.387
[3,     7] loss: 1.385
[4,     7] loss: 1.378
[5,     7] loss: 1.341
[6,     7] loss: 1.331
[7,     7] loss: 1.323
[8,     7] loss: 1.307
[9,     7] loss: 1.292
[10,     7] loss: 1.273
[11,     7] loss: 1.285
[12,     7] loss: 1.274
[13,     7] loss: 1.255
[14,     7] loss: 1.264
[15,     7] loss: 1.233
[16,     7] loss: 1.233
[17,     7] loss: 1.241
[18,     7] loss: 1.224
[19,     7] loss: 1.250
[20,     7] loss: 1.246
[21,     7] loss: 1.245
[22,     7] loss: 1.217
[23,     7] loss: 1.203
[24,     7] loss: 1.202
[25,     7] loss: 1.207
[26,     7] loss: 1.197
[27,     7] loss: 1.180
[28,     7] loss: 1.166
[29,     7] loss: 1.165
[30,     7] loss: 1.141
[31,     7] loss: 1.139
[32,     7] loss: 1.177
[33,     7] loss: 1.200
[34,     7] loss: 1.167
[35,     7] loss: 1.143
[36,     7] loss: 1.131
[37,     7] loss: 1.151
[38,     7] loss: 1.124
[39,     7] loss: 1.138
[40,     7] loss: 1.108
[41,     7] loss: 1.116
[42,     7] loss: 1.167
[43,     7] loss: 1.126
[44,     7] loss: 1.117
[45,     7] loss: 1.129
[46,     7] loss: 1.154
[47,     7] loss: 1.123
[48,     7] loss: 1.131
[49,     7] loss: 1.105
[50,     7] loss: 1.110
[51,     7] loss: 1.132
[52,     7] loss: 1.179
[53,     7] loss: 1.181
[54,     7] loss: 1.165
[55,     7] loss: 1.121
[56,     7] loss: 1.118
[57,     7] loss: 1.107
[58,     7] loss: 1.079
[59,     7] loss: 1.200
[60,     7] loss: 1.177
[61,     7] loss: 1.138
[62,     7] loss: 1.090
[63,     7] loss: 1.116
[64,     7] loss: 1.093
[65,     7] loss: 1.112
[66,     7] loss: 1.085
[67,     7] loss: 1.073
[68,     7] loss: 1.190
[69,     7] loss: 1.147
[70,     7] loss: 1.119
[71,     7] loss: 1.088
[72,     7] loss: 1.125
[73,     7] loss: 1.157
[74,     7] loss: 1.105
[75,     7] loss: 1.088
[76,     7] loss: 1.086
[77,     7] loss: 1.094
[78,     7] loss: 1.105
[79,     7] loss: 1.069
[80,     7] loss: 1.082
[81,     7] loss: 1.120
[82,     7] loss: 1.104
[83,     7] loss: 1.101
[84,     7] loss: 1.079
[85,     7] loss: 1.074
[86,     7] loss: 1.164
[87,     7] loss: 1.096
[88,     7] loss: 1.076
Early stopping applied (best metric=0.35283926129341125)
Finished Training
Total time taken: 89.49900126457214
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.379
[3,     7] loss: 1.345
[4,     7] loss: 1.323
[5,     7] loss: 1.316
[6,     7] loss: 1.302
[7,     7] loss: 1.295
[8,     7] loss: 1.296
[9,     7] loss: 1.288
[10,     7] loss: 1.264
[11,     7] loss: 1.258
[12,     7] loss: 1.274
[13,     7] loss: 1.262
[14,     7] loss: 1.258
[15,     7] loss: 1.242
[16,     7] loss: 1.234
[17,     7] loss: 1.231
[18,     7] loss: 1.224
[19,     7] loss: 1.237
[20,     7] loss: 1.236
[21,     7] loss: 1.227
[22,     7] loss: 1.222
[23,     7] loss: 1.200
[24,     7] loss: 1.193
[25,     7] loss: 1.199
[26,     7] loss: 1.189
[27,     7] loss: 1.182
[28,     7] loss: 1.167
[29,     7] loss: 1.169
[30,     7] loss: 1.153
[31,     7] loss: 1.173
[32,     7] loss: 1.132
[33,     7] loss: 1.096
[34,     7] loss: 1.193
[35,     7] loss: 1.190
[36,     7] loss: 1.155
[37,     7] loss: 1.126
[38,     7] loss: 1.111
[39,     7] loss: 1.105
[40,     7] loss: 1.116
[41,     7] loss: 1.118
[42,     7] loss: 1.194
[43,     7] loss: 1.120
[44,     7] loss: 1.083
[45,     7] loss: 1.125
[46,     7] loss: 1.102
[47,     7] loss: 1.097
[48,     7] loss: 1.137
[49,     7] loss: 1.158
[50,     7] loss: 1.119
[51,     7] loss: 1.106
[52,     7] loss: 1.095
[53,     7] loss: 1.099
[54,     7] loss: 1.084
[55,     7] loss: 1.089
[56,     7] loss: 1.065
[57,     7] loss: 1.139
[58,     7] loss: 1.103
[59,     7] loss: 1.106
[60,     7] loss: 1.088
[61,     7] loss: 1.047
[62,     7] loss: 1.129
[63,     7] loss: 1.089
[64,     7] loss: 1.079
[65,     7] loss: 1.058
[66,     7] loss: 1.051
[67,     7] loss: 1.094
[68,     7] loss: 1.084
[69,     7] loss: 1.086
[70,     7] loss: 1.069
[71,     7] loss: 1.067
[72,     7] loss: 1.076
[73,     7] loss: 1.061
[74,     7] loss: 1.124
[75,     7] loss: 1.129
[76,     7] loss: 1.085
[77,     7] loss: 1.065
[78,     7] loss: 1.039
[79,     7] loss: 1.072
[80,     7] loss: 1.083
[81,     7] loss: 1.074
[82,     7] loss: 1.052
[83,     7] loss: 1.092
[84,     7] loss: 1.081
[85,     7] loss: 1.101
[86,     7] loss: 1.068
[87,     7] loss: 1.078
[88,     7] loss: 1.058
[89,     7] loss: 1.057
[90,     7] loss: 1.051
[91,     7] loss: 1.112
[92,     7] loss: 1.206
[93,     7] loss: 1.153
[94,     7] loss: 1.106
[95,     7] loss: 1.075
[96,     7] loss: 1.086
[97,     7] loss: 1.105
[98,     7] loss: 1.086
[99,     7] loss: 1.068
[100,     7] loss: 1.071
[101,     7] loss: 1.059
[102,     7] loss: 1.071
Early stopping applied (best metric=0.4161321222782135)
Finished Training
Total time taken: 93.19946360588074
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.393
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.385
[5,     7] loss: 1.374
[6,     7] loss: 1.351
[7,     7] loss: 1.333
[8,     7] loss: 1.330
[9,     7] loss: 1.290
[10,     7] loss: 1.304
[11,     7] loss: 1.281
[12,     7] loss: 1.268
[13,     7] loss: 1.261
[14,     7] loss: 1.260
[15,     7] loss: 1.278
[16,     7] loss: 1.255
[17,     7] loss: 1.245
[18,     7] loss: 1.245
[19,     7] loss: 1.220
[20,     7] loss: 1.210
[21,     7] loss: 1.211
[22,     7] loss: 1.221
[23,     7] loss: 1.214
[24,     7] loss: 1.200
[25,     7] loss: 1.202
[26,     7] loss: 1.169
[27,     7] loss: 1.207
[28,     7] loss: 1.203
[29,     7] loss: 1.195
[30,     7] loss: 1.184
[31,     7] loss: 1.152
[32,     7] loss: 1.127
[33,     7] loss: 1.244
[34,     7] loss: 1.190
[35,     7] loss: 1.150
[36,     7] loss: 1.154
[37,     7] loss: 1.135
[38,     7] loss: 1.139
[39,     7] loss: 1.102
[40,     7] loss: 1.149
[41,     7] loss: 1.136
[42,     7] loss: 1.116
[43,     7] loss: 1.114
[44,     7] loss: 1.165
[45,     7] loss: 1.160
[46,     7] loss: 1.135
[47,     7] loss: 1.109
[48,     7] loss: 1.085
[49,     7] loss: 1.112
[50,     7] loss: 1.127
[51,     7] loss: 1.101
[52,     7] loss: 1.104
[53,     7] loss: 1.107
[54,     7] loss: 1.097
[55,     7] loss: 1.108
[56,     7] loss: 1.094
[57,     7] loss: 1.072
[58,     7] loss: 1.143
[59,     7] loss: 1.093
[60,     7] loss: 1.122
[61,     7] loss: 1.117
[62,     7] loss: 1.100
[63,     7] loss: 1.080
[64,     7] loss: 1.079
[65,     7] loss: 1.076
[66,     7] loss: 1.168
[67,     7] loss: 1.257
[68,     7] loss: 1.300
[69,     7] loss: 1.261
[70,     7] loss: 1.208
[71,     7] loss: 1.177
[72,     7] loss: 1.144
[73,     7] loss: 1.108
[74,     7] loss: 1.105
[75,     7] loss: 1.155
[76,     7] loss: 1.131
[77,     7] loss: 1.105
[78,     7] loss: 1.113
[79,     7] loss: 1.119
[80,     7] loss: 1.131
[81,     7] loss: 1.109
[82,     7] loss: 1.079
[83,     7] loss: 1.109
[84,     7] loss: 1.116
[85,     7] loss: 1.091
[86,     7] loss: 1.082
[87,     7] loss: 1.075
[88,     7] loss: 1.181
[89,     7] loss: 1.143
[90,     7] loss: 1.143
[91,     7] loss: 1.126
[92,     7] loss: 1.088
[93,     7] loss: 1.125
[94,     7] loss: 1.097
[95,     7] loss: 1.072
[96,     7] loss: 1.077
[97,     7] loss: 1.087
[98,     7] loss: 1.069
[99,     7] loss: 1.078
[100,     7] loss: 1.073
[101,     7] loss: 1.095
[102,     7] loss: 1.114
[103,     7] loss: 1.086
[104,     7] loss: 1.080
[105,     7] loss: 1.052
[106,     7] loss: 1.121
[107,     7] loss: 1.123
[108,     7] loss: 1.093
[109,     7] loss: 1.094
Early stopping applied (best metric=0.36198854446411133)
Finished Training
Total time taken: 100.22148180007935
{'Methylation-R Validation Accuracy': 0.5884246217014586, 'Methylation-R Validation Sensitivity': 0.8317738770822986, 'Methylation-R Validation Specificity': 0.5659141104294478, 'Methylation-R Validation Precision': 0.15475895487473107, 'Methylation-R AUC ROC': 0.7997797895657609, 'Methylation-R AUC PR': 0.36007443329323363, 'Methylation-R MCC': 0.22631909086733304, 'Methylation-R F1': 0.2596782415570613, 'Validation Loss (Methylation-R)': 0.3068701207637787, 'Methylation-K Validation Accuracy': 0.4846818218655507, 'Methylation-K Validation Sensitivity': 0.7680322273247266, 'Methylation-K Validation Specificity': 0.45395364116979847, 'Methylation-K Validation Precision': 0.13326280870075374, 'Methylation-K AUC ROC': 0.6658768100971518, 'Methylation-K AUC PR': 0.1758539537455275, 'Methylation-K MCC': 0.13508428526358887, 'Methylation-K F1': 0.226410882531392, 'Validation Loss (Methylation-K)': 0.3925200760364532, 'Validation Loss (total)': 0.6993902087211609, 'TimeToTrain': 93.05653648376465}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012089927209159223,
 'learning_rate_Methylation-K': 0.004188015973831132,
 'learning_rate_Methylation-R': 0.00018412647050705292,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7381020407693786,
 'loss_weight_Methylation-R': 0.607372319773187,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 533351713,
 'sample_weights': [0.7133515182830237, 0.3933672952931805],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.4313721025196022,
 'weight_decay_Methylation-K': 3.3708657161219038,
 'weight_decay_Methylation-R': 8.593245588395092}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.382
[3,     7] loss: 1.362
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023943920604619718,
 'learning_rate_Methylation-K': 0.006737218089296484,
 'learning_rate_Methylation-R': 0.0011889612913807716,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8893686010078783,
 'loss_weight_Methylation-R': 0.564313107006847,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 674296986,
 'sample_weights': [0.607372319773187, 0.7381020407693786],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6224121121976061,
 'weight_decay_Methylation-K': 4.2675305125515655,
 'weight_decay_Methylation-R': 7.789921498113827}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.385
[3,     7] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022209725617630192,
 'learning_rate_Methylation-K': 0.0032504877035508407,
 'learning_rate_Methylation-R': 0.0025844620843867134,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.400523140663125,
 'loss_weight_Methylation-R': 0.7773892762354832,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3944084037,
 'sample_weights': [0.564313107006847, 0.8893686010078783],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.588668208134755,
 'weight_decay_Methylation-K': 6.227440682447004,
 'weight_decay_Methylation-R': 1.5293762228174184}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.383
[4,     7] loss: 1.357
[5,     7] loss: 1.332
[6,     7] loss: 1.317
[7,     7] loss: 1.310
[8,     7] loss: 1.298
[9,     7] loss: 1.293
[10,     7] loss: 1.296
[11,     7] loss: 1.266
[12,     7] loss: 1.242
[13,     7] loss: 1.238
[14,     7] loss: 1.237
[15,     7] loss: 1.258
[16,     7] loss: 1.248
[17,     7] loss: 1.234
[18,     7] loss: 1.213
[19,     7] loss: 1.210
[20,     7] loss: 1.207
[21,     7] loss: 1.211
[22,     7] loss: 1.219
[23,     7] loss: 1.187
[24,     7] loss: 1.175
[25,     7] loss: 1.178
[26,     7] loss: 1.188
[27,     7] loss: 1.160
[28,     7] loss: 1.149
[29,     7] loss: 1.137
[30,     7] loss: 1.127
[31,     7] loss: 1.106
[32,     7] loss: 1.127
[33,     7] loss: 1.124
[34,     7] loss: 1.128
[35,     7] loss: 1.094
[36,     7] loss: 1.070
[37,     7] loss: 1.081
[38,     7] loss: 1.072
[39,     7] loss: 1.090
[40,     7] loss: 1.087
[41,     7] loss: 1.097
[42,     7] loss: 1.081
[43,     7] loss: 1.065
[44,     7] loss: 1.045
[45,     7] loss: 1.040
[46,     7] loss: 1.019
[47,     7] loss: 1.054
[48,     7] loss: 1.077
[49,     7] loss: 1.068
[50,     7] loss: 1.048
[51,     7] loss: 1.044
[52,     7] loss: 1.007
[53,     7] loss: 1.022
[54,     7] loss: 1.017
[55,     7] loss: 1.090
[56,     7] loss: 1.074
[57,     7] loss: 1.063
[58,     7] loss: 1.023
[59,     7] loss: 1.000
[60,     7] loss: 1.033
[61,     7] loss: 1.022
[62,     7] loss: 1.041
[63,     7] loss: 1.057
[64,     7] loss: 1.041
[65,     7] loss: 1.039
[66,     7] loss: 1.039
[67,     7] loss: 1.000
[68,     7] loss: 1.021
[69,     7] loss: 1.017
[70,     7] loss: 1.005
[71,     7] loss: 1.039
[72,     7] loss: 1.040
[73,     7] loss: 1.005
[74,     7] loss: 1.006
[75,     7] loss: 1.018
[76,     7] loss: 1.015
[77,     7] loss: 1.045
Early stopping applied (best metric=0.4172859787940979)
Finished Training
Total time taken: 69.93682098388672
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.371
[3,     7] loss: 1.337
[4,     7] loss: 1.332
[5,     7] loss: 1.308
[6,     7] loss: 1.304
[7,     7] loss: 1.295
[8,     7] loss: 1.271
[9,     7] loss: 1.272
[10,     7] loss: 1.252
[11,     7] loss: 1.259
[12,     7] loss: 1.270
[13,     7] loss: 1.247
[14,     7] loss: 1.252
[15,     7] loss: 1.212
[16,     7] loss: 1.232
[17,     7] loss: 1.216
[18,     7] loss: 1.220
[19,     7] loss: 1.202
[20,     7] loss: 1.227
[21,     7] loss: 1.209
[22,     7] loss: 1.190
[23,     7] loss: 1.202
[24,     7] loss: 1.173
[25,     7] loss: 1.164
[26,     7] loss: 1.176
[27,     7] loss: 1.160
[28,     7] loss: 1.166
[29,     7] loss: 1.135
[30,     7] loss: 1.147
[31,     7] loss: 1.160
[32,     7] loss: 1.158
[33,     7] loss: 1.119
[34,     7] loss: 1.117
[35,     7] loss: 1.088
[36,     7] loss: 1.123
[37,     7] loss: 1.115
[38,     7] loss: 1.120
[39,     7] loss: 1.109
[40,     7] loss: 1.090
[41,     7] loss: 1.071
[42,     7] loss: 1.059
[43,     7] loss: 1.057
[44,     7] loss: 1.064
[45,     7] loss: 1.070
[46,     7] loss: 1.075
[47,     7] loss: 1.072
[48,     7] loss: 1.047
[49,     7] loss: 1.036
[50,     7] loss: 1.101
[51,     7] loss: 1.047
[52,     7] loss: 1.044
[53,     7] loss: 1.038
[54,     7] loss: 1.072
[55,     7] loss: 1.038
[56,     7] loss: 1.068
[57,     7] loss: 1.087
[58,     7] loss: 1.099
[59,     7] loss: 1.048
[60,     7] loss: 1.031
[61,     7] loss: 1.017
[62,     7] loss: 1.016
[63,     7] loss: 1.023
[64,     7] loss: 1.072
[65,     7] loss: 1.060
[66,     7] loss: 1.032
[67,     7] loss: 1.029
[68,     7] loss: 1.068
[69,     7] loss: 1.041
[70,     7] loss: 1.022
[71,     7] loss: 1.038
[72,     7] loss: 1.047
[73,     7] loss: 1.079
[74,     7] loss: 1.038
[75,     7] loss: 1.022
[76,     7] loss: 1.013
[77,     7] loss: 1.084
[78,     7] loss: 1.063
[79,     7] loss: 1.041
[80,     7] loss: 1.038
[81,     7] loss: 1.029
[82,     7] loss: 1.041
[83,     7] loss: 1.037
[84,     7] loss: 1.040
[85,     7] loss: 1.015
[86,     7] loss: 1.025
Early stopping applied (best metric=0.37722545862197876)
Finished Training
Total time taken: 75.23870372772217
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.384
[3,     7] loss: 1.366
[4,     7] loss: 1.329
[5,     7] loss: 1.323
[6,     7] loss: 1.307
[7,     7] loss: 1.291
[8,     7] loss: 1.279
[9,     7] loss: 1.281
[10,     7] loss: 1.256
[11,     7] loss: 1.251
[12,     7] loss: 1.244
[13,     7] loss: 1.249
[14,     7] loss: 1.240
[15,     7] loss: 1.239
[16,     7] loss: 1.223
[17,     7] loss: 1.232
[18,     7] loss: 1.234
[19,     7] loss: 1.229
[20,     7] loss: 1.222
[21,     7] loss: 1.202
[22,     7] loss: 1.201
[23,     7] loss: 1.211
[24,     7] loss: 1.215
[25,     7] loss: 1.221
[26,     7] loss: 1.180
[27,     7] loss: 1.188
[28,     7] loss: 1.167
[29,     7] loss: 1.167
[30,     7] loss: 1.183
[31,     7] loss: 1.173
[32,     7] loss: 1.164
[33,     7] loss: 1.167
[34,     7] loss: 1.137
[35,     7] loss: 1.116
[36,     7] loss: 1.137
[37,     7] loss: 1.115
[38,     7] loss: 1.110
[39,     7] loss: 1.083
[40,     7] loss: 1.125
[41,     7] loss: 1.135
[42,     7] loss: 1.117
[43,     7] loss: 1.103
[44,     7] loss: 1.068
[45,     7] loss: 1.086
[46,     7] loss: 1.076
[47,     7] loss: 1.065
[48,     7] loss: 1.068
[49,     7] loss: 1.051
[50,     7] loss: 1.078
[51,     7] loss: 1.093
[52,     7] loss: 1.059
[53,     7] loss: 1.068
[54,     7] loss: 1.064
[55,     7] loss: 1.039
[56,     7] loss: 1.039
[57,     7] loss: 1.048
[58,     7] loss: 1.053
[59,     7] loss: 1.057
[60,     7] loss: 1.070
[61,     7] loss: 1.019
[62,     7] loss: 1.046
[63,     7] loss: 1.039
[64,     7] loss: 1.052
[65,     7] loss: 1.054
[66,     7] loss: 1.052
[67,     7] loss: 1.025
[68,     7] loss: 1.085
[69,     7] loss: 1.030
[70,     7] loss: 1.047
[71,     7] loss: 1.043
[72,     7] loss: 1.097
[73,     7] loss: 1.052
[74,     7] loss: 1.039
[75,     7] loss: 1.024
[76,     7] loss: 1.040
[77,     7] loss: 1.022
[78,     7] loss: 1.014
[79,     7] loss: 1.040
[80,     7] loss: 1.017
[81,     7] loss: 1.030
[82,     7] loss: 1.048
[83,     7] loss: 1.060
[84,     7] loss: 1.070
[85,     7] loss: 1.052
[86,     7] loss: 1.021
[87,     7] loss: 1.037
[88,     7] loss: 1.077
[89,     7] loss: 1.048
[90,     7] loss: 1.030
[91,     7] loss: 1.026
[92,     7] loss: 1.077
[93,     7] loss: 1.072
[94,     7] loss: 1.075
[95,     7] loss: 1.051
[96,     7] loss: 1.007
[97,     7] loss: 1.033
[98,     7] loss: 1.041
[99,     7] loss: 1.018
[100,     7] loss: 1.024
[101,     7] loss: 1.015
[102,     7] loss: 1.136
[103,     7] loss: 1.123
[104,     7] loss: 1.054
[105,     7] loss: 1.044
[106,     7] loss: 1.016
[107,     7] loss: 1.015
[108,     7] loss: 1.014
[109,     7] loss: 1.036
[110,     7] loss: 1.043
[111,     7] loss: 1.053
[112,     7] loss: 1.016
[113,     7] loss: 0.993
[114,     7] loss: 1.054
[115,     7] loss: 1.028
[116,     7] loss: 1.027
[117,     7] loss: 1.054
[118,     7] loss: 1.034
[119,     7] loss: 1.020
[120,     7] loss: 1.018
[121,     7] loss: 1.002
[122,     7] loss: 1.023
[123,     7] loss: 0.999
[124,     7] loss: 0.991
[125,     7] loss: 1.020
[126,     7] loss: 1.053
[127,     7] loss: 1.050
[128,     7] loss: 1.012
[129,     7] loss: 1.014
[130,     7] loss: 1.013
[131,     7] loss: 0.981
[132,     7] loss: 1.012
[133,     7] loss: 1.041
[134,     7] loss: 1.051
Early stopping applied (best metric=0.3526601791381836)
Finished Training
Total time taken: 117.05134916305542
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.397
[2,     7] loss: 1.382
[3,     7] loss: 1.363
[4,     7] loss: 1.344
[5,     7] loss: 1.328
[6,     7] loss: 1.319
[7,     7] loss: 1.295
[8,     7] loss: 1.271
[9,     7] loss: 1.254
[10,     7] loss: 1.269
[11,     7] loss: 1.264
[12,     7] loss: 1.269
[13,     7] loss: 1.245
[14,     7] loss: 1.238
[15,     7] loss: 1.229
[16,     7] loss: 1.224
[17,     7] loss: 1.215
[18,     7] loss: 1.220
[19,     7] loss: 1.228
[20,     7] loss: 1.182
[21,     7] loss: 1.181
[22,     7] loss: 1.189
[23,     7] loss: 1.173
[24,     7] loss: 1.141
[25,     7] loss: 1.147
[26,     7] loss: 1.136
[27,     7] loss: 1.117
[28,     7] loss: 1.130
[29,     7] loss: 1.105
[30,     7] loss: 1.112
[31,     7] loss: 1.110
[32,     7] loss: 1.125
[33,     7] loss: 1.100
[34,     7] loss: 1.074
[35,     7] loss: 1.119
[36,     7] loss: 1.096
[37,     7] loss: 1.093
[38,     7] loss: 1.068
[39,     7] loss: 1.068
[40,     7] loss: 1.078
[41,     7] loss: 1.072
[42,     7] loss: 1.059
[43,     7] loss: 1.034
[44,     7] loss: 1.063
[45,     7] loss: 1.082
[46,     7] loss: 1.058
[47,     7] loss: 1.013
[48,     7] loss: 1.003
[49,     7] loss: 1.021
[50,     7] loss: 1.035
[51,     7] loss: 1.029
Early stopping applied (best metric=0.4482201933860779)
Finished Training
Total time taken: 44.096221923828125
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.388
[2,     7] loss: 1.382
[3,     7] loss: 1.352
[4,     7] loss: 1.329
[5,     7] loss: 1.320
[6,     7] loss: 1.313
[7,     7] loss: 1.302
[8,     7] loss: 1.294
[9,     7] loss: 1.287
[10,     7] loss: 1.260
[11,     7] loss: 1.253
[12,     7] loss: 1.258
[13,     7] loss: 1.243
[14,     7] loss: 1.222
[15,     7] loss: 1.228
[16,     7] loss: 1.232
[17,     7] loss: 1.217
[18,     7] loss: 1.212
[19,     7] loss: 1.215
[20,     7] loss: 1.242
[21,     7] loss: 1.218
[22,     7] loss: 1.203
[23,     7] loss: 1.207
[24,     7] loss: 1.182
[25,     7] loss: 1.191
[26,     7] loss: 1.176
[27,     7] loss: 1.185
[28,     7] loss: 1.163
[29,     7] loss: 1.169
[30,     7] loss: 1.188
[31,     7] loss: 1.159
[32,     7] loss: 1.120
[33,     7] loss: 1.110
[34,     7] loss: 1.127
[35,     7] loss: 1.102
[36,     7] loss: 1.109
[37,     7] loss: 1.137
[38,     7] loss: 1.114
[39,     7] loss: 1.112
[40,     7] loss: 1.078
[41,     7] loss: 1.056
[42,     7] loss: 1.092
[43,     7] loss: 1.093
[44,     7] loss: 1.071
[45,     7] loss: 1.084
[46,     7] loss: 1.086
[47,     7] loss: 1.058
[48,     7] loss: 1.068
[49,     7] loss: 1.070
[50,     7] loss: 1.062
[51,     7] loss: 1.041
Early stopping applied (best metric=0.4426051378250122)
Finished Training
Total time taken: 44.45543646812439
{'Methylation-R Validation Accuracy': 0.4334475674179908, 'Methylation-R Validation Sensitivity': 0.8811671087533156, 'Methylation-R Validation Specificity': 0.39204907975460124, 'Methylation-R Validation Precision': 0.1292499646348184, 'Methylation-R AUC ROC': 0.7553457500110811, 'Methylation-R AUC PR': 0.31818776593984743, 'Methylation-R MCC': 0.15783835555088535, 'Methylation-R F1': 0.2229744276815193, 'Validation Loss (Methylation-R)': 0.3522402584552765, 'Methylation-K Validation Accuracy': 0.42198257860898536, 'Methylation-K Validation Sensitivity': 0.7542596592272618, 'Methylation-K Validation Specificity': 0.3859584800228194, 'Methylation-K Validation Precision': 0.12156239493277451, 'Methylation-K AUC ROC': 0.6067087741252137, 'Methylation-K AUC PR': 0.15596827736457755, 'Methylation-K MCC': 0.0836692653309082, 'Methylation-K F1': 0.2077529926538429, 'Validation Loss (Methylation-K)': 0.40759938955307007, 'Validation Loss (total)': 0.759839653968811, 'TimeToTrain': 70.15570645332336}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023229202968811638,
 'learning_rate_Methylation-K': 0.004414162701515839,
 'learning_rate_Methylation-R': 0.0008812751594031926,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3912140739787681,
 'loss_weight_Methylation-R': 0.3119121964257144,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3589563948,
 'sample_weights': [0.7773892762354832, 0.400523140663125],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6463752824810478,
 'weight_decay_Methylation-K': 7.102929039470812,
 'weight_decay_Methylation-R': 3.339307580615924}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.385
[3,     7] loss: 1.367
[4,     7] loss: 1.337
[5,     7] loss: 1.332
[6,     7] loss: 1.326
[7,     7] loss: 1.312
[8,     7] loss: 1.299
[9,     7] loss: 1.292
[10,     7] loss: 1.281
[11,     7] loss: 1.284
[12,     7] loss: 1.288
[13,     7] loss: 1.266
[14,     7] loss: 1.255
[15,     7] loss: 1.260
[16,     7] loss: 1.246
[17,     7] loss: 1.231
[18,     7] loss: 1.246
[19,     7] loss: 1.243
[20,     7] loss: 1.240
[21,     7] loss: 1.229
[22,     7] loss: 1.224
[23,     7] loss: 1.215
[24,     7] loss: 1.223
[25,     7] loss: 1.199
[26,     7] loss: 1.197
[27,     7] loss: 1.205
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008480395416932818,
 'learning_rate_Methylation-K': 0.0006598484443336849,
 'learning_rate_Methylation-R': 0.009542183605031668,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2642617530611441,
 'loss_weight_Methylation-R': 0.6200051528808387,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1919706020,
 'sample_weights': [0.3119121964257144, 0.3912140739787681],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.4897973319394446,
 'weight_decay_Methylation-K': 4.7175925188252545,
 'weight_decay_Methylation-R': 9.408658253332467}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009765139809164724,
 'learning_rate_Methylation-K': 0.006811436632551979,
 'learning_rate_Methylation-R': 0.0007232049172069868,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.864809103368078,
 'loss_weight_Methylation-R': 0.00538485257762715,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4220530082,
 'sample_weights': [0.6200051528808387, 0.2642617530611441],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.918994965488142,
 'weight_decay_Methylation-K': 4.850390827978353,
 'weight_decay_Methylation-R': 1.8067537939648335}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008977742298609214,
 'learning_rate_Methylation-K': 0.0011155853570657035,
 'learning_rate_Methylation-R': 0.009510699776728962,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.27517606482050727,
 'loss_weight_Methylation-R': 0.42564292184956093,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4186474154,
 'sample_weights': [0.00538485257762715, 0.864809103368078],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.7455379719130875,
 'weight_decay_Methylation-K': 7.375319936215069,
 'weight_decay_Methylation-R': 9.187469070177727}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009780094375469247,
 'learning_rate_Methylation-K': 0.0015645392013513468,
 'learning_rate_Methylation-R': 0.009500964550406986,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.21219797468172247,
 'loss_weight_Methylation-R': 0.2980771640803337,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2555508157,
 'sample_weights': [0.42564292184956093, 0.27517606482050727],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.225936830515773,
 'weight_decay_Methylation-K': 5.494886900953624,
 'weight_decay_Methylation-R': 9.918850173044069}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009569934717346093,
 'learning_rate_Methylation-K': 0.001278750773481024,
 'learning_rate_Methylation-R': 0.00703447175158646,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.05508085037199957,
 'loss_weight_Methylation-R': 0.37022548283911416,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 894172975,
 'sample_weights': [0.2980771640803337, 0.21219797468172247],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.009149218227161,
 'weight_decay_Methylation-K': 8.119365285820708,
 'weight_decay_Methylation-R': 8.057922745134956}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.396
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0048112910569595504,
 'learning_rate_Methylation-K': 0.00370136047295131,
 'learning_rate_Methylation-R': 0.00020720047690915675,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5542995073156035,
 'loss_weight_Methylation-R': 0.4613811012408875,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3391035954,
 'sample_weights': [0.37022548283911416, 0.05508085037199957],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.369191510752977,
 'weight_decay_Methylation-K': 1.8643790090141392,
 'weight_decay_Methylation-R': 2.2190299259818653}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.383
[3,     7] loss: 1.351
[4,     7] loss: 1.332
[5,     7] loss: 1.315
[6,     7] loss: 1.300
[7,     7] loss: 1.277
[8,     7] loss: 1.298
[9,     7] loss: 1.276
[10,     7] loss: 1.268
[11,     7] loss: 1.276
[12,     7] loss: 1.243
[13,     7] loss: 1.248
[14,     7] loss: 1.238
[15,     7] loss: 1.267
[16,     7] loss: 1.295
[17,     7] loss: 1.303
[18,     7] loss: 1.276
[19,     7] loss: 1.272
[20,     7] loss: 1.235
[21,     7] loss: 1.270
[22,     7] loss: 1.246
[23,     7] loss: 1.246
[24,     7] loss: 1.245
[25,     7] loss: 1.256
[26,     7] loss: 1.302
[27,     7] loss: 1.302
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007888513977113848,
 'learning_rate_Methylation-K': 0.0023054008524123395,
 'learning_rate_Methylation-R': 0.0018966191312836645,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7423747409765453,
 'loss_weight_Methylation-R': 0.8793546013822992,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2392286596,
 'sample_weights': [0.4613811012408875, 0.5542995073156035],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.2687969063084035,
 'weight_decay_Methylation-K': 9.568908588902499,
 'weight_decay_Methylation-R': 6.587709256974218}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.384
[3,     7] loss: 1.378
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009505367525042368,
 'learning_rate_Methylation-K': 0.0034680335309266058,
 'learning_rate_Methylation-R': 0.006672582644822179,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1901801067552372,
 'loss_weight_Methylation-R': 0.8819522934560917,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2505027289,
 'sample_weights': [0.8793546013822992, 0.7423747409765453],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.4117931985823826,
 'weight_decay_Methylation-K': 6.597157853078565,
 'weight_decay_Methylation-R': 8.948378463926295}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002050614380846263,
 'learning_rate_Methylation-K': 0.004086544353213921,
 'learning_rate_Methylation-R': 0.0005542998786655863,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8861567854642187,
 'loss_weight_Methylation-R': 0.7189294505736469,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2111445694,
 'sample_weights': [0.8819522934560917, 0.1901801067552372],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.701199712832908,
 'weight_decay_Methylation-K': 4.74899998843004,
 'weight_decay_Methylation-R': 1.7070681119714939}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.385
[3,     7] loss: 1.380
[4,     7] loss: 1.348
[5,     7] loss: 1.327
[6,     7] loss: 1.329
[7,     7] loss: 1.304
[8,     7] loss: 1.291
[9,     7] loss: 1.284
[10,     7] loss: 1.272
[11,     7] loss: 1.250
[12,     7] loss: 1.263
[13,     7] loss: 1.233
[14,     7] loss: 1.203
[15,     7] loss: 1.193
[16,     7] loss: 1.185
[17,     7] loss: 1.164
[18,     7] loss: 1.166
[19,     7] loss: 1.150
[20,     7] loss: 1.168
[21,     7] loss: 1.145
[22,     7] loss: 1.115
[23,     7] loss: 1.117
[24,     7] loss: 1.124
[25,     7] loss: 1.106
[26,     7] loss: 1.093
[27,     7] loss: 1.098
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009307534120067788,
 'learning_rate_Methylation-K': 0.00021181593190463047,
 'learning_rate_Methylation-R': 0.00885347746147377,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.019397748252285976,
 'loss_weight_Methylation-R': 0.6348814913748786,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4138553392,
 'sample_weights': [0.7189294505736469, 0.8861567854642187],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.341277762752195,
 'weight_decay_Methylation-K': 7.250937437138556,
 'weight_decay_Methylation-R': 8.620642497560281}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.397
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.356
[6,     7] loss: 1.353
[7,     7] loss: 1.340
[8,     7] loss: 1.314
[9,     7] loss: 1.311
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009852299660526247,
 'learning_rate_Methylation-K': 0.007231697329856676,
 'learning_rate_Methylation-R': 0.007234916207917278,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5330670795588224,
 'loss_weight_Methylation-R': 0.23321470122441462,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4245175077,
 'sample_weights': [0.6348814913748786, 0.019397748252285976],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.0895566690309,
 'weight_decay_Methylation-K': 3.8935984933801158,
 'weight_decay_Methylation-R': 8.884030949279868}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00564097055613199,
 'learning_rate_Methylation-K': 0.004951998735529547,
 'learning_rate_Methylation-R': 0.0009272335042568927,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.08685548541627183,
 'loss_weight_Methylation-R': 0.811837143802913,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3464140294,
 'sample_weights': [0.23321470122441462, 0.5330670795588224],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.7681874335296985,
 'weight_decay_Methylation-K': 5.399896100469414,
 'weight_decay_Methylation-R': 2.337078587953009}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.377
[4,     7] loss: 1.340
[5,     7] loss: 1.315
[6,     7] loss: 1.310
[7,     7] loss: 1.287
[8,     7] loss: 1.285
[9,     7] loss: 1.281
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007205978280876584,
 'learning_rate_Methylation-K': 0.006958170223634487,
 'learning_rate_Methylation-R': 0.0026419558645518672,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1046593256530949,
 'loss_weight_Methylation-R': 0.47049277987305327,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3472854222,
 'sample_weights': [0.811837143802913, 0.08685548541627183],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.186863943973689,
 'weight_decay_Methylation-K': 9.409197538548264,
 'weight_decay_Methylation-R': 0.544940653129925}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.396
[2,     7] loss: 1.386
[3,     7] loss: 1.383
[4,     7] loss: 1.362
[5,     7] loss: 1.330
[6,     7] loss: 1.326
[7,     7] loss: 1.315
[8,     7] loss: 1.328
[9,     7] loss: 1.305
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0057681405165111894,
 'learning_rate_Methylation-K': 0.001821197506775857,
 'learning_rate_Methylation-R': 0.0008882802877627546,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3123144792783402,
 'loss_weight_Methylation-R': 0.6926369915456096,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3774705716,
 'sample_weights': [0.47049277987305327, 0.1046593256530949],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.005394143145165,
 'weight_decay_Methylation-K': 4.92315058848669,
 'weight_decay_Methylation-R': 5.867862378934978}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.385
[11,     7] loss: 1.367
[12,     7] loss: 1.347
[13,     7] loss: 1.327
[14,     7] loss: 1.302
[15,     7] loss: 1.297
[16,     7] loss: 1.291
[17,     7] loss: 1.284
[18,     7] loss: 1.265
[19,     7] loss: 1.251
[20,     7] loss: 1.252
[21,     7] loss: 1.244
[22,     7] loss: 1.243
[23,     7] loss: 1.234
[24,     7] loss: 1.217
[25,     7] loss: 1.214
[26,     7] loss: 1.235
[27,     7] loss: 1.236
[28,     7] loss: 1.238
[29,     7] loss: 1.222
[30,     7] loss: 1.197
[31,     7] loss: 1.215
[32,     7] loss: 1.223
[33,     7] loss: 1.182
[34,     7] loss: 1.186
[35,     7] loss: 1.180
[36,     7] loss: 1.150
[37,     7] loss: 1.261
[38,     7] loss: 1.333
[39,     7] loss: 1.320
[40,     7] loss: 1.268
[41,     7] loss: 1.218
[42,     7] loss: 1.200
[43,     7] loss: 1.244
[44,     7] loss: 1.218
[45,     7] loss: 1.189
[46,     7] loss: 1.179
[47,     7] loss: 1.211
[48,     7] loss: 1.216
[49,     7] loss: 1.188
[50,     7] loss: 1.179
[51,     7] loss: 1.169
[52,     7] loss: 1.200
[53,     7] loss: 1.192
[54,     7] loss: 1.152
[55,     7] loss: 1.159
[56,     7] loss: 1.157
[57,     7] loss: 1.168
[58,     7] loss: 1.165
[59,     7] loss: 1.165
[60,     7] loss: 1.161
[61,     7] loss: 1.155
[62,     7] loss: 1.202
[63,     7] loss: 1.191
[64,     7] loss: 1.229
[65,     7] loss: 1.214
[66,     7] loss: 1.188
[67,     7] loss: 1.165
[68,     7] loss: 1.142
[69,     7] loss: 1.152
[70,     7] loss: 1.123
[71,     7] loss: 1.158
[72,     7] loss: 1.224
[73,     7] loss: 1.190
[74,     7] loss: 1.196
[75,     7] loss: 1.166
[76,     7] loss: 1.147
Early stopping applied (best metric=0.37743470072746277)
Finished Training
Total time taken: 66.66850900650024
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.383
[3,     7] loss: 1.363
[4,     7] loss: 1.331
[5,     7] loss: 1.325
[6,     7] loss: 1.319
[7,     7] loss: 1.288
[8,     7] loss: 1.279
[9,     7] loss: 1.266
[10,     7] loss: 1.280
[11,     7] loss: 1.257
[12,     7] loss: 1.245
[13,     7] loss: 1.247
[14,     7] loss: 1.250
[15,     7] loss: 1.274
[16,     7] loss: 1.254
[17,     7] loss: 1.239
[18,     7] loss: 1.235
[19,     7] loss: 1.259
[20,     7] loss: 1.263
[21,     7] loss: 1.243
[22,     7] loss: 1.233
[23,     7] loss: 1.227
[24,     7] loss: 1.227
[25,     7] loss: 1.226
[26,     7] loss: 1.210
[27,     7] loss: 1.258
[28,     7] loss: 1.256
[29,     7] loss: 1.247
[30,     7] loss: 1.215
[31,     7] loss: 1.221
[32,     7] loss: 1.236
[33,     7] loss: 1.241
[34,     7] loss: 1.215
[35,     7] loss: 1.195
[36,     7] loss: 1.211
[37,     7] loss: 1.196
[38,     7] loss: 1.215
[39,     7] loss: 1.203
[40,     7] loss: 1.172
[41,     7] loss: 1.173
[42,     7] loss: 1.321
[43,     7] loss: 1.267
[44,     7] loss: 1.269
[45,     7] loss: 1.228
[46,     7] loss: 1.202
[47,     7] loss: 1.285
[48,     7] loss: 1.319
[49,     7] loss: 1.280
[50,     7] loss: 1.256
[51,     7] loss: 1.231
[52,     7] loss: 1.207
[53,     7] loss: 1.293
[54,     7] loss: 1.349
[55,     7] loss: 1.370
[56,     7] loss: 1.358
[57,     7] loss: 1.346
[58,     7] loss: 1.328
[59,     7] loss: 1.333
[60,     7] loss: 1.323
[61,     7] loss: 1.316
[62,     7] loss: 1.307
[63,     7] loss: 1.301
[64,     7] loss: 1.331
[65,     7] loss: 1.301
[66,     7] loss: 1.301
[67,     7] loss: 1.287
[68,     7] loss: 1.283
[69,     7] loss: 1.283
[70,     7] loss: 1.283
[71,     7] loss: 1.259
[72,     7] loss: 1.295
[73,     7] loss: 1.404
[74,     7] loss: 1.354
[75,     7] loss: 1.350
[76,     7] loss: 1.347
[77,     7] loss: 1.329
[78,     7] loss: 1.321
[79,     7] loss: 1.307
[80,     7] loss: 1.314
[81,     7] loss: 1.312
[82,     7] loss: 1.307
[83,     7] loss: 1.298
[84,     7] loss: 1.280
[85,     7] loss: 1.280
[86,     7] loss: 1.294
[87,     7] loss: 1.306
Early stopping applied (best metric=0.35937124490737915)
Finished Training
Total time taken: 76.27803874015808
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.388
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.383
[14,     7] loss: 1.367
[15,     7] loss: 1.334
[16,     7] loss: 1.319
[17,     7] loss: 1.296
[18,     7] loss: 1.287
[19,     7] loss: 1.283
[20,     7] loss: 1.266
[21,     7] loss: 1.245
[22,     7] loss: 1.265
[23,     7] loss: 1.250
[24,     7] loss: 1.243
[25,     7] loss: 1.230
[26,     7] loss: 1.253
[27,     7] loss: 1.243
[28,     7] loss: 1.218
[29,     7] loss: 1.216
[30,     7] loss: 1.240
[31,     7] loss: 1.227
[32,     7] loss: 1.270
[33,     7] loss: 1.252
[34,     7] loss: 1.230
[35,     7] loss: 1.228
[36,     7] loss: 1.211
[37,     7] loss: 1.207
[38,     7] loss: 1.253
[39,     7] loss: 1.340
[40,     7] loss: 1.375
[41,     7] loss: 1.387
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.387
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
Early stopping applied (best metric=0.41920727491378784)
Finished Training
Total time taken: 75.03423142433167
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.385
[6,     7] loss: 1.376
[7,     7] loss: 1.345
[8,     7] loss: 1.326
[9,     7] loss: 1.301
[10,     7] loss: 1.289
[11,     7] loss: 1.281
[12,     7] loss: 1.279
[13,     7] loss: 1.272
[14,     7] loss: 1.245
[15,     7] loss: 1.244
[16,     7] loss: 1.248
[17,     7] loss: 1.261
[18,     7] loss: 1.266
[19,     7] loss: 1.236
[20,     7] loss: 1.217
[21,     7] loss: 1.260
[22,     7] loss: 1.265
[23,     7] loss: 1.240
[24,     7] loss: 1.234
[25,     7] loss: 1.232
[26,     7] loss: 1.203
[27,     7] loss: 1.205
[28,     7] loss: 1.303
[29,     7] loss: 1.279
[30,     7] loss: 1.247
[31,     7] loss: 1.209
[32,     7] loss: 1.203
[33,     7] loss: 1.201
[34,     7] loss: 1.368
[35,     7] loss: 1.348
[36,     7] loss: 1.308
[37,     7] loss: 1.304
[38,     7] loss: 1.265
[39,     7] loss: 1.216
[40,     7] loss: 1.197
[41,     7] loss: 1.260
[42,     7] loss: 1.208
[43,     7] loss: 1.179
[44,     7] loss: 1.167
[45,     7] loss: 1.162
[46,     7] loss: 1.153
[47,     7] loss: 1.147
[48,     7] loss: 1.231
[49,     7] loss: 1.246
[50,     7] loss: 1.215
[51,     7] loss: 1.201
[52,     7] loss: 1.174
[53,     7] loss: 1.160
[54,     7] loss: 1.163
[55,     7] loss: 1.140
[56,     7] loss: 1.169
[57,     7] loss: 1.161
[58,     7] loss: 1.177
[59,     7] loss: 1.140
[60,     7] loss: 1.157
[61,     7] loss: 1.124
[62,     7] loss: 1.134
[63,     7] loss: 1.155
[64,     7] loss: 1.201
[65,     7] loss: 1.262
[66,     7] loss: 1.268
[67,     7] loss: 1.220
[68,     7] loss: 1.179
[69,     7] loss: 1.203
[70,     7] loss: 1.259
[71,     7] loss: 1.321
[72,     7] loss: 1.255
[73,     7] loss: 1.221
[74,     7] loss: 1.199
[75,     7] loss: 1.196
[76,     7] loss: 1.182
[77,     7] loss: 1.192
[78,     7] loss: 1.172
[79,     7] loss: 1.155
[80,     7] loss: 1.174
[81,     7] loss: 1.148
[82,     7] loss: 1.143
[83,     7] loss: 1.161
Early stopping applied (best metric=0.37454667687416077)
Finished Training
Total time taken: 72.75561881065369
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.385
[6,     7] loss: 1.369
[7,     7] loss: 1.338
[8,     7] loss: 1.315
[9,     7] loss: 1.297
[10,     7] loss: 1.299
[11,     7] loss: 1.293
[12,     7] loss: 1.272
[13,     7] loss: 1.254
[14,     7] loss: 1.260
[15,     7] loss: 1.253
[16,     7] loss: 1.248
[17,     7] loss: 1.251
[18,     7] loss: 1.239
[19,     7] loss: 1.238
[20,     7] loss: 1.229
[21,     7] loss: 1.246
[22,     7] loss: 1.222
[23,     7] loss: 1.226
[24,     7] loss: 1.230
[25,     7] loss: 1.251
[26,     7] loss: 1.252
[27,     7] loss: 1.244
[28,     7] loss: 1.224
[29,     7] loss: 1.220
[30,     7] loss: 1.213
[31,     7] loss: 1.237
[32,     7] loss: 1.213
[33,     7] loss: 1.215
[34,     7] loss: 1.311
[35,     7] loss: 1.359
[36,     7] loss: 1.340
[37,     7] loss: 1.300
[38,     7] loss: 1.273
[39,     7] loss: 1.273
[40,     7] loss: 1.256
[41,     7] loss: 1.264
[42,     7] loss: 1.258
[43,     7] loss: 1.211
[44,     7] loss: 1.214
[45,     7] loss: 1.215
[46,     7] loss: 1.223
[47,     7] loss: 1.192
[48,     7] loss: 1.236
[49,     7] loss: 1.235
[50,     7] loss: 1.203
[51,     7] loss: 1.187
[52,     7] loss: 1.177
[53,     7] loss: 1.226
[54,     7] loss: 1.268
[55,     7] loss: 1.229
[56,     7] loss: 1.200
[57,     7] loss: 1.191
[58,     7] loss: 1.175
[59,     7] loss: 1.240
[60,     7] loss: 1.232
[61,     7] loss: 1.237
[62,     7] loss: 1.197
[63,     7] loss: 1.197
[64,     7] loss: 1.220
[65,     7] loss: 1.197
[66,     7] loss: 1.187
[67,     7] loss: 1.202
[68,     7] loss: 1.180
[69,     7] loss: 1.196
[70,     7] loss: 1.166
[71,     7] loss: 1.184
[72,     7] loss: 1.223
[73,     7] loss: 1.245
[74,     7] loss: 1.200
[75,     7] loss: 1.185
[76,     7] loss: 1.172
[77,     7] loss: 1.182
[78,     7] loss: 1.176
[79,     7] loss: 1.192
[80,     7] loss: 1.228
[81,     7] loss: 1.284
[82,     7] loss: 1.282
[83,     7] loss: 1.227
[84,     7] loss: 1.209
[85,     7] loss: 1.173
[86,     7] loss: 1.221
[87,     7] loss: 1.202
[88,     7] loss: 1.182
[89,     7] loss: 1.192
[90,     7] loss: 1.173
[91,     7] loss: 1.157
[92,     7] loss: 1.201
[93,     7] loss: 1.152
[94,     7] loss: 1.181
[95,     7] loss: 1.151
[96,     7] loss: 1.137
[97,     7] loss: 1.172
[98,     7] loss: 1.230
[99,     7] loss: 1.189
[100,     7] loss: 1.189
[101,     7] loss: 1.173
[102,     7] loss: 1.178
[103,     7] loss: 1.171
[104,     7] loss: 1.186
[105,     7] loss: 1.171
[106,     7] loss: 1.166
[107,     7] loss: 1.136
[108,     7] loss: 1.186
[109,     7] loss: 1.188
[110,     7] loss: 1.157
[111,     7] loss: 1.188
[112,     7] loss: 1.266
[113,     7] loss: 1.296
Early stopping applied (best metric=0.36299973726272583)
Finished Training
Total time taken: 98.99178791046143
{'Methylation-R Validation Accuracy': 0.6154006811356783, 'Methylation-R Validation Sensitivity': 0.7909233094148604, 'Methylation-R Validation Specificity': 0.5991656441717792, 'Methylation-R Validation Precision': 0.15923178441641705, 'Methylation-R AUC ROC': 0.7853387021473591, 'Methylation-R AUC PR': 0.34215446722367576, 'Methylation-R MCC': 0.22355975384971277, 'Methylation-R F1': 0.2634881726591369, 'Validation Loss (Methylation-R)': 0.3163534104824066, 'Methylation-K Validation Accuracy': 0.4777756448167604, 'Methylation-K Validation Sensitivity': 0.7988900305451292, 'Methylation-K Validation Specificity': 0.44295283693095444, 'Methylation-K Validation Precision': 0.1354352418376967, 'Methylation-K AUC ROC': 0.6848790250912519, 'Methylation-K AUC PR': 0.18325334697307508, 'Methylation-K MCC': 0.14759082601387943, 'Methylation-K F1': 0.23105034293519172, 'Validation Loss (Methylation-K)': 0.37871192693710326, 'Validation Loss (total)': 0.6950653195381165, 'TimeToTrain': 77.94563717842102}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00897551988319848,
 'learning_rate_Methylation-K': 0.00022169304584900658,
 'learning_rate_Methylation-R': 0.008665347791486887,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.17772672969783704,
 'loss_weight_Methylation-R': 0.3002328984342907,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 64382921,
 'sample_weights': [0.6926369915456096, 0.3123144792783402],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.737106013570102,
 'weight_decay_Methylation-K': 9.530110841432787,
 'weight_decay_Methylation-R': 9.843364662402227}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.399
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006819517016795454,
 'learning_rate_Methylation-K': 0.004809685199011934,
 'learning_rate_Methylation-R': 0.0020793726983708485,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6638905132406729,
 'loss_weight_Methylation-R': 0.7630464524789919,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1430261370,
 'sample_weights': [0.3002328984342907, 0.17772672969783704],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.12751981095507,
 'weight_decay_Methylation-K': 8.983947361128957,
 'weight_decay_Methylation-R': 2.239271707056174}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.375
[4,     7] loss: 1.337
[5,     7] loss: 1.325
[6,     7] loss: 1.310
[7,     7] loss: 1.300
[8,     7] loss: 1.287
[9,     7] loss: 1.342
[10,     7] loss: 1.318
[11,     7] loss: 1.358
[12,     7] loss: 1.337
[13,     7] loss: 1.335
[14,     7] loss: 1.312
[15,     7] loss: 1.286
[16,     7] loss: 1.293
[17,     7] loss: 1.294
[18,     7] loss: 1.278
[19,     7] loss: 1.286
[20,     7] loss: 1.278
[21,     7] loss: 1.277
[22,     7] loss: 1.263
[23,     7] loss: 1.270
[24,     7] loss: 1.279
[25,     7] loss: 1.318
[26,     7] loss: 1.384
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008590781594017612,
 'learning_rate_Methylation-K': 0.0008232192012690056,
 'learning_rate_Methylation-R': 0.003981389012483681,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.08111726890919888,
 'loss_weight_Methylation-R': 0.9504143889768604,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3444042119,
 'sample_weights': [0.7630464524789919, 0.6638905132406729],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.838902478189057,
 'weight_decay_Methylation-K': 6.4778789539199915,
 'weight_decay_Methylation-R': 4.651764363790822}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007377180680883809,
 'learning_rate_Methylation-K': 0.006577207142995967,
 'learning_rate_Methylation-R': 0.007017095104367569,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.31810063861530724,
 'loss_weight_Methylation-R': 0.6645743614180446,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1551687522,
 'sample_weights': [0.9504143889768604, 0.08111726890919888],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5638157050580686,
 'weight_decay_Methylation-K': 5.160709798490121,
 'weight_decay_Methylation-R': 8.521954609463414}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009263883130473362,
 'learning_rate_Methylation-K': 0.008640021882065908,
 'learning_rate_Methylation-R': 0.0015673150799920166,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.844718130191686,
 'loss_weight_Methylation-R': 0.6088929521219213,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1705346706,
 'sample_weights': [0.6645743614180446, 0.31810063861530724],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.4040972056882053,
 'weight_decay_Methylation-K': 3.6594733355116764,
 'weight_decay_Methylation-R': 3.8360888153543646}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009090636363477244,
 'learning_rate_Methylation-K': 0.009366724267074805,
 'learning_rate_Methylation-R': 0.005594272200419175,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3951115827451164,
 'loss_weight_Methylation-R': 0.4239471628147463,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 87452171,
 'sample_weights': [0.6088929521219213, 0.844718130191686],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.402880903320594,
 'weight_decay_Methylation-K': 4.919549034820642,
 'weight_decay_Methylation-R': 8.09567970780559}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007999081202094704,
 'learning_rate_Methylation-K': 0.001563318799192553,
 'learning_rate_Methylation-R': 0.005318549928382271,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.09772582570843463,
 'loss_weight_Methylation-R': 0.9774785606896507,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2789101094,
 'sample_weights': [0.4239471628147463, 0.3951115827451164],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.625554454299515,
 'weight_decay_Methylation-K': 4.296549314599233,
 'weight_decay_Methylation-R': 7.247654970755171}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.387
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.387
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00682810080077992,
 'learning_rate_Methylation-K': 0.0020985188550302347,
 'learning_rate_Methylation-R': 0.002979451641298534,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2814517985932563,
 'loss_weight_Methylation-R': 0.9235961014122847,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2930669526,
 'sample_weights': [0.9774785606896507, 0.09772582570843463],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.132912262265642,
 'weight_decay_Methylation-K': 2.054238581843225,
 'weight_decay_Methylation-R': 7.072116231103017}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.378
[5,     7] loss: 1.352
[6,     7] loss: 1.360
[7,     7] loss: 1.331
[8,     7] loss: 1.328
[9,     7] loss: 1.318
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009509076362276811,
 'learning_rate_Methylation-K': 8.707793711163863e-05,
 'learning_rate_Methylation-R': 0.0099722389671156,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2972110407504162,
 'loss_weight_Methylation-R': 0.8871484382852961,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1579846160,
 'sample_weights': [0.9235961014122847, 0.2814517985932563],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.779256536068765,
 'weight_decay_Methylation-K': 7.601275130380206,
 'weight_decay_Methylation-R': 8.476624820598706}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009987197170076501,
 'learning_rate_Methylation-K': 0.009175761681450036,
 'learning_rate_Methylation-R': 0.007616749307814322,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8451060081441434,
 'loss_weight_Methylation-R': 0.6079999357974338,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4165081300,
 'sample_weights': [0.8871484382852961, 0.2972110407504162],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7275494289938633,
 'weight_decay_Methylation-K': 7.036419497594713,
 'weight_decay_Methylation-R': 9.842068080907973}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007637158745901086,
 'learning_rate_Methylation-K': 0.009302788124975724,
 'learning_rate_Methylation-R': 0.008552192173261332,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6284388242569765,
 'loss_weight_Methylation-R': 0.3918661844350468,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 71829228,
 'sample_weights': [0.6079999357974338, 0.8451060081441434],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9222618248041721,
 'weight_decay_Methylation-K': 6.455059299242837,
 'weight_decay_Methylation-R': 9.301539128046924}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007986899596987758,
 'learning_rate_Methylation-K': 0.006937399568456761,
 'learning_rate_Methylation-R': 0.00683766106911865,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6650420613201453,
 'loss_weight_Methylation-R': 0.8932829003244623,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 514165054,
 'sample_weights': [0.3918661844350468, 0.6284388242569765],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9450288557651642,
 'weight_decay_Methylation-K': 8.019982531919466,
 'weight_decay_Methylation-R': 6.946137867064214}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007660613989898428,
 'learning_rate_Methylation-K': 0.0023462106510708978,
 'learning_rate_Methylation-R': 0.0041164693588372275,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.30505587768398257,
 'loss_weight_Methylation-R': 0.872793676854949,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 411747049,
 'sample_weights': [0.8932829003244623, 0.6650420613201453],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.664029852398144,
 'weight_decay_Methylation-K': 3.2784775528116157,
 'weight_decay_Methylation-R': 6.7135732873027365}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009148077370889011,
 'learning_rate_Methylation-K': 0.003589827980366696,
 'learning_rate_Methylation-R': 0.005166721225793016,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.027442256232492534,
 'loss_weight_Methylation-R': 0.9985145037040237,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2383009355,
 'sample_weights': [0.872793676854949, 0.30505587768398257],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.989698151664171,
 'weight_decay_Methylation-K': 5.626532825965004,
 'weight_decay_Methylation-R': 7.8978895480452165}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009944204366471568,
 'learning_rate_Methylation-K': 0.0002961893495056979,
 'learning_rate_Methylation-R': 0.0069674723770482075,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.03015952718862213,
 'loss_weight_Methylation-R': 0.9740866150718869,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1094617409,
 'sample_weights': [0.9985145037040237, 0.027442256232492534],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.969867621188012,
 'weight_decay_Methylation-K': 3.5292429536055736,
 'weight_decay_Methylation-R': 7.018468087244273}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.376
[12,     7] loss: 1.358
[13,     7] loss: 1.384
[14,     7] loss: 1.388
[15,     7] loss: 1.387
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007772625814961865,
 'learning_rate_Methylation-K': 0.002358055551755891,
 'learning_rate_Methylation-R': 0.00038862003682924116,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4059309678828561,
 'loss_weight_Methylation-R': 0.6595564263159024,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 893491198,
 'sample_weights': [0.9740866150718869, 0.03015952718862213],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.0975480742140595,
 'weight_decay_Methylation-K': 7.038638072187778,
 'weight_decay_Methylation-R': 6.186997376106229}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
Early stopping applied (best metric=0.44468292593955994)
Finished Training
Total time taken: 51.969199657440186
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.375
[13,     7] loss: 1.357
[14,     7] loss: 1.337
[15,     7] loss: 1.313
[16,     7] loss: 1.295
[17,     7] loss: 1.288
[18,     7] loss: 1.287
[19,     7] loss: 1.296
[20,     7] loss: 1.286
[21,     7] loss: 1.273
[22,     7] loss: 1.287
[23,     7] loss: 1.258
[24,     7] loss: 1.258
[25,     7] loss: 1.249
[26,     7] loss: 1.270
[27,     7] loss: 1.267
[28,     7] loss: 1.242
[29,     7] loss: 1.252
[30,     7] loss: 1.247
[31,     7] loss: 1.249
[32,     7] loss: 1.249
[33,     7] loss: 1.243
[34,     7] loss: 1.303
[35,     7] loss: 1.281
[36,     7] loss: 1.244
[37,     7] loss: 1.251
[38,     7] loss: 1.261
[39,     7] loss: 1.249
[40,     7] loss: 1.273
[41,     7] loss: 1.293
[42,     7] loss: 1.257
[43,     7] loss: 1.255
[44,     7] loss: 1.232
[45,     7] loss: 1.257
[46,     7] loss: 1.330
[47,     7] loss: 1.323
[48,     7] loss: 1.263
[49,     7] loss: 1.240
[50,     7] loss: 1.249
[51,     7] loss: 1.270
[52,     7] loss: 1.242
[53,     7] loss: 1.294
[54,     7] loss: 1.287
[55,     7] loss: 1.255
[56,     7] loss: 1.242
[57,     7] loss: 1.239
[58,     7] loss: 1.255
[59,     7] loss: 1.226
[60,     7] loss: 1.245
[61,     7] loss: 1.242
[62,     7] loss: 1.316
[63,     7] loss: 1.358
[64,     7] loss: 1.345
[65,     7] loss: 1.327
[66,     7] loss: 1.303
[67,     7] loss: 1.305
[68,     7] loss: 1.297
[69,     7] loss: 1.262
[70,     7] loss: 1.250
[71,     7] loss: 1.265
[72,     7] loss: 1.278
[73,     7] loss: 1.283
[74,     7] loss: 1.271
[75,     7] loss: 1.264
[76,     7] loss: 1.246
[77,     7] loss: 1.246
[78,     7] loss: 1.275
[79,     7] loss: 1.252
[80,     7] loss: 1.236
[81,     7] loss: 1.241
[82,     7] loss: 1.244
[83,     7] loss: 1.245
[84,     7] loss: 1.249
[85,     7] loss: 1.261
[86,     7] loss: 1.256
[87,     7] loss: 1.245
[88,     7] loss: 1.268
[89,     7] loss: 1.247
[90,     7] loss: 1.256
[91,     7] loss: 1.268
[92,     7] loss: 1.266
[93,     7] loss: 1.264
[94,     7] loss: 1.247
[95,     7] loss: 1.258
[96,     7] loss: 1.237
[97,     7] loss: 1.247
[98,     7] loss: 1.240
[99,     7] loss: 1.279
[100,     7] loss: 1.300
Early stopping applied (best metric=0.3980940580368042)
Finished Training
Total time taken: 92.34010004997253
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.384
[7,     7] loss: 1.362
[8,     7] loss: 1.349
[9,     7] loss: 1.341
[10,     7] loss: 1.312
[11,     7] loss: 1.312
[12,     7] loss: 1.297
[13,     7] loss: 1.295
[14,     7] loss: 1.318
[15,     7] loss: 1.298
[16,     7] loss: 1.280
[17,     7] loss: 1.310
[18,     7] loss: 1.281
[19,     7] loss: 1.271
[20,     7] loss: 1.324
[21,     7] loss: 1.300
[22,     7] loss: 1.273
[23,     7] loss: 1.271
[24,     7] loss: 1.254
[25,     7] loss: 1.257
[26,     7] loss: 1.322
[27,     7] loss: 1.301
[28,     7] loss: 1.272
[29,     7] loss: 1.260
[30,     7] loss: 1.259
[31,     7] loss: 1.237
[32,     7] loss: 1.258
[33,     7] loss: 1.257
[34,     7] loss: 1.244
[35,     7] loss: 1.269
[36,     7] loss: 1.254
[37,     7] loss: 1.235
[38,     7] loss: 1.254
[39,     7] loss: 1.261
[40,     7] loss: 1.217
[41,     7] loss: 1.400
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.385
[48,     7] loss: 1.377
[49,     7] loss: 1.363
[50,     7] loss: 1.362
[51,     7] loss: 1.348
[52,     7] loss: 1.342
[53,     7] loss: 1.338
[54,     7] loss: 1.340
[55,     7] loss: 1.322
[56,     7] loss: 1.322
[57,     7] loss: 1.323
[58,     7] loss: 1.294
[59,     7] loss: 1.291
[60,     7] loss: 1.313
[61,     7] loss: 1.296
[62,     7] loss: 1.286
[63,     7] loss: 1.275
[64,     7] loss: 1.317
[65,     7] loss: 1.309
[66,     7] loss: 1.267
[67,     7] loss: 1.271
[68,     7] loss: 1.282
[69,     7] loss: 1.283
[70,     7] loss: 1.271
[71,     7] loss: 1.250
[72,     7] loss: 1.293
[73,     7] loss: 1.280
[74,     7] loss: 1.271
[75,     7] loss: 1.263
[76,     7] loss: 1.274
[77,     7] loss: 1.250
[78,     7] loss: 1.271
[79,     7] loss: 1.255
[80,     7] loss: 1.301
[81,     7] loss: 1.339
[82,     7] loss: 1.333
[83,     7] loss: 1.323
[84,     7] loss: 1.314
[85,     7] loss: 1.320
[86,     7] loss: 1.300
[87,     7] loss: 1.289
[88,     7] loss: 1.305
[89,     7] loss: 1.278
[90,     7] loss: 1.281
[91,     7] loss: 1.271
[92,     7] loss: 1.264
[93,     7] loss: 1.261
[94,     7] loss: 1.257
[95,     7] loss: 1.275
[96,     7] loss: 1.307
[97,     7] loss: 1.296
[98,     7] loss: 1.286
[99,     7] loss: 1.265
[100,     7] loss: 1.255
[101,     7] loss: 1.247
[102,     7] loss: 1.252
[103,     7] loss: 1.274
[104,     7] loss: 1.289
[105,     7] loss: 1.267
[106,     7] loss: 1.243
[107,     7] loss: 1.250
[108,     7] loss: 1.279
[109,     7] loss: 1.262
[110,     7] loss: 1.263
[111,     7] loss: 1.256
[112,     7] loss: 1.244
[113,     7] loss: 1.347
[114,     7] loss: 1.317
[115,     7] loss: 1.390
[116,     7] loss: 1.376
[117,     7] loss: 1.358
[118,     7] loss: 1.325
[119,     7] loss: 1.318
[120,     7] loss: 1.285
[121,     7] loss: 1.284
[122,     7] loss: 1.284
[123,     7] loss: 1.270
[124,     7] loss: 1.289
[125,     7] loss: 1.271
[126,     7] loss: 1.272
[127,     7] loss: 1.262
[128,     7] loss: 1.281
[129,     7] loss: 1.249
[130,     7] loss: 1.255
[131,     7] loss: 1.257
Early stopping applied (best metric=0.42597174644470215)
Finished Training
Total time taken: 114.66634392738342
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.384
[4,     7] loss: 1.366
[5,     7] loss: 1.322
[6,     7] loss: 1.309
[7,     7] loss: 1.330
[8,     7] loss: 1.296
[9,     7] loss: 1.269
[10,     7] loss: 1.265
[11,     7] loss: 1.269
[12,     7] loss: 1.242
[13,     7] loss: 1.256
[14,     7] loss: 1.270
[15,     7] loss: 1.280
[16,     7] loss: 1.254
[17,     7] loss: 1.246
[18,     7] loss: 1.240
[19,     7] loss: 1.222
[20,     7] loss: 1.269
[21,     7] loss: 1.273
[22,     7] loss: 1.245
[23,     7] loss: 1.246
[24,     7] loss: 1.283
[25,     7] loss: 1.280
[26,     7] loss: 1.254
[27,     7] loss: 1.248
[28,     7] loss: 1.224
[29,     7] loss: 1.298
[30,     7] loss: 1.289
[31,     7] loss: 1.283
[32,     7] loss: 1.242
[33,     7] loss: 1.240
[34,     7] loss: 1.236
[35,     7] loss: 1.242
[36,     7] loss: 1.229
[37,     7] loss: 1.255
[38,     7] loss: 1.348
[39,     7] loss: 1.349
[40,     7] loss: 1.332
[41,     7] loss: 1.309
[42,     7] loss: 1.299
[43,     7] loss: 1.314
[44,     7] loss: 1.287
[45,     7] loss: 1.275
[46,     7] loss: 1.290
[47,     7] loss: 1.258
[48,     7] loss: 1.255
[49,     7] loss: 1.242
[50,     7] loss: 1.248
[51,     7] loss: 1.274
[52,     7] loss: 1.343
[53,     7] loss: 1.308
[54,     7] loss: 1.272
[55,     7] loss: 1.271
[56,     7] loss: 1.241
[57,     7] loss: 1.246
[58,     7] loss: 1.242
[59,     7] loss: 1.273
[60,     7] loss: 1.341
[61,     7] loss: 1.310
[62,     7] loss: 1.316
[63,     7] loss: 1.296
[64,     7] loss: 1.264
[65,     7] loss: 1.266
[66,     7] loss: 1.260
[67,     7] loss: 1.265
[68,     7] loss: 1.262
[69,     7] loss: 1.256
[70,     7] loss: 1.277
[71,     7] loss: 1.246
[72,     7] loss: 1.269
[73,     7] loss: 1.250
[74,     7] loss: 1.267
[75,     7] loss: 1.254
[76,     7] loss: 1.242
[77,     7] loss: 1.237
[78,     7] loss: 1.232
[79,     7] loss: 1.233
[80,     7] loss: 1.245
[81,     7] loss: 1.291
[82,     7] loss: 1.234
[83,     7] loss: 1.215
[84,     7] loss: 1.194
[85,     7] loss: 1.199
[86,     7] loss: 1.184
[87,     7] loss: 1.195
[88,     7] loss: 1.251
[89,     7] loss: 1.320
Early stopping applied (best metric=0.4174765944480896)
Finished Training
Total time taken: 78.26207900047302
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.384
[9,     7] loss: 1.371
[10,     7] loss: 1.351
[11,     7] loss: 1.326
[12,     7] loss: 1.313
[13,     7] loss: 1.292
[14,     7] loss: 1.299
[15,     7] loss: 1.295
[16,     7] loss: 1.281
[17,     7] loss: 1.268
[18,     7] loss: 1.253
[19,     7] loss: 1.279
[20,     7] loss: 1.253
[21,     7] loss: 1.273
[22,     7] loss: 1.295
[23,     7] loss: 1.269
[24,     7] loss: 1.238
[25,     7] loss: 1.251
[26,     7] loss: 1.250
[27,     7] loss: 1.256
[28,     7] loss: 1.254
[29,     7] loss: 1.261
[30,     7] loss: 1.231
[31,     7] loss: 1.250
[32,     7] loss: 1.244
[33,     7] loss: 1.235
[34,     7] loss: 1.227
[35,     7] loss: 1.362
[36,     7] loss: 1.375
[37,     7] loss: 1.354
[38,     7] loss: 1.349
[39,     7] loss: 1.343
[40,     7] loss: 1.330
[41,     7] loss: 1.314
[42,     7] loss: 1.282
[43,     7] loss: 1.323
[44,     7] loss: 1.320
[45,     7] loss: 1.290
[46,     7] loss: 1.284
[47,     7] loss: 1.293
[48,     7] loss: 1.310
[49,     7] loss: 1.267
[50,     7] loss: 1.269
[51,     7] loss: 1.256
[52,     7] loss: 1.278
[53,     7] loss: 1.241
[54,     7] loss: 1.243
[55,     7] loss: 1.266
[56,     7] loss: 1.258
[57,     7] loss: 1.265
[58,     7] loss: 1.235
[59,     7] loss: 1.252
[60,     7] loss: 1.238
[61,     7] loss: 1.245
[62,     7] loss: 1.240
[63,     7] loss: 1.228
[64,     7] loss: 1.257
[65,     7] loss: 1.256
[66,     7] loss: 1.237
[67,     7] loss: 1.252
[68,     7] loss: 1.256
[69,     7] loss: 1.255
[70,     7] loss: 1.256
[71,     7] loss: 1.228
[72,     7] loss: 1.217
[73,     7] loss: 1.224
[74,     7] loss: 1.224
[75,     7] loss: 1.215
[76,     7] loss: 1.222
[77,     7] loss: 1.219
[78,     7] loss: 1.212
[79,     7] loss: 1.198
[80,     7] loss: 1.230
[81,     7] loss: 1.263
[82,     7] loss: 1.220
[83,     7] loss: 1.214
[84,     7] loss: 1.207
[85,     7] loss: 1.197
[86,     7] loss: 1.208
[87,     7] loss: 1.183
[88,     7] loss: 1.202
[89,     7] loss: 1.224
[90,     7] loss: 1.217
[91,     7] loss: 1.191
[92,     7] loss: 1.198
[93,     7] loss: 1.188
[94,     7] loss: 1.282
[95,     7] loss: 1.274
[96,     7] loss: 1.295
[97,     7] loss: 1.273
[98,     7] loss: 1.252
[99,     7] loss: 1.216
[100,     7] loss: 1.207
[101,     7] loss: 1.204
[102,     7] loss: 1.218
[103,     7] loss: 1.212
[104,     7] loss: 1.190
[105,     7] loss: 1.192
[106,     7] loss: 1.200
[107,     7] loss: 1.193
[108,     7] loss: 1.186
[109,     7] loss: 1.181
[110,     7] loss: 1.214
[111,     7] loss: 1.250
[112,     7] loss: 1.234
[113,     7] loss: 1.188
[114,     7] loss: 1.210
[115,     7] loss: 1.204
[116,     7] loss: 1.191
[117,     7] loss: 1.183
[118,     7] loss: 1.177
Early stopping applied (best metric=0.41061174869537354)
Finished Training
Total time taken: 101.47130489349365
{'Methylation-R Validation Accuracy': 0.45344709512193865, 'Methylation-R Validation Sensitivity': 0.873446620238762, 'Methylation-R Validation Specificity': 0.41460122699386504, 'Methylation-R Validation Precision': 0.13212137761601062, 'Methylation-R AUC ROC': 0.7551457379866873, 'Methylation-R AUC PR': 0.3082326350396191, 'Methylation-R MCC': 0.1645783601723949, 'Methylation-R F1': 0.22650026297338888, 'Validation Loss (Methylation-R)': 0.3535099983215332, 'Methylation-K Validation Accuracy': 0.3449545096928031, 'Methylation-K Validation Sensitivity': 0.7874389854636872, 'Methylation-K Validation Specificity': 0.2969656546330279, 'Methylation-K Validation Precision': 0.1095221097838205, 'Methylation-K AUC ROC': 0.5739750500928982, 'Methylation-K AUC PR': 0.12085893697654523, 'Methylation-K MCC': 0.05342287855313339, 'Methylation-K F1': 0.1913260674227127, 'Validation Loss (Methylation-K)': 0.4193674147129059, 'Validation Loss (total)': 0.7728774189949036, 'TimeToTrain': 87.74180550575257}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004004043984792269,
 'learning_rate_Methylation-K': 0.006214915593947063,
 'learning_rate_Methylation-R': 0.006128195522932127,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.019892749876515625,
 'loss_weight_Methylation-R': 0.836781099594716,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2410155185,
 'sample_weights': [0.6595564263159024, 0.4059309678828561],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1986338142395256,
 'weight_decay_Methylation-K': 6.114387957731255,
 'weight_decay_Methylation-R': 0.15662721446839534}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.380
[3,     7] loss: 1.359
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005264289223758701,
 'learning_rate_Methylation-K': 0.00017982341806167313,
 'learning_rate_Methylation-R': 0.0036513559417169755,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07335430832595369,
 'loss_weight_Methylation-R': 0.9015113946263247,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2485946214,
 'sample_weights': [0.836781099594716, 0.019892749876515625],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.565842291461607,
 'weight_decay_Methylation-K': 4.5620634905336965,
 'weight_decay_Methylation-R': 8.142031100634183}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.370
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030682888216155826,
 'learning_rate_Methylation-K': 0.009121732363468141,
 'learning_rate_Methylation-R': 0.0030535167610793515,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8219284448283277,
 'loss_weight_Methylation-R': 0.3774323850088398,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4065243904,
 'sample_weights': [0.9015113946263247, 0.07335430832595369],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5164695671330248,
 'weight_decay_Methylation-K': 6.993578870819519,
 'weight_decay_Methylation-R': 3.711456809393569}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.384
[6,     7] loss: 1.377
[7,     7] loss: 1.347
[8,     7] loss: 1.342
[9,     7] loss: 1.326
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006851502485974801,
 'learning_rate_Methylation-K': 0.005400600705588686,
 'learning_rate_Methylation-R': 0.007869425101695757,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.31138904751783225,
 'loss_weight_Methylation-R': 0.17331761244393024,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2378345339,
 'sample_weights': [0.3774323850088398, 0.8219284448283277],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.157367494995055,
 'weight_decay_Methylation-K': 4.199236975436068,
 'weight_decay_Methylation-R': 6.567611862784265}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009704613047029801,
 'learning_rate_Methylation-K': 0.008411432102445953,
 'learning_rate_Methylation-R': 0.0042112459985437075,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.18334808465438995,
 'loss_weight_Methylation-R': 0.852993994528885,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3353921485,
 'sample_weights': [0.17331761244393024, 0.31138904751783225],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.877779541987002,
 'weight_decay_Methylation-K': 7.3484808015897904,
 'weight_decay_Methylation-R': 4.26698035319304}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.385
[6,     7] loss: 1.354
[7,     7] loss: 1.360
[8,     7] loss: 1.355
[9,     7] loss: 1.323
[10,     7] loss: 1.305
[11,     7] loss: 1.305
[12,     7] loss: 1.293
[13,     7] loss: 1.291
[14,     7] loss: 1.273
[15,     7] loss: 1.312
[16,     7] loss: 1.389
[17,     7] loss: 1.383
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.387
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008844583431368602,
 'learning_rate_Methylation-K': 0.006218333181033055,
 'learning_rate_Methylation-R': 0.0015839408441106334,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7427583936656137,
 'loss_weight_Methylation-R': 0.0715192670311166,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2872655406,
 'sample_weights': [0.852993994528885, 0.18334808465438995],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.113580514360663,
 'weight_decay_Methylation-K': 3.8926829790334163,
 'weight_decay_Methylation-R': 6.152593946691049}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.373
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007658173864604805,
 'learning_rate_Methylation-K': 0.00676844813483615,
 'learning_rate_Methylation-R': 0.009423295477532848,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7065655004566975,
 'loss_weight_Methylation-R': 0.7902827982867305,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 150364692,
 'sample_weights': [0.0715192670311166, 0.7427583936656137],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.30805263113055603,
 'weight_decay_Methylation-K': 2.372077243264391,
 'weight_decay_Methylation-R': 6.891522130054647}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007822340881659895,
 'learning_rate_Methylation-K': 0.006114409927956337,
 'learning_rate_Methylation-R': 0.008139498341875872,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7090216070731034,
 'loss_weight_Methylation-R': 0.44655007579638945,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 789519137,
 'sample_weights': [0.7902827982867305, 0.7065655004566975],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.0672945794727315,
 'weight_decay_Methylation-K': 4.385150687849549,
 'weight_decay_Methylation-R': 9.812809823476465}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009852243531742997,
 'learning_rate_Methylation-K': 0.0005554315694917317,
 'learning_rate_Methylation-R': 0.005906819454898857,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3704628753582141,
 'loss_weight_Methylation-R': 0.8038355401456712,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1526380348,
 'sample_weights': [0.44655007579638945, 0.7090216070731034],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.1773282190967196,
 'weight_decay_Methylation-K': 9.587847471412541,
 'weight_decay_Methylation-R': 8.304596931880587}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.387
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.387
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008355400315167603,
 'learning_rate_Methylation-K': 0.00044459452836373577,
 'learning_rate_Methylation-R': 0.004974404540590531,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.448353516632563,
 'loss_weight_Methylation-R': 0.97128523331625,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3665898954,
 'sample_weights': [0.8038355401456712, 0.3704628753582141],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.7507647231094525,
 'weight_decay_Methylation-K': 3.8067362423051154,
 'weight_decay_Methylation-R': 9.238960154060132}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009419024474600614,
 'learning_rate_Methylation-K': 0.0014786130774531055,
 'learning_rate_Methylation-R': 0.0073178256535839864,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.011300326000307628,
 'loss_weight_Methylation-R': 0.9320579420839986,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1101126005,
 'sample_weights': [0.97128523331625, 0.448353516632563],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.349920355751715,
 'weight_decay_Methylation-K': 3.5445779998925975,
 'weight_decay_Methylation-R': 4.403534142374564}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.400
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008775740962352467,
 'learning_rate_Methylation-K': 0.001487258837561261,
 'learning_rate_Methylation-R': 0.006024206848041727,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.052110552538587256,
 'loss_weight_Methylation-R': 0.7186766853996793,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2152482097,
 'sample_weights': [0.9320579420839986, 0.011300326000307628],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.687503078720949,
 'weight_decay_Methylation-K': 3.8675396447196406,
 'weight_decay_Methylation-R': 7.958469671055998}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00421519674479128,
 'learning_rate_Methylation-K': 0.0011663262190676866,
 'learning_rate_Methylation-R': 0.002979139891320248,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.37538840388332795,
 'loss_weight_Methylation-R': 0.6137823598214546,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3563983250,
 'sample_weights': [0.7186766853996793, 0.052110552538587256],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.435075220818973,
 'weight_decay_Methylation-K': 4.769231595633314,
 'weight_decay_Methylation-R': 8.971063810577801}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.385
[4,     7] loss: 1.380
[5,     7] loss: 1.354
[6,     7] loss: 1.321
[7,     7] loss: 1.315
[8,     7] loss: 1.297
[9,     7] loss: 1.293
[10,     7] loss: 1.284
[11,     7] loss: 1.271
[12,     7] loss: 1.266
[13,     7] loss: 1.261
[14,     7] loss: 1.265
[15,     7] loss: 1.261
[16,     7] loss: 1.250
[17,     7] loss: 1.241
[18,     7] loss: 1.229
[19,     7] loss: 1.227
[20,     7] loss: 1.218
[21,     7] loss: 1.241
[22,     7] loss: 1.235
[23,     7] loss: 1.225
[24,     7] loss: 1.192
[25,     7] loss: 1.190
[26,     7] loss: 1.252
[27,     7] loss: 1.219
[28,     7] loss: 1.199
[29,     7] loss: 1.217
[30,     7] loss: 1.205
[31,     7] loss: 1.194
[32,     7] loss: 1.221
[33,     7] loss: 1.264
[34,     7] loss: 1.330
[35,     7] loss: 1.358
[36,     7] loss: 1.351
[37,     7] loss: 1.329
[38,     7] loss: 1.330
[39,     7] loss: 1.322
[40,     7] loss: 1.308
[41,     7] loss: 1.315
[42,     7] loss: 1.317
[43,     7] loss: 1.302
[44,     7] loss: 1.277
[45,     7] loss: 1.270
[46,     7] loss: 1.278
[47,     7] loss: 1.264
[48,     7] loss: 1.246
[49,     7] loss: 1.241
[50,     7] loss: 1.225
[51,     7] loss: 1.272
[52,     7] loss: 1.247
[53,     7] loss: 1.220
[54,     7] loss: 1.226
[55,     7] loss: 1.228
[56,     7] loss: 1.211
[57,     7] loss: 1.209
[58,     7] loss: 1.209
[59,     7] loss: 1.197
[60,     7] loss: 1.235
[61,     7] loss: 1.237
[62,     7] loss: 1.212
[63,     7] loss: 1.193
[64,     7] loss: 1.208
[65,     7] loss: 1.217
[66,     7] loss: 1.190
[67,     7] loss: 1.211
[68,     7] loss: 1.201
[69,     7] loss: 1.184
[70,     7] loss: 1.174
[71,     7] loss: 1.209
[72,     7] loss: 1.175
[73,     7] loss: 1.166
[74,     7] loss: 1.200
[75,     7] loss: 1.200
Early stopping applied (best metric=0.3661983907222748)
Finished Training
Total time taken: 64.60519504547119
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.383
[6,     7] loss: 1.361
[7,     7] loss: 1.333
[8,     7] loss: 1.309
[9,     7] loss: 1.315
[10,     7] loss: 1.292
[11,     7] loss: 1.265
[12,     7] loss: 1.262
[13,     7] loss: 1.252
[14,     7] loss: 1.265
[15,     7] loss: 1.250
[16,     7] loss: 1.228
[17,     7] loss: 1.246
[18,     7] loss: 1.245
[19,     7] loss: 1.235
[20,     7] loss: 1.219
[21,     7] loss: 1.256
[22,     7] loss: 1.238
[23,     7] loss: 1.214
[24,     7] loss: 1.241
[25,     7] loss: 1.224
[26,     7] loss: 1.241
[27,     7] loss: 1.237
[28,     7] loss: 1.215
[29,     7] loss: 1.229
[30,     7] loss: 1.204
[31,     7] loss: 1.307
[32,     7] loss: 1.286
[33,     7] loss: 1.261
[34,     7] loss: 1.242
[35,     7] loss: 1.230
[36,     7] loss: 1.218
[37,     7] loss: 1.232
[38,     7] loss: 1.216
[39,     7] loss: 1.235
[40,     7] loss: 1.248
[41,     7] loss: 1.220
[42,     7] loss: 1.191
[43,     7] loss: 1.198
[44,     7] loss: 1.201
[45,     7] loss: 1.200
[46,     7] loss: 1.213
[47,     7] loss: 1.202
[48,     7] loss: 1.206
[49,     7] loss: 1.184
[50,     7] loss: 1.187
[51,     7] loss: 1.185
[52,     7] loss: 1.198
[53,     7] loss: 1.199
[54,     7] loss: 1.180
[55,     7] loss: 1.189
[56,     7] loss: 1.211
[57,     7] loss: 1.235
[58,     7] loss: 1.200
[59,     7] loss: 1.193
[60,     7] loss: 1.163
[61,     7] loss: 1.201
[62,     7] loss: 1.305
[63,     7] loss: 1.300
[64,     7] loss: 1.258
[65,     7] loss: 1.238
[66,     7] loss: 1.210
[67,     7] loss: 1.196
[68,     7] loss: 1.189
[69,     7] loss: 1.203
[70,     7] loss: 1.202
[71,     7] loss: 1.219
[72,     7] loss: 1.211
[73,     7] loss: 1.186
[74,     7] loss: 1.171
[75,     7] loss: 1.178
[76,     7] loss: 1.245
[77,     7] loss: 1.251
[78,     7] loss: 1.197
[79,     7] loss: 1.179
[80,     7] loss: 1.186
[81,     7] loss: 1.198
[82,     7] loss: 1.159
[83,     7] loss: 1.178
[84,     7] loss: 1.193
[85,     7] loss: 1.196
[86,     7] loss: 1.203
[87,     7] loss: 1.189
[88,     7] loss: 1.157
[89,     7] loss: 1.196
[90,     7] loss: 1.197
[91,     7] loss: 1.172
[92,     7] loss: 1.171
[93,     7] loss: 1.190
[94,     7] loss: 1.196
[95,     7] loss: 1.195
[96,     7] loss: 1.187
[97,     7] loss: 1.212
[98,     7] loss: 1.163
[99,     7] loss: 1.192
[100,     7] loss: 1.202
[101,     7] loss: 1.185
Early stopping applied (best metric=0.3650854527950287)
Finished Training
Total time taken: 87.44526219367981
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.384
[4,     7] loss: 1.366
[5,     7] loss: 1.337
[6,     7] loss: 1.331
[7,     7] loss: 1.311
[8,     7] loss: 1.309
[9,     7] loss: 1.303
[10,     7] loss: 1.283
[11,     7] loss: 1.280
[12,     7] loss: 1.268
[13,     7] loss: 1.278
[14,     7] loss: 1.268
[15,     7] loss: 1.252
[16,     7] loss: 1.244
[17,     7] loss: 1.243
[18,     7] loss: 1.238
[19,     7] loss: 1.255
[20,     7] loss: 1.232
[21,     7] loss: 1.217
[22,     7] loss: 1.250
[23,     7] loss: 1.232
[24,     7] loss: 1.208
[25,     7] loss: 1.219
[26,     7] loss: 1.202
[27,     7] loss: 1.245
[28,     7] loss: 1.273
[29,     7] loss: 1.285
[30,     7] loss: 1.260
[31,     7] loss: 1.227
[32,     7] loss: 1.218
[33,     7] loss: 1.224
[34,     7] loss: 1.219
[35,     7] loss: 1.235
[36,     7] loss: 1.187
[37,     7] loss: 1.203
[38,     7] loss: 1.309
[39,     7] loss: 1.267
[40,     7] loss: 1.247
[41,     7] loss: 1.217
[42,     7] loss: 1.197
[43,     7] loss: 1.190
[44,     7] loss: 1.225
[45,     7] loss: 1.216
[46,     7] loss: 1.191
[47,     7] loss: 1.195
[48,     7] loss: 1.189
[49,     7] loss: 1.175
[50,     7] loss: 1.235
[51,     7] loss: 1.256
[52,     7] loss: 1.199
[53,     7] loss: 1.196
[54,     7] loss: 1.197
[55,     7] loss: 1.219
[56,     7] loss: 1.238
[57,     7] loss: 1.199
[58,     7] loss: 1.185
[59,     7] loss: 1.185
[60,     7] loss: 1.173
[61,     7] loss: 1.166
[62,     7] loss: 1.207
[63,     7] loss: 1.208
[64,     7] loss: 1.197
[65,     7] loss: 1.174
[66,     7] loss: 1.173
[67,     7] loss: 1.176
[68,     7] loss: 1.164
[69,     7] loss: 1.165
[70,     7] loss: 1.220
[71,     7] loss: 1.257
[72,     7] loss: 1.222
[73,     7] loss: 1.172
[74,     7] loss: 1.164
[75,     7] loss: 1.204
[76,     7] loss: 1.219
[77,     7] loss: 1.173
[78,     7] loss: 1.197
[79,     7] loss: 1.180
[80,     7] loss: 1.194
[81,     7] loss: 1.184
[82,     7] loss: 1.145
[83,     7] loss: 1.196
[84,     7] loss: 1.187
[85,     7] loss: 1.169
[86,     7] loss: 1.190
[87,     7] loss: 1.170
[88,     7] loss: 1.242
[89,     7] loss: 1.182
[90,     7] loss: 1.166
[91,     7] loss: 1.178
[92,     7] loss: 1.168
[93,     7] loss: 1.142
Early stopping applied (best metric=0.36627012491226196)
Finished Training
Total time taken: 80.9052426815033
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.397
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.372
[6,     7] loss: 1.339
[7,     7] loss: 1.324
[8,     7] loss: 1.325
[9,     7] loss: 1.308
[10,     7] loss: 1.293
[11,     7] loss: 1.282
[12,     7] loss: 1.263
[13,     7] loss: 1.263
[14,     7] loss: 1.252
[15,     7] loss: 1.235
[16,     7] loss: 1.238
[17,     7] loss: 1.239
[18,     7] loss: 1.224
[19,     7] loss: 1.240
[20,     7] loss: 1.211
[21,     7] loss: 1.222
[22,     7] loss: 1.230
[23,     7] loss: 1.209
[24,     7] loss: 1.214
[25,     7] loss: 1.202
[26,     7] loss: 1.217
[27,     7] loss: 1.247
[28,     7] loss: 1.221
[29,     7] loss: 1.211
[30,     7] loss: 1.193
[31,     7] loss: 1.173
[32,     7] loss: 1.237
[33,     7] loss: 1.228
[34,     7] loss: 1.189
[35,     7] loss: 1.215
[36,     7] loss: 1.188
[37,     7] loss: 1.173
[38,     7] loss: 1.211
[39,     7] loss: 1.223
[40,     7] loss: 1.217
[41,     7] loss: 1.196
[42,     7] loss: 1.145
[43,     7] loss: 1.258
[44,     7] loss: 1.286
[45,     7] loss: 1.266
[46,     7] loss: 1.246
[47,     7] loss: 1.225
[48,     7] loss: 1.225
[49,     7] loss: 1.202
[50,     7] loss: 1.180
[51,     7] loss: 1.203
[52,     7] loss: 1.202
[53,     7] loss: 1.189
[54,     7] loss: 1.206
[55,     7] loss: 1.201
[56,     7] loss: 1.189
[57,     7] loss: 1.192
[58,     7] loss: 1.189
[59,     7] loss: 1.230
[60,     7] loss: 1.178
[61,     7] loss: 1.172
[62,     7] loss: 1.181
[63,     7] loss: 1.178
[64,     7] loss: 1.193
[65,     7] loss: 1.251
[66,     7] loss: 1.216
[67,     7] loss: 1.198
[68,     7] loss: 1.172
[69,     7] loss: 1.162
[70,     7] loss: 1.158
[71,     7] loss: 1.162
[72,     7] loss: 1.175
[73,     7] loss: 1.186
[74,     7] loss: 1.182
[75,     7] loss: 1.165
[76,     7] loss: 1.148
[77,     7] loss: 1.128
[78,     7] loss: 1.231
[79,     7] loss: 1.185
Early stopping applied (best metric=0.3615306317806244)
Finished Training
Total time taken: 69.01720666885376
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.380
[5,     7] loss: 1.350
[6,     7] loss: 1.327
[7,     7] loss: 1.310
[8,     7] loss: 1.302
[9,     7] loss: 1.292
[10,     7] loss: 1.276
[11,     7] loss: 1.278
[12,     7] loss: 1.260
[13,     7] loss: 1.262
[14,     7] loss: 1.257
[15,     7] loss: 1.244
[16,     7] loss: 1.257
[17,     7] loss: 1.241
[18,     7] loss: 1.247
[19,     7] loss: 1.237
[20,     7] loss: 1.248
[21,     7] loss: 1.226
[22,     7] loss: 1.239
[23,     7] loss: 1.242
[24,     7] loss: 1.239
[25,     7] loss: 1.238
[26,     7] loss: 1.239
[27,     7] loss: 1.273
[28,     7] loss: 1.236
[29,     7] loss: 1.233
[30,     7] loss: 1.227
[31,     7] loss: 1.232
[32,     7] loss: 1.223
[33,     7] loss: 1.249
[34,     7] loss: 1.262
[35,     7] loss: 1.218
[36,     7] loss: 1.222
[37,     7] loss: 1.225
[38,     7] loss: 1.209
[39,     7] loss: 1.220
[40,     7] loss: 1.292
[41,     7] loss: 1.266
[42,     7] loss: 1.265
[43,     7] loss: 1.238
[44,     7] loss: 1.212
[45,     7] loss: 1.201
[46,     7] loss: 1.201
[47,     7] loss: 1.192
[48,     7] loss: 1.207
[49,     7] loss: 1.184
[50,     7] loss: 1.201
[51,     7] loss: 1.204
[52,     7] loss: 1.179
[53,     7] loss: 1.191
[54,     7] loss: 1.158
[55,     7] loss: 1.193
[56,     7] loss: 1.184
[57,     7] loss: 1.174
[58,     7] loss: 1.178
[59,     7] loss: 1.152
[60,     7] loss: 1.192
[61,     7] loss: 1.182
[62,     7] loss: 1.151
[63,     7] loss: 1.190
[64,     7] loss: 1.152
[65,     7] loss: 1.138
[66,     7] loss: 1.172
[67,     7] loss: 1.165
[68,     7] loss: 1.143
[69,     7] loss: 1.181
[70,     7] loss: 1.175
[71,     7] loss: 1.172
[72,     7] loss: 1.169
[73,     7] loss: 1.169
[74,     7] loss: 1.170
[75,     7] loss: 1.179
[76,     7] loss: 1.154
[77,     7] loss: 1.154
[78,     7] loss: 1.152
[79,     7] loss: 1.150
[80,     7] loss: 1.144
[81,     7] loss: 1.196
[82,     7] loss: 1.157
[83,     7] loss: 1.159
[84,     7] loss: 1.161
[85,     7] loss: 1.168
[86,     7] loss: 1.174
[87,     7] loss: 1.134
[88,     7] loss: 1.150
[89,     7] loss: 1.159
Early stopping applied (best metric=0.4107612669467926)
Finished Training
Total time taken: 77.0262291431427
{'Methylation-R Validation Accuracy': 0.5394107642527192, 'Methylation-R Validation Sensitivity': 0.8575219898478588, 'Methylation-R Validation Specificity': 0.5099877300613497, 'Methylation-R Validation Precision': 0.1403563494726799, 'Methylation-R AUC ROC': 0.796873117749611, 'Methylation-R AUC PR': 0.35149877202580904, 'Methylation-R MCC': 0.2060203775554826, 'Methylation-R F1': 0.24089582298774323, 'Validation Loss (Methylation-R)': 0.3016024470329285, 'Methylation-K Validation Accuracy': 0.39681107578108815, 'Methylation-K Validation Sensitivity': 0.8612149086325521, 'Methylation-K Validation Specificity': 0.346441631335435, 'Methylation-K Validation Precision': 0.12606565493132904, 'Methylation-K AUC ROC': 0.6869945539918424, 'Methylation-K AUC PR': 0.1825201351202749, 'Methylation-K MCC': 0.13387183660234142, 'Methylation-K F1': 0.219471944524295, 'Validation Loss (Methylation-K)': 0.37396917343139646, 'Validation Loss (total)': 0.675571620464325, 'TimeToTrain': 75.79982714653015}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008173631658490783,
 'learning_rate_Methylation-K': 0.0023536494763213094,
 'learning_rate_Methylation-R': 0.007269362528987119,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.0033068918728958556,
 'loss_weight_Methylation-R': 0.9495358756764959,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3319113191,
 'sample_weights': [0.6137823598214546, 0.37538840388332795],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.097385545985144,
 'weight_decay_Methylation-K': 4.771172609282909,
 'weight_decay_Methylation-R': 7.015798183278275}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030978744353870277,
 'learning_rate_Methylation-K': 0.006635210253977634,
 'learning_rate_Methylation-R': 0.006401810350780735,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.30429613029501645,
 'loss_weight_Methylation-R': 0.21462919271242453,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1925208155,
 'sample_weights': [0.9495358756764959, 0.0033068918728958556],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.468305462288411,
 'weight_decay_Methylation-K': 7.34510350005702,
 'weight_decay_Methylation-R': 7.394307197090221}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.374
[3,     7] loss: 1.338
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003662719046686193,
 'learning_rate_Methylation-K': 0.000884349934580072,
 'learning_rate_Methylation-R': 0.0015559816554853042,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.12507645059825023,
 'loss_weight_Methylation-R': 0.942802226841444,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 32434579,
 'sample_weights': [0.21462919271242453, 0.30429613029501645],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.650775207838844,
 'weight_decay_Methylation-K': 5.109977756977147,
 'weight_decay_Methylation-R': 8.648151857081196}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.381
[5,     7] loss: 1.355
[6,     7] loss: 1.335
[7,     7] loss: 1.332
[8,     7] loss: 1.301
[9,     7] loss: 1.295
[10,     7] loss: 1.290
[11,     7] loss: 1.269
[12,     7] loss: 1.273
[13,     7] loss: 1.264
[14,     7] loss: 1.280
[15,     7] loss: 1.271
[16,     7] loss: 1.264
[17,     7] loss: 1.248
[18,     7] loss: 1.230
[19,     7] loss: 1.239
[20,     7] loss: 1.243
[21,     7] loss: 1.229
[22,     7] loss: 1.221
[23,     7] loss: 1.224
[24,     7] loss: 1.225
[25,     7] loss: 1.208
[26,     7] loss: 1.222
[27,     7] loss: 1.207
[28,     7] loss: 1.200
[29,     7] loss: 1.212
[30,     7] loss: 1.217
[31,     7] loss: 1.185
[32,     7] loss: 1.225
[33,     7] loss: 1.193
[34,     7] loss: 1.159
[35,     7] loss: 1.168
[36,     7] loss: 1.167
[37,     7] loss: 1.229
[38,     7] loss: 1.275
[39,     7] loss: 1.276
[40,     7] loss: 1.222
[41,     7] loss: 1.202
[42,     7] loss: 1.169
[43,     7] loss: 1.192
[44,     7] loss: 1.162
[45,     7] loss: 1.176
[46,     7] loss: 1.194
[47,     7] loss: 1.191
[48,     7] loss: 1.190
[49,     7] loss: 1.159
[50,     7] loss: 1.168
[51,     7] loss: 1.181
[52,     7] loss: 1.167
[53,     7] loss: 1.180
[54,     7] loss: 1.148
[55,     7] loss: 1.172
[56,     7] loss: 1.174
[57,     7] loss: 1.159
[58,     7] loss: 1.145
[59,     7] loss: 1.185
[60,     7] loss: 1.175
[61,     7] loss: 1.180
[62,     7] loss: 1.162
[63,     7] loss: 1.154
[64,     7] loss: 1.170
[65,     7] loss: 1.153
[66,     7] loss: 1.151
[67,     7] loss: 1.225
[68,     7] loss: 1.302
[69,     7] loss: 1.269
[70,     7] loss: 1.232
[71,     7] loss: 1.188
[72,     7] loss: 1.168
[73,     7] loss: 1.166
[74,     7] loss: 1.163
[75,     7] loss: 1.155
[76,     7] loss: 1.171
[77,     7] loss: 1.161
[78,     7] loss: 1.170
[79,     7] loss: 1.172
[80,     7] loss: 1.153
[81,     7] loss: 1.138
[82,     7] loss: 1.189
[83,     7] loss: 1.166
[84,     7] loss: 1.157
[85,     7] loss: 1.171
[86,     7] loss: 1.149
[87,     7] loss: 1.191
[88,     7] loss: 1.141
[89,     7] loss: 1.159
[90,     7] loss: 1.167
[91,     7] loss: 1.188
[92,     7] loss: 1.151
[93,     7] loss: 1.151
[94,     7] loss: 1.171
[95,     7] loss: 1.181
[96,     7] loss: 1.180
[97,     7] loss: 1.166
[98,     7] loss: 1.165
[99,     7] loss: 1.168
[100,     7] loss: 1.156
[101,     7] loss: 1.132
[102,     7] loss: 1.172
[103,     7] loss: 1.173
[104,     7] loss: 1.171
[105,     7] loss: 1.167
[106,     7] loss: 1.177
[107,     7] loss: 1.155
[108,     7] loss: 1.171
[109,     7] loss: 1.146
[110,     7] loss: 1.129
[111,     7] loss: 1.161
[112,     7] loss: 1.136
[113,     7] loss: 1.164
[114,     7] loss: 1.142
[115,     7] loss: 1.186
[116,     7] loss: 1.165
Early stopping applied (best metric=0.3500610589981079)
Finished Training
Total time taken: 100.80330348014832
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.400
[2,     7] loss: 1.387
[3,     7] loss: 1.385
[4,     7] loss: 1.381
[5,     7] loss: 1.354
[6,     7] loss: 1.323
[7,     7] loss: 1.310
[8,     7] loss: 1.300
[9,     7] loss: 1.282
[10,     7] loss: 1.275
[11,     7] loss: 1.264
[12,     7] loss: 1.257
[13,     7] loss: 1.248
[14,     7] loss: 1.245
[15,     7] loss: 1.234
[16,     7] loss: 1.239
[17,     7] loss: 1.230
[18,     7] loss: 1.259
[19,     7] loss: 1.235
[20,     7] loss: 1.227
[21,     7] loss: 1.217
[22,     7] loss: 1.225
[23,     7] loss: 1.233
[24,     7] loss: 1.219
[25,     7] loss: 1.214
[26,     7] loss: 1.217
[27,     7] loss: 1.219
[28,     7] loss: 1.206
[29,     7] loss: 1.183
[30,     7] loss: 1.234
[31,     7] loss: 1.229
[32,     7] loss: 1.188
[33,     7] loss: 1.180
[34,     7] loss: 1.186
[35,     7] loss: 1.185
[36,     7] loss: 1.185
[37,     7] loss: 1.249
[38,     7] loss: 1.220
[39,     7] loss: 1.179
[40,     7] loss: 1.198
[41,     7] loss: 1.188
[42,     7] loss: 1.198
[43,     7] loss: 1.188
[44,     7] loss: 1.187
[45,     7] loss: 1.197
[46,     7] loss: 1.186
[47,     7] loss: 1.148
[48,     7] loss: 1.174
[49,     7] loss: 1.174
[50,     7] loss: 1.160
[51,     7] loss: 1.144
[52,     7] loss: 1.152
[53,     7] loss: 1.219
[54,     7] loss: 1.200
[55,     7] loss: 1.198
[56,     7] loss: 1.154
[57,     7] loss: 1.144
[58,     7] loss: 1.146
[59,     7] loss: 1.206
[60,     7] loss: 1.165
[61,     7] loss: 1.180
[62,     7] loss: 1.175
[63,     7] loss: 1.184
[64,     7] loss: 1.191
[65,     7] loss: 1.213
[66,     7] loss: 1.172
[67,     7] loss: 1.159
[68,     7] loss: 1.136
[69,     7] loss: 1.172
[70,     7] loss: 1.175
[71,     7] loss: 1.176
[72,     7] loss: 1.189
[73,     7] loss: 1.175
[74,     7] loss: 1.143
[75,     7] loss: 1.140
[76,     7] loss: 1.155
[77,     7] loss: 1.149
[78,     7] loss: 1.176
[79,     7] loss: 1.166
[80,     7] loss: 1.167
[81,     7] loss: 1.185
[82,     7] loss: 1.173
[83,     7] loss: 1.152
[84,     7] loss: 1.175
[85,     7] loss: 1.140
[86,     7] loss: 1.162
[87,     7] loss: 1.152
[88,     7] loss: 1.179
[89,     7] loss: 1.164
[90,     7] loss: 1.146
[91,     7] loss: 1.127
[92,     7] loss: 1.155
[93,     7] loss: 1.200
[94,     7] loss: 1.227
[95,     7] loss: 1.184
[96,     7] loss: 1.139
[97,     7] loss: 1.131
[98,     7] loss: 1.191
[99,     7] loss: 1.227
[100,     7] loss: 1.221
[101,     7] loss: 1.190
[102,     7] loss: 1.147
[103,     7] loss: 1.152
[104,     7] loss: 1.150
[105,     7] loss: 1.183
[106,     7] loss: 1.159
[107,     7] loss: 1.169
[108,     7] loss: 1.153
[109,     7] loss: 1.154
[110,     7] loss: 1.167
[111,     7] loss: 1.179
[112,     7] loss: 1.132
[113,     7] loss: 1.189
[114,     7] loss: 1.164
[115,     7] loss: 1.238
[116,     7] loss: 1.171
[117,     7] loss: 1.149
[118,     7] loss: 1.158
[119,     7] loss: 1.138
[120,     7] loss: 1.148
[121,     7] loss: 1.151
[122,     7] loss: 1.153
[123,     7] loss: 1.158
[124,     7] loss: 1.136
[125,     7] loss: 1.159
[126,     7] loss: 1.162
[127,     7] loss: 1.174
[128,     7] loss: 1.141
[129,     7] loss: 1.146
[130,     7] loss: 1.140
[131,     7] loss: 1.161
[132,     7] loss: 1.168
[133,     7] loss: 1.141
[134,     7] loss: 1.141
[135,     7] loss: 1.159
[136,     7] loss: 1.149
[137,     7] loss: 1.142
[138,     7] loss: 1.183
[139,     7] loss: 1.122
[140,     7] loss: 1.145
[141,     7] loss: 1.137
[142,     7] loss: 1.141
Early stopping applied (best metric=0.3475954234600067)
Finished Training
Total time taken: 124.06136918067932
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.385
[3,     7] loss: 1.376
[4,     7] loss: 1.346
[5,     7] loss: 1.337
[6,     7] loss: 1.328
[7,     7] loss: 1.325
[8,     7] loss: 1.301
[9,     7] loss: 1.289
[10,     7] loss: 1.296
[11,     7] loss: 1.266
[12,     7] loss: 1.263
[13,     7] loss: 1.254
[14,     7] loss: 1.236
[15,     7] loss: 1.244
[16,     7] loss: 1.269
[17,     7] loss: 1.249
[18,     7] loss: 1.242
[19,     7] loss: 1.205
[20,     7] loss: 1.262
[21,     7] loss: 1.225
[22,     7] loss: 1.222
[23,     7] loss: 1.193
[24,     7] loss: 1.194
[25,     7] loss: 1.201
[26,     7] loss: 1.183
[27,     7] loss: 1.180
[28,     7] loss: 1.262
[29,     7] loss: 1.242
[30,     7] loss: 1.188
[31,     7] loss: 1.177
[32,     7] loss: 1.167
[33,     7] loss: 1.149
[34,     7] loss: 1.182
[35,     7] loss: 1.197
[36,     7] loss: 1.189
[37,     7] loss: 1.262
[38,     7] loss: 1.287
[39,     7] loss: 1.347
[40,     7] loss: 1.303
[41,     7] loss: 1.276
[42,     7] loss: 1.263
[43,     7] loss: 1.236
[44,     7] loss: 1.218
[45,     7] loss: 1.206
[46,     7] loss: 1.229
[47,     7] loss: 1.230
[48,     7] loss: 1.217
[49,     7] loss: 1.196
[50,     7] loss: 1.192
[51,     7] loss: 1.175
[52,     7] loss: 1.215
[53,     7] loss: 1.197
[54,     7] loss: 1.170
[55,     7] loss: 1.205
[56,     7] loss: 1.180
[57,     7] loss: 1.232
[58,     7] loss: 1.208
[59,     7] loss: 1.199
[60,     7] loss: 1.176
[61,     7] loss: 1.159
[62,     7] loss: 1.186
[63,     7] loss: 1.202
[64,     7] loss: 1.177
[65,     7] loss: 1.189
[66,     7] loss: 1.176
[67,     7] loss: 1.157
[68,     7] loss: 1.172
[69,     7] loss: 1.156
[70,     7] loss: 1.148
[71,     7] loss: 1.145
[72,     7] loss: 1.212
[73,     7] loss: 1.233
[74,     7] loss: 1.197
[75,     7] loss: 1.161
[76,     7] loss: 1.162
[77,     7] loss: 1.183
[78,     7] loss: 1.201
[79,     7] loss: 1.178
[80,     7] loss: 1.171
[81,     7] loss: 1.180
[82,     7] loss: 1.175
[83,     7] loss: 1.164
[84,     7] loss: 1.159
[85,     7] loss: 1.177
[86,     7] loss: 1.174
[87,     7] loss: 1.157
[88,     7] loss: 1.156
[89,     7] loss: 1.185
[90,     7] loss: 1.194
[91,     7] loss: 1.185
[92,     7] loss: 1.156
[93,     7] loss: 1.143
[94,     7] loss: 1.280
[95,     7] loss: 1.302
[96,     7] loss: 1.222
[97,     7] loss: 1.241
[98,     7] loss: 1.184
[99,     7] loss: 1.147
[100,     7] loss: 1.144
[101,     7] loss: 1.183
[102,     7] loss: 1.174
[103,     7] loss: 1.177
[104,     7] loss: 1.180
[105,     7] loss: 1.187
[106,     7] loss: 1.156
[107,     7] loss: 1.131
[108,     7] loss: 1.183
[109,     7] loss: 1.160
[110,     7] loss: 1.168
[111,     7] loss: 1.175
[112,     7] loss: 1.159
[113,     7] loss: 1.160
[114,     7] loss: 1.178
[115,     7] loss: 1.167
[116,     7] loss: 1.160
[117,     7] loss: 1.170
[118,     7] loss: 1.179
[119,     7] loss: 1.128
[120,     7] loss: 1.183
[121,     7] loss: 1.235
[122,     7] loss: 1.228
[123,     7] loss: 1.285
[124,     7] loss: 1.242
[125,     7] loss: 1.199
[126,     7] loss: 1.171
[127,     7] loss: 1.152
[128,     7] loss: 1.163
[129,     7] loss: 1.172
[130,     7] loss: 1.172
[131,     7] loss: 1.155
[132,     7] loss: 1.170
[133,     7] loss: 1.123
[134,     7] loss: 1.157
Early stopping applied (best metric=0.34826183319091797)
Finished Training
Total time taken: 116.44034886360168
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.382
[3,     7] loss: 1.362
[4,     7] loss: 1.324
[5,     7] loss: 1.326
[6,     7] loss: 1.308
[7,     7] loss: 1.287
[8,     7] loss: 1.292
[9,     7] loss: 1.292
[10,     7] loss: 1.253
[11,     7] loss: 1.251
[12,     7] loss: 1.235
[13,     7] loss: 1.238
[14,     7] loss: 1.249
[15,     7] loss: 1.248
[16,     7] loss: 1.256
[17,     7] loss: 1.230
[18,     7] loss: 1.240
[19,     7] loss: 1.223
[20,     7] loss: 1.210
[21,     7] loss: 1.248
[22,     7] loss: 1.232
[23,     7] loss: 1.225
[24,     7] loss: 1.212
[25,     7] loss: 1.222
[26,     7] loss: 1.229
[27,     7] loss: 1.219
[28,     7] loss: 1.224
[29,     7] loss: 1.230
[30,     7] loss: 1.265
[31,     7] loss: 1.251
[32,     7] loss: 1.236
[33,     7] loss: 1.219
[34,     7] loss: 1.204
[35,     7] loss: 1.221
[36,     7] loss: 1.190
[37,     7] loss: 1.249
[38,     7] loss: 1.232
[39,     7] loss: 1.208
[40,     7] loss: 1.204
[41,     7] loss: 1.185
[42,     7] loss: 1.197
[43,     7] loss: 1.209
[44,     7] loss: 1.193
[45,     7] loss: 1.193
[46,     7] loss: 1.211
[47,     7] loss: 1.228
[48,     7] loss: 1.213
[49,     7] loss: 1.175
[50,     7] loss: 1.205
[51,     7] loss: 1.205
[52,     7] loss: 1.178
[53,     7] loss: 1.166
[54,     7] loss: 1.212
[55,     7] loss: 1.175
[56,     7] loss: 1.203
[57,     7] loss: 1.220
[58,     7] loss: 1.176
[59,     7] loss: 1.164
[60,     7] loss: 1.176
[61,     7] loss: 1.176
[62,     7] loss: 1.162
[63,     7] loss: 1.175
[64,     7] loss: 1.167
[65,     7] loss: 1.192
[66,     7] loss: 1.154
[67,     7] loss: 1.183
[68,     7] loss: 1.195
[69,     7] loss: 1.191
[70,     7] loss: 1.165
[71,     7] loss: 1.157
[72,     7] loss: 1.157
[73,     7] loss: 1.177
[74,     7] loss: 1.169
[75,     7] loss: 1.183
[76,     7] loss: 1.143
[77,     7] loss: 1.135
[78,     7] loss: 1.145
[79,     7] loss: 1.274
[80,     7] loss: 1.258
[81,     7] loss: 1.247
[82,     7] loss: 1.203
[83,     7] loss: 1.180
[84,     7] loss: 1.159
[85,     7] loss: 1.157
[86,     7] loss: 1.140
[87,     7] loss: 1.183
[88,     7] loss: 1.200
[89,     7] loss: 1.184
[90,     7] loss: 1.160
[91,     7] loss: 1.140
[92,     7] loss: 1.191
[93,     7] loss: 1.182
[94,     7] loss: 1.214
[95,     7] loss: 1.186
[96,     7] loss: 1.147
[97,     7] loss: 1.149
[98,     7] loss: 1.179
[99,     7] loss: 1.173
[100,     7] loss: 1.172
[101,     7] loss: 1.164
[102,     7] loss: 1.189
[103,     7] loss: 1.166
Early stopping applied (best metric=0.35855311155319214)
Finished Training
Total time taken: 89.77125358581543
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.388
[2,     7] loss: 1.384
[3,     7] loss: 1.368
[4,     7] loss: 1.336
[5,     7] loss: 1.325
[6,     7] loss: 1.319
[7,     7] loss: 1.302
[8,     7] loss: 1.280
[9,     7] loss: 1.277
[10,     7] loss: 1.274
[11,     7] loss: 1.268
[12,     7] loss: 1.258
[13,     7] loss: 1.260
[14,     7] loss: 1.251
[15,     7] loss: 1.242
[16,     7] loss: 1.273
[17,     7] loss: 1.237
[18,     7] loss: 1.237
[19,     7] loss: 1.235
[20,     7] loss: 1.241
[21,     7] loss: 1.249
[22,     7] loss: 1.238
[23,     7] loss: 1.215
[24,     7] loss: 1.196
[25,     7] loss: 1.232
[26,     7] loss: 1.262
[27,     7] loss: 1.278
[28,     7] loss: 1.254
[29,     7] loss: 1.227
[30,     7] loss: 1.220
[31,     7] loss: 1.222
[32,     7] loss: 1.237
[33,     7] loss: 1.269
[34,     7] loss: 1.261
[35,     7] loss: 1.238
[36,     7] loss: 1.232
[37,     7] loss: 1.224
[38,     7] loss: 1.228
[39,     7] loss: 1.218
[40,     7] loss: 1.223
[41,     7] loss: 1.223
[42,     7] loss: 1.220
[43,     7] loss: 1.228
[44,     7] loss: 1.214
[45,     7] loss: 1.221
[46,     7] loss: 1.237
[47,     7] loss: 1.265
[48,     7] loss: 1.238
[49,     7] loss: 1.230
[50,     7] loss: 1.216
[51,     7] loss: 1.212
[52,     7] loss: 1.217
[53,     7] loss: 1.211
[54,     7] loss: 1.207
[55,     7] loss: 1.235
[56,     7] loss: 1.228
[57,     7] loss: 1.257
[58,     7] loss: 1.227
[59,     7] loss: 1.250
[60,     7] loss: 1.226
[61,     7] loss: 1.207
[62,     7] loss: 1.204
[63,     7] loss: 1.215
[64,     7] loss: 1.197
[65,     7] loss: 1.197
[66,     7] loss: 1.183
[67,     7] loss: 1.239
[68,     7] loss: 1.207
[69,     7] loss: 1.274
[70,     7] loss: 1.243
[71,     7] loss: 1.218
[72,     7] loss: 1.202
[73,     7] loss: 1.184
[74,     7] loss: 1.193
[75,     7] loss: 1.183
[76,     7] loss: 1.196
[77,     7] loss: 1.192
[78,     7] loss: 1.209
[79,     7] loss: 1.207
[80,     7] loss: 1.211
[81,     7] loss: 1.188
[82,     7] loss: 1.208
[83,     7] loss: 1.228
[84,     7] loss: 1.196
[85,     7] loss: 1.167
[86,     7] loss: 1.152
[87,     7] loss: 1.237
[88,     7] loss: 1.195
[89,     7] loss: 1.186
[90,     7] loss: 1.182
[91,     7] loss: 1.187
[92,     7] loss: 1.175
[93,     7] loss: 1.186
[94,     7] loss: 1.187
[95,     7] loss: 1.168
[96,     7] loss: 1.154
[97,     7] loss: 1.169
[98,     7] loss: 1.195
[99,     7] loss: 1.185
[100,     7] loss: 1.209
[101,     7] loss: 1.169
[102,     7] loss: 1.182
[103,     7] loss: 1.151
[104,     7] loss: 1.216
[105,     7] loss: 1.168
[106,     7] loss: 1.182
[107,     7] loss: 1.182
[108,     7] loss: 1.175
[109,     7] loss: 1.162
[110,     7] loss: 1.171
[111,     7] loss: 1.178
[112,     7] loss: 1.181
[113,     7] loss: 1.177
[114,     7] loss: 1.140
[115,     7] loss: 1.136
[116,     7] loss: 1.163
[117,     7] loss: 1.196
[118,     7] loss: 1.223
[119,     7] loss: 1.233
[120,     7] loss: 1.197
[121,     7] loss: 1.167
[122,     7] loss: 1.158
[123,     7] loss: 1.149
[124,     7] loss: 1.149
[125,     7] loss: 1.143
[126,     7] loss: 1.159
[127,     7] loss: 1.153
[128,     7] loss: 1.176
[129,     7] loss: 1.158
[130,     7] loss: 1.165
[131,     7] loss: 1.175
[132,     7] loss: 1.171
[133,     7] loss: 1.163
[134,     7] loss: 1.149
[135,     7] loss: 1.128
[136,     7] loss: 1.178
[137,     7] loss: 1.187
[138,     7] loss: 1.145
[139,     7] loss: 1.221
[140,     7] loss: 1.201
[141,     7] loss: 1.166
[142,     7] loss: 1.153
[143,     7] loss: 1.151
[144,     7] loss: 1.179
[145,     7] loss: 1.167
[146,     7] loss: 1.148
[147,     7] loss: 1.163
[148,     7] loss: 1.159
[149,     7] loss: 1.145
[150,     7] loss: 1.187
[151,     7] loss: 1.191
[152,     7] loss: 1.183
[153,     7] loss: 1.151
[154,     7] loss: 1.149
[155,     7] loss: 1.136
[156,     7] loss: 1.188
[157,     7] loss: 1.176
[158,     7] loss: 1.162
[159,     7] loss: 1.145
[160,     7] loss: 1.213
[161,     7] loss: 1.187
[162,     7] loss: 1.181
[163,     7] loss: 1.147
[164,     7] loss: 1.129
[165,     7] loss: 1.148
[166,     7] loss: 1.152
[167,     7] loss: 1.149
[168,     7] loss: 1.172
[169,     7] loss: 1.169
[170,     7] loss: 1.152
[171,     7] loss: 1.165
[172,     7] loss: 1.270
[173,     7] loss: 1.233
[174,     7] loss: 1.231
[175,     7] loss: 1.188
[176,     7] loss: 1.168
[177,     7] loss: 1.160
[178,     7] loss: 1.155
[179,     7] loss: 1.160
[180,     7] loss: 1.179
[181,     7] loss: 1.160
[182,     7] loss: 1.148
[183,     7] loss: 1.170
[184,     7] loss: 1.210
[185,     7] loss: 1.201
[186,     7] loss: 1.172
[187,     7] loss: 1.179
[188,     7] loss: 1.153
[189,     7] loss: 1.184
[190,     7] loss: 1.183
[191,     7] loss: 1.173
[192,     7] loss: 1.180
[193,     7] loss: 1.194
[194,     7] loss: 1.212
[195,     7] loss: 1.195
[196,     7] loss: 1.167
[197,     7] loss: 1.146
[198,     7] loss: 1.168
[199,     7] loss: 1.184
[200,     7] loss: 1.197
Finished Training
Total time taken: 174.59147143363953
{'Methylation-R Validation Accuracy': 0.5477028574617578, 'Methylation-R Validation Sensitivity': 0.8357336348681313, 'Methylation-R Validation Specificity': 0.5210552147239264, 'Methylation-R Validation Precision': 0.14610271528253826, 'Methylation-R AUC ROC': 0.7856394412909946, 'Methylation-R AUC PR': 0.34416040475460014, 'Methylation-R MCC': 0.2057254986085451, 'Methylation-R F1': 0.24617465774325892, 'Validation Loss (Methylation-R)': 0.3173176109790802, 'Methylation-K Validation Accuracy': 0.3836554292092883, 'Methylation-K Validation Sensitivity': 0.9151872898711793, 'Methylation-K Validation Specificity': 0.3260090896928295, 'Methylation-K Validation Precision': 0.12868381700862294, 'Methylation-K AUC ROC': 0.7301189171915721, 'Methylation-K AUC PR': 0.22143093780013587, 'Methylation-K MCC': 0.1567250049775388, 'Methylation-K F1': 0.22552602078051884, 'Validation Loss (Methylation-K)': 0.35154262781143186, 'Validation Loss (total)': 0.6688602209091187, 'TimeToTrain': 121.13354930877685}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00803094280983322,
 'learning_rate_Methylation-K': 6.909671584639631e-05,
 'learning_rate_Methylation-R': 0.0007722017723003063,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2514328462666904,
 'loss_weight_Methylation-R': 0.03761843288628819,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1487201173,
 'sample_weights': [0.942802226841444, 0.12507645059825023],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.46075083919336546,
 'weight_decay_Methylation-K': 8.216084436285715,
 'weight_decay_Methylation-R': 5.414743296484144}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.400
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009002858842044782,
 'learning_rate_Methylation-K': 0.003976542883301127,
 'learning_rate_Methylation-R': 0.006132398834868561,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.32122107348657025,
 'loss_weight_Methylation-R': 0.1491526127335209,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3606009107,
 'sample_weights': [0.03761843288628819, 0.2514328462666904],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.638981592647204,
 'weight_decay_Methylation-K': 3.8828247208133457,
 'weight_decay_Methylation-R': 9.200926047809418}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.373
[8,     7] loss: 1.353
[9,     7] loss: 1.369
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00861335005998102,
 'learning_rate_Methylation-K': 0.0004110638368270786,
 'learning_rate_Methylation-R': 0.008791406332642583,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.15722418599816324,
 'loss_weight_Methylation-R': 0.14335932574332177,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 926165653,
 'sample_weights': [0.1491526127335209, 0.32122107348657025],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.375899886275914,
 'weight_decay_Methylation-K': 5.641885026365064,
 'weight_decay_Methylation-R': 7.140629956489822}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.362
[6,     7] loss: 1.330
[7,     7] loss: 1.320
[8,     7] loss: 1.325
[9,     7] loss: 1.307
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00991494288199127,
 'learning_rate_Methylation-K': 0.0028951351961321536,
 'learning_rate_Methylation-R': 0.0046273720535722936,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.012650809006667874,
 'loss_weight_Methylation-R': 0.9727239275553877,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 351306522,
 'sample_weights': [0.14335932574332177, 0.15722418599816324],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.313795156398784,
 'weight_decay_Methylation-K': 2.786302808838296,
 'weight_decay_Methylation-R': 8.672822397202305}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006815651078882895,
 'learning_rate_Methylation-K': 0.0011899144841762575,
 'learning_rate_Methylation-R': 0.005327244755419614,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.46870238178556867,
 'loss_weight_Methylation-R': 0.30678825963667544,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4116634500,
 'sample_weights': [0.9727239275553877, 0.012650809006667874],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.505980112761149,
 'weight_decay_Methylation-K': 6.956563003789853,
 'weight_decay_Methylation-R': 5.381389224373007}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00571544632492017,
 'learning_rate_Methylation-K': 0.0068344040622570915,
 'learning_rate_Methylation-R': 0.006697480334202862,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.10444494778364705,
 'loss_weight_Methylation-R': 0.7936320776559799,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2899283605,
 'sample_weights': [0.30678825963667544, 0.46870238178556867],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.35495599418283,
 'weight_decay_Methylation-K': 7.2555088855193075,
 'weight_decay_Methylation-R': 2.5287520675236728}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.383
[3,     7] loss: 1.356
[4,     7] loss: 1.338
[5,     7] loss: 1.316
[6,     7] loss: 1.296
[7,     7] loss: 1.295
[8,     7] loss: 1.308
[9,     7] loss: 1.280
[10,     7] loss: 1.274
[11,     7] loss: 1.289
[12,     7] loss: 1.271
[13,     7] loss: 1.306
[14,     7] loss: 1.305
[15,     7] loss: 1.290
[16,     7] loss: 1.279
[17,     7] loss: 1.280
[18,     7] loss: 1.268
[19,     7] loss: 1.252
[20,     7] loss: 1.303
[21,     7] loss: 1.274
[22,     7] loss: 1.255
[23,     7] loss: 1.275
[24,     7] loss: 1.272
[25,     7] loss: 1.260
[26,     7] loss: 1.264
[27,     7] loss: 1.271
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00488538434368195,
 'learning_rate_Methylation-K': 0.008551988580008349,
 'learning_rate_Methylation-R': 0.0055253016131227494,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7898603579108037,
 'loss_weight_Methylation-R': 0.1618319510772065,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2578715911,
 'sample_weights': [0.7936320776559799, 0.10444494778364705],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1491506265829408,
 'weight_decay_Methylation-K': 7.81834101176308,
 'weight_decay_Methylation-R': 3.1703134466208778}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.350
[3,     7] loss: 1.341
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006270022586665351,
 'learning_rate_Methylation-K': 0.006387293807617403,
 'learning_rate_Methylation-R': 0.009011786511104012,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.38630788692931595,
 'loss_weight_Methylation-R': 0.72618326836131,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1438531513,
 'sample_weights': [0.1618319510772065, 0.7898603579108037],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.218398317401348,
 'weight_decay_Methylation-K': 7.4820809518710245,
 'weight_decay_Methylation-R': 4.964487240187139}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013328424599164442,
 'learning_rate_Methylation-K': 0.0076263600404862944,
 'learning_rate_Methylation-R': 0.006752945944267122,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6830314429616762,
 'loss_weight_Methylation-R': 0.9599320472278439,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 413321303,
 'sample_weights': [0.72618326836131, 0.38630788692931595],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.161215927328658,
 'weight_decay_Methylation-K': 9.675586301128497,
 'weight_decay_Methylation-R': 2.4588713795153607}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.379
[3,     7] loss: 1.357
[4,     7] loss: 1.334
[5,     7] loss: 1.323
[6,     7] loss: 1.302
[7,     7] loss: 1.293
[8,     7] loss: 1.279
[9,     7] loss: 1.276
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008487007135094312,
 'learning_rate_Methylation-K': 0.006014874952362163,
 'learning_rate_Methylation-R': 0.007838376858593258,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7840294844292275,
 'loss_weight_Methylation-R': 0.6438569430153183,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2784907245,
 'sample_weights': [0.9599320472278439, 0.6830314429616762],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7862018166483074,
 'weight_decay_Methylation-K': 6.3599919048081,
 'weight_decay_Methylation-R': 3.649767288463228}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.396
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008815858526485972,
 'learning_rate_Methylation-K': 0.008431353143006654,
 'learning_rate_Methylation-R': 0.009045172974868386,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5251023141043705,
 'loss_weight_Methylation-R': 0.44416644229147256,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1846125891,
 'sample_weights': [0.6438569430153183, 0.7840294844292275],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.2338369697366476,
 'weight_decay_Methylation-K': 1.8357038708989366,
 'weight_decay_Methylation-R': 7.195176055844297}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008294335389984803,
 'learning_rate_Methylation-K': 0.00020234191743846405,
 'learning_rate_Methylation-R': 0.004080361024747666,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.28488174537690336,
 'loss_weight_Methylation-R': 0.8378228709368085,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1864981623,
 'sample_weights': [0.44416644229147256, 0.5251023141043705],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1044566678124905,
 'weight_decay_Methylation-K': 9.319602937474817,
 'weight_decay_Methylation-R': 8.498408480432085}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00357638585601163,
 'learning_rate_Methylation-K': 0.004686791776744563,
 'learning_rate_Methylation-R': 0.0036045929102664995,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9407322345363976,
 'loss_weight_Methylation-R': 0.9537454871793001,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3809236059,
 'sample_weights': [0.8378228709368085, 0.28488174537690336],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.629398967061261,
 'weight_decay_Methylation-K': 4.46651858204789,
 'weight_decay_Methylation-R': 7.6206606953769205}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.379
[3,     7] loss: 1.345
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008262638127416472,
 'learning_rate_Methylation-K': 0.009215042989754667,
 'learning_rate_Methylation-R': 0.003536729366696744,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.05448621725081754,
 'loss_weight_Methylation-R': 0.26329585655910837,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1127357086,
 'sample_weights': [0.9537454871793001, 0.9407322345363976],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.4354400483019316,
 'weight_decay_Methylation-K': 6.096719017545187,
 'weight_decay_Methylation-R': 8.756127396031683}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00906860019512573,
 'learning_rate_Methylation-K': 0.007669431917381128,
 'learning_rate_Methylation-R': 0.007780196373202817,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3617031314406699,
 'loss_weight_Methylation-R': 0.7521464742351014,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2388920238,
 'sample_weights': [0.26329585655910837, 0.05448621725081754],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.3854382452104623,
 'weight_decay_Methylation-K': 6.757873751507217,
 'weight_decay_Methylation-R': 2.6713956448407754}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.388
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00475811720072721,
 'learning_rate_Methylation-K': 0.00026384320445774364,
 'learning_rate_Methylation-R': 0.0022921439945225463,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.09317739042831856,
 'loss_weight_Methylation-R': 0.9369673388041735,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2726687,
 'sample_weights': [0.7521464742351014, 0.3617031314406699],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2966550224485642,
 'weight_decay_Methylation-K': 5.274783172807615,
 'weight_decay_Methylation-R': 9.217504645429859}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.383
[5,     7] loss: 1.370
[6,     7] loss: 1.339
[7,     7] loss: 1.325
[8,     7] loss: 1.326
[9,     7] loss: 1.306
[10,     7] loss: 1.296
[11,     7] loss: 1.293
[12,     7] loss: 1.278
[13,     7] loss: 1.262
[14,     7] loss: 1.252
[15,     7] loss: 1.245
[16,     7] loss: 1.272
[17,     7] loss: 1.257
[18,     7] loss: 1.243
[19,     7] loss: 1.228
[20,     7] loss: 1.232
[21,     7] loss: 1.221
[22,     7] loss: 1.220
[23,     7] loss: 1.223
[24,     7] loss: 1.224
[25,     7] loss: 1.217
[26,     7] loss: 1.203
[27,     7] loss: 1.191
[28,     7] loss: 1.222
[29,     7] loss: 1.214
[30,     7] loss: 1.200
[31,     7] loss: 1.172
[32,     7] loss: 1.181
[33,     7] loss: 1.179
[34,     7] loss: 1.210
[35,     7] loss: 1.179
[36,     7] loss: 1.176
[37,     7] loss: 1.160
[38,     7] loss: 1.154
[39,     7] loss: 1.213
[40,     7] loss: 1.178
[41,     7] loss: 1.182
[42,     7] loss: 1.140
[43,     7] loss: 1.179
[44,     7] loss: 1.161
[45,     7] loss: 1.139
[46,     7] loss: 1.155
[47,     7] loss: 1.168
[48,     7] loss: 1.165
[49,     7] loss: 1.158
[50,     7] loss: 1.181
[51,     7] loss: 1.161
[52,     7] loss: 1.151
[53,     7] loss: 1.192
[54,     7] loss: 1.160
[55,     7] loss: 1.163
[56,     7] loss: 1.142
[57,     7] loss: 1.141
[58,     7] loss: 1.187
[59,     7] loss: 1.157
[60,     7] loss: 1.148
[61,     7] loss: 1.149
[62,     7] loss: 1.145
[63,     7] loss: 1.147
[64,     7] loss: 1.151
[65,     7] loss: 1.158
[66,     7] loss: 1.215
[67,     7] loss: 1.185
[68,     7] loss: 1.142
[69,     7] loss: 1.145
[70,     7] loss: 1.129
[71,     7] loss: 1.152
[72,     7] loss: 1.158
[73,     7] loss: 1.144
[74,     7] loss: 1.141
[75,     7] loss: 1.129
[76,     7] loss: 1.121
[77,     7] loss: 1.147
[78,     7] loss: 1.126
[79,     7] loss: 1.113
[80,     7] loss: 1.253
[81,     7] loss: 1.256
[82,     7] loss: 1.211
[83,     7] loss: 1.161
[84,     7] loss: 1.146
[85,     7] loss: 1.125
[86,     7] loss: 1.134
[87,     7] loss: 1.121
[88,     7] loss: 1.135
[89,     7] loss: 1.128
[90,     7] loss: 1.157
[91,     7] loss: 1.144
[92,     7] loss: 1.132
[93,     7] loss: 1.120
[94,     7] loss: 1.130
[95,     7] loss: 1.156
[96,     7] loss: 1.148
[97,     7] loss: 1.138
[98,     7] loss: 1.131
[99,     7] loss: 1.135
[100,     7] loss: 1.127
[101,     7] loss: 1.102
[102,     7] loss: 1.122
[103,     7] loss: 1.152
[104,     7] loss: 1.132
[105,     7] loss: 1.130
[106,     7] loss: 1.124
[107,     7] loss: 1.117
[108,     7] loss: 1.099
[109,     7] loss: 1.155
[110,     7] loss: 1.129
[111,     7] loss: 1.138
[112,     7] loss: 1.111
[113,     7] loss: 1.110
[114,     7] loss: 1.155
[115,     7] loss: 1.145
[116,     7] loss: 1.115
[117,     7] loss: 1.122
[118,     7] loss: 1.174
[119,     7] loss: 1.191
[120,     7] loss: 1.135
[121,     7] loss: 1.129
[122,     7] loss: 1.138
[123,     7] loss: 1.126
[124,     7] loss: 1.192
[125,     7] loss: 1.250
[126,     7] loss: 1.206
[127,     7] loss: 1.156
[128,     7] loss: 1.127
[129,     7] loss: 1.119
Early stopping applied (best metric=0.35290074348449707)
Finished Training
Total time taken: 113.6000759601593
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.384
[4,     7] loss: 1.370
[5,     7] loss: 1.340
[6,     7] loss: 1.321
[7,     7] loss: 1.317
[8,     7] loss: 1.304
[9,     7] loss: 1.286
[10,     7] loss: 1.281
[11,     7] loss: 1.275
[12,     7] loss: 1.261
[13,     7] loss: 1.287
[14,     7] loss: 1.266
[15,     7] loss: 1.241
[16,     7] loss: 1.241
[17,     7] loss: 1.229
[18,     7] loss: 1.228
[19,     7] loss: 1.262
[20,     7] loss: 1.233
[21,     7] loss: 1.220
[22,     7] loss: 1.237
[23,     7] loss: 1.222
[24,     7] loss: 1.218
[25,     7] loss: 1.202
[26,     7] loss: 1.224
[27,     7] loss: 1.231
[28,     7] loss: 1.230
[29,     7] loss: 1.215
[30,     7] loss: 1.217
[31,     7] loss: 1.193
[32,     7] loss: 1.188
[33,     7] loss: 1.207
[34,     7] loss: 1.183
[35,     7] loss: 1.180
[36,     7] loss: 1.206
[37,     7] loss: 1.194
[38,     7] loss: 1.183
[39,     7] loss: 1.159
[40,     7] loss: 1.150
[41,     7] loss: 1.154
[42,     7] loss: 1.183
[43,     7] loss: 1.170
[44,     7] loss: 1.169
[45,     7] loss: 1.156
[46,     7] loss: 1.162
[47,     7] loss: 1.145
[48,     7] loss: 1.141
[49,     7] loss: 1.136
[50,     7] loss: 1.097
[51,     7] loss: 1.122
[52,     7] loss: 1.112
[53,     7] loss: 1.129
[54,     7] loss: 1.150
[55,     7] loss: 1.152
[56,     7] loss: 1.123
[57,     7] loss: 1.121
[58,     7] loss: 1.102
[59,     7] loss: 1.099
[60,     7] loss: 1.119
[61,     7] loss: 1.109
[62,     7] loss: 1.194
[63,     7] loss: 1.148
[64,     7] loss: 1.137
[65,     7] loss: 1.103
[66,     7] loss: 1.110
[67,     7] loss: 1.107
[68,     7] loss: 1.104
[69,     7] loss: 1.093
[70,     7] loss: 1.130
[71,     7] loss: 1.112
[72,     7] loss: 1.097
[73,     7] loss: 1.125
[74,     7] loss: 1.124
[75,     7] loss: 1.111
[76,     7] loss: 1.111
[77,     7] loss: 1.097
[78,     7] loss: 1.070
[79,     7] loss: 1.203
[80,     7] loss: 1.194
[81,     7] loss: 1.149
[82,     7] loss: 1.134
[83,     7] loss: 1.115
[84,     7] loss: 1.099
[85,     7] loss: 1.123
[86,     7] loss: 1.085
[87,     7] loss: 1.098
[88,     7] loss: 1.074
[89,     7] loss: 1.080
[90,     7] loss: 1.135
[91,     7] loss: 1.111
[92,     7] loss: 1.095
[93,     7] loss: 1.102
[94,     7] loss: 1.105
[95,     7] loss: 1.082
Early stopping applied (best metric=0.4159770607948303)
Finished Training
Total time taken: 87.49798059463501
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.381
[4,     7] loss: 1.356
[5,     7] loss: 1.329
[6,     7] loss: 1.310
[7,     7] loss: 1.313
[8,     7] loss: 1.287
[9,     7] loss: 1.278
[10,     7] loss: 1.283
[11,     7] loss: 1.275
[12,     7] loss: 1.270
[13,     7] loss: 1.247
[14,     7] loss: 1.253
[15,     7] loss: 1.244
[16,     7] loss: 1.228
[17,     7] loss: 1.222
[18,     7] loss: 1.221
[19,     7] loss: 1.220
[20,     7] loss: 1.213
[21,     7] loss: 1.203
[22,     7] loss: 1.226
[23,     7] loss: 1.230
[24,     7] loss: 1.217
[25,     7] loss: 1.186
[26,     7] loss: 1.182
[27,     7] loss: 1.198
[28,     7] loss: 1.170
[29,     7] loss: 1.149
[30,     7] loss: 1.165
[31,     7] loss: 1.190
[32,     7] loss: 1.148
[33,     7] loss: 1.170
[34,     7] loss: 1.143
[35,     7] loss: 1.134
[36,     7] loss: 1.122
[37,     7] loss: 1.154
[38,     7] loss: 1.145
[39,     7] loss: 1.129
[40,     7] loss: 1.130
[41,     7] loss: 1.156
[42,     7] loss: 1.146
[43,     7] loss: 1.135
[44,     7] loss: 1.122
[45,     7] loss: 1.124
[46,     7] loss: 1.125
[47,     7] loss: 1.134
[48,     7] loss: 1.127
[49,     7] loss: 1.139
[50,     7] loss: 1.097
[51,     7] loss: 1.105
[52,     7] loss: 1.115
[53,     7] loss: 1.121
[54,     7] loss: 1.122
[55,     7] loss: 1.152
[56,     7] loss: 1.141
[57,     7] loss: 1.102
[58,     7] loss: 1.091
[59,     7] loss: 1.070
[60,     7] loss: 1.084
[61,     7] loss: 1.102
[62,     7] loss: 1.110
[63,     7] loss: 1.107
[64,     7] loss: 1.091
[65,     7] loss: 1.112
[66,     7] loss: 1.093
[67,     7] loss: 1.081
[68,     7] loss: 1.160
[69,     7] loss: 1.131
[70,     7] loss: 1.093
[71,     7] loss: 1.099
[72,     7] loss: 1.097
[73,     7] loss: 1.089
[74,     7] loss: 1.119
[75,     7] loss: 1.127
[76,     7] loss: 1.106
[77,     7] loss: 1.092
[78,     7] loss: 1.093
[79,     7] loss: 1.117
[80,     7] loss: 1.105
[81,     7] loss: 1.117
[82,     7] loss: 1.095
[83,     7] loss: 1.086
[84,     7] loss: 1.080
[85,     7] loss: 1.079
[86,     7] loss: 1.086
[87,     7] loss: 1.086
[88,     7] loss: 1.117
[89,     7] loss: 1.082
[90,     7] loss: 1.085
[91,     7] loss: 1.143
[92,     7] loss: 1.145
[93,     7] loss: 1.124
[94,     7] loss: 1.114
[95,     7] loss: 1.089
[96,     7] loss: 1.079
[97,     7] loss: 1.109
[98,     7] loss: 1.109
[99,     7] loss: 1.119
[100,     7] loss: 1.087
[101,     7] loss: 1.096
[102,     7] loss: 1.071
[103,     7] loss: 1.109
[104,     7] loss: 1.118
[105,     7] loss: 1.102
[106,     7] loss: 1.119
[107,     7] loss: 1.087
[108,     7] loss: 1.071
[109,     7] loss: 1.070
[110,     7] loss: 1.091
[111,     7] loss: 1.118
[112,     7] loss: 1.092
Early stopping applied (best metric=0.4267483353614807)
Finished Training
Total time taken: 98.06826686859131
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.385
[3,     7] loss: 1.380
[4,     7] loss: 1.354
[5,     7] loss: 1.333
[6,     7] loss: 1.330
[7,     7] loss: 1.322
[8,     7] loss: 1.305
[9,     7] loss: 1.303
[10,     7] loss: 1.289
[11,     7] loss: 1.276
[12,     7] loss: 1.255
[13,     7] loss: 1.245
[14,     7] loss: 1.265
[15,     7] loss: 1.250
[16,     7] loss: 1.234
[17,     7] loss: 1.226
[18,     7] loss: 1.225
[19,     7] loss: 1.227
[20,     7] loss: 1.244
[21,     7] loss: 1.223
[22,     7] loss: 1.231
[23,     7] loss: 1.215
[24,     7] loss: 1.221
[25,     7] loss: 1.218
[26,     7] loss: 1.203
[27,     7] loss: 1.182
[28,     7] loss: 1.195
[29,     7] loss: 1.179
[30,     7] loss: 1.197
[31,     7] loss: 1.185
[32,     7] loss: 1.168
[33,     7] loss: 1.249
[34,     7] loss: 1.190
[35,     7] loss: 1.183
[36,     7] loss: 1.191
[37,     7] loss: 1.162
[38,     7] loss: 1.203
[39,     7] loss: 1.222
[40,     7] loss: 1.178
[41,     7] loss: 1.214
[42,     7] loss: 1.235
[43,     7] loss: 1.241
[44,     7] loss: 1.193
[45,     7] loss: 1.175
[46,     7] loss: 1.154
[47,     7] loss: 1.156
[48,     7] loss: 1.143
[49,     7] loss: 1.173
[50,     7] loss: 1.131
[51,     7] loss: 1.152
[52,     7] loss: 1.172
[53,     7] loss: 1.146
[54,     7] loss: 1.131
[55,     7] loss: 1.132
[56,     7] loss: 1.142
[57,     7] loss: 1.130
[58,     7] loss: 1.137
[59,     7] loss: 1.113
[60,     7] loss: 1.169
[61,     7] loss: 1.158
[62,     7] loss: 1.127
[63,     7] loss: 1.134
[64,     7] loss: 1.125
[65,     7] loss: 1.128
[66,     7] loss: 1.092
[67,     7] loss: 1.176
[68,     7] loss: 1.162
[69,     7] loss: 1.154
[70,     7] loss: 1.126
[71,     7] loss: 1.109
[72,     7] loss: 1.102
[73,     7] loss: 1.108
[74,     7] loss: 1.142
[75,     7] loss: 1.116
[76,     7] loss: 1.124
[77,     7] loss: 1.105
[78,     7] loss: 1.118
[79,     7] loss: 1.117
[80,     7] loss: 1.134
[81,     7] loss: 1.135
[82,     7] loss: 1.121
Early stopping applied (best metric=0.38032299280166626)
Finished Training
Total time taken: 71.20568585395813
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.385
[4,     7] loss: 1.383
[5,     7] loss: 1.362
[6,     7] loss: 1.327
[7,     7] loss: 1.324
[8,     7] loss: 1.304
[9,     7] loss: 1.285
[10,     7] loss: 1.278
[11,     7] loss: 1.259
[12,     7] loss: 1.269
[13,     7] loss: 1.245
[14,     7] loss: 1.249
[15,     7] loss: 1.242
[16,     7] loss: 1.255
[17,     7] loss: 1.261
[18,     7] loss: 1.248
[19,     7] loss: 1.245
[20,     7] loss: 1.224
[21,     7] loss: 1.207
[22,     7] loss: 1.213
[23,     7] loss: 1.228
[24,     7] loss: 1.211
[25,     7] loss: 1.190
[26,     7] loss: 1.198
[27,     7] loss: 1.218
[28,     7] loss: 1.221
[29,     7] loss: 1.179
[30,     7] loss: 1.180
[31,     7] loss: 1.164
[32,     7] loss: 1.181
[33,     7] loss: 1.159
[34,     7] loss: 1.169
[35,     7] loss: 1.158
[36,     7] loss: 1.175
[37,     7] loss: 1.145
[38,     7] loss: 1.188
[39,     7] loss: 1.150
[40,     7] loss: 1.133
[41,     7] loss: 1.230
[42,     7] loss: 1.202
[43,     7] loss: 1.157
[44,     7] loss: 1.152
[45,     7] loss: 1.135
[46,     7] loss: 1.132
[47,     7] loss: 1.162
[48,     7] loss: 1.156
[49,     7] loss: 1.125
[50,     7] loss: 1.135
[51,     7] loss: 1.154
[52,     7] loss: 1.126
[53,     7] loss: 1.134
[54,     7] loss: 1.138
[55,     7] loss: 1.121
[56,     7] loss: 1.118
[57,     7] loss: 1.098
[58,     7] loss: 1.113
[59,     7] loss: 1.246
[60,     7] loss: 1.201
[61,     7] loss: 1.168
[62,     7] loss: 1.121
[63,     7] loss: 1.124
[64,     7] loss: 1.137
[65,     7] loss: 1.117
[66,     7] loss: 1.153
[67,     7] loss: 1.129
[68,     7] loss: 1.110
[69,     7] loss: 1.139
[70,     7] loss: 1.126
[71,     7] loss: 1.116
[72,     7] loss: 1.095
[73,     7] loss: 1.104
[74,     7] loss: 1.132
[75,     7] loss: 1.161
[76,     7] loss: 1.159
[77,     7] loss: 1.128
[78,     7] loss: 1.089
[79,     7] loss: 1.114
[80,     7] loss: 1.108
[81,     7] loss: 1.148
[82,     7] loss: 1.134
[83,     7] loss: 1.115
[84,     7] loss: 1.095
[85,     7] loss: 1.085
[86,     7] loss: 1.120
[87,     7] loss: 1.097
[88,     7] loss: 1.117
[89,     7] loss: 1.111
[90,     7] loss: 1.103
Early stopping applied (best metric=0.35399991273880005)
Finished Training
Total time taken: 79.20823812484741
{'Methylation-R Validation Accuracy': 0.5276175394001376, 'Methylation-R Validation Sensitivity': 0.8596415399410317, 'Methylation-R Validation Specificity': 0.4969079754601227, 'Methylation-R Validation Precision': 0.1401211909720506, 'Methylation-R AUC ROC': 0.7953233854814694, 'Methylation-R AUC PR': 0.35267433131491027, 'Methylation-R MCC': 0.2026844298672786, 'Methylation-R F1': 0.23994344679686655, 'Validation Loss (Methylation-R)': 0.3054250359535217, 'Methylation-K Validation Accuracy': 0.4444834656306027, 'Methylation-K Validation Sensitivity': 0.803421939837046, 'Methylation-K Validation Specificity': 0.4055567139017196, 'Methylation-K Validation Precision': 0.12853721044642352, 'Methylation-K AUC ROC': 0.6687045347759812, 'Methylation-K AUC PR': 0.17273770564156046, 'Methylation-K MCC': 0.13017605982586544, 'Methylation-K F1': 0.22116807241373923, 'Validation Loss (Methylation-K)': 0.3859898090362549, 'Validation Loss (total)': 0.6914148569107056, 'TimeToTrain': 89.91604948043823}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00894097397767912,
 'learning_rate_Methylation-K': 5.85599633686776e-05,
 'learning_rate_Methylation-R': 0.0056500881485921925,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5204934735636159,
 'loss_weight_Methylation-R': 0.74790773064982,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2514169277,
 'sample_weights': [0.9369673388041735, 0.09317739042831856],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.593973175761464,
 'weight_decay_Methylation-K': 9.695425923849866,
 'weight_decay_Methylation-R': 9.181439118398249}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004191489660286996,
 'learning_rate_Methylation-K': 0.0011976803928801757,
 'learning_rate_Methylation-R': 0.004618339487855078,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4552190121954535,
 'loss_weight_Methylation-R': 0.5716012728173236,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2876582765,
 'sample_weights': [0.74790773064982, 0.5204934735636159],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.479611458443523,
 'weight_decay_Methylation-K': 1.5023720600578785,
 'weight_decay_Methylation-R': 9.430047082493552}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.382
[4,     7] loss: 1.356
[5,     7] loss: 1.324
[6,     7] loss: 1.313
[7,     7] loss: 1.300
[8,     7] loss: 1.286
[9,     7] loss: 1.291
[10,     7] loss: 1.288
[11,     7] loss: 1.277
[12,     7] loss: 1.257
[13,     7] loss: 1.267
[14,     7] loss: 1.254
[15,     7] loss: 1.257
[16,     7] loss: 1.253
[17,     7] loss: 1.270
[18,     7] loss: 1.268
[19,     7] loss: 1.250
[20,     7] loss: 1.240
[21,     7] loss: 1.255
[22,     7] loss: 1.249
[23,     7] loss: 1.223
[24,     7] loss: 1.255
[25,     7] loss: 1.259
[26,     7] loss: 1.234
[27,     7] loss: 1.233
[28,     7] loss: 1.229
[29,     7] loss: 1.210
[30,     7] loss: 1.242
[31,     7] loss: 1.305
[32,     7] loss: 1.302
[33,     7] loss: 1.265
[34,     7] loss: 1.237
[35,     7] loss: 1.266
[36,     7] loss: 1.251
[37,     7] loss: 1.237
[38,     7] loss: 1.223
[39,     7] loss: 1.219
[40,     7] loss: 1.215
[41,     7] loss: 1.296
[42,     7] loss: 1.283
[43,     7] loss: 1.256
[44,     7] loss: 1.232
[45,     7] loss: 1.215
[46,     7] loss: 1.244
[47,     7] loss: 1.227
[48,     7] loss: 1.217
[49,     7] loss: 1.211
[50,     7] loss: 1.216
[51,     7] loss: 1.205
[52,     7] loss: 1.186
[53,     7] loss: 1.194
[54,     7] loss: 1.217
[55,     7] loss: 1.211
[56,     7] loss: 1.207
[57,     7] loss: 1.196
[58,     7] loss: 1.170
[59,     7] loss: 1.197
[60,     7] loss: 1.179
[61,     7] loss: 1.190
[62,     7] loss: 1.183
[63,     7] loss: 1.213
[64,     7] loss: 1.172
[65,     7] loss: 1.164
[66,     7] loss: 1.222
[67,     7] loss: 1.208
[68,     7] loss: 1.181
[69,     7] loss: 1.170
[70,     7] loss: 1.198
[71,     7] loss: 1.210
[72,     7] loss: 1.182
[73,     7] loss: 1.233
[74,     7] loss: 1.204
[75,     7] loss: 1.177
[76,     7] loss: 1.179
[77,     7] loss: 1.156
[78,     7] loss: 1.193
[79,     7] loss: 1.195
[80,     7] loss: 1.239
[81,     7] loss: 1.225
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027678403068918623,
 'learning_rate_Methylation-K': 0.006315769977157459,
 'learning_rate_Methylation-R': 0.00957006273793742,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9485618662906761,
 'loss_weight_Methylation-R': 0.5097452956373085,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2533126708,
 'sample_weights': [0.5716012728173236, 0.4552190121954535],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.889906046381226,
 'weight_decay_Methylation-K': 5.017202533152532,
 'weight_decay_Methylation-R': 3.437296829703553}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.385
[3,     7] loss: 1.375
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005202291645226474,
 'learning_rate_Methylation-K': 0.005024516571517087,
 'learning_rate_Methylation-R': 0.0055081540817380654,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6657441178410042,
 'loss_weight_Methylation-R': 0.9562346943902031,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2524219145,
 'sample_weights': [0.5097452956373085, 0.9485618662906761],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9914421443764283,
 'weight_decay_Methylation-K': 4.3862183680019555,
 'weight_decay_Methylation-R': 9.244839629705186}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004523794912097093,
 'learning_rate_Methylation-K': 0.00979381421678996,
 'learning_rate_Methylation-R': 0.00920163841873692,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2293137446401594,
 'loss_weight_Methylation-R': 0.9637334614670235,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1079859421,
 'sample_weights': [0.9562346943902031, 0.6657441178410042],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.937563486816321,
 'weight_decay_Methylation-K': 4.500680650042903,
 'weight_decay_Methylation-R': 4.524045701640954}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.396
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.384
[5,     7] loss: 1.358
[6,     7] loss: 1.328
[7,     7] loss: 1.311
[8,     7] loss: 1.292
[9,     7] loss: 1.320
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008020237841880901,
 'learning_rate_Methylation-K': 0.001128425393673472,
 'learning_rate_Methylation-R': 0.006738703144768416,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2629387311556563,
 'loss_weight_Methylation-R': 0.891878972119976,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4140945083,
 'sample_weights': [0.9637334614670235, 0.2293137446401594],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.666923843839353,
 'weight_decay_Methylation-K': 3.0714327920188493,
 'weight_decay_Methylation-R': 5.582879819323055}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00917743411552735,
 'learning_rate_Methylation-K': 0.0013339914469566332,
 'learning_rate_Methylation-R': 0.00756291568738511,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.24617720096441725,
 'loss_weight_Methylation-R': 0.6272799825213496,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4066863443,
 'sample_weights': [0.891878972119976, 0.2629387311556563],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7334486651288721,
 'weight_decay_Methylation-K': 8.469317905230206,
 'weight_decay_Methylation-R': 3.154738594772297}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008862913925193637,
 'learning_rate_Methylation-K': 0.0025041603391235587,
 'learning_rate_Methylation-R': 0.0035987868168234176,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.023771672886509,
 'loss_weight_Methylation-R': 0.988372515787793,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1774260431,
 'sample_weights': [0.6272799825213496, 0.24617720096441725],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.366161681480916,
 'weight_decay_Methylation-K': 8.976718057117788,
 'weight_decay_Methylation-R': 1.4306814107656065}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.368
[9,     7] loss: 1.371
[10,     7] loss: 1.384
[11,     7] loss: 1.387
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009242189025750167,
 'learning_rate_Methylation-K': 0.00039708696058417747,
 'learning_rate_Methylation-R': 0.0068524022893602515,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4821723897869555,
 'loss_weight_Methylation-R': 0.795586328910816,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4138518282,
 'sample_weights': [0.988372515787793, 0.023771672886509],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.41040912459893364,
 'weight_decay_Methylation-K': 9.249760619521263,
 'weight_decay_Methylation-R': 9.894962771870015}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008826497751920253,
 'learning_rate_Methylation-K': 0.00465596408123591,
 'learning_rate_Methylation-R': 0.006907520526618253,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.37329392030428094,
 'loss_weight_Methylation-R': 0.584566929813248,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 627702444,
 'sample_weights': [0.795586328910816, 0.4821723897869555],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.774061016104863,
 'weight_decay_Methylation-K': 7.4312954983353485,
 'weight_decay_Methylation-R': 1.0173387014376234}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.381
[5,     7] loss: 1.354
[6,     7] loss: 1.339
[7,     7] loss: 1.324
[8,     7] loss: 1.306
[9,     7] loss: 1.317
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014492750627712611,
 'learning_rate_Methylation-K': 0.00091666366601779,
 'learning_rate_Methylation-R': 0.0008709109097347151,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.29816525663483595,
 'loss_weight_Methylation-R': 0.6825202963801317,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3194069172,
 'sample_weights': [0.584566929813248, 0.37329392030428094],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.345352145295959,
 'weight_decay_Methylation-K': 4.029374592494596,
 'weight_decay_Methylation-R': 6.610377220820487}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.380
[3,     7] loss: 1.351
[4,     7] loss: 1.330
[5,     7] loss: 1.308
[6,     7] loss: 1.308
[7,     7] loss: 1.279
[8,     7] loss: 1.253
[9,     7] loss: 1.232
[10,     7] loss: 1.217
[11,     7] loss: 1.197
[12,     7] loss: 1.191
[13,     7] loss: 1.158
[14,     7] loss: 1.161
[15,     7] loss: 1.179
[16,     7] loss: 1.170
[17,     7] loss: 1.147
[18,     7] loss: 1.145
[19,     7] loss: 1.138
[20,     7] loss: 1.146
[21,     7] loss: 1.157
[22,     7] loss: 1.121
[23,     7] loss: 1.131
[24,     7] loss: 1.134
[25,     7] loss: 1.125
[26,     7] loss: 1.125
[27,     7] loss: 1.095
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008820894796244262,
 'learning_rate_Methylation-K': 0.0071155159195615,
 'learning_rate_Methylation-R': 0.009753649231745067,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6366744365660613,
 'loss_weight_Methylation-R': 0.5475035814664871,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1147083321,
 'sample_weights': [0.6825202963801317, 0.29816525663483595],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.5200118440335895,
 'weight_decay_Methylation-K': 9.268390938397614,
 'weight_decay_Methylation-R': 4.490410814262401}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.385
[4,     7] loss: 1.383
[5,     7] loss: 1.359
[6,     7] loss: 1.339
[7,     7] loss: 1.322
[8,     7] loss: 1.297
[9,     7] loss: 1.337
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007955393936545261,
 'learning_rate_Methylation-K': 0.004004738894970505,
 'learning_rate_Methylation-R': 0.004407459230881211,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3986602075812785,
 'loss_weight_Methylation-R': 0.6375955919589142,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 890852762,
 'sample_weights': [0.5475035814664871, 0.6366744365660613],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8801640117385521,
 'weight_decay_Methylation-K': 5.058301129616602,
 'weight_decay_Methylation-R': 7.978200299241732}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.385
[7,     7] loss: 1.381
[8,     7] loss: 1.361
[9,     7] loss: 1.345
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008121746550272898,
 'learning_rate_Methylation-K': 0.00010475734642749022,
 'learning_rate_Methylation-R': 0.009445855914123577,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.37937034558034977,
 'loss_weight_Methylation-R': 0.48390184677003867,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 626970121,
 'sample_weights': [0.6375955919589142, 0.3986602075812785],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.261924676321986,
 'weight_decay_Methylation-K': 7.247675487848533,
 'weight_decay_Methylation-R': 6.922020019791636}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007767876028634539,
 'learning_rate_Methylation-K': 0.0034933852998590385,
 'learning_rate_Methylation-R': 0.005709503222763386,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7322453654239849,
 'loss_weight_Methylation-R': 0.9788225804336356,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3010052637,
 'sample_weights': [0.48390184677003867, 0.37937034558034977],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.953381920309843,
 'weight_decay_Methylation-K': 8.942916565956367,
 'weight_decay_Methylation-R': 8.344208052582456}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008660872759576778,
 'learning_rate_Methylation-K': 0.00017444171288587805,
 'learning_rate_Methylation-R': 0.008103743922661095,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.44940550263535384,
 'loss_weight_Methylation-R': 0.5600943781362065,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3547304492,
 'sample_weights': [0.9788225804336356, 0.7322453654239849],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.546872429986731,
 'weight_decay_Methylation-K': 5.126199678158221,
 'weight_decay_Methylation-R': 7.993366920854819}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003614390129213954,
 'learning_rate_Methylation-K': 0.003323589744729371,
 'learning_rate_Methylation-R': 0.0027133313832332553,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.14468276685824072,
 'loss_weight_Methylation-R': 0.8786727243154494,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2720749397,
 'sample_weights': [0.5600943781362065, 0.44940550263535384],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.800194110514884,
 'weight_decay_Methylation-K': 4.680252134574876,
 'weight_decay_Methylation-R': 8.8969327534187}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.384
[3,     7] loss: 1.365
[4,     7] loss: 1.335
[5,     7] loss: 1.318
[6,     7] loss: 1.309
[7,     7] loss: 1.304
[8,     7] loss: 1.287
[9,     7] loss: 1.270
[10,     7] loss: 1.264
[11,     7] loss: 1.267
[12,     7] loss: 1.249
[13,     7] loss: 1.249
[14,     7] loss: 1.260
[15,     7] loss: 1.255
[16,     7] loss: 1.242
[17,     7] loss: 1.241
[18,     7] loss: 1.268
[19,     7] loss: 1.246
[20,     7] loss: 1.270
[21,     7] loss: 1.249
[22,     7] loss: 1.230
[23,     7] loss: 1.245
[24,     7] loss: 1.261
[25,     7] loss: 1.236
[26,     7] loss: 1.234
[27,     7] loss: 1.234
[28,     7] loss: 1.224
[29,     7] loss: 1.227
[30,     7] loss: 1.282
[31,     7] loss: 1.298
[32,     7] loss: 1.264
[33,     7] loss: 1.243
[34,     7] loss: 1.226
[35,     7] loss: 1.235
[36,     7] loss: 1.226
[37,     7] loss: 1.230
[38,     7] loss: 1.224
[39,     7] loss: 1.239
[40,     7] loss: 1.207
[41,     7] loss: 1.295
[42,     7] loss: 1.304
[43,     7] loss: 1.272
[44,     7] loss: 1.245
[45,     7] loss: 1.231
[46,     7] loss: 1.254
[47,     7] loss: 1.233
[48,     7] loss: 1.239
[49,     7] loss: 1.205
[50,     7] loss: 1.257
[51,     7] loss: 1.260
[52,     7] loss: 1.245
[53,     7] loss: 1.227
[54,     7] loss: 1.209
[55,     7] loss: 1.216
[56,     7] loss: 1.214
[57,     7] loss: 1.262
[58,     7] loss: 1.217
[59,     7] loss: 1.196
[60,     7] loss: 1.238
[61,     7] loss: 1.298
[62,     7] loss: 1.311
[63,     7] loss: 1.275
[64,     7] loss: 1.230
[65,     7] loss: 1.233
[66,     7] loss: 1.231
[67,     7] loss: 1.262
[68,     7] loss: 1.243
[69,     7] loss: 1.285
[70,     7] loss: 1.270
[71,     7] loss: 1.250
[72,     7] loss: 1.240
[73,     7] loss: 1.250
[74,     7] loss: 1.250
[75,     7] loss: 1.248
[76,     7] loss: 1.240
[77,     7] loss: 1.245
[78,     7] loss: 1.237
[79,     7] loss: 1.250
[80,     7] loss: 1.219
[81,     7] loss: 1.213
[82,     7] loss: 1.256
[83,     7] loss: 1.235
[84,     7] loss: 1.222
[85,     7] loss: 1.242
[86,     7] loss: 1.226
[87,     7] loss: 1.230
[88,     7] loss: 1.234
[89,     7] loss: 1.228
[90,     7] loss: 1.215
Early stopping applied (best metric=0.3666142523288727)
Finished Training
Total time taken: 78.49073457717896
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.385
[3,     7] loss: 1.374
[4,     7] loss: 1.341
[5,     7] loss: 1.317
[6,     7] loss: 1.306
[7,     7] loss: 1.313
[8,     7] loss: 1.283
[9,     7] loss: 1.297
[10,     7] loss: 1.276
[11,     7] loss: 1.278
[12,     7] loss: 1.261
[13,     7] loss: 1.258
[14,     7] loss: 1.264
[15,     7] loss: 1.286
[16,     7] loss: 1.245
[17,     7] loss: 1.261
[18,     7] loss: 1.289
[19,     7] loss: 1.271
[20,     7] loss: 1.257
[21,     7] loss: 1.284
[22,     7] loss: 1.279
[23,     7] loss: 1.243
[24,     7] loss: 1.259
[25,     7] loss: 1.244
[26,     7] loss: 1.264
[27,     7] loss: 1.258
[28,     7] loss: 1.256
[29,     7] loss: 1.257
[30,     7] loss: 1.255
[31,     7] loss: 1.244
[32,     7] loss: 1.248
[33,     7] loss: 1.263
[34,     7] loss: 1.257
[35,     7] loss: 1.235
[36,     7] loss: 1.238
[37,     7] loss: 1.277
[38,     7] loss: 1.289
[39,     7] loss: 1.287
[40,     7] loss: 1.262
[41,     7] loss: 1.251
[42,     7] loss: 1.246
[43,     7] loss: 1.253
[44,     7] loss: 1.252
[45,     7] loss: 1.220
[46,     7] loss: 1.240
[47,     7] loss: 1.251
[48,     7] loss: 1.227
[49,     7] loss: 1.279
[50,     7] loss: 1.274
[51,     7] loss: 1.242
[52,     7] loss: 1.214
[53,     7] loss: 1.221
[54,     7] loss: 1.208
[55,     7] loss: 1.261
[56,     7] loss: 1.260
[57,     7] loss: 1.239
[58,     7] loss: 1.201
[59,     7] loss: 1.209
[60,     7] loss: 1.226
[61,     7] loss: 1.276
[62,     7] loss: 1.294
[63,     7] loss: 1.255
[64,     7] loss: 1.225
[65,     7] loss: 1.233
[66,     7] loss: 1.215
[67,     7] loss: 1.233
[68,     7] loss: 1.244
[69,     7] loss: 1.232
[70,     7] loss: 1.236
[71,     7] loss: 1.237
[72,     7] loss: 1.230
[73,     7] loss: 1.226
[74,     7] loss: 1.213
[75,     7] loss: 1.217
[76,     7] loss: 1.247
[77,     7] loss: 1.216
[78,     7] loss: 1.212
[79,     7] loss: 1.220
[80,     7] loss: 1.223
[81,     7] loss: 1.236
[82,     7] loss: 1.217
[83,     7] loss: 1.214
[84,     7] loss: 1.226
[85,     7] loss: 1.203
[86,     7] loss: 1.280
[87,     7] loss: 1.273
[88,     7] loss: 1.231
[89,     7] loss: 1.232
[90,     7] loss: 1.229
[91,     7] loss: 1.206
[92,     7] loss: 1.284
[93,     7] loss: 1.240
[94,     7] loss: 1.222
[95,     7] loss: 1.217
[96,     7] loss: 1.222
[97,     7] loss: 1.199
[98,     7] loss: 1.204
[99,     7] loss: 1.220
[100,     7] loss: 1.219
[101,     7] loss: 1.220
[102,     7] loss: 1.234
[103,     7] loss: 1.201
[104,     7] loss: 1.214
[105,     7] loss: 1.224
[106,     7] loss: 1.236
[107,     7] loss: 1.211
[108,     7] loss: 1.200
[109,     7] loss: 1.227
[110,     7] loss: 1.212
[111,     7] loss: 1.196
[112,     7] loss: 1.193
[113,     7] loss: 1.198
[114,     7] loss: 1.207
[115,     7] loss: 1.202
[116,     7] loss: 1.211
[117,     7] loss: 1.204
[118,     7] loss: 1.228
Early stopping applied (best metric=0.42013072967529297)
Finished Training
Total time taken: 102.93127608299255
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.383
[3,     7] loss: 1.355
[4,     7] loss: 1.328
[5,     7] loss: 1.327
[6,     7] loss: 1.297
[7,     7] loss: 1.301
[8,     7] loss: 1.286
[9,     7] loss: 1.275
[10,     7] loss: 1.265
[11,     7] loss: 1.266
[12,     7] loss: 1.281
[13,     7] loss: 1.265
[14,     7] loss: 1.268
[15,     7] loss: 1.252
[16,     7] loss: 1.255
[17,     7] loss: 1.285
[18,     7] loss: 1.298
[19,     7] loss: 1.265
[20,     7] loss: 1.262
[21,     7] loss: 1.231
[22,     7] loss: 1.242
[23,     7] loss: 1.270
[24,     7] loss: 1.251
[25,     7] loss: 1.224
[26,     7] loss: 1.224
[27,     7] loss: 1.253
[28,     7] loss: 1.326
[29,     7] loss: 1.345
[30,     7] loss: 1.341
[31,     7] loss: 1.308
[32,     7] loss: 1.285
[33,     7] loss: 1.262
[34,     7] loss: 1.260
[35,     7] loss: 1.241
[36,     7] loss: 1.245
[37,     7] loss: 1.255
[38,     7] loss: 1.265
[39,     7] loss: 1.255
[40,     7] loss: 1.243
[41,     7] loss: 1.243
[42,     7] loss: 1.251
[43,     7] loss: 1.231
[44,     7] loss: 1.229
[45,     7] loss: 1.226
[46,     7] loss: 1.235
[47,     7] loss: 1.211
[48,     7] loss: 1.202
[49,     7] loss: 1.227
[50,     7] loss: 1.262
[51,     7] loss: 1.248
[52,     7] loss: 1.226
[53,     7] loss: 1.232
[54,     7] loss: 1.211
[55,     7] loss: 1.227
[56,     7] loss: 1.210
[57,     7] loss: 1.219
[58,     7] loss: 1.227
[59,     7] loss: 1.194
[60,     7] loss: 1.204
[61,     7] loss: 1.222
[62,     7] loss: 1.203
[63,     7] loss: 1.202
[64,     7] loss: 1.249
[65,     7] loss: 1.223
[66,     7] loss: 1.220
[67,     7] loss: 1.204
[68,     7] loss: 1.232
[69,     7] loss: 1.217
[70,     7] loss: 1.224
[71,     7] loss: 1.190
[72,     7] loss: 1.164
[73,     7] loss: 1.171
[74,     7] loss: 1.194
[75,     7] loss: 1.184
Early stopping applied (best metric=0.37947627902030945)
Finished Training
Total time taken: 65.6191794872284
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.375
[4,     7] loss: 1.350
[5,     7] loss: 1.333
[6,     7] loss: 1.320
[7,     7] loss: 1.321
[8,     7] loss: 1.307
[9,     7] loss: 1.292
[10,     7] loss: 1.288
[11,     7] loss: 1.279
[12,     7] loss: 1.264
[13,     7] loss: 1.252
[14,     7] loss: 1.278
[15,     7] loss: 1.259
[16,     7] loss: 1.254
[17,     7] loss: 1.251
[18,     7] loss: 1.277
[19,     7] loss: 1.259
[20,     7] loss: 1.280
[21,     7] loss: 1.275
[22,     7] loss: 1.262
[23,     7] loss: 1.247
[24,     7] loss: 1.249
[25,     7] loss: 1.245
[26,     7] loss: 1.263
[27,     7] loss: 1.269
[28,     7] loss: 1.255
[29,     7] loss: 1.261
[30,     7] loss: 1.321
[31,     7] loss: 1.336
[32,     7] loss: 1.325
[33,     7] loss: 1.310
[34,     7] loss: 1.295
[35,     7] loss: 1.295
[36,     7] loss: 1.286
[37,     7] loss: 1.290
[38,     7] loss: 1.286
[39,     7] loss: 1.279
[40,     7] loss: 1.259
[41,     7] loss: 1.265
[42,     7] loss: 1.266
[43,     7] loss: 1.278
[44,     7] loss: 1.329
[45,     7] loss: 1.326
[46,     7] loss: 1.286
[47,     7] loss: 1.273
[48,     7] loss: 1.250
[49,     7] loss: 1.252
[50,     7] loss: 1.277
[51,     7] loss: 1.272
[52,     7] loss: 1.267
[53,     7] loss: 1.255
[54,     7] loss: 1.261
[55,     7] loss: 1.251
[56,     7] loss: 1.246
[57,     7] loss: 1.251
[58,     7] loss: 1.244
[59,     7] loss: 1.289
[60,     7] loss: 1.267
[61,     7] loss: 1.262
[62,     7] loss: 1.242
[63,     7] loss: 1.249
[64,     7] loss: 1.263
[65,     7] loss: 1.239
[66,     7] loss: 1.248
[67,     7] loss: 1.232
[68,     7] loss: 1.223
[69,     7] loss: 1.263
[70,     7] loss: 1.237
[71,     7] loss: 1.231
[72,     7] loss: 1.246
[73,     7] loss: 1.226
[74,     7] loss: 1.251
[75,     7] loss: 1.251
[76,     7] loss: 1.238
[77,     7] loss: 1.267
[78,     7] loss: 1.257
[79,     7] loss: 1.230
[80,     7] loss: 1.227
[81,     7] loss: 1.234
[82,     7] loss: 1.240
[83,     7] loss: 1.230
[84,     7] loss: 1.307
[85,     7] loss: 1.307
[86,     7] loss: 1.292
[87,     7] loss: 1.273
[88,     7] loss: 1.246
[89,     7] loss: 1.255
[90,     7] loss: 1.250
[91,     7] loss: 1.242
[92,     7] loss: 1.238
[93,     7] loss: 1.224
[94,     7] loss: 1.329
[95,     7] loss: 1.349
[96,     7] loss: 1.346
[97,     7] loss: 1.333
[98,     7] loss: 1.319
[99,     7] loss: 1.312
[100,     7] loss: 1.282
[101,     7] loss: 1.294
[102,     7] loss: 1.292
[103,     7] loss: 1.282
[104,     7] loss: 1.269
[105,     7] loss: 1.268
[106,     7] loss: 1.281
[107,     7] loss: 1.274
[108,     7] loss: 1.281
[109,     7] loss: 1.258
[110,     7] loss: 1.281
[111,     7] loss: 1.248
[112,     7] loss: 1.243
[113,     7] loss: 1.263
[114,     7] loss: 1.267
[115,     7] loss: 1.236
[116,     7] loss: 1.274
[117,     7] loss: 1.256
[118,     7] loss: 1.239
[119,     7] loss: 1.252
[120,     7] loss: 1.245
[121,     7] loss: 1.250
[122,     7] loss: 1.240
[123,     7] loss: 1.257
[124,     7] loss: 1.290
[125,     7] loss: 1.278
[126,     7] loss: 1.246
[127,     7] loss: 1.244
[128,     7] loss: 1.278
[129,     7] loss: 1.239
[130,     7] loss: 1.262
[131,     7] loss: 1.258
[132,     7] loss: 1.245
[133,     7] loss: 1.232
Early stopping applied (best metric=0.3781377375125885)
Finished Training
Total time taken: 116.09731340408325
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.389
[2,     7] loss: 1.379
[3,     7] loss: 1.344
[4,     7] loss: 1.325
[5,     7] loss: 1.302
[6,     7] loss: 1.286
[7,     7] loss: 1.312
[8,     7] loss: 1.287
[9,     7] loss: 1.284
[10,     7] loss: 1.259
[11,     7] loss: 1.247
[12,     7] loss: 1.254
[13,     7] loss: 1.276
[14,     7] loss: 1.271
[15,     7] loss: 1.267
[16,     7] loss: 1.235
[17,     7] loss: 1.250
[18,     7] loss: 1.240
[19,     7] loss: 1.238
[20,     7] loss: 1.248
[21,     7] loss: 1.272
[22,     7] loss: 1.271
[23,     7] loss: 1.233
[24,     7] loss: 1.233
[25,     7] loss: 1.244
[26,     7] loss: 1.237
[27,     7] loss: 1.236
[28,     7] loss: 1.244
[29,     7] loss: 1.245
[30,     7] loss: 1.231
[31,     7] loss: 1.252
[32,     7] loss: 1.244
[33,     7] loss: 1.243
[34,     7] loss: 1.222
[35,     7] loss: 1.220
[36,     7] loss: 1.220
[37,     7] loss: 1.222
[38,     7] loss: 1.219
[39,     7] loss: 1.325
[40,     7] loss: 1.285
[41,     7] loss: 1.246
[42,     7] loss: 1.216
[43,     7] loss: 1.221
[44,     7] loss: 1.203
[45,     7] loss: 1.286
[46,     7] loss: 1.252
[47,     7] loss: 1.246
[48,     7] loss: 1.223
[49,     7] loss: 1.226
[50,     7] loss: 1.219
[51,     7] loss: 1.222
[52,     7] loss: 1.247
[53,     7] loss: 1.233
[54,     7] loss: 1.198
[55,     7] loss: 1.240
[56,     7] loss: 1.282
[57,     7] loss: 1.264
[58,     7] loss: 1.262
[59,     7] loss: 1.218
[60,     7] loss: 1.203
[61,     7] loss: 1.194
[62,     7] loss: 1.224
[63,     7] loss: 1.216
[64,     7] loss: 1.194
[65,     7] loss: 1.220
[66,     7] loss: 1.206
[67,     7] loss: 1.192
[68,     7] loss: 1.227
[69,     7] loss: 1.203
[70,     7] loss: 1.192
[71,     7] loss: 1.180
[72,     7] loss: 1.189
[73,     7] loss: 1.211
[74,     7] loss: 1.216
[75,     7] loss: 1.200
[76,     7] loss: 1.207
[77,     7] loss: 1.225
[78,     7] loss: 1.208
[79,     7] loss: 1.195
[80,     7] loss: 1.203
[81,     7] loss: 1.187
[82,     7] loss: 1.202
[83,     7] loss: 1.214
[84,     7] loss: 1.198
[85,     7] loss: 1.199
[86,     7] loss: 1.190
[87,     7] loss: 1.195
[88,     7] loss: 1.202
Early stopping applied (best metric=0.3653709292411804)
Finished Training
Total time taken: 76.45120573043823
{'Methylation-R Validation Accuracy': 0.4490174602199063, 'Methylation-R Validation Sensitivity': 0.880627798267584, 'Methylation-R Validation Specificity': 0.4091042944785276, 'Methylation-R Validation Precision': 0.12666748608164302, 'Methylation-R AUC ROC': 0.7809289679467567, 'Methylation-R AUC PR': 0.340005389141111, 'Methylation-R MCC': 0.17161309695345528, 'Methylation-R F1': 0.2200379012047848, 'Validation Loss (Methylation-R)': 0.31731605529785156, 'Methylation-K Validation Accuracy': 0.40919558839758224, 'Methylation-K Validation Sensitivity': 0.8474544560706988, 'Methylation-K Validation Specificity': 0.36167098456061353, 'Methylation-K Validation Precision': 0.12943947178343826, 'Methylation-K AUC ROC': 0.6733067124639225, 'Methylation-K AUC PR': 0.16190573450740484, 'Methylation-K MCC': 0.13710984625469902, 'Methylation-K F1': 0.22272189563055436, 'Validation Loss (Methylation-K)': 0.3819459855556488, 'Validation Loss (total)': 0.6992620348930358, 'TimeToTrain': 87.91794185638427}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009848379926747803,
 'learning_rate_Methylation-K': 0.0003385001327981288,
 'learning_rate_Methylation-R': 0.009794895183196572,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.10309490642353156,
 'loss_weight_Methylation-R': 0.4166373741919755,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1289115617,
 'sample_weights': [0.8786727243154494, 0.14468276685824072],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2656395894109163,
 'weight_decay_Methylation-K': 5.866980613510258,
 'weight_decay_Methylation-R': 8.392185338708268}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020264426754280137,
 'learning_rate_Methylation-K': 0.003062773693688279,
 'learning_rate_Methylation-R': 0.0038762214127034665,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.18580924217382633,
 'loss_weight_Methylation-R': 0.4834786661602797,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2334927804,
 'sample_weights': [0.4166373741919755, 0.10309490642353156],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7716698802379818,
 'weight_decay_Methylation-K': 5.681476967200839,
 'weight_decay_Methylation-R': 7.26894764090674}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.378
[3,     7] loss: 1.352
[4,     7] loss: 1.339
[5,     7] loss: 1.322
[6,     7] loss: 1.312
[7,     7] loss: 1.301
[8,     7] loss: 1.281
[9,     7] loss: 1.279
[10,     7] loss: 1.270
[11,     7] loss: 1.273
[12,     7] loss: 1.254
[13,     7] loss: 1.230
[14,     7] loss: 1.213
[15,     7] loss: 1.202
[16,     7] loss: 1.164
[17,     7] loss: 1.159
[18,     7] loss: 1.161
[19,     7] loss: 1.160
[20,     7] loss: 1.142
[21,     7] loss: 1.152
[22,     7] loss: 1.137
[23,     7] loss: 1.141
[24,     7] loss: 1.114
[25,     7] loss: 1.095
[26,     7] loss: 1.103
[27,     7] loss: 1.107
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007806744970333248,
 'learning_rate_Methylation-K': 0.003718317216146225,
 'learning_rate_Methylation-R': 0.009133267487186271,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7135779997618696,
 'loss_weight_Methylation-R': 0.5409797292545866,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1556500990,
 'sample_weights': [0.4834786661602797, 0.18580924217382633],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.066774484820912,
 'weight_decay_Methylation-K': 1.9115378456123175,
 'weight_decay_Methylation-R': 5.7867131850538644}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.356
[6,     7] loss: 1.327
[7,     7] loss: 1.319
[8,     7] loss: 1.306
[9,     7] loss: 1.342
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007337982138627221,
 'learning_rate_Methylation-K': 0.0051928263828568645,
 'learning_rate_Methylation-R': 0.009046047829781816,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8170775518950987,
 'loss_weight_Methylation-R': 0.4940266803569469,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3768877546,
 'sample_weights': [0.5409797292545866, 0.7135779997618696],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4126016169201636,
 'weight_decay_Methylation-K': 7.489198818073559,
 'weight_decay_Methylation-R': 9.938111269488711}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.402
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008603929285215963,
 'learning_rate_Methylation-K': 0.006009994732533598,
 'learning_rate_Methylation-R': 0.00983854360458139,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.39377399947608027,
 'loss_weight_Methylation-R': 0.666607634811407,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4100435506,
 'sample_weights': [0.4940266803569469, 0.8170775518950987],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.757195639205365,
 'weight_decay_Methylation-K': 5.596434325640166,
 'weight_decay_Methylation-R': 8.174231210214787}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009932723639660484,
 'learning_rate_Methylation-K': 0.003811124351368835,
 'learning_rate_Methylation-R': 0.0055841217383582045,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5184712351850239,
 'loss_weight_Methylation-R': 0.4851593296482834,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2435459102,
 'sample_weights': [0.666607634811407, 0.39377399947608027],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.308232243250041,
 'weight_decay_Methylation-K': 7.653770938545333,
 'weight_decay_Methylation-R': 5.400182657138304}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006255009741379872,
 'learning_rate_Methylation-K': 0.0022490381405936683,
 'learning_rate_Methylation-R': 0.006523734619988609,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2016820449430986,
 'loss_weight_Methylation-R': 0.6017774850632737,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2098736531,
 'sample_weights': [0.4851593296482834, 0.5184712351850239],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.592335957626447,
 'weight_decay_Methylation-K': 3.4158404053163114,
 'weight_decay_Methylation-R': 7.666176779070565}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
Early stopping applied (best metric=0.44592928886413574)
Finished Training
Total time taken: 53.752148151397705
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.385
[5,     7] loss: 1.379
[6,     7] loss: 1.345
[7,     7] loss: 1.320
[8,     7] loss: 1.320
[9,     7] loss: 1.308
[10,     7] loss: 1.273
[11,     7] loss: 1.274
[12,     7] loss: 1.268
[13,     7] loss: 1.254
[14,     7] loss: 1.266
[15,     7] loss: 1.252
[16,     7] loss: 1.265
[17,     7] loss: 1.256
[18,     7] loss: 1.247
[19,     7] loss: 1.226
[20,     7] loss: 1.292
[21,     7] loss: 1.292
[22,     7] loss: 1.305
[23,     7] loss: 1.270
[24,     7] loss: 1.241
[25,     7] loss: 1.244
[26,     7] loss: 1.251
[27,     7] loss: 1.267
[28,     7] loss: 1.250
[29,     7] loss: 1.245
[30,     7] loss: 1.278
[31,     7] loss: 1.249
[32,     7] loss: 1.241
[33,     7] loss: 1.238
[34,     7] loss: 1.229
[35,     7] loss: 1.251
[36,     7] loss: 1.218
[37,     7] loss: 1.211
[38,     7] loss: 1.251
[39,     7] loss: 1.215
[40,     7] loss: 1.235
[41,     7] loss: 1.208
[42,     7] loss: 1.223
[43,     7] loss: 1.198
[44,     7] loss: 1.174
[45,     7] loss: 1.327
[46,     7] loss: 1.321
[47,     7] loss: 1.267
[48,     7] loss: 1.247
[49,     7] loss: 1.259
[50,     7] loss: 1.223
[51,     7] loss: 1.249
[52,     7] loss: 1.194
[53,     7] loss: 1.191
[54,     7] loss: 1.199
[55,     7] loss: 1.201
[56,     7] loss: 1.204
[57,     7] loss: 1.202
[58,     7] loss: 1.178
[59,     7] loss: 1.175
[60,     7] loss: 1.184
[61,     7] loss: 1.163
[62,     7] loss: 1.184
[63,     7] loss: 1.193
[64,     7] loss: 1.176
[65,     7] loss: 1.160
[66,     7] loss: 1.189
[67,     7] loss: 1.262
[68,     7] loss: 1.263
[69,     7] loss: 1.294
[70,     7] loss: 1.223
[71,     7] loss: 1.221
[72,     7] loss: 1.181
[73,     7] loss: 1.166
[74,     7] loss: 1.166
[75,     7] loss: 1.196
[76,     7] loss: 1.192
[77,     7] loss: 1.167
[78,     7] loss: 1.162
[79,     7] loss: 1.256
[80,     7] loss: 1.224
[81,     7] loss: 1.181
[82,     7] loss: 1.173
[83,     7] loss: 1.171
[84,     7] loss: 1.216
[85,     7] loss: 1.246
[86,     7] loss: 1.217
[87,     7] loss: 1.232
[88,     7] loss: 1.189
[89,     7] loss: 1.159
[90,     7] loss: 1.213
[91,     7] loss: 1.215
[92,     7] loss: 1.210
[93,     7] loss: 1.186
[94,     7] loss: 1.166
[95,     7] loss: 1.159
[96,     7] loss: 1.172
Early stopping applied (best metric=0.425912082195282)
Finished Training
Total time taken: 83.80522727966309
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.381
[5,     7] loss: 1.341
[6,     7] loss: 1.323
[7,     7] loss: 1.316
[8,     7] loss: 1.327
[9,     7] loss: 1.310
[10,     7] loss: 1.286
[11,     7] loss: 1.277
[12,     7] loss: 1.290
[13,     7] loss: 1.284
[14,     7] loss: 1.252
[15,     7] loss: 1.272
[16,     7] loss: 1.260
[17,     7] loss: 1.238
[18,     7] loss: 1.234
[19,     7] loss: 1.237
[20,     7] loss: 1.248
[21,     7] loss: 1.261
[22,     7] loss: 1.243
[23,     7] loss: 1.248
[24,     7] loss: 1.201
[25,     7] loss: 1.255
[26,     7] loss: 1.299
[27,     7] loss: 1.324
[28,     7] loss: 1.297
[29,     7] loss: 1.255
[30,     7] loss: 1.246
[31,     7] loss: 1.233
[32,     7] loss: 1.214
[33,     7] loss: 1.242
[34,     7] loss: 1.231
[35,     7] loss: 1.210
[36,     7] loss: 1.292
[37,     7] loss: 1.299
[38,     7] loss: 1.255
[39,     7] loss: 1.251
[40,     7] loss: 1.220
[41,     7] loss: 1.219
[42,     7] loss: 1.293
[43,     7] loss: 1.375
[44,     7] loss: 1.367
[45,     7] loss: 1.319
[46,     7] loss: 1.293
[47,     7] loss: 1.294
[48,     7] loss: 1.272
[49,     7] loss: 1.236
[50,     7] loss: 1.205
[51,     7] loss: 1.211
[52,     7] loss: 1.196
[53,     7] loss: 1.197
[54,     7] loss: 1.207
[55,     7] loss: 1.185
[56,     7] loss: 1.182
[57,     7] loss: 1.189
[58,     7] loss: 1.227
[59,     7] loss: 1.240
[60,     7] loss: 1.216
[61,     7] loss: 1.170
[62,     7] loss: 1.202
[63,     7] loss: 1.191
[64,     7] loss: 1.183
[65,     7] loss: 1.174
[66,     7] loss: 1.171
[67,     7] loss: 1.179
[68,     7] loss: 1.159
[69,     7] loss: 1.183
[70,     7] loss: 1.170
[71,     7] loss: 1.207
[72,     7] loss: 1.215
[73,     7] loss: 1.203
[74,     7] loss: 1.196
[75,     7] loss: 1.169
[76,     7] loss: 1.150
[77,     7] loss: 1.152
[78,     7] loss: 1.164
[79,     7] loss: 1.169
[80,     7] loss: 1.169
[81,     7] loss: 1.197
[82,     7] loss: 1.290
[83,     7] loss: 1.326
[84,     7] loss: 1.311
[85,     7] loss: 1.303
Early stopping applied (best metric=0.38416165113449097)
Finished Training
Total time taken: 74.42720103263855
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.384
[3,     7] loss: 1.370
[4,     7] loss: 1.334
[5,     7] loss: 1.325
[6,     7] loss: 1.314
[7,     7] loss: 1.298
[8,     7] loss: 1.280
[9,     7] loss: 1.291
[10,     7] loss: 1.274
[11,     7] loss: 1.283
[12,     7] loss: 1.254
[13,     7] loss: 1.246
[14,     7] loss: 1.249
[15,     7] loss: 1.264
[16,     7] loss: 1.232
[17,     7] loss: 1.275
[18,     7] loss: 1.252
[19,     7] loss: 1.279
[20,     7] loss: 1.288
[21,     7] loss: 1.262
[22,     7] loss: 1.246
[23,     7] loss: 1.258
[24,     7] loss: 1.238
[25,     7] loss: 1.242
[26,     7] loss: 1.242
[27,     7] loss: 1.307
[28,     7] loss: 1.270
[29,     7] loss: 1.246
[30,     7] loss: 1.246
[31,     7] loss: 1.252
[32,     7] loss: 1.242
[33,     7] loss: 1.230
[34,     7] loss: 1.236
[35,     7] loss: 1.261
[36,     7] loss: 1.282
[37,     7] loss: 1.259
[38,     7] loss: 1.222
[39,     7] loss: 1.274
[40,     7] loss: 1.240
[41,     7] loss: 1.244
[42,     7] loss: 1.267
[43,     7] loss: 1.284
[44,     7] loss: 1.246
[45,     7] loss: 1.206
[46,     7] loss: 1.202
[47,     7] loss: 1.185
[48,     7] loss: 1.197
[49,     7] loss: 1.197
[50,     7] loss: 1.166
[51,     7] loss: 1.200
[52,     7] loss: 1.195
[53,     7] loss: 1.185
[54,     7] loss: 1.217
[55,     7] loss: 1.209
[56,     7] loss: 1.190
[57,     7] loss: 1.166
[58,     7] loss: 1.191
[59,     7] loss: 1.232
[60,     7] loss: 1.245
[61,     7] loss: 1.290
[62,     7] loss: 1.239
[63,     7] loss: 1.219
[64,     7] loss: 1.210
[65,     7] loss: 1.178
[66,     7] loss: 1.178
[67,     7] loss: 1.180
[68,     7] loss: 1.178
[69,     7] loss: 1.178
[70,     7] loss: 1.196
[71,     7] loss: 1.162
[72,     7] loss: 1.170
[73,     7] loss: 1.165
[74,     7] loss: 1.183
[75,     7] loss: 1.201
[76,     7] loss: 1.178
[77,     7] loss: 1.198
[78,     7] loss: 1.196
[79,     7] loss: 1.215
[80,     7] loss: 1.191
Early stopping applied (best metric=0.39402058720588684)
Finished Training
Total time taken: 70.59419059753418
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.364
[6,     7] loss: 1.340
[7,     7] loss: 1.325
[8,     7] loss: 1.316
[9,     7] loss: 1.284
[10,     7] loss: 1.290
[11,     7] loss: 1.276
[12,     7] loss: 1.269
[13,     7] loss: 1.268
[14,     7] loss: 1.254
[15,     7] loss: 1.246
[16,     7] loss: 1.237
[17,     7] loss: 1.252
[18,     7] loss: 1.247
[19,     7] loss: 1.229
[20,     7] loss: 1.262
[21,     7] loss: 1.226
[22,     7] loss: 1.253
[23,     7] loss: 1.256
[24,     7] loss: 1.256
[25,     7] loss: 1.268
[26,     7] loss: 1.261
[27,     7] loss: 1.226
[28,     7] loss: 1.246
[29,     7] loss: 1.258
[30,     7] loss: 1.238
[31,     7] loss: 1.260
[32,     7] loss: 1.230
[33,     7] loss: 1.235
[34,     7] loss: 1.222
[35,     7] loss: 1.277
[36,     7] loss: 1.257
[37,     7] loss: 1.236
[38,     7] loss: 1.255
[39,     7] loss: 1.240
[40,     7] loss: 1.216
[41,     7] loss: 1.209
[42,     7] loss: 1.242
[43,     7] loss: 1.254
[44,     7] loss: 1.223
[45,     7] loss: 1.217
[46,     7] loss: 1.216
[47,     7] loss: 1.216
[48,     7] loss: 1.195
[49,     7] loss: 1.184
[50,     7] loss: 1.216
[51,     7] loss: 1.202
[52,     7] loss: 1.205
[53,     7] loss: 1.198
[54,     7] loss: 1.158
Early stopping applied (best metric=0.4378015100955963)
Finished Training
Total time taken: 47.0531268119812
{'Methylation-R Validation Accuracy': 0.34447642450493937, 'Methylation-R Validation Sensitivity': 0.9058351915063002, 'Methylation-R Validation Specificity': 0.2925644171779141, 'Methylation-R Validation Precision': 0.11414254105032305, 'Methylation-R AUC ROC': 0.7354317366585148, 'Methylation-R AUC PR': 0.29009570355548087, 'Methylation-R MCC': 0.1159023906785352, 'Methylation-R F1': 0.20048400885332474, 'Validation Loss (Methylation-R)': 0.3633532464504242, 'Methylation-K Validation Accuracy': 0.2995301329488609, 'Methylation-K Validation Sensitivity': 0.8634206350870571, 'Methylation-K Validation Specificity': 0.23838128206325537, 'Methylation-K Validation Precision': 0.11247519993610153, 'Methylation-K AUC ROC': 0.5734943303942709, 'Methylation-K AUC PR': 0.12107804374844698, 'Methylation-K MCC': 0.0612213929281636, 'Methylation-K F1': 0.19776557890019378, 'Validation Loss (Methylation-K)': 0.41756502389907835, 'Validation Loss (total)': 0.780918276309967, 'TimeToTrain': 65.92637877464294}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007724130435061493,
 'learning_rate_Methylation-K': 0.0031658816411868664,
 'learning_rate_Methylation-R': 0.007466278991246772,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5089529325028607,
 'loss_weight_Methylation-R': 0.3294156962115896,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3809986435,
 'sample_weights': [0.6017774850632737, 0.2016820449430986],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.618252167651967,
 'weight_decay_Methylation-K': 1.6431117576164334,
 'weight_decay_Methylation-R': 9.808455299372193}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.388
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.384
[7,     7] loss: 1.367
[8,     7] loss: 1.333
[9,     7] loss: 1.309
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006165314801086609,
 'learning_rate_Methylation-K': 0.0030475497966544344,
 'learning_rate_Methylation-R': 0.0003796628343328227,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.15950791721482946,
 'loss_weight_Methylation-R': 0.42241630153819104,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 733782811,
 'sample_weights': [0.3294156962115896, 0.5089529325028607],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.441075883225473,
 'weight_decay_Methylation-K': 4.417217020730451,
 'weight_decay_Methylation-R': 8.92795657247069}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.367
[3,     7] loss: 1.334
[4,     7] loss: 1.336
[5,     7] loss: 1.310
[6,     7] loss: 1.300
[7,     7] loss: 1.296
[8,     7] loss: 1.272
[9,     7] loss: 1.277
[10,     7] loss: 1.261
[11,     7] loss: 1.272
[12,     7] loss: 1.262
[13,     7] loss: 1.253
[14,     7] loss: 1.241
[15,     7] loss: 1.254
[16,     7] loss: 1.237
[17,     7] loss: 1.273
[18,     7] loss: 1.263
[19,     7] loss: 1.238
[20,     7] loss: 1.274
[21,     7] loss: 1.275
[22,     7] loss: 1.243
[23,     7] loss: 1.291
[24,     7] loss: 1.375
[25,     7] loss: 1.378
[26,     7] loss: 1.367
[27,     7] loss: 1.346
[28,     7] loss: 1.339
[29,     7] loss: 1.321
[30,     7] loss: 1.317
[31,     7] loss: 1.349
[32,     7] loss: 1.329
[33,     7] loss: 1.314
[34,     7] loss: 1.290
[35,     7] loss: 1.293
[36,     7] loss: 1.292
[37,     7] loss: 1.276
[38,     7] loss: 1.283
[39,     7] loss: 1.281
[40,     7] loss: 1.276
[41,     7] loss: 1.298
[42,     7] loss: 1.283
[43,     7] loss: 1.278
[44,     7] loss: 1.272
[45,     7] loss: 1.271
[46,     7] loss: 1.296
[47,     7] loss: 1.289
[48,     7] loss: 1.276
[49,     7] loss: 1.283
[50,     7] loss: 1.275
[51,     7] loss: 1.265
[52,     7] loss: 1.285
[53,     7] loss: 1.275
[54,     7] loss: 1.278
[55,     7] loss: 1.276
[56,     7] loss: 1.267
[57,     7] loss: 1.259
[58,     7] loss: 1.257
[59,     7] loss: 1.280
[60,     7] loss: 1.275
[61,     7] loss: 1.265
[62,     7] loss: 1.247
[63,     7] loss: 1.271
[64,     7] loss: 1.255
[65,     7] loss: 1.258
[66,     7] loss: 1.282
[67,     7] loss: 1.281
Early stopping applied (best metric=0.394532173871994)
Finished Training
Total time taken: 58.79416084289551
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.372
[6,     7] loss: 1.337
[7,     7] loss: 1.325
[8,     7] loss: 1.308
[9,     7] loss: 1.290
[10,     7] loss: 1.280
[11,     7] loss: 1.286
[12,     7] loss: 1.274
[13,     7] loss: 1.263
[14,     7] loss: 1.289
[15,     7] loss: 1.259
[16,     7] loss: 1.260
[17,     7] loss: 1.322
[18,     7] loss: 1.290
[19,     7] loss: 1.273
[20,     7] loss: 1.268
[21,     7] loss: 1.253
[22,     7] loss: 1.259
[23,     7] loss: 1.249
[24,     7] loss: 1.253
[25,     7] loss: 1.242
[26,     7] loss: 1.244
[27,     7] loss: 1.321
[28,     7] loss: 1.340
[29,     7] loss: 1.378
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
Early stopping applied (best metric=0.436640202999115)
Finished Training
Total time taken: 68.32388186454773
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.378
[8,     7] loss: 1.347
[9,     7] loss: 1.332
[10,     7] loss: 1.326
[11,     7] loss: 1.311
[12,     7] loss: 1.300
[13,     7] loss: 1.299
[14,     7] loss: 1.296
[15,     7] loss: 1.299
[16,     7] loss: 1.277
[17,     7] loss: 1.278
[18,     7] loss: 1.288
[19,     7] loss: 1.282
[20,     7] loss: 1.280
[21,     7] loss: 1.282
[22,     7] loss: 1.265
[23,     7] loss: 1.252
[24,     7] loss: 1.291
[25,     7] loss: 1.311
[26,     7] loss: 1.269
[27,     7] loss: 1.265
[28,     7] loss: 1.279
[29,     7] loss: 1.267
[30,     7] loss: 1.269
[31,     7] loss: 1.255
[32,     7] loss: 1.264
[33,     7] loss: 1.293
[34,     7] loss: 1.296
[35,     7] loss: 1.262
[36,     7] loss: 1.259
[37,     7] loss: 1.248
[38,     7] loss: 1.266
[39,     7] loss: 1.269
[40,     7] loss: 1.268
[41,     7] loss: 1.250
[42,     7] loss: 1.253
[43,     7] loss: 1.256
[44,     7] loss: 1.277
[45,     7] loss: 1.338
[46,     7] loss: 1.309
[47,     7] loss: 1.259
[48,     7] loss: 1.261
[49,     7] loss: 1.251
[50,     7] loss: 1.267
[51,     7] loss: 1.255
Early stopping applied (best metric=0.4418014883995056)
Finished Training
Total time taken: 44.84811997413635
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.362
[6,     7] loss: 1.335
[7,     7] loss: 1.311
[8,     7] loss: 1.315
[9,     7] loss: 1.290
[10,     7] loss: 1.332
[11,     7] loss: 1.336
[12,     7] loss: 1.297
[13,     7] loss: 1.277
[14,     7] loss: 1.273
[15,     7] loss: 1.277
[16,     7] loss: 1.258
[17,     7] loss: 1.271
[18,     7] loss: 1.288
[19,     7] loss: 1.308
[20,     7] loss: 1.284
[21,     7] loss: 1.265
[22,     7] loss: 1.266
[23,     7] loss: 1.257
[24,     7] loss: 1.249
[25,     7] loss: 1.274
[26,     7] loss: 1.267
[27,     7] loss: 1.267
[28,     7] loss: 1.254
[29,     7] loss: 1.250
[30,     7] loss: 1.293
[31,     7] loss: 1.267
[32,     7] loss: 1.253
[33,     7] loss: 1.260
[34,     7] loss: 1.263
[35,     7] loss: 1.243
[36,     7] loss: 1.254
[37,     7] loss: 1.252
[38,     7] loss: 1.235
[39,     7] loss: 1.313
[40,     7] loss: 1.414
[41,     7] loss: 1.375
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.387
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
Early stopping applied (best metric=0.4179808795452118)
Finished Training
Total time taken: 74.30920076370239
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.383
[6,     7] loss: 1.357
[7,     7] loss: 1.355
[8,     7] loss: 1.341
[9,     7] loss: 1.323
[10,     7] loss: 1.309
[11,     7] loss: 1.301
[12,     7] loss: 1.290
[13,     7] loss: 1.290
[14,     7] loss: 1.257
[15,     7] loss: 1.261
[16,     7] loss: 1.276
[17,     7] loss: 1.269
[18,     7] loss: 1.274
[19,     7] loss: 1.261
[20,     7] loss: 1.275
[21,     7] loss: 1.275
[22,     7] loss: 1.266
[23,     7] loss: 1.266
[24,     7] loss: 1.253
[25,     7] loss: 1.238
[26,     7] loss: 1.253
[27,     7] loss: 1.280
[28,     7] loss: 1.345
[29,     7] loss: 1.366
[30,     7] loss: 1.333
[31,     7] loss: 1.318
[32,     7] loss: 1.361
[33,     7] loss: 1.382
[34,     7] loss: 1.386
[35,     7] loss: 1.385
[36,     7] loss: 1.376
[37,     7] loss: 1.364
[38,     7] loss: 1.367
[39,     7] loss: 1.365
[40,     7] loss: 1.362
[41,     7] loss: 1.355
[42,     7] loss: 1.340
[43,     7] loss: 1.331
[44,     7] loss: 1.329
[45,     7] loss: 1.317
[46,     7] loss: 1.315
[47,     7] loss: 1.311
[48,     7] loss: 1.311
[49,     7] loss: 1.295
[50,     7] loss: 1.288
[51,     7] loss: 1.311
[52,     7] loss: 1.287
Early stopping applied (best metric=0.44158118963241577)
Finished Training
Total time taken: 45.6691255569458
{'Methylation-R Validation Accuracy': 0.3642651522513939, 'Methylation-R Validation Sensitivity': 0.8843501326259947, 'Methylation-R Validation Specificity': 0.31617177914110434, 'Methylation-R Validation Precision': 0.12151208658979706, 'Methylation-R AUC ROC': 0.7153615079964272, 'Methylation-R AUC PR': 0.2590473786170467, 'Methylation-R MCC': 0.11821744434358378, 'Methylation-R F1': 0.20837143596620544, 'Validation Loss (Methylation-R)': 0.37322309613227844, 'Methylation-K Validation Accuracy': 0.29784008327442424, 'Methylation-K Validation Sensitivity': 0.8280474649406688, 'Methylation-K Validation Specificity': 0.24034636087058273, 'Methylation-K Validation Precision': 0.10891012397567382, 'Methylation-K AUC ROC': 0.5600501882814747, 'Methylation-K AUC PR': 0.11549168818527179, 'Methylation-K MCC': 0.045378087026242735, 'Methylation-K F1': 0.18961701031178826, 'Validation Loss (Methylation-K)': 0.42650718688964845, 'Validation Loss (total)': 0.7997302889823914, 'TimeToTrain': 58.388897800445555}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0036756663831942773,
 'learning_rate_Methylation-K': 0.009573095985188476,
 'learning_rate_Methylation-R': 0.0003107893246796737,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7733838380049571,
 'loss_weight_Methylation-R': 0.20111970004639834,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 944325851,
 'sample_weights': [0.42241630153819104, 0.15950791721482946],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.344612766611312,
 'weight_decay_Methylation-K': 4.182072822821862,
 'weight_decay_Methylation-R': 4.901947616562004}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.386
[3,     7] loss: 1.385
[4,     7] loss: 1.375
[5,     7] loss: 1.343
[6,     7] loss: 1.325
[7,     7] loss: 1.310
[8,     7] loss: 1.298
[9,     7] loss: 1.296
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006560213204353196,
 'learning_rate_Methylation-K': 0.00972921450523616,
 'learning_rate_Methylation-R': 0.004716541147886659,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4587857963910335,
 'loss_weight_Methylation-R': 0.22146017097585688,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1334960096,
 'sample_weights': [0.20111970004639834, 0.7733838380049571],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.613304150128842,
 'weight_decay_Methylation-K': 7.344226150419188,
 'weight_decay_Methylation-R': 9.410630959187458}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00818705485997762,
 'learning_rate_Methylation-K': 0.0016210952382898674,
 'learning_rate_Methylation-R': 0.005083115647601271,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.46898227246968577,
 'loss_weight_Methylation-R': 0.5372664521967416,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1300426889,
 'sample_weights': [0.22146017097585688, 0.4587857963910335],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.857901223270349,
 'weight_decay_Methylation-K': 4.448619933511409,
 'weight_decay_Methylation-R': 8.387047251002363}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.396
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007198718779558194,
 'learning_rate_Methylation-K': 0.0059773800330455585,
 'learning_rate_Methylation-R': 0.002766204593508412,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.44288314338555984,
 'loss_weight_Methylation-R': 0.14534023307441468,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 117289725,
 'sample_weights': [0.5372664521967416, 0.46898227246968577],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.370440200111108,
 'weight_decay_Methylation-K': 6.688469379181754,
 'weight_decay_Methylation-R': 7.337763756439628}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.397
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.381
[7,     7] loss: 1.345
[8,     7] loss: 1.341
[9,     7] loss: 1.344
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009661776520913537,
 'learning_rate_Methylation-K': 0.0008177688360184944,
 'learning_rate_Methylation-R': 0.007374045732193852,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.008132151558673983,
 'loss_weight_Methylation-R': 0.9038535610336526,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3932280140,
 'sample_weights': [0.14534023307441468, 0.44288314338555984],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.202619514055961,
 'weight_decay_Methylation-K': 3.881312477392966,
 'weight_decay_Methylation-R': 9.749956694415033}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0049176672942660826,
 'learning_rate_Methylation-K': 0.003420799551240914,
 'learning_rate_Methylation-R': 0.008555779225773762,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.554104931750687,
 'loss_weight_Methylation-R': 0.8084825477098903,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4041926270,
 'sample_weights': [0.9038535610336526, 0.008132151558673983],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.537313177136482,
 'weight_decay_Methylation-K': 0.019305549298882507,
 'weight_decay_Methylation-R': 2.2756322929096617}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009455633024216653,
 'learning_rate_Methylation-K': 0.003264733686157632,
 'learning_rate_Methylation-R': 0.006471409698952049,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.477062866803603,
 'loss_weight_Methylation-R': 0.3050211052501498,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3626858817,
 'sample_weights': [0.8084825477098903, 0.554104931750687],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.704678542742188,
 'weight_decay_Methylation-K': 4.067754868604171,
 'weight_decay_Methylation-R': 5.542482045411705}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008362976216437707,
 'learning_rate_Methylation-K': 0.008814634356505695,
 'learning_rate_Methylation-R': 0.008235437856968866,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6439036116453204,
 'loss_weight_Methylation-R': 0.8056843675501523,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 960600788,
 'sample_weights': [0.3050211052501498, 0.477062866803603],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.031505965829367044,
 'weight_decay_Methylation-K': 2.227658036813027,
 'weight_decay_Methylation-R': 8.049764187815951}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007376347928085681,
 'learning_rate_Methylation-K': 8.047659558149309e-05,
 'learning_rate_Methylation-R': 0.007520310368282955,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.09491375872694752,
 'loss_weight_Methylation-R': 0.42104603217738285,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3218158135,
 'sample_weights': [0.8056843675501523, 0.6439036116453204],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.787583867834661,
 'weight_decay_Methylation-K': 5.31005455458973,
 'weight_decay_Methylation-R': 9.619687186162999}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.387
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.387
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.387
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.4434674084186554)
Finished Training
Total time taken: 43.893120527267456
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.387
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
Early stopping applied (best metric=0.44466349482536316)
Finished Training
Total time taken: 46.53763699531555
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.383
[9,     7] loss: 1.362
[10,     7] loss: 1.363
[11,     7] loss: 1.342
[12,     7] loss: 1.333
[13,     7] loss: 1.334
[14,     7] loss: 1.315
[15,     7] loss: 1.322
[16,     7] loss: 1.308
[17,     7] loss: 1.299
[18,     7] loss: 1.294
[19,     7] loss: 1.292
[20,     7] loss: 1.284
[21,     7] loss: 1.286
[22,     7] loss: 1.291
[23,     7] loss: 1.291
[24,     7] loss: 1.288
[25,     7] loss: 1.306
[26,     7] loss: 1.311
[27,     7] loss: 1.273
[28,     7] loss: 1.275
[29,     7] loss: 1.284
[30,     7] loss: 1.303
[31,     7] loss: 1.299
[32,     7] loss: 1.272
[33,     7] loss: 1.284
[34,     7] loss: 1.285
[35,     7] loss: 1.293
[36,     7] loss: 1.296
[37,     7] loss: 1.286
[38,     7] loss: 1.274
[39,     7] loss: 1.289
[40,     7] loss: 1.302
[41,     7] loss: 1.282
[42,     7] loss: 1.261
[43,     7] loss: 1.273
[44,     7] loss: 1.261
[45,     7] loss: 1.283
[46,     7] loss: 1.276
[47,     7] loss: 1.278
[48,     7] loss: 1.290
[49,     7] loss: 1.260
[50,     7] loss: 1.277
[51,     7] loss: 1.302
Early stopping applied (best metric=0.4407835900783539)
Finished Training
Total time taken: 44.38211965560913
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.387
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.387
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.387
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.4415647089481354)
Finished Training
Total time taken: 43.64811563491821
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.384
[4,     7] loss: 1.353
[5,     7] loss: 1.326
[6,     7] loss: 1.320
[7,     7] loss: 1.300
[8,     7] loss: 1.304
[9,     7] loss: 1.307
[10,     7] loss: 1.360
[11,     7] loss: 1.331
[12,     7] loss: 1.324
[13,     7] loss: 1.317
[14,     7] loss: 1.305
[15,     7] loss: 1.284
[16,     7] loss: 1.305
[17,     7] loss: 1.306
[18,     7] loss: 1.295
[19,     7] loss: 1.277
[20,     7] loss: 1.279
[21,     7] loss: 1.287
[22,     7] loss: 1.311
[23,     7] loss: 1.279
[24,     7] loss: 1.280
[25,     7] loss: 1.259
[26,     7] loss: 1.276
[27,     7] loss: 1.263
[28,     7] loss: 1.300
[29,     7] loss: 1.312
[30,     7] loss: 1.285
[31,     7] loss: 1.267
[32,     7] loss: 1.306
[33,     7] loss: 1.302
[34,     7] loss: 1.273
[35,     7] loss: 1.275
[36,     7] loss: 1.274
[37,     7] loss: 1.261
[38,     7] loss: 1.301
[39,     7] loss: 1.348
[40,     7] loss: 1.402
[41,     7] loss: 1.386
[42,     7] loss: 1.384
[43,     7] loss: 1.381
[44,     7] loss: 1.368
[45,     7] loss: 1.356
[46,     7] loss: 1.365
[47,     7] loss: 1.353
[48,     7] loss: 1.347
[49,     7] loss: 1.344
[50,     7] loss: 1.343
[51,     7] loss: 1.343
[52,     7] loss: 1.342
[53,     7] loss: 1.335
[54,     7] loss: 1.334
[55,     7] loss: 1.344
[56,     7] loss: 1.329
[57,     7] loss: 1.333
[58,     7] loss: 1.331
[59,     7] loss: 1.324
[60,     7] loss: 1.346
[61,     7] loss: 1.326
[62,     7] loss: 1.321
[63,     7] loss: 1.324
[64,     7] loss: 1.338
[65,     7] loss: 1.330
[66,     7] loss: 1.318
[67,     7] loss: 1.348
[68,     7] loss: 1.387
[69,     7] loss: 1.386
[70,     7] loss: 1.387
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.384
[74,     7] loss: 1.377
[75,     7] loss: 1.371
[76,     7] loss: 1.362
[77,     7] loss: 1.355
[78,     7] loss: 1.346
[79,     7] loss: 1.343
[80,     7] loss: 1.336
[81,     7] loss: 1.341
[82,     7] loss: 1.346
[83,     7] loss: 1.335
[84,     7] loss: 1.351
[85,     7] loss: 1.340
[86,     7] loss: 1.334
[87,     7] loss: 1.337
[88,     7] loss: 1.333
[89,     7] loss: 1.321
Early stopping applied (best metric=0.43368640542030334)
Finished Training
Total time taken: 77.83221173286438
{'Methylation-R Validation Accuracy': 0.1852782494851418, 'Methylation-R Validation Sensitivity': 0.9537848605577689, 'Methylation-R Validation Specificity': 0.11418404907975459, 'Methylation-R Validation Precision': 0.09615503986696611, 'Methylation-R AUC ROC': 0.6407346093972712, 'Methylation-R AUC PR': 0.19701586886957467, 'Methylation-R MCC': 0.037960406845480826, 'Methylation-R F1': 0.17287223027541934, 'Validation Loss (Methylation-R)': 0.4159258008003235, 'Methylation-K Validation Accuracy': 0.18969944342646733, 'Methylation-K Validation Sensitivity': 0.9075593952483801, 'Methylation-K Validation Specificity': 0.1118314803978935, 'Methylation-K Validation Precision': 0.10163852617960666, 'Methylation-K AUC ROC': 0.4952292501634515, 'Methylation-K AUC PR': 0.09862817900355225, 'Methylation-K MCC': 0.011575702280077337, 'Methylation-K F1': 0.18098949365025266, 'Validation Loss (Methylation-K)': 0.44083312153816223, 'Validation Loss (total)': 0.8567589163780213, 'TimeToTrain': 51.258640909194945}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00928122451112032,
 'learning_rate_Methylation-K': 0.0023998430479264454,
 'learning_rate_Methylation-R': 0.003250277390848131,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7076790079326157,
 'loss_weight_Methylation-R': 0.37717274634622044,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1229401640,
 'sample_weights': [0.42104603217738285, 0.09491375872694752],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.82619353980921,
 'weight_decay_Methylation-K': 3.309780993679731,
 'weight_decay_Methylation-R': 9.67807744077403}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005473439484315404,
 'learning_rate_Methylation-K': 0.0008571182689577059,
 'learning_rate_Methylation-R': 0.00639380343107572,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.06968207052095333,
 'loss_weight_Methylation-R': 0.3467941271542161,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3483129050,
 'sample_weights': [0.37717274634622044, 0.7076790079326157],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.753071506065596,
 'weight_decay_Methylation-K': 4.605422075908536,
 'weight_decay_Methylation-R': 8.554466792250782}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.388
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006491378035050486,
 'learning_rate_Methylation-K': 0.0015366940461553323,
 'learning_rate_Methylation-R': 0.0043612489418811545,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.514776350306381,
 'loss_weight_Methylation-R': 0.7457040034879985,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3797529037,
 'sample_weights': [0.3467941271542161, 0.06968207052095333],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.069650134093392,
 'weight_decay_Methylation-K': 6.590241556296549,
 'weight_decay_Methylation-R': 7.535274537030144}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.385
[3,     7] loss: 1.385
[4,     7] loss: 1.363
[5,     7] loss: 1.343
[6,     7] loss: 1.326
[7,     7] loss: 1.308
[8,     7] loss: 1.299
[9,     7] loss: 1.290
[10,     7] loss: 1.276
[11,     7] loss: 1.291
[12,     7] loss: 1.328
[13,     7] loss: 1.358
[14,     7] loss: 1.312
[15,     7] loss: 1.295
[16,     7] loss: 1.301
[17,     7] loss: 1.330
[18,     7] loss: 1.334
[19,     7] loss: 1.308
[20,     7] loss: 1.299
[21,     7] loss: 1.292
[22,     7] loss: 1.329
[23,     7] loss: 1.292
[24,     7] loss: 1.284
[25,     7] loss: 1.262
[26,     7] loss: 1.270
[27,     7] loss: 1.268
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00704352645516722,
 'learning_rate_Methylation-K': 0.000368117400003774,
 'learning_rate_Methylation-R': 0.007189232070749125,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07483876734467192,
 'loss_weight_Methylation-R': 0.5045464669457529,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 279885997,
 'sample_weights': [0.7457040034879985, 0.514776350306381],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.83482470569686,
 'weight_decay_Methylation-K': 7.291697696413973,
 'weight_decay_Methylation-R': 9.631513152236368}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.387
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007297309318506627,
 'learning_rate_Methylation-K': 0.007674453641465885,
 'learning_rate_Methylation-R': 0.009907959704246459,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5041875361737264,
 'loss_weight_Methylation-R': 0.3601371863151045,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3001220948,
 'sample_weights': [0.5045464669457529, 0.07483876734467192],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.274028073824915,
 'weight_decay_Methylation-K': 0.005412891982632395,
 'weight_decay_Methylation-R': 6.021703410510463}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.388
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035236335892651397,
 'learning_rate_Methylation-K': 0.0007495016481976185,
 'learning_rate_Methylation-R': 0.0071587312295635225,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8168710634437765,
 'loss_weight_Methylation-R': 0.49864641150567507,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1837970547,
 'sample_weights': [0.3601371863151045, 0.5041875361737264],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.200750960681823,
 'weight_decay_Methylation-K': 1.9658575446195306,
 'weight_decay_Methylation-R': 8.499788993982634}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005376854914547242,
 'learning_rate_Methylation-K': 0.007318707240147711,
 'learning_rate_Methylation-R': 0.0024034151516582965,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5724721393979701,
 'loss_weight_Methylation-R': 0.5427801244821229,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2574975086,
 'sample_weights': [0.49864641150567507, 0.8168710634437765],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2979517951873794,
 'weight_decay_Methylation-K': 4.352525315600284,
 'weight_decay_Methylation-R': 9.994143738789601}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.385
[7,     7] loss: 1.376
[8,     7] loss: 1.348
[9,     7] loss: 1.336
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0098612243277111,
 'learning_rate_Methylation-K': 0.00262248736542505,
 'learning_rate_Methylation-R': 0.008783236976110671,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.013033752426553136,
 'loss_weight_Methylation-R': 0.5079040299441866,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 849739468,
 'sample_weights': [0.5427801244821229, 0.5724721393979701],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7898761316340113,
 'weight_decay_Methylation-K': 8.86106970905407,
 'weight_decay_Methylation-R': 7.938793233974637}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.387
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.387
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.4411686360836029)
Finished Training
Total time taken: 44.25312113761902
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.399
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.4374393820762634)
Finished Training
Total time taken: 44.457181453704834
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.387
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.387
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.387
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.386
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
[95,     7] loss: 1.386
[96,     7] loss: 1.386
[97,     7] loss: 1.386
[98,     7] loss: 1.386
[99,     7] loss: 1.386
[100,     7] loss: 1.386
[101,     7] loss: 1.386
[102,     7] loss: 1.386
[103,     7] loss: 1.386
[104,     7] loss: 1.386
[105,     7] loss: 1.386
[106,     7] loss: 1.386
Early stopping applied (best metric=0.44502395391464233)
Finished Training
Total time taken: 92.22624731063843
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.387
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.387
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
Early stopping applied (best metric=0.4456150233745575)
Finished Training
Total time taken: 60.00616192817688
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.378
[11,     7] loss: 1.361
[12,     7] loss: 1.336
[13,     7] loss: 1.319
[14,     7] loss: 1.310
[15,     7] loss: 1.323
[16,     7] loss: 1.296
[17,     7] loss: 1.297
[18,     7] loss: 1.285
[19,     7] loss: 1.286
[20,     7] loss: 1.268
[21,     7] loss: 1.305
[22,     7] loss: 1.286
[23,     7] loss: 1.271
[24,     7] loss: 1.273
[25,     7] loss: 1.290
[26,     7] loss: 1.302
[27,     7] loss: 1.318
[28,     7] loss: 1.278
[29,     7] loss: 1.275
[30,     7] loss: 1.262
[31,     7] loss: 1.270
[32,     7] loss: 1.264
[33,     7] loss: 1.311
[34,     7] loss: 1.306
[35,     7] loss: 1.271
[36,     7] loss: 1.260
[37,     7] loss: 1.261
[38,     7] loss: 1.272
[39,     7] loss: 1.261
[40,     7] loss: 1.267
[41,     7] loss: 1.304
[42,     7] loss: 1.284
[43,     7] loss: 1.254
[44,     7] loss: 1.266
[45,     7] loss: 1.274
[46,     7] loss: 1.269
[47,     7] loss: 1.269
[48,     7] loss: 1.303
[49,     7] loss: 1.269
[50,     7] loss: 1.271
[51,     7] loss: 1.272
[52,     7] loss: 1.335
[53,     7] loss: 1.306
[54,     7] loss: 1.305
[55,     7] loss: 1.271
[56,     7] loss: 1.263
[57,     7] loss: 1.268
[58,     7] loss: 1.270
[59,     7] loss: 1.249
[60,     7] loss: 1.301
[61,     7] loss: 1.287
[62,     7] loss: 1.264
[63,     7] loss: 1.248
[64,     7] loss: 1.303
[65,     7] loss: 1.284
[66,     7] loss: 1.278
[67,     7] loss: 1.270
[68,     7] loss: 1.265
[69,     7] loss: 1.250
[70,     7] loss: 1.267
[71,     7] loss: 1.241
[72,     7] loss: 1.265
[73,     7] loss: 1.272
[74,     7] loss: 1.260
[75,     7] loss: 1.252
[76,     7] loss: 1.267
Early stopping applied (best metric=0.4423726201057434)
Finished Training
Total time taken: 67.16048812866211
{'Methylation-R Validation Accuracy': 0.1727656132950935, 'Methylation-R Validation Sensitivity': 0.9755644090305445, 'Methylation-R Validation Specificity': 0.09850306748466257, 'Methylation-R Validation Precision': 0.09530372475609475, 'Methylation-R AUC ROC': 0.5505437910419693, 'Methylation-R AUC PR': 0.31808946569393287, 'Methylation-R MCC': 0.04134371604389778, 'Methylation-R F1': 0.17255162969969348, 'Validation Loss (Methylation-R)': 0.4152005672454834, 'Methylation-K Validation Accuracy': 0.16150812255221964, 'Methylation-K Validation Sensitivity': 0.9280777537796976, 'Methylation-K Validation Specificity': 0.07836161497952018, 'Methylation-K Validation Precision': 0.09876924636458824, 'Methylation-K AUC ROC': 0.5003826937133568, 'Methylation-K AUC PR': 0.28038161630247094, 'Methylation-K MCC': 0.0039235810881915354, 'Methylation-K F1': 0.1779340266642232, 'Validation Loss (Methylation-K)': 0.4423239231109619, 'Validation Loss (total)': 0.8575244903564453, 'TimeToTrain': 61.62063999176026}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032851625315926166,
 'learning_rate_Methylation-K': 0.006471638277850946,
 'learning_rate_Methylation-R': 0.003009187123635622,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.009150405348685442,
 'loss_weight_Methylation-R': 0.027695044790327417,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3075800547,
 'sample_weights': [0.5079040299441866, 0.013033752426553136],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.265286451187828,
 'weight_decay_Methylation-K': 3.8328022045453833,
 'weight_decay_Methylation-R': 1.546572176720261}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.380
[3,     7] loss: 1.342
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007040198198426084,
 'learning_rate_Methylation-K': 0.008305906251515572,
 'learning_rate_Methylation-R': 0.00807397812884757,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8979345887061764,
 'loss_weight_Methylation-R': 0.8190152195648396,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1123784396,
 'sample_weights': [0.027695044790327417, 0.009150405348685442],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3597412087142686,
 'weight_decay_Methylation-K': 2.825316164870306,
 'weight_decay_Methylation-R': 7.3933463397906305}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0072943316109674375,
 'learning_rate_Methylation-K': 0.002811039835071967,
 'learning_rate_Methylation-R': 0.009789567754922145,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.17605997002911045,
 'loss_weight_Methylation-R': 0.41160967185624514,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1196381798,
 'sample_weights': [0.8190152195648396, 0.8979345887061764],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.853686714636559,
 'weight_decay_Methylation-K': 4.949496083402982,
 'weight_decay_Methylation-R': 9.186454056377306}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008606648955046847,
 'learning_rate_Methylation-K': 0.00024107824424738096,
 'learning_rate_Methylation-R': 0.009868206588237597,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2541346740118119,
 'loss_weight_Methylation-R': 0.229274394289685,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3460527343,
 'sample_weights': [0.41160967185624514, 0.17605997002911045],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.034680250583425,
 'weight_decay_Methylation-K': 9.551647938535012,
 'weight_decay_Methylation-R': 7.553782044796874}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.396
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00682055669780298,
 'learning_rate_Methylation-K': 0.006611205360292599,
 'learning_rate_Methylation-R': 0.008217873123641743,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7942170716289707,
 'loss_weight_Methylation-R': 0.9087877316520938,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2964023279,
 'sample_weights': [0.229274394289685, 0.2541346740118119],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7687816344284089,
 'weight_decay_Methylation-K': 2.073433722628644,
 'weight_decay_Methylation-R': 6.329477702331865}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.384
[7,     7] loss: 1.377
[8,     7] loss: 1.345
[9,     7] loss: 1.334
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0021618748405871444,
 'learning_rate_Methylation-K': 0.0010505305497803632,
 'learning_rate_Methylation-R': 0.001912856537850934,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.36715567027591234,
 'loss_weight_Methylation-R': 0.9860472518814761,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3973792395,
 'sample_weights': [0.9087877316520938, 0.7942170716289707],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.449315659440728,
 'weight_decay_Methylation-K': 9.646729857038117,
 'weight_decay_Methylation-R': 7.875293117309868}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.404
[2,     7] loss: 1.386
[3,     7] loss: 1.369
[4,     7] loss: 1.337
[5,     7] loss: 1.322
[6,     7] loss: 1.316
[7,     7] loss: 1.302
[8,     7] loss: 1.284
[9,     7] loss: 1.285
[10,     7] loss: 1.264
[11,     7] loss: 1.272
[12,     7] loss: 1.252
[13,     7] loss: 1.282
[14,     7] loss: 1.269
[15,     7] loss: 1.253
[16,     7] loss: 1.242
[17,     7] loss: 1.235
[18,     7] loss: 1.230
[19,     7] loss: 1.221
[20,     7] loss: 1.219
[21,     7] loss: 1.241
[22,     7] loss: 1.221
[23,     7] loss: 1.216
[24,     7] loss: 1.214
[25,     7] loss: 1.216
[26,     7] loss: 1.221
[27,     7] loss: 1.228
[28,     7] loss: 1.225
[29,     7] loss: 1.201
[30,     7] loss: 1.233
[31,     7] loss: 1.209
[32,     7] loss: 1.205
[33,     7] loss: 1.204
[34,     7] loss: 1.199
[35,     7] loss: 1.224
[36,     7] loss: 1.201
[37,     7] loss: 1.202
[38,     7] loss: 1.205
[39,     7] loss: 1.183
[40,     7] loss: 1.157
[41,     7] loss: 1.188
[42,     7] loss: 1.161
[43,     7] loss: 1.186
[44,     7] loss: 1.171
[45,     7] loss: 1.197
[46,     7] loss: 1.177
[47,     7] loss: 1.163
[48,     7] loss: 1.159
[49,     7] loss: 1.159
[50,     7] loss: 1.176
[51,     7] loss: 1.155
[52,     7] loss: 1.173
[53,     7] loss: 1.184
[54,     7] loss: 1.190
[55,     7] loss: 1.184
[56,     7] loss: 1.181
[57,     7] loss: 1.155
[58,     7] loss: 1.169
[59,     7] loss: 1.166
[60,     7] loss: 1.160
[61,     7] loss: 1.169
[62,     7] loss: 1.179
[63,     7] loss: 1.201
[64,     7] loss: 1.204
[65,     7] loss: 1.177
[66,     7] loss: 1.144
[67,     7] loss: 1.193
[68,     7] loss: 1.184
[69,     7] loss: 1.193
[70,     7] loss: 1.177
[71,     7] loss: 1.147
[72,     7] loss: 1.169
[73,     7] loss: 1.147
[74,     7] loss: 1.159
[75,     7] loss: 1.157
[76,     7] loss: 1.152
[77,     7] loss: 1.179
[78,     7] loss: 1.171
[79,     7] loss: 1.147
[80,     7] loss: 1.145
[81,     7] loss: 1.133
[82,     7] loss: 1.124
[83,     7] loss: 1.179
[84,     7] loss: 1.166
[85,     7] loss: 1.160
[86,     7] loss: 1.145
[87,     7] loss: 1.134
[88,     7] loss: 1.157
[89,     7] loss: 1.123
[90,     7] loss: 1.123
[91,     7] loss: 1.166
[92,     7] loss: 1.143
[93,     7] loss: 1.134
[94,     7] loss: 1.137
[95,     7] loss: 1.120
[96,     7] loss: 1.143
[97,     7] loss: 1.118
[98,     7] loss: 1.118
[99,     7] loss: 1.110
[100,     7] loss: 1.159
[101,     7] loss: 1.134
[102,     7] loss: 1.121
[103,     7] loss: 1.128
[104,     7] loss: 1.131
[105,     7] loss: 1.109
[106,     7] loss: 1.124
[107,     7] loss: 1.141
[108,     7] loss: 1.144
[109,     7] loss: 1.112
[110,     7] loss: 1.130
[111,     7] loss: 1.161
[112,     7] loss: 1.148
[113,     7] loss: 1.144
[114,     7] loss: 1.127
[115,     7] loss: 1.167
[116,     7] loss: 1.146
[117,     7] loss: 1.131
[118,     7] loss: 1.140
[119,     7] loss: 1.118
[120,     7] loss: 1.119
[121,     7] loss: 1.119
[122,     7] loss: 1.184
[123,     7] loss: 1.142
[124,     7] loss: 1.141
[125,     7] loss: 1.112
[126,     7] loss: 1.134
[127,     7] loss: 1.110
[128,     7] loss: 1.162
[129,     7] loss: 1.157
[130,     7] loss: 1.113
[131,     7] loss: 1.126
[132,     7] loss: 1.128
[133,     7] loss: 1.122
[134,     7] loss: 1.113
[135,     7] loss: 1.157
[136,     7] loss: 1.159
[137,     7] loss: 1.143
[138,     7] loss: 1.133
[139,     7] loss: 1.128
[140,     7] loss: 1.123
[141,     7] loss: 1.146
[142,     7] loss: 1.121
[143,     7] loss: 1.116
[144,     7] loss: 1.130
[145,     7] loss: 1.128
[146,     7] loss: 1.115
[147,     7] loss: 1.130
[148,     7] loss: 1.131
[149,     7] loss: 1.162
[150,     7] loss: 1.136
[151,     7] loss: 1.132
[152,     7] loss: 1.138
[153,     7] loss: 1.139
[154,     7] loss: 1.141
[155,     7] loss: 1.133
[156,     7] loss: 1.157
[157,     7] loss: 1.178
[158,     7] loss: 1.165
[159,     7] loss: 1.165
[160,     7] loss: 1.138
Early stopping applied (best metric=0.34704476594924927)
Finished Training
Total time taken: 141.21091198921204
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.383
[3,     7] loss: 1.371
[4,     7] loss: 1.338
[5,     7] loss: 1.320
[6,     7] loss: 1.315
[7,     7] loss: 1.293
[8,     7] loss: 1.282
[9,     7] loss: 1.269
[10,     7] loss: 1.264
[11,     7] loss: 1.260
[12,     7] loss: 1.249
[13,     7] loss: 1.234
[14,     7] loss: 1.233
[15,     7] loss: 1.246
[16,     7] loss: 1.235
[17,     7] loss: 1.213
[18,     7] loss: 1.195
[19,     7] loss: 1.210
[20,     7] loss: 1.189
[21,     7] loss: 1.191
[22,     7] loss: 1.190
[23,     7] loss: 1.184
[24,     7] loss: 1.170
[25,     7] loss: 1.184
[26,     7] loss: 1.155
[27,     7] loss: 1.179
[28,     7] loss: 1.176
[29,     7] loss: 1.170
[30,     7] loss: 1.145
[31,     7] loss: 1.150
[32,     7] loss: 1.152
[33,     7] loss: 1.145
[34,     7] loss: 1.200
[35,     7] loss: 1.153
[36,     7] loss: 1.138
[37,     7] loss: 1.158
[38,     7] loss: 1.140
[39,     7] loss: 1.150
[40,     7] loss: 1.178
[41,     7] loss: 1.203
[42,     7] loss: 1.170
[43,     7] loss: 1.166
[44,     7] loss: 1.158
[45,     7] loss: 1.176
[46,     7] loss: 1.170
[47,     7] loss: 1.174
[48,     7] loss: 1.166
[49,     7] loss: 1.158
[50,     7] loss: 1.167
[51,     7] loss: 1.136
Early stopping applied (best metric=0.43766453862190247)
Finished Training
Total time taken: 44.061119556427
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.375
[3,     7] loss: 1.350
[4,     7] loss: 1.324
[5,     7] loss: 1.304
[6,     7] loss: 1.288
[7,     7] loss: 1.285
[8,     7] loss: 1.275
[9,     7] loss: 1.268
[10,     7] loss: 1.257
[11,     7] loss: 1.260
[12,     7] loss: 1.261
[13,     7] loss: 1.255
[14,     7] loss: 1.240
[15,     7] loss: 1.241
[16,     7] loss: 1.235
[17,     7] loss: 1.233
[18,     7] loss: 1.222
[19,     7] loss: 1.213
[20,     7] loss: 1.224
[21,     7] loss: 1.226
[22,     7] loss: 1.201
[23,     7] loss: 1.247
[24,     7] loss: 1.218
[25,     7] loss: 1.190
[26,     7] loss: 1.205
[27,     7] loss: 1.189
[28,     7] loss: 1.181
[29,     7] loss: 1.228
[30,     7] loss: 1.221
[31,     7] loss: 1.196
[32,     7] loss: 1.171
[33,     7] loss: 1.184
[34,     7] loss: 1.157
[35,     7] loss: 1.179
[36,     7] loss: 1.195
[37,     7] loss: 1.197
[38,     7] loss: 1.185
[39,     7] loss: 1.159
[40,     7] loss: 1.157
[41,     7] loss: 1.169
[42,     7] loss: 1.224
[43,     7] loss: 1.184
[44,     7] loss: 1.181
[45,     7] loss: 1.188
[46,     7] loss: 1.195
[47,     7] loss: 1.163
[48,     7] loss: 1.160
[49,     7] loss: 1.176
[50,     7] loss: 1.178
[51,     7] loss: 1.165
[52,     7] loss: 1.167
[53,     7] loss: 1.156
[54,     7] loss: 1.233
[55,     7] loss: 1.187
[56,     7] loss: 1.164
[57,     7] loss: 1.146
[58,     7] loss: 1.179
[59,     7] loss: 1.178
[60,     7] loss: 1.173
[61,     7] loss: 1.169
[62,     7] loss: 1.148
[63,     7] loss: 1.147
[64,     7] loss: 1.160
[65,     7] loss: 1.162
[66,     7] loss: 1.142
[67,     7] loss: 1.175
[68,     7] loss: 1.148
[69,     7] loss: 1.143
[70,     7] loss: 1.170
[71,     7] loss: 1.135
[72,     7] loss: 1.147
[73,     7] loss: 1.149
[74,     7] loss: 1.141
[75,     7] loss: 1.147
[76,     7] loss: 1.139
[77,     7] loss: 1.139
[78,     7] loss: 1.159
[79,     7] loss: 1.143
[80,     7] loss: 1.145
[81,     7] loss: 1.150
[82,     7] loss: 1.150
[83,     7] loss: 1.144
[84,     7] loss: 1.152
[85,     7] loss: 1.143
[86,     7] loss: 1.139
[87,     7] loss: 1.139
[88,     7] loss: 1.127
[89,     7] loss: 1.129
[90,     7] loss: 1.123
[91,     7] loss: 1.132
[92,     7] loss: 1.151
[93,     7] loss: 1.173
[94,     7] loss: 1.161
[95,     7] loss: 1.153
[96,     7] loss: 1.154
[97,     7] loss: 1.150
[98,     7] loss: 1.167
[99,     7] loss: 1.158
[100,     7] loss: 1.127
[101,     7] loss: 1.128
[102,     7] loss: 1.128
[103,     7] loss: 1.159
[104,     7] loss: 1.173
[105,     7] loss: 1.156
[106,     7] loss: 1.180
[107,     7] loss: 1.154
[108,     7] loss: 1.139
[109,     7] loss: 1.136
[110,     7] loss: 1.127
[111,     7] loss: 1.145
[112,     7] loss: 1.152
[113,     7] loss: 1.134
[114,     7] loss: 1.141
[115,     7] loss: 1.132
[116,     7] loss: 1.121
[117,     7] loss: 1.169
[118,     7] loss: 1.168
[119,     7] loss: 1.140
[120,     7] loss: 1.138
[121,     7] loss: 1.156
[122,     7] loss: 1.147
[123,     7] loss: 1.126
[124,     7] loss: 1.149
[125,     7] loss: 1.143
[126,     7] loss: 1.140
[127,     7] loss: 1.126
[128,     7] loss: 1.141
[129,     7] loss: 1.169
[130,     7] loss: 1.150
[131,     7] loss: 1.170
[132,     7] loss: 1.166
[133,     7] loss: 1.157
[134,     7] loss: 1.143
Early stopping applied (best metric=0.3461921215057373)
Finished Training
Total time taken: 116.26731419563293
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.385
[3,     7] loss: 1.375
[4,     7] loss: 1.352
[5,     7] loss: 1.326
[6,     7] loss: 1.331
[7,     7] loss: 1.312
[8,     7] loss: 1.289
[9,     7] loss: 1.292
[10,     7] loss: 1.278
[11,     7] loss: 1.266
[12,     7] loss: 1.249
[13,     7] loss: 1.222
[14,     7] loss: 1.197
[15,     7] loss: 1.198
[16,     7] loss: 1.204
[17,     7] loss: 1.180
[18,     7] loss: 1.178
[19,     7] loss: 1.194
[20,     7] loss: 1.164
[21,     7] loss: 1.163
[22,     7] loss: 1.189
[23,     7] loss: 1.166
[24,     7] loss: 1.138
[25,     7] loss: 1.145
[26,     7] loss: 1.135
[27,     7] loss: 1.132
[28,     7] loss: 1.122
[29,     7] loss: 1.127
[30,     7] loss: 1.126
[31,     7] loss: 1.127
[32,     7] loss: 1.136
[33,     7] loss: 1.118
[34,     7] loss: 1.127
[35,     7] loss: 1.139
[36,     7] loss: 1.121
[37,     7] loss: 1.100
[38,     7] loss: 1.151
[39,     7] loss: 1.148
[40,     7] loss: 1.132
[41,     7] loss: 1.123
[42,     7] loss: 1.138
[43,     7] loss: 1.115
[44,     7] loss: 1.136
[45,     7] loss: 1.115
[46,     7] loss: 1.129
[47,     7] loss: 1.154
[48,     7] loss: 1.149
[49,     7] loss: 1.143
[50,     7] loss: 1.136
[51,     7] loss: 1.127
Early stopping applied (best metric=0.44441893696784973)
Finished Training
Total time taken: 44.63311719894409
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.392
[2,     7] loss: 1.385
[3,     7] loss: 1.372
[4,     7] loss: 1.338
[5,     7] loss: 1.324
[6,     7] loss: 1.318
[7,     7] loss: 1.299
[8,     7] loss: 1.285
[9,     7] loss: 1.264
[10,     7] loss: 1.256
[11,     7] loss: 1.246
[12,     7] loss: 1.252
[13,     7] loss: 1.259
[14,     7] loss: 1.238
[15,     7] loss: 1.233
[16,     7] loss: 1.224
[17,     7] loss: 1.236
[18,     7] loss: 1.229
[19,     7] loss: 1.255
[20,     7] loss: 1.227
[21,     7] loss: 1.220
[22,     7] loss: 1.224
[23,     7] loss: 1.202
[24,     7] loss: 1.224
[25,     7] loss: 1.231
[26,     7] loss: 1.189
[27,     7] loss: 1.200
[28,     7] loss: 1.187
[29,     7] loss: 1.215
[30,     7] loss: 1.188
[31,     7] loss: 1.169
[32,     7] loss: 1.166
[33,     7] loss: 1.193
[34,     7] loss: 1.172
[35,     7] loss: 1.157
[36,     7] loss: 1.186
[37,     7] loss: 1.176
[38,     7] loss: 1.163
[39,     7] loss: 1.198
[40,     7] loss: 1.170
[41,     7] loss: 1.151
[42,     7] loss: 1.139
[43,     7] loss: 1.177
[44,     7] loss: 1.156
[45,     7] loss: 1.154
[46,     7] loss: 1.156
[47,     7] loss: 1.151
[48,     7] loss: 1.153
[49,     7] loss: 1.172
[50,     7] loss: 1.165
[51,     7] loss: 1.158
[52,     7] loss: 1.146
[53,     7] loss: 1.158
[54,     7] loss: 1.231
[55,     7] loss: 1.168
[56,     7] loss: 1.150
[57,     7] loss: 1.166
[58,     7] loss: 1.151
[59,     7] loss: 1.164
[60,     7] loss: 1.137
[61,     7] loss: 1.180
[62,     7] loss: 1.171
[63,     7] loss: 1.144
[64,     7] loss: 1.177
[65,     7] loss: 1.194
[66,     7] loss: 1.142
[67,     7] loss: 1.147
[68,     7] loss: 1.142
[69,     7] loss: 1.151
[70,     7] loss: 1.151
[71,     7] loss: 1.145
[72,     7] loss: 1.136
[73,     7] loss: 1.161
[74,     7] loss: 1.177
[75,     7] loss: 1.168
[76,     7] loss: 1.149
[77,     7] loss: 1.131
[78,     7] loss: 1.151
[79,     7] loss: 1.155
[80,     7] loss: 1.137
[81,     7] loss: 1.121
[82,     7] loss: 1.186
[83,     7] loss: 1.152
[84,     7] loss: 1.157
[85,     7] loss: 1.137
[86,     7] loss: 1.144
[87,     7] loss: 1.125
[88,     7] loss: 1.145
[89,     7] loss: 1.121
[90,     7] loss: 1.133
[91,     7] loss: 1.156
[92,     7] loss: 1.219
[93,     7] loss: 1.207
[94,     7] loss: 1.194
[95,     7] loss: 1.170
[96,     7] loss: 1.148
[97,     7] loss: 1.131
[98,     7] loss: 1.136
[99,     7] loss: 1.151
[100,     7] loss: 1.146
[101,     7] loss: 1.152
[102,     7] loss: 1.154
[103,     7] loss: 1.163
[104,     7] loss: 1.126
[105,     7] loss: 1.131
[106,     7] loss: 1.149
[107,     7] loss: 1.131
[108,     7] loss: 1.138
[109,     7] loss: 1.142
[110,     7] loss: 1.143
[111,     7] loss: 1.138
[112,     7] loss: 1.133
[113,     7] loss: 1.164
Early stopping applied (best metric=0.3535338342189789)
Finished Training
Total time taken: 98.75126695632935
{'Methylation-R Validation Accuracy': 0.44112005210596106, 'Methylation-R Validation Sensitivity': 0.8604225009775223, 'Methylation-R Validation Specificity': 0.4023312883435583, 'Methylation-R Validation Precision': 0.14150717749409472, 'Methylation-R AUC ROC': 0.7531172675546263, 'Methylation-R AUC PR': 0.30395580008473283, 'Methylation-R MCC': 0.1528922679950023, 'Methylation-R F1': 0.23645362966880368, 'Validation Loss (Methylation-R)': 0.3635262966156006, 'Methylation-K Validation Accuracy': 0.3489948030168889, 'Methylation-K Validation Sensitivity': 0.9017877404759076, 'Methylation-K Validation Specificity': 0.28903688119106774, 'Methylation-K Validation Precision': 0.12894319172959356, 'Methylation-K AUC ROC': 0.6325549178847308, 'Methylation-K AUC PR': 0.1828466814348898, 'Methylation-K MCC': 0.11453285412270739, 'Methylation-K F1': 0.22346517702621171, 'Validation Loss (Methylation-K)': 0.38577083945274354, 'Validation Loss (total)': 0.7492971301078797, 'TimeToTrain': 88.98474597930908}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008586479927882532,
 'learning_rate_Methylation-K': 0.0037198889641946358,
 'learning_rate_Methylation-R': 0.008403632588745765,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.003892162335181852,
 'loss_weight_Methylation-R': 0.443166946070576,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3688268487,
 'sample_weights': [0.9860472518814761, 0.36715567027591234],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1673431038697633,
 'weight_decay_Methylation-K': 9.591755592214351,
 'weight_decay_Methylation-R': 9.2415856483243}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007435427810021775,
 'learning_rate_Methylation-K': 0.0019540866314214497,
 'learning_rate_Methylation-R': 0.004623067603487561,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.280194653611712,
 'loss_weight_Methylation-R': 0.5918621335177008,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2501286346,
 'sample_weights': [0.443166946070576, 0.003892162335181852],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.454967653091259,
 'weight_decay_Methylation-K': 3.296286902460148,
 'weight_decay_Methylation-R': 9.75166787219588}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.382
[9,     7] loss: 1.377
[10,     7] loss: 1.371
[11,     7] loss: 1.382
[12,     7] loss: 1.386
[13,     7] loss: 1.378
[14,     7] loss: 1.367
[15,     7] loss: 1.355
[16,     7] loss: 1.353
[17,     7] loss: 1.354
[18,     7] loss: 1.332
[19,     7] loss: 1.342
[20,     7] loss: 1.329
[21,     7] loss: 1.318
[22,     7] loss: 1.327
[23,     7] loss: 1.331
[24,     7] loss: 1.323
[25,     7] loss: 1.341
[26,     7] loss: 1.322
[27,     7] loss: 1.310
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006552254051236838,
 'learning_rate_Methylation-K': 0.006247540164898798,
 'learning_rate_Methylation-R': 0.009987476695733993,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7287562593087387,
 'loss_weight_Methylation-R': 0.6030374254590853,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 913474840,
 'sample_weights': [0.5918621335177008, 0.280194653611712],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.2433476186070619,
 'weight_decay_Methylation-K': 3.446027166361468,
 'weight_decay_Methylation-R': 5.661505639247363}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.385
[8,     7] loss: 1.384
[9,     7] loss: 1.374
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009782111810388931,
 'learning_rate_Methylation-K': 0.004548285725297425,
 'learning_rate_Methylation-R': 0.006686120338258589,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5929281800278419,
 'loss_weight_Methylation-R': 0.7134688772768991,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1865146235,
 'sample_weights': [0.6030374254590853, 0.7287562593087387],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7942880186121928,
 'weight_decay_Methylation-K': 2.347908866177626,
 'weight_decay_Methylation-R': 4.514441165870187}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009577389258848065,
 'learning_rate_Methylation-K': 0.002765134997171924,
 'learning_rate_Methylation-R': 0.006964992277286644,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.355424105837441,
 'loss_weight_Methylation-R': 0.44993980676264933,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1777504173,
 'sample_weights': [0.7134688772768991, 0.5929281800278419],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.708173664518302,
 'weight_decay_Methylation-K': 7.440634058416417,
 'weight_decay_Methylation-R': 7.842741886717566}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009517144080431058,
 'learning_rate_Methylation-K': 0.00036113823081231213,
 'learning_rate_Methylation-R': 0.00928305877296501,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.06705287630845223,
 'loss_weight_Methylation-R': 0.7796890322387063,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3017064364,
 'sample_weights': [0.44993980676264933, 0.355424105837441],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.5656829464290425,
 'weight_decay_Methylation-K': 7.4678492063316595,
 'weight_decay_Methylation-R': 8.825700333128694}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008717093541342397,
 'learning_rate_Methylation-K': 0.002360316988005965,
 'learning_rate_Methylation-R': 0.007687494908365723,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6813257236552064,
 'loss_weight_Methylation-R': 0.24994197526453055,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 36653573,
 'sample_weights': [0.7796890322387063, 0.06705287630845223],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.51298509142574,
 'weight_decay_Methylation-K': 3.354441367065558,
 'weight_decay_Methylation-R': 9.81721175977206}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008012075741026069,
 'learning_rate_Methylation-K': 0.00226172685676686,
 'learning_rate_Methylation-R': 0.006112249196924478,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.19409522864741008,
 'loss_weight_Methylation-R': 0.6387311869956273,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3307281266,
 'sample_weights': [0.24994197526453055, 0.6813257236552064],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2898627859756373,
 'weight_decay_Methylation-K': 9.968570060636916,
 'weight_decay_Methylation-R': 7.253667897120884}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.44487860798835754)
Finished Training
Total time taken: 45.20112419128418
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.382
[10,     7] loss: 1.347
[11,     7] loss: 1.334
[12,     7] loss: 1.308
[13,     7] loss: 1.312
[14,     7] loss: 1.290
[15,     7] loss: 1.283
[16,     7] loss: 1.287
[17,     7] loss: 1.287
[18,     7] loss: 1.266
[19,     7] loss: 1.260
[20,     7] loss: 1.254
[21,     7] loss: 1.277
[22,     7] loss: 1.254
[23,     7] loss: 1.242
[24,     7] loss: 1.263
[25,     7] loss: 1.243
[26,     7] loss: 1.238
[27,     7] loss: 1.257
[28,     7] loss: 1.256
[29,     7] loss: 1.256
[30,     7] loss: 1.267
[31,     7] loss: 1.292
[32,     7] loss: 1.284
[33,     7] loss: 1.246
[34,     7] loss: 1.231
[35,     7] loss: 1.241
[36,     7] loss: 1.239
[37,     7] loss: 1.225
[38,     7] loss: 1.311
[39,     7] loss: 1.330
[40,     7] loss: 1.270
[41,     7] loss: 1.252
[42,     7] loss: 1.277
[43,     7] loss: 1.247
[44,     7] loss: 1.226
[45,     7] loss: 1.217
[46,     7] loss: 1.330
[47,     7] loss: 1.365
[48,     7] loss: 1.306
[49,     7] loss: 1.274
[50,     7] loss: 1.244
[51,     7] loss: 1.242
[52,     7] loss: 1.235
[53,     7] loss: 1.332
[54,     7] loss: 1.326
[55,     7] loss: 1.304
[56,     7] loss: 1.314
[57,     7] loss: 1.302
[58,     7] loss: 1.262
[59,     7] loss: 1.248
[60,     7] loss: 1.232
[61,     7] loss: 1.232
[62,     7] loss: 1.230
[63,     7] loss: 1.240
[64,     7] loss: 1.251
[65,     7] loss: 1.224
[66,     7] loss: 1.239
[67,     7] loss: 1.270
[68,     7] loss: 1.268
[69,     7] loss: 1.242
[70,     7] loss: 1.240
[71,     7] loss: 1.222
[72,     7] loss: 1.223
[73,     7] loss: 1.329
[74,     7] loss: 1.274
[75,     7] loss: 1.251
[76,     7] loss: 1.235
[77,     7] loss: 1.221
[78,     7] loss: 1.219
[79,     7] loss: 1.245
[80,     7] loss: 1.228
[81,     7] loss: 1.235
[82,     7] loss: 1.233
[83,     7] loss: 1.246
[84,     7] loss: 1.210
[85,     7] loss: 1.190
[86,     7] loss: 1.238
[87,     7] loss: 1.226
[88,     7] loss: 1.216
[89,     7] loss: 1.197
[90,     7] loss: 1.233
[91,     7] loss: 1.226
[92,     7] loss: 1.206
[93,     7] loss: 1.214
[94,     7] loss: 1.184
[95,     7] loss: 1.182
[96,     7] loss: 1.248
[97,     7] loss: 1.218
[98,     7] loss: 1.173
[99,     7] loss: 1.181
[100,     7] loss: 1.183
[101,     7] loss: 1.190
[102,     7] loss: 1.273
[103,     7] loss: 1.300
[104,     7] loss: 1.227
[105,     7] loss: 1.189
[106,     7] loss: 1.180
[107,     7] loss: 1.175
[108,     7] loss: 1.214
[109,     7] loss: 1.182
[110,     7] loss: 1.187
[111,     7] loss: 1.174
[112,     7] loss: 1.217
[113,     7] loss: 1.171
[114,     7] loss: 1.165
[115,     7] loss: 1.234
[116,     7] loss: 1.193
[117,     7] loss: 1.211
[118,     7] loss: 1.200
[119,     7] loss: 1.184
[120,     7] loss: 1.163
[121,     7] loss: 1.160
[122,     7] loss: 1.185
[123,     7] loss: 1.178
[124,     7] loss: 1.177
[125,     7] loss: 1.203
[126,     7] loss: 1.180
[127,     7] loss: 1.154
[128,     7] loss: 1.142
[129,     7] loss: 1.275
[130,     7] loss: 1.334
[131,     7] loss: 1.303
[132,     7] loss: 1.290
Early stopping applied (best metric=0.3767845928668976)
Finished Training
Total time taken: 114.19331049919128
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
Early stopping applied (best metric=0.44540178775787354)
Finished Training
Total time taken: 61.54016470909119
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.367
[6,     7] loss: 1.344
[7,     7] loss: 1.332
[8,     7] loss: 1.315
[9,     7] loss: 1.307
[10,     7] loss: 1.297
[11,     7] loss: 1.286
[12,     7] loss: 1.268
[13,     7] loss: 1.262
[14,     7] loss: 1.277
[15,     7] loss: 1.307
[16,     7] loss: 1.274
[17,     7] loss: 1.262
[18,     7] loss: 1.264
[19,     7] loss: 1.247
[20,     7] loss: 1.251
[21,     7] loss: 1.244
[22,     7] loss: 1.256
[23,     7] loss: 1.240
[24,     7] loss: 1.228
[25,     7] loss: 1.224
[26,     7] loss: 1.328
[27,     7] loss: 1.318
[28,     7] loss: 1.282
[29,     7] loss: 1.284
[30,     7] loss: 1.260
[31,     7] loss: 1.253
[32,     7] loss: 1.251
[33,     7] loss: 1.226
[34,     7] loss: 1.229
[35,     7] loss: 1.230
[36,     7] loss: 1.236
[37,     7] loss: 1.261
[38,     7] loss: 1.237
[39,     7] loss: 1.224
[40,     7] loss: 1.226
[41,     7] loss: 1.239
[42,     7] loss: 1.217
[43,     7] loss: 1.247
[44,     7] loss: 1.313
[45,     7] loss: 1.280
[46,     7] loss: 1.263
[47,     7] loss: 1.235
[48,     7] loss: 1.223
[49,     7] loss: 1.196
[50,     7] loss: 1.244
[51,     7] loss: 1.244
[52,     7] loss: 1.227
[53,     7] loss: 1.198
[54,     7] loss: 1.201
[55,     7] loss: 1.200
[56,     7] loss: 1.203
[57,     7] loss: 1.219
[58,     7] loss: 1.184
[59,     7] loss: 1.189
[60,     7] loss: 1.285
[61,     7] loss: 1.281
[62,     7] loss: 1.267
[63,     7] loss: 1.237
[64,     7] loss: 1.212
[65,     7] loss: 1.205
[66,     7] loss: 1.197
[67,     7] loss: 1.199
[68,     7] loss: 1.188
[69,     7] loss: 1.182
[70,     7] loss: 1.247
[71,     7] loss: 1.254
[72,     7] loss: 1.233
[73,     7] loss: 1.179
[74,     7] loss: 1.265
[75,     7] loss: 1.228
[76,     7] loss: 1.221
[77,     7] loss: 1.218
[78,     7] loss: 1.191
[79,     7] loss: 1.188
[80,     7] loss: 1.205
[81,     7] loss: 1.192
[82,     7] loss: 1.226
[83,     7] loss: 1.221
[84,     7] loss: 1.211
[85,     7] loss: 1.199
[86,     7] loss: 1.191
[87,     7] loss: 1.201
[88,     7] loss: 1.257
[89,     7] loss: 1.219
[90,     7] loss: 1.190
[91,     7] loss: 1.179
[92,     7] loss: 1.193
[93,     7] loss: 1.256
[94,     7] loss: 1.332
[95,     7] loss: 1.317
[96,     7] loss: 1.282
[97,     7] loss: 1.254
[98,     7] loss: 1.260
[99,     7] loss: 1.268
[100,     7] loss: 1.241
[101,     7] loss: 1.205
[102,     7] loss: 1.227
[103,     7] loss: 1.245
[104,     7] loss: 1.397
[105,     7] loss: 1.389
[106,     7] loss: 1.386
[107,     7] loss: 1.387
[108,     7] loss: 1.386
[109,     7] loss: 1.386
[110,     7] loss: 1.386
[111,     7] loss: 1.386
[112,     7] loss: 1.386
[113,     7] loss: 1.386
[114,     7] loss: 1.386
[115,     7] loss: 1.386
[116,     7] loss: 1.386
[117,     7] loss: 1.386
[118,     7] loss: 1.386
[119,     7] loss: 1.386
[120,     7] loss: 1.386
[121,     7] loss: 1.386
[122,     7] loss: 1.386
[123,     7] loss: 1.386
Early stopping applied (best metric=0.3565201759338379)
Finished Training
Total time taken: 105.85928416252136
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.385
[5,     7] loss: 1.378
[6,     7] loss: 1.336
[7,     7] loss: 1.330
[8,     7] loss: 1.306
[9,     7] loss: 1.287
[10,     7] loss: 1.276
[11,     7] loss: 1.278
[12,     7] loss: 1.271
[13,     7] loss: 1.278
[14,     7] loss: 1.253
[15,     7] loss: 1.249
[16,     7] loss: 1.246
[17,     7] loss: 1.232
[18,     7] loss: 1.260
[19,     7] loss: 1.251
[20,     7] loss: 1.237
[21,     7] loss: 1.228
[22,     7] loss: 1.255
[23,     7] loss: 1.225
[24,     7] loss: 1.225
[25,     7] loss: 1.401
[26,     7] loss: 1.385
[27,     7] loss: 1.386
[28,     7] loss: 1.385
[29,     7] loss: 1.383
[30,     7] loss: 1.380
[31,     7] loss: 1.353
[32,     7] loss: 1.329
[33,     7] loss: 1.325
[34,     7] loss: 1.388
[35,     7] loss: 1.356
[36,     7] loss: 1.329
[37,     7] loss: 1.307
[38,     7] loss: 1.286
[39,     7] loss: 1.273
[40,     7] loss: 1.271
[41,     7] loss: 1.286
[42,     7] loss: 1.272
[43,     7] loss: 1.258
[44,     7] loss: 1.279
[45,     7] loss: 1.357
[46,     7] loss: 1.330
[47,     7] loss: 1.321
[48,     7] loss: 1.282
[49,     7] loss: 1.270
[50,     7] loss: 1.274
[51,     7] loss: 1.255
[52,     7] loss: 1.277
[53,     7] loss: 1.264
[54,     7] loss: 1.254
[55,     7] loss: 1.262
[56,     7] loss: 1.273
[57,     7] loss: 1.251
[58,     7] loss: 1.258
[59,     7] loss: 1.261
[60,     7] loss: 1.252
[61,     7] loss: 1.243
[62,     7] loss: 1.237
[63,     7] loss: 1.343
[64,     7] loss: 1.319
[65,     7] loss: 1.295
[66,     7] loss: 1.265
[67,     7] loss: 1.261
[68,     7] loss: 1.261
[69,     7] loss: 1.247
[70,     7] loss: 1.260
[71,     7] loss: 1.263
[72,     7] loss: 1.359
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.386
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
[95,     7] loss: 1.386
[96,     7] loss: 1.386
[97,     7] loss: 1.386
[98,     7] loss: 1.386
[99,     7] loss: 1.386
[100,     7] loss: 1.386
[101,     7] loss: 1.386
[102,     7] loss: 1.386
[103,     7] loss: 1.386
[104,     7] loss: 1.386
[105,     7] loss: 1.386
[106,     7] loss: 1.386
[107,     7] loss: 1.386
[108,     7] loss: 1.386
[109,     7] loss: 1.386
[110,     7] loss: 1.386
[111,     7] loss: 1.386
[112,     7] loss: 1.386
Early stopping applied (best metric=0.3814046382904053)
Finished Training
Total time taken: 96.04623103141785
{'Methylation-R Validation Accuracy': 0.34956009861299364, 'Methylation-R Validation Sensitivity': 0.9145645534572585, 'Methylation-R Validation Specificity': 0.29730061349693254, 'Methylation-R Validation Precision': 0.11715965340881491, 'Methylation-R AUC ROC': 0.6702555589535346, 'Methylation-R AUC PR': 0.3413208221704745, 'Methylation-R MCC': 0.12010469511215431, 'Methylation-R F1': 0.20529472927633016, 'Validation Loss (Methylation-R)': 0.36154603958129883, 'Methylation-K Validation Accuracy': 0.2164181651906714, 'Methylation-K Validation Sensitivity': 0.9568314146518764, 'Methylation-K Validation Specificity': 0.13611652740266184, 'Methylation-K Validation Precision': 0.10840212771783168, 'Methylation-K AUC ROC': 0.6056863664628319, 'Methylation-K AUC PR': 0.22716327007487147, 'Methylation-K MCC': 0.06825758319039454, 'Methylation-K F1': 0.19444711254740915, 'Validation Loss (Methylation-K)': 0.4009979605674744, 'Validation Loss (total)': 0.7625440120697021, 'TimeToTrain': 84.56802291870117}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037804724333834186,
 'learning_rate_Methylation-K': 0.00355592783286966,
 'learning_rate_Methylation-R': 0.005526992342093699,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2230315949271918,
 'loss_weight_Methylation-R': 0.8254698242188917,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1564267226,
 'sample_weights': [0.6387311869956273, 0.19409522864741008],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.536374867336072,
 'weight_decay_Methylation-K': 9.969955569479161,
 'weight_decay_Methylation-R': 8.98647045542132}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009657729059415615,
 'learning_rate_Methylation-K': 0.0016836809267170758,
 'learning_rate_Methylation-R': 0.0048862416048952775,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1019437377895755,
 'loss_weight_Methylation-R': 0.574666192926884,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3020378909,
 'sample_weights': [0.8254698242188917, 0.2230315949271918],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.4530741994669243,
 'weight_decay_Methylation-K': 5.435986787064287,
 'weight_decay_Methylation-R': 7.512240989009074}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00597088253200352,
 'learning_rate_Methylation-K': 0.00046657404552641574,
 'learning_rate_Methylation-R': 0.003806029932997264,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.47225597162214,
 'loss_weight_Methylation-R': 0.712476991143546,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3708186038,
 'sample_weights': [0.574666192926884, 0.1019437377895755],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.798060920587414,
 'weight_decay_Methylation-K': 9.818584768685362,
 'weight_decay_Methylation-R': 4.332589298098789}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009609623497583254,
 'learning_rate_Methylation-K': 0.0007882368543756022,
 'learning_rate_Methylation-R': 0.006920844722727897,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07347380899174943,
 'loss_weight_Methylation-R': 0.48682234087732656,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2417659940,
 'sample_weights': [0.712476991143546, 0.47225597162214],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8382870864592893,
 'weight_decay_Methylation-K': 8.979604385922887,
 'weight_decay_Methylation-R': 3.7312321460772537}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009858636665926486,
 'learning_rate_Methylation-K': 0.002066655700417847,
 'learning_rate_Methylation-R': 0.0034167343470190496,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07179223421024852,
 'loss_weight_Methylation-R': 0.9321214973618263,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1946162783,
 'sample_weights': [0.48682234087732656, 0.07347380899174943],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.794119680371008,
 'weight_decay_Methylation-K': 8.858603582960896,
 'weight_decay_Methylation-R': 5.7930315847873946}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005002024923652931,
 'learning_rate_Methylation-K': 0.001920210718730385,
 'learning_rate_Methylation-R': 0.003903788209492168,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2891121085267921,
 'loss_weight_Methylation-R': 0.518251950716069,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2637213488,
 'sample_weights': [0.9321214973618263, 0.07179223421024852],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.056828128689973,
 'weight_decay_Methylation-K': 2.4237787960346053,
 'weight_decay_Methylation-R': 4.592293222747024}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.385
[7,     7] loss: 1.380
[8,     7] loss: 1.333
[9,     7] loss: 1.322
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00954561490014297,
 'learning_rate_Methylation-K': 0.0029610160871704704,
 'learning_rate_Methylation-R': 0.008523287792212158,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6063876734925365,
 'loss_weight_Methylation-R': 0.8920566829426189,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 442817421,
 'sample_weights': [0.518251950716069, 0.2891121085267921],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.394424650630214,
 'weight_decay_Methylation-K': 6.580444354042392,
 'weight_decay_Methylation-R': 6.84814311688012}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009699624017045189,
 'learning_rate_Methylation-K': 0.005294203754979504,
 'learning_rate_Methylation-R': 0.007399436591006701,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.08252647975809496,
 'loss_weight_Methylation-R': 0.5124662410523079,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3177946725,
 'sample_weights': [0.8920566829426189, 0.6063876734925365],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.216711527583823,
 'weight_decay_Methylation-K': 7.324425955111313,
 'weight_decay_Methylation-R': 5.592690928673156}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007712025811107388,
 'learning_rate_Methylation-K': 0.00430089620645225,
 'learning_rate_Methylation-R': 0.009907571034952887,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6241991309245594,
 'loss_weight_Methylation-R': 0.6975014665163015,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3974587284,
 'sample_weights': [0.5124662410523079, 0.08252647975809496],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1031271942700878,
 'weight_decay_Methylation-K': 1.0485754386271446,
 'weight_decay_Methylation-R': 8.933798654433861}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009665012330001057,
 'learning_rate_Methylation-K': 0.0027165591185803585,
 'learning_rate_Methylation-R': 0.00931423388379601,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.16479108880048213,
 'loss_weight_Methylation-R': 0.7308998400029781,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2952053668,
 'sample_weights': [0.6975014665163015, 0.6241991309245594],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.0679870173269483,
 'weight_decay_Methylation-K': 9.911412679858,
 'weight_decay_Methylation-R': 8.43611157971734}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005995692140943286,
 'learning_rate_Methylation-K': 0.007509586209388361,
 'learning_rate_Methylation-R': 0.006732250115825665,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8074575099741799,
 'loss_weight_Methylation-R': 0.24127216305227378,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2766145948,
 'sample_weights': [0.7308998400029781, 0.16479108880048213],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.622995472923629,
 'weight_decay_Methylation-K': 2.9805365931979555,
 'weight_decay_Methylation-R': 8.8707019422319}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.385
[5,     7] loss: 1.381
[6,     7] loss: 1.346
[7,     7] loss: 1.320
[8,     7] loss: 1.318
[9,     7] loss: 1.314
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008654288585507198,
 'learning_rate_Methylation-K': 0.004920906375427343,
 'learning_rate_Methylation-R': 0.008223878827599427,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.057022464905326226,
 'loss_weight_Methylation-R': 0.6393206243978111,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3714422118,
 'sample_weights': [0.24127216305227378, 0.8074575099741799],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.84842378670975,
 'weight_decay_Methylation-K': 4.035069811312284,
 'weight_decay_Methylation-R': 6.025752948817358}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.387
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0075506390849840715,
 'learning_rate_Methylation-K': 0.006810230223716393,
 'learning_rate_Methylation-R': 0.007961436555125396,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.758777034662222,
 'loss_weight_Methylation-R': 0.45086897721909136,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3781205618,
 'sample_weights': [0.6393206243978111, 0.057022464905326226],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.856093707819805,
 'weight_decay_Methylation-K': 4.907635050211927,
 'weight_decay_Methylation-R': 8.362370639619144}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00958682641521313,
 'learning_rate_Methylation-K': 0.0007497201184455881,
 'learning_rate_Methylation-R': 0.005749359297721149,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3253228408001636,
 'loss_weight_Methylation-R': 0.6825288296190416,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4283672596,
 'sample_weights': [0.45086897721909136, 0.758777034662222],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.1545644604137566,
 'weight_decay_Methylation-K': 9.336304665995076,
 'weight_decay_Methylation-R': 6.091970331373138}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.44289857149124146)
Finished Training
Total time taken: 44.392104148864746
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.387
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.387
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.387
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.387
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
Early stopping applied (best metric=0.4447486996650696)
Finished Training
Total time taken: 80.95519280433655
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.387
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
Early stopping applied (best metric=0.44198134541511536)
Finished Training
Total time taken: 45.900110483169556
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.385
[16,     7] loss: 1.385
[17,     7] loss: 1.381
[18,     7] loss: 1.376
[19,     7] loss: 1.362
[20,     7] loss: 1.349
[21,     7] loss: 1.351
[22,     7] loss: 1.345
[23,     7] loss: 1.341
[24,     7] loss: 1.343
[25,     7] loss: 1.340
[26,     7] loss: 1.334
[27,     7] loss: 1.338
[28,     7] loss: 1.334
[29,     7] loss: 1.330
[30,     7] loss: 1.332
[31,     7] loss: 1.334
[32,     7] loss: 1.333
[33,     7] loss: 1.328
[34,     7] loss: 1.335
[35,     7] loss: 1.334
[36,     7] loss: 1.333
[37,     7] loss: 1.333
[38,     7] loss: 1.322
[39,     7] loss: 1.321
[40,     7] loss: 1.322
[41,     7] loss: 1.322
[42,     7] loss: 1.313
[43,     7] loss: 1.319
[44,     7] loss: 1.319
[45,     7] loss: 1.322
[46,     7] loss: 1.317
[47,     7] loss: 1.324
[48,     7] loss: 1.327
[49,     7] loss: 1.322
[50,     7] loss: 1.317
[51,     7] loss: 1.310
[52,     7] loss: 1.310
[53,     7] loss: 1.318
[54,     7] loss: 1.317
[55,     7] loss: 1.323
[56,     7] loss: 1.323
[57,     7] loss: 1.319
[58,     7] loss: 1.319
[59,     7] loss: 1.311
[60,     7] loss: 1.308
[61,     7] loss: 1.315
[62,     7] loss: 1.309
[63,     7] loss: 1.310
Early stopping applied (best metric=0.44534599781036377)
Finished Training
Total time taken: 54.89413237571716
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.387
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.387
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.387
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.386
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
Early stopping applied (best metric=0.44510969519615173)
Finished Training
Total time taken: 81.06419467926025
{'Methylation-R Validation Accuracy': 0.08466048019389166, 'Methylation-R Validation Sensitivity': 1.0, 'Methylation-R Validation Specificity': 0.0, 'Methylation-R Validation Precision': 0.08466048019389166, 'Methylation-R AUC ROC': 0.5645974353549983, 'Methylation-R AUC PR': 0.3080924406583863, 'Methylation-R MCC': 0.0, 'Methylation-R F1': 0.15610503065657413, 'Validation Loss (Methylation-R)': 0.4295562207698822, 'Methylation-K Validation Accuracy': 0.09784008327442427, 'Methylation-K Validation Sensitivity': 1.0, 'Methylation-K Validation Specificity': 0.0, 'Methylation-K Validation Precision': 0.09784008327442427, 'Methylation-K AUC ROC': 0.5008740186681835, 'Methylation-K AUC PR': 0.27976710200598043, 'Methylation-K MCC': 0.0, 'Methylation-K F1': 0.17824104586382167, 'Validation Loss (Methylation-K)': 0.44401686191558837, 'Validation Loss (total)': 0.8735730767250061, 'TimeToTrain': 61.44114689826965}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00998831291068708,
 'learning_rate_Methylation-K': 0.0006004876011271205,
 'learning_rate_Methylation-R': 0.0071783344568278245,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.28149960410849034,
 'loss_weight_Methylation-R': 0.5661848878025162,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4227554389,
 'sample_weights': [0.6825288296190416, 0.3253228408001636],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.429423017852443,
 'weight_decay_Methylation-K': 8.240647965382635,
 'weight_decay_Methylation-R': 9.100281305701282}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007482345342630113,
 'learning_rate_Methylation-K': 0.0022867973791346826,
 'learning_rate_Methylation-R': 0.005600112157074169,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1010580919718076,
 'loss_weight_Methylation-R': 0.6346166944281558,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1022947980,
 'sample_weights': [0.5661848878025162, 0.28149960410849034],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.300137804091005,
 'weight_decay_Methylation-K': 9.95769653568889,
 'weight_decay_Methylation-R': 7.072014856316459}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008945276098885062,
 'learning_rate_Methylation-K': 0.003926714516911623,
 'learning_rate_Methylation-R': 0.006352076977289109,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.24322627719541615,
 'loss_weight_Methylation-R': 0.8414097658632883,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3803044260,
 'sample_weights': [0.6346166944281558, 0.1010580919718076],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3686574086695473,
 'weight_decay_Methylation-K': 8.870733684933295,
 'weight_decay_Methylation-R': 6.239393973413353}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007326670577140488,
 'learning_rate_Methylation-K': 0.0015243552454412277,
 'learning_rate_Methylation-R': 0.0009631142738381985,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4065799424765625,
 'loss_weight_Methylation-R': 0.7005291966599002,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 468641251,
 'sample_weights': [0.8414097658632883, 0.24322627719541615],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.466370167795949,
 'weight_decay_Methylation-K': 0.9790522136953328,
 'weight_decay_Methylation-R': 5.037697963770542}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.383
[5,     7] loss: 1.361
[6,     7] loss: 1.335
[7,     7] loss: 1.311
[8,     7] loss: 1.299
[9,     7] loss: 1.315
[10,     7] loss: 1.272
[11,     7] loss: 1.276
[12,     7] loss: 1.301
[13,     7] loss: 1.363
[14,     7] loss: 1.363
[15,     7] loss: 1.344
[16,     7] loss: 1.336
[17,     7] loss: 1.344
[18,     7] loss: 1.331
[19,     7] loss: 1.294
[20,     7] loss: 1.329
[21,     7] loss: 1.345
[22,     7] loss: 1.323
[23,     7] loss: 1.301
[24,     7] loss: 1.310
[25,     7] loss: 1.355
[26,     7] loss: 1.327
[27,     7] loss: 1.311
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009066585965972157,
 'learning_rate_Methylation-K': 0.003396961854445837,
 'learning_rate_Methylation-R': 0.0075854496330197176,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7348235159205114,
 'loss_weight_Methylation-R': 0.3875483719908295,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3198622333,
 'sample_weights': [0.7005291966599002, 0.4065799424765625],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.047139774135527,
 'weight_decay_Methylation-K': 4.805931549025011,
 'weight_decay_Methylation-R': 9.44460052878521}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.396
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009859581732477356,
 'learning_rate_Methylation-K': 0.008354488635958123,
 'learning_rate_Methylation-R': 0.007967215116077132,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4309826223919253,
 'loss_weight_Methylation-R': 0.26196353624035584,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 745115925,
 'sample_weights': [0.3875483719908295, 0.7348235159205114],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.90104991178276,
 'weight_decay_Methylation-K': 8.6031410002923,
 'weight_decay_Methylation-R': 9.480280615230523}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006010368802436732,
 'learning_rate_Methylation-K': 0.007569267563236205,
 'learning_rate_Methylation-R': 0.0006073477816200116,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.54447593798133,
 'loss_weight_Methylation-R': 0.7701540352193077,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1735634192,
 'sample_weights': [0.26196353624035584, 0.4309826223919253],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.638038344179353,
 'weight_decay_Methylation-K': 9.221073325721449,
 'weight_decay_Methylation-R': 1.4679656579660194}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.383
[3,     7] loss: 1.372
[4,     7] loss: 1.353
[5,     7] loss: 1.331
[6,     7] loss: 1.325
[7,     7] loss: 1.313
[8,     7] loss: 1.298
[9,     7] loss: 1.291
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014683210194966637,
 'learning_rate_Methylation-K': 0.00022187790012525438,
 'learning_rate_Methylation-R': 0.007983462222676459,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9681377171871346,
 'loss_weight_Methylation-R': 0.027040028103596625,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2374570516,
 'sample_weights': [0.7701540352193077, 0.54447593798133],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.621174429422776,
 'weight_decay_Methylation-K': 4.791986042889046,
 'weight_decay_Methylation-R': 1.9085697831238946}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.381
[3,     7] loss: 1.357
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009391518744463668,
 'learning_rate_Methylation-K': 0.0009711550222461589,
 'learning_rate_Methylation-R': 0.0034498750968823834,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6019957680034944,
 'loss_weight_Methylation-R': 0.47042237633823825,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2192134594,
 'sample_weights': [0.027040028103596625, 0.9681377171871346],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4866746082639004,
 'weight_decay_Methylation-K': 8.386580859693057,
 'weight_decay_Methylation-R': 7.488616369188403}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009372433029577663,
 'learning_rate_Methylation-K': 4.244646966287366e-05,
 'learning_rate_Methylation-R': 0.006170557169861179,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.29180208241713873,
 'loss_weight_Methylation-R': 0.9914697670683825,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1376967929,
 'sample_weights': [0.47042237633823825, 0.6019957680034944],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.743717665378211,
 'weight_decay_Methylation-K': 3.937370440292578,
 'weight_decay_Methylation-R': 6.157325058410169}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005176901745274278,
 'learning_rate_Methylation-K': 0.000420655359173634,
 'learning_rate_Methylation-R': 0.004350401641317726,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6817554389534457,
 'loss_weight_Methylation-R': 0.49795668491253375,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1497740991,
 'sample_weights': [0.9914697670683825, 0.29180208241713873],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1712294517171262,
 'weight_decay_Methylation-K': 3.8288607208301513,
 'weight_decay_Methylation-R': 9.273556657181862}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.383
[5,     7] loss: 1.374
[6,     7] loss: 1.343
[7,     7] loss: 1.326
[8,     7] loss: 1.318
[9,     7] loss: 1.312
[10,     7] loss: 1.305
[11,     7] loss: 1.294
[12,     7] loss: 1.275
[13,     7] loss: 1.282
[14,     7] loss: 1.269
[15,     7] loss: 1.257
[16,     7] loss: 1.253
[17,     7] loss: 1.273
[18,     7] loss: 1.246
[19,     7] loss: 1.229
[20,     7] loss: 1.234
[21,     7] loss: 1.238
[22,     7] loss: 1.228
[23,     7] loss: 1.221
[24,     7] loss: 1.223
[25,     7] loss: 1.204
[26,     7] loss: 1.200
[27,     7] loss: 1.201
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007790223681293567,
 'learning_rate_Methylation-K': 0.0008769282877763615,
 'learning_rate_Methylation-R': 0.007402464742886347,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07608351404199282,
 'loss_weight_Methylation-R': 0.19326703313101629,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3047087484,
 'sample_weights': [0.49795668491253375, 0.6817554389534457],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.616369221362303,
 'weight_decay_Methylation-K': 2.078873819646536,
 'weight_decay_Methylation-R': 8.432210007210415}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.387
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.387
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.387
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009512245226326136,
 'learning_rate_Methylation-K': 0.00027392554744198015,
 'learning_rate_Methylation-R': 0.006849778684312096,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1235865102725755,
 'loss_weight_Methylation-R': 0.3548010374681063,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1530869556,
 'sample_weights': [0.19326703313101629, 0.07608351404199282],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.853578883530394,
 'weight_decay_Methylation-K': 6.53881095279126,
 'weight_decay_Methylation-R': 8.319348406085826}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.382
[8,     7] loss: 1.367
[9,     7] loss: 1.376
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009831221883501029,
 'learning_rate_Methylation-K': 0.005447840270338759,
 'learning_rate_Methylation-R': 0.009097187757814302,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.18859772300250838,
 'loss_weight_Methylation-R': 0.2798806566848597,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 867077542,
 'sample_weights': [0.3548010374681063, 0.1235865102725755],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.005099465381695,
 'weight_decay_Methylation-K': 9.388888866018403,
 'weight_decay_Methylation-R': 9.41343809642898}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006545872044514994,
 'learning_rate_Methylation-K': 0.003662259478969734,
 'learning_rate_Methylation-R': 0.007216132790919016,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.14121135066488705,
 'loss_weight_Methylation-R': 0.6449030916465817,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1634774079,
 'sample_weights': [0.2798806566848597, 0.18859772300250838],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5631155132198469,
 'weight_decay_Methylation-K': 9.791086907470241,
 'weight_decay_Methylation-R': 3.523866069677989}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00945323065778666,
 'learning_rate_Methylation-K': 0.0007428303975553126,
 'learning_rate_Methylation-R': 0.005474626615515589,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4222984308669455,
 'loss_weight_Methylation-R': 0.6930491246479166,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3005208545,
 'sample_weights': [0.6449030916465817, 0.14121135066488705],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6824438384658086,
 'weight_decay_Methylation-K': 7.498238218325993,
 'weight_decay_Methylation-R': 3.1431694864545054}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.384
[13,     7] loss: 1.372
[14,     7] loss: 1.349
[15,     7] loss: 1.335
[16,     7] loss: 1.319
[17,     7] loss: 1.309
[18,     7] loss: 1.311
[19,     7] loss: 1.306
[20,     7] loss: 1.305
[21,     7] loss: 1.302
[22,     7] loss: 1.312
[23,     7] loss: 1.301
[24,     7] loss: 1.302
[25,     7] loss: 1.297
[26,     7] loss: 1.288
[27,     7] loss: 1.291
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009626898411389372,
 'learning_rate_Methylation-K': 0.0089767136349924,
 'learning_rate_Methylation-R': 0.00963929418089168,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5185082338342742,
 'loss_weight_Methylation-R': 0.10985125879522531,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 980725533,
 'sample_weights': [0.6930491246479166, 0.4222984308669455],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.350825702484663,
 'weight_decay_Methylation-K': 8.755989214209272,
 'weight_decay_Methylation-R': 8.181229494878043}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0066056899366087815,
 'learning_rate_Methylation-K': 0.002168466130478134,
 'learning_rate_Methylation-R': 0.007222183959471195,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.48365362399999223,
 'loss_weight_Methylation-R': 0.44314313686678153,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1470333083,
 'sample_weights': [0.10985125879522531, 0.5185082338342742],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.475614498129257,
 'weight_decay_Methylation-K': 4.764815834765698,
 'weight_decay_Methylation-R': 9.0654479937783}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.384
[8,     7] loss: 1.369
[9,     7] loss: 1.361
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008346039111466518,
 'learning_rate_Methylation-K': 0.00026714966146700286,
 'learning_rate_Methylation-R': 0.0031700933949827203,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1369081133654896,
 'loss_weight_Methylation-R': 0.9819484066904118,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 906308199,
 'sample_weights': [0.44314313686678153, 0.48365362399999223],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.020488329243625,
 'weight_decay_Methylation-K': 5.616884964077438,
 'weight_decay_Methylation-R': 7.5401612125606565}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0091518461235374,
 'learning_rate_Methylation-K': 0.008203256263116545,
 'learning_rate_Methylation-R': 0.006897640487615538,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3686404696289034,
 'loss_weight_Methylation-R': 0.16969818476335735,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3165768610,
 'sample_weights': [0.9819484066904118, 0.1369081133654896],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8851303612441925,
 'weight_decay_Methylation-K': 7.500168528218518,
 'weight_decay_Methylation-R': 7.0807986155024984}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009906423029143968,
 'learning_rate_Methylation-K': 0.003880390848867518,
 'learning_rate_Methylation-R': 0.006565202450209949,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.49102327554182795,
 'loss_weight_Methylation-R': 0.7470015788380826,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1543120039,
 'sample_weights': [0.16969818476335735, 0.3686404696289034],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.682010268618014,
 'weight_decay_Methylation-K': 9.717857482326886,
 'weight_decay_Methylation-R': 8.948117649621036}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006282032158118483,
 'learning_rate_Methylation-K': 0.00021240316469581144,
 'learning_rate_Methylation-R': 0.00858126264004411,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.18156857970294726,
 'loss_weight_Methylation-R': 0.45859242325497324,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 107962403,
 'sample_weights': [0.7470015788380826, 0.49102327554182795],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.89273057134848,
 'weight_decay_Methylation-K': 3.9223355624875587,
 'weight_decay_Methylation-R': 9.20126713378477}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0046806396975286714,
 'learning_rate_Methylation-K': 0.006689341561813919,
 'learning_rate_Methylation-R': 0.0011822308571358612,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9780568334711934,
 'loss_weight_Methylation-R': 0.6393154992505905,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2971554594,
 'sample_weights': [0.45859242325497324, 0.18156857970294726],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.503686439844746,
 'weight_decay_Methylation-K': 8.806696012282314,
 'weight_decay_Methylation-R': 2.566540988779048}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.377
[4,     7] loss: 1.339
[5,     7] loss: 1.332
[6,     7] loss: 1.317
[7,     7] loss: 1.314
[8,     7] loss: 1.291
[9,     7] loss: 1.290
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00910351989003096,
 'learning_rate_Methylation-K': 0.008827840624130506,
 'learning_rate_Methylation-R': 0.0051690472175642335,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.35726850123492065,
 'loss_weight_Methylation-R': 0.576768312613557,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2905328958,
 'sample_weights': [0.6393154992505905, 0.9780568334711934],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7930660850811764,
 'weight_decay_Methylation-K': 9.319062352545222,
 'weight_decay_Methylation-R': 9.141327323536473}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00976484253105599,
 'learning_rate_Methylation-K': 0.0004937208114356236,
 'learning_rate_Methylation-R': 0.006410232187431387,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.11243240787366199,
 'loss_weight_Methylation-R': 0.8739994391352093,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1289586771,
 'sample_weights': [0.576768312613557, 0.35726850123492065],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.046140311743951,
 'weight_decay_Methylation-K': 9.320668141695014,
 'weight_decay_Methylation-R': 3.5052607226200454}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007004022715795818,
 'learning_rate_Methylation-K': 0.0005582917519731554,
 'learning_rate_Methylation-R': 0.008921895153470522,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.10744059058655106,
 'loss_weight_Methylation-R': 0.4590963341855099,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 833255188,
 'sample_weights': [0.8739994391352093, 0.11243240787366199],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.5557643879985985,
 'weight_decay_Methylation-K': 7.926766174542147,
 'weight_decay_Methylation-R': 9.764158487388297}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005475526206995318,
 'learning_rate_Methylation-K': 0.001667064191211787,
 'learning_rate_Methylation-R': 0.005357817673886957,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.17477957948368544,
 'loss_weight_Methylation-R': 0.5608706360460445,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 358721300,
 'sample_weights': [0.4590963341855099, 0.10744059058655106],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.17465146922541486,
 'weight_decay_Methylation-K': 9.900408369561498,
 'weight_decay_Methylation-R': 8.617453637698826}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009743064642315148,
 'learning_rate_Methylation-K': 0.0019353155501387349,
 'learning_rate_Methylation-R': 0.007125494239308199,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2429195510627758,
 'loss_weight_Methylation-R': 0.7841417786545666,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 925654743,
 'sample_weights': [0.5608706360460445, 0.17477957948368544],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.058461113390504,
 'weight_decay_Methylation-K': 9.894628643539342,
 'weight_decay_Methylation-R': 7.828348964781926}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006036049276914202,
 'learning_rate_Methylation-K': 0.004800676665821805,
 'learning_rate_Methylation-R': 0.0042718995364208106,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.24465566444962117,
 'loss_weight_Methylation-R': 0.8322872013881129,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 657569771,
 'sample_weights': [0.7841417786545666, 0.2429195510627758],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.954383622936987,
 'weight_decay_Methylation-K': 8.099771933091196,
 'weight_decay_Methylation-R': 9.575415393323254}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032060224524429713,
 'learning_rate_Methylation-K': 0.0009849601169564957,
 'learning_rate_Methylation-R': 0.0014280638871732717,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6253104075907711,
 'loss_weight_Methylation-R': 0.8760872803598676,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3030858683,
 'sample_weights': [0.8322872013881129, 0.24465566444962117],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.869389696536067,
 'weight_decay_Methylation-K': 8.389232618243861,
 'weight_decay_Methylation-R': 2.7315559819365576}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.383
[4,     7] loss: 1.374
[5,     7] loss: 1.342
[6,     7] loss: 1.327
[7,     7] loss: 1.316
[8,     7] loss: 1.308
[9,     7] loss: 1.301
[10,     7] loss: 1.277
[11,     7] loss: 1.277
[12,     7] loss: 1.261
[13,     7] loss: 1.266
[14,     7] loss: 1.264
[15,     7] loss: 1.254
[16,     7] loss: 1.242
[17,     7] loss: 1.254
[18,     7] loss: 1.243
[19,     7] loss: 1.248
[20,     7] loss: 1.217
[21,     7] loss: 1.221
[22,     7] loss: 1.218
[23,     7] loss: 1.216
[24,     7] loss: 1.206
[25,     7] loss: 1.204
[26,     7] loss: 1.179
[27,     7] loss: 1.184
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008009988173619689,
 'learning_rate_Methylation-K': 0.0027492472766074507,
 'learning_rate_Methylation-R': 0.005711826298248231,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.39722366657826313,
 'loss_weight_Methylation-R': 0.8676809512565244,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4282460102,
 'sample_weights': [0.8760872803598676, 0.6253104075907711],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.2572872571404865,
 'weight_decay_Methylation-K': 8.516022984696633,
 'weight_decay_Methylation-R': 7.000620533405392}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.4439200758934021)
Finished Training
Total time taken: 44.35810828208923
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.385
[19,     7] loss: 1.383
[20,     7] loss: 1.372
[21,     7] loss: 1.355
[22,     7] loss: 1.341
[23,     7] loss: 1.344
[24,     7] loss: 1.333
[25,     7] loss: 1.326
[26,     7] loss: 1.323
[27,     7] loss: 1.316
[28,     7] loss: 1.315
[29,     7] loss: 1.311
[30,     7] loss: 1.313
[31,     7] loss: 1.310
[32,     7] loss: 1.314
[33,     7] loss: 1.308
[34,     7] loss: 1.304
[35,     7] loss: 1.301
[36,     7] loss: 1.301
[37,     7] loss: 1.300
[38,     7] loss: 1.292
[39,     7] loss: 1.294
[40,     7] loss: 1.289
[41,     7] loss: 1.290
[42,     7] loss: 1.300
[43,     7] loss: 1.305
[44,     7] loss: 1.293
[45,     7] loss: 1.297
[46,     7] loss: 1.296
[47,     7] loss: 1.288
[48,     7] loss: 1.292
[49,     7] loss: 1.288
[50,     7] loss: 1.296
[51,     7] loss: 1.289
[52,     7] loss: 1.292
[53,     7] loss: 1.285
[54,     7] loss: 1.277
[55,     7] loss: 1.284
[56,     7] loss: 1.279
[57,     7] loss: 1.274
[58,     7] loss: 1.279
[59,     7] loss: 1.277
[60,     7] loss: 1.271
[61,     7] loss: 1.269
[62,     7] loss: 1.266
[63,     7] loss: 1.258
[64,     7] loss: 1.257
[65,     7] loss: 1.263
[66,     7] loss: 1.259
[67,     7] loss: 1.263
[68,     7] loss: 1.259
[69,     7] loss: 1.268
Early stopping applied (best metric=0.44416341185569763)
Finished Training
Total time taken: 60.10614824295044
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.385
[10,     7] loss: 1.383
[11,     7] loss: 1.374
[12,     7] loss: 1.343
[13,     7] loss: 1.336
[14,     7] loss: 1.329
[15,     7] loss: 1.333
[16,     7] loss: 1.332
[17,     7] loss: 1.315
[18,     7] loss: 1.307
[19,     7] loss: 1.323
[20,     7] loss: 1.315
[21,     7] loss: 1.315
[22,     7] loss: 1.311
[23,     7] loss: 1.306
[24,     7] loss: 1.313
[25,     7] loss: 1.304
[26,     7] loss: 1.305
[27,     7] loss: 1.312
[28,     7] loss: 1.304
[29,     7] loss: 1.301
[30,     7] loss: 1.309
[31,     7] loss: 1.313
[32,     7] loss: 1.297
[33,     7] loss: 1.293
[34,     7] loss: 1.301
[35,     7] loss: 1.292
[36,     7] loss: 1.296
[37,     7] loss: 1.290
[38,     7] loss: 1.295
[39,     7] loss: 1.283
[40,     7] loss: 1.303
[41,     7] loss: 1.301
[42,     7] loss: 1.287
[43,     7] loss: 1.285
[44,     7] loss: 1.281
[45,     7] loss: 1.277
[46,     7] loss: 1.276
[47,     7] loss: 1.279
[48,     7] loss: 1.272
[49,     7] loss: 1.278
[50,     7] loss: 1.284
[51,     7] loss: 1.274
Early stopping applied (best metric=0.4403190314769745)
Finished Training
Total time taken: 44.705108404159546
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.387
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.387
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.387
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.4412582814693451)
Finished Training
Total time taken: 44.92610836029053
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.4407588839530945)
Finished Training
Total time taken: 43.91310358047485
{'Methylation-R Validation Accuracy': 0.1094807856745745, 'Methylation-R Validation Sensitivity': 0.9875331564986738, 'Methylation-R Validation Specificity': 0.028269938650306747, 'Methylation-R Validation Precision': 0.08607599141080603, 'Methylation-R AUC ROC': 0.6052423685998386, 'Methylation-R AUC PR': 0.16218582372572035, 'Methylation-R MCC': 0.012888747605702851, 'Methylation-R F1': 0.1583088808776997, 'Validation Loss (Methylation-R)': 0.4235092520713806, 'Methylation-K Validation Accuracy': 0.1488693242751632, 'Methylation-K Validation Sensitivity': 0.9303128371089536, 'Methylation-K Validation Specificity': 0.06412356658085654, 'Methylation-K Validation Precision': 0.0971142236056028, 'Methylation-K AUC ROC': 0.4918326278693764, 'Methylation-K AUC PR': 0.09666647905448955, 'Methylation-K MCC': -0.003534063987744393, 'Methylation-K F1': 0.17551618976040484, 'Validation Loss (Methylation-K)': 0.44208393692970277, 'Validation Loss (total)': 0.8655931949615479, 'TimeToTrain': 47.60171537399292}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00983225005097015,
 'learning_rate_Methylation-K': 0.007943623398194308,
 'learning_rate_Methylation-R': 0.0016985622028419618,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4137829265405297,
 'loss_weight_Methylation-R': 0.5868482450916018,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2429867050,
 'sample_weights': [0.8676809512565244, 0.39722366657826313],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.132159087668669,
 'weight_decay_Methylation-K': 7.9951142366657475,
 'weight_decay_Methylation-R': 7.887992573829865}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.387
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.387
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.387
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.387
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00927620561465854,
 'learning_rate_Methylation-K': 0.006832171606724368,
 'learning_rate_Methylation-R': 0.0007652133037150701,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3839554722024919,
 'loss_weight_Methylation-R': 0.3150130932274079,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 967401818,
 'sample_weights': [0.5868482450916018, 0.4137829265405297],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.489023726181102,
 'weight_decay_Methylation-K': 9.935212191059902,
 'weight_decay_Methylation-R': 8.156564649439677}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006862770116951623,
 'learning_rate_Methylation-K': 0.0010643219625221295,
 'learning_rate_Methylation-R': 0.006425256090949528,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.21942929499466762,
 'loss_weight_Methylation-R': 0.7390470488999994,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1931753394,
 'sample_weights': [0.3150130932274079, 0.3839554722024919],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6282051158296638,
 'weight_decay_Methylation-K': 8.396000126865298,
 'weight_decay_Methylation-R': 5.694623215373094}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006273899268903501,
 'learning_rate_Methylation-K': 0.0025137776390029617,
 'learning_rate_Methylation-R': 0.005018979657412122,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.51960575384126,
 'loss_weight_Methylation-R': 0.17419652765993784,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 206603876,
 'sample_weights': [0.7390470488999994, 0.21942929499466762],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.035315173389361,
 'weight_decay_Methylation-K': 4.002636422600019,
 'weight_decay_Methylation-R': 8.272156642088948}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.384
[3,     7] loss: 1.366
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008897029740748534,
 'learning_rate_Methylation-K': 0.0002786861098942072,
 'learning_rate_Methylation-R': 0.005608084970324788,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.15781674475527177,
 'loss_weight_Methylation-R': 0.6788074141279403,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4243059570,
 'sample_weights': [0.17419652765993784, 0.51960575384126],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.075922177441003,
 'weight_decay_Methylation-K': 8.467336799960362,
 'weight_decay_Methylation-R': 6.671132016977502}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00847712716900955,
 'learning_rate_Methylation-K': 0.008863745292455042,
 'learning_rate_Methylation-R': 0.002307364381532017,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4644197038195835,
 'loss_weight_Methylation-R': 0.7708240822856867,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2998073957,
 'sample_weights': [0.6788074141279403, 0.15781674475527177],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.577252963626279,
 'weight_decay_Methylation-K': 7.846370733555586,
 'weight_decay_Methylation-R': 6.939122047546494}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00759822912912646,
 'learning_rate_Methylation-K': 0.003431547678720594,
 'learning_rate_Methylation-R': 0.0038219946007057373,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5499175017921969,
 'loss_weight_Methylation-R': 0.9908173436138046,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1782395082,
 'sample_weights': [0.7708240822856867, 0.4644197038195835],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.4125005791011721,
 'weight_decay_Methylation-K': 6.704695124019656,
 'weight_decay_Methylation-R': 5.274873105042655}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0002747361755712184,
 'learning_rate_Methylation-K': 0.007589934846098239,
 'learning_rate_Methylation-R': 0.005888925124835776,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7921403560390685,
 'loss_weight_Methylation-R': 0.5181410230215134,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2262789273,
 'sample_weights': [0.9908173436138046, 0.5499175017921969],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.601691982388923,
 'weight_decay_Methylation-K': 4.6167876828389405,
 'weight_decay_Methylation-R': 9.753631613182062}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.384
[4,     7] loss: 1.379
[5,     7] loss: 1.370
[6,     7] loss: 1.359
[7,     7] loss: 1.342
[8,     7] loss: 1.331
[9,     7] loss: 1.321
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003982697074103599,
 'learning_rate_Methylation-K': 0.0013877490716721983,
 'learning_rate_Methylation-R': 0.009880915117862503,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.17846082026829008,
 'loss_weight_Methylation-R': 0.7181753127591368,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2026201707,
 'sample_weights': [0.5181410230215134, 0.7921403560390685],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2688979155668965,
 'weight_decay_Methylation-K': 3.6012195941058023,
 'weight_decay_Methylation-R': 6.552706262555244}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.385
[3,     7] loss: 1.376
[4,     7] loss: 1.348
[5,     7] loss: 1.339
[6,     7] loss: 1.327
[7,     7] loss: 1.323
[8,     7] loss: 1.303
[9,     7] loss: 1.291
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009172553586534415,
 'learning_rate_Methylation-K': 0.0031729848621356756,
 'learning_rate_Methylation-R': 0.009998823432608373,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.011189913682539505,
 'loss_weight_Methylation-R': 0.28132359250566297,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1964357000,
 'sample_weights': [0.7181753127591368, 0.17846082026829008],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.0789393905963935,
 'weight_decay_Methylation-K': 8.748257542652393,
 'weight_decay_Methylation-R': 5.851950975088469}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.385
[7,     7] loss: 1.370
[8,     7] loss: 1.340
[9,     7] loss: 1.338
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009179133996949656,
 'learning_rate_Methylation-K': 0.004602024902565111,
 'learning_rate_Methylation-R': 0.0048509976574985,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.17501099305132428,
 'loss_weight_Methylation-R': 0.5317518597729397,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2045598889,
 'sample_weights': [0.28132359250566297, 0.011189913682539505],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.783927507821724,
 'weight_decay_Methylation-K': 6.166954038179107,
 'weight_decay_Methylation-R': 2.713184039693428}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.388
[10,     7] loss: 1.384
[11,     7] loss: 1.378
[12,     7] loss: 1.374
[13,     7] loss: 1.334
[14,     7] loss: 1.365
[15,     7] loss: 1.353
[16,     7] loss: 1.366
[17,     7] loss: 1.351
[18,     7] loss: 1.322
[19,     7] loss: 1.351
[20,     7] loss: 1.321
[21,     7] loss: 1.390
[22,     7] loss: 1.386
[23,     7] loss: 1.385
[24,     7] loss: 1.381
[25,     7] loss: 1.365
[26,     7] loss: 1.346
[27,     7] loss: 1.339
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00841209233754763,
 'learning_rate_Methylation-K': 0.001742164854677604,
 'learning_rate_Methylation-R': 0.008131104689464149,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.059069600611691246,
 'loss_weight_Methylation-R': 0.5136329609637696,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1313881550,
 'sample_weights': [0.5317518597729397, 0.17501099305132428],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.403651616698236,
 'weight_decay_Methylation-K': 8.786500978614288,
 'weight_decay_Methylation-R': 6.896415506004316}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009426052221146857,
 'learning_rate_Methylation-K': 0.002549455336253335,
 'learning_rate_Methylation-R': 0.008395156290624133,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.455006749290233,
 'loss_weight_Methylation-R': 0.7104677193107808,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 20989835,
 'sample_weights': [0.5136329609637696, 0.059069600611691246],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.20043597224360415,
 'weight_decay_Methylation-K': 7.110633852139431,
 'weight_decay_Methylation-R': 7.142669177059969}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006799822660218738,
 'learning_rate_Methylation-K': 0.007719842148095362,
 'learning_rate_Methylation-R': 0.00817629387010111,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6501128248917302,
 'loss_weight_Methylation-R': 0.8859533805711235,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2840281230,
 'sample_weights': [0.7104677193107808, 0.455006749290233],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.526159350274511,
 'weight_decay_Methylation-K': 9.188941264610802,
 'weight_decay_Methylation-R': 3.6907881408253727}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.381
[3,     7] loss: 1.366
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009612364516103889,
 'learning_rate_Methylation-K': 0.0004388585032688737,
 'learning_rate_Methylation-R': 0.006226645212467302,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.09035761192811667,
 'loss_weight_Methylation-R': 0.7643337385199473,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1238907625,
 'sample_weights': [0.8859533805711235, 0.6501128248917302],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.925424949795191,
 'weight_decay_Methylation-K': 2.1397949368653553,
 'weight_decay_Methylation-R': 6.854915836082732}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009215676523654057,
 'learning_rate_Methylation-K': 0.0015792384920392346,
 'learning_rate_Methylation-R': 0.009439291997080372,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.40585955027676546,
 'loss_weight_Methylation-R': 0.21722085312638573,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 999512171,
 'sample_weights': [0.7643337385199473, 0.09035761192811667],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.33529928702282863,
 'weight_decay_Methylation-K': 0.45416511159917583,
 'weight_decay_Methylation-R': 8.229287507484358}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006087035554132746,
 'learning_rate_Methylation-K': 0.004068420339203944,
 'learning_rate_Methylation-R': 0.008227776754212221,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4881610080229976,
 'loss_weight_Methylation-R': 0.4871509478119063,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2677125215,
 'sample_weights': [0.21722085312638573, 0.40585955027676546],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.962027461821267,
 'weight_decay_Methylation-K': 5.612805889894995,
 'weight_decay_Methylation-R': 8.466521068185997}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.381
[7,     7] loss: 1.356
[8,     7] loss: 1.321
[9,     7] loss: 1.313
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00808154791780848,
 'learning_rate_Methylation-K': 0.009697884010487979,
 'learning_rate_Methylation-R': 0.003259778650781981,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5401721233959464,
 'loss_weight_Methylation-R': 0.5656375735024868,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 957813855,
 'sample_weights': [0.4871509478119063, 0.4881610080229976],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6568835076737973,
 'weight_decay_Methylation-K': 9.619365869702078,
 'weight_decay_Methylation-R': 9.650237635412168}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009389332911699768,
 'learning_rate_Methylation-K': 0.0018421012727279154,
 'learning_rate_Methylation-R': 0.005625760444943188,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.41279677306027907,
 'loss_weight_Methylation-R': 0.8776685492270959,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 189263062,
 'sample_weights': [0.5656375735024868, 0.5401721233959464],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.337225727732449,
 'weight_decay_Methylation-K': 8.182042490704513,
 'weight_decay_Methylation-R': 7.86925871912627}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00898671443284867,
 'learning_rate_Methylation-K': 0.00770771912816637,
 'learning_rate_Methylation-R': 0.0065110860926046715,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2703635071654529,
 'loss_weight_Methylation-R': 0.6484386870452252,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1755823781,
 'sample_weights': [0.8776685492270959, 0.41279677306027907],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.827419289654333,
 'weight_decay_Methylation-K': 8.563276645801364,
 'weight_decay_Methylation-R': 9.844391628390337}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.398
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006103294821068046,
 'learning_rate_Methylation-K': 0.001440546204287373,
 'learning_rate_Methylation-R': 0.0070701195673039795,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.42350820284522744,
 'loss_weight_Methylation-R': 0.8752369841551011,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4190261530,
 'sample_weights': [0.6484386870452252, 0.2703635071654529],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.0118599367755623,
 'weight_decay_Methylation-K': 6.025699358219514,
 'weight_decay_Methylation-R': 6.374049488864568}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008727518590916227,
 'learning_rate_Methylation-K': 0.00022615848364543106,
 'learning_rate_Methylation-R': 0.009493997172464323,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.24921656414024632,
 'loss_weight_Methylation-R': 0.7879720659674492,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2757747488,
 'sample_weights': [0.8752369841551011, 0.42350820284522744],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.0321265895790517,
 'weight_decay_Methylation-K': 7.305435566577246,
 'weight_decay_Methylation-R': 7.964768731400762}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.385
[13,     7] loss: 1.373
[14,     7] loss: 1.356
[15,     7] loss: 1.337
[16,     7] loss: 1.337
[17,     7] loss: 1.322
[18,     7] loss: 1.314
[19,     7] loss: 1.301
[20,     7] loss: 1.289
[21,     7] loss: 1.283
[22,     7] loss: 1.283
[23,     7] loss: 1.268
[24,     7] loss: 1.270
[25,     7] loss: 1.256
[26,     7] loss: 1.257
[27,     7] loss: 1.244
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009693973379331821,
 'learning_rate_Methylation-K': 0.00037382015638592723,
 'learning_rate_Methylation-R': 0.005306424553872304,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3393714333232502,
 'loss_weight_Methylation-R': 0.8528668821157496,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 392059231,
 'sample_weights': [0.7879720659674492, 0.24921656414024632],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.4354999066314362,
 'weight_decay_Methylation-K': 9.636379138244422,
 'weight_decay_Methylation-R': 6.6886788829242345}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006650787953364799,
 'learning_rate_Methylation-K': 0.0027131086112699896,
 'learning_rate_Methylation-R': 0.005328180283911661,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.23705235980687836,
 'loss_weight_Methylation-R': 0.9450792807007833,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3735224503,
 'sample_weights': [0.8528668821157496, 0.3393714333232502],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.045609728031763,
 'weight_decay_Methylation-K': 9.644287551612969,
 'weight_decay_Methylation-R': 8.722744601330584}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.381
[15,     7] loss: 1.356
[16,     7] loss: 1.339
[17,     7] loss: 1.324
[18,     7] loss: 1.316
[19,     7] loss: 1.298
[20,     7] loss: 1.292
[21,     7] loss: 1.305
[22,     7] loss: 1.291
[23,     7] loss: 1.270
[24,     7] loss: 1.255
[25,     7] loss: 1.262
[26,     7] loss: 1.266
[27,     7] loss: 1.258
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007260535601150086,
 'learning_rate_Methylation-K': 0.0014738685681101814,
 'learning_rate_Methylation-R': 0.009540340857430786,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6335038805551656,
 'loss_weight_Methylation-R': 0.9898332912373276,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4007951585,
 'sample_weights': [0.9450792807007833, 0.23705235980687836],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.67574548789479,
 'weight_decay_Methylation-K': 6.9524614459703376,
 'weight_decay_Methylation-R': 4.843493670642836}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.385
[5,     7] loss: 1.370
[6,     7] loss: 1.354
[7,     7] loss: 1.324
[8,     7] loss: 1.307
[9,     7] loss: 1.310
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007833304540774392,
 'learning_rate_Methylation-K': 0.0008531589463934715,
 'learning_rate_Methylation-R': 0.003727213097871656,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.23375400088769724,
 'loss_weight_Methylation-R': 0.9993578202968945,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2396664334,
 'sample_weights': [0.9898332912373276, 0.6335038805551656],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.0738386477831647,
 'weight_decay_Methylation-K': 6.147216251430793,
 'weight_decay_Methylation-R': 8.753893577269222}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.385
[5,     7] loss: 1.382
[6,     7] loss: 1.363
[7,     7] loss: 1.335
[8,     7] loss: 1.327
[9,     7] loss: 1.304
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009515857869131039,
 'learning_rate_Methylation-K': 0.0005258748552602793,
 'learning_rate_Methylation-R': 0.008889067519305984,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2345753223412268,
 'loss_weight_Methylation-R': 0.9667464664230443,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 72285434,
 'sample_weights': [0.9993578202968945, 0.23375400088769724],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.1637585717715275,
 'weight_decay_Methylation-K': 7.7060536934420965,
 'weight_decay_Methylation-R': 7.174072126079331}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005517469156595,
 'learning_rate_Methylation-K': 0.005296995980435613,
 'learning_rate_Methylation-R': 0.005943991894136382,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.10034034774097472,
 'loss_weight_Methylation-R': 0.7434873576309854,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2094322124,
 'sample_weights': [0.9667464664230443, 0.2345753223412268],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6467535516873646,
 'weight_decay_Methylation-K': 2.0750269836740904,
 'weight_decay_Methylation-R': 9.760109524367497}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.371
[6,     7] loss: 1.343
[7,     7] loss: 1.341
[8,     7] loss: 1.324
[9,     7] loss: 1.310
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008312609695757034,
 'learning_rate_Methylation-K': 0.004242181685968854,
 'learning_rate_Methylation-R': 0.007281156566589078,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.443357878607995,
 'loss_weight_Methylation-R': 0.8256458986949948,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2339477546,
 'sample_weights': [0.7434873576309854, 0.10034034774097472],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.85228157001681,
 'weight_decay_Methylation-K': 0.4552816916843092,
 'weight_decay_Methylation-R': 5.3120679586819755}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.377
[7,     7] loss: 1.356
[8,     7] loss: 1.333
[9,     7] loss: 1.308
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009194435654292208,
 'learning_rate_Methylation-K': 0.0008995568911559839,
 'learning_rate_Methylation-R': 0.006546823586787416,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.19208866024329407,
 'loss_weight_Methylation-R': 0.5977328450768837,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1378738117,
 'sample_weights': [0.8256458986949948, 0.443357878607995],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.799286462325796,
 'weight_decay_Methylation-K': 6.199247757777021,
 'weight_decay_Methylation-R': 4.581805261154816}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.369
[5,     7] loss: 1.343
[6,     7] loss: 1.314
[7,     7] loss: 1.365
[8,     7] loss: 1.324
[9,     7] loss: 1.319
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006122327922486339,
 'learning_rate_Methylation-K': 0.0012233780327452087,
 'learning_rate_Methylation-R': 0.008720391534373921,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.18839349378756642,
 'loss_weight_Methylation-R': 0.8286587542675916,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4255085014,
 'sample_weights': [0.5977328450768837, 0.19208866024329407],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.5461080617877445,
 'weight_decay_Methylation-K': 5.515326794327572,
 'weight_decay_Methylation-R': 5.789845485351082}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.381
[5,     7] loss: 1.349
[6,     7] loss: 1.330
[7,     7] loss: 1.318
[8,     7] loss: 1.306
[9,     7] loss: 1.290
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009925612109131893,
 'learning_rate_Methylation-K': 0.0002820391700761051,
 'learning_rate_Methylation-R': 0.009346899131955248,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1481893356456074,
 'loss_weight_Methylation-R': 0.45982528387218213,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1415431124,
 'sample_weights': [0.8286587542675916, 0.18839349378756642],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.328811744810903,
 'weight_decay_Methylation-K': 8.678418806329358,
 'weight_decay_Methylation-R': 9.808773701232173}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00623740533130922,
 'learning_rate_Methylation-K': 0.005664405052026752,
 'learning_rate_Methylation-R': 0.003974016064630559,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.20258449352296654,
 'loss_weight_Methylation-R': 0.7693022352798863,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2498813119,
 'sample_weights': [0.45982528387218213, 0.1481893356456074],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7763770632204012,
 'weight_decay_Methylation-K': 7.2332997540766275,
 'weight_decay_Methylation-R': 6.862736782224337}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.384
[8,     7] loss: 1.365
[9,     7] loss: 1.340
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006560637478936064,
 'learning_rate_Methylation-K': 0.007196882040254056,
 'learning_rate_Methylation-R': 0.00013324269292931245,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8182952307323881,
 'loss_weight_Methylation-R': 0.5386742690415259,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 78055301,
 'sample_weights': [0.7693022352798863, 0.20258449352296654],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.847398881968376,
 'weight_decay_Methylation-K': 3.353502313811668,
 'weight_decay_Methylation-R': 7.535164442329548}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.385
[7,     7] loss: 1.370
[8,     7] loss: 1.341
[9,     7] loss: 1.325
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00967992829498051,
 'learning_rate_Methylation-K': 0.006510598577776685,
 'learning_rate_Methylation-R': 0.005292448955595629,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.09327471033220613,
 'loss_weight_Methylation-R': 0.9714523290702654,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3947448794,
 'sample_weights': [0.5386742690415259, 0.8182952307323881],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.728519223912641,
 'weight_decay_Methylation-K': 1.5077733723747944,
 'weight_decay_Methylation-R': 4.775736902156745}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.376
[7,     7] loss: 1.347
[8,     7] loss: 1.332
[9,     7] loss: 1.305
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008270824779823688,
 'learning_rate_Methylation-K': 0.005655485473800826,
 'learning_rate_Methylation-R': 0.00705036234958397,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.26839934068842786,
 'loss_weight_Methylation-R': 0.7143889707165807,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 964995929,
 'sample_weights': [0.9714523290702654, 0.09327471033220613],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.9112359518787922,
 'weight_decay_Methylation-K': 1.5801993602780189,
 'weight_decay_Methylation-R': 8.985147160335162}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005041716845714395,
 'learning_rate_Methylation-K': 0.000886430635658697,
 'learning_rate_Methylation-R': 0.0025630703913433733,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.31892087196841523,
 'loss_weight_Methylation-R': 0.6978879115111447,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 65746726,
 'sample_weights': [0.7143889707165807, 0.26839934068842786],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.655752827267805,
 'weight_decay_Methylation-K': 3.2067830082235975,
 'weight_decay_Methylation-R': 6.455393790825099}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.384
[11,     7] loss: 1.375
[12,     7] loss: 1.345
[13,     7] loss: 1.331
[14,     7] loss: 1.310
[15,     7] loss: 1.273
[16,     7] loss: 1.264
[17,     7] loss: 1.246
[18,     7] loss: 1.229
[19,     7] loss: 1.219
[20,     7] loss: 1.192
[21,     7] loss: 1.189
[22,     7] loss: 1.215
[23,     7] loss: 1.203
[24,     7] loss: 1.178
[25,     7] loss: 1.168
[26,     7] loss: 1.155
[27,     7] loss: 1.159
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0040356138943650225,
 'learning_rate_Methylation-K': 0.0005589476921683259,
 'learning_rate_Methylation-R': 0.0014928197902862373,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5934164504795599,
 'loss_weight_Methylation-R': 0.6763358435480725,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 975812690,
 'sample_weights': [0.6978879115111447, 0.31892087196841523],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.176071179966591,
 'weight_decay_Methylation-K': 6.614293683253043,
 'weight_decay_Methylation-R': 8.196197749792043}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.369
[3,     7] loss: 1.344
[4,     7] loss: 1.328
[5,     7] loss: 1.313
[6,     7] loss: 1.297
[7,     7] loss: 1.297
[8,     7] loss: 1.290
[9,     7] loss: 1.282
[10,     7] loss: 1.263
[11,     7] loss: 1.257
[12,     7] loss: 1.246
[13,     7] loss: 1.259
[14,     7] loss: 1.246
[15,     7] loss: 1.245
[16,     7] loss: 1.238
[17,     7] loss: 1.229
[18,     7] loss: 1.227
[19,     7] loss: 1.228
[20,     7] loss: 1.224
[21,     7] loss: 1.231
[22,     7] loss: 1.224
[23,     7] loss: 1.208
[24,     7] loss: 1.218
[25,     7] loss: 1.210
[26,     7] loss: 1.202
[27,     7] loss: 1.211
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009914952177500101,
 'learning_rate_Methylation-K': 0.002302638610840454,
 'learning_rate_Methylation-R': 0.007122409281944474,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.10506223331961842,
 'loss_weight_Methylation-R': 0.8750954929823223,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 943407523,
 'sample_weights': [0.6763358435480725, 0.5934164504795599],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.041248618674969,
 'weight_decay_Methylation-K': 1.9664385121362702,
 'weight_decay_Methylation-R': 6.939214271014312}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006537221005443874,
 'learning_rate_Methylation-K': 0.004700851906604316,
 'learning_rate_Methylation-R': 0.005277511462592433,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.14023275043433603,
 'loss_weight_Methylation-R': 0.7005505186730919,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3519363719,
 'sample_weights': [0.8750954929823223, 0.10506223331961842],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3822000969195227,
 'weight_decay_Methylation-K': 6.169786830462658,
 'weight_decay_Methylation-R': 8.594640820488356}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.385
[9,     7] loss: 1.371
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005218040899618096,
 'learning_rate_Methylation-K': 0.004141593040990155,
 'learning_rate_Methylation-R': 0.005485536667382828,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1750561829076364,
 'loss_weight_Methylation-R': 0.1990034773243518,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2136500079,
 'sample_weights': [0.7005505186730919, 0.14023275043433603],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.71815026447625,
 'weight_decay_Methylation-K': 3.809513949754982,
 'weight_decay_Methylation-R': 9.257943098099048}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.385
[3,     7] loss: 1.371
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00616506187247445,
 'learning_rate_Methylation-K': 0.0032200464941287863,
 'learning_rate_Methylation-R': 0.008092484754173592,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6505658756820601,
 'loss_weight_Methylation-R': 0.9354839309630335,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 388716710,
 'sample_weights': [0.1990034773243518, 0.1750561829076364],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.4491330429747765,
 'weight_decay_Methylation-K': 8.281060563193831,
 'weight_decay_Methylation-R': 4.716303065424231}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00764703110261903,
 'learning_rate_Methylation-K': 0.005585379459810025,
 'learning_rate_Methylation-R': 0.006016665068934571,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3289072085621503,
 'loss_weight_Methylation-R': 0.5105799721830132,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1847107186,
 'sample_weights': [0.9354839309630335, 0.6505658756820601],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.169077175758033,
 'weight_decay_Methylation-K': 4.8531137043813075,
 'weight_decay_Methylation-R': 9.843865704717661}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009941812909651293,
 'learning_rate_Methylation-K': 0.008978942639653825,
 'learning_rate_Methylation-R': 0.006193822327670338,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.291099747267782,
 'loss_weight_Methylation-R': 0.38497570469046927,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2929696017,
 'sample_weights': [0.5105799721830132, 0.3289072085621503],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.011160425329271,
 'weight_decay_Methylation-K': 9.34265787893769,
 'weight_decay_Methylation-R': 9.689361450071296}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006516710429711554,
 'learning_rate_Methylation-K': 0.004694763668460479,
 'learning_rate_Methylation-R': 0.005101138405098599,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4065718432747308,
 'loss_weight_Methylation-R': 0.43798465792116537,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1764314066,
 'sample_weights': [0.38497570469046927, 0.291099747267782],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.397975801538236,
 'weight_decay_Methylation-K': 2.6170454921393076,
 'weight_decay_Methylation-R': 8.48030193837348}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030195874415665834,
 'learning_rate_Methylation-K': 0.004240878521872618,
 'learning_rate_Methylation-R': 0.0017939603492515988,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6250146123001618,
 'loss_weight_Methylation-R': 0.5987528862020508,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2299048602,
 'sample_weights': [0.43798465792116537, 0.4065718432747308],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.326781274673293,
 'weight_decay_Methylation-K': 6.990066118801389,
 'weight_decay_Methylation-R': 4.881385835237908}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.383
[3,     7] loss: 1.356
[4,     7] loss: 1.330
[5,     7] loss: 1.315
[6,     7] loss: 1.307
[7,     7] loss: 1.302
[8,     7] loss: 1.281
[9,     7] loss: 1.276
[10,     7] loss: 1.283
[11,     7] loss: 1.255
[12,     7] loss: 1.252
[13,     7] loss: 1.241
[14,     7] loss: 1.253
[15,     7] loss: 1.236
[16,     7] loss: 1.221
[17,     7] loss: 1.194
[18,     7] loss: 1.183
[19,     7] loss: 1.196
[20,     7] loss: 1.167
[21,     7] loss: 1.156
[22,     7] loss: 1.163
[23,     7] loss: 1.149
[24,     7] loss: 1.129
[25,     7] loss: 1.122
[26,     7] loss: 1.118
[27,     7] loss: 1.103
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009213299132763128,
 'learning_rate_Methylation-K': 0.007118270558521416,
 'learning_rate_Methylation-R': 0.007339209424480968,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6687208374811194,
 'loss_weight_Methylation-R': 0.1882776507873441,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2538124276,
 'sample_weights': [0.5987528862020508, 0.6250146123001618],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6056988585578362,
 'weight_decay_Methylation-K': 9.453320452850566,
 'weight_decay_Methylation-R': 8.549653854728058}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004262738829666643,
 'learning_rate_Methylation-K': 0.00332240273421507,
 'learning_rate_Methylation-R': 0.0031905273035696315,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5684966397747439,
 'loss_weight_Methylation-R': 0.6082634135314134,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1917849221,
 'sample_weights': [0.1882776507873441, 0.6687208374811194],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7638486299906737,
 'weight_decay_Methylation-K': 8.541779420246465,
 'weight_decay_Methylation-R': 0.5804823109403427}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.383
[4,     7] loss: 1.362
[5,     7] loss: 1.336
[6,     7] loss: 1.312
[7,     7] loss: 1.308
[8,     7] loss: 1.302
[9,     7] loss: 1.291
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008759660908143512,
 'learning_rate_Methylation-K': 0.007394590007210529,
 'learning_rate_Methylation-R': 0.005291544731279249,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.35014107802232297,
 'loss_weight_Methylation-R': 0.31699783448376706,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 345413898,
 'sample_weights': [0.6082634135314134, 0.5684966397747439],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.88123978983623,
 'weight_decay_Methylation-K': 4.209540430802852,
 'weight_decay_Methylation-R': 9.88669985284398}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003965988657359716,
 'learning_rate_Methylation-K': 0.0001501707874927335,
 'learning_rate_Methylation-R': 0.0024377173403581096,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1609798131288851,
 'loss_weight_Methylation-R': 0.7822242518765881,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4127230427,
 'sample_weights': [0.31699783448376706, 0.35014107802232297],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.500475441039749,
 'weight_decay_Methylation-K': 2.720967125746022,
 'weight_decay_Methylation-R': 9.362986258991786}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.385
[3,     7] loss: 1.381
[4,     7] loss: 1.354
[5,     7] loss: 1.332
[6,     7] loss: 1.323
[7,     7] loss: 1.315
[8,     7] loss: 1.301
[9,     7] loss: 1.271
[10,     7] loss: 1.305
[11,     7] loss: 1.278
[12,     7] loss: 1.256
[13,     7] loss: 1.259
[14,     7] loss: 1.266
[15,     7] loss: 1.262
[16,     7] loss: 1.226
[17,     7] loss: 1.241
[18,     7] loss: 1.240
[19,     7] loss: 1.239
[20,     7] loss: 1.235
[21,     7] loss: 1.263
[22,     7] loss: 1.239
[23,     7] loss: 1.218
[24,     7] loss: 1.230
[25,     7] loss: 1.238
[26,     7] loss: 1.226
[27,     7] loss: 1.237
[28,     7] loss: 1.228
[29,     7] loss: 1.209
[30,     7] loss: 1.203
[31,     7] loss: 1.211
[32,     7] loss: 1.203
[33,     7] loss: 1.222
[34,     7] loss: 1.219
[35,     7] loss: 1.195
[36,     7] loss: 1.221
[37,     7] loss: 1.239
[38,     7] loss: 1.219
[39,     7] loss: 1.186
[40,     7] loss: 1.198
[41,     7] loss: 1.230
[42,     7] loss: 1.218
[43,     7] loss: 1.268
[44,     7] loss: 1.251
[45,     7] loss: 1.223
[46,     7] loss: 1.186
[47,     7] loss: 1.216
[48,     7] loss: 1.200
[49,     7] loss: 1.192
[50,     7] loss: 1.238
[51,     7] loss: 1.204
[52,     7] loss: 1.175
[53,     7] loss: 1.187
[54,     7] loss: 1.255
[55,     7] loss: 1.281
[56,     7] loss: 1.218
[57,     7] loss: 1.196
[58,     7] loss: 1.169
[59,     7] loss: 1.203
[60,     7] loss: 1.246
[61,     7] loss: 1.258
[62,     7] loss: 1.208
[63,     7] loss: 1.201
[64,     7] loss: 1.180
[65,     7] loss: 1.203
[66,     7] loss: 1.195
[67,     7] loss: 1.174
[68,     7] loss: 1.184
[69,     7] loss: 1.186
[70,     7] loss: 1.200
[71,     7] loss: 1.207
[72,     7] loss: 1.214
[73,     7] loss: 1.188
[74,     7] loss: 1.147
[75,     7] loss: 1.158
[76,     7] loss: 1.189
[77,     7] loss: 1.184
[78,     7] loss: 1.189
[79,     7] loss: 1.159
[80,     7] loss: 1.232
[81,     7] loss: 1.199
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0056948581363279165,
 'learning_rate_Methylation-K': 0.005761887464369795,
 'learning_rate_Methylation-R': 0.005587953225777318,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3650273289864385,
 'loss_weight_Methylation-R': 0.38637585886439646,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3233817713,
 'sample_weights': [0.7822242518765881, 0.1609798131288851],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.846543569573816,
 'weight_decay_Methylation-K': 7.308126790205578,
 'weight_decay_Methylation-R': 8.578441911953815}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.385
[3,     7] loss: 1.375
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009628346222124098,
 'learning_rate_Methylation-K': 0.008431981195811072,
 'learning_rate_Methylation-R': 0.0016484646329715494,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4724824951800826,
 'loss_weight_Methylation-R': 0.5643526564202128,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1741579362,
 'sample_weights': [0.38637585886439646, 0.3650273289864385],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7359795895495047,
 'weight_decay_Methylation-K': 9.258585656268691,
 'weight_decay_Methylation-R': 6.780002396887971}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00816550816472584,
 'learning_rate_Methylation-K': 0.007627516161041476,
 'learning_rate_Methylation-R': 0.006406864474433595,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.22656433685727068,
 'loss_weight_Methylation-R': 0.614778385533896,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2799101783,
 'sample_weights': [0.5643526564202128, 0.4724824951800826],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.328654442737913,
 'weight_decay_Methylation-K': 5.169991686976221,
 'weight_decay_Methylation-R': 9.239765094155398}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008007002744842635,
 'learning_rate_Methylation-K': 0.003520502167415457,
 'learning_rate_Methylation-R': 0.007558058779370557,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.032875203232469855,
 'loss_weight_Methylation-R': 0.781173349385457,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 810825634,
 'sample_weights': [0.614778385533896, 0.22656433685727068],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.575913148059793,
 'weight_decay_Methylation-K': 3.7117412044321436,
 'weight_decay_Methylation-R': 7.285459869900143}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008816146729280116,
 'learning_rate_Methylation-K': 0.001011470354526943,
 'learning_rate_Methylation-R': 0.006597482168099947,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2243699599761641,
 'loss_weight_Methylation-R': 0.4574133463968358,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 679894869,
 'sample_weights': [0.781173349385457, 0.032875203232469855],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.041912314052922,
 'weight_decay_Methylation-K': 5.845161380872993,
 'weight_decay_Methylation-R': 8.99352365981033}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.387
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009880085938920655,
 'learning_rate_Methylation-K': 0.0024427969193902875,
 'learning_rate_Methylation-R': 0.005136251058643582,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4878589927241691,
 'loss_weight_Methylation-R': 0.6118468141760319,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1372578703,
 'sample_weights': [0.4574133463968358, 0.2243699599761641],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.18791512766046958,
 'weight_decay_Methylation-K': 9.91579196388151,
 'weight_decay_Methylation-R': 4.9485069955116225}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008884805655724151,
 'learning_rate_Methylation-K': 0.007517668743086803,
 'learning_rate_Methylation-R': 0.009933948173937291,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7441330327697102,
 'loss_weight_Methylation-R': 0.8573895170212112,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1066751098,
 'sample_weights': [0.6118468141760319, 0.4878589927241691],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.8050688351600686,
 'weight_decay_Methylation-K': 6.846152575322714,
 'weight_decay_Methylation-R': 8.139195349817308}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009665209978589348,
 'learning_rate_Methylation-K': 0.0032766355845916095,
 'learning_rate_Methylation-R': 0.006907896298468507,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.045836530336506864,
 'loss_weight_Methylation-R': 0.9904074086079225,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2800568235,
 'sample_weights': [0.8573895170212112, 0.7441330327697102],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.976552921112089,
 'weight_decay_Methylation-K': 2.0337347464755653,
 'weight_decay_Methylation-R': 5.4390883283683955}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008294775875866373,
 'learning_rate_Methylation-K': 0.008155582864508518,
 'learning_rate_Methylation-R': 0.005588213710548181,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4030821581381194,
 'loss_weight_Methylation-R': 0.7745158510211944,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3244185525,
 'sample_weights': [0.9904074086079225, 0.045836530336506864],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.817042807413028,
 'weight_decay_Methylation-K': 8.739079323586886,
 'weight_decay_Methylation-R': 0.06266732070942505}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.378
[7,     7] loss: 1.341
[8,     7] loss: 1.338
[9,     7] loss: 1.352
[10,     7] loss: 1.310
[11,     7] loss: 1.308
[12,     7] loss: 1.310
[13,     7] loss: 1.317
[14,     7] loss: 1.324
[15,     7] loss: 1.318
[16,     7] loss: 1.304
[17,     7] loss: 1.297
[18,     7] loss: 1.288
[19,     7] loss: 1.304
[20,     7] loss: 1.355
[21,     7] loss: 1.383
[22,     7] loss: 1.359
[23,     7] loss: 1.353
[24,     7] loss: 1.391
[25,     7] loss: 1.388
[26,     7] loss: 1.388
[27,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00730902460671693,
 'learning_rate_Methylation-K': 0.005823387205545878,
 'learning_rate_Methylation-R': 0.0009109601871480415,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.46162924679265316,
 'loss_weight_Methylation-R': 0.5154716426254521,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1394566576,
 'sample_weights': [0.7745158510211944, 0.4030821581381194],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.594731641916553,
 'weight_decay_Methylation-K': 6.4896637495911405,
 'weight_decay_Methylation-R': 6.583735717687598}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.387
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.4401208758354187)
Finished Training
Total time taken: 45.15620827674866
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
Early stopping applied (best metric=0.44379931688308716)
Finished Training
Total time taken: 46.61327886581421
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.358
[6,     7] loss: 1.344
[7,     7] loss: 1.333
[8,     7] loss: 1.300
[9,     7] loss: 1.291
[10,     7] loss: 1.310
[11,     7] loss: 1.326
[12,     7] loss: 1.291
[13,     7] loss: 1.261
[14,     7] loss: 1.306
[15,     7] loss: 1.278
[16,     7] loss: 1.257
[17,     7] loss: 1.249
[18,     7] loss: 1.255
[19,     7] loss: 1.244
[20,     7] loss: 1.352
[21,     7] loss: 1.365
[22,     7] loss: 1.367
[23,     7] loss: 1.380
[24,     7] loss: 1.373
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.387
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
Early stopping applied (best metric=0.42545074224472046)
Finished Training
Total time taken: 62.864073753356934
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.374
[9,     7] loss: 1.341
[10,     7] loss: 1.321
[11,     7] loss: 1.309
[12,     7] loss: 1.307
[13,     7] loss: 1.305
[14,     7] loss: 1.288
[15,     7] loss: 1.283
[16,     7] loss: 1.303
[17,     7] loss: 1.286
[18,     7] loss: 1.260
[19,     7] loss: 1.253
[20,     7] loss: 1.296
[21,     7] loss: 1.277
[22,     7] loss: 1.260
[23,     7] loss: 1.243
[24,     7] loss: 1.251
[25,     7] loss: 1.275
[26,     7] loss: 1.267
[27,     7] loss: 1.243
[28,     7] loss: 1.240
[29,     7] loss: 1.253
[30,     7] loss: 1.292
[31,     7] loss: 1.278
[32,     7] loss: 1.244
[33,     7] loss: 1.249
[34,     7] loss: 1.248
[35,     7] loss: 1.258
[36,     7] loss: 1.225
[37,     7] loss: 1.337
[38,     7] loss: 1.340
[39,     7] loss: 1.299
[40,     7] loss: 1.272
[41,     7] loss: 1.249
[42,     7] loss: 1.242
[43,     7] loss: 1.233
[44,     7] loss: 1.247
[45,     7] loss: 1.242
[46,     7] loss: 1.253
[47,     7] loss: 1.282
[48,     7] loss: 1.313
[49,     7] loss: 1.289
[50,     7] loss: 1.264
[51,     7] loss: 1.256
[52,     7] loss: 1.248
[53,     7] loss: 1.236
[54,     7] loss: 1.264
[55,     7] loss: 1.254
[56,     7] loss: 1.261
[57,     7] loss: 1.253
[58,     7] loss: 1.246
[59,     7] loss: 1.235
[60,     7] loss: 1.230
[61,     7] loss: 1.237
[62,     7] loss: 1.228
[63,     7] loss: 1.234
[64,     7] loss: 1.218
[65,     7] loss: 1.230
[66,     7] loss: 1.269
[67,     7] loss: 1.337
[68,     7] loss: 1.379
[69,     7] loss: 1.365
[70,     7] loss: 1.345
[71,     7] loss: 1.335
[72,     7] loss: 1.319
[73,     7] loss: 1.304
[74,     7] loss: 1.292
[75,     7] loss: 1.283
[76,     7] loss: 1.278
[77,     7] loss: 1.285
[78,     7] loss: 1.281
[79,     7] loss: 1.268
[80,     7] loss: 1.274
[81,     7] loss: 1.271
[82,     7] loss: 1.261
[83,     7] loss: 1.281
[84,     7] loss: 1.276
[85,     7] loss: 1.271
[86,     7] loss: 1.274
[87,     7] loss: 1.274
[88,     7] loss: 1.282
[89,     7] loss: 1.277
[90,     7] loss: 1.278
[91,     7] loss: 1.268
[92,     7] loss: 1.287
[93,     7] loss: 1.269
[94,     7] loss: 1.272
[95,     7] loss: 1.266
[96,     7] loss: 1.255
[97,     7] loss: 1.268
[98,     7] loss: 1.262
[99,     7] loss: 1.254
[100,     7] loss: 1.266
[101,     7] loss: 1.259
[102,     7] loss: 1.255
[103,     7] loss: 1.286
[104,     7] loss: 1.298
[105,     7] loss: 1.332
[106,     7] loss: 1.280
[107,     7] loss: 1.262
[108,     7] loss: 1.279
[109,     7] loss: 1.253
[110,     7] loss: 1.254
[111,     7] loss: 1.241
[112,     7] loss: 1.262
[113,     7] loss: 1.264
[114,     7] loss: 1.253
[115,     7] loss: 1.285
[116,     7] loss: 1.264
[117,     7] loss: 1.267
Early stopping applied (best metric=0.4146884083747864)
Finished Training
Total time taken: 101.6999728679657
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.385
[10,     7] loss: 1.374
[11,     7] loss: 1.357
[12,     7] loss: 1.330
[13,     7] loss: 1.322
[14,     7] loss: 1.322
[15,     7] loss: 1.305
[16,     7] loss: 1.277
[17,     7] loss: 1.299
[18,     7] loss: 1.300
[19,     7] loss: 1.340
[20,     7] loss: 1.356
[21,     7] loss: 1.326
[22,     7] loss: 1.320
[23,     7] loss: 1.290
[24,     7] loss: 1.270
[25,     7] loss: 1.286
[26,     7] loss: 1.296
[27,     7] loss: 1.281
[28,     7] loss: 1.253
[29,     7] loss: 1.260
[30,     7] loss: 1.263
[31,     7] loss: 1.266
[32,     7] loss: 1.261
[33,     7] loss: 1.268
[34,     7] loss: 1.249
[35,     7] loss: 1.246
[36,     7] loss: 1.252
[37,     7] loss: 1.248
[38,     7] loss: 1.274
[39,     7] loss: 1.268
[40,     7] loss: 1.235
[41,     7] loss: 1.241
[42,     7] loss: 1.268
[43,     7] loss: 1.247
[44,     7] loss: 1.260
[45,     7] loss: 1.247
[46,     7] loss: 1.258
[47,     7] loss: 1.302
[48,     7] loss: 1.250
[49,     7] loss: 1.249
[50,     7] loss: 1.280
[51,     7] loss: 1.373
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.386
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
[95,     7] loss: 1.386
[96,     7] loss: 1.386
Early stopping applied (best metric=0.4030196964740753)
Finished Training
Total time taken: 82.37302780151367
{'Methylation-R Validation Accuracy': 0.146032468436142, 'Methylation-R Validation Sensitivity': 0.9893758300132802, 'Methylation-R Validation Specificity': 0.06802453987730062, 'Methylation-R Validation Precision': 0.09075207235364081, 'Methylation-R AUC ROC': 0.6841972759345308, 'Methylation-R AUC PR': 0.2313693904725262, 'Methylation-R MCC': 0.04165363486316409, 'Methylation-R F1': 0.16598815759835503, 'Validation Loss (Methylation-R)': 0.38612688779830934, 'Methylation-K Validation Accuracy': 0.14752734441348808, 'Methylation-K Validation Sensitivity': 0.9714912127418156, 'Methylation-K Validation Specificity': 0.058161882200987954, 'Methylation-K Validation Precision': 0.10115609166838123, 'Methylation-K AUC ROC': 0.5457193858067083, 'Methylation-K AUC PR': 0.11237130727139415, 'Methylation-K MCC': 0.02650116252431287, 'Methylation-K F1': 0.18303245223171244, 'Validation Loss (Methylation-K)': 0.4254158079624176, 'Validation Loss (total)': 0.8115426898002625, 'TimeToTrain': 67.74131231307983}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008032122832168469,
 'learning_rate_Methylation-K': 0.0006220117049723226,
 'learning_rate_Methylation-R': 0.008831646802992045,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1612839874308143,
 'loss_weight_Methylation-R': 0.3359088276993972,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1186054248,
 'sample_weights': [0.5154716426254521, 0.46162924679265316],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.878965847134573,
 'weight_decay_Methylation-K': 6.492334547449132,
 'weight_decay_Methylation-R': 8.691020636846076}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.376
[5,     7] loss: 1.340
[6,     7] loss: 1.331
[7,     7] loss: 1.315
[8,     7] loss: 1.322
[9,     7] loss: 1.319
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008842660246187252,
 'learning_rate_Methylation-K': 0.0006909986173979513,
 'learning_rate_Methylation-R': 0.0087255401712858,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.12335338635331891,
 'loss_weight_Methylation-R': 0.7996456267831886,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1078355204,
 'sample_weights': [0.3359088276993972, 0.1612839874308143],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.547052763726144,
 'weight_decay_Methylation-K': 4.272183575031827,
 'weight_decay_Methylation-R': 6.9659797842851905}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00678116006592501,
 'learning_rate_Methylation-K': 0.0034518440829880035,
 'learning_rate_Methylation-R': 0.008790728316017554,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3437294392726278,
 'loss_weight_Methylation-R': 0.8347579764995597,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3483039463,
 'sample_weights': [0.7996456267831886, 0.12335338635331891],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7827359456829894,
 'weight_decay_Methylation-K': 1.6765033933804396,
 'weight_decay_Methylation-R': 9.521959150227685}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.387
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.387
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.387
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006146706587552906,
 'learning_rate_Methylation-K': 0.006096324944427292,
 'learning_rate_Methylation-R': 0.007391753553264954,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.19485976242105743,
 'loss_weight_Methylation-R': 0.35395247934142715,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4001619573,
 'sample_weights': [0.8347579764995597, 0.3437294392726278],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.199224255699876,
 'weight_decay_Methylation-K': 4.072836333608603,
 'weight_decay_Methylation-R': 9.503854600536425}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008197904519240126,
 'learning_rate_Methylation-K': 0.0042391754076462,
 'learning_rate_Methylation-R': 0.005667387008746074,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.045116713991665655,
 'loss_weight_Methylation-R': 0.9771563886369242,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1307361280,
 'sample_weights': [0.35395247934142715, 0.19485976242105743],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8119805151365833,
 'weight_decay_Methylation-K': 0.9499068685822036,
 'weight_decay_Methylation-R': 8.540225199050827}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.387
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005810848181191255,
 'learning_rate_Methylation-K': 0.0028503685472791194,
 'learning_rate_Methylation-R': 0.005759766291133915,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.08313294358372185,
 'loss_weight_Methylation-R': 0.9301394053179214,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3990141592,
 'sample_weights': [0.9771563886369242, 0.045116713991665655],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.376824736558581,
 'weight_decay_Methylation-K': 4.971249409283413,
 'weight_decay_Methylation-R': 8.28386813585462}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007910189901118294,
 'learning_rate_Methylation-K': 0.0021248856937987177,
 'learning_rate_Methylation-R': 0.004916944852037033,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4836485153498218,
 'loss_weight_Methylation-R': 0.9819414266648568,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2555152865,
 'sample_weights': [0.9301394053179214, 0.08313294358372185],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.771439037713115,
 'weight_decay_Methylation-K': 7.774035464870403,
 'weight_decay_Methylation-R': 9.905328098341906}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009068831790247043,
 'learning_rate_Methylation-K': 0.00030147752065537333,
 'learning_rate_Methylation-R': 0.006871534682123435,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7166764572243466,
 'loss_weight_Methylation-R': 0.556273395886563,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4230281356,
 'sample_weights': [0.9819414266648568, 0.4836485153498218],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.404492691220008,
 'weight_decay_Methylation-K': 7.925396856815071,
 'weight_decay_Methylation-R': 7.4238020805825276}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008923538761159679,
 'learning_rate_Methylation-K': 0.006704379316315073,
 'learning_rate_Methylation-R': 0.001898163737870512,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.18020326441123513,
 'loss_weight_Methylation-R': 0.5052929962329237,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3427828226,
 'sample_weights': [0.556273395886563, 0.7166764572243466],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.7853234361026455,
 'weight_decay_Methylation-K': 5.684970035678639,
 'weight_decay_Methylation-R': 8.523497270420894}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00889764140359333,
 'learning_rate_Methylation-K': 0.0001598050986465144,
 'learning_rate_Methylation-R': 0.005973794412458587,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.03718649292524405,
 'loss_weight_Methylation-R': 0.9311820292272803,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2992847236,
 'sample_weights': [0.5052929962329237, 0.18020326441123513],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.312510100203085,
 'weight_decay_Methylation-K': 5.868444153013337,
 'weight_decay_Methylation-R': 5.316898844797185}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009947161850568636,
 'learning_rate_Methylation-K': 0.0009040133662549447,
 'learning_rate_Methylation-R': 0.008986013265593151,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.28679672371620596,
 'loss_weight_Methylation-R': 0.7345614856636458,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3332695602,
 'sample_weights': [0.9311820292272803, 0.03718649292524405],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.0177294619465616,
 'weight_decay_Methylation-K': 4.055050961896536,
 'weight_decay_Methylation-R': 9.964874710702807}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.387
[17,     7] loss: 1.386
[18,     7] loss: 1.387
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
Early stopping applied (best metric=0.44629019498825073)
Finished Training
Total time taken: 47.29331111907959
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.387
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.387
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.386
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
[95,     7] loss: 1.386
[96,     7] loss: 1.386
[97,     7] loss: 1.386
[98,     7] loss: 1.386
[99,     7] loss: 1.386
[100,     7] loss: 1.386
[101,     7] loss: 1.386
[102,     7] loss: 1.386
[103,     7] loss: 1.386
[104,     7] loss: 1.386
[105,     7] loss: 1.386
[106,     7] loss: 1.386
[107,     7] loss: 1.386
[108,     7] loss: 1.386
[109,     7] loss: 1.386
[110,     7] loss: 1.386
[111,     7] loss: 1.386
[112,     7] loss: 1.386
[113,     7] loss: 1.386
[114,     7] loss: 1.386
[115,     7] loss: 1.386
[116,     7] loss: 1.386
[117,     7] loss: 1.386
[118,     7] loss: 1.386
[119,     7] loss: 1.386
[120,     7] loss: 1.386
[121,     7] loss: 1.386
[122,     7] loss: 1.386
[123,     7] loss: 1.386
[124,     7] loss: 1.386
[125,     7] loss: 1.386
[126,     7] loss: 1.386
[127,     7] loss: 1.386
[128,     7] loss: 1.386
[129,     7] loss: 1.386
[130,     7] loss: 1.386
[131,     7] loss: 1.386
[132,     7] loss: 1.386
[133,     7] loss: 1.386
[134,     7] loss: 1.386
[135,     7] loss: 1.386
[136,     7] loss: 1.386
[137,     7] loss: 1.386
[138,     7] loss: 1.386
[139,     7] loss: 1.386
[140,     7] loss: 1.386
[141,     7] loss: 1.386
[142,     7] loss: 1.386
[143,     7] loss: 1.386
[144,     7] loss: 1.386
[145,     7] loss: 1.387
[146,     7] loss: 1.386
[147,     7] loss: 1.386
[148,     7] loss: 1.386
[149,     7] loss: 1.386
[150,     7] loss: 1.386
[151,     7] loss: 1.387
[152,     7] loss: 1.386
[153,     7] loss: 1.386
[154,     7] loss: 1.386
[155,     7] loss: 1.386
Early stopping applied (best metric=0.4458335041999817)
Finished Training
Total time taken: 134.6105797290802
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.387
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.387
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
Early stopping applied (best metric=0.44552311301231384)
Finished Training
Total time taken: 74.92366337776184
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.387
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.387
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.387
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
Early stopping applied (best metric=0.4458305239677429)
Finished Training
Total time taken: 60.5729603767395
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
Early stopping applied (best metric=0.445523202419281)
Finished Training
Total time taken: 45.84724450111389
{'Methylation-R Validation Accuracy': 0.08466048019389166, 'Methylation-R Validation Sensitivity': 1.0, 'Methylation-R Validation Specificity': 0.0, 'Methylation-R Validation Precision': 0.08466048019389166, 'Methylation-R AUC ROC': 0.508631736969714, 'Methylation-R AUC PR': 0.36439995319765867, 'Methylation-R MCC': 0.0, 'Methylation-R F1': 0.15610503065657413, 'Validation Loss (Methylation-R)': 0.4317693173885345, 'Methylation-K Validation Accuracy': 0.09784008327442427, 'Methylation-K Validation Sensitivity': 1.0, 'Methylation-K Validation Specificity': 0.0, 'Methylation-K Validation Precision': 0.09784008327442427, 'Methylation-K AUC ROC': 0.49576985371351306, 'Methylation-K AUC PR': 0.3679986340060665, 'Methylation-K MCC': 0.0, 'Methylation-K F1': 0.17824104586382167, 'Validation Loss (Methylation-K)': 0.44580010771751405, 'Validation Loss (total)': 0.8775694251060486, 'TimeToTrain': 72.64955182075501}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006693630701882785,
 'learning_rate_Methylation-K': 0.0019083789521438393,
 'learning_rate_Methylation-R': 0.008348407683714094,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6731910432344274,
 'loss_weight_Methylation-R': 0.8883001707939282,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2268739903,
 'sample_weights': [0.7345614856636458, 0.28679672371620596],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.874478786187234,
 'weight_decay_Methylation-K': 8.402711696895059,
 'weight_decay_Methylation-R': 6.611610185850739}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.385
[8,     7] loss: 1.379
[9,     7] loss: 1.361
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006001037158117379,
 'learning_rate_Methylation-K': 0.00391390792366969,
 'learning_rate_Methylation-R': 0.0009371908013821271,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.24983582717829309,
 'loss_weight_Methylation-R': 0.43742433698411254,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2673587406,
 'sample_weights': [0.8883001707939282, 0.6731910432344274],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.7234244422262135,
 'weight_decay_Methylation-K': 6.592084982429418,
 'weight_decay_Methylation-R': 3.2703433878760135}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.381
[3,     7] loss: 1.352
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008069126418370398,
 'learning_rate_Methylation-K': 0.006407836479194779,
 'learning_rate_Methylation-R': 0.0011707998972017174,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4995759959732835,
 'loss_weight_Methylation-R': 0.8098334555764248,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1931882866,
 'sample_weights': [0.43742433698411254, 0.24983582717829309],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6813537371638114,
 'weight_decay_Methylation-K': 4.36497211664684,
 'weight_decay_Methylation-R': 6.006355925560686}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007384759596420513,
 'learning_rate_Methylation-K': 0.0013718015486100482,
 'learning_rate_Methylation-R': 0.009737322357655957,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4140909966906021,
 'loss_weight_Methylation-R': 0.9955683087523641,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1900469549,
 'sample_weights': [0.8098334555764248, 0.4995759959732835],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3883774523090358,
 'weight_decay_Methylation-K': 8.36559653198834,
 'weight_decay_Methylation-R': 7.498292126801522}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0047318740810815794,
 'learning_rate_Methylation-K': 0.0038207861566939977,
 'learning_rate_Methylation-R': 0.002283366296446949,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.060700711355018505,
 'loss_weight_Methylation-R': 0.8017628215712502,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1032113125,
 'sample_weights': [0.9955683087523641, 0.4140909966906021],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.276542139666041,
 'weight_decay_Methylation-K': 4.100463262644663,
 'weight_decay_Methylation-R': 6.063986624761356}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.382
[5,     7] loss: 1.354
[6,     7] loss: 1.329
[7,     7] loss: 1.313
[8,     7] loss: 1.303
[9,     7] loss: 1.306
[10,     7] loss: 1.281
[11,     7] loss: 1.277
[12,     7] loss: 1.287
[13,     7] loss: 1.272
[14,     7] loss: 1.257
[15,     7] loss: 1.251
[16,     7] loss: 1.236
[17,     7] loss: 1.257
[18,     7] loss: 1.251
[19,     7] loss: 1.234
[20,     7] loss: 1.234
[21,     7] loss: 1.239
[22,     7] loss: 1.224
[23,     7] loss: 1.233
[24,     7] loss: 1.231
[25,     7] loss: 1.228
[26,     7] loss: 1.227
[27,     7] loss: 1.273
[28,     7] loss: 1.329
[29,     7] loss: 1.302
[30,     7] loss: 1.291
[31,     7] loss: 1.275
[32,     7] loss: 1.283
[33,     7] loss: 1.252
[34,     7] loss: 1.242
[35,     7] loss: 1.259
[36,     7] loss: 1.238
[37,     7] loss: 1.233
[38,     7] loss: 1.218
[39,     7] loss: 1.231
[40,     7] loss: 1.205
[41,     7] loss: 1.214
[42,     7] loss: 1.281
[43,     7] loss: 1.334
[44,     7] loss: 1.315
[45,     7] loss: 1.269
[46,     7] loss: 1.231
[47,     7] loss: 1.250
[48,     7] loss: 1.218
[49,     7] loss: 1.209
[50,     7] loss: 1.277
[51,     7] loss: 1.259
[52,     7] loss: 1.222
[53,     7] loss: 1.215
[54,     7] loss: 1.197
[55,     7] loss: 1.211
[56,     7] loss: 1.257
[57,     7] loss: 1.211
[58,     7] loss: 1.227
[59,     7] loss: 1.230
[60,     7] loss: 1.203
[61,     7] loss: 1.249
[62,     7] loss: 1.270
[63,     7] loss: 1.280
[64,     7] loss: 1.239
[65,     7] loss: 1.218
[66,     7] loss: 1.205
[67,     7] loss: 1.181
[68,     7] loss: 1.198
[69,     7] loss: 1.204
[70,     7] loss: 1.176
[71,     7] loss: 1.215
[72,     7] loss: 1.182
[73,     7] loss: 1.174
[74,     7] loss: 1.261
[75,     7] loss: 1.253
[76,     7] loss: 1.198
[77,     7] loss: 1.188
[78,     7] loss: 1.181
[79,     7] loss: 1.168
[80,     7] loss: 1.151
[81,     7] loss: 1.176
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008101310780304728,
 'learning_rate_Methylation-K': 0.002653678208878931,
 'learning_rate_Methylation-R': 0.006341567733958678,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6815388984118936,
 'loss_weight_Methylation-R': 0.5485091592444713,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 790698452,
 'sample_weights': [0.8017628215712502, 0.060700711355018505],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.688137458270418,
 'weight_decay_Methylation-K': 6.425384025306595,
 'weight_decay_Methylation-R': 8.93094803551127}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.385
[8,     7] loss: 1.369
[9,     7] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007693155551191195,
 'learning_rate_Methylation-K': 0.0012116916816074178,
 'learning_rate_Methylation-R': 0.0041313385048049045,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.445981514026723,
 'loss_weight_Methylation-R': 0.8028419980041819,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3451386908,
 'sample_weights': [0.5485091592444713, 0.6815388984118936],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.12524078454270995,
 'weight_decay_Methylation-K': 9.903145366581816,
 'weight_decay_Methylation-R': 6.637927057991555}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009995535907558703,
 'learning_rate_Methylation-K': 0.0060309484452758955,
 'learning_rate_Methylation-R': 0.004974416037332974,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4790597260005546,
 'loss_weight_Methylation-R': 0.7003223750580385,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1399649861,
 'sample_weights': [0.8028419980041819, 0.445981514026723],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.498600575460851,
 'weight_decay_Methylation-K': 6.346681306610947,
 'weight_decay_Methylation-R': 6.704090911674222}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0042546324191699144,
 'learning_rate_Methylation-K': 0.0005468751344589677,
 'learning_rate_Methylation-R': 0.004096132304752795,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.27322329441288656,
 'loss_weight_Methylation-R': 0.5803540010923716,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2488540311,
 'sample_weights': [0.7003223750580385, 0.4790597260005546],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.4267113313138635,
 'weight_decay_Methylation-K': 7.649875805699197,
 'weight_decay_Methylation-R': 9.317398409497779}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.385
[3,     7] loss: 1.382
[4,     7] loss: 1.360
[5,     7] loss: 1.334
[6,     7] loss: 1.319
[7,     7] loss: 1.305
[8,     7] loss: 1.294
[9,     7] loss: 1.314
[10,     7] loss: 1.274
[11,     7] loss: 1.277
[12,     7] loss: 1.267
[13,     7] loss: 1.244
[14,     7] loss: 1.264
[15,     7] loss: 1.253
[16,     7] loss: 1.238
[17,     7] loss: 1.236
[18,     7] loss: 1.245
[19,     7] loss: 1.285
[20,     7] loss: 1.256
[21,     7] loss: 1.230
[22,     7] loss: 1.231
[23,     7] loss: 1.225
[24,     7] loss: 1.248
[25,     7] loss: 1.264
[26,     7] loss: 1.240
[27,     7] loss: 1.227
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008564441714203562,
 'learning_rate_Methylation-K': 0.0049603125709103,
 'learning_rate_Methylation-R': 0.003700263373774019,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.37022100247172934,
 'loss_weight_Methylation-R': 0.7184217016385678,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1229769592,
 'sample_weights': [0.5803540010923716, 0.27322329441288656],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.876270741674144,
 'weight_decay_Methylation-K': 7.551830325542026,
 'weight_decay_Methylation-R': 0.8276970277919601}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.385
[5,     7] loss: 1.354
[6,     7] loss: 1.324
[7,     7] loss: 1.309
[8,     7] loss: 1.308
[9,     7] loss: 1.306
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005899443404020887,
 'learning_rate_Methylation-K': 0.0036495603363422215,
 'learning_rate_Methylation-R': 0.0015844029356095546,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.620138892688743,
 'loss_weight_Methylation-R': 0.49491164233637697,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1965853033,
 'sample_weights': [0.7184217016385678, 0.37022100247172934],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2219798173708396,
 'weight_decay_Methylation-K': 6.753108611418982,
 'weight_decay_Methylation-R': 7.495289159029678}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.397
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009729844589561637,
 'learning_rate_Methylation-K': 0.0016613577597332915,
 'learning_rate_Methylation-R': 0.007778119187179217,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.22202093955608296,
 'loss_weight_Methylation-R': 0.9899657357798501,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1995546950,
 'sample_weights': [0.49491164233637697, 0.620138892688743],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.020386242063226,
 'weight_decay_Methylation-K': 5.976375157472556,
 'weight_decay_Methylation-R': 8.047881006476072}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004855221896275407,
 'learning_rate_Methylation-K': 0.0011756165031866377,
 'learning_rate_Methylation-R': 0.005663041709771916,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2572745069797048,
 'loss_weight_Methylation-R': 0.5745752032106717,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 374214447,
 'sample_weights': [0.9899657357798501, 0.22202093955608296],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4895591171108333,
 'weight_decay_Methylation-K': 3.057609684895518,
 'weight_decay_Methylation-R': 9.538778744606468}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.385
[8,     7] loss: 1.382
[9,     7] loss: 1.361
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00908295418654784,
 'learning_rate_Methylation-K': 0.008883527358857581,
 'learning_rate_Methylation-R': 0.007835718402590912,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9146839160897234,
 'loss_weight_Methylation-R': 0.25784793363678493,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1194127692,
 'sample_weights': [0.5745752032106717, 0.2572745069797048],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.0177428249951688,
 'weight_decay_Methylation-K': 5.450949180791897,
 'weight_decay_Methylation-R': 8.927250790337727}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00966367410451722,
 'learning_rate_Methylation-K': 0.0034882701340506065,
 'learning_rate_Methylation-R': 0.0042642998989618555,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5978492239320539,
 'loss_weight_Methylation-R': 0.6372105181186533,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3113434986,
 'sample_weights': [0.25784793363678493, 0.9146839160897234],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.572586424276306,
 'weight_decay_Methylation-K': 9.71297632633396,
 'weight_decay_Methylation-R': 8.286080129238133}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009687547762391635,
 'learning_rate_Methylation-K': 0.008712901256043643,
 'learning_rate_Methylation-R': 0.007801551999184398,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.20172070473245549,
 'loss_weight_Methylation-R': 0.22349761519869232,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3019358104,
 'sample_weights': [0.6372105181186533, 0.5978492239320539],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7232205921974537,
 'weight_decay_Methylation-K': 6.1660570608808625,
 'weight_decay_Methylation-R': 9.731340912123137}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009892814696285822,
 'learning_rate_Methylation-K': 0.002022417776112558,
 'learning_rate_Methylation-R': 0.005570354089123788,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.016915584694186032,
 'loss_weight_Methylation-R': 0.9095438920881839,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3071576954,
 'sample_weights': [0.22349761519869232, 0.20172070473245549],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.729661146794104,
 'weight_decay_Methylation-K': 3.39473019356214,
 'weight_decay_Methylation-R': 6.6302668693706535}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.383
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.387
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.387
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.387
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.387
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.387
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.4389069080352783)
Finished Training
Total time taken: 44.42017197608948
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.385
[12,     7] loss: 1.371
[13,     7] loss: 1.370
[14,     7] loss: 1.363
[15,     7] loss: 1.322
[16,     7] loss: 1.331
[17,     7] loss: 1.351
[18,     7] loss: 1.387
[19,     7] loss: 1.387
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.387
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.387
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
Early stopping applied (best metric=0.4393036961555481)
Finished Training
Total time taken: 54.74467396736145
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.387
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.387
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.387
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.4382449686527252)
Finished Training
Total time taken: 44.942198753356934
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.387
[41,     7] loss: 1.386
[42,     7] loss: 1.387
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.387
Early stopping applied (best metric=0.4431630074977875)
Finished Training
Total time taken: 44.18616008758545
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.387
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.387
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.44313228130340576)
Finished Training
Total time taken: 45.41222047805786
{'Methylation-R Validation Accuracy': 0.13241429870242716, 'Methylation-R Validation Sensitivity': 0.979840848806366, 'Methylation-R Validation Specificity': 0.054036809815950916, 'Methylation-R Validation Precision': 0.08818910724477808, 'Methylation-R AUC ROC': 0.5953457858422185, 'Methylation-R AUC PR': 0.1468339414621661, 'Methylation-R MCC': 0.021615997879599027, 'Methylation-R F1': 0.16162500062123547, 'Validation Loss (Methylation-R)': 0.4166193664073944, 'Methylation-K Validation Accuracy': 0.15750439236341401, 'Methylation-K Validation Sensitivity': 0.9195253505933118, 'Methylation-K Validation Specificity': 0.0748654341212263, 'Methylation-K Validation Precision': 0.09704514834640535, 'Methylation-K AUC ROC': 0.4975079640786782, 'Methylation-K AUC PR': 0.10038529550235771, 'Methylation-K MCC': -0.003438783923566771, 'Methylation-K F1': 0.1750417984211647, 'Validation Loss (Methylation-K)': 0.440550172328949, 'Validation Loss (total)': 0.8571695566177369, 'TimeToTrain': 46.741085052490234}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008952334432132362,
 'learning_rate_Methylation-K': 0.0018865078205064641,
 'learning_rate_Methylation-R': 0.008217843615040984,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.36600146373020126,
 'loss_weight_Methylation-R': 0.8641682692779968,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3894414132,
 'sample_weights': [0.9095438920881839, 0.016915584694186032],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6973728388350449,
 'weight_decay_Methylation-K': 4.269613262195687,
 'weight_decay_Methylation-R': 9.619307105732906}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008952197415280968,
 'learning_rate_Methylation-K': 0.001355706509020625,
 'learning_rate_Methylation-R': 0.006495224672278745,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6746805878242986,
 'loss_weight_Methylation-R': 0.6030242360035181,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3905121446,
 'sample_weights': [0.8641682692779968, 0.36600146373020126],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.126012448844332,
 'weight_decay_Methylation-K': 8.416059014419476,
 'weight_decay_Methylation-R': 9.853607555223789}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0029374400021758163,
 'learning_rate_Methylation-K': 0.007264683878506012,
 'learning_rate_Methylation-R': 0.0030448056806375774,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5372245308337691,
 'loss_weight_Methylation-R': 0.8852442774092132,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 231822864,
 'sample_weights': [0.6030242360035181, 0.6746805878242986],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5774644956176109,
 'weight_decay_Methylation-K': 9.772484986146628,
 'weight_decay_Methylation-R': 2.28572543671079}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.384
[3,     7] loss: 1.373
[4,     7] loss: 1.342
[5,     7] loss: 1.327
[6,     7] loss: 1.315
[7,     7] loss: 1.307
[8,     7] loss: 1.299
[9,     7] loss: 1.285
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009568484675034503,
 'learning_rate_Methylation-K': 0.0053976765292859785,
 'learning_rate_Methylation-R': 0.0007434337784067344,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5042961115335544,
 'loss_weight_Methylation-R': 0.67769289824336,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1279465559,
 'sample_weights': [0.8852442774092132, 0.5372245308337691],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.008402763462329,
 'weight_decay_Methylation-K': 6.319166560076118,
 'weight_decay_Methylation-R': 8.274272942929912}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009990886948906801,
 'learning_rate_Methylation-K': 0.002866615235547056,
 'learning_rate_Methylation-R': 0.0055965737716850185,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.11856090702435457,
 'loss_weight_Methylation-R': 0.7327407646259416,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2610513813,
 'sample_weights': [0.67769289824336, 0.5042961115335544],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.154865043860168,
 'weight_decay_Methylation-K': 1.8820703897887125,
 'weight_decay_Methylation-R': 5.295835097436843}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007036662340580327,
 'learning_rate_Methylation-K': 0.00412013141263872,
 'learning_rate_Methylation-R': 0.00837625883960888,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4998322574309961,
 'loss_weight_Methylation-R': 0.5302768377176165,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3224550522,
 'sample_weights': [0.7327407646259416, 0.11856090702435457],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.6922407205551755,
 'weight_decay_Methylation-K': 4.787335568135085,
 'weight_decay_Methylation-R': 9.883428505256527}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006258861196327401,
 'learning_rate_Methylation-K': 0.003192700445148799,
 'learning_rate_Methylation-R': 0.00679217318296116,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4405022803947871,
 'loss_weight_Methylation-R': 0.6311159491248363,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 642622958,
 'sample_weights': [0.5302768377176165, 0.4998322574309961],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.124068204078255,
 'weight_decay_Methylation-K': 8.491710683732773,
 'weight_decay_Methylation-R': 7.627925675727172}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.378
[6,     7] loss: 1.352
[7,     7] loss: 1.331
[8,     7] loss: 1.309
[9,     7] loss: 1.296
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009549381033248622,
 'learning_rate_Methylation-K': 0.0012769542004220668,
 'learning_rate_Methylation-R': 0.009615005378393727,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.02702653839747099,
 'loss_weight_Methylation-R': 0.6915401082027877,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4077518418,
 'sample_weights': [0.6311159491248363, 0.4405022803947871],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.341346855187894,
 'weight_decay_Methylation-K': 0.4603459328692159,
 'weight_decay_Methylation-R': 7.269064686174873}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.387
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.387
[23,     7] loss: 1.386
[24,     7] loss: 1.387
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009345458057730604,
 'learning_rate_Methylation-K': 0.00012249603353608335,
 'learning_rate_Methylation-R': 0.005541583195983133,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.02248847946181558,
 'loss_weight_Methylation-R': 0.9780952713343743,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1617880671,
 'sample_weights': [0.6915401082027877, 0.02702653839747099],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6454214454003067,
 'weight_decay_Methylation-K': 3.388960543721364,
 'weight_decay_Methylation-R': 6.191371693293429}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007832799141052189,
 'learning_rate_Methylation-K': 0.0008762481319841575,
 'learning_rate_Methylation-R': 0.00806630409237867,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6326902318566608,
 'loss_weight_Methylation-R': 0.7839253314119851,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 377919539,
 'sample_weights': [0.9780952713343743, 0.02248847946181558],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.980760971352353,
 'weight_decay_Methylation-K': 7.099721838933398,
 'weight_decay_Methylation-R': 9.127323205717921}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00953320445039385,
 'learning_rate_Methylation-K': 0.0006613898481501763,
 'learning_rate_Methylation-R': 0.00494214533833984,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.05646618577666039,
 'loss_weight_Methylation-R': 0.7876350377465023,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3668347019,
 'sample_weights': [0.7839253314119851, 0.6326902318566608],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.826157303173311,
 'weight_decay_Methylation-K': 1.4352478353935338,
 'weight_decay_Methylation-R': 8.597526877067926}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003565190751904973,
 'learning_rate_Methylation-K': 0.007676854373239756,
 'learning_rate_Methylation-R': 0.0014757642918557467,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.591340824176725,
 'loss_weight_Methylation-R': 0.792695801434363,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2817127579,
 'sample_weights': [0.7876350377465023, 0.05646618577666039],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8931971052755667,
 'weight_decay_Methylation-K': 7.801309955887468,
 'weight_decay_Methylation-R': 1.3047416086005361}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.380
[3,     7] loss: 1.350
[4,     7] loss: 1.325
[5,     7] loss: 1.306
[6,     7] loss: 1.300
[7,     7] loss: 1.270
[8,     7] loss: 1.271
[9,     7] loss: 1.269
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007849504247725129,
 'learning_rate_Methylation-K': 0.0004601946202671767,
 'learning_rate_Methylation-R': 0.009939647414503476,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.436029010157718,
 'loss_weight_Methylation-R': 0.7691334578409561,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3972371095,
 'sample_weights': [0.792695801434363, 0.591340824176725],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7825285696966043,
 'weight_decay_Methylation-K': 8.391759158569007,
 'weight_decay_Methylation-R': 3.9042529957183265}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.385
[3,     7] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004103747310153904,
 'learning_rate_Methylation-K': 0.0029929461713396432,
 'learning_rate_Methylation-R': 0.003995331606607087,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.693513376615239,
 'loss_weight_Methylation-R': 0.5958962968925499,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2446177716,
 'sample_weights': [0.7691334578409561, 0.436029010157718],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.865394812710123,
 'weight_decay_Methylation-K': 0.07444270596103131,
 'weight_decay_Methylation-R': 1.141134538559077}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.397
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.357
[6,     7] loss: 1.336
[7,     7] loss: 1.322
[8,     7] loss: 1.299
[9,     7] loss: 1.281
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009646422961160151,
 'learning_rate_Methylation-K': 0.000876626195256251,
 'learning_rate_Methylation-R': 0.007397681574054302,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3947905400030072,
 'loss_weight_Methylation-R': 0.5004897884870378,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 342501411,
 'sample_weights': [0.5958962968925499, 0.693513376615239],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.834196109944416,
 'weight_decay_Methylation-K': 3.4127500971140763,
 'weight_decay_Methylation-R': 8.806769192653}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.388
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.387
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.43860092759132385)
Finished Training
Total time taken: 44.31717038154602
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.387
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.387
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.387
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.387
[66,     7] loss: 1.386
[67,     7] loss: 1.387
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.387
[89,     7] loss: 1.386
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
[95,     7] loss: 1.386
[96,     7] loss: 1.386
Early stopping applied (best metric=0.4442218244075775)
Finished Training
Total time taken: 82.9890604019165
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.387
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.376
[18,     7] loss: 1.361
[19,     7] loss: 1.354
[20,     7] loss: 1.346
[21,     7] loss: 1.333
[22,     7] loss: 1.331
[23,     7] loss: 1.323
[24,     7] loss: 1.302
[25,     7] loss: 1.304
[26,     7] loss: 1.286
[27,     7] loss: 1.280
[28,     7] loss: 1.270
[29,     7] loss: 1.263
[30,     7] loss: 1.278
[31,     7] loss: 1.257
[32,     7] loss: 1.264
[33,     7] loss: 1.256
[34,     7] loss: 1.256
[35,     7] loss: 1.244
[36,     7] loss: 1.249
[37,     7] loss: 1.258
[38,     7] loss: 1.239
[39,     7] loss: 1.227
[40,     7] loss: 1.218
[41,     7] loss: 1.224
[42,     7] loss: 1.227
[43,     7] loss: 1.233
[44,     7] loss: 1.207
[45,     7] loss: 1.211
[46,     7] loss: 1.206
[47,     7] loss: 1.211
[48,     7] loss: 1.201
[49,     7] loss: 1.185
[50,     7] loss: 1.191
[51,     7] loss: 1.196
[52,     7] loss: 1.187
[53,     7] loss: 1.193
[54,     7] loss: 1.168
[55,     7] loss: 1.165
[56,     7] loss: 1.166
[57,     7] loss: 1.176
[58,     7] loss: 1.167
[59,     7] loss: 1.149
[60,     7] loss: 1.140
[61,     7] loss: 1.135
[62,     7] loss: 1.132
[63,     7] loss: 1.121
[64,     7] loss: 1.142
[65,     7] loss: 1.129
[66,     7] loss: 1.144
[67,     7] loss: 1.142
[68,     7] loss: 1.101
[69,     7] loss: 1.122
[70,     7] loss: 1.114
[71,     7] loss: 1.101
[72,     7] loss: 1.085
[73,     7] loss: 1.085
[74,     7] loss: 1.126
[75,     7] loss: 1.116
[76,     7] loss: 1.098
[77,     7] loss: 1.112
[78,     7] loss: 1.119
[79,     7] loss: 1.107
[80,     7] loss: 1.099
[81,     7] loss: 1.114
[82,     7] loss: 1.098
[83,     7] loss: 1.115
[84,     7] loss: 1.082
[85,     7] loss: 1.090
[86,     7] loss: 1.126
[87,     7] loss: 1.076
[88,     7] loss: 1.066
[89,     7] loss: 1.072
[90,     7] loss: 1.119
[91,     7] loss: 1.071
[92,     7] loss: 1.088
[93,     7] loss: 1.100
[94,     7] loss: 1.061
[95,     7] loss: 1.062
[96,     7] loss: 1.070
[97,     7] loss: 1.065
Early stopping applied (best metric=0.43944865465164185)
Finished Training
Total time taken: 85.21816897392273
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.387
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
Early stopping applied (best metric=0.4453873038291931)
Finished Training
Total time taken: 68.20233416557312
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.387
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.387
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.387
[89,     7] loss: 1.386
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.387
[93,     7] loss: 1.386
[94,     7] loss: 1.386
[95,     7] loss: 1.386
[96,     7] loss: 1.386
[97,     7] loss: 1.386
Early stopping applied (best metric=0.4450054466724396)
Finished Training
Total time taken: 82.99405837059021
{'Methylation-R Validation Accuracy': 0.17664161226936337, 'Methylation-R Validation Sensitivity': 0.9761273209549072, 'Methylation-R Validation Specificity': 0.1026993865030675, 'Methylation-R Validation Precision': 0.09641297341167548, 'Methylation-R AUC ROC': 0.577291516818278, 'Methylation-R AUC PR': 0.42168942363431744, 'Methylation-R MCC': 0.043926460900386335, 'Methylation-R F1': 0.17421754958220717, 'Validation Loss (Methylation-R)': 0.40178980231285094, 'Methylation-K Validation Accuracy': 0.1773713827571647, 'Methylation-K Validation Sensitivity': 0.9372168284789644, 'Methylation-K Validation Specificity': 0.09496840627194009, 'Methylation-K Validation Precision': 0.10309302575534687, 'Methylation-K AUC ROC': 0.521820487438877, 'Methylation-K AUC PR': 0.37428915178015093, 'Methylation-K MCC': 0.01919016584711849, 'Methylation-K F1': 0.1846298372905407, 'Validation Loss (Methylation-K)': 0.4425328314304352, 'Validation Loss (total)': 0.8443226337432861, 'TimeToTrain': 72.74415845870972}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00986673946341496,
 'learning_rate_Methylation-K': 0.0030969125851186092,
 'learning_rate_Methylation-R': 0.009278135337473794,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.039722462151239105,
 'loss_weight_Methylation-R': 0.40311540131575935,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3146457479,
 'sample_weights': [0.5004897884870378, 0.3947905400030072],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.3142587204193035,
 'weight_decay_Methylation-K': 8.653270561392697,
 'weight_decay_Methylation-R': 7.3790505237347395}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007814277676091356,
 'learning_rate_Methylation-K': 0.006761221291835489,
 'learning_rate_Methylation-R': 0.005432571231565455,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3123831777555266,
 'loss_weight_Methylation-R': 0.5775418314385147,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 785053459,
 'sample_weights': [0.40311540131575935, 0.039722462151239105],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.5925280213069035,
 'weight_decay_Methylation-K': 9.944886626986065,
 'weight_decay_Methylation-R': 7.72092275984167}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00833469702601446,
 'learning_rate_Methylation-K': 0.008825656677434186,
 'learning_rate_Methylation-R': 0.007736690475784648,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4712399312957041,
 'loss_weight_Methylation-R': 0.24022962771749332,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1439904078,
 'sample_weights': [0.5775418314385147, 0.3123831777555266],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.449275895166257,
 'weight_decay_Methylation-K': 9.464399968864104,
 'weight_decay_Methylation-R': 9.767690889163289}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009900609643735485,
 'learning_rate_Methylation-K': 0.003410800078289645,
 'learning_rate_Methylation-R': 0.007595723632000743,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.17290201216624496,
 'loss_weight_Methylation-R': 0.1567761793830894,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2506584480,
 'sample_weights': [0.24022962771749332, 0.4712399312957041],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5911023012212547,
 'weight_decay_Methylation-K': 8.20876005752718,
 'weight_decay_Methylation-R': 7.83531406968733}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.387
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008504125269705277,
 'learning_rate_Methylation-K': 0.0012834222533038631,
 'learning_rate_Methylation-R': 0.0054477005946357735,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.49655832534164834,
 'loss_weight_Methylation-R': 0.19698848608586822,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2191690046,
 'sample_weights': [0.1567761793830894, 0.17290201216624496],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6331844477089114,
 'weight_decay_Methylation-K': 4.584488473104613,
 'weight_decay_Methylation-R': 7.023203613682643}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022143670189695964,
 'learning_rate_Methylation-K': 0.005745252245400197,
 'learning_rate_Methylation-R': 0.0019997224661662716,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.609060155148183,
 'loss_weight_Methylation-R': 0.7822439321663897,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4104937758,
 'sample_weights': [0.19698848608586822, 0.49655832534164834],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.918155255758934,
 'weight_decay_Methylation-K': 9.607677681525795,
 'weight_decay_Methylation-R': 3.4156999904830965}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.363
[3,     7] loss: 1.344
[4,     7] loss: 1.319
[5,     7] loss: 1.304
[6,     7] loss: 1.297
[7,     7] loss: 1.289
[8,     7] loss: 1.287
[9,     7] loss: 1.274
[10,     7] loss: 1.273
[11,     7] loss: 1.261
[12,     7] loss: 1.248
[13,     7] loss: 1.250
[14,     7] loss: 1.231
[15,     7] loss: 1.241
[16,     7] loss: 1.222
[17,     7] loss: 1.230
[18,     7] loss: 1.242
[19,     7] loss: 1.229
[20,     7] loss: 1.200
[21,     7] loss: 1.201
[22,     7] loss: 1.186
[23,     7] loss: 1.165
[24,     7] loss: 1.146
[25,     7] loss: 1.136
[26,     7] loss: 1.131
[27,     7] loss: 1.126
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006048364800161289,
 'learning_rate_Methylation-K': 0.001735132578439732,
 'learning_rate_Methylation-R': 0.008063126433281257,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.278726757448874,
 'loss_weight_Methylation-R': 0.6427787665093164,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3132568484,
 'sample_weights': [0.7822439321663897, 0.609060155148183],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.782144052986368,
 'weight_decay_Methylation-K': 3.4272679824604917,
 'weight_decay_Methylation-R': 8.53916763961452}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.385
[6,     7] loss: 1.370
[7,     7] loss: 1.337
[8,     7] loss: 1.317
[9,     7] loss: 1.299
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007888163365257108,
 'learning_rate_Methylation-K': 0.002583999113674885,
 'learning_rate_Methylation-R': 0.008372312202538486,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2532304082274728,
 'loss_weight_Methylation-R': 0.13071345205070103,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3203757939,
 'sample_weights': [0.6427787665093164, 0.278726757448874],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3122249185295083,
 'weight_decay_Methylation-K': 8.689836124672187,
 'weight_decay_Methylation-R': 9.811623903203053}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00977482062741614,
 'learning_rate_Methylation-K': 0.005285364416435128,
 'learning_rate_Methylation-R': 0.0008655986445307564,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.041433163448269084,
 'loss_weight_Methylation-R': 0.788122065333266,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3969846922,
 'sample_weights': [0.13071345205070103, 0.2532304082274728],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.55358543980254,
 'weight_decay_Methylation-K': 6.835862599006018,
 'weight_decay_Methylation-R': 0.5999846010771119}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.396
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.367
[6,     7] loss: 1.326
[7,     7] loss: 1.337
[8,     7] loss: 1.336
[9,     7] loss: 1.320
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007462550554745445,
 'learning_rate_Methylation-K': 0.005599192863914063,
 'learning_rate_Methylation-R': 6.716174042323373e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4423407544184281,
 'loss_weight_Methylation-R': 0.4282621196454232,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 580181778,
 'sample_weights': [0.788122065333266, 0.041433163448269084],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.6323477901823074,
 'weight_decay_Methylation-K': 5.512307999983535,
 'weight_decay_Methylation-R': 4.190836530932417}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.382
[8,     7] loss: 1.356
[9,     7] loss: 1.322
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0057423410082199765,
 'learning_rate_Methylation-K': 0.006273223697849291,
 'learning_rate_Methylation-R': 0.0027329536668603874,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5616223962043083,
 'loss_weight_Methylation-R': 0.6489220713136052,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3327026143,
 'sample_weights': [0.4282621196454232, 0.4423407544184281],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.708336303842579,
 'weight_decay_Methylation-K': 7.090921101982448,
 'weight_decay_Methylation-R': 5.0034649090007735}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009530069263627856,
 'learning_rate_Methylation-K': 0.0016517455358540695,
 'learning_rate_Methylation-R': 0.009375528604501037,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4683406042762351,
 'loss_weight_Methylation-R': 0.33020062306834524,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1882170165,
 'sample_weights': [0.6489220713136052, 0.5616223962043083],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8567358399591123,
 'weight_decay_Methylation-K': 6.425464923109553,
 'weight_decay_Methylation-R': 6.377334142780682}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.370
[18,     7] loss: 1.357
[19,     7] loss: 1.340
[20,     7] loss: 1.320
[21,     7] loss: 1.322
[22,     7] loss: 1.317
[23,     7] loss: 1.304
[24,     7] loss: 1.298
[25,     7] loss: 1.284
[26,     7] loss: 1.271
[27,     7] loss: 1.265
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009093952392966892,
 'learning_rate_Methylation-K': 0.0006809221942383242,
 'learning_rate_Methylation-R': 0.005943951764841388,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6954573287579849,
 'loss_weight_Methylation-R': 0.8363647866430864,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2526809740,
 'sample_weights': [0.33020062306834524, 0.4683406042762351],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.462707865627662,
 'weight_decay_Methylation-K': 9.59209215500184,
 'weight_decay_Methylation-R': 8.434125388537732}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009148967928540199,
 'learning_rate_Methylation-K': 0.0006108707019763181,
 'learning_rate_Methylation-R': 0.004333617126698368,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.46819070338595364,
 'loss_weight_Methylation-R': 0.43161705349601176,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 716793838,
 'sample_weights': [0.8363647866430864, 0.6954573287579849],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.502348137857287,
 'weight_decay_Methylation-K': 4.361963622584455,
 'weight_decay_Methylation-R': 9.42925066374765}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0044528925328057075,
 'learning_rate_Methylation-K': 0.007475088079640184,
 'learning_rate_Methylation-R': 0.007503163017104138,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8576956096605348,
 'loss_weight_Methylation-R': 0.7613161818047296,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 87803193,
 'sample_weights': [0.43161705349601176, 0.46819070338595364],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.3209195493403192,
 'weight_decay_Methylation-K': 8.708319259847718,
 'weight_decay_Methylation-R': 9.346706946205865}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00998284361380888,
 'learning_rate_Methylation-K': 0.007011926920741778,
 'learning_rate_Methylation-R': 0.005589002815729667,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1150589718827595,
 'loss_weight_Methylation-R': 0.29267205448174044,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1770565021,
 'sample_weights': [0.7613161818047296, 0.8576956096605348],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7091887394620815,
 'weight_decay_Methylation-K': 7.419941551729784,
 'weight_decay_Methylation-R': 9.000718869744773}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008461850443843616,
 'learning_rate_Methylation-K': 0.0009322786386441448,
 'learning_rate_Methylation-R': 0.009218770197610702,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5794915553546143,
 'loss_weight_Methylation-R': 0.4054510028615943,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1587750195,
 'sample_weights': [0.29267205448174044, 0.1150589718827595],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.8713930545147983,
 'weight_decay_Methylation-K': 1.3904316339313847,
 'weight_decay_Methylation-R': 9.817719878975767}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.387
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.377
[19,     7] loss: 1.385
[20,     7] loss: 1.376
[21,     7] loss: 1.346
[22,     7] loss: 1.345
[23,     7] loss: 1.338
[24,     7] loss: 1.334
[25,     7] loss: 1.330
[26,     7] loss: 1.328
[27,     7] loss: 1.316
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007832386123391877,
 'learning_rate_Methylation-K': 0.006347475408633349,
 'learning_rate_Methylation-R': 0.0010043705386726348,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9217848776285237,
 'loss_weight_Methylation-R': 0.05763951343298761,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1225765331,
 'sample_weights': [0.4054510028615943, 0.5794915553546143],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.084571605887245,
 'weight_decay_Methylation-K': 3.695068284184927,
 'weight_decay_Methylation-R': 2.7751488865587253}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.374
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0091359676372138,
 'learning_rate_Methylation-K': 0.007314008684178234,
 'learning_rate_Methylation-R': 0.0015747741261362387,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4430413124472631,
 'loss_weight_Methylation-R': 0.71206972007489,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 887178291,
 'sample_weights': [0.05763951343298761, 0.9217848776285237],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.516493461432135,
 'weight_decay_Methylation-K': 6.853074961482902,
 'weight_decay_Methylation-R': 9.852181749744274}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005215012626011503,
 'learning_rate_Methylation-K': 0.0047515670851703586,
 'learning_rate_Methylation-R': 0.0015159021129942049,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3595167804061665,
 'loss_weight_Methylation-R': 0.82554198227454,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2471002738,
 'sample_weights': [0.71206972007489, 0.4430413124472631],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.310358746394715,
 'weight_decay_Methylation-K': 4.182340093232677,
 'weight_decay_Methylation-R': 6.848911691831073}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.367
[6,     7] loss: 1.339
[7,     7] loss: 1.321
[8,     7] loss: 1.292
[9,     7] loss: 1.292
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007450525345321579,
 'learning_rate_Methylation-K': 0.004279709373427052,
 'learning_rate_Methylation-R': 0.0058270955981206424,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.31283289196760694,
 'loss_weight_Methylation-R': 0.47509544969550205,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1874199124,
 'sample_weights': [0.82554198227454, 0.3595167804061665],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.657264431105861,
 'weight_decay_Methylation-K': 5.290247163573761,
 'weight_decay_Methylation-R': 9.567185410810863}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009240387095622226,
 'learning_rate_Methylation-K': 0.0032101171810759365,
 'learning_rate_Methylation-R': 0.007536647915105402,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.046008604326634644,
 'loss_weight_Methylation-R': 0.1011519704936673,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1913732561,
 'sample_weights': [0.47509544969550205, 0.31283289196760694],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.619313145389705,
 'weight_decay_Methylation-K': 8.142553914567856,
 'weight_decay_Methylation-R': 9.522735239019857}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008740095024895584,
 'learning_rate_Methylation-K': 0.005498066557149156,
 'learning_rate_Methylation-R': 0.008007230112618162,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.35146780862623817,
 'loss_weight_Methylation-R': 0.25793551473566634,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3123433005,
 'sample_weights': [0.1011519704936673, 0.046008604326634644],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6219512339291641,
 'weight_decay_Methylation-K': 8.84634037432103,
 'weight_decay_Methylation-R': 6.489933989179433}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005401616208197784,
 'learning_rate_Methylation-K': 0.00110552361563584,
 'learning_rate_Methylation-R': 0.000149703711058661,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.16100678615821973,
 'loss_weight_Methylation-R': 0.8042098853540285,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 384248004,
 'sample_weights': [0.25793551473566634, 0.35146780862623817],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.354104856776213,
 'weight_decay_Methylation-K': 5.727784316405401,
 'weight_decay_Methylation-R': 5.946265021026352}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.387
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.4448356628417969)
Finished Training
Total time taken: 44.33716583251953
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.384
[6,     7] loss: 1.374
[7,     7] loss: 1.349
[8,     7] loss: 1.332
[9,     7] loss: 1.330
[10,     7] loss: 1.316
[11,     7] loss: 1.307
[12,     7] loss: 1.286
[13,     7] loss: 1.286
[14,     7] loss: 1.283
[15,     7] loss: 1.268
[16,     7] loss: 1.264
[17,     7] loss: 1.251
[18,     7] loss: 1.249
[19,     7] loss: 1.251
[20,     7] loss: 1.264
[21,     7] loss: 1.260
[22,     7] loss: 1.235
[23,     7] loss: 1.229
[24,     7] loss: 1.228
[25,     7] loss: 1.215
[26,     7] loss: 1.206
[27,     7] loss: 1.212
[28,     7] loss: 1.202
[29,     7] loss: 1.195
[30,     7] loss: 1.196
[31,     7] loss: 1.193
[32,     7] loss: 1.172
[33,     7] loss: 1.178
[34,     7] loss: 1.164
[35,     7] loss: 1.166
[36,     7] loss: 1.165
[37,     7] loss: 1.162
[38,     7] loss: 1.201
[39,     7] loss: 1.163
[40,     7] loss: 1.148
[41,     7] loss: 1.147
[42,     7] loss: 1.123
[43,     7] loss: 1.119
[44,     7] loss: 1.145
[45,     7] loss: 1.127
[46,     7] loss: 1.126
[47,     7] loss: 1.138
[48,     7] loss: 1.107
[49,     7] loss: 1.109
[50,     7] loss: 1.088
[51,     7] loss: 1.070
Early stopping applied (best metric=0.4294600784778595)
Finished Training
Total time taken: 44.86019325256348
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.385
[6,     7] loss: 1.377
[7,     7] loss: 1.350
[8,     7] loss: 1.326
[9,     7] loss: 1.313
[10,     7] loss: 1.305
[11,     7] loss: 1.310
[12,     7] loss: 1.298
[13,     7] loss: 1.280
[14,     7] loss: 1.277
[15,     7] loss: 1.268
[16,     7] loss: 1.268
[17,     7] loss: 1.239
[18,     7] loss: 1.255
[19,     7] loss: 1.240
[20,     7] loss: 1.241
[21,     7] loss: 1.235
[22,     7] loss: 1.237
[23,     7] loss: 1.220
[24,     7] loss: 1.222
[25,     7] loss: 1.230
[26,     7] loss: 1.211
[27,     7] loss: 1.195
[28,     7] loss: 1.221
[29,     7] loss: 1.212
[30,     7] loss: 1.197
[31,     7] loss: 1.203
[32,     7] loss: 1.195
[33,     7] loss: 1.182
[34,     7] loss: 1.181
[35,     7] loss: 1.169
[36,     7] loss: 1.166
[37,     7] loss: 1.160
[38,     7] loss: 1.173
[39,     7] loss: 1.164
[40,     7] loss: 1.160
[41,     7] loss: 1.141
[42,     7] loss: 1.151
[43,     7] loss: 1.141
[44,     7] loss: 1.148
[45,     7] loss: 1.134
[46,     7] loss: 1.124
[47,     7] loss: 1.137
[48,     7] loss: 1.119
[49,     7] loss: 1.126
[50,     7] loss: 1.122
[51,     7] loss: 1.115
[52,     7] loss: 1.142
[53,     7] loss: 1.122
[54,     7] loss: 1.123
[55,     7] loss: 1.123
[56,     7] loss: 1.104
[57,     7] loss: 1.105
[58,     7] loss: 1.111
[59,     7] loss: 1.085
[60,     7] loss: 1.104
[61,     7] loss: 1.094
[62,     7] loss: 1.110
[63,     7] loss: 1.118
[64,     7] loss: 1.077
[65,     7] loss: 1.088
[66,     7] loss: 1.074
[67,     7] loss: 1.051
[68,     7] loss: 1.056
[69,     7] loss: 1.067
[70,     7] loss: 1.064
[71,     7] loss: 1.071
[72,     7] loss: 1.082
[73,     7] loss: 1.053
[74,     7] loss: 1.038
[75,     7] loss: 1.056
[76,     7] loss: 1.052
[77,     7] loss: 1.064
[78,     7] loss: 1.044
[79,     7] loss: 1.042
[80,     7] loss: 1.023
[81,     7] loss: 1.038
[82,     7] loss: 1.061
[83,     7] loss: 1.046
[84,     7] loss: 1.044
[85,     7] loss: 1.029
[86,     7] loss: 1.036
[87,     7] loss: 1.035
[88,     7] loss: 1.014
[89,     7] loss: 1.011
[90,     7] loss: 1.009
[91,     7] loss: 1.008
[92,     7] loss: 1.030
[93,     7] loss: 1.038
[94,     7] loss: 1.014
[95,     7] loss: 1.030
[96,     7] loss: 1.023
[97,     7] loss: 1.001
[98,     7] loss: 1.016
[99,     7] loss: 1.022
[100,     7] loss: 1.014
[101,     7] loss: 1.047
[102,     7] loss: 1.000
[103,     7] loss: 1.019
[104,     7] loss: 1.002
[105,     7] loss: 0.979
[106,     7] loss: 0.987
[107,     7] loss: 0.997
[108,     7] loss: 1.015
[109,     7] loss: 1.012
[110,     7] loss: 1.006
[111,     7] loss: 0.987
[112,     7] loss: 0.998
[113,     7] loss: 0.980
Early stopping applied (best metric=0.38481253385543823)
Finished Training
Total time taken: 97.9697904586792
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.385
[8,     7] loss: 1.383
[9,     7] loss: 1.365
[10,     7] loss: 1.344
[11,     7] loss: 1.333
[12,     7] loss: 1.325
[13,     7] loss: 1.317
[14,     7] loss: 1.322
[15,     7] loss: 1.307
[16,     7] loss: 1.283
[17,     7] loss: 1.292
[18,     7] loss: 1.281
[19,     7] loss: 1.264
[20,     7] loss: 1.262
[21,     7] loss: 1.255
[22,     7] loss: 1.241
[23,     7] loss: 1.242
[24,     7] loss: 1.229
[25,     7] loss: 1.240
[26,     7] loss: 1.246
[27,     7] loss: 1.227
[28,     7] loss: 1.228
[29,     7] loss: 1.205
[30,     7] loss: 1.217
[31,     7] loss: 1.209
[32,     7] loss: 1.179
[33,     7] loss: 1.197
[34,     7] loss: 1.180
[35,     7] loss: 1.181
[36,     7] loss: 1.160
[37,     7] loss: 1.166
[38,     7] loss: 1.151
[39,     7] loss: 1.157
[40,     7] loss: 1.159
[41,     7] loss: 1.137
[42,     7] loss: 1.144
[43,     7] loss: 1.133
[44,     7] loss: 1.094
[45,     7] loss: 1.107
[46,     7] loss: 1.096
[47,     7] loss: 1.091
[48,     7] loss: 1.136
[49,     7] loss: 1.109
[50,     7] loss: 1.098
[51,     7] loss: 1.077
[52,     7] loss: 1.083
[53,     7] loss: 1.079
[54,     7] loss: 1.076
[55,     7] loss: 1.072
[56,     7] loss: 1.060
[57,     7] loss: 1.053
[58,     7] loss: 1.070
[59,     7] loss: 1.079
[60,     7] loss: 1.065
[61,     7] loss: 1.024
[62,     7] loss: 1.053
[63,     7] loss: 1.039
[64,     7] loss: 1.039
[65,     7] loss: 1.032
[66,     7] loss: 1.051
[67,     7] loss: 1.028
[68,     7] loss: 1.042
[69,     7] loss: 1.034
[70,     7] loss: 1.027
[71,     7] loss: 1.022
[72,     7] loss: 1.031
[73,     7] loss: 1.030
[74,     7] loss: 1.036
[75,     7] loss: 1.010
[76,     7] loss: 1.013
[77,     7] loss: 1.067
[78,     7] loss: 1.037
[79,     7] loss: 1.022
[80,     7] loss: 1.026
[81,     7] loss: 0.987
[82,     7] loss: 1.007
[83,     7] loss: 1.007
[84,     7] loss: 1.013
[85,     7] loss: 1.011
[86,     7] loss: 1.042
[87,     7] loss: 1.024
[88,     7] loss: 1.004
[89,     7] loss: 1.011
[90,     7] loss: 1.015
[91,     7] loss: 1.028
[92,     7] loss: 1.007
[93,     7] loss: 0.985
[94,     7] loss: 1.015
[95,     7] loss: 1.003
[96,     7] loss: 0.986
[97,     7] loss: 0.981
Early stopping applied (best metric=0.39572232961654663)
Finished Training
Total time taken: 83.40008091926575
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.385
[9,     7] loss: 1.380
[10,     7] loss: 1.352
[11,     7] loss: 1.334
[12,     7] loss: 1.327
[13,     7] loss: 1.317
[14,     7] loss: 1.314
[15,     7] loss: 1.296
[16,     7] loss: 1.282
[17,     7] loss: 1.271
[18,     7] loss: 1.280
[19,     7] loss: 1.262
[20,     7] loss: 1.256
[21,     7] loss: 1.245
[22,     7] loss: 1.235
[23,     7] loss: 1.247
[24,     7] loss: 1.235
[25,     7] loss: 1.236
[26,     7] loss: 1.228
[27,     7] loss: 1.203
[28,     7] loss: 1.200
[29,     7] loss: 1.197
[30,     7] loss: 1.213
[31,     7] loss: 1.201
[32,     7] loss: 1.192
[33,     7] loss: 1.194
[34,     7] loss: 1.176
[35,     7] loss: 1.195
[36,     7] loss: 1.195
[37,     7] loss: 1.174
[38,     7] loss: 1.174
[39,     7] loss: 1.179
[40,     7] loss: 1.170
[41,     7] loss: 1.143
[42,     7] loss: 1.161
[43,     7] loss: 1.148
[44,     7] loss: 1.142
[45,     7] loss: 1.153
[46,     7] loss: 1.133
[47,     7] loss: 1.151
[48,     7] loss: 1.157
[49,     7] loss: 1.123
[50,     7] loss: 1.126
[51,     7] loss: 1.139
[52,     7] loss: 1.149
[53,     7] loss: 1.137
[54,     7] loss: 1.121
[55,     7] loss: 1.115
[56,     7] loss: 1.115
[57,     7] loss: 1.097
[58,     7] loss: 1.088
[59,     7] loss: 1.098
[60,     7] loss: 1.126
[61,     7] loss: 1.109
[62,     7] loss: 1.114
[63,     7] loss: 1.101
[64,     7] loss: 1.092
[65,     7] loss: 1.069
[66,     7] loss: 1.074
[67,     7] loss: 1.069
[68,     7] loss: 1.089
[69,     7] loss: 1.072
[70,     7] loss: 1.052
[71,     7] loss: 1.074
[72,     7] loss: 1.055
[73,     7] loss: 1.045
[74,     7] loss: 1.063
[75,     7] loss: 1.105
[76,     7] loss: 1.068
[77,     7] loss: 1.044
[78,     7] loss: 1.051
[79,     7] loss: 1.048
[80,     7] loss: 1.038
[81,     7] loss: 1.026
[82,     7] loss: 1.047
[83,     7] loss: 1.037
[84,     7] loss: 1.040
[85,     7] loss: 1.055
[86,     7] loss: 1.038
[87,     7] loss: 1.047
[88,     7] loss: 1.114
[89,     7] loss: 1.054
[90,     7] loss: 1.044
[91,     7] loss: 1.012
[92,     7] loss: 1.028
[93,     7] loss: 1.061
[94,     7] loss: 1.032
[95,     7] loss: 1.014
[96,     7] loss: 0.993
[97,     7] loss: 1.024
[98,     7] loss: 1.012
[99,     7] loss: 0.991
[100,     7] loss: 1.005
[101,     7] loss: 0.988
[102,     7] loss: 0.993
[103,     7] loss: 1.054
[104,     7] loss: 1.030
[105,     7] loss: 0.989
[106,     7] loss: 0.999
[107,     7] loss: 1.017
[108,     7] loss: 0.986
[109,     7] loss: 1.003
[110,     7] loss: 0.998
[111,     7] loss: 1.011
[112,     7] loss: 1.005
[113,     7] loss: 0.979
[114,     7] loss: 0.985
[115,     7] loss: 0.960
[116,     7] loss: 0.966
[117,     7] loss: 0.988
[118,     7] loss: 1.015
[119,     7] loss: 0.981
[120,     7] loss: 0.955
[121,     7] loss: 0.980
[122,     7] loss: 0.974
[123,     7] loss: 0.987
[124,     7] loss: 1.009
Early stopping applied (best metric=0.3822835087776184)
Finished Training
Total time taken: 108.10728621482849
{'Methylation-R Validation Accuracy': 0.4243621757871777, 'Methylation-R Validation Sensitivity': 0.8697168884145117, 'Methylation-R Validation Specificity': 0.3831656441717791, 'Methylation-R Validation Precision': 0.13707258667638636, 'Methylation-R AUC ROC': 0.7024249531845009, 'Methylation-R AUC PR': 0.26369638473977164, 'Methylation-R MCC': 0.14655754203061216, 'Methylation-R F1': 0.23049318831406218, 'Validation Loss (Methylation-R)': 0.36106106638908386, 'Methylation-K Validation Accuracy': 0.35114416788288355, 'Methylation-K Validation Sensitivity': 0.8640352655282723, 'Methylation-K Validation Specificity': 0.2955168689542581, 'Methylation-K Validation Precision': 0.12451922757509123, 'Methylation-K AUC ROC': 0.5992241488101017, 'Methylation-K AUC PR': 0.14142383449574653, 'Methylation-K MCC': 0.09530256256425143, 'Methylation-K F1': 0.21541476657638292, 'Validation Loss (Methylation-K)': 0.40742282271385194, 'Validation Loss (total)': 0.7684838891029357, 'TimeToTrain': 75.73490333557129}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004153487352959963,
 'learning_rate_Methylation-K': 0.002811401734985277,
 'learning_rate_Methylation-R': 0.00021532618664976222,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9536534584751585,
 'loss_weight_Methylation-R': 0.4939959033649361,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1375195514,
 'sample_weights': [0.8042098853540285, 0.16100678615821973],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.19197786520633997,
 'weight_decay_Methylation-K': 1.693245283912494,
 'weight_decay_Methylation-R': 6.8715346197481955}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.385
[3,     7] loss: 1.378
[4,     7] loss: 1.359
[5,     7] loss: 1.338
[6,     7] loss: 1.332
[7,     7] loss: 1.318
[8,     7] loss: 1.305
[9,     7] loss: 1.316
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008412533168520519,
 'learning_rate_Methylation-K': 0.0008260485554147394,
 'learning_rate_Methylation-R': 0.0065557067578987365,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6637155109900266,
 'loss_weight_Methylation-R': 0.13681258804149388,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1940658105,
 'sample_weights': [0.4939959033649361, 0.9536534584751585],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.838643225399627,
 'weight_decay_Methylation-K': 3.9481037019220198,
 'weight_decay_Methylation-R': 8.641408075739957}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009466896069278597,
 'learning_rate_Methylation-K': 0.006052269169458731,
 'learning_rate_Methylation-R': 0.008900316652013636,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5483213666050033,
 'loss_weight_Methylation-R': 0.7235673048684553,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3188715924,
 'sample_weights': [0.13681258804149388, 0.6637155109900266],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.3026045176072945,
 'weight_decay_Methylation-K': 4.767978180064869,
 'weight_decay_Methylation-R': 2.9970448091670945}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.387
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.387
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.387
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00511295196445553,
 'learning_rate_Methylation-K': 0.005796210017458433,
 'learning_rate_Methylation-R': 0.00293825938424119,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6748692803582195,
 'loss_weight_Methylation-R': 0.4104817417626232,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3711438616,
 'sample_weights': [0.7235673048684553, 0.5483213666050033],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.314292416178104,
 'weight_decay_Methylation-K': 5.332563380966002,
 'weight_decay_Methylation-R': 0.6942605488712023}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.382
[3,     7] loss: 1.362
[4,     7] loss: 1.332
[5,     7] loss: 1.332
[6,     7] loss: 1.317
[7,     7] loss: 1.324
[8,     7] loss: 1.300
[9,     7] loss: 1.296
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001974279128796045,
 'learning_rate_Methylation-K': 0.006479759700980518,
 'learning_rate_Methylation-R': 0.005953074830687662,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1737029242082263,
 'loss_weight_Methylation-R': 0.9535725055452957,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1788424548,
 'sample_weights': [0.4104817417626232, 0.6748692803582195],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.774678193520742,
 'weight_decay_Methylation-K': 4.109165829828906,
 'weight_decay_Methylation-R': 8.708805901449852}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.375
[3,     7] loss: 1.341
[4,     7] loss: 1.333
[5,     7] loss: 1.317
[6,     7] loss: 1.307
[7,     7] loss: 1.282
[8,     7] loss: 1.279
[9,     7] loss: 1.251
[10,     7] loss: 1.227
[11,     7] loss: 1.216
[12,     7] loss: 1.222
[13,     7] loss: 1.193
[14,     7] loss: 1.186
[15,     7] loss: 1.201
[16,     7] loss: 1.187
[17,     7] loss: 1.199
[18,     7] loss: 1.173
[19,     7] loss: 1.173
[20,     7] loss: 1.160
[21,     7] loss: 1.155
[22,     7] loss: 1.143
[23,     7] loss: 1.149
[24,     7] loss: 1.151
[25,     7] loss: 1.138
[26,     7] loss: 1.141
[27,     7] loss: 1.124
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008945393576650609,
 'learning_rate_Methylation-K': 0.001529167061131472,
 'learning_rate_Methylation-R': 0.007195338604125082,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07332619930331871,
 'loss_weight_Methylation-R': 0.8614459938065007,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 450324709,
 'sample_weights': [0.9535725055452957, 0.1737029242082263],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7925185239592385,
 'weight_decay_Methylation-K': 3.774000522497264,
 'weight_decay_Methylation-R': 9.021039821769394}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.387
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.387
Early stopping applied (best metric=0.4452194273471832)
Finished Training
Total time taken: 68.18733429908752
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.387
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
Early stopping applied (best metric=0.4430662989616394)
Finished Training
Total time taken: 45.92725610733032
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.387
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.387
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.387
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
Early stopping applied (best metric=0.4448211193084717)
Finished Training
Total time taken: 46.16026067733765
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.387
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.387
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.4424192011356354)
Finished Training
Total time taken: 45.314215660095215
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.387
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.387
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.387
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.387
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.387
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.387
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.387
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.387
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.387
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.386
[90,     7] loss: 1.386
[91,     7] loss: 1.387
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
[95,     7] loss: 1.386
[96,     7] loss: 1.386
[97,     7] loss: 1.386
[98,     7] loss: 1.386
[99,     7] loss: 1.386
[100,     7] loss: 1.386
[101,     7] loss: 1.386
[102,     7] loss: 1.386
[103,     7] loss: 1.386
[104,     7] loss: 1.386
[105,     7] loss: 1.386
[106,     7] loss: 1.386
[107,     7] loss: 1.386
[108,     7] loss: 1.386
[109,     7] loss: 1.386
[110,     7] loss: 1.386
[111,     7] loss: 1.386
[112,     7] loss: 1.386
[113,     7] loss: 1.386
[114,     7] loss: 1.386
[115,     7] loss: 1.386
[116,     7] loss: 1.386
[117,     7] loss: 1.386
[118,     7] loss: 1.386
[119,     7] loss: 1.386
[120,     7] loss: 1.386
[121,     7] loss: 1.386
[122,     7] loss: 1.386
[123,     7] loss: 1.386
[124,     7] loss: 1.386
[125,     7] loss: 1.386
[126,     7] loss: 1.386
[127,     7] loss: 1.386
[128,     7] loss: 1.386
[129,     7] loss: 1.386
[130,     7] loss: 1.386
[131,     7] loss: 1.386
[132,     7] loss: 1.386
[133,     7] loss: 1.386
[134,     7] loss: 1.386
[135,     7] loss: 1.386
[136,     7] loss: 1.386
[137,     7] loss: 1.387
[138,     7] loss: 1.386
[139,     7] loss: 1.386
[140,     7] loss: 1.386
[141,     7] loss: 1.386
[142,     7] loss: 1.386
[143,     7] loss: 1.386
[144,     7] loss: 1.386
[145,     7] loss: 1.386
[146,     7] loss: 1.386
[147,     7] loss: 1.387
[148,     7] loss: 1.386
[149,     7] loss: 1.386
[150,     7] loss: 1.386
[151,     7] loss: 1.386
[152,     7] loss: 1.386
[153,     7] loss: 1.386
[154,     7] loss: 1.386
[155,     7] loss: 1.386
[156,     7] loss: 1.386
[157,     7] loss: 1.386
[158,     7] loss: 1.386
[159,     7] loss: 1.386
Early stopping applied (best metric=0.44482138752937317)
Finished Training
Total time taken: 138.00075006484985
{'Methylation-R Validation Accuracy': 0.08466048019389166, 'Methylation-R Validation Sensitivity': 1.0, 'Methylation-R Validation Specificity': 0.0, 'Methylation-R Validation Precision': 0.08466048019389166, 'Methylation-R AUC ROC': 0.47216849196921123, 'Methylation-R AUC PR': 0.2646395175223649, 'Methylation-R MCC': 0.0, 'Methylation-R F1': 0.15610503065657413, 'Validation Loss (Methylation-R)': 0.42981860041618347, 'Methylation-K Validation Accuracy': 0.09784008327442427, 'Methylation-K Validation Sensitivity': 1.0, 'Methylation-K Validation Specificity': 0.0, 'Methylation-K Validation Precision': 0.09784008327442427, 'Methylation-K AUC ROC': 0.4979765573502722, 'Methylation-K AUC PR': 0.2776464813238261, 'Methylation-K MCC': 0.0, 'Methylation-K F1': 0.17824104586382167, 'Validation Loss (Methylation-K)': 0.4440694868564606, 'Validation Loss (total)': 0.8738880753517151, 'TimeToTrain': 68.71796336174012}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007347596469299308,
 'learning_rate_Methylation-K': 0.009715824086568237,
 'learning_rate_Methylation-R': 0.0064699252985951335,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.47572045631028964,
 'loss_weight_Methylation-R': 0.7788376633763427,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 566718479,
 'sample_weights': [0.8614459938065007, 0.07332619930331871],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.859302249440879,
 'weight_decay_Methylation-K': 9.34619161197954,
 'weight_decay_Methylation-R': 9.737740368294974}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00867198847190245,
 'learning_rate_Methylation-K': 0.0046603000105642604,
 'learning_rate_Methylation-R': 0.0046212299127464836,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3710683995686711,
 'loss_weight_Methylation-R': 0.4915861800567485,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 177149895,
 'sample_weights': [0.7788376633763427, 0.47572045631028964],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.626812014200558,
 'weight_decay_Methylation-K': 3.3022248977366084,
 'weight_decay_Methylation-R': 8.86251822227791}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.381
[11,     7] loss: 1.399
[12,     7] loss: 1.386
[13,     7] loss: 1.387
[14,     7] loss: 1.387
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.382
[18,     7] loss: 1.361
[19,     7] loss: 1.399
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.385
[25,     7] loss: 1.374
[26,     7] loss: 1.355
[27,     7] loss: 1.327
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00991626649219844,
 'learning_rate_Methylation-K': 0.006596009662987744,
 'learning_rate_Methylation-R': 0.007850152393537582,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5278584373775097,
 'loss_weight_Methylation-R': 0.9123447615546214,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1901568558,
 'sample_weights': [0.4915861800567485, 0.3710683995686711],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.9184144273512134,
 'weight_decay_Methylation-K': 3.7920443337608116,
 'weight_decay_Methylation-R': 0.8429239267922455}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.398
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008932891037501643,
 'learning_rate_Methylation-K': 0.002373794993675296,
 'learning_rate_Methylation-R': 0.008139108289301629,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.10906985774326576,
 'loss_weight_Methylation-R': 0.2425563930562511,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1940262000,
 'sample_weights': [0.9123447615546214, 0.5278584373775097],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.06030295674728936,
 'weight_decay_Methylation-K': 6.676515181514844,
 'weight_decay_Methylation-R': 6.582063159024461}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.385
[11,     7] loss: 1.383
[12,     7] loss: 1.378
[13,     7] loss: 1.358
[14,     7] loss: 1.347
[15,     7] loss: 1.346
[16,     7] loss: 1.339
[17,     7] loss: 1.341
[18,     7] loss: 1.340
[19,     7] loss: 1.335
[20,     7] loss: 1.328
[21,     7] loss: 1.326
[22,     7] loss: 1.322
[23,     7] loss: 1.324
[24,     7] loss: 1.326
[25,     7] loss: 1.328
[26,     7] loss: 1.323
[27,     7] loss: 1.317
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009962987550679247,
 'learning_rate_Methylation-K': 0.00403537173301287,
 'learning_rate_Methylation-R': 0.005787055433852745,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.43255911106131617,
 'loss_weight_Methylation-R': 0.36855734952769315,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4257034574,
 'sample_weights': [0.2425563930562511, 0.10906985774326576],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.12779976834227863,
 'weight_decay_Methylation-K': 5.127921236890173,
 'weight_decay_Methylation-R': 9.817205306094145}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.388
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.387
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.387
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.4440374970436096)
Finished Training
Total time taken: 45.08920454978943
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.387
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.387
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.44349557161331177)
Finished Training
Total time taken: 44.11715626716614
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.385
[10,     7] loss: 1.384
[11,     7] loss: 1.379
[12,     7] loss: 1.365
[13,     7] loss: 1.353
[14,     7] loss: 1.350
[15,     7] loss: 1.341
[16,     7] loss: 1.340
[17,     7] loss: 1.335
[18,     7] loss: 1.333
[19,     7] loss: 1.331
[20,     7] loss: 1.330
[21,     7] loss: 1.334
[22,     7] loss: 1.334
[23,     7] loss: 1.336
[24,     7] loss: 1.326
[25,     7] loss: 1.330
[26,     7] loss: 1.326
[27,     7] loss: 1.322
[28,     7] loss: 1.330
[29,     7] loss: 1.333
[30,     7] loss: 1.330
[31,     7] loss: 1.319
[32,     7] loss: 1.322
[33,     7] loss: 1.324
[34,     7] loss: 1.317
[35,     7] loss: 1.327
[36,     7] loss: 1.325
[37,     7] loss: 1.323
[38,     7] loss: 1.334
[39,     7] loss: 1.328
[40,     7] loss: 1.327
[41,     7] loss: 1.315
[42,     7] loss: 1.322
[43,     7] loss: 1.319
[44,     7] loss: 1.320
[45,     7] loss: 1.318
[46,     7] loss: 1.315
[47,     7] loss: 1.319
[48,     7] loss: 1.324
[49,     7] loss: 1.329
[50,     7] loss: 1.331
[51,     7] loss: 1.330
[52,     7] loss: 1.317
[53,     7] loss: 1.326
[54,     7] loss: 1.321
[55,     7] loss: 1.326
[56,     7] loss: 1.324
Early stopping applied (best metric=0.44703778624534607)
Finished Training
Total time taken: 48.44137001037598
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.387
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.44403186440467834)
Finished Training
Total time taken: 45.001201152801514
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.387
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.43989816308021545)
Finished Training
Total time taken: 45.0002019405365
{'Methylation-R Validation Accuracy': 0.08466048019389166, 'Methylation-R Validation Sensitivity': 1.0, 'Methylation-R Validation Specificity': 0.0, 'Methylation-R Validation Precision': 0.08466048019389166, 'Methylation-R AUC ROC': 0.5939233228785509, 'Methylation-R AUC PR': 0.12943579839208894, 'Methylation-R MCC': 0.0, 'Methylation-R F1': 0.15610503065657413, 'Validation Loss (Methylation-R)': 0.42925350069999696, 'Methylation-K Validation Accuracy': 0.09784008327442427, 'Methylation-K Validation Sensitivity': 1.0, 'Methylation-K Validation Specificity': 0.0, 'Methylation-K Validation Precision': 0.09784008327442427, 'Methylation-K AUC ROC': 0.505803149921785, 'Methylation-K AUC PR': 0.10146183900441118, 'Methylation-K MCC': 0.0, 'Methylation-K F1': 0.17824104586382167, 'Validation Loss (Methylation-K)': 0.44370017647743226, 'Validation Loss (total)': 0.8729536652565002, 'TimeToTrain': 45.52982678413391}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007908344845190877,
 'learning_rate_Methylation-K': 0.005572110966158395,
 'learning_rate_Methylation-R': 0.0067743031080539735,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.40020787403222213,
 'loss_weight_Methylation-R': 0.4020575423722341,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1819011238,
 'sample_weights': [0.36855734952769315, 0.43255911106131617],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3448765491466623,
 'weight_decay_Methylation-K': 4.931790909149271,
 'weight_decay_Methylation-R': 9.291666841396914}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009750261413546632,
 'learning_rate_Methylation-K': 0.009315212547193143,
 'learning_rate_Methylation-R': 0.0011079775815590537,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3004225082856061,
 'loss_weight_Methylation-R': 0.4948345275734964,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3366869608,
 'sample_weights': [0.4020575423722341, 0.40020787403222213],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.173694309826658,
 'weight_decay_Methylation-K': 6.643512915068052,
 'weight_decay_Methylation-R': 8.439303280049517}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009532405300208375,
 'learning_rate_Methylation-K': 0.003323593495658368,
 'learning_rate_Methylation-R': 0.005758183148869856,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.14662474814620513,
 'loss_weight_Methylation-R': 0.3061574341152099,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 88239507,
 'sample_weights': [0.4948345275734964, 0.3004225082856061],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.0755816204106434,
 'weight_decay_Methylation-K': 5.708032379113279,
 'weight_decay_Methylation-R': 8.362447848424738}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009179431074423833,
 'learning_rate_Methylation-K': 0.0038753303437666837,
 'learning_rate_Methylation-R': 0.0052122064086320904,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.15716851007549948,
 'loss_weight_Methylation-R': 0.19331807161915315,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2359329509,
 'sample_weights': [0.3061574341152099, 0.14662474814620513],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8706773841581092,
 'weight_decay_Methylation-K': 8.447878252570352,
 'weight_decay_Methylation-R': 6.996455513585456}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002562616184705005,
 'learning_rate_Methylation-K': 0.0075096076940452195,
 'learning_rate_Methylation-R': 0.0019916260280104445,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5055068169723019,
 'loss_weight_Methylation-R': 0.6137707834976847,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 931757693,
 'sample_weights': [0.19331807161915315, 0.15716851007549948],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7465426650593252,
 'weight_decay_Methylation-K': 7.530298943628973,
 'weight_decay_Methylation-R': 2.9151058798915965}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.398
[2,     7] loss: 1.386
[3,     7] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009964336250381317,
 'learning_rate_Methylation-K': 0.0016654772315327147,
 'learning_rate_Methylation-R': 0.004850127879507364,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.028168693708694924,
 'loss_weight_Methylation-R': 0.9590401445465073,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2672878734,
 'sample_weights': [0.6137707834976847, 0.5055068169723019],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.415382055656831,
 'weight_decay_Methylation-K': 7.540423653480554,
 'weight_decay_Methylation-R': 8.317940879420073}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.385
[6,     7] loss: 1.362
[7,     7] loss: 1.348
[8,     7] loss: 1.329
[9,     7] loss: 1.344
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008154366571737345,
 'learning_rate_Methylation-K': 0.001423247264722828,
 'learning_rate_Methylation-R': 0.006789727678183447,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.10033562964890103,
 'loss_weight_Methylation-R': 0.8267946415399994,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 215601187,
 'sample_weights': [0.9590401445465073, 0.028168693708694924],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.0986110599805363,
 'weight_decay_Methylation-K': 2.8830039076238223,
 'weight_decay_Methylation-R': 7.591143101848342}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.388
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007875289644197392,
 'learning_rate_Methylation-K': 0.00037566991163973893,
 'learning_rate_Methylation-R': 0.006083890344822311,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.003367993047532866,
 'loss_weight_Methylation-R': 0.9531249124876511,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4075204574,
 'sample_weights': [0.8267946415399994, 0.10033562964890103],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.069755685867866,
 'weight_decay_Methylation-K': 4.341231382332874,
 'weight_decay_Methylation-R': 8.431341546735005}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007401298980595871,
 'learning_rate_Methylation-K': 0.0031828914170185956,
 'learning_rate_Methylation-R': 0.006256702431216089,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6386465316299867,
 'loss_weight_Methylation-R': 0.2314563157008487,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 383227372,
 'sample_weights': [0.9531249124876511, 0.003367993047532866],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.14945509017052755,
 'weight_decay_Methylation-K': 4.915099663295728,
 'weight_decay_Methylation-R': 9.06930233916807}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.385
[3,     7] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009397789097891483,
 'learning_rate_Methylation-K': 0.00035164558027198583,
 'learning_rate_Methylation-R': 0.006948986261834846,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.18348027596354033,
 'loss_weight_Methylation-R': 0.35384773943150033,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1795384050,
 'sample_weights': [0.2314563157008487, 0.6386465316299867],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.744700306255568,
 'weight_decay_Methylation-K': 2.49689651379221,
 'weight_decay_Methylation-R': 8.952036406021708}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00983598701988242,
 'learning_rate_Methylation-K': 0.002054218781815073,
 'learning_rate_Methylation-R': 0.00732813425989466,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.1087198952002234,
 'loss_weight_Methylation-R': 0.8538640841123349,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 991972391,
 'sample_weights': [0.35384773943150033, 0.18348027596354033],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.244807528496497,
 'weight_decay_Methylation-K': 1.5514026593813168,
 'weight_decay_Methylation-R': 7.312646056902819}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.388
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008057885305914812,
 'learning_rate_Methylation-K': 0.0026774458689107585,
 'learning_rate_Methylation-R': 0.008160156665762124,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.39618313001448036,
 'loss_weight_Methylation-R': 0.4001064141880433,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1585468978,
 'sample_weights': [0.8538640841123349, 0.1087198952002234],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.046629766425322,
 'weight_decay_Methylation-K': 5.361204007317604,
 'weight_decay_Methylation-R': 9.447257042453687}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009297092018231964,
 'learning_rate_Methylation-K': 0.005681601774368809,
 'learning_rate_Methylation-R': 0.0020701585762523053,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2646218600125026,
 'loss_weight_Methylation-R': 0.8098510237530835,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3638489444,
 'sample_weights': [0.4001064141880433, 0.39618313001448036],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.5228968073640727,
 'weight_decay_Methylation-K': 3.2925511882879634,
 'weight_decay_Methylation-R': 7.698438877789584}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00678753389103135,
 'learning_rate_Methylation-K': 0.0017349708340407897,
 'learning_rate_Methylation-R': 0.005643340847522553,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.019513791062032354,
 'loss_weight_Methylation-R': 0.7016738558578299,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 322865894,
 'sample_weights': [0.8098510237530835, 0.2646218600125026],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.83613593555197,
 'weight_decay_Methylation-K': 4.305558664463632,
 'weight_decay_Methylation-R': 6.664412066328698}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.382
[8,     7] loss: 1.361
[9,     7] loss: 1.349
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0034451487900273615,
 'learning_rate_Methylation-K': 0.0020355993043380065,
 'learning_rate_Methylation-R': 0.006545802272782914,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2683686616578108,
 'loss_weight_Methylation-R': 0.5725321641060557,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1186620016,
 'sample_weights': [0.7016738558578299, 0.019513791062032354],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.3181461363963605,
 'weight_decay_Methylation-K': 0.5497144215388445,
 'weight_decay_Methylation-R': 6.108453707674063}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.396
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.385
[7,     7] loss: 1.380
[8,     7] loss: 1.359
[9,     7] loss: 1.339
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004432074183129449,
 'learning_rate_Methylation-K': 0.006177285522630343,
 'learning_rate_Methylation-R': 0.0025193737270107867,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.257305209813646,
 'loss_weight_Methylation-R': 0.8498063239271788,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3357591161,
 'sample_weights': [0.5725321641060557, 0.2683686616578108],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.957309428036131,
 'weight_decay_Methylation-K': 7.292824124924064,
 'weight_decay_Methylation-R': 8.031034806411535}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.366
[3,     7] loss: 1.326
[4,     7] loss: 1.328
[5,     7] loss: 1.310
[6,     7] loss: 1.317
[7,     7] loss: 1.288
[8,     7] loss: 1.277
[9,     7] loss: 1.285
[10,     7] loss: 1.295
[11,     7] loss: 1.283
[12,     7] loss: 1.255
[13,     7] loss: 1.248
[14,     7] loss: 1.266
[15,     7] loss: 1.245
[16,     7] loss: 1.271
[17,     7] loss: 1.276
[18,     7] loss: 1.253
[19,     7] loss: 1.253
[20,     7] loss: 1.267
[21,     7] loss: 1.320
[22,     7] loss: 1.324
[23,     7] loss: 1.318
[24,     7] loss: 1.306
[25,     7] loss: 1.291
[26,     7] loss: 1.297
[27,     7] loss: 1.284
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00225511561512131,
 'learning_rate_Methylation-K': 0.0003271036999931284,
 'learning_rate_Methylation-R': 0.0008298498032383034,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.001962968649658281,
 'loss_weight_Methylation-R': 0.9455564117860074,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1977847503,
 'sample_weights': [0.8498063239271788, 0.257305209813646],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.990791188790203,
 'weight_decay_Methylation-K': 5.922625168607509,
 'weight_decay_Methylation-R': 8.93024890466318}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.385
[3,     7] loss: 1.376
[4,     7] loss: 1.351
[5,     7] loss: 1.324
[6,     7] loss: 1.304
[7,     7] loss: 1.279
[8,     7] loss: 1.284
[9,     7] loss: 1.269
[10,     7] loss: 1.261
[11,     7] loss: 1.249
[12,     7] loss: 1.239
[13,     7] loss: 1.241
[14,     7] loss: 1.238
[15,     7] loss: 1.247
[16,     7] loss: 1.217
[17,     7] loss: 1.215
[18,     7] loss: 1.232
[19,     7] loss: 1.225
[20,     7] loss: 1.209
[21,     7] loss: 1.216
[22,     7] loss: 1.208
[23,     7] loss: 1.215
[24,     7] loss: 1.198
[25,     7] loss: 1.235
[26,     7] loss: 1.200
[27,     7] loss: 1.190
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004279320831538489,
 'learning_rate_Methylation-K': 0.004598314344795558,
 'learning_rate_Methylation-R': 0.0033499421202084394,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.0016683152219469366,
 'loss_weight_Methylation-R': 0.9272699739467649,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3857182753,
 'sample_weights': [0.9455564117860074, 0.001962968649658281],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.761579100061459,
 'weight_decay_Methylation-K': 3.3945023330967237,
 'weight_decay_Methylation-R': 7.949251795547487}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.383
[3,     7] loss: 1.352
[4,     7] loss: 1.322
[5,     7] loss: 1.322
[6,     7] loss: 1.301
[7,     7] loss: 1.296
[8,     7] loss: 1.287
[9,     7] loss: 1.271
[10,     7] loss: 1.302
[11,     7] loss: 1.281
[12,     7] loss: 1.267
[13,     7] loss: 1.288
[14,     7] loss: 1.275
[15,     7] loss: 1.268
[16,     7] loss: 1.272
[17,     7] loss: 1.284
[18,     7] loss: 1.257
[19,     7] loss: 1.268
[20,     7] loss: 1.261
[21,     7] loss: 1.326
[22,     7] loss: 1.310
[23,     7] loss: 1.311
[24,     7] loss: 1.300
[25,     7] loss: 1.267
[26,     7] loss: 1.280
[27,     7] loss: 1.264
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009593118565022733,
 'learning_rate_Methylation-K': 0.009662930873462225,
 'learning_rate_Methylation-R': 0.007327596818133053,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6402177876822861,
 'loss_weight_Methylation-R': 0.3631825515584378,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2098791915,
 'sample_weights': [0.9272699739467649, 0.0016683152219469366],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2444170519300837,
 'weight_decay_Methylation-K': 6.452868772944291,
 'weight_decay_Methylation-R': 9.306597576069267}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037179546669400014,
 'learning_rate_Methylation-K': 0.0038840504538143602,
 'learning_rate_Methylation-R': 0.0008807230564436043,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.23031456828417313,
 'loss_weight_Methylation-R': 0.7521738582302808,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 738548767,
 'sample_weights': [0.3631825515584378, 0.6402177876822861],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.219812170627991,
 'weight_decay_Methylation-K': 4.482367640956158,
 'weight_decay_Methylation-R': 9.757346222889261}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.388
[3,     7] loss: 1.386
[4,     7] loss: 1.384
[5,     7] loss: 1.371
[6,     7] loss: 1.341
[7,     7] loss: 1.322
[8,     7] loss: 1.312
[9,     7] loss: 1.310
[10,     7] loss: 1.295
[11,     7] loss: 1.283
[12,     7] loss: 1.280
[13,     7] loss: 1.264
[14,     7] loss: 1.238
[15,     7] loss: 1.258
[16,     7] loss: 1.264
[17,     7] loss: 1.238
[18,     7] loss: 1.261
[19,     7] loss: 1.241
[20,     7] loss: 1.232
[21,     7] loss: 1.244
[22,     7] loss: 1.248
[23,     7] loss: 1.265
[24,     7] loss: 1.250
[25,     7] loss: 1.231
[26,     7] loss: 1.222
[27,     7] loss: 1.218
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009555355054732883,
 'learning_rate_Methylation-K': 0.0005447523902877074,
 'learning_rate_Methylation-R': 0.00893135110286903,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.14489207153503358,
 'loss_weight_Methylation-R': 0.5391756941160869,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3742038579,
 'sample_weights': [0.7521738582302808, 0.23031456828417313],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6051463974092917,
 'weight_decay_Methylation-K': 7.900562742370746,
 'weight_decay_Methylation-R': 6.101603197997738}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009811276038887803,
 'learning_rate_Methylation-K': 0.0011963558042795445,
 'learning_rate_Methylation-R': 0.006524478939188235,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5049930940137836,
 'loss_weight_Methylation-R': 0.07504617684650511,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3004777262,
 'sample_weights': [0.5391756941160869, 0.14489207153503358],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9651854711536996,
 'weight_decay_Methylation-K': 6.1058204311896,
 'weight_decay_Methylation-R': 9.396752750169304}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.387
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.387
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00954527717933399,
 'learning_rate_Methylation-K': 0.004993491767608995,
 'learning_rate_Methylation-R': 0.008801727987200325,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5967361215304884,
 'loss_weight_Methylation-R': 0.7042684901457452,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1763318768,
 'sample_weights': [0.07504617684650511, 0.5049930940137836],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.4505835946204915,
 'weight_decay_Methylation-K': 5.779379294705617,
 'weight_decay_Methylation-R': 3.787965360572461}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.375
[5,     7] loss: 1.338
[6,     7] loss: 1.323
[7,     7] loss: 1.289
[8,     7] loss: 1.340
[9,     7] loss: 1.333
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009016893273330403,
 'learning_rate_Methylation-K': 0.002074051660256529,
 'learning_rate_Methylation-R': 0.007408757668153446,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.005350725456485295,
 'loss_weight_Methylation-R': 0.5510076439873672,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3318677163,
 'sample_weights': [0.7042684901457452, 0.5967361215304884],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7022358250174839,
 'weight_decay_Methylation-K': 7.14387816292793,
 'weight_decay_Methylation-R': 9.33572901743657}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009175042785918224,
 'learning_rate_Methylation-K': 0.0009659578886901671,
 'learning_rate_Methylation-R': 0.007390031696214725,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5923728893184601,
 'loss_weight_Methylation-R': 0.04634852124947346,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3060462708,
 'sample_weights': [0.5510076439873672, 0.005350725456485295],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.6485106101506064,
 'weight_decay_Methylation-K': 6.72857961673073,
 'weight_decay_Methylation-R': 8.366510411135547}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00957704881729877,
 'learning_rate_Methylation-K': 0.00014727654899000125,
 'learning_rate_Methylation-R': 0.0067763313960559,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5663653290583193,
 'loss_weight_Methylation-R': 0.11011680976747906,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 287972493,
 'sample_weights': [0.04634852124947346, 0.5923728893184601],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.22010349469664137,
 'weight_decay_Methylation-K': 5.828362207116564,
 'weight_decay_Methylation-R': 9.73730509779326}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008959678229751829,
 'learning_rate_Methylation-K': 0.003944043106927696,
 'learning_rate_Methylation-R': 0.008834791788535367,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.058585433912543144,
 'loss_weight_Methylation-R': 0.05001664086349929,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 655166515,
 'sample_weights': [0.11011680976747906, 0.5663653290583193],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.4617122358333525,
 'weight_decay_Methylation-K': 7.3981779639760195,
 'weight_decay_Methylation-R': 7.812748079157604}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009756338309902102,
 'learning_rate_Methylation-K': 0.002144397874550793,
 'learning_rate_Methylation-R': 0.006173253034805422,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.047365797274515765,
 'loss_weight_Methylation-R': 0.9875991731986429,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1550206307,
 'sample_weights': [0.05001664086349929, 0.058585433912543144],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.758303513356817,
 'weight_decay_Methylation-K': 3.8211238244985095,
 'weight_decay_Methylation-R': 7.449757391926384}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.380
[6,     7] loss: 1.346
[7,     7] loss: 1.323
[8,     7] loss: 1.296
[9,     7] loss: 1.305
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008883206023607326,
 'learning_rate_Methylation-K': 0.0008813125174106204,
 'learning_rate_Methylation-R': 0.0056836605024234155,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.41080778132363693,
 'loss_weight_Methylation-R': 0.45361207384914476,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3377033098,
 'sample_weights': [0.9875991731986429, 0.047365797274515765],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3566278113453611,
 'weight_decay_Methylation-K': 5.915211962446563,
 'weight_decay_Methylation-R': 7.03667921703397}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008329314803387973,
 'learning_rate_Methylation-K': 0.0017445677701413177,
 'learning_rate_Methylation-R': 0.003370986635879107,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5006269198760375,
 'loss_weight_Methylation-R': 0.14656980545259762,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3057907515,
 'sample_weights': [0.45361207384914476, 0.41080778132363693],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6690274297358745,
 'weight_decay_Methylation-K': 6.701814277071682,
 'weight_decay_Methylation-R': 9.950943659853257}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006015888618595093,
 'learning_rate_Methylation-K': 0.00863531855769705,
 'learning_rate_Methylation-R': 0.0004755827513700448,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6076250040185182,
 'loss_weight_Methylation-R': 0.4321824045186986,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 267007621,
 'sample_weights': [0.14656980545259762, 0.5006269198760375],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.193172877389918,
 'weight_decay_Methylation-K': 6.745935479306089,
 'weight_decay_Methylation-R': 7.189316407747391}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.388
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00996789091407021,
 'learning_rate_Methylation-K': 3.8000105959517435e-05,
 'learning_rate_Methylation-R': 0.009145039188565116,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.161485217438183,
 'loss_weight_Methylation-R': 0.49515281751368334,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3982175115,
 'sample_weights': [0.4321824045186986, 0.6076250040185182],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.193178797428074,
 'weight_decay_Methylation-K': 7.101047710336105,
 'weight_decay_Methylation-R': 7.9342605399812784}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.395
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008305970297082578,
 'learning_rate_Methylation-K': 0.006834140461225961,
 'learning_rate_Methylation-R': 0.00921929513265622,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4936135125986561,
 'loss_weight_Methylation-R': 0.9533894266823881,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2461082955,
 'sample_weights': [0.49515281751368334, 0.161485217438183],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.979181448746615,
 'weight_decay_Methylation-K': 5.173348482450154,
 'weight_decay_Methylation-R': 7.337762351147974}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009611487740311678,
 'learning_rate_Methylation-K': 0.0030463114323621065,
 'learning_rate_Methylation-R': 0.00811872291094,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3413609837090889,
 'loss_weight_Methylation-R': 0.03652737753757512,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 330301034,
 'sample_weights': [0.9533894266823881, 0.4936135125986561],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.352690936153316,
 'weight_decay_Methylation-K': 6.804361346536643,
 'weight_decay_Methylation-R': 9.097058411118836}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006974097735013521,
 'learning_rate_Methylation-K': 0.000607162866892635,
 'learning_rate_Methylation-R': 0.006346216242587184,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4768967221350976,
 'loss_weight_Methylation-R': 0.6558562337583658,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1403377220,
 'sample_weights': [0.03652737753757512, 0.3413609837090889],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.24528436060765502,
 'weight_decay_Methylation-K': 2.2323469547640395,
 'weight_decay_Methylation-R': 6.672563967273437}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.385
[4,     7] loss: 1.385
[5,     7] loss: 1.384
[6,     7] loss: 1.380
[7,     7] loss: 1.360
[8,     7] loss: 1.339
[9,     7] loss: 1.337
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008215481710147497,
 'learning_rate_Methylation-K': 0.005853067677367808,
 'learning_rate_Methylation-R': 0.009263130751282343,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6764305956652532,
 'loss_weight_Methylation-R': 0.7104321892982379,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2129739203,
 'sample_weights': [0.6558562337583658, 0.4768967221350976],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.331340175936013,
 'weight_decay_Methylation-K': 2.978059632464869,
 'weight_decay_Methylation-R': 1.0820521268345817}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.387
[5,     7] loss: 1.385
[6,     7] loss: 1.363
[7,     7] loss: 1.344
[8,     7] loss: 1.319
[9,     7] loss: 1.317
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006652214094133405,
 'learning_rate_Methylation-K': 0.0023387033800933736,
 'learning_rate_Methylation-R': 0.00023126137502766687,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4785024606900009,
 'loss_weight_Methylation-R': 0.5363095334976733,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2793754687,
 'sample_weights': [0.7104321892982379, 0.6764305956652532],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.179785646352526,
 'weight_decay_Methylation-K': 7.94733444478393,
 'weight_decay_Methylation-R': 0.460681346006206}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.385
[7,     7] loss: 1.386
[8,     7] loss: 1.379
[9,     7] loss: 1.346
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009592849884255038,
 'learning_rate_Methylation-K': 0.0017641095533695909,
 'learning_rate_Methylation-R': 0.005318038747806734,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3583522893634232,
 'loss_weight_Methylation-R': 0.13507644480744574,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2039542896,
 'sample_weights': [0.5363095334976733, 0.4785024606900009],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.4031681872105186,
 'weight_decay_Methylation-K': 7.6867553127984936,
 'weight_decay_Methylation-R': 9.324824596681568}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009937322465326654,
 'learning_rate_Methylation-K': 0.006226263569167882,
 'learning_rate_Methylation-R': 0.006096190285228855,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8673534195790037,
 'loss_weight_Methylation-R': 0.6463447849882824,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3176913152,
 'sample_weights': [0.13507644480744574, 0.3583522893634232],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7161412497741408,
 'weight_decay_Methylation-K': 9.262045220055757,
 'weight_decay_Methylation-R': 9.458796231187716}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.387
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00985203035309342,
 'learning_rate_Methylation-K': 0.0024032347498680858,
 'learning_rate_Methylation-R': 0.0040180152598304295,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4937607572759881,
 'loss_weight_Methylation-R': 0.451875822518495,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2706907984,
 'sample_weights': [0.6463447849882824, 0.8673534195790037],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6099241614010465,
 'weight_decay_Methylation-K': 2.8111758589603175,
 'weight_decay_Methylation-R': 8.060679147048397}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.387
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.387
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009082438358160597,
 'learning_rate_Methylation-K': 0.005541600913957327,
 'learning_rate_Methylation-R': 0.0035460374243125245,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.8089746203806523,
 'loss_weight_Methylation-R': 0.2954882136578814,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3999920300,
 'sample_weights': [0.451875822518495, 0.4937607572759881],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8395463447738423,
 'weight_decay_Methylation-K': 3.2538705243778017,
 'weight_decay_Methylation-R': 9.32349164051497}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007215743444670708,
 'learning_rate_Methylation-K': 0.0036310922507958436,
 'learning_rate_Methylation-R': 0.0048610972027021224,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7490334143152749,
 'loss_weight_Methylation-R': 0.020744323429176426,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1071984166,
 'sample_weights': [0.2954882136578814, 0.8089746203806523],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.9059168508004305,
 'weight_decay_Methylation-K': 7.907633082190868,
 'weight_decay_Methylation-R': 0.3585533531995697}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.386
[3,     7] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00181047476442844,
 'learning_rate_Methylation-K': 0.007263991387247519,
 'learning_rate_Methylation-R': 0.0015330311884721804,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7290200294942948,
 'loss_weight_Methylation-R': 0.5079814977208771,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1866372295,
 'sample_weights': [0.020744323429176426, 0.7490334143152749],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.781614388742134,
 'weight_decay_Methylation-K': 0.8864733380022276,
 'weight_decay_Methylation-R': 6.146661250054519}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.383
[3,     7] loss: 1.363
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009810321029581336,
 'learning_rate_Methylation-K': 0.005497044022150404,
 'learning_rate_Methylation-R': 0.003616512267223088,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3462134271592212,
 'loss_weight_Methylation-R': 0.8202241562559546,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 235119249,
 'sample_weights': [0.5079814977208771, 0.7290200294942948],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9297301301587513,
 'weight_decay_Methylation-K': 3.8008824937935306,
 'weight_decay_Methylation-R': 9.264779675963862}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.387
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.387
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
Early stopping applied (best metric=0.4444534182548523)
Finished Training
Total time taken: 48.30436158180237
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.387
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.387
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.387
[46,     7] loss: 1.387
[47,     7] loss: 1.386
[48,     7] loss: 1.387
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
Early stopping applied (best metric=0.4455024302005768)
Finished Training
Total time taken: 45.68230676651001
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.387
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.387
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.387
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
Early stopping applied (best metric=0.44378992915153503)
Finished Training
Total time taken: 44.226256370544434
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.387
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
Early stopping applied (best metric=0.44486531615257263)
Finished Training
Total time taken: 50.17842483520508
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.387
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.387
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
Early stopping applied (best metric=0.4459764361381531)
Finished Training
Total time taken: 56.345107316970825
{'Methylation-R Validation Accuracy': 0.08466048019389166, 'Methylation-R Validation Sensitivity': 1.0, 'Methylation-R Validation Specificity': 0.0, 'Methylation-R Validation Precision': 0.08466048019389166, 'Methylation-R AUC ROC': 0.5173055605279002, 'Methylation-R AUC PR': 0.27920050371269634, 'Methylation-R MCC': 0.0, 'Methylation-R F1': 0.15610503065657413, 'Validation Loss (Methylation-R)': 0.43073739409446715, 'Methylation-K Validation Accuracy': 0.09784008327442427, 'Methylation-K Validation Sensitivity': 1.0, 'Methylation-K Validation Specificity': 0.0, 'Methylation-K Validation Precision': 0.09784008327442427, 'Methylation-K AUC ROC': 0.4937521190607288, 'Methylation-K AUC PR': 0.27772077405278806, 'Methylation-K MCC': 0.0, 'Methylation-K F1': 0.17824104586382167, 'Validation Loss (Methylation-K)': 0.44491750597953794, 'Validation Loss (total)': 0.8756549119949341, 'TimeToTrain': 48.94729137420654}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00681000238037875,
 'learning_rate_Methylation-K': 0.0005007302003803959,
 'learning_rate_Methylation-R': 0.004769174211810693,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2449248271507614,
 'loss_weight_Methylation-R': 0.5952819152601989,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3357230034,
 'sample_weights': [0.8202241562559546, 0.3462134271592212],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.521714652691765,
 'weight_decay_Methylation-K': 5.145366739540349,
 'weight_decay_Methylation-R': 9.848758633032924}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025499770348169585,
 'learning_rate_Methylation-K': 0.0018634967671298766,
 'learning_rate_Methylation-R': 0.009425564184795619,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7330891300883604,
 'loss_weight_Methylation-R': 0.12051659233256112,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1896365606,
 'sample_weights': [0.5952819152601989, 0.2449248271507614],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5839694303825613,
 'weight_decay_Methylation-K': 9.269038005142226,
 'weight_decay_Methylation-R': 8.419301826430807}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.381
[3,     7] loss: 1.360
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005566985181374032,
 'learning_rate_Methylation-K': 3.839333347453917e-05,
 'learning_rate_Methylation-R': 0.0010622174477830358,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.40291368645145736,
 'loss_weight_Methylation-R': 0.9935324354280833,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4221863232,
 'sample_weights': [0.12051659233256112, 0.7330891300883604],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.463682183904723,
 'weight_decay_Methylation-K': 5.0831477109978245,
 'weight_decay_Methylation-R': 8.268106401972188}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.383
[7,     7] loss: 1.353
[8,     7] loss: 1.335
[9,     7] loss: 1.324
[10,     7] loss: 1.313
[11,     7] loss: 1.372
[12,     7] loss: 1.346
[13,     7] loss: 1.326
[14,     7] loss: 1.312
[15,     7] loss: 1.300
[16,     7] loss: 1.311
[17,     7] loss: 1.291
[18,     7] loss: 1.277
[19,     7] loss: 1.289
[20,     7] loss: 1.299
[21,     7] loss: 1.280
[22,     7] loss: 1.278
[23,     7] loss: 1.277
[24,     7] loss: 1.298
[25,     7] loss: 1.291
[26,     7] loss: 1.294
[27,     7] loss: 1.291
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0036347048025176963,
 'learning_rate_Methylation-K': 0.004585783538752404,
 'learning_rate_Methylation-R': 0.00015664150699103412,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9403941579907913,
 'loss_weight_Methylation-R': 0.9403911980260075,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1174077604,
 'sample_weights': [0.9935324354280833, 0.40291368645145736],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9684622237304232,
 'weight_decay_Methylation-K': 3.8909404134334453,
 'weight_decay_Methylation-R': 3.560189127204033}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.381
[3,     7] loss: 1.364
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00953067583642599,
 'learning_rate_Methylation-K': 0.007043998400827626,
 'learning_rate_Methylation-R': 0.0049041837531166345,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9375216114874613,
 'loss_weight_Methylation-R': 0.49650266060005194,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1682589199,
 'sample_weights': [0.9403911980260075, 0.9403941579907913],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.4648469544672134,
 'weight_decay_Methylation-K': 7.951422065803939,
 'weight_decay_Methylation-R': 9.288352473309416}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.398
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009231416853028139,
 'learning_rate_Methylation-K': 0.008057929916264597,
 'learning_rate_Methylation-R': 0.005201989926492706,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7728293712057717,
 'loss_weight_Methylation-R': 0.799435431589002,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 761050869,
 'sample_weights': [0.49650266060005194, 0.9375216114874613],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.4402051807456164,
 'weight_decay_Methylation-K': 7.1269740963567845,
 'weight_decay_Methylation-R': 7.705688648588154}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0099804988998646,
 'learning_rate_Methylation-K': 0.006034308736529215,
 'learning_rate_Methylation-R': 0.004609028681922523,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.9812813425704385,
 'loss_weight_Methylation-R': 0.7677000182756208,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 213484030,
 'sample_weights': [0.799435431589002, 0.7728293712057717],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.23501507467965344,
 'weight_decay_Methylation-K': 9.643417403105275,
 'weight_decay_Methylation-R': 9.60542322711957}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008298537034053186,
 'learning_rate_Methylation-K': 0.0036858192388244428,
 'learning_rate_Methylation-R': 0.004718175884027677,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.25390029336619624,
 'loss_weight_Methylation-R': 0.9170752234147312,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1010417870,
 'sample_weights': [0.7677000182756208, 0.9812813425704385],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6849464207059305,
 'weight_decay_Methylation-K': 9.579011964158553,
 'weight_decay_Methylation-R': 4.519009421529419}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.384
[17,     7] loss: 1.372
[18,     7] loss: 1.364
[19,     7] loss: 1.334
[20,     7] loss: 1.326
[21,     7] loss: 1.317
[22,     7] loss: 1.290
[23,     7] loss: 1.291
[24,     7] loss: 1.286
[25,     7] loss: 1.282
[26,     7] loss: 1.298
[27,     7] loss: 1.288
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008471498376444068,
 'learning_rate_Methylation-K': 0.0011514846048878888,
 'learning_rate_Methylation-R': 0.008352032512970106,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.022540873647525377,
 'loss_weight_Methylation-R': 0.8637633427017555,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3276580937,
 'sample_weights': [0.9170752234147312, 0.25390029336619624],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.374169640462256,
 'weight_decay_Methylation-K': 7.065244277816102,
 'weight_decay_Methylation-R': 9.188734079994358}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.384
[8,     7] loss: 1.360
[9,     7] loss: 1.338
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008237187597845492,
 'learning_rate_Methylation-K': 0.0024990488882365085,
 'learning_rate_Methylation-R': 0.00941279394730686,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4703769709965464,
 'loss_weight_Methylation-R': 0.23604022556415022,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1665967532,
 'sample_weights': [0.8637633427017555, 0.022540873647525377],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8134755922161986,
 'weight_decay_Methylation-K': 4.106270726376138,
 'weight_decay_Methylation-R': 5.970460146378135}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.387
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007963628080195165,
 'learning_rate_Methylation-K': 0.00039752299631252655,
 'learning_rate_Methylation-R': 0.006206362833742121,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4002016756703769,
 'loss_weight_Methylation-R': 0.23428009682711462,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 323149555,
 'sample_weights': [0.23604022556415022, 0.4703769709965464],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.9897434091223305,
 'weight_decay_Methylation-K': 7.247671813617245,
 'weight_decay_Methylation-R': 9.210488203876197}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.398
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016062198434135884,
 'learning_rate_Methylation-K': 0.0026908616741254227,
 'learning_rate_Methylation-R': 0.005427600202840591,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.03620407463491343,
 'loss_weight_Methylation-R': 0.6215524052472443,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3065272877,
 'sample_weights': [0.23428009682711462, 0.4002016756703769],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.369249120875176,
 'weight_decay_Methylation-K': 3.8376198022173096,
 'weight_decay_Methylation-R': 7.483991944259548}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.374
[3,     7] loss: 1.337
[4,     7] loss: 1.312
[5,     7] loss: 1.307
[6,     7] loss: 1.291
[7,     7] loss: 1.281
[8,     7] loss: 1.274
[9,     7] loss: 1.265
[10,     7] loss: 1.258
[11,     7] loss: 1.253
[12,     7] loss: 1.260
[13,     7] loss: 1.249
[14,     7] loss: 1.234
[15,     7] loss: 1.239
[16,     7] loss: 1.218
[17,     7] loss: 1.227
[18,     7] loss: 1.228
[19,     7] loss: 1.213
[20,     7] loss: 1.219
[21,     7] loss: 1.207
[22,     7] loss: 1.203
[23,     7] loss: 1.202
[24,     7] loss: 1.186
[25,     7] loss: 1.214
[26,     7] loss: 1.192
[27,     7] loss: 1.170
[28,     7] loss: 1.188
[29,     7] loss: 1.172
[30,     7] loss: 1.161
[31,     7] loss: 1.177
[32,     7] loss: 1.178
[33,     7] loss: 1.145
[34,     7] loss: 1.146
[35,     7] loss: 1.143
[36,     7] loss: 1.136
[37,     7] loss: 1.134
[38,     7] loss: 1.167
[39,     7] loss: 1.145
[40,     7] loss: 1.153
[41,     7] loss: 1.110
[42,     7] loss: 1.111
[43,     7] loss: 1.106
[44,     7] loss: 1.124
[45,     7] loss: 1.142
[46,     7] loss: 1.132
[47,     7] loss: 1.134
[48,     7] loss: 1.117
[49,     7] loss: 1.134
[50,     7] loss: 1.133
[51,     7] loss: 1.114
[52,     7] loss: 1.096
[53,     7] loss: 1.154
[54,     7] loss: 1.175
[55,     7] loss: 1.132
[56,     7] loss: 1.133
[57,     7] loss: 1.117
[58,     7] loss: 1.164
[59,     7] loss: 1.140
[60,     7] loss: 1.125
[61,     7] loss: 1.118
[62,     7] loss: 1.121
[63,     7] loss: 1.144
[64,     7] loss: 1.133
[65,     7] loss: 1.111
[66,     7] loss: 1.115
[67,     7] loss: 1.110
[68,     7] loss: 1.117
[69,     7] loss: 1.128
[70,     7] loss: 1.115
[71,     7] loss: 1.126
[72,     7] loss: 1.110
[73,     7] loss: 1.112
[74,     7] loss: 1.121
[75,     7] loss: 1.131
[76,     7] loss: 1.140
[77,     7] loss: 1.108
[78,     7] loss: 1.121
[79,     7] loss: 1.103
[80,     7] loss: 1.091
[81,     7] loss: 1.103
[82,     7] loss: 1.135
[83,     7] loss: 1.130
[84,     7] loss: 1.162
[85,     7] loss: 1.108
[86,     7] loss: 1.113
[87,     7] loss: 1.128
[88,     7] loss: 1.110
[89,     7] loss: 1.110
[90,     7] loss: 1.155
[91,     7] loss: 1.122
[92,     7] loss: 1.123
[93,     7] loss: 1.151
[94,     7] loss: 1.113
[95,     7] loss: 1.123
[96,     7] loss: 1.100
[97,     7] loss: 1.131
[98,     7] loss: 1.115
[99,     7] loss: 1.110
[100,     7] loss: 1.099
[101,     7] loss: 1.127
[102,     7] loss: 1.111
[103,     7] loss: 1.115
[104,     7] loss: 1.112
[105,     7] loss: 1.112
[106,     7] loss: 1.110
[107,     7] loss: 1.124
[108,     7] loss: 1.124
[109,     7] loss: 1.100
[110,     7] loss: 1.119
[111,     7] loss: 1.113
[112,     7] loss: 1.108
[113,     7] loss: 1.107
[114,     7] loss: 1.112
[115,     7] loss: 1.118
[116,     7] loss: 1.129
[117,     7] loss: 1.131
[118,     7] loss: 1.108
[119,     7] loss: 1.099
[120,     7] loss: 1.110
[121,     7] loss: 1.140
[122,     7] loss: 1.137
[123,     7] loss: 1.122
[124,     7] loss: 1.124
[125,     7] loss: 1.123
[126,     7] loss: 1.129
[127,     7] loss: 1.134
[128,     7] loss: 1.132
[129,     7] loss: 1.116
[130,     7] loss: 1.116
[131,     7] loss: 1.166
[132,     7] loss: 1.140
[133,     7] loss: 1.141
[134,     7] loss: 1.137
Early stopping applied (best metric=0.3518904149532318)
Finished Training
Total time taken: 117.118323802948
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.378
[3,     7] loss: 1.351
[4,     7] loss: 1.330
[5,     7] loss: 1.314
[6,     7] loss: 1.292
[7,     7] loss: 1.265
[8,     7] loss: 1.245
[9,     7] loss: 1.229
[10,     7] loss: 1.203
[11,     7] loss: 1.217
[12,     7] loss: 1.199
[13,     7] loss: 1.175
[14,     7] loss: 1.179
[15,     7] loss: 1.175
[16,     7] loss: 1.156
[17,     7] loss: 1.164
[18,     7] loss: 1.171
[19,     7] loss: 1.157
[20,     7] loss: 1.156
[21,     7] loss: 1.150
[22,     7] loss: 1.134
[23,     7] loss: 1.152
[24,     7] loss: 1.126
[25,     7] loss: 1.141
[26,     7] loss: 1.140
[27,     7] loss: 1.129
[28,     7] loss: 1.106
[29,     7] loss: 1.127
[30,     7] loss: 1.111
[31,     7] loss: 1.113
[32,     7] loss: 1.120
[33,     7] loss: 1.123
[34,     7] loss: 1.125
[35,     7] loss: 1.121
[36,     7] loss: 1.108
[37,     7] loss: 1.086
[38,     7] loss: 1.118
[39,     7] loss: 1.113
[40,     7] loss: 1.119
[41,     7] loss: 1.113
[42,     7] loss: 1.098
[43,     7] loss: 1.118
[44,     7] loss: 1.128
[45,     7] loss: 1.105
[46,     7] loss: 1.106
[47,     7] loss: 1.150
[48,     7] loss: 1.137
[49,     7] loss: 1.127
[50,     7] loss: 1.127
[51,     7] loss: 1.124
[52,     7] loss: 1.137
[53,     7] loss: 1.136
[54,     7] loss: 1.131
[55,     7] loss: 1.119
[56,     7] loss: 1.110
[57,     7] loss: 1.115
[58,     7] loss: 1.126
[59,     7] loss: 1.154
[60,     7] loss: 1.111
[61,     7] loss: 1.113
[62,     7] loss: 1.129
[63,     7] loss: 1.134
[64,     7] loss: 1.133
[65,     7] loss: 1.124
[66,     7] loss: 1.110
[67,     7] loss: 1.124
[68,     7] loss: 1.110
[69,     7] loss: 1.102
[70,     7] loss: 1.134
[71,     7] loss: 1.115
[72,     7] loss: 1.132
[73,     7] loss: 1.125
[74,     7] loss: 1.133
[75,     7] loss: 1.128
[76,     7] loss: 1.134
[77,     7] loss: 1.129
[78,     7] loss: 1.122
[79,     7] loss: 1.120
[80,     7] loss: 1.115
[81,     7] loss: 1.122
[82,     7] loss: 1.096
[83,     7] loss: 1.100
[84,     7] loss: 1.115
[85,     7] loss: 1.139
[86,     7] loss: 1.146
[87,     7] loss: 1.152
[88,     7] loss: 1.132
[89,     7] loss: 1.141
[90,     7] loss: 1.122
[91,     7] loss: 1.119
[92,     7] loss: 1.121
[93,     7] loss: 1.126
[94,     7] loss: 1.113
[95,     7] loss: 1.109
[96,     7] loss: 1.111
[97,     7] loss: 1.099
[98,     7] loss: 1.115
[99,     7] loss: 1.129
[100,     7] loss: 1.135
[101,     7] loss: 1.126
[102,     7] loss: 1.116
[103,     7] loss: 1.143
[104,     7] loss: 1.113
[105,     7] loss: 1.137
[106,     7] loss: 1.129
[107,     7] loss: 1.108
[108,     7] loss: 1.114
[109,     7] loss: 1.127
[110,     7] loss: 1.125
[111,     7] loss: 1.126
[112,     7] loss: 1.116
[113,     7] loss: 1.132
[114,     7] loss: 1.147
[115,     7] loss: 1.132
[116,     7] loss: 1.109
[117,     7] loss: 1.127
[118,     7] loss: 1.127
[119,     7] loss: 1.125
[120,     7] loss: 1.109
[121,     7] loss: 1.113
[122,     7] loss: 1.147
[123,     7] loss: 1.130
[124,     7] loss: 1.128
[125,     7] loss: 1.127
[126,     7] loss: 1.132
[127,     7] loss: 1.099
[128,     7] loss: 1.141
[129,     7] loss: 1.125
[130,     7] loss: 1.134
[131,     7] loss: 1.136
[132,     7] loss: 1.127
[133,     7] loss: 1.159
[134,     7] loss: 1.131
[135,     7] loss: 1.107
[136,     7] loss: 1.136
[137,     7] loss: 1.147
Early stopping applied (best metric=0.41272079944610596)
Finished Training
Total time taken: 119.20438623428345
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.379
[3,     7] loss: 1.351
[4,     7] loss: 1.328
[5,     7] loss: 1.318
[6,     7] loss: 1.298
[7,     7] loss: 1.283
[8,     7] loss: 1.270
[9,     7] loss: 1.258
[10,     7] loss: 1.231
[11,     7] loss: 1.220
[12,     7] loss: 1.208
[13,     7] loss: 1.195
[14,     7] loss: 1.202
[15,     7] loss: 1.192
[16,     7] loss: 1.178
[17,     7] loss: 1.165
[18,     7] loss: 1.156
[19,     7] loss: 1.137
[20,     7] loss: 1.140
[21,     7] loss: 1.157
[22,     7] loss: 1.141
[23,     7] loss: 1.134
[24,     7] loss: 1.171
[25,     7] loss: 1.152
[26,     7] loss: 1.124
[27,     7] loss: 1.124
[28,     7] loss: 1.128
[29,     7] loss: 1.112
[30,     7] loss: 1.103
[31,     7] loss: 1.111
[32,     7] loss: 1.131
[33,     7] loss: 1.124
[34,     7] loss: 1.129
[35,     7] loss: 1.108
[36,     7] loss: 1.120
[37,     7] loss: 1.094
[38,     7] loss: 1.102
[39,     7] loss: 1.117
[40,     7] loss: 1.115
[41,     7] loss: 1.105
[42,     7] loss: 1.121
[43,     7] loss: 1.121
[44,     7] loss: 1.107
[45,     7] loss: 1.101
[46,     7] loss: 1.104
[47,     7] loss: 1.103
[48,     7] loss: 1.155
[49,     7] loss: 1.138
[50,     7] loss: 1.154
[51,     7] loss: 1.113
Early stopping applied (best metric=0.4517524838447571)
Finished Training
Total time taken: 44.56326937675476
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.384
[3,     7] loss: 1.366
[4,     7] loss: 1.344
[5,     7] loss: 1.307
[6,     7] loss: 1.277
[7,     7] loss: 1.263
[8,     7] loss: 1.246
[9,     7] loss: 1.224
[10,     7] loss: 1.217
[11,     7] loss: 1.195
[12,     7] loss: 1.196
[13,     7] loss: 1.176
[14,     7] loss: 1.183
[15,     7] loss: 1.171
[16,     7] loss: 1.175
[17,     7] loss: 1.138
[18,     7] loss: 1.162
[19,     7] loss: 1.166
[20,     7] loss: 1.166
[21,     7] loss: 1.143
[22,     7] loss: 1.146
[23,     7] loss: 1.128
[24,     7] loss: 1.127
[25,     7] loss: 1.134
[26,     7] loss: 1.127
[27,     7] loss: 1.128
[28,     7] loss: 1.128
[29,     7] loss: 1.102
[30,     7] loss: 1.109
[31,     7] loss: 1.117
[32,     7] loss: 1.116
[33,     7] loss: 1.114
[34,     7] loss: 1.138
[35,     7] loss: 1.115
[36,     7] loss: 1.114
[37,     7] loss: 1.104
[38,     7] loss: 1.093
[39,     7] loss: 1.121
[40,     7] loss: 1.121
[41,     7] loss: 1.112
[42,     7] loss: 1.072
[43,     7] loss: 1.085
[44,     7] loss: 1.124
[45,     7] loss: 1.098
[46,     7] loss: 1.104
[47,     7] loss: 1.129
[48,     7] loss: 1.134
[49,     7] loss: 1.118
[50,     7] loss: 1.108
[51,     7] loss: 1.097
Early stopping applied (best metric=0.45027685165405273)
Finished Training
Total time taken: 45.598294734954834
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.392
[2,     7] loss: 1.382
[3,     7] loss: 1.362
[4,     7] loss: 1.337
[5,     7] loss: 1.329
[6,     7] loss: 1.316
[7,     7] loss: 1.299
[8,     7] loss: 1.291
[9,     7] loss: 1.278
[10,     7] loss: 1.265
[11,     7] loss: 1.242
[12,     7] loss: 1.242
[13,     7] loss: 1.227
[14,     7] loss: 1.211
[15,     7] loss: 1.190
[16,     7] loss: 1.184
[17,     7] loss: 1.171
[18,     7] loss: 1.181
[19,     7] loss: 1.194
[20,     7] loss: 1.189
[21,     7] loss: 1.169
[22,     7] loss: 1.150
[23,     7] loss: 1.148
[24,     7] loss: 1.147
[25,     7] loss: 1.144
[26,     7] loss: 1.152
[27,     7] loss: 1.140
[28,     7] loss: 1.115
[29,     7] loss: 1.131
[30,     7] loss: 1.104
[31,     7] loss: 1.119
[32,     7] loss: 1.129
[33,     7] loss: 1.106
[34,     7] loss: 1.120
[35,     7] loss: 1.117
[36,     7] loss: 1.153
[37,     7] loss: 1.122
[38,     7] loss: 1.102
[39,     7] loss: 1.119
[40,     7] loss: 1.096
[41,     7] loss: 1.094
[42,     7] loss: 1.149
[43,     7] loss: 1.127
[44,     7] loss: 1.092
[45,     7] loss: 1.121
[46,     7] loss: 1.114
[47,     7] loss: 1.104
[48,     7] loss: 1.100
[49,     7] loss: 1.095
[50,     7] loss: 1.099
[51,     7] loss: 1.134
Early stopping applied (best metric=0.4405660033226013)
Finished Training
Total time taken: 44.8432719707489
{'Methylation-R Validation Accuracy': 0.5024277757913759, 'Methylation-R Validation Sensitivity': 0.7944297082228117, 'Methylation-R Validation Specificity': 0.47543558282208587, 'Methylation-R Validation Precision': 0.13567989167735267, 'Methylation-R AUC ROC': 0.7354486077431175, 'Methylation-R AUC PR': 0.28708812991546095, 'Methylation-R MCC': 0.15379697404690162, 'Methylation-R F1': 0.22840061413818172, 'Validation Loss (Methylation-R)': 0.38607474565505984, 'Methylation-K Validation Accuracy': 0.520768405875501, 'Methylation-K Validation Sensitivity': 0.5812297734627832, 'Methylation-K Validation Specificity': 0.514228879007723, 'Methylation-K Validation Precision': 0.11214288190339776, 'Methylation-K AUC ROC': 0.5700749328332775, 'Methylation-K AUC PR': 0.13569737662924053, 'Methylation-K MCC': 0.05606885476914832, 'Methylation-K F1': 0.17997103749267493, 'Validation Loss (Methylation-K)': 0.4214413106441498, 'Validation Loss (total)': 0.8075160503387451, 'TimeToTrain': 74.26550922393798}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006879422315624127,
 'learning_rate_Methylation-K': 0.00404192924184963,
 'learning_rate_Methylation-R': 0.004072272586185223,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.43511812775334713,
 'loss_weight_Methylation-R': 0.6074425565230839,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4043974840,
 'sample_weights': [0.6215524052472443, 0.03620407463491343],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.68985423177804,
 'weight_decay_Methylation-K': 4.500158524953818,
 'weight_decay_Methylation-R': 9.884917152816001}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.385
[5,     7] loss: 1.373
[6,     7] loss: 1.346
[7,     7] loss: 1.343
[8,     7] loss: 1.323
[9,     7] loss: 1.312
[10,     7] loss: 1.294
[11,     7] loss: 1.300
[12,     7] loss: 1.279
[13,     7] loss: 1.288
[14,     7] loss: 1.266
[15,     7] loss: 1.277
[16,     7] loss: 1.300
[17,     7] loss: 1.278
[18,     7] loss: 1.262
[19,     7] loss: 1.289
[20,     7] loss: 1.265
[21,     7] loss: 1.267
[22,     7] loss: 1.286
[23,     7] loss: 1.283
[24,     7] loss: 1.287
[25,     7] loss: 1.255
[26,     7] loss: 1.244
[27,     7] loss: 1.241
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00909177513944477,
 'learning_rate_Methylation-K': 0.005118187631473302,
 'learning_rate_Methylation-R': 0.004744669361896582,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5372322667564944,
 'loss_weight_Methylation-R': 0.3913519149890335,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 906614722,
 'sample_weights': [0.6074425565230839, 0.43511812775334713],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.28529362962615873,
 'weight_decay_Methylation-K': 3.3653420150078075,
 'weight_decay_Methylation-R': 9.346094663406555}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009811259214558225,
 'learning_rate_Methylation-K': 0.00802392705135448,
 'learning_rate_Methylation-R': 0.007975780285266045,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.6128239325981155,
 'loss_weight_Methylation-R': 0.7080919503723612,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4166210138,
 'sample_weights': [0.3913519149890335, 0.5372322667564944],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.239048095192624,
 'weight_decay_Methylation-K': 5.541958076629229,
 'weight_decay_Methylation-R': 4.092645314717398}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009154277911281884,
 'learning_rate_Methylation-K': 0.0003271351585853004,
 'learning_rate_Methylation-R': 0.007360828548939548,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.29165557094531225,
 'loss_weight_Methylation-R': 0.2127560545845411,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1492028075,
 'sample_weights': [0.7080919503723612, 0.6128239325981155],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.819566893165254,
 'weight_decay_Methylation-K': 8.502512176884597,
 'weight_decay_Methylation-R': 4.688232387228986}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007833165862098462,
 'learning_rate_Methylation-K': 0.0031189472291862272,
 'learning_rate_Methylation-R': 0.007256423251980549,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.44695237996988,
 'loss_weight_Methylation-R': 0.6206171417225832,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2659748326,
 'sample_weights': [0.2127560545845411, 0.29165557094531225],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.025914445309372758,
 'weight_decay_Methylation-K': 9.500640737406169,
 'weight_decay_Methylation-R': 6.343104642188665}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.387
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009804301050730308,
 'learning_rate_Methylation-K': 0.005324608438543791,
 'learning_rate_Methylation-R': 0.005624322221669901,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.44756689296927665,
 'loss_weight_Methylation-R': 0.2109772982857067,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 359883632,
 'sample_weights': [0.6206171417225832, 0.44695237996988],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5648463716653875,
 'weight_decay_Methylation-K': 5.820776211041875,
 'weight_decay_Methylation-R': 9.64839906820665}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006634203243627564,
 'learning_rate_Methylation-K': 0.0012854623228436893,
 'learning_rate_Methylation-R': 0.00909812468833704,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07601314272543205,
 'loss_weight_Methylation-R': 0.9682087308295034,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4046901954,
 'sample_weights': [0.2109772982857067, 0.44756689296927665],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8237484373033555,
 'weight_decay_Methylation-K': 8.191846819341754,
 'weight_decay_Methylation-R': 5.8001272947382745}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009372784243303144,
 'learning_rate_Methylation-K': 0.004580179981926981,
 'learning_rate_Methylation-R': 0.003316476667960534,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.3155628082747082,
 'loss_weight_Methylation-R': 0.97203686988544,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3717473529,
 'sample_weights': [0.9682087308295034, 0.07601314272543205],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.493317681764932,
 'weight_decay_Methylation-K': 4.238603433032221,
 'weight_decay_Methylation-R': 5.423317646493581}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009736048071752497,
 'learning_rate_Methylation-K': 0.004284266207313739,
 'learning_rate_Methylation-R': 0.0072287709182673205,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.07081846680082972,
 'loss_weight_Methylation-R': 0.7191647215734904,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2530636268,
 'sample_weights': [0.97203686988544, 0.3155628082747082],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9709107648365223,
 'weight_decay_Methylation-K': 3.005458967485343,
 'weight_decay_Methylation-R': 8.41869920807994}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.393
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.387
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.387
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.387
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009672021465552317,
 'learning_rate_Methylation-K': 0.004694197445949763,
 'learning_rate_Methylation-R': 0.007212071062479421,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.5613444133218771,
 'loss_weight_Methylation-R': 0.28460560726859097,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1724663516,
 'sample_weights': [0.7191647215734904, 0.07081846680082972],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.537376027568179,
 'weight_decay_Methylation-K': 3.64292645524007,
 'weight_decay_Methylation-R': 9.664282669221729}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0070436377326388395,
 'learning_rate_Methylation-K': 0.002339636701724567,
 'learning_rate_Methylation-R': 0.0045120752466701365,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.08888091310056637,
 'loss_weight_Methylation-R': 0.8472000848118172,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2328132680,
 'sample_weights': [0.28460560726859097, 0.5613444133218771],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.458836583051628,
 'weight_decay_Methylation-K': 4.825593716531446,
 'weight_decay_Methylation-R': 4.5895052594757875}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008068214228370077,
 'learning_rate_Methylation-K': 0.0035118504691521017,
 'learning_rate_Methylation-R': 0.009858803616594289,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.039995687334404784,
 'loss_weight_Methylation-R': 0.7031691043566435,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2342825363,
 'sample_weights': [0.8472000848118172, 0.08888091310056637],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.384778197880395,
 'weight_decay_Methylation-K': 9.532940591111323,
 'weight_decay_Methylation-R': 8.169597342356969}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.385
[7,     7] loss: 1.368
[8,     7] loss: 1.350
[9,     7] loss: 1.339
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007921115014071941,
 'learning_rate_Methylation-K': 0.007454882196744696,
 'learning_rate_Methylation-R': 0.007508046381592744,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.7424302336140841,
 'loss_weight_Methylation-R': 0.5962631332241735,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 582466242,
 'sample_weights': [0.7031691043566435, 0.039995687334404784],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.32679809455684405,
 'weight_decay_Methylation-K': 6.9477417034655184,
 'weight_decay_Methylation-R': 8.055750693364791}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.391
[2,     7] loss: 1.386
[3,     7] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009626049749810836,
 'learning_rate_Methylation-K': 0.0012235471083049997,
 'learning_rate_Methylation-R': 0.0069631083297848635,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.2499341275513251,
 'loss_weight_Methylation-R': 0.531122594287313,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3301652087,
 'sample_weights': [0.5962631332241735, 0.7424302336140841],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7501733508547714,
 'weight_decay_Methylation-K': 9.940035108178437,
 'weight_decay_Methylation-R': 6.795174488754895}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.386
Early stopping applied (best metric=0.4452498257160187)
Finished Training
Total time taken: 47.21433758735657
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.388
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.386
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.387
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.387
[25,     7] loss: 1.386
[26,     7] loss: 1.387
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.387
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.386
[51,     7] loss: 1.386
[52,     7] loss: 1.387
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.387
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.386
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.386
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.386
[90,     7] loss: 1.387
[91,     7] loss: 1.386
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
[95,     7] loss: 1.386
[96,     7] loss: 1.386
[97,     7] loss: 1.386
[98,     7] loss: 1.386
[99,     7] loss: 1.386
[100,     7] loss: 1.386
[101,     7] loss: 1.386
[102,     7] loss: 1.386
[103,     7] loss: 1.386
[104,     7] loss: 1.386
[105,     7] loss: 1.386
[106,     7] loss: 1.386
[107,     7] loss: 1.386
[108,     7] loss: 1.387
[109,     7] loss: 1.386
Early stopping applied (best metric=0.4431924819946289)
Finished Training
Total time taken: 114.54510521888733
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.385
[6,     7] loss: 1.384
[7,     7] loss: 1.378
[8,     7] loss: 1.360
[9,     7] loss: 1.342
[10,     7] loss: 1.332
[11,     7] loss: 1.334
[12,     7] loss: 1.322
[13,     7] loss: 1.312
[14,     7] loss: 1.313
[15,     7] loss: 1.309
[16,     7] loss: 1.305
[17,     7] loss: 1.316
[18,     7] loss: 1.293
[19,     7] loss: 1.302
[20,     7] loss: 1.285
[21,     7] loss: 1.286
[22,     7] loss: 1.270
[23,     7] loss: 1.279
[24,     7] loss: 1.281
[25,     7] loss: 1.286
[26,     7] loss: 1.280
[27,     7] loss: 1.269
[28,     7] loss: 1.261
[29,     7] loss: 1.260
[30,     7] loss: 1.250
[31,     7] loss: 1.238
[32,     7] loss: 1.240
[33,     7] loss: 1.230
[34,     7] loss: 1.247
[35,     7] loss: 1.241
[36,     7] loss: 1.245
[37,     7] loss: 1.213
[38,     7] loss: 1.214
[39,     7] loss: 1.229
[40,     7] loss: 1.209
[41,     7] loss: 1.205
[42,     7] loss: 1.219
[43,     7] loss: 1.214
[44,     7] loss: 1.224
[45,     7] loss: 1.230
[46,     7] loss: 1.219
[47,     7] loss: 1.221
[48,     7] loss: 1.219
[49,     7] loss: 1.211
[50,     7] loss: 1.200
[51,     7] loss: 1.201
[52,     7] loss: 1.188
[53,     7] loss: 1.187
[54,     7] loss: 1.181
[55,     7] loss: 1.182
[56,     7] loss: 1.174
Early stopping applied (best metric=0.4427836835384369)
Finished Training
Total time taken: 59.31341218948364
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.383
[6,     7] loss: 1.370
[7,     7] loss: 1.343
[8,     7] loss: 1.332
[9,     7] loss: 1.327
[10,     7] loss: 1.328
[11,     7] loss: 1.314
[12,     7] loss: 1.312
[13,     7] loss: 1.311
[14,     7] loss: 1.306
[15,     7] loss: 1.299
[16,     7] loss: 1.293
[17,     7] loss: 1.297
[18,     7] loss: 1.289
[19,     7] loss: 1.291
[20,     7] loss: 1.286
[21,     7] loss: 1.276
[22,     7] loss: 1.265
[23,     7] loss: 1.257
[24,     7] loss: 1.262
[25,     7] loss: 1.240
[26,     7] loss: 1.250
[27,     7] loss: 1.240
[28,     7] loss: 1.255
[29,     7] loss: 1.239
[30,     7] loss: 1.235
[31,     7] loss: 1.259
[32,     7] loss: 1.242
[33,     7] loss: 1.221
[34,     7] loss: 1.239
[35,     7] loss: 1.241
[36,     7] loss: 1.218
[37,     7] loss: 1.203
[38,     7] loss: 1.209
[39,     7] loss: 1.221
[40,     7] loss: 1.217
[41,     7] loss: 1.194
[42,     7] loss: 1.209
[43,     7] loss: 1.203
[44,     7] loss: 1.192
[45,     7] loss: 1.197
[46,     7] loss: 1.208
[47,     7] loss: 1.189
[48,     7] loss: 1.177
[49,     7] loss: 1.181
[50,     7] loss: 1.194
[51,     7] loss: 1.187
[52,     7] loss: 1.184
[53,     7] loss: 1.180
[54,     7] loss: 1.198
Early stopping applied (best metric=0.43946585059165955)
Finished Training
Total time taken: 60.311076641082764
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.386
[7,     7] loss: 1.387
[8,     7] loss: 1.386
[9,     7] loss: 1.386
[10,     7] loss: 1.386
[11,     7] loss: 1.386
[12,     7] loss: 1.386
[13,     7] loss: 1.386
[14,     7] loss: 1.386
[15,     7] loss: 1.386
[16,     7] loss: 1.386
[17,     7] loss: 1.386
[18,     7] loss: 1.386
[19,     7] loss: 1.386
[20,     7] loss: 1.386
[21,     7] loss: 1.386
[22,     7] loss: 1.386
[23,     7] loss: 1.386
[24,     7] loss: 1.386
[25,     7] loss: 1.386
[26,     7] loss: 1.386
[27,     7] loss: 1.386
[28,     7] loss: 1.386
[29,     7] loss: 1.386
[30,     7] loss: 1.386
[31,     7] loss: 1.386
[32,     7] loss: 1.386
[33,     7] loss: 1.386
[34,     7] loss: 1.386
[35,     7] loss: 1.386
[36,     7] loss: 1.386
[37,     7] loss: 1.386
[38,     7] loss: 1.386
[39,     7] loss: 1.386
[40,     7] loss: 1.386
[41,     7] loss: 1.386
[42,     7] loss: 1.386
[43,     7] loss: 1.386
[44,     7] loss: 1.386
[45,     7] loss: 1.386
[46,     7] loss: 1.386
[47,     7] loss: 1.386
[48,     7] loss: 1.386
[49,     7] loss: 1.386
[50,     7] loss: 1.387
[51,     7] loss: 1.386
[52,     7] loss: 1.386
[53,     7] loss: 1.386
[54,     7] loss: 1.386
[55,     7] loss: 1.386
[56,     7] loss: 1.386
[57,     7] loss: 1.386
[58,     7] loss: 1.386
[59,     7] loss: 1.386
[60,     7] loss: 1.386
[61,     7] loss: 1.386
[62,     7] loss: 1.386
[63,     7] loss: 1.386
[64,     7] loss: 1.386
[65,     7] loss: 1.386
[66,     7] loss: 1.386
[67,     7] loss: 1.386
[68,     7] loss: 1.387
[69,     7] loss: 1.386
[70,     7] loss: 1.386
[71,     7] loss: 1.386
[72,     7] loss: 1.386
[73,     7] loss: 1.386
[74,     7] loss: 1.386
[75,     7] loss: 1.386
[76,     7] loss: 1.386
[77,     7] loss: 1.386
[78,     7] loss: 1.386
[79,     7] loss: 1.386
[80,     7] loss: 1.386
[81,     7] loss: 1.386
[82,     7] loss: 1.386
[83,     7] loss: 1.386
[84,     7] loss: 1.386
[85,     7] loss: 1.386
[86,     7] loss: 1.387
[87,     7] loss: 1.386
[88,     7] loss: 1.386
[89,     7] loss: 1.387
[90,     7] loss: 1.386
[91,     7] loss: 1.386
[92,     7] loss: 1.386
[93,     7] loss: 1.386
[94,     7] loss: 1.386
[95,     7] loss: 1.386
[96,     7] loss: 1.386
[97,     7] loss: 1.386
[98,     7] loss: 1.386
[99,     7] loss: 1.386
[100,     7] loss: 1.386
[101,     7] loss: 1.386
[102,     7] loss: 1.386
[103,     7] loss: 1.386
[104,     7] loss: 1.387
[105,     7] loss: 1.386
[106,     7] loss: 1.386
[107,     7] loss: 1.386
[108,     7] loss: 1.386
[109,     7] loss: 1.386
[110,     7] loss: 1.386
[111,     7] loss: 1.386
[112,     7] loss: 1.386
[113,     7] loss: 1.386
[114,     7] loss: 1.386
[115,     7] loss: 1.386
[116,     7] loss: 1.386
[117,     7] loss: 1.386
Early stopping applied (best metric=0.4438333809375763)
Finished Training
Total time taken: 120.81119084358215
{'Methylation-R Validation Accuracy': 0.0865697344616365, 'Methylation-R Validation Sensitivity': 0.9984084880636604, 'Methylation-R Validation Specificity': 0.0022331288343558284, 'Methylation-R Validation Precision': 0.08471075976914172, 'Methylation-R AUC ROC': 0.5609193178304666, 'Methylation-R AUC PR': 0.3190007216587748, 'Methylation-R MCC': 0.0017208396546171574, 'Methylation-R F1': 0.15617083086146447, 'Validation Loss (Methylation-R)': 0.42732738256454467, 'Methylation-K Validation Accuracy': 0.10529284375156983, 'Methylation-K Validation Sensitivity': 0.9902912621359223, 'Methylation-K Validation Specificity': 0.0093142990872923, 'Methylation-K Validation Precision': 0.09780355350438015, 'Methylation-K AUC ROC': 0.48988148659794284, 'Methylation-K AUC PR': 0.2766471389023407, 'Methylation-K MCC': -0.0005550794845922969, 'Methylation-K F1': 0.17801955885429607, 'Validation Loss (Methylation-K)': 0.44290504455566404, 'Validation Loss (total)': 0.8702324271202088, 'TimeToTrain': 80.43902449607849}
{'CNNType': 'Musite',
 'CV_Repeats': 1,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008518667841228006,
 'learning_rate_Methylation-K': 0.0022674961538612162,
 'learning_rate_Methylation-R': 0.006012203085884905,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.4019366301484363,
 'loss_weight_Methylation-R': 0.11898340469639776,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3682679044,
 'sample_weights': [0.531122594287313, 0.2499341275513251],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.127821645993314,
 'weight_decay_Methylation-K': 4.822823301121168,
 'weight_decay_Methylation-R': 9.193562538664318}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 5,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-R': [1e-05, 0.01],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-R': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Methylation-K': [0, 10],
                  'weight_decay_Methylation-R': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Methylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Methylation-R', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003662719046686193,
 'learning_rate_Methylation-K': 0.000884349934580072,
 'learning_rate_Methylation-R': 0.0015559816554853042,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Methylation-K': 0.12507645059825023,
 'loss_weight_Methylation-R': 0.942802226841444,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 397456092,
 'sample_weights': [0.11898340469639776, 0.4019366301484363],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.650775207838844,
 'weight_decay_Methylation-K': 5.109977756977147,
 'weight_decay_Methylation-R': 8.648151857081196}
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.380
[3,     7] loss: 1.344
[4,     7] loss: 1.323
[5,     7] loss: 1.318
[6,     7] loss: 1.304
[7,     7] loss: 1.307
[8,     7] loss: 1.272
[9,     7] loss: 1.268
[10,     7] loss: 1.273
[11,     7] loss: 1.256
[12,     7] loss: 1.259
[13,     7] loss: 1.247
[14,     7] loss: 1.244
[15,     7] loss: 1.228
[16,     7] loss: 1.234
[17,     7] loss: 1.235
[18,     7] loss: 1.227
[19,     7] loss: 1.222
[20,     7] loss: 1.232
[21,     7] loss: 1.258
[22,     7] loss: 1.229
[23,     7] loss: 1.207
[24,     7] loss: 1.190
[25,     7] loss: 1.196
[26,     7] loss: 1.239
[27,     7] loss: 1.199
[28,     7] loss: 1.206
[29,     7] loss: 1.200
[30,     7] loss: 1.185
[31,     7] loss: 1.233
[32,     7] loss: 1.200
[33,     7] loss: 1.184
[34,     7] loss: 1.186
[35,     7] loss: 1.174
[36,     7] loss: 1.243
[37,     7] loss: 1.260
[38,     7] loss: 1.230
[39,     7] loss: 1.212
[40,     7] loss: 1.192
[41,     7] loss: 1.206
[42,     7] loss: 1.180
[43,     7] loss: 1.193
[44,     7] loss: 1.182
[45,     7] loss: 1.168
[46,     7] loss: 1.202
[47,     7] loss: 1.199
[48,     7] loss: 1.191
[49,     7] loss: 1.182
[50,     7] loss: 1.177
[51,     7] loss: 1.160
[52,     7] loss: 1.160
[53,     7] loss: 1.180
[54,     7] loss: 1.211
[55,     7] loss: 1.171
[56,     7] loss: 1.163
[57,     7] loss: 1.166
[58,     7] loss: 1.142
[59,     7] loss: 1.221
[60,     7] loss: 1.238
[61,     7] loss: 1.283
[62,     7] loss: 1.248
[63,     7] loss: 1.218
[64,     7] loss: 1.196
[65,     7] loss: 1.164
[66,     7] loss: 1.164
[67,     7] loss: 1.167
[68,     7] loss: 1.184
[69,     7] loss: 1.173
[70,     7] loss: 1.183
[71,     7] loss: 1.193
[72,     7] loss: 1.154
[73,     7] loss: 1.188
[74,     7] loss: 1.194
[75,     7] loss: 1.163
[76,     7] loss: 1.166
[77,     7] loss: 1.163
[78,     7] loss: 1.167
[79,     7] loss: 1.198
[80,     7] loss: 1.198
[81,     7] loss: 1.179
[82,     7] loss: 1.169
[83,     7] loss: 1.182
[84,     7] loss: 1.151
[85,     7] loss: 1.146
[86,     7] loss: 1.167
[87,     7] loss: 1.196
[88,     7] loss: 1.173
[89,     7] loss: 1.151
[90,     7] loss: 1.166
[91,     7] loss: 1.152
[92,     7] loss: 1.186
[93,     7] loss: 1.166
[94,     7] loss: 1.148
[95,     7] loss: 1.151
[96,     7] loss: 1.161
[97,     7] loss: 1.160
[98,     7] loss: 1.161
[99,     7] loss: 1.161
[100,     7] loss: 1.163
[101,     7] loss: 1.163
[102,     7] loss: 1.178
[103,     7] loss: 1.186
[104,     7] loss: 1.147
[105,     7] loss: 1.153
[106,     7] loss: 1.146
[107,     7] loss: 1.197
[108,     7] loss: 1.178
[109,     7] loss: 1.147
[110,     7] loss: 1.158
[111,     7] loss: 1.152
[112,     7] loss: 1.137
[113,     7] loss: 1.163
[114,     7] loss: 1.146
[115,     7] loss: 1.174
[116,     7] loss: 1.152
[117,     7] loss: 1.178
[118,     7] loss: 1.178
[119,     7] loss: 1.177
[120,     7] loss: 1.264
[121,     7] loss: 1.214
[122,     7] loss: 1.165
[123,     7] loss: 1.156
[124,     7] loss: 1.155
[125,     7] loss: 1.196
[126,     7] loss: 1.150
[127,     7] loss: 1.148
[128,     7] loss: 1.158
Early stopping applied (best metric=0.3534848690032959)
Finished Training
Total time taken: 125.07123494148254
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.382
[3,     7] loss: 1.361
[4,     7] loss: 1.343
[5,     7] loss: 1.324
[6,     7] loss: 1.299
[7,     7] loss: 1.292
[8,     7] loss: 1.279
[9,     7] loss: 1.256
[10,     7] loss: 1.258
[11,     7] loss: 1.250
[12,     7] loss: 1.272
[13,     7] loss: 1.260
[14,     7] loss: 1.264
[15,     7] loss: 1.241
[16,     7] loss: 1.236
[17,     7] loss: 1.233
[18,     7] loss: 1.209
[19,     7] loss: 1.246
[20,     7] loss: 1.218
[21,     7] loss: 1.222
[22,     7] loss: 1.198
[23,     7] loss: 1.197
[24,     7] loss: 1.186
[25,     7] loss: 1.198
[26,     7] loss: 1.198
[27,     7] loss: 1.212
[28,     7] loss: 1.179
[29,     7] loss: 1.172
[30,     7] loss: 1.196
[31,     7] loss: 1.192
[32,     7] loss: 1.163
[33,     7] loss: 1.194
[34,     7] loss: 1.171
[35,     7] loss: 1.173
[36,     7] loss: 1.212
[37,     7] loss: 1.165
[38,     7] loss: 1.149
[39,     7] loss: 1.151
[40,     7] loss: 1.199
[41,     7] loss: 1.286
[42,     7] loss: 1.241
[43,     7] loss: 1.214
[44,     7] loss: 1.167
[45,     7] loss: 1.173
[46,     7] loss: 1.179
[47,     7] loss: 1.151
[48,     7] loss: 1.193
[49,     7] loss: 1.198
[50,     7] loss: 1.191
[51,     7] loss: 1.212
[52,     7] loss: 1.172
[53,     7] loss: 1.186
[54,     7] loss: 1.131
[55,     7] loss: 1.147
[56,     7] loss: 1.200
[57,     7] loss: 1.190
[58,     7] loss: 1.178
[59,     7] loss: 1.167
[60,     7] loss: 1.164
[61,     7] loss: 1.136
[62,     7] loss: 1.145
[63,     7] loss: 1.180
[64,     7] loss: 1.197
[65,     7] loss: 1.179
[66,     7] loss: 1.164
[67,     7] loss: 1.143
[68,     7] loss: 1.155
[69,     7] loss: 1.154
[70,     7] loss: 1.196
[71,     7] loss: 1.164
[72,     7] loss: 1.181
[73,     7] loss: 1.150
[74,     7] loss: 1.150
[75,     7] loss: 1.166
[76,     7] loss: 1.139
[77,     7] loss: 1.168
[78,     7] loss: 1.135
[79,     7] loss: 1.167
[80,     7] loss: 1.209
[81,     7] loss: 1.218
[82,     7] loss: 1.167
[83,     7] loss: 1.155
[84,     7] loss: 1.175
[85,     7] loss: 1.167
[86,     7] loss: 1.140
[87,     7] loss: 1.174
[88,     7] loss: 1.183
[89,     7] loss: 1.166
[90,     7] loss: 1.157
[91,     7] loss: 1.150
[92,     7] loss: 1.159
[93,     7] loss: 1.155
[94,     7] loss: 1.154
[95,     7] loss: 1.142
[96,     7] loss: 1.167
Early stopping applied (best metric=0.3608778715133667)
Finished Training
Total time taken: 93.76449632644653
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.386
[3,     7] loss: 1.384
[4,     7] loss: 1.373
[5,     7] loss: 1.339
[6,     7] loss: 1.335
[7,     7] loss: 1.313
[8,     7] loss: 1.302
[9,     7] loss: 1.287
[10,     7] loss: 1.282
[11,     7] loss: 1.294
[12,     7] loss: 1.304
[13,     7] loss: 1.265
[14,     7] loss: 1.246
[15,     7] loss: 1.258
[16,     7] loss: 1.249
[17,     7] loss: 1.255
[18,     7] loss: 1.238
[19,     7] loss: 1.227
[20,     7] loss: 1.244
[21,     7] loss: 1.233
[22,     7] loss: 1.237
[23,     7] loss: 1.226
[24,     7] loss: 1.235
[25,     7] loss: 1.228
[26,     7] loss: 1.233
[27,     7] loss: 1.209
[28,     7] loss: 1.209
[29,     7] loss: 1.206
[30,     7] loss: 1.207
[31,     7] loss: 1.218
[32,     7] loss: 1.215
[33,     7] loss: 1.204
[34,     7] loss: 1.189
[35,     7] loss: 1.250
[36,     7] loss: 1.219
[37,     7] loss: 1.197
[38,     7] loss: 1.186
[39,     7] loss: 1.214
[40,     7] loss: 1.246
[41,     7] loss: 1.195
[42,     7] loss: 1.180
[43,     7] loss: 1.152
[44,     7] loss: 1.242
[45,     7] loss: 1.213
[46,     7] loss: 1.179
[47,     7] loss: 1.172
[48,     7] loss: 1.167
[49,     7] loss: 1.169
[50,     7] loss: 1.234
[51,     7] loss: 1.178
[52,     7] loss: 1.163
[53,     7] loss: 1.158
[54,     7] loss: 1.183
[55,     7] loss: 1.192
[56,     7] loss: 1.172
[57,     7] loss: 1.186
[58,     7] loss: 1.141
[59,     7] loss: 1.163
[60,     7] loss: 1.151
[61,     7] loss: 1.147
[62,     7] loss: 1.162
[63,     7] loss: 1.176
[64,     7] loss: 1.160
[65,     7] loss: 1.160
[66,     7] loss: 1.149
[67,     7] loss: 1.134
[68,     7] loss: 1.149
[69,     7] loss: 1.189
[70,     7] loss: 1.222
[71,     7] loss: 1.197
[72,     7] loss: 1.165
[73,     7] loss: 1.152
[74,     7] loss: 1.148
[75,     7] loss: 1.154
[76,     7] loss: 1.145
[77,     7] loss: 1.156
[78,     7] loss: 1.136
[79,     7] loss: 1.198
[80,     7] loss: 1.191
[81,     7] loss: 1.159
[82,     7] loss: 1.152
[83,     7] loss: 1.162
[84,     7] loss: 1.154
[85,     7] loss: 1.182
[86,     7] loss: 1.187
[87,     7] loss: 1.160
[88,     7] loss: 1.146
Early stopping applied (best metric=0.3823249340057373)
Finished Training
Total time taken: 84.32597780227661
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.388
[3,     7] loss: 1.387
[4,     7] loss: 1.387
[5,     7] loss: 1.385
[6,     7] loss: 1.378
[7,     7] loss: 1.351
[8,     7] loss: 1.337
[9,     7] loss: 1.336
[10,     7] loss: 1.298
[11,     7] loss: 1.287
[12,     7] loss: 1.292
[13,     7] loss: 1.271
[14,     7] loss: 1.267
[15,     7] loss: 1.256
[16,     7] loss: 1.267
[17,     7] loss: 1.252
[18,     7] loss: 1.257
[19,     7] loss: 1.252
[20,     7] loss: 1.233
[21,     7] loss: 1.248
[22,     7] loss: 1.270
[23,     7] loss: 1.248
[24,     7] loss: 1.240
[25,     7] loss: 1.241
[26,     7] loss: 1.210
[27,     7] loss: 1.228
[28,     7] loss: 1.237
[29,     7] loss: 1.212
[30,     7] loss: 1.206
[31,     7] loss: 1.204
[32,     7] loss: 1.231
[33,     7] loss: 1.260
[34,     7] loss: 1.231
[35,     7] loss: 1.209
[36,     7] loss: 1.206
[37,     7] loss: 1.211
[38,     7] loss: 1.242
[39,     7] loss: 1.234
[40,     7] loss: 1.208
[41,     7] loss: 1.185
[42,     7] loss: 1.249
[43,     7] loss: 1.219
[44,     7] loss: 1.200
[45,     7] loss: 1.198
[46,     7] loss: 1.203
[47,     7] loss: 1.199
[48,     7] loss: 1.188
[49,     7] loss: 1.192
[50,     7] loss: 1.180
[51,     7] loss: 1.253
[52,     7] loss: 1.217
[53,     7] loss: 1.205
[54,     7] loss: 1.182
[55,     7] loss: 1.237
[56,     7] loss: 1.192
[57,     7] loss: 1.170
[58,     7] loss: 1.172
[59,     7] loss: 1.179
[60,     7] loss: 1.184
[61,     7] loss: 1.198
[62,     7] loss: 1.168
[63,     7] loss: 1.143
[64,     7] loss: 1.155
[65,     7] loss: 1.172
[66,     7] loss: 1.140
[67,     7] loss: 1.153
[68,     7] loss: 1.170
[69,     7] loss: 1.159
[70,     7] loss: 1.139
[71,     7] loss: 1.216
[72,     7] loss: 1.174
[73,     7] loss: 1.138
[74,     7] loss: 1.160
[75,     7] loss: 1.129
[76,     7] loss: 1.160
[77,     7] loss: 1.178
[78,     7] loss: 1.193
[79,     7] loss: 1.180
[80,     7] loss: 1.151
[81,     7] loss: 1.161
[82,     7] loss: 1.158
[83,     7] loss: 1.135
[84,     7] loss: 1.130
[85,     7] loss: 1.159
[86,     7] loss: 1.138
[87,     7] loss: 1.145
[88,     7] loss: 1.140
[89,     7] loss: 1.123
[90,     7] loss: 1.143
[91,     7] loss: 1.144
Early stopping applied (best metric=0.3785867989063263)
Finished Training
Total time taken: 85.50187087059021
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.380
[5,     7] loss: 1.348
[6,     7] loss: 1.326
[7,     7] loss: 1.310
[8,     7] loss: 1.298
[9,     7] loss: 1.278
[10,     7] loss: 1.276
[11,     7] loss: 1.288
[12,     7] loss: 1.259
[13,     7] loss: 1.269
[14,     7] loss: 1.251
[15,     7] loss: 1.252
[16,     7] loss: 1.250
[17,     7] loss: 1.254
[18,     7] loss: 1.235
[19,     7] loss: 1.225
[20,     7] loss: 1.241
[21,     7] loss: 1.244
[22,     7] loss: 1.223
[23,     7] loss: 1.196
[24,     7] loss: 1.230
[25,     7] loss: 1.212
[26,     7] loss: 1.207
[27,     7] loss: 1.253
[28,     7] loss: 1.236
[29,     7] loss: 1.208
[30,     7] loss: 1.208
[31,     7] loss: 1.204
[32,     7] loss: 1.219
[33,     7] loss: 1.203
[34,     7] loss: 1.194
[35,     7] loss: 1.184
[36,     7] loss: 1.208
[37,     7] loss: 1.179
[38,     7] loss: 1.203
[39,     7] loss: 1.182
[40,     7] loss: 1.183
[41,     7] loss: 1.177
[42,     7] loss: 1.183
[43,     7] loss: 1.188
[44,     7] loss: 1.192
[45,     7] loss: 1.188
[46,     7] loss: 1.177
[47,     7] loss: 1.175
[48,     7] loss: 1.195
[49,     7] loss: 1.205
[50,     7] loss: 1.236
[51,     7] loss: 1.193
[52,     7] loss: 1.199
[53,     7] loss: 1.191
[54,     7] loss: 1.156
[55,     7] loss: 1.158
[56,     7] loss: 1.176
[57,     7] loss: 1.210
[58,     7] loss: 1.196
[59,     7] loss: 1.184
[60,     7] loss: 1.193
[61,     7] loss: 1.184
[62,     7] loss: 1.174
[63,     7] loss: 1.220
[64,     7] loss: 1.210
[65,     7] loss: 1.180
[66,     7] loss: 1.181
[67,     7] loss: 1.178
[68,     7] loss: 1.166
[69,     7] loss: 1.152
[70,     7] loss: 1.189
[71,     7] loss: 1.182
[72,     7] loss: 1.189
[73,     7] loss: 1.167
[74,     7] loss: 1.186
[75,     7] loss: 1.223
[76,     7] loss: 1.197
[77,     7] loss: 1.153
[78,     7] loss: 1.165
[79,     7] loss: 1.215
[80,     7] loss: 1.199
[81,     7] loss: 1.184
[82,     7] loss: 1.148
[83,     7] loss: 1.184
[84,     7] loss: 1.164
[85,     7] loss: 1.158
[86,     7] loss: 1.177
[87,     7] loss: 1.168
[88,     7] loss: 1.195
[89,     7] loss: 1.202
[90,     7] loss: 1.168
[91,     7] loss: 1.169
[92,     7] loss: 1.215
[93,     7] loss: 1.187
[94,     7] loss: 1.205
[95,     7] loss: 1.150
[96,     7] loss: 1.187
[97,     7] loss: 1.201
[98,     7] loss: 1.176
[99,     7] loss: 1.159
[100,     7] loss: 1.155
[101,     7] loss: 1.148
[102,     7] loss: 1.158
[103,     7] loss: 1.170
[104,     7] loss: 1.173
[105,     7] loss: 1.151
[106,     7] loss: 1.144
[107,     7] loss: 1.162
[108,     7] loss: 1.161
[109,     7] loss: 1.179
[110,     7] loss: 1.168
[111,     7] loss: 1.163
[112,     7] loss: 1.193
[113,     7] loss: 1.165
[114,     7] loss: 1.205
[115,     7] loss: 1.177
[116,     7] loss: 1.205
[117,     7] loss: 1.184
[118,     7] loss: 1.159
[119,     7] loss: 1.166
[120,     7] loss: 1.174
[121,     7] loss: 1.163
[122,     7] loss: 1.176
[123,     7] loss: 1.176
[124,     7] loss: 1.160
[125,     7] loss: 1.147
[126,     7] loss: 1.167
[127,     7] loss: 1.137
[128,     7] loss: 1.154
[129,     7] loss: 1.189
[130,     7] loss: 1.209
[131,     7] loss: 1.179
[132,     7] loss: 1.174
[133,     7] loss: 1.150
[134,     7] loss: 1.143
[135,     7] loss: 1.183
[136,     7] loss: 1.205
[137,     7] loss: 1.179
[138,     7] loss: 1.163
[139,     7] loss: 1.170
[140,     7] loss: 1.163
Early stopping applied (best metric=0.3532487154006958)
Finished Training
Total time taken: 131.46027135849
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.386
[3,     7] loss: 1.386
[4,     7] loss: 1.378
[5,     7] loss: 1.347
[6,     7] loss: 1.318
[7,     7] loss: 1.314
[8,     7] loss: 1.310
[9,     7] loss: 1.307
[10,     7] loss: 1.288
[11,     7] loss: 1.275
[12,     7] loss: 1.264
[13,     7] loss: 1.259
[14,     7] loss: 1.256
[15,     7] loss: 1.263
[16,     7] loss: 1.244
[17,     7] loss: 1.235
[18,     7] loss: 1.244
[19,     7] loss: 1.252
[20,     7] loss: 1.242
[21,     7] loss: 1.228
[22,     7] loss: 1.218
[23,     7] loss: 1.235
[24,     7] loss: 1.251
[25,     7] loss: 1.228
[26,     7] loss: 1.220
[27,     7] loss: 1.204
[28,     7] loss: 1.207
[29,     7] loss: 1.199
[30,     7] loss: 1.201
[31,     7] loss: 1.207
[32,     7] loss: 1.195
[33,     7] loss: 1.205
[34,     7] loss: 1.216
[35,     7] loss: 1.224
[36,     7] loss: 1.201
[37,     7] loss: 1.187
[38,     7] loss: 1.183
[39,     7] loss: 1.191
[40,     7] loss: 1.200
[41,     7] loss: 1.199
[42,     7] loss: 1.206
[43,     7] loss: 1.172
[44,     7] loss: 1.171
[45,     7] loss: 1.166
[46,     7] loss: 1.207
[47,     7] loss: 1.175
[48,     7] loss: 1.213
[49,     7] loss: 1.257
[50,     7] loss: 1.212
[51,     7] loss: 1.185
[52,     7] loss: 1.178
[53,     7] loss: 1.176
[54,     7] loss: 1.218
[55,     7] loss: 1.220
[56,     7] loss: 1.177
[57,     7] loss: 1.187
[58,     7] loss: 1.181
[59,     7] loss: 1.152
[60,     7] loss: 1.248
[61,     7] loss: 1.301
[62,     7] loss: 1.276
[63,     7] loss: 1.248
[64,     7] loss: 1.211
[65,     7] loss: 1.179
[66,     7] loss: 1.174
[67,     7] loss: 1.177
[68,     7] loss: 1.211
[69,     7] loss: 1.217
[70,     7] loss: 1.211
[71,     7] loss: 1.177
[72,     7] loss: 1.148
[73,     7] loss: 1.221
[74,     7] loss: 1.173
[75,     7] loss: 1.180
[76,     7] loss: 1.187
[77,     7] loss: 1.169
[78,     7] loss: 1.168
[79,     7] loss: 1.165
[80,     7] loss: 1.156
[81,     7] loss: 1.176
[82,     7] loss: 1.171
[83,     7] loss: 1.168
[84,     7] loss: 1.161
[85,     7] loss: 1.156
[86,     7] loss: 1.167
[87,     7] loss: 1.183
[88,     7] loss: 1.200
[89,     7] loss: 1.171
[90,     7] loss: 1.196
[91,     7] loss: 1.192
[92,     7] loss: 1.259
[93,     7] loss: 1.203
[94,     7] loss: 1.179
[95,     7] loss: 1.144
[96,     7] loss: 1.176
[97,     7] loss: 1.164
[98,     7] loss: 1.169
[99,     7] loss: 1.161
[100,     7] loss: 1.157
[101,     7] loss: 1.193
[102,     7] loss: 1.175
[103,     7] loss: 1.160
[104,     7] loss: 1.167
[105,     7] loss: 1.157
[106,     7] loss: 1.171
[107,     7] loss: 1.196
[108,     7] loss: 1.173
[109,     7] loss: 1.172
[110,     7] loss: 1.157
[111,     7] loss: 1.176
[112,     7] loss: 1.162
[113,     7] loss: 1.161
[114,     7] loss: 1.169
[115,     7] loss: 1.143
[116,     7] loss: 1.156
[117,     7] loss: 1.163
[118,     7] loss: 1.162
[119,     7] loss: 1.176
[120,     7] loss: 1.188
[121,     7] loss: 1.156
[122,     7] loss: 1.147
[123,     7] loss: 1.177
[124,     7] loss: 1.182
[125,     7] loss: 1.168
Early stopping applied (best metric=0.35137128829956055)
Finished Training
Total time taken: 119.95483350753784
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.383
[4,     7] loss: 1.366
[5,     7] loss: 1.337
[6,     7] loss: 1.323
[7,     7] loss: 1.306
[8,     7] loss: 1.288
[9,     7] loss: 1.275
[10,     7] loss: 1.278
[11,     7] loss: 1.272
[12,     7] loss: 1.268
[13,     7] loss: 1.286
[14,     7] loss: 1.272
[15,     7] loss: 1.257
[16,     7] loss: 1.240
[17,     7] loss: 1.229
[18,     7] loss: 1.251
[19,     7] loss: 1.241
[20,     7] loss: 1.225
[21,     7] loss: 1.234
[22,     7] loss: 1.232
[23,     7] loss: 1.224
[24,     7] loss: 1.216
[25,     7] loss: 1.209
[26,     7] loss: 1.223
[27,     7] loss: 1.212
[28,     7] loss: 1.208
[29,     7] loss: 1.227
[30,     7] loss: 1.209
[31,     7] loss: 1.193
[32,     7] loss: 1.209
[33,     7] loss: 1.190
[34,     7] loss: 1.182
[35,     7] loss: 1.180
[36,     7] loss: 1.194
[37,     7] loss: 1.202
[38,     7] loss: 1.197
[39,     7] loss: 1.181
[40,     7] loss: 1.170
[41,     7] loss: 1.169
[42,     7] loss: 1.171
[43,     7] loss: 1.189
[44,     7] loss: 1.208
[45,     7] loss: 1.212
[46,     7] loss: 1.186
[47,     7] loss: 1.189
[48,     7] loss: 1.203
[49,     7] loss: 1.205
[50,     7] loss: 1.178
[51,     7] loss: 1.166
[52,     7] loss: 1.161
[53,     7] loss: 1.148
[54,     7] loss: 1.152
[55,     7] loss: 1.234
[56,     7] loss: 1.205
[57,     7] loss: 1.171
[58,     7] loss: 1.168
[59,     7] loss: 1.153
[60,     7] loss: 1.239
[61,     7] loss: 1.207
[62,     7] loss: 1.178
[63,     7] loss: 1.165
[64,     7] loss: 1.184
[65,     7] loss: 1.170
[66,     7] loss: 1.177
[67,     7] loss: 1.214
[68,     7] loss: 1.180
[69,     7] loss: 1.168
[70,     7] loss: 1.146
[71,     7] loss: 1.173
[72,     7] loss: 1.236
[73,     7] loss: 1.229
[74,     7] loss: 1.198
[75,     7] loss: 1.173
[76,     7] loss: 1.168
[77,     7] loss: 1.192
[78,     7] loss: 1.165
[79,     7] loss: 1.163
[80,     7] loss: 1.201
[81,     7] loss: 1.175
[82,     7] loss: 1.179
[83,     7] loss: 1.166
[84,     7] loss: 1.189
[85,     7] loss: 1.162
[86,     7] loss: 1.149
[87,     7] loss: 1.184
[88,     7] loss: 1.176
[89,     7] loss: 1.153
[90,     7] loss: 1.151
[91,     7] loss: 1.147
[92,     7] loss: 1.159
[93,     7] loss: 1.159
[94,     7] loss: 1.145
[95,     7] loss: 1.157
[96,     7] loss: 1.153
[97,     7] loss: 1.162
[98,     7] loss: 1.142
[99,     7] loss: 1.149
[100,     7] loss: 1.144
[101,     7] loss: 1.163
[102,     7] loss: 1.153
[103,     7] loss: 1.151
[104,     7] loss: 1.226
[105,     7] loss: 1.236
[106,     7] loss: 1.175
[107,     7] loss: 1.194
[108,     7] loss: 1.167
[109,     7] loss: 1.148
[110,     7] loss: 1.161
[111,     7] loss: 1.129
[112,     7] loss: 1.169
[113,     7] loss: 1.228
[114,     7] loss: 1.245
[115,     7] loss: 1.200
[116,     7] loss: 1.169
[117,     7] loss: 1.181
[118,     7] loss: 1.146
[119,     7] loss: 1.143
[120,     7] loss: 1.152
[121,     7] loss: 1.159
[122,     7] loss: 1.147
[123,     7] loss: 1.203
[124,     7] loss: 1.160
[125,     7] loss: 1.162
[126,     7] loss: 1.195
[127,     7] loss: 1.168
[128,     7] loss: 1.131
[129,     7] loss: 1.158
[130,     7] loss: 1.172
[131,     7] loss: 1.220
[132,     7] loss: 1.193
[133,     7] loss: 1.180
[134,     7] loss: 1.150
[135,     7] loss: 1.148
[136,     7] loss: 1.143
[137,     7] loss: 1.151
[138,     7] loss: 1.191
[139,     7] loss: 1.206
[140,     7] loss: 1.183
[141,     7] loss: 1.159
[142,     7] loss: 1.152
[143,     7] loss: 1.140
[144,     7] loss: 1.139
[145,     7] loss: 1.204
[146,     7] loss: 1.222
[147,     7] loss: 1.175
[148,     7] loss: 1.187
[149,     7] loss: 1.179
[150,     7] loss: 1.161
[151,     7] loss: 1.145
[152,     7] loss: 1.171
[153,     7] loss: 1.191
[154,     7] loss: 1.179
[155,     7] loss: 1.166
[156,     7] loss: 1.153
[157,     7] loss: 1.146
[158,     7] loss: 1.148
[159,     7] loss: 1.151
[160,     7] loss: 1.162
[161,     7] loss: 1.171
[162,     7] loss: 1.168
[163,     7] loss: 1.147
[164,     7] loss: 1.174
[165,     7] loss: 1.198
[166,     7] loss: 1.202
[167,     7] loss: 1.168
[168,     7] loss: 1.158
[169,     7] loss: 1.139
[170,     7] loss: 1.152
Early stopping applied (best metric=0.3511817157268524)
Finished Training
Total time taken: 170.8984501361847
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.385
[4,     7] loss: 1.371
[5,     7] loss: 1.341
[6,     7] loss: 1.331
[7,     7] loss: 1.317
[8,     7] loss: 1.303
[9,     7] loss: 1.289
[10,     7] loss: 1.282
[11,     7] loss: 1.258
[12,     7] loss: 1.280
[13,     7] loss: 1.260
[14,     7] loss: 1.242
[15,     7] loss: 1.235
[16,     7] loss: 1.232
[17,     7] loss: 1.239
[18,     7] loss: 1.222
[19,     7] loss: 1.228
[20,     7] loss: 1.259
[21,     7] loss: 1.241
[22,     7] loss: 1.231
[23,     7] loss: 1.213
[24,     7] loss: 1.197
[25,     7] loss: 1.241
[26,     7] loss: 1.215
[27,     7] loss: 1.224
[28,     7] loss: 1.221
[29,     7] loss: 1.214
[30,     7] loss: 1.210
[31,     7] loss: 1.194
[32,     7] loss: 1.273
[33,     7] loss: 1.228
[34,     7] loss: 1.224
[35,     7] loss: 1.188
[36,     7] loss: 1.207
[37,     7] loss: 1.202
[38,     7] loss: 1.230
[39,     7] loss: 1.223
[40,     7] loss: 1.197
[41,     7] loss: 1.180
[42,     7] loss: 1.196
[43,     7] loss: 1.201
[44,     7] loss: 1.204
[45,     7] loss: 1.207
[46,     7] loss: 1.193
[47,     7] loss: 1.202
[48,     7] loss: 1.173
[49,     7] loss: 1.193
[50,     7] loss: 1.196
[51,     7] loss: 1.195
[52,     7] loss: 1.153
[53,     7] loss: 1.196
[54,     7] loss: 1.212
[55,     7] loss: 1.190
[56,     7] loss: 1.179
[57,     7] loss: 1.196
[58,     7] loss: 1.180
[59,     7] loss: 1.181
[60,     7] loss: 1.169
[61,     7] loss: 1.154
[62,     7] loss: 1.194
[63,     7] loss: 1.220
[64,     7] loss: 1.192
[65,     7] loss: 1.146
[66,     7] loss: 1.161
[67,     7] loss: 1.237
[68,     7] loss: 1.216
[69,     7] loss: 1.213
[70,     7] loss: 1.183
[71,     7] loss: 1.166
[72,     7] loss: 1.189
[73,     7] loss: 1.178
[74,     7] loss: 1.182
[75,     7] loss: 1.165
[76,     7] loss: 1.160
[77,     7] loss: 1.188
[78,     7] loss: 1.175
[79,     7] loss: 1.153
[80,     7] loss: 1.185
[81,     7] loss: 1.191
[82,     7] loss: 1.155
[83,     7] loss: 1.143
[84,     7] loss: 1.224
[85,     7] loss: 1.168
[86,     7] loss: 1.131
[87,     7] loss: 1.270
[88,     7] loss: 1.273
[89,     7] loss: 1.235
[90,     7] loss: 1.200
[91,     7] loss: 1.171
[92,     7] loss: 1.164
[93,     7] loss: 1.164
[94,     7] loss: 1.149
[95,     7] loss: 1.194
[96,     7] loss: 1.179
[97,     7] loss: 1.158
[98,     7] loss: 1.178
[99,     7] loss: 1.189
[100,     7] loss: 1.141
[101,     7] loss: 1.158
[102,     7] loss: 1.184
[103,     7] loss: 1.141
[104,     7] loss: 1.157
[105,     7] loss: 1.153
[106,     7] loss: 1.117
[107,     7] loss: 1.163
[108,     7] loss: 1.183
[109,     7] loss: 1.174
[110,     7] loss: 1.158
[111,     7] loss: 1.177
[112,     7] loss: 1.138
[113,     7] loss: 1.120
[114,     7] loss: 1.197
[115,     7] loss: 1.211
[116,     7] loss: 1.179
[117,     7] loss: 1.157
[118,     7] loss: 1.151
[119,     7] loss: 1.160
[120,     7] loss: 1.170
[121,     7] loss: 1.142
Early stopping applied (best metric=0.35619989037513733)
Finished Training
Total time taken: 127.02354669570923
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.389
[2,     7] loss: 1.385
[3,     7] loss: 1.371
[4,     7] loss: 1.348
[5,     7] loss: 1.326
[6,     7] loss: 1.330
[7,     7] loss: 1.305
[8,     7] loss: 1.301
[9,     7] loss: 1.289
[10,     7] loss: 1.283
[11,     7] loss: 1.265
[12,     7] loss: 1.272
[13,     7] loss: 1.263
[14,     7] loss: 1.240
[15,     7] loss: 1.236
[16,     7] loss: 1.261
[17,     7] loss: 1.245
[18,     7] loss: 1.228
[19,     7] loss: 1.221
[20,     7] loss: 1.243
[21,     7] loss: 1.236
[22,     7] loss: 1.244
[23,     7] loss: 1.223
[24,     7] loss: 1.218
[25,     7] loss: 1.272
[26,     7] loss: 1.257
[27,     7] loss: 1.238
[28,     7] loss: 1.219
[29,     7] loss: 1.217
[30,     7] loss: 1.227
[31,     7] loss: 1.237
[32,     7] loss: 1.219
[33,     7] loss: 1.213
[34,     7] loss: 1.267
[35,     7] loss: 1.240
[36,     7] loss: 1.258
[37,     7] loss: 1.225
[38,     7] loss: 1.223
[39,     7] loss: 1.251
[40,     7] loss: 1.245
[41,     7] loss: 1.240
[42,     7] loss: 1.231
[43,     7] loss: 1.206
[44,     7] loss: 1.217
[45,     7] loss: 1.281
[46,     7] loss: 1.255
[47,     7] loss: 1.234
[48,     7] loss: 1.220
[49,     7] loss: 1.214
[50,     7] loss: 1.192
[51,     7] loss: 1.206
[52,     7] loss: 1.223
[53,     7] loss: 1.204
[54,     7] loss: 1.196
[55,     7] loss: 1.195
[56,     7] loss: 1.193
[57,     7] loss: 1.198
[58,     7] loss: 1.191
[59,     7] loss: 1.183
[60,     7] loss: 1.167
[61,     7] loss: 1.190
[62,     7] loss: 1.186
[63,     7] loss: 1.191
[64,     7] loss: 1.178
[65,     7] loss: 1.166
[66,     7] loss: 1.167
[67,     7] loss: 1.184
[68,     7] loss: 1.169
[69,     7] loss: 1.173
[70,     7] loss: 1.173
[71,     7] loss: 1.165
[72,     7] loss: 1.159
[73,     7] loss: 1.168
[74,     7] loss: 1.162
[75,     7] loss: 1.170
[76,     7] loss: 1.213
[77,     7] loss: 1.228
[78,     7] loss: 1.167
[79,     7] loss: 1.160
[80,     7] loss: 1.135
[81,     7] loss: 1.211
[82,     7] loss: 1.169
[83,     7] loss: 1.171
[84,     7] loss: 1.202
[85,     7] loss: 1.173
[86,     7] loss: 1.178
[87,     7] loss: 1.167
[88,     7] loss: 1.193
[89,     7] loss: 1.162
[90,     7] loss: 1.151
[91,     7] loss: 1.167
[92,     7] loss: 1.175
[93,     7] loss: 1.166
[94,     7] loss: 1.177
Early stopping applied (best metric=0.38394373655319214)
Finished Training
Total time taken: 89.10449743270874
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.395
[2,     7] loss: 1.385
[3,     7] loss: 1.371
[4,     7] loss: 1.337
[5,     7] loss: 1.327
[6,     7] loss: 1.331
[7,     7] loss: 1.305
[8,     7] loss: 1.293
[9,     7] loss: 1.288
[10,     7] loss: 1.281
[11,     7] loss: 1.274
[12,     7] loss: 1.251
[13,     7] loss: 1.265
[14,     7] loss: 1.237
[15,     7] loss: 1.246
[16,     7] loss: 1.251
[17,     7] loss: 1.247
[18,     7] loss: 1.243
[19,     7] loss: 1.226
[20,     7] loss: 1.218
[21,     7] loss: 1.255
[22,     7] loss: 1.245
[23,     7] loss: 1.226
[24,     7] loss: 1.220
[25,     7] loss: 1.223
[26,     7] loss: 1.223
[27,     7] loss: 1.218
[28,     7] loss: 1.209
[29,     7] loss: 1.214
[30,     7] loss: 1.216
[31,     7] loss: 1.193
[32,     7] loss: 1.185
[33,     7] loss: 1.272
[34,     7] loss: 1.337
[35,     7] loss: 1.373
[36,     7] loss: 1.359
[37,     7] loss: 1.342
[38,     7] loss: 1.315
[39,     7] loss: 1.304
[40,     7] loss: 1.299
[41,     7] loss: 1.324
[42,     7] loss: 1.324
[43,     7] loss: 1.298
[44,     7] loss: 1.292
[45,     7] loss: 1.291
[46,     7] loss: 1.271
[47,     7] loss: 1.253
[48,     7] loss: 1.231
[49,     7] loss: 1.214
[50,     7] loss: 1.201
[51,     7] loss: 1.203
[52,     7] loss: 1.260
[53,     7] loss: 1.226
[54,     7] loss: 1.217
[55,     7] loss: 1.200
[56,     7] loss: 1.209
[57,     7] loss: 1.204
[58,     7] loss: 1.217
[59,     7] loss: 1.178
[60,     7] loss: 1.200
[61,     7] loss: 1.187
[62,     7] loss: 1.176
[63,     7] loss: 1.188
[64,     7] loss: 1.181
[65,     7] loss: 1.163
[66,     7] loss: 1.198
[67,     7] loss: 1.185
[68,     7] loss: 1.159
[69,     7] loss: 1.198
[70,     7] loss: 1.243
[71,     7] loss: 1.182
[72,     7] loss: 1.157
[73,     7] loss: 1.171
[74,     7] loss: 1.158
[75,     7] loss: 1.183
[76,     7] loss: 1.156
[77,     7] loss: 1.163
[78,     7] loss: 1.220
[79,     7] loss: 1.187
[80,     7] loss: 1.185
[81,     7] loss: 1.161
[82,     7] loss: 1.169
[83,     7] loss: 1.219
[84,     7] loss: 1.208
[85,     7] loss: 1.191
[86,     7] loss: 1.176
[87,     7] loss: 1.167
[88,     7] loss: 1.342
[89,     7] loss: 1.297
[90,     7] loss: 1.278
[91,     7] loss: 1.266
[92,     7] loss: 1.246
[93,     7] loss: 1.225
[94,     7] loss: 1.228
[95,     7] loss: 1.221
[96,     7] loss: 1.203
[97,     7] loss: 1.226
[98,     7] loss: 1.221
[99,     7] loss: 1.208
[100,     7] loss: 1.209
[101,     7] loss: 1.219
[102,     7] loss: 1.196
[103,     7] loss: 1.186
[104,     7] loss: 1.168
[105,     7] loss: 1.174
[106,     7] loss: 1.150
[107,     7] loss: 1.165
[108,     7] loss: 1.179
[109,     7] loss: 1.212
[110,     7] loss: 1.251
[111,     7] loss: 1.278
[112,     7] loss: 1.223
[113,     7] loss: 1.220
[114,     7] loss: 1.182
[115,     7] loss: 1.171
[116,     7] loss: 1.199
[117,     7] loss: 1.165
[118,     7] loss: 1.152
[119,     7] loss: 1.259
[120,     7] loss: 1.225
[121,     7] loss: 1.207
[122,     7] loss: 1.164
[123,     7] loss: 1.152
[124,     7] loss: 1.171
[125,     7] loss: 1.183
[126,     7] loss: 1.188
[127,     7] loss: 1.178
[128,     7] loss: 1.140
[129,     7] loss: 1.187
[130,     7] loss: 1.159
[131,     7] loss: 1.176
[132,     7] loss: 1.230
[133,     7] loss: 1.330
[134,     7] loss: 1.300
[135,     7] loss: 1.305
[136,     7] loss: 1.270
[137,     7] loss: 1.251
[138,     7] loss: 1.226
[139,     7] loss: 1.225
[140,     7] loss: 1.220
[141,     7] loss: 1.231
[142,     7] loss: 1.194
[143,     7] loss: 1.227
[144,     7] loss: 1.204
[145,     7] loss: 1.193
[146,     7] loss: 1.187
[147,     7] loss: 1.207
[148,     7] loss: 1.214
[149,     7] loss: 1.193
[150,     7] loss: 1.164
[151,     7] loss: 1.210
[152,     7] loss: 1.200
[153,     7] loss: 1.170
[154,     7] loss: 1.192
[155,     7] loss: 1.188
[156,     7] loss: 1.197
[157,     7] loss: 1.196
[158,     7] loss: 1.177
[159,     7] loss: 1.181
[160,     7] loss: 1.169
[161,     7] loss: 1.217
[162,     7] loss: 1.183
[163,     7] loss: 1.180
[164,     7] loss: 1.234
[165,     7] loss: 1.206
[166,     7] loss: 1.210
[167,     7] loss: 1.204
[168,     7] loss: 1.157
[169,     7] loss: 1.176
[170,     7] loss: 1.173
[171,     7] loss: 1.160
[172,     7] loss: 1.187
[173,     7] loss: 1.224
[174,     7] loss: 1.197
[175,     7] loss: 1.177
[176,     7] loss: 1.171
[177,     7] loss: 1.155
[178,     7] loss: 1.166
[179,     7] loss: 1.191
[180,     7] loss: 1.170
[181,     7] loss: 1.141
[182,     7] loss: 1.276
[183,     7] loss: 1.220
[184,     7] loss: 1.191
[185,     7] loss: 1.170
[186,     7] loss: 1.158
[187,     7] loss: 1.144
[188,     7] loss: 1.230
[189,     7] loss: 1.169
[190,     7] loss: 1.164
[191,     7] loss: 1.183
[192,     7] loss: 1.179
[193,     7] loss: 1.214
[194,     7] loss: 1.190
[195,     7] loss: 1.167
[196,     7] loss: 1.154
[197,     7] loss: 1.148
[198,     7] loss: 1.203
[199,     7] loss: 1.191
[200,     7] loss: 1.183
Finished Training
Total time taken: 196.7027988433838
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.383
[3,     7] loss: 1.349
[4,     7] loss: 1.338
[5,     7] loss: 1.323
[6,     7] loss: 1.300
[7,     7] loss: 1.296
[8,     7] loss: 1.273
[9,     7] loss: 1.277
[10,     7] loss: 1.267
[11,     7] loss: 1.271
[12,     7] loss: 1.264
[13,     7] loss: 1.247
[14,     7] loss: 1.237
[15,     7] loss: 1.274
[16,     7] loss: 1.256
[17,     7] loss: 1.239
[18,     7] loss: 1.258
[19,     7] loss: 1.224
[20,     7] loss: 1.221
[21,     7] loss: 1.216
[22,     7] loss: 1.220
[23,     7] loss: 1.192
[24,     7] loss: 1.241
[25,     7] loss: 1.228
[26,     7] loss: 1.208
[27,     7] loss: 1.193
[28,     7] loss: 1.193
[29,     7] loss: 1.221
[30,     7] loss: 1.213
[31,     7] loss: 1.185
[32,     7] loss: 1.180
[33,     7] loss: 1.218
[34,     7] loss: 1.190
[35,     7] loss: 1.204
[36,     7] loss: 1.182
[37,     7] loss: 1.194
[38,     7] loss: 1.165
[39,     7] loss: 1.168
[40,     7] loss: 1.151
[41,     7] loss: 1.271
[42,     7] loss: 1.258
[43,     7] loss: 1.223
[44,     7] loss: 1.194
[45,     7] loss: 1.227
[46,     7] loss: 1.196
[47,     7] loss: 1.183
[48,     7] loss: 1.179
[49,     7] loss: 1.164
[50,     7] loss: 1.170
[51,     7] loss: 1.168
[52,     7] loss: 1.166
[53,     7] loss: 1.148
[54,     7] loss: 1.246
[55,     7] loss: 1.267
[56,     7] loss: 1.238
[57,     7] loss: 1.192
[58,     7] loss: 1.178
[59,     7] loss: 1.151
[60,     7] loss: 1.140
[61,     7] loss: 1.186
[62,     7] loss: 1.221
[63,     7] loss: 1.177
[64,     7] loss: 1.163
[65,     7] loss: 1.172
[66,     7] loss: 1.148
[67,     7] loss: 1.157
[68,     7] loss: 1.295
[69,     7] loss: 1.261
[70,     7] loss: 1.204
[71,     7] loss: 1.187
[72,     7] loss: 1.156
[73,     7] loss: 1.167
[74,     7] loss: 1.187
[75,     7] loss: 1.152
[76,     7] loss: 1.188
[77,     7] loss: 1.198
[78,     7] loss: 1.189
[79,     7] loss: 1.163
[80,     7] loss: 1.198
[81,     7] loss: 1.186
[82,     7] loss: 1.151
[83,     7] loss: 1.133
[84,     7] loss: 1.157
[85,     7] loss: 1.154
[86,     7] loss: 1.157
[87,     7] loss: 1.168
[88,     7] loss: 1.185
[89,     7] loss: 1.158
[90,     7] loss: 1.148
[91,     7] loss: 1.158
[92,     7] loss: 1.189
[93,     7] loss: 1.167
[94,     7] loss: 1.146
[95,     7] loss: 1.168
[96,     7] loss: 1.185
[97,     7] loss: 1.168
[98,     7] loss: 1.169
[99,     7] loss: 1.153
[100,     7] loss: 1.131
[101,     7] loss: 1.163
[102,     7] loss: 1.143
[103,     7] loss: 1.158
[104,     7] loss: 1.152
[105,     7] loss: 1.151
[106,     7] loss: 1.165
[107,     7] loss: 1.174
[108,     7] loss: 1.160
[109,     7] loss: 1.139
[110,     7] loss: 1.160
[111,     7] loss: 1.152
[112,     7] loss: 1.160
[113,     7] loss: 1.144
[114,     7] loss: 1.153
[115,     7] loss: 1.152
[116,     7] loss: 1.165
[117,     7] loss: 1.151
Early stopping applied (best metric=0.3541772663593292)
Finished Training
Total time taken: 116.24729609489441
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.381
[4,     7] loss: 1.358
[5,     7] loss: 1.328
[6,     7] loss: 1.328
[7,     7] loss: 1.304
[8,     7] loss: 1.282
[9,     7] loss: 1.274
[10,     7] loss: 1.273
[11,     7] loss: 1.263
[12,     7] loss: 1.250
[13,     7] loss: 1.252
[14,     7] loss: 1.255
[15,     7] loss: 1.247
[16,     7] loss: 1.264
[17,     7] loss: 1.245
[18,     7] loss: 1.236
[19,     7] loss: 1.233
[20,     7] loss: 1.210
[21,     7] loss: 1.261
[22,     7] loss: 1.230
[23,     7] loss: 1.227
[24,     7] loss: 1.226
[25,     7] loss: 1.234
[26,     7] loss: 1.224
[27,     7] loss: 1.208
[28,     7] loss: 1.189
[29,     7] loss: 1.208
[30,     7] loss: 1.179
[31,     7] loss: 1.207
[32,     7] loss: 1.186
[33,     7] loss: 1.166
[34,     7] loss: 1.244
[35,     7] loss: 1.257
[36,     7] loss: 1.252
[37,     7] loss: 1.215
[38,     7] loss: 1.178
[39,     7] loss: 1.177
[40,     7] loss: 1.205
[41,     7] loss: 1.193
[42,     7] loss: 1.179
[43,     7] loss: 1.193
[44,     7] loss: 1.164
[45,     7] loss: 1.181
[46,     7] loss: 1.171
[47,     7] loss: 1.144
[48,     7] loss: 1.215
[49,     7] loss: 1.198
[50,     7] loss: 1.184
[51,     7] loss: 1.184
[52,     7] loss: 1.189
[53,     7] loss: 1.173
[54,     7] loss: 1.195
[55,     7] loss: 1.185
[56,     7] loss: 1.172
[57,     7] loss: 1.190
[58,     7] loss: 1.160
[59,     7] loss: 1.159
[60,     7] loss: 1.204
[61,     7] loss: 1.186
[62,     7] loss: 1.169
[63,     7] loss: 1.138
[64,     7] loss: 1.148
[65,     7] loss: 1.228
[66,     7] loss: 1.193
[67,     7] loss: 1.163
[68,     7] loss: 1.149
[69,     7] loss: 1.168
[70,     7] loss: 1.156
[71,     7] loss: 1.146
[72,     7] loss: 1.217
[73,     7] loss: 1.189
[74,     7] loss: 1.186
[75,     7] loss: 1.175
[76,     7] loss: 1.125
[77,     7] loss: 1.197
[78,     7] loss: 1.168
[79,     7] loss: 1.171
[80,     7] loss: 1.144
[81,     7] loss: 1.181
[82,     7] loss: 1.153
[83,     7] loss: 1.189
[84,     7] loss: 1.143
[85,     7] loss: 1.178
[86,     7] loss: 1.182
[87,     7] loss: 1.139
[88,     7] loss: 1.176
[89,     7] loss: 1.168
[90,     7] loss: 1.132
[91,     7] loss: 1.160
[92,     7] loss: 1.186
[93,     7] loss: 1.177
[94,     7] loss: 1.140
[95,     7] loss: 1.189
[96,     7] loss: 1.180
[97,     7] loss: 1.159
[98,     7] loss: 1.158
[99,     7] loss: 1.193
[100,     7] loss: 1.157
[101,     7] loss: 1.155
[102,     7] loss: 1.172
[103,     7] loss: 1.160
[104,     7] loss: 1.222
[105,     7] loss: 1.220
[106,     7] loss: 1.204
[107,     7] loss: 1.181
[108,     7] loss: 1.152
[109,     7] loss: 1.125
[110,     7] loss: 1.139
[111,     7] loss: 1.153
[112,     7] loss: 1.160
[113,     7] loss: 1.161
[114,     7] loss: 1.159
[115,     7] loss: 1.231
[116,     7] loss: 1.183
[117,     7] loss: 1.166
[118,     7] loss: 1.143
[119,     7] loss: 1.152
[120,     7] loss: 1.126
[121,     7] loss: 1.314
[122,     7] loss: 1.317
[123,     7] loss: 1.313
[124,     7] loss: 1.324
[125,     7] loss: 1.300
[126,     7] loss: 1.271
[127,     7] loss: 1.238
[128,     7] loss: 1.233
[129,     7] loss: 1.203
[130,     7] loss: 1.226
[131,     7] loss: 1.209
[132,     7] loss: 1.205
[133,     7] loss: 1.182
[134,     7] loss: 1.191
[135,     7] loss: 1.163
[136,     7] loss: 1.198
[137,     7] loss: 1.178
[138,     7] loss: 1.166
[139,     7] loss: 1.187
[140,     7] loss: 1.218
[141,     7] loss: 1.188
[142,     7] loss: 1.195
[143,     7] loss: 1.189
[144,     7] loss: 1.197
[145,     7] loss: 1.175
[146,     7] loss: 1.175
[147,     7] loss: 1.165
[148,     7] loss: 1.175
[149,     7] loss: 1.199
[150,     7] loss: 1.187
[151,     7] loss: 1.172
[152,     7] loss: 1.174
[153,     7] loss: 1.174
[154,     7] loss: 1.164
[155,     7] loss: 1.165
[156,     7] loss: 1.163
[157,     7] loss: 1.184
[158,     7] loss: 1.174
[159,     7] loss: 1.185
[160,     7] loss: 1.180
[161,     7] loss: 1.168
[162,     7] loss: 1.160
[163,     7] loss: 1.159
[164,     7] loss: 1.191
[165,     7] loss: 1.175
[166,     7] loss: 1.181
[167,     7] loss: 1.177
[168,     7] loss: 1.167
[169,     7] loss: 1.157
[170,     7] loss: 1.165
Early stopping applied (best metric=0.3547980487346649)
Finished Training
Total time taken: 171.35053968429565
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.400
[2,     7] loss: 1.387
[3,     7] loss: 1.387
[4,     7] loss: 1.385
[5,     7] loss: 1.380
[6,     7] loss: 1.352
[7,     7] loss: 1.327
[8,     7] loss: 1.314
[9,     7] loss: 1.294
[10,     7] loss: 1.277
[11,     7] loss: 1.274
[12,     7] loss: 1.250
[13,     7] loss: 1.261
[14,     7] loss: 1.268
[15,     7] loss: 1.231
[16,     7] loss: 1.236
[17,     7] loss: 1.237
[18,     7] loss: 1.243
[19,     7] loss: 1.229
[20,     7] loss: 1.243
[21,     7] loss: 1.229
[22,     7] loss: 1.223
[23,     7] loss: 1.199
[24,     7] loss: 1.236
[25,     7] loss: 1.241
[26,     7] loss: 1.234
[27,     7] loss: 1.211
[28,     7] loss: 1.205
[29,     7] loss: 1.204
[30,     7] loss: 1.231
[31,     7] loss: 1.242
[32,     7] loss: 1.210
[33,     7] loss: 1.228
[34,     7] loss: 1.205
[35,     7] loss: 1.221
[36,     7] loss: 1.243
[37,     7] loss: 1.247
[38,     7] loss: 1.255
[39,     7] loss: 1.239
[40,     7] loss: 1.240
[41,     7] loss: 1.229
[42,     7] loss: 1.219
[43,     7] loss: 1.219
[44,     7] loss: 1.224
[45,     7] loss: 1.215
[46,     7] loss: 1.209
[47,     7] loss: 1.203
[48,     7] loss: 1.200
[49,     7] loss: 1.264
[50,     7] loss: 1.208
[51,     7] loss: 1.207
[52,     7] loss: 1.202
[53,     7] loss: 1.190
[54,     7] loss: 1.285
[55,     7] loss: 1.248
[56,     7] loss: 1.217
[57,     7] loss: 1.193
[58,     7] loss: 1.188
[59,     7] loss: 1.209
[60,     7] loss: 1.240
[61,     7] loss: 1.195
[62,     7] loss: 1.178
[63,     7] loss: 1.187
[64,     7] loss: 1.193
[65,     7] loss: 1.211
[66,     7] loss: 1.205
[67,     7] loss: 1.195
[68,     7] loss: 1.191
[69,     7] loss: 1.186
[70,     7] loss: 1.212
[71,     7] loss: 1.194
[72,     7] loss: 1.205
[73,     7] loss: 1.232
[74,     7] loss: 1.223
[75,     7] loss: 1.203
[76,     7] loss: 1.180
[77,     7] loss: 1.168
[78,     7] loss: 1.190
[79,     7] loss: 1.192
[80,     7] loss: 1.175
[81,     7] loss: 1.181
[82,     7] loss: 1.163
[83,     7] loss: 1.167
[84,     7] loss: 1.196
[85,     7] loss: 1.204
[86,     7] loss: 1.200
[87,     7] loss: 1.185
[88,     7] loss: 1.226
[89,     7] loss: 1.198
[90,     7] loss: 1.182
[91,     7] loss: 1.167
[92,     7] loss: 1.181
[93,     7] loss: 1.150
[94,     7] loss: 1.181
[95,     7] loss: 1.243
[96,     7] loss: 1.209
[97,     7] loss: 1.159
[98,     7] loss: 1.173
[99,     7] loss: 1.166
[100,     7] loss: 1.199
[101,     7] loss: 1.172
[102,     7] loss: 1.148
[103,     7] loss: 1.170
[104,     7] loss: 1.181
[105,     7] loss: 1.157
[106,     7] loss: 1.166
[107,     7] loss: 1.187
[108,     7] loss: 1.194
[109,     7] loss: 1.195
[110,     7] loss: 1.196
[111,     7] loss: 1.182
[112,     7] loss: 1.175
[113,     7] loss: 1.158
[114,     7] loss: 1.147
[115,     7] loss: 1.156
[116,     7] loss: 1.174
[117,     7] loss: 1.190
[118,     7] loss: 1.178
[119,     7] loss: 1.218
[120,     7] loss: 1.167
[121,     7] loss: 1.152
[122,     7] loss: 1.152
[123,     7] loss: 1.160
[124,     7] loss: 1.205
[125,     7] loss: 1.175
[126,     7] loss: 1.160
[127,     7] loss: 1.139
[128,     7] loss: 1.155
[129,     7] loss: 1.147
[130,     7] loss: 1.154
[131,     7] loss: 1.192
[132,     7] loss: 1.176
[133,     7] loss: 1.170
[134,     7] loss: 1.166
[135,     7] loss: 1.179
[136,     7] loss: 1.141
[137,     7] loss: 1.161
[138,     7] loss: 1.180
[139,     7] loss: 1.147
[140,     7] loss: 1.200
[141,     7] loss: 1.187
[142,     7] loss: 1.190
[143,     7] loss: 1.167
[144,     7] loss: 1.157
[145,     7] loss: 1.151
[146,     7] loss: 1.151
[147,     7] loss: 1.183
[148,     7] loss: 1.163
[149,     7] loss: 1.168
[150,     7] loss: 1.155
[151,     7] loss: 1.156
[152,     7] loss: 1.150
[153,     7] loss: 1.138
[154,     7] loss: 1.236
[155,     7] loss: 1.209
[156,     7] loss: 1.185
[157,     7] loss: 1.171
[158,     7] loss: 1.167
[159,     7] loss: 1.157
[160,     7] loss: 1.190
[161,     7] loss: 1.179
[162,     7] loss: 1.174
[163,     7] loss: 1.160
[164,     7] loss: 1.233
[165,     7] loss: 1.181
[166,     7] loss: 1.170
[167,     7] loss: 1.139
[168,     7] loss: 1.165
[169,     7] loss: 1.163
[170,     7] loss: 1.170
[171,     7] loss: 1.148
[172,     7] loss: 1.143
[173,     7] loss: 1.182
[174,     7] loss: 1.159
[175,     7] loss: 1.180
[176,     7] loss: 1.166
[177,     7] loss: 1.153
[178,     7] loss: 1.159
[179,     7] loss: 1.163
[180,     7] loss: 1.167
[181,     7] loss: 1.148
[182,     7] loss: 1.153
[183,     7] loss: 1.166
[184,     7] loss: 1.167
[185,     7] loss: 1.168
[186,     7] loss: 1.168
[187,     7] loss: 1.157
[188,     7] loss: 1.222
[189,     7] loss: 1.224
[190,     7] loss: 1.193
[191,     7] loss: 1.162
[192,     7] loss: 1.146
[193,     7] loss: 1.147
[194,     7] loss: 1.160
[195,     7] loss: 1.164
[196,     7] loss: 1.160
[197,     7] loss: 1.170
[198,     7] loss: 1.149
Early stopping applied (best metric=0.34941351413726807)
Finished Training
Total time taken: 199.04293608665466
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.392
[2,     7] loss: 1.386
[3,     7] loss: 1.385
[4,     7] loss: 1.377
[5,     7] loss: 1.342
[6,     7] loss: 1.326
[7,     7] loss: 1.307
[8,     7] loss: 1.303
[9,     7] loss: 1.291
[10,     7] loss: 1.268
[11,     7] loss: 1.276
[12,     7] loss: 1.271
[13,     7] loss: 1.257
[14,     7] loss: 1.273
[15,     7] loss: 1.249
[16,     7] loss: 1.242
[17,     7] loss: 1.263
[18,     7] loss: 1.249
[19,     7] loss: 1.226
[20,     7] loss: 1.222
[21,     7] loss: 1.214
[22,     7] loss: 1.233
[23,     7] loss: 1.232
[24,     7] loss: 1.232
[25,     7] loss: 1.204
[26,     7] loss: 1.220
[27,     7] loss: 1.208
[28,     7] loss: 1.239
[29,     7] loss: 1.237
[30,     7] loss: 1.214
[31,     7] loss: 1.185
[32,     7] loss: 1.173
[33,     7] loss: 1.233
[34,     7] loss: 1.274
[35,     7] loss: 1.314
[36,     7] loss: 1.289
[37,     7] loss: 1.242
[38,     7] loss: 1.212
[39,     7] loss: 1.201
[40,     7] loss: 1.190
[41,     7] loss: 1.208
[42,     7] loss: 1.196
[43,     7] loss: 1.189
[44,     7] loss: 1.216
[45,     7] loss: 1.201
[46,     7] loss: 1.180
[47,     7] loss: 1.176
[48,     7] loss: 1.179
[49,     7] loss: 1.193
[50,     7] loss: 1.199
[51,     7] loss: 1.174
[52,     7] loss: 1.159
[53,     7] loss: 1.183
[54,     7] loss: 1.179
[55,     7] loss: 1.204
[56,     7] loss: 1.181
[57,     7] loss: 1.173
[58,     7] loss: 1.182
[59,     7] loss: 1.162
[60,     7] loss: 1.143
[61,     7] loss: 1.160
[62,     7] loss: 1.183
[63,     7] loss: 1.201
[64,     7] loss: 1.170
[65,     7] loss: 1.154
[66,     7] loss: 1.185
[67,     7] loss: 1.198
[68,     7] loss: 1.167
[69,     7] loss: 1.154
[70,     7] loss: 1.120
[71,     7] loss: 1.180
[72,     7] loss: 1.144
[73,     7] loss: 1.161
[74,     7] loss: 1.158
[75,     7] loss: 1.141
[76,     7] loss: 1.142
[77,     7] loss: 1.167
[78,     7] loss: 1.168
[79,     7] loss: 1.163
[80,     7] loss: 1.144
[81,     7] loss: 1.171
[82,     7] loss: 1.164
[83,     7] loss: 1.168
[84,     7] loss: 1.181
[85,     7] loss: 1.138
[86,     7] loss: 1.140
[87,     7] loss: 1.125
[88,     7] loss: 1.208
[89,     7] loss: 1.250
[90,     7] loss: 1.197
[91,     7] loss: 1.170
[92,     7] loss: 1.149
[93,     7] loss: 1.159
[94,     7] loss: 1.279
[95,     7] loss: 1.213
[96,     7] loss: 1.229
[97,     7] loss: 1.181
[98,     7] loss: 1.146
[99,     7] loss: 1.143
[100,     7] loss: 1.164
[101,     7] loss: 1.189
[102,     7] loss: 1.199
[103,     7] loss: 1.184
[104,     7] loss: 1.161
[105,     7] loss: 1.147
[106,     7] loss: 1.150
[107,     7] loss: 1.178
[108,     7] loss: 1.169
[109,     7] loss: 1.132
[110,     7] loss: 1.215
[111,     7] loss: 1.179
[112,     7] loss: 1.161
[113,     7] loss: 1.148
[114,     7] loss: 1.152
[115,     7] loss: 1.151
[116,     7] loss: 1.145
[117,     7] loss: 1.144
[118,     7] loss: 1.184
[119,     7] loss: 1.168
[120,     7] loss: 1.148
[121,     7] loss: 1.184
[122,     7] loss: 1.247
[123,     7] loss: 1.413
[124,     7] loss: 1.378
[125,     7] loss: 1.369
[126,     7] loss: 1.358
[127,     7] loss: 1.348
[128,     7] loss: 1.343
[129,     7] loss: 1.335
[130,     7] loss: 1.322
[131,     7] loss: 1.319
[132,     7] loss: 1.309
[133,     7] loss: 1.307
[134,     7] loss: 1.298
[135,     7] loss: 1.293
[136,     7] loss: 1.288
[137,     7] loss: 1.302
[138,     7] loss: 1.293
[139,     7] loss: 1.282
[140,     7] loss: 1.268
[141,     7] loss: 1.262
[142,     7] loss: 1.274
[143,     7] loss: 1.277
[144,     7] loss: 1.269
[145,     7] loss: 1.265
[146,     7] loss: 1.269
[147,     7] loss: 1.264
[148,     7] loss: 1.263
[149,     7] loss: 1.268
[150,     7] loss: 1.275
[151,     7] loss: 1.248
[152,     7] loss: 1.264
[153,     7] loss: 1.259
[154,     7] loss: 1.270
[155,     7] loss: 1.273
[156,     7] loss: 1.260
[157,     7] loss: 1.252
[158,     7] loss: 1.262
[159,     7] loss: 1.249
[160,     7] loss: 1.265
Early stopping applied (best metric=0.35437560081481934)
Finished Training
Total time taken: 139.93276858329773
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.385
[2,     7] loss: 1.387
[3,     7] loss: 1.385
[4,     7] loss: 1.378
[5,     7] loss: 1.340
[6,     7] loss: 1.332
[7,     7] loss: 1.314
[8,     7] loss: 1.305
[9,     7] loss: 1.296
[10,     7] loss: 1.292
[11,     7] loss: 1.269
[12,     7] loss: 1.277
[13,     7] loss: 1.264
[14,     7] loss: 1.244
[15,     7] loss: 1.269
[16,     7] loss: 1.251
[17,     7] loss: 1.234
[18,     7] loss: 1.212
[19,     7] loss: 1.233
[20,     7] loss: 1.246
[21,     7] loss: 1.264
[22,     7] loss: 1.243
[23,     7] loss: 1.229
[24,     7] loss: 1.217
[25,     7] loss: 1.217
[26,     7] loss: 1.242
[27,     7] loss: 1.243
[28,     7] loss: 1.230
[29,     7] loss: 1.230
[30,     7] loss: 1.222
[31,     7] loss: 1.202
[32,     7] loss: 1.216
[33,     7] loss: 1.222
[34,     7] loss: 1.222
[35,     7] loss: 1.224
[36,     7] loss: 1.226
[37,     7] loss: 1.202
[38,     7] loss: 1.202
[39,     7] loss: 1.184
[40,     7] loss: 1.236
[41,     7] loss: 1.225
[42,     7] loss: 1.212
[43,     7] loss: 1.237
[44,     7] loss: 1.205
[45,     7] loss: 1.178
[46,     7] loss: 1.199
[47,     7] loss: 1.202
[48,     7] loss: 1.189
[49,     7] loss: 1.195
[50,     7] loss: 1.189
[51,     7] loss: 1.175
[52,     7] loss: 1.196
[53,     7] loss: 1.220
[54,     7] loss: 1.213
[55,     7] loss: 1.173
[56,     7] loss: 1.176
[57,     7] loss: 1.178
[58,     7] loss: 1.207
[59,     7] loss: 1.231
[60,     7] loss: 1.203
[61,     7] loss: 1.186
[62,     7] loss: 1.186
[63,     7] loss: 1.176
[64,     7] loss: 1.170
[65,     7] loss: 1.209
[66,     7] loss: 1.194
[67,     7] loss: 1.165
[68,     7] loss: 1.179
[69,     7] loss: 1.158
[70,     7] loss: 1.172
[71,     7] loss: 1.186
[72,     7] loss: 1.177
[73,     7] loss: 1.164
[74,     7] loss: 1.196
[75,     7] loss: 1.215
[76,     7] loss: 1.184
[77,     7] loss: 1.190
[78,     7] loss: 1.166
[79,     7] loss: 1.184
[80,     7] loss: 1.184
[81,     7] loss: 1.193
[82,     7] loss: 1.166
[83,     7] loss: 1.170
[84,     7] loss: 1.177
[85,     7] loss: 1.169
[86,     7] loss: 1.158
[87,     7] loss: 1.167
[88,     7] loss: 1.153
[89,     7] loss: 1.233
[90,     7] loss: 1.207
[91,     7] loss: 1.199
[92,     7] loss: 1.163
[93,     7] loss: 1.166
[94,     7] loss: 1.196
[95,     7] loss: 1.224
[96,     7] loss: 1.186
[97,     7] loss: 1.163
[98,     7] loss: 1.146
[99,     7] loss: 1.170
[100,     7] loss: 1.187
[101,     7] loss: 1.181
[102,     7] loss: 1.165
[103,     7] loss: 1.167
[104,     7] loss: 1.134
[105,     7] loss: 1.184
[106,     7] loss: 1.183
[107,     7] loss: 1.178
[108,     7] loss: 1.158
[109,     7] loss: 1.148
[110,     7] loss: 1.170
[111,     7] loss: 1.187
[112,     7] loss: 1.158
[113,     7] loss: 1.184
[114,     7] loss: 1.181
[115,     7] loss: 1.166
[116,     7] loss: 1.155
[117,     7] loss: 1.162
Early stopping applied (best metric=0.35578587651252747)
Finished Training
Total time taken: 98.98567700386047
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.380
[4,     7] loss: 1.359
[5,     7] loss: 1.345
[6,     7] loss: 1.332
[7,     7] loss: 1.328
[8,     7] loss: 1.301
[9,     7] loss: 1.289
[10,     7] loss: 1.296
[11,     7] loss: 1.264
[12,     7] loss: 1.276
[13,     7] loss: 1.257
[14,     7] loss: 1.249
[15,     7] loss: 1.232
[16,     7] loss: 1.230
[17,     7] loss: 1.239
[18,     7] loss: 1.238
[19,     7] loss: 1.231
[20,     7] loss: 1.208
[21,     7] loss: 1.196
[22,     7] loss: 1.207
[23,     7] loss: 1.195
[24,     7] loss: 1.199
[25,     7] loss: 1.190
[26,     7] loss: 1.177
[27,     7] loss: 1.233
[28,     7] loss: 1.232
[29,     7] loss: 1.201
[30,     7] loss: 1.176
[31,     7] loss: 1.185
[32,     7] loss: 1.167
[33,     7] loss: 1.184
[34,     7] loss: 1.168
[35,     7] loss: 1.179
[36,     7] loss: 1.192
[37,     7] loss: 1.190
[38,     7] loss: 1.187
[39,     7] loss: 1.203
[40,     7] loss: 1.231
[41,     7] loss: 1.190
[42,     7] loss: 1.183
[43,     7] loss: 1.166
[44,     7] loss: 1.184
[45,     7] loss: 1.167
[46,     7] loss: 1.161
[47,     7] loss: 1.181
[48,     7] loss: 1.159
[49,     7] loss: 1.170
[50,     7] loss: 1.141
[51,     7] loss: 1.185
[52,     7] loss: 1.195
[53,     7] loss: 1.181
[54,     7] loss: 1.155
[55,     7] loss: 1.139
[56,     7] loss: 1.178
[57,     7] loss: 1.197
[58,     7] loss: 1.174
[59,     7] loss: 1.177
[60,     7] loss: 1.149
[61,     7] loss: 1.163
[62,     7] loss: 1.236
[63,     7] loss: 1.186
[64,     7] loss: 1.150
[65,     7] loss: 1.231
[66,     7] loss: 1.229
[67,     7] loss: 1.186
[68,     7] loss: 1.179
[69,     7] loss: 1.163
[70,     7] loss: 1.149
[71,     7] loss: 1.177
[72,     7] loss: 1.191
[73,     7] loss: 1.181
[74,     7] loss: 1.171
[75,     7] loss: 1.160
[76,     7] loss: 1.160
[77,     7] loss: 1.204
[78,     7] loss: 1.205
[79,     7] loss: 1.177
[80,     7] loss: 1.162
[81,     7] loss: 1.157
[82,     7] loss: 1.179
[83,     7] loss: 1.183
[84,     7] loss: 1.149
[85,     7] loss: 1.150
[86,     7] loss: 1.163
[87,     7] loss: 1.158
[88,     7] loss: 1.138
[89,     7] loss: 1.129
[90,     7] loss: 1.173
[91,     7] loss: 1.170
[92,     7] loss: 1.148
[93,     7] loss: 1.153
[94,     7] loss: 1.146
[95,     7] loss: 1.156
[96,     7] loss: 1.178
[97,     7] loss: 1.189
[98,     7] loss: 1.166
[99,     7] loss: 1.146
[100,     7] loss: 1.174
[101,     7] loss: 1.151
[102,     7] loss: 1.152
[103,     7] loss: 1.160
[104,     7] loss: 1.154
[105,     7] loss: 1.147
[106,     7] loss: 1.145
[107,     7] loss: 1.178
[108,     7] loss: 1.147
[109,     7] loss: 1.152
[110,     7] loss: 1.178
[111,     7] loss: 1.167
[112,     7] loss: 1.161
[113,     7] loss: 1.150
[114,     7] loss: 1.149
[115,     7] loss: 1.156
[116,     7] loss: 1.146
[117,     7] loss: 1.128
[118,     7] loss: 1.169
[119,     7] loss: 1.198
[120,     7] loss: 1.141
[121,     7] loss: 1.140
[122,     7] loss: 1.130
[123,     7] loss: 1.138
[124,     7] loss: 1.167
[125,     7] loss: 1.185
[126,     7] loss: 1.166
[127,     7] loss: 1.168
[128,     7] loss: 1.152
[129,     7] loss: 1.193
[130,     7] loss: 1.203
[131,     7] loss: 1.184
[132,     7] loss: 1.159
[133,     7] loss: 1.134
[134,     7] loss: 1.144
[135,     7] loss: 1.158
[136,     7] loss: 1.163
[137,     7] loss: 1.162
[138,     7] loss: 1.167
[139,     7] loss: 1.162
[140,     7] loss: 1.136
[141,     7] loss: 1.170
[142,     7] loss: 1.226
[143,     7] loss: 1.189
[144,     7] loss: 1.172
[145,     7] loss: 1.169
[146,     7] loss: 1.178
[147,     7] loss: 1.142
[148,     7] loss: 1.193
[149,     7] loss: 1.194
[150,     7] loss: 1.176
[151,     7] loss: 1.142
[152,     7] loss: 1.153
[153,     7] loss: 1.152
[154,     7] loss: 1.150
[155,     7] loss: 1.160
[156,     7] loss: 1.149
[157,     7] loss: 1.187
[158,     7] loss: 1.146
[159,     7] loss: 1.149
Early stopping applied (best metric=0.34909048676490784)
Finished Training
Total time taken: 138.09608006477356
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.394
[2,     7] loss: 1.385
[3,     7] loss: 1.372
[4,     7] loss: 1.341
[5,     7] loss: 1.322
[6,     7] loss: 1.308
[7,     7] loss: 1.285
[8,     7] loss: 1.274
[9,     7] loss: 1.264
[10,     7] loss: 1.251
[11,     7] loss: 1.260
[12,     7] loss: 1.249
[13,     7] loss: 1.250
[14,     7] loss: 1.263
[15,     7] loss: 1.249
[16,     7] loss: 1.246
[17,     7] loss: 1.234
[18,     7] loss: 1.258
[19,     7] loss: 1.228
[20,     7] loss: 1.221
[21,     7] loss: 1.232
[22,     7] loss: 1.210
[23,     7] loss: 1.222
[24,     7] loss: 1.209
[25,     7] loss: 1.220
[26,     7] loss: 1.220
[27,     7] loss: 1.211
[28,     7] loss: 1.229
[29,     7] loss: 1.207
[30,     7] loss: 1.223
[31,     7] loss: 1.229
[32,     7] loss: 1.223
[33,     7] loss: 1.208
[34,     7] loss: 1.207
[35,     7] loss: 1.269
[36,     7] loss: 1.256
[37,     7] loss: 1.220
[38,     7] loss: 1.223
[39,     7] loss: 1.188
[40,     7] loss: 1.208
[41,     7] loss: 1.242
[42,     7] loss: 1.218
[43,     7] loss: 1.198
[44,     7] loss: 1.200
[45,     7] loss: 1.208
[46,     7] loss: 1.188
[47,     7] loss: 1.202
[48,     7] loss: 1.228
[49,     7] loss: 1.220
[50,     7] loss: 1.189
[51,     7] loss: 1.183
[52,     7] loss: 1.176
[53,     7] loss: 1.186
[54,     7] loss: 1.191
[55,     7] loss: 1.175
[56,     7] loss: 1.198
[57,     7] loss: 1.216
[58,     7] loss: 1.201
[59,     7] loss: 1.179
[60,     7] loss: 1.178
[61,     7] loss: 1.187
[62,     7] loss: 1.206
[63,     7] loss: 1.200
[64,     7] loss: 1.184
[65,     7] loss: 1.177
[66,     7] loss: 1.212
[67,     7] loss: 1.177
[68,     7] loss: 1.185
[69,     7] loss: 1.181
[70,     7] loss: 1.189
[71,     7] loss: 1.216
[72,     7] loss: 1.248
[73,     7] loss: 1.221
[74,     7] loss: 1.210
[75,     7] loss: 1.191
[76,     7] loss: 1.181
[77,     7] loss: 1.164
[78,     7] loss: 1.189
[79,     7] loss: 1.162
[80,     7] loss: 1.185
[81,     7] loss: 1.202
[82,     7] loss: 1.184
[83,     7] loss: 1.172
[84,     7] loss: 1.172
[85,     7] loss: 1.184
[86,     7] loss: 1.186
[87,     7] loss: 1.214
[88,     7] loss: 1.184
[89,     7] loss: 1.171
[90,     7] loss: 1.184
[91,     7] loss: 1.168
[92,     7] loss: 1.185
[93,     7] loss: 1.163
[94,     7] loss: 1.167
[95,     7] loss: 1.193
[96,     7] loss: 1.216
[97,     7] loss: 1.195
[98,     7] loss: 1.174
[99,     7] loss: 1.172
[100,     7] loss: 1.161
[101,     7] loss: 1.141
[102,     7] loss: 1.160
[103,     7] loss: 1.193
[104,     7] loss: 1.154
[105,     7] loss: 1.193
Early stopping applied (best metric=0.348178893327713)
Finished Training
Total time taken: 91.65804648399353
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.388
[2,     7] loss: 1.385
[3,     7] loss: 1.376
[4,     7] loss: 1.334
[5,     7] loss: 1.319
[6,     7] loss: 1.304
[7,     7] loss: 1.293
[8,     7] loss: 1.283
[9,     7] loss: 1.274
[10,     7] loss: 1.271
[11,     7] loss: 1.261
[12,     7] loss: 1.252
[13,     7] loss: 1.251
[14,     7] loss: 1.246
[15,     7] loss: 1.242
[16,     7] loss: 1.268
[17,     7] loss: 1.263
[18,     7] loss: 1.247
[19,     7] loss: 1.242
[20,     7] loss: 1.235
[21,     7] loss: 1.229
[22,     7] loss: 1.250
[23,     7] loss: 1.245
[24,     7] loss: 1.223
[25,     7] loss: 1.221
[26,     7] loss: 1.194
[27,     7] loss: 1.280
[28,     7] loss: 1.252
[29,     7] loss: 1.222
[30,     7] loss: 1.216
[31,     7] loss: 1.209
[32,     7] loss: 1.202
[33,     7] loss: 1.222
[34,     7] loss: 1.235
[35,     7] loss: 1.254
[36,     7] loss: 1.241
[37,     7] loss: 1.235
[38,     7] loss: 1.227
[39,     7] loss: 1.205
[40,     7] loss: 1.179
[41,     7] loss: 1.180
[42,     7] loss: 1.202
[43,     7] loss: 1.189
[44,     7] loss: 1.180
[45,     7] loss: 1.194
[46,     7] loss: 1.267
[47,     7] loss: 1.230
[48,     7] loss: 1.199
[49,     7] loss: 1.180
[50,     7] loss: 1.172
[51,     7] loss: 1.175
[52,     7] loss: 1.186
[53,     7] loss: 1.198
[54,     7] loss: 1.201
[55,     7] loss: 1.184
[56,     7] loss: 1.225
[57,     7] loss: 1.181
[58,     7] loss: 1.169
[59,     7] loss: 1.241
[60,     7] loss: 1.190
[61,     7] loss: 1.162
[62,     7] loss: 1.172
[63,     7] loss: 1.164
[64,     7] loss: 1.194
[65,     7] loss: 1.174
[66,     7] loss: 1.178
[67,     7] loss: 1.155
[68,     7] loss: 1.198
[69,     7] loss: 1.170
[70,     7] loss: 1.174
[71,     7] loss: 1.182
[72,     7] loss: 1.265
[73,     7] loss: 1.216
[74,     7] loss: 1.181
[75,     7] loss: 1.155
[76,     7] loss: 1.156
[77,     7] loss: 1.172
[78,     7] loss: 1.164
[79,     7] loss: 1.149
[80,     7] loss: 1.148
[81,     7] loss: 1.195
[82,     7] loss: 1.176
[83,     7] loss: 1.150
[84,     7] loss: 1.187
[85,     7] loss: 1.189
[86,     7] loss: 1.156
[87,     7] loss: 1.161
[88,     7] loss: 1.133
[89,     7] loss: 1.208
[90,     7] loss: 1.174
[91,     7] loss: 1.160
[92,     7] loss: 1.145
[93,     7] loss: 1.134
[94,     7] loss: 1.168
[95,     7] loss: 1.170
[96,     7] loss: 1.179
[97,     7] loss: 1.175
[98,     7] loss: 1.152
[99,     7] loss: 1.148
[100,     7] loss: 1.194
[101,     7] loss: 1.218
[102,     7] loss: 1.207
[103,     7] loss: 1.160
[104,     7] loss: 1.167
[105,     7] loss: 1.138
[106,     7] loss: 1.186
[107,     7] loss: 1.173
[108,     7] loss: 1.172
[109,     7] loss: 1.167
[110,     7] loss: 1.148
[111,     7] loss: 1.186
[112,     7] loss: 1.172
[113,     7] loss: 1.161
[114,     7] loss: 1.158
[115,     7] loss: 1.160
[116,     7] loss: 1.155
[117,     7] loss: 1.153
[118,     7] loss: 1.138
[119,     7] loss: 1.164
[120,     7] loss: 1.201
[121,     7] loss: 1.198
[122,     7] loss: 1.217
[123,     7] loss: 1.192
[124,     7] loss: 1.184
[125,     7] loss: 1.159
[126,     7] loss: 1.167
[127,     7] loss: 1.139
[128,     7] loss: 1.171
[129,     7] loss: 1.195
[130,     7] loss: 1.164
[131,     7] loss: 1.161
[132,     7] loss: 1.160
[133,     7] loss: 1.178
[134,     7] loss: 1.174
[135,     7] loss: 1.162
[136,     7] loss: 1.163
[137,     7] loss: 1.153
[138,     7] loss: 1.172
[139,     7] loss: 1.161
[140,     7] loss: 1.154
[141,     7] loss: 1.155
[142,     7] loss: 1.151
[143,     7] loss: 1.147
[144,     7] loss: 1.163
[145,     7] loss: 1.184
[146,     7] loss: 1.170
[147,     7] loss: 1.172
[148,     7] loss: 1.173
[149,     7] loss: 1.154
[150,     7] loss: 1.152
[151,     7] loss: 1.153
[152,     7] loss: 1.142
[153,     7] loss: 1.187
[154,     7] loss: 1.173
[155,     7] loss: 1.155
[156,     7] loss: 1.178
[157,     7] loss: 1.223
[158,     7] loss: 1.205
[159,     7] loss: 1.207
[160,     7] loss: 1.178
[161,     7] loss: 1.145
[162,     7] loss: 1.134
[163,     7] loss: 1.154
[164,     7] loss: 1.141
[165,     7] loss: 1.182
[166,     7] loss: 1.168
[167,     7] loss: 1.167
[168,     7] loss: 1.155
[169,     7] loss: 1.179
[170,     7] loss: 1.166
[171,     7] loss: 1.156
[172,     7] loss: 1.147
[173,     7] loss: 1.157
[174,     7] loss: 1.144
[175,     7] loss: 1.193
[176,     7] loss: 1.187
[177,     7] loss: 1.182
[178,     7] loss: 1.169
Early stopping applied (best metric=0.3521970808506012)
Finished Training
Total time taken: 152.8610167503357
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.385
[2,     7] loss: 1.361
[3,     7] loss: 1.329
[4,     7] loss: 1.315
[5,     7] loss: 1.300
[6,     7] loss: 1.297
[7,     7] loss: 1.281
[8,     7] loss: 1.280
[9,     7] loss: 1.265
[10,     7] loss: 1.265
[11,     7] loss: 1.261
[12,     7] loss: 1.248
[13,     7] loss: 1.238
[14,     7] loss: 1.228
[15,     7] loss: 1.247
[16,     7] loss: 1.239
[17,     7] loss: 1.223
[18,     7] loss: 1.227
[19,     7] loss: 1.224
[20,     7] loss: 1.222
[21,     7] loss: 1.228
[22,     7] loss: 1.211
[23,     7] loss: 1.215
[24,     7] loss: 1.224
[25,     7] loss: 1.232
[26,     7] loss: 1.229
[27,     7] loss: 1.215
[28,     7] loss: 1.206
[29,     7] loss: 1.233
[30,     7] loss: 1.208
[31,     7] loss: 1.207
[32,     7] loss: 1.210
[33,     7] loss: 1.190
[34,     7] loss: 1.191
[35,     7] loss: 1.297
[36,     7] loss: 1.261
[37,     7] loss: 1.244
[38,     7] loss: 1.212
[39,     7] loss: 1.196
[40,     7] loss: 1.205
[41,     7] loss: 1.198
[42,     7] loss: 1.194
[43,     7] loss: 1.212
[44,     7] loss: 1.191
[45,     7] loss: 1.186
[46,     7] loss: 1.272
[47,     7] loss: 1.257
[48,     7] loss: 1.250
[49,     7] loss: 1.219
[50,     7] loss: 1.192
[51,     7] loss: 1.178
[52,     7] loss: 1.189
[53,     7] loss: 1.185
[54,     7] loss: 1.186
[55,     7] loss: 1.177
[56,     7] loss: 1.151
[57,     7] loss: 1.186
[58,     7] loss: 1.180
[59,     7] loss: 1.169
[60,     7] loss: 1.168
[61,     7] loss: 1.170
[62,     7] loss: 1.161
[63,     7] loss: 1.201
[64,     7] loss: 1.187
[65,     7] loss: 1.186
[66,     7] loss: 1.161
[67,     7] loss: 1.150
[68,     7] loss: 1.257
[69,     7] loss: 1.318
[70,     7] loss: 1.311
[71,     7] loss: 1.291
[72,     7] loss: 1.251
[73,     7] loss: 1.210
[74,     7] loss: 1.189
[75,     7] loss: 1.202
[76,     7] loss: 1.204
[77,     7] loss: 1.218
[78,     7] loss: 1.166
[79,     7] loss: 1.159
[80,     7] loss: 1.172
[81,     7] loss: 1.167
[82,     7] loss: 1.143
[83,     7] loss: 1.188
[84,     7] loss: 1.214
[85,     7] loss: 1.192
[86,     7] loss: 1.172
[87,     7] loss: 1.171
[88,     7] loss: 1.163
[89,     7] loss: 1.170
[90,     7] loss: 1.164
[91,     7] loss: 1.154
[92,     7] loss: 1.208
[93,     7] loss: 1.214
[94,     7] loss: 1.257
[95,     7] loss: 1.233
[96,     7] loss: 1.201
[97,     7] loss: 1.173
[98,     7] loss: 1.166
[99,     7] loss: 1.147
[100,     7] loss: 1.154
[101,     7] loss: 1.139
[102,     7] loss: 1.189
[103,     7] loss: 1.174
[104,     7] loss: 1.159
[105,     7] loss: 1.140
[106,     7] loss: 1.181
[107,     7] loss: 1.174
[108,     7] loss: 1.140
Early stopping applied (best metric=0.3608887791633606)
Finished Training
Total time taken: 91.92203521728516
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.386
[2,     7] loss: 1.387
[3,     7] loss: 1.386
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.385
[7,     7] loss: 1.369
[8,     7] loss: 1.340
[9,     7] loss: 1.338
[10,     7] loss: 1.312
[11,     7] loss: 1.303
[12,     7] loss: 1.279
[13,     7] loss: 1.309
[14,     7] loss: 1.278
[15,     7] loss: 1.284
[16,     7] loss: 1.245
[17,     7] loss: 1.275
[18,     7] loss: 1.270
[19,     7] loss: 1.241
[20,     7] loss: 1.242
[21,     7] loss: 1.274
[22,     7] loss: 1.263
[23,     7] loss: 1.256
[24,     7] loss: 1.234
[25,     7] loss: 1.231
[26,     7] loss: 1.231
[27,     7] loss: 1.243
[28,     7] loss: 1.247
[29,     7] loss: 1.291
[30,     7] loss: 1.257
[31,     7] loss: 1.239
[32,     7] loss: 1.227
[33,     7] loss: 1.229
[34,     7] loss: 1.239
[35,     7] loss: 1.239
[36,     7] loss: 1.241
[37,     7] loss: 1.227
[38,     7] loss: 1.234
[39,     7] loss: 1.230
[40,     7] loss: 1.243
[41,     7] loss: 1.221
[42,     7] loss: 1.214
[43,     7] loss: 1.219
[44,     7] loss: 1.222
[45,     7] loss: 1.241
[46,     7] loss: 1.229
[47,     7] loss: 1.232
[48,     7] loss: 1.245
[49,     7] loss: 1.245
[50,     7] loss: 1.214
[51,     7] loss: 1.196
[52,     7] loss: 1.186
[53,     7] loss: 1.198
[54,     7] loss: 1.191
[55,     7] loss: 1.200
[56,     7] loss: 1.187
[57,     7] loss: 1.193
[58,     7] loss: 1.192
[59,     7] loss: 1.248
[60,     7] loss: 1.241
[61,     7] loss: 1.203
[62,     7] loss: 1.180
[63,     7] loss: 1.192
[64,     7] loss: 1.186
[65,     7] loss: 1.181
[66,     7] loss: 1.190
[67,     7] loss: 1.201
[68,     7] loss: 1.205
[69,     7] loss: 1.204
[70,     7] loss: 1.187
[71,     7] loss: 1.187
[72,     7] loss: 1.191
[73,     7] loss: 1.165
[74,     7] loss: 1.223
[75,     7] loss: 1.203
[76,     7] loss: 1.208
[77,     7] loss: 1.194
[78,     7] loss: 1.172
[79,     7] loss: 1.197
[80,     7] loss: 1.192
[81,     7] loss: 1.195
[82,     7] loss: 1.179
[83,     7] loss: 1.208
[84,     7] loss: 1.182
[85,     7] loss: 1.191
[86,     7] loss: 1.177
[87,     7] loss: 1.149
[88,     7] loss: 1.151
[89,     7] loss: 1.254
[90,     7] loss: 1.240
[91,     7] loss: 1.198
[92,     7] loss: 1.178
[93,     7] loss: 1.160
[94,     7] loss: 1.179
[95,     7] loss: 1.206
[96,     7] loss: 1.204
[97,     7] loss: 1.196
[98,     7] loss: 1.200
[99,     7] loss: 1.195
[100,     7] loss: 1.261
[101,     7] loss: 1.250
[102,     7] loss: 1.221
[103,     7] loss: 1.185
[104,     7] loss: 1.169
[105,     7] loss: 1.180
[106,     7] loss: 1.192
[107,     7] loss: 1.154
[108,     7] loss: 1.174
[109,     7] loss: 1.187
[110,     7] loss: 1.169
[111,     7] loss: 1.176
[112,     7] loss: 1.175
[113,     7] loss: 1.186
[114,     7] loss: 1.184
[115,     7] loss: 1.177
[116,     7] loss: 1.153
[117,     7] loss: 1.164
[118,     7] loss: 1.198
[119,     7] loss: 1.199
[120,     7] loss: 1.182
[121,     7] loss: 1.183
[122,     7] loss: 1.201
[123,     7] loss: 1.176
[124,     7] loss: 1.170
[125,     7] loss: 1.199
[126,     7] loss: 1.190
[127,     7] loss: 1.161
[128,     7] loss: 1.187
[129,     7] loss: 1.171
[130,     7] loss: 1.161
[131,     7] loss: 1.174
[132,     7] loss: 1.193
[133,     7] loss: 1.192
[134,     7] loss: 1.190
[135,     7] loss: 1.164
[136,     7] loss: 1.159
[137,     7] loss: 1.246
[138,     7] loss: 1.240
[139,     7] loss: 1.189
[140,     7] loss: 1.187
[141,     7] loss: 1.208
[142,     7] loss: 1.186
[143,     7] loss: 1.179
[144,     7] loss: 1.171
[145,     7] loss: 1.148
[146,     7] loss: 1.169
[147,     7] loss: 1.152
[148,     7] loss: 1.188
[149,     7] loss: 1.178
[150,     7] loss: 1.184
[151,     7] loss: 1.164
[152,     7] loss: 1.152
[153,     7] loss: 1.154
[154,     7] loss: 1.168
[155,     7] loss: 1.232
[156,     7] loss: 1.223
[157,     7] loss: 1.186
[158,     7] loss: 1.177
Early stopping applied (best metric=0.35413357615470886)
Finished Training
Total time taken: 135.76965069770813
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.390
[2,     7] loss: 1.386
[3,     7] loss: 1.385
[4,     7] loss: 1.377
[5,     7] loss: 1.354
[6,     7] loss: 1.338
[7,     7] loss: 1.329
[8,     7] loss: 1.318
[9,     7] loss: 1.313
[10,     7] loss: 1.296
[11,     7] loss: 1.275
[12,     7] loss: 1.261
[13,     7] loss: 1.270
[14,     7] loss: 1.284
[15,     7] loss: 1.250
[16,     7] loss: 1.242
[17,     7] loss: 1.243
[18,     7] loss: 1.223
[19,     7] loss: 1.240
[20,     7] loss: 1.240
[21,     7] loss: 1.221
[22,     7] loss: 1.231
[23,     7] loss: 1.204
[24,     7] loss: 1.200
[25,     7] loss: 1.248
[26,     7] loss: 1.235
[27,     7] loss: 1.196
[28,     7] loss: 1.188
[29,     7] loss: 1.227
[30,     7] loss: 1.227
[31,     7] loss: 1.237
[32,     7] loss: 1.212
[33,     7] loss: 1.174
[34,     7] loss: 1.164
[35,     7] loss: 1.194
[36,     7] loss: 1.252
[37,     7] loss: 1.257
[38,     7] loss: 1.213
[39,     7] loss: 1.195
[40,     7] loss: 1.183
[41,     7] loss: 1.161
[42,     7] loss: 1.178
[43,     7] loss: 1.180
[44,     7] loss: 1.154
[45,     7] loss: 1.178
[46,     7] loss: 1.217
[47,     7] loss: 1.257
[48,     7] loss: 1.197
[49,     7] loss: 1.189
[50,     7] loss: 1.179
[51,     7] loss: 1.163
[52,     7] loss: 1.224
[53,     7] loss: 1.200
[54,     7] loss: 1.158
[55,     7] loss: 1.161
[56,     7] loss: 1.149
[57,     7] loss: 1.169
[58,     7] loss: 1.160
[59,     7] loss: 1.145
[60,     7] loss: 1.139
[61,     7] loss: 1.195
[62,     7] loss: 1.245
[63,     7] loss: 1.291
[64,     7] loss: 1.251
[65,     7] loss: 1.247
[66,     7] loss: 1.190
[67,     7] loss: 1.185
[68,     7] loss: 1.175
[69,     7] loss: 1.199
[70,     7] loss: 1.211
[71,     7] loss: 1.178
[72,     7] loss: 1.170
[73,     7] loss: 1.192
[74,     7] loss: 1.200
[75,     7] loss: 1.168
[76,     7] loss: 1.170
[77,     7] loss: 1.187
[78,     7] loss: 1.186
[79,     7] loss: 1.158
[80,     7] loss: 1.160
[81,     7] loss: 1.147
[82,     7] loss: 1.182
[83,     7] loss: 1.232
[84,     7] loss: 1.191
[85,     7] loss: 1.182
[86,     7] loss: 1.160
[87,     7] loss: 1.152
[88,     7] loss: 1.207
[89,     7] loss: 1.178
[90,     7] loss: 1.165
[91,     7] loss: 1.169
[92,     7] loss: 1.147
[93,     7] loss: 1.146
[94,     7] loss: 1.177
[95,     7] loss: 1.164
[96,     7] loss: 1.157
[97,     7] loss: 1.149
[98,     7] loss: 1.155
[99,     7] loss: 1.173
[100,     7] loss: 1.216
[101,     7] loss: 1.197
[102,     7] loss: 1.170
[103,     7] loss: 1.144
[104,     7] loss: 1.207
[105,     7] loss: 1.197
[106,     7] loss: 1.176
[107,     7] loss: 1.150
[108,     7] loss: 1.154
[109,     7] loss: 1.148
[110,     7] loss: 1.157
[111,     7] loss: 1.160
[112,     7] loss: 1.174
[113,     7] loss: 1.209
[114,     7] loss: 1.181
[115,     7] loss: 1.165
[116,     7] loss: 1.220
[117,     7] loss: 1.205
[118,     7] loss: 1.163
[119,     7] loss: 1.141
[120,     7] loss: 1.164
[121,     7] loss: 1.159
[122,     7] loss: 1.152
[123,     7] loss: 1.148
[124,     7] loss: 1.170
[125,     7] loss: 1.208
[126,     7] loss: 1.146
[127,     7] loss: 1.146
[128,     7] loss: 1.133
[129,     7] loss: 1.244
[130,     7] loss: 1.281
[131,     7] loss: 1.281
[132,     7] loss: 1.255
[133,     7] loss: 1.210
[134,     7] loss: 1.163
[135,     7] loss: 1.144
[136,     7] loss: 1.146
[137,     7] loss: 1.159
[138,     7] loss: 1.167
[139,     7] loss: 1.162
[140,     7] loss: 1.141
[141,     7] loss: 1.197
[142,     7] loss: 1.224
[143,     7] loss: 1.174
[144,     7] loss: 1.169
[145,     7] loss: 1.163
[146,     7] loss: 1.170
[147,     7] loss: 1.186
[148,     7] loss: 1.202
[149,     7] loss: 1.172
[150,     7] loss: 1.174
[151,     7] loss: 1.232
[152,     7] loss: 1.225
[153,     7] loss: 1.182
[154,     7] loss: 1.169
[155,     7] loss: 1.167
[156,     7] loss: 1.158
[157,     7] loss: 1.164
[158,     7] loss: 1.139
[159,     7] loss: 1.167
[160,     7] loss: 1.249
[161,     7] loss: 1.250
[162,     7] loss: 1.188
[163,     7] loss: 1.194
[164,     7] loss: 1.165
[165,     7] loss: 1.166
[166,     7] loss: 1.174
[167,     7] loss: 1.190
[168,     7] loss: 1.164
[169,     7] loss: 1.146
[170,     7] loss: 1.164
[171,     7] loss: 1.183
[172,     7] loss: 1.171
[173,     7] loss: 1.144
[174,     7] loss: 1.189
[175,     7] loss: 1.192
[176,     7] loss: 1.212
[177,     7] loss: 1.197
[178,     7] loss: 1.174
[179,     7] loss: 1.139
[180,     7] loss: 1.163
[181,     7] loss: 1.183
[182,     7] loss: 1.144
[183,     7] loss: 1.198
[184,     7] loss: 1.188
[185,     7] loss: 1.155
[186,     7] loss: 1.144
[187,     7] loss: 1.195
[188,     7] loss: 1.182
[189,     7] loss: 1.165
[190,     7] loss: 1.164
[191,     7] loss: 1.203
[192,     7] loss: 1.219
[193,     7] loss: 1.200
[194,     7] loss: 1.177
[195,     7] loss: 1.142
[196,     7] loss: 1.150
[197,     7] loss: 1.287
[198,     7] loss: 1.344
[199,     7] loss: 1.312
[200,     7] loss: 1.310
Finished Training
Total time taken: 171.10558915138245
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.386
[2,     7] loss: 1.386
[3,     7] loss: 1.385
[4,     7] loss: 1.382
[5,     7] loss: 1.359
[6,     7] loss: 1.331
[7,     7] loss: 1.298
[8,     7] loss: 1.268
[9,     7] loss: 1.242
[10,     7] loss: 1.221
[11,     7] loss: 1.216
[12,     7] loss: 1.204
[13,     7] loss: 1.215
[14,     7] loss: 1.196
[15,     7] loss: 1.203
[16,     7] loss: 1.187
[17,     7] loss: 1.169
[18,     7] loss: 1.169
[19,     7] loss: 1.146
[20,     7] loss: 1.162
[21,     7] loss: 1.171
[22,     7] loss: 1.163
[23,     7] loss: 1.136
[24,     7] loss: 1.141
[25,     7] loss: 1.161
[26,     7] loss: 1.130
[27,     7] loss: 1.133
[28,     7] loss: 1.130
[29,     7] loss: 1.155
[30,     7] loss: 1.141
[31,     7] loss: 1.152
[32,     7] loss: 1.162
[33,     7] loss: 1.170
[34,     7] loss: 1.144
[35,     7] loss: 1.144
[36,     7] loss: 1.136
[37,     7] loss: 1.159
[38,     7] loss: 1.144
[39,     7] loss: 1.148
[40,     7] loss: 1.153
[41,     7] loss: 1.130
[42,     7] loss: 1.109
[43,     7] loss: 1.155
[44,     7] loss: 1.190
[45,     7] loss: 1.174
[46,     7] loss: 1.139
[47,     7] loss: 1.132
[48,     7] loss: 1.121
[49,     7] loss: 1.130
[50,     7] loss: 1.127
[51,     7] loss: 1.103
Early stopping applied (best metric=0.4443967044353485)
Finished Training
Total time taken: 43.69315218925476
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.387
[2,     7] loss: 1.386
[3,     7] loss: 1.387
[4,     7] loss: 1.386
[5,     7] loss: 1.386
[6,     7] loss: 1.384
[7,     7] loss: 1.371
[8,     7] loss: 1.346
[9,     7] loss: 1.325
[10,     7] loss: 1.306
[11,     7] loss: 1.291
[12,     7] loss: 1.260
[13,     7] loss: 1.231
[14,     7] loss: 1.240
[15,     7] loss: 1.217
[16,     7] loss: 1.195
[17,     7] loss: 1.177
[18,     7] loss: 1.216
[19,     7] loss: 1.202
[20,     7] loss: 1.170
[21,     7] loss: 1.177
[22,     7] loss: 1.158
[23,     7] loss: 1.150
[24,     7] loss: 1.176
[25,     7] loss: 1.210
[26,     7] loss: 1.168
[27,     7] loss: 1.152
[28,     7] loss: 1.162
[29,     7] loss: 1.139
[30,     7] loss: 1.145
[31,     7] loss: 1.161
[32,     7] loss: 1.128
[33,     7] loss: 1.148
[34,     7] loss: 1.124
[35,     7] loss: 1.125
[36,     7] loss: 1.184
[37,     7] loss: 1.152
[38,     7] loss: 1.149
[39,     7] loss: 1.143
[40,     7] loss: 1.138
[41,     7] loss: 1.162
[42,     7] loss: 1.126
[43,     7] loss: 1.141
[44,     7] loss: 1.187
[45,     7] loss: 1.176
[46,     7] loss: 1.147
[47,     7] loss: 1.142
[48,     7] loss: 1.139
[49,     7] loss: 1.153
[50,     7] loss: 1.134
[51,     7] loss: 1.151
Early stopping applied (best metric=0.44032758474349976)
Finished Training
Total time taken: 44.078962087631226
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6032
1130 7417
[1,     1] loss: 1.384
[2,     7] loss: 1.382
[3,     7] loss: 1.348
[4,     7] loss: 1.322
[5,     7] loss: 1.310
[6,     7] loss: 1.308
[7,     7] loss: 1.294
[8,     7] loss: 1.279
[9,     7] loss: 1.264
[10,     7] loss: 1.266
[11,     7] loss: 1.269
[12,     7] loss: 1.253
[13,     7] loss: 1.266
[14,     7] loss: 1.248
[15,     7] loss: 1.234
[16,     7] loss: 1.238
[17,     7] loss: 1.245
[18,     7] loss: 1.239
[19,     7] loss: 1.235
[20,     7] loss: 1.225
[21,     7] loss: 1.228
[22,     7] loss: 1.259
[23,     7] loss: 1.246
[24,     7] loss: 1.225
[25,     7] loss: 1.226
[26,     7] loss: 1.220
[27,     7] loss: 1.210
[28,     7] loss: 1.234
[29,     7] loss: 1.223
[30,     7] loss: 1.197
[31,     7] loss: 1.200
[32,     7] loss: 1.205
[33,     7] loss: 1.210
[34,     7] loss: 1.177
[35,     7] loss: 1.221
[36,     7] loss: 1.193
[37,     7] loss: 1.196
[38,     7] loss: 1.184
[39,     7] loss: 1.188
[40,     7] loss: 1.191
[41,     7] loss: 1.204
[42,     7] loss: 1.218
[43,     7] loss: 1.189
[44,     7] loss: 1.163
[45,     7] loss: 1.182
[46,     7] loss: 1.174
[47,     7] loss: 1.179
[48,     7] loss: 1.275
[49,     7] loss: 1.236
[50,     7] loss: 1.214
[51,     7] loss: 1.183
[52,     7] loss: 1.200
[53,     7] loss: 1.164
[54,     7] loss: 1.206
[55,     7] loss: 1.181
[56,     7] loss: 1.185
[57,     7] loss: 1.264
[58,     7] loss: 1.213
[59,     7] loss: 1.177
[60,     7] loss: 1.155
[61,     7] loss: 1.170
[62,     7] loss: 1.212
[63,     7] loss: 1.195
[64,     7] loss: 1.192
[65,     7] loss: 1.177
[66,     7] loss: 1.158
[67,     7] loss: 1.275
[68,     7] loss: 1.255
[69,     7] loss: 1.228
[70,     7] loss: 1.195
[71,     7] loss: 1.211
[72,     7] loss: 1.210
[73,     7] loss: 1.193
[74,     7] loss: 1.178
[75,     7] loss: 1.174
[76,     7] loss: 1.160
[77,     7] loss: 1.203
[78,     7] loss: 1.233
[79,     7] loss: 1.293
[80,     7] loss: 1.233
[81,     7] loss: 1.217
[82,     7] loss: 1.199
[83,     7] loss: 1.179
[84,     7] loss: 1.174
[85,     7] loss: 1.186
[86,     7] loss: 1.180
[87,     7] loss: 1.185
[88,     7] loss: 1.182
[89,     7] loss: 1.184
[90,     7] loss: 1.178
[91,     7] loss: 1.168
[92,     7] loss: 1.198
[93,     7] loss: 1.166
[94,     7] loss: 1.168
[95,     7] loss: 1.170
[96,     7] loss: 1.175
[97,     7] loss: 1.151
[98,     7] loss: 1.147
[99,     7] loss: 1.234
[100,     7] loss: 1.196
[101,     7] loss: 1.197
[102,     7] loss: 1.191
[103,     7] loss: 1.155
[104,     7] loss: 1.147
[105,     7] loss: 1.153
[106,     7] loss: 1.144
[107,     7] loss: 1.233
[108,     7] loss: 1.187
[109,     7] loss: 1.179
[110,     7] loss: 1.191
[111,     7] loss: 1.180
[112,     7] loss: 1.242
[113,     7] loss: 1.191
[114,     7] loss: 1.172
[115,     7] loss: 1.159
[116,     7] loss: 1.164
[117,     7] loss: 1.153
[118,     7] loss: 1.205
[119,     7] loss: 1.248
[120,     7] loss: 1.286
[121,     7] loss: 1.250
[122,     7] loss: 1.214
[123,     7] loss: 1.175
[124,     7] loss: 1.174
[125,     7] loss: 1.196
[126,     7] loss: 1.213
[127,     7] loss: 1.177
[128,     7] loss: 1.160
[129,     7] loss: 1.237
[130,     7] loss: 1.225
[131,     7] loss: 1.191
[132,     7] loss: 1.165
[133,     7] loss: 1.171
[134,     7] loss: 1.193
[135,     7] loss: 1.165
[136,     7] loss: 1.160
[137,     7] loss: 1.157
[138,     7] loss: 1.156
[139,     7] loss: 1.150
[140,     7] loss: 1.176
[141,     7] loss: 1.174
Early stopping applied (best metric=0.3610936403274536)
Finished Training
Total time taken: 98.43894100189209
(3769,)
Loaded folder code/Thesis/dataset/train/Methylation-R/indices (44519 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
919 6034
1130 7420
[1,     1] loss: 1.387
[2,     7] loss: 1.384
[3,     7] loss: 1.372
[4,     7] loss: 1.342
[5,     7] loss: 1.327
[6,     7] loss: 1.312
[7,     7] loss: 1.295
[8,     7] loss: 1.279
[9,     7] loss: 1.268
[10,     7] loss: 1.264
[11,     7] loss: 1.258
[12,     7] loss: 1.276
[13,     7] loss: 1.245
[14,     7] loss: 1.248
[15,     7] loss: 1.257
[16,     7] loss: 1.243
[17,     7] loss: 1.241
[18,     7] loss: 1.242
[19,     7] loss: 1.258
[20,     7] loss: 1.250
[21,     7] loss: 1.234
[22,     7] loss: 1.228
[23,     7] loss: 1.229
[24,     7] loss: 1.252
[25,     7] loss: 1.218
[26,     7] loss: 1.234
[27,     7] loss: 1.218
[28,     7] loss: 1.214
[29,     7] loss: 1.226
[30,     7] loss: 1.214
[31,     7] loss: 1.204
[32,     7] loss: 1.225
[33,     7] loss: 1.203
[34,     7] loss: 1.235
[35,     7] loss: 1.245
[36,     7] loss: 1.254
[37,     7] loss: 1.220
[38,     7] loss: 1.195
[39,     7] loss: 1.178
[40,     7] loss: 1.200
[41,     7] loss: 1.269
[42,     7] loss: 1.249
[43,     7] loss: 1.228
[44,     7] loss: 1.210
[45,     7] loss: 1.214
[46,     7] loss: 1.225
[47,     7] loss: 1.205
[48,     7] loss: 1.193
[49,     7] loss: 1.189
[50,     7] loss: 1.195
[51,     7] loss: 1.194
[52,     7] loss: 1.178
[53,     7] loss: 1.187
[54,     7] loss: 1.161
[55,     7] loss: 1.152
[56,     7] loss: 1.186
[57,     7] loss: 1.187
[58,     7] loss: 1.197
[59,     7] loss: 1.230
[60,     7] loss: 1.193
[61,     7] loss: 1.158
[62,     7] loss: 1.169
[63,     7] loss: 1.176
[64,     7] loss: 1.183
[65,     7] loss: 1.179
[66,     7] loss: 1.179
[67,     7] loss: 1.171
[68,     7] loss: 1.285
[69,     7] loss: 1.274
[70,     7] loss: 1.217
[71,     7] loss: 1.201
[72,     7] loss: 1.180
[73,     7] loss: 1.154
[74,     7] loss: 1.164
[75,     7] loss: 1.163
[76,     7] loss: 1.215
[77,     7] loss: 1.216
[78,     7] loss: 1.195
[79,     7] loss: 1.167
[80,     7] loss: 1.202
[81,     7] loss: 1.170
[82,     7] loss: 1.163
[83,     7] loss: 1.156
[84,     7] loss: 1.172
[85,     7] loss: 1.221
[86,     7] loss: 1.177
[87,     7] loss: 1.161
[88,     7] loss: 1.163
[89,     7] loss: 1.156
[90,     7] loss: 1.154
[91,     7] loss: 1.152
[92,     7] loss: 1.155
[93,     7] loss: 1.168
[94,     7] loss: 1.173
[95,     7] loss: 1.153
[96,     7] loss: 1.144
[97,     7] loss: 1.185
[98,     7] loss: 1.227
[99,     7] loss: 1.199
[100,     7] loss: 1.177
[101,     7] loss: 1.139
[102,     7] loss: 1.186
[103,     7] loss: 1.162
[104,     7] loss: 1.160
[105,     7] loss: 1.173
[106,     7] loss: 1.161
[107,     7] loss: 1.149
[108,     7] loss: 1.153
[109,     7] loss: 1.177
Early stopping applied (best metric=0.35848841071128845)
Finished Training
Total time taken: 70.0142126083374
results!
{'gpu_mode': True, 'epochs': 200, 'batch_size': 2048, 'learning_rate': 0.003662719046686193, 'test_data_ratio': 0.2, 'data_sample_mode': ['balanced', 'balanced'], 'crossValidation': True, 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'folds': 5, 'earlyStopping': True, 'ValidationMetric': 'Validation Loss (Methylation-K)', 'earlyStoppingPatience': 50, 'CV_Repeats': 5, 'Experiment Name': 'Model architecture - added max, ranges, bceloss', 'CreateFigures': False, 'weight_decay': 5.650775207838844, 'embeddingType': 'adaptiveEmbedding', 'LSTM_layers': 1, 'LSTM_hidden_size': 64, 'LSTM_dropout': 0, 'MultiTask': True, 'MultiTask_sample_method': 'balanced', 'UseUncertaintyBasedLoss': False, 'useLrWeight': False, 'CNNType': 'Musite', 'FCType': 'Adapt', 'layerToSplitOn': 'FC', 'dontAverageLoss': False, 'useWeightDecayWeight': False, 'SeperateTuningLRandWD': True, 'aminoAcid': ['Methylation-R', 'Methylation-K'], 'n_trials': 500, 'FloatsToTune': {'learning_rate': [1e-05, 0.01], 'weight_decay': [0, 10], 'learning_rate_Methylation-R': [1e-05, 0.01], 'learning_rate_Methylation-K': [1e-05, 0.01], 'weight_decay_Methylation-R': [0, 10], 'weight_decay_Methylation-K': [0, 10], 'loss_weight_Methylation-R': [1e-05, 0.9999], 'loss_weight_Methylation-K': [1e-05, 0.9999]}, 'IntsToTune': {}, 'learning_rate_Methylation-R': 0.0015559816554853042, 'learning_rate_Methylation-K': 0.000884349934580072, 'weight_decay_Methylation-R': 8.648151857081196, 'weight_decay_Methylation-K': 5.109977756977147, 'loss_weight_Methylation-R': 0.942802226841444, 'loss_weight_Methylation-K': 0.12507645059825023, 'random_state': 397456117, 'current_CV_Repeat': 5, 'sample_weights': [0.942802226841444, 0.12507645059825023], 'WeightDecayWeights': [], 'currentFold': 4}
{'Methylation-R Validation Accuracy': 0.5491245079366425, 'Methylation-R Validation Sensitivity': 0.8340577918212209, 'Methylation-R Validation Specificity': 0.5227680981595092, 'Methylation-R Validation Precision': 0.14666763821447887, 'Methylation-R AUC ROC': 0.7786859602343962, 'Methylation-R AUC PR': 0.3290772973550854, 'Methylation-R MCC': 0.2017522825950782, 'Methylation-R F1': 0.24769691616097128, 'Validation Loss (Methylation-R)': 0.32496945023536683, 'Methylation-K Validation Accuracy': 0.4290748406607343, 'Methylation-K Validation Sensitivity': 0.8769089074815762, 'Methylation-K Validation Specificity': 0.380505984410666, 'Methylation-K Validation Precision': 0.13564388038192438, 'Methylation-K AUC ROC': 0.709453183003727, 'Methylation-K AUC PR': 0.21491008100789374, 'Methylation-K MCC': 0.158023199766075, 'Methylation-K F1': 0.2342927736370962, 'Validation Loss (Methylation-K)': 0.36419185042381286, 'Validation Loss (total)': 0.689161298274994, 'TimeToTrain': 119.48019526481629}
{'Methylation-R Validation Accuracy': 0.156490885648231, 'Methylation-R Validation Sensitivity': 0.0701603351863067, 'Methylation-R Validation Specificity': 0.1769199573498366, 'Methylation-R Validation Precision': 0.024556071087953706, 'Methylation-R AUC ROC': 0.038865918606006744, 'Methylation-R AUC PR': 0.04951721594891021, 'Methylation-R MCC': 0.06545200996802598, 'Methylation-R F1': 0.034810165353679666, 'Validation Loss (Methylation-R)': 0.03349478671442775, 'Methylation-K Validation Accuracy': 0.11326449721138228, 'Methylation-K Validation Sensitivity': 0.05252160768255776, 'Methylation-K Validation Specificity': 0.13074467093037764, 'Methylation-K Validation Precision': 0.014422291618872882, 'Methylation-K AUC ROC': 0.06685191238336922, 'Methylation-K AUC PR': 0.04360215521347593, 'Methylation-K MCC': 0.0508202174439907, 'Methylation-K F1': 0.02080798670889446, 'Validation Loss (Methylation-K)': 0.025559624934229908, 'Validation Loss (total)': 0.05637176372946302, 'TimeToTrain': 42.291878389366836}
