{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0062554491716299105,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21902433417999975,
 'loss_weight_S-palmitoylation-C': 0.5907189823488217,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2783069367,
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.662733833213537,
 'weight_decay_Hydroxylation-K': 2.7293623193170715,
 'weight_decay_S-palmitoylation-C': 3.8759201131242813}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.403
[3,     3] loss: 1.383
[4,     3] loss: 1.383
[5,     3] loss: 1.414
[6,     3] loss: 1.396
[7,     3] loss: 1.386
[8,     3] loss: 1.384
[9,     3] loss: 1.390
[10,     3] loss: 1.389
[11,     3] loss: 1.386
[12,     3] loss: 1.389
[13,     3] loss: 1.385
[14,     3] loss: 1.388
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.384
[20,     3] loss: 1.381
[21,     3] loss: 1.359
[22,     3] loss: 1.283
[23,     3] loss: 1.345
[24,     3] loss: 1.325
[25,     3] loss: 1.352
[26,     3] loss: 1.291
[27,     3] loss: 1.330
[28,     3] loss: 1.292
[29,     3] loss: 1.197
[30,     3] loss: 1.217
[31,     3] loss: 1.012
[32,     3] loss: 1.179
[33,     3] loss: 1.241
[34,     3] loss: 1.176
[35,     3] loss: 1.196
[36,     3] loss: 1.010
[37,     3] loss: 1.064
[38,     3] loss: 1.003
[39,     3] loss: 1.491
[40,     3] loss: 1.230
[41,     3] loss: 1.271
[42,     3] loss: 1.278
[43,     3] loss: 1.217
[44,     3] loss: 1.221
[45,     3] loss: 1.188
[46,     3] loss: 1.069
[47,     3] loss: 1.007
[48,     3] loss: 1.134
[49,     3] loss: 1.402
[50,     3] loss: 1.170
[51,     3] loss: 1.282
[52,     3] loss: 1.255
[53,     3] loss: 1.254
[54,     3] loss: 1.173
[55,     3] loss: 1.038
[56,     3] loss: 1.038
[57,     3] loss: 1.033
[58,     3] loss: 1.035
[59,     3] loss: 1.095
[60,     3] loss: 1.095
[61,     3] loss: 1.150
[62,     3] loss: 1.219
[63,     3] loss: 1.176
[64,     3] loss: 1.218
[65,     3] loss: 1.129
[66,     3] loss: 1.162
[67,     3] loss: 1.042
[68,     3] loss: 1.103
[69,     3] loss: 0.938
[70,     3] loss: 0.950
[71,     3] loss: 0.939
[72,     3] loss: 1.177
[73,     3] loss: 1.010
[74,     3] loss: 1.084
[75,     3] loss: 1.134
[76,     3] loss: 0.993
[77,     3] loss: 1.016
[78,     3] loss: 1.058
[79,     3] loss: 0.969
[80,     3] loss: 1.148
[81,     3] loss: 1.183
[82,     3] loss: 1.053
[83,     3] loss: 1.091
[84,     3] loss: 1.098
[85,     3] loss: 1.010
[86,     3] loss: 0.947
[87,     3] loss: 0.951
[88,     3] loss: 0.956
[89,     3] loss: 1.233
[90,     3] loss: 1.000
[91,     3] loss: 1.071
[92,     3] loss: 1.060
[93,     3] loss: 1.036
[94,     3] loss: 1.003
[95,     3] loss: 0.900
[96,     3] loss: 0.841
[97,     3] loss: 0.894
[98,     3] loss: 0.861
[99,     3] loss: 0.813
[100,     3] loss: 0.811
[101,     3] loss: 0.987
[102,     3] loss: 1.166
[103,     3] loss: 1.262
[104,     3] loss: 1.190
[105,     3] loss: 1.263
[106,     3] loss: 1.135
[107,     3] loss: 1.055
[108,     3] loss: 1.257
[109,     3] loss: 1.215
[110,     3] loss: 1.081
[111,     3] loss: 1.054
[112,     3] loss: 1.018
[113,     3] loss: 0.962
[114,     3] loss: 1.016
[115,     3] loss: 1.003
[116,     3] loss: 0.977
[117,     3] loss: 0.934
[118,     3] loss: 1.089
[119,     3] loss: 0.915
Early stopping applied (best metric=0.5299274325370789)
Finished Training
Total time taken: 40.93105864524841
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.404
[3,     3] loss: 1.392
[4,     3] loss: 1.383
[5,     3] loss: 1.393
[6,     3] loss: 1.392
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.381
[10,     3] loss: 1.401
[11,     3] loss: 1.394
[12,     3] loss: 1.386
[13,     3] loss: 1.385
[14,     3] loss: 1.384
[15,     3] loss: 1.381
[16,     3] loss: 1.391
[17,     3] loss: 1.383
[18,     3] loss: 1.384
[19,     3] loss: 1.392
[20,     3] loss: 1.386
[21,     3] loss: 1.384
[22,     3] loss: 1.389
[23,     3] loss: 1.386
[24,     3] loss: 1.385
[25,     3] loss: 1.384
[26,     3] loss: 1.385
[27,     3] loss: 1.388
[28,     3] loss: 1.390
[29,     3] loss: 1.386
[30,     3] loss: 1.389
[31,     3] loss: 1.385
[32,     3] loss: 1.385
[33,     3] loss: 1.384
[34,     3] loss: 1.380
[35,     3] loss: 1.363
[36,     3] loss: 1.337
[37,     3] loss: 1.337
[38,     3] loss: 1.340
[39,     3] loss: 1.186
[40,     3] loss: 1.160
[41,     3] loss: 1.650
[42,     3] loss: 1.356
[43,     3] loss: 1.358
[44,     3] loss: 1.395
[45,     3] loss: 1.373
[46,     3] loss: 1.374
[47,     3] loss: 1.361
[48,     3] loss: 1.296
[49,     3] loss: 1.225
[50,     3] loss: 1.298
[51,     3] loss: 1.294
[52,     3] loss: 1.272
[53,     3] loss: 1.273
[54,     3] loss: 1.242
[55,     3] loss: 1.137
[56,     3] loss: 1.143
[57,     3] loss: 1.191
[58,     3] loss: 1.201
[59,     3] loss: 1.203
[60,     3] loss: 1.116
[61,     3] loss: 1.051
[62,     3] loss: 1.063
[63,     3] loss: 1.061
[64,     3] loss: 1.113
[65,     3] loss: 1.052
[66,     3] loss: 1.034
[67,     3] loss: 0.931
[68,     3] loss: 0.867
[69,     3] loss: 0.979
[70,     3] loss: 1.187
[71,     3] loss: 1.289
[72,     3] loss: 1.262
[73,     3] loss: 1.219
[74,     3] loss: 1.163
[75,     3] loss: 1.146
[76,     3] loss: 1.103
[77,     3] loss: 1.155
[78,     3] loss: 1.079
[79,     3] loss: 1.068
[80,     3] loss: 1.073
[81,     3] loss: 1.069
[82,     3] loss: 1.181
[83,     3] loss: 1.239
[84,     3] loss: 1.086
[85,     3] loss: 1.098
[86,     3] loss: 1.140
[87,     3] loss: 1.038
[88,     3] loss: 1.050
[89,     3] loss: 0.898
[90,     3] loss: 0.922
[91,     3] loss: 0.985
[92,     3] loss: 0.959
[93,     3] loss: 0.990
[94,     3] loss: 1.030
[95,     3] loss: 0.971
[96,     3] loss: 0.935
[97,     3] loss: 0.934
[98,     3] loss: 1.073
[99,     3] loss: 0.977
[100,     3] loss: 1.018
[101,     3] loss: 0.981
[102,     3] loss: 1.038
[103,     3] loss: 0.944
[104,     3] loss: 0.915
[105,     3] loss: 0.885
[106,     3] loss: 0.869
[107,     3] loss: 0.952
[108,     3] loss: 0.982
[109,     3] loss: 1.060
[110,     3] loss: 0.976
[111,     3] loss: 1.008
[112,     3] loss: 0.991
[113,     3] loss: 1.021
[114,     3] loss: 1.048
[115,     3] loss: 1.085
[116,     3] loss: 1.069
[117,     3] loss: 0.969
[118,     3] loss: 0.874
Early stopping applied (best metric=0.5368318557739258)
Finished Training
Total time taken: 36.45213317871094
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.381
[3,     3] loss: 1.384
[4,     3] loss: 1.389
[5,     3] loss: 1.383
[6,     3] loss: 1.382
[7,     3] loss: 1.387
[8,     3] loss: 1.375
[9,     3] loss: 1.393
[10,     3] loss: 1.371
[11,     3] loss: 1.380
[12,     3] loss: 1.377
[13,     3] loss: 1.353
[14,     3] loss: 1.311
[15,     3] loss: 1.283
[16,     3] loss: 1.216
[17,     3] loss: 1.187
[18,     3] loss: 1.253
[19,     3] loss: 1.187
[20,     3] loss: 1.184
[21,     3] loss: 1.218
[22,     3] loss: 1.133
[23,     3] loss: 1.126
[24,     3] loss: 1.093
[25,     3] loss: 1.014
[26,     3] loss: 1.149
[27,     3] loss: 0.998
[28,     3] loss: 1.003
[29,     3] loss: 0.995
[30,     3] loss: 1.006
[31,     3] loss: 1.044
[32,     3] loss: 1.119
[33,     3] loss: 0.967
[34,     3] loss: 0.934
[35,     3] loss: 0.896
[36,     3] loss: 1.022
[37,     3] loss: 0.978
[38,     3] loss: 0.928
[39,     3] loss: 1.009
[40,     3] loss: 0.996
[41,     3] loss: 0.949
[42,     3] loss: 0.898
[43,     3] loss: 0.934
[44,     3] loss: 1.164
[45,     3] loss: 0.951
[46,     3] loss: 1.061
[47,     3] loss: 1.079
[48,     3] loss: 1.022
[49,     3] loss: 1.022
[50,     3] loss: 0.958
[51,     3] loss: 1.034
[52,     3] loss: 0.927
[53,     3] loss: 0.854
[54,     3] loss: 0.922
[55,     3] loss: 0.834
[56,     3] loss: 0.874
[57,     3] loss: 0.908
[58,     3] loss: 1.241
[59,     3] loss: 1.182
[60,     3] loss: 1.279
[61,     3] loss: 1.287
[62,     3] loss: 1.139
[63,     3] loss: 1.212
[64,     3] loss: 1.136
[65,     3] loss: 1.023
[66,     3] loss: 0.984
[67,     3] loss: 1.066
[68,     3] loss: 0.860
[69,     3] loss: 1.047
[70,     3] loss: 0.986
[71,     3] loss: 0.873
[72,     3] loss: 0.840
[73,     3] loss: 0.877
[74,     3] loss: 0.814
[75,     3] loss: 0.927
[76,     3] loss: 0.872
[77,     3] loss: 0.997
[78,     3] loss: 0.981
[79,     3] loss: 1.068
[80,     3] loss: 1.057
[81,     3] loss: 0.922
[82,     3] loss: 0.924
[83,     3] loss: 0.877
[84,     3] loss: 0.804
[85,     3] loss: 0.959
[86,     3] loss: 0.865
[87,     3] loss: 0.984
[88,     3] loss: 0.977
[89,     3] loss: 0.953
[90,     3] loss: 0.835
[91,     3] loss: 0.803
[92,     3] loss: 0.778
[93,     3] loss: 0.768
[94,     3] loss: 0.764
[95,     3] loss: 1.030
[96,     3] loss: 1.402
[97,     3] loss: 1.255
[98,     3] loss: 1.234
[99,     3] loss: 1.286
[100,     3] loss: 1.242
[101,     3] loss: 1.183
[102,     3] loss: 1.137
[103,     3] loss: 1.131
[104,     3] loss: 1.102
[105,     3] loss: 1.032
[106,     3] loss: 0.988
[107,     3] loss: 0.971
[108,     3] loss: 1.045
[109,     3] loss: 1.035
[110,     3] loss: 1.004
[111,     3] loss: 0.932
[112,     3] loss: 1.015
[113,     3] loss: 1.242
[114,     3] loss: 0.985
[115,     3] loss: 1.054
[116,     3] loss: 0.989
[117,     3] loss: 0.886
[118,     3] loss: 0.819
[119,     3] loss: 0.874
[120,     3] loss: 1.115
[121,     3] loss: 0.885
[122,     3] loss: 0.846
[123,     3] loss: 1.051
[124,     3] loss: 1.039
[125,     3] loss: 1.122
[126,     3] loss: 0.943
[127,     3] loss: 0.994
[128,     3] loss: 0.941
[129,     3] loss: 0.962
[130,     3] loss: 0.912
[131,     3] loss: 0.909
[132,     3] loss: 0.922
Early stopping applied (best metric=0.545828104019165)
Finished Training
Total time taken: 39.82609033584595
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.391
[3,     3] loss: 1.388
[4,     3] loss: 1.374
[5,     3] loss: 1.399
[6,     3] loss: 1.409
[7,     3] loss: 1.388
[8,     3] loss: 1.400
[9,     3] loss: 1.385
[10,     3] loss: 1.388
[11,     3] loss: 1.384
[12,     3] loss: 1.384
[13,     3] loss: 1.387
[14,     3] loss: 1.385
[15,     3] loss: 1.382
[16,     3] loss: 1.388
[17,     3] loss: 1.385
[18,     3] loss: 1.365
[19,     3] loss: 1.328
[20,     3] loss: 1.264
[21,     3] loss: 1.223
[22,     3] loss: 1.348
[23,     3] loss: 1.159
[24,     3] loss: 1.151
[25,     3] loss: 1.206
[26,     3] loss: 1.159
[27,     3] loss: 1.128
[28,     3] loss: 1.146
[29,     3] loss: 1.123
[30,     3] loss: 1.041
[31,     3] loss: 0.991
[32,     3] loss: 0.950
[33,     3] loss: 0.907
[34,     3] loss: 1.020
[35,     3] loss: 0.855
[36,     3] loss: 0.855
[37,     3] loss: 0.885
[38,     3] loss: 0.911
[39,     3] loss: 0.857
[40,     3] loss: 1.136
[41,     3] loss: 0.931
[42,     3] loss: 0.851
[43,     3] loss: 0.896
[44,     3] loss: 0.881
[45,     3] loss: 1.179
[46,     3] loss: 1.094
[47,     3] loss: 1.115
[48,     3] loss: 1.040
[49,     3] loss: 0.993
[50,     3] loss: 0.962
[51,     3] loss: 0.978
[52,     3] loss: 0.895
[53,     3] loss: 0.937
[54,     3] loss: 0.838
[55,     3] loss: 0.812
[56,     3] loss: 0.818
[57,     3] loss: 0.911
[58,     3] loss: 1.191
[59,     3] loss: 0.917
[60,     3] loss: 0.974
[61,     3] loss: 0.919
[62,     3] loss: 0.985
[63,     3] loss: 0.939
[64,     3] loss: 1.051
[65,     3] loss: 0.969
[66,     3] loss: 0.977
[67,     3] loss: 0.965
[68,     3] loss: 0.886
[69,     3] loss: 0.999
[70,     3] loss: 0.958
[71,     3] loss: 0.917
[72,     3] loss: 0.954
[73,     3] loss: 0.863
[74,     3] loss: 0.815
[75,     3] loss: 0.793
[76,     3] loss: 0.796
[77,     3] loss: 1.511
[78,     3] loss: 1.128
[79,     3] loss: 1.154
[80,     3] loss: 1.065
[81,     3] loss: 1.120
[82,     3] loss: 1.114
[83,     3] loss: 0.990
Early stopping applied (best metric=0.5378801226615906)
Finished Training
Total time taken: 25.142875909805298
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.391
[3,     3] loss: 1.387
[4,     3] loss: 1.389
[5,     3] loss: 1.385
[6,     3] loss: 1.388
[7,     3] loss: 1.382
[8,     3] loss: 1.382
[9,     3] loss: 1.389
[10,     3] loss: 1.381
[11,     3] loss: 1.391
[12,     3] loss: 1.380
[13,     3] loss: 1.385
[14,     3] loss: 1.390
[15,     3] loss: 1.390
[16,     3] loss: 1.389
[17,     3] loss: 1.388
[18,     3] loss: 1.385
[19,     3] loss: 1.385
[20,     3] loss: 1.385
[21,     3] loss: 1.370
[22,     3] loss: 1.333
[23,     3] loss: 1.406
[24,     3] loss: 1.307
[25,     3] loss: 1.307
[26,     3] loss: 1.267
[27,     3] loss: 1.189
[28,     3] loss: 1.284
[29,     3] loss: 1.468
[30,     3] loss: 1.287
[31,     3] loss: 1.431
[32,     3] loss: 1.337
[33,     3] loss: 1.292
[34,     3] loss: 1.245
[35,     3] loss: 1.236
[36,     3] loss: 1.196
[37,     3] loss: 1.212
[38,     3] loss: 1.040
[39,     3] loss: 1.075
[40,     3] loss: 1.063
[41,     3] loss: 1.201
[42,     3] loss: 1.185
[43,     3] loss: 1.167
[44,     3] loss: 1.119
[45,     3] loss: 1.073
[46,     3] loss: 1.128
[47,     3] loss: 1.079
[48,     3] loss: 1.007
[49,     3] loss: 1.182
[50,     3] loss: 1.210
[51,     3] loss: 1.136
[52,     3] loss: 1.129
[53,     3] loss: 1.070
[54,     3] loss: 0.983
[55,     3] loss: 0.874
[56,     3] loss: 0.978
[57,     3] loss: 1.205
[58,     3] loss: 1.084
[59,     3] loss: 1.025
[60,     3] loss: 1.049
[61,     3] loss: 0.990
[62,     3] loss: 0.995
[63,     3] loss: 0.933
[64,     3] loss: 0.930
[65,     3] loss: 0.994
[66,     3] loss: 0.934
[67,     3] loss: 0.947
[68,     3] loss: 0.988
[69,     3] loss: 1.032
[70,     3] loss: 0.949
[71,     3] loss: 1.143
[72,     3] loss: 0.970
[73,     3] loss: 1.123
[74,     3] loss: 1.076
[75,     3] loss: 1.058
[76,     3] loss: 0.975
[77,     3] loss: 1.004
Early stopping applied (best metric=0.5263015627861023)
Finished Training
Total time taken: 22.608864068984985
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.386
[3,     3] loss: 1.394
[4,     3] loss: 1.392
[5,     3] loss: 1.386
[6,     3] loss: 1.387
[7,     3] loss: 1.383
[8,     3] loss: 1.389
[9,     3] loss: 1.387
[10,     3] loss: 1.387
[11,     3] loss: 1.387
[12,     3] loss: 1.383
[13,     3] loss: 1.388
[14,     3] loss: 1.382
[15,     3] loss: 1.381
[16,     3] loss: 1.385
[17,     3] loss: 1.389
[18,     3] loss: 1.390
[19,     3] loss: 1.386
[20,     3] loss: 1.384
[21,     3] loss: 1.369
[22,     3] loss: 1.362
[23,     3] loss: 1.339
[24,     3] loss: 1.340
[25,     3] loss: 1.246
[26,     3] loss: 1.373
[27,     3] loss: 1.266
[28,     3] loss: 1.229
[29,     3] loss: 1.224
[30,     3] loss: 1.111
[31,     3] loss: 1.141
[32,     3] loss: 1.197
[33,     3] loss: 1.185
[34,     3] loss: 1.071
[35,     3] loss: 1.199
[36,     3] loss: 1.229
[37,     3] loss: 1.165
[38,     3] loss: 1.165
[39,     3] loss: 1.222
[40,     3] loss: 1.101
[41,     3] loss: 1.046
[42,     3] loss: 1.002
[43,     3] loss: 1.146
[44,     3] loss: 1.117
[45,     3] loss: 1.118
[46,     3] loss: 1.080
[47,     3] loss: 1.097
[48,     3] loss: 1.148
[49,     3] loss: 1.142
[50,     3] loss: 1.106
[51,     3] loss: 1.132
[52,     3] loss: 0.951
[53,     3] loss: 0.945
[54,     3] loss: 0.991
[55,     3] loss: 0.878
[56,     3] loss: 1.260
[57,     3] loss: 1.068
[58,     3] loss: 1.115
[59,     3] loss: 1.143
[60,     3] loss: 1.113
[61,     3] loss: 1.020
[62,     3] loss: 1.011
[63,     3] loss: 0.957
[64,     3] loss: 1.036
[65,     3] loss: 0.952
[66,     3] loss: 0.983
[67,     3] loss: 0.958
[68,     3] loss: 0.924
[69,     3] loss: 0.950
[70,     3] loss: 1.250
[71,     3] loss: 1.436
[72,     3] loss: 1.231
[73,     3] loss: 1.253
[74,     3] loss: 1.301
[75,     3] loss: 1.193
[76,     3] loss: 1.165
[77,     3] loss: 1.034
[78,     3] loss: 1.008
Early stopping applied (best metric=0.5463274717330933)
Finished Training
Total time taken: 22.942209005355835
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.391
[3,     3] loss: 1.379
[4,     3] loss: 1.394
[5,     3] loss: 1.384
[6,     3] loss: 1.383
[7,     3] loss: 1.388
[8,     3] loss: 1.390
[9,     3] loss: 1.391
[10,     3] loss: 1.385
[11,     3] loss: 1.383
[12,     3] loss: 1.380
[13,     3] loss: 1.392
[14,     3] loss: 1.379
[15,     3] loss: 1.369
[16,     3] loss: 1.355
[17,     3] loss: 1.300
[18,     3] loss: 1.175
[19,     3] loss: 1.176
[20,     3] loss: 1.198
[21,     3] loss: 1.230
[22,     3] loss: 1.279
[23,     3] loss: 1.263
[24,     3] loss: 1.227
[25,     3] loss: 1.195
[26,     3] loss: 1.115
[27,     3] loss: 1.288
[28,     3] loss: 1.279
[29,     3] loss: 1.227
[30,     3] loss: 1.186
[31,     3] loss: 1.181
[32,     3] loss: 1.212
[33,     3] loss: 1.088
[34,     3] loss: 1.035
[35,     3] loss: 1.044
[36,     3] loss: 1.077
[37,     3] loss: 1.115
[38,     3] loss: 1.035
[39,     3] loss: 1.063
[40,     3] loss: 0.957
[41,     3] loss: 1.037
[42,     3] loss: 1.181
[43,     3] loss: 0.999
[44,     3] loss: 1.024
[45,     3] loss: 0.980
[46,     3] loss: 0.959
[47,     3] loss: 0.886
[48,     3] loss: 0.906
[49,     3] loss: 1.005
[50,     3] loss: 1.008
[51,     3] loss: 1.107
[52,     3] loss: 1.000
[53,     3] loss: 1.010
[54,     3] loss: 0.903
[55,     3] loss: 1.089
[56,     3] loss: 0.888
[57,     3] loss: 0.919
[58,     3] loss: 0.867
[59,     3] loss: 0.835
[60,     3] loss: 0.881
[61,     3] loss: 0.854
[62,     3] loss: 0.938
[63,     3] loss: 0.808
[64,     3] loss: 0.921
[65,     3] loss: 1.573
[66,     3] loss: 1.124
[67,     3] loss: 1.198
[68,     3] loss: 1.154
[69,     3] loss: 1.251
[70,     3] loss: 1.229
[71,     3] loss: 1.082
[72,     3] loss: 1.053
[73,     3] loss: 1.075
[74,     3] loss: 0.918
[75,     3] loss: 0.923
[76,     3] loss: 1.246
[77,     3] loss: 1.131
Early stopping applied (best metric=0.5450173616409302)
Finished Training
Total time taken: 22.60344409942627
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.397
[3,     3] loss: 1.385
[4,     3] loss: 1.384
[5,     3] loss: 1.388
[6,     3] loss: 1.383
[7,     3] loss: 1.394
[8,     3] loss: 1.390
[9,     3] loss: 1.389
[10,     3] loss: 1.386
[11,     3] loss: 1.383
[12,     3] loss: 1.385
[13,     3] loss: 1.386
[14,     3] loss: 1.392
[15,     3] loss: 1.385
[16,     3] loss: 1.387
[17,     3] loss: 1.385
[18,     3] loss: 1.388
[19,     3] loss: 1.384
[20,     3] loss: 1.382
[21,     3] loss: 1.386
[22,     3] loss: 1.362
[23,     3] loss: 1.342
[24,     3] loss: 1.345
[25,     3] loss: 1.198
[26,     3] loss: 1.280
[27,     3] loss: 1.141
[28,     3] loss: 1.275
[29,     3] loss: 1.197
[30,     3] loss: 1.148
[31,     3] loss: 1.118
[32,     3] loss: 1.171
[33,     3] loss: 1.076
[34,     3] loss: 1.236
[35,     3] loss: 1.065
[36,     3] loss: 1.017
[37,     3] loss: 0.947
[38,     3] loss: 0.957
[39,     3] loss: 1.026
[40,     3] loss: 0.970
[41,     3] loss: 1.030
[42,     3] loss: 0.962
[43,     3] loss: 1.038
[44,     3] loss: 1.069
[45,     3] loss: 1.117
[46,     3] loss: 0.975
[47,     3] loss: 0.921
[48,     3] loss: 0.917
[49,     3] loss: 0.934
[50,     3] loss: 1.038
[51,     3] loss: 1.455
[52,     3] loss: 1.323
[53,     3] loss: 1.239
[54,     3] loss: 1.352
[55,     3] loss: 1.297
[56,     3] loss: 1.235
[57,     3] loss: 1.158
[58,     3] loss: 1.144
[59,     3] loss: 1.495
[60,     3] loss: 1.287
[61,     3] loss: 1.315
[62,     3] loss: 1.329
[63,     3] loss: 1.240
[64,     3] loss: 1.211
[65,     3] loss: 1.196
[66,     3] loss: 1.093
[67,     3] loss: 1.046
[68,     3] loss: 1.188
[69,     3] loss: 1.162
[70,     3] loss: 1.065
[71,     3] loss: 1.040
[72,     3] loss: 1.071
[73,     3] loss: 1.063
[74,     3] loss: 0.949
[75,     3] loss: 0.990
[76,     3] loss: 0.959
[77,     3] loss: 1.046
[78,     3] loss: 0.917
[79,     3] loss: 0.886
[80,     3] loss: 1.016
[81,     3] loss: 1.052
[82,     3] loss: 0.963
[83,     3] loss: 0.857
[84,     3] loss: 0.900
[85,     3] loss: 0.865
[86,     3] loss: 0.839
[87,     3] loss: 0.788
[88,     3] loss: 1.356
[89,     3] loss: 1.140
[90,     3] loss: 1.066
[91,     3] loss: 0.999
[92,     3] loss: 0.918
[93,     3] loss: 0.891
[94,     3] loss: 0.945
[95,     3] loss: 1.037
[96,     3] loss: 0.998
[97,     3] loss: 0.999
[98,     3] loss: 0.889
[99,     3] loss: 0.861
[100,     3] loss: 0.784
[101,     3] loss: 0.960
[102,     3] loss: 1.077
[103,     3] loss: 1.005
[104,     3] loss: 0.934
[105,     3] loss: 0.996
[106,     3] loss: 1.072
[107,     3] loss: 1.014
[108,     3] loss: 0.945
[109,     3] loss: 0.953
[110,     3] loss: 0.896
[111,     3] loss: 0.892
[112,     3] loss: 0.849
[113,     3] loss: 0.884
[114,     3] loss: 0.834
[115,     3] loss: 0.909
[116,     3] loss: 0.861
[117,     3] loss: 1.311
[118,     3] loss: 1.118
[119,     3] loss: 1.125
[120,     3] loss: 1.153
[121,     3] loss: 1.117
[122,     3] loss: 1.026
[123,     3] loss: 0.943
[124,     3] loss: 1.031
[125,     3] loss: 1.152
[126,     3] loss: 1.084
[127,     3] loss: 1.007
[128,     3] loss: 1.036
[129,     3] loss: 0.976
[130,     3] loss: 0.883
[131,     3] loss: 0.868
[132,     3] loss: 0.821
[133,     3] loss: 0.915
Early stopping applied (best metric=0.5254379510879517)
Finished Training
Total time taken: 39.111966133117676
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.390
[3,     3] loss: 1.393
[4,     3] loss: 1.389
[5,     3] loss: 1.381
[6,     3] loss: 1.393
[7,     3] loss: 1.394
[8,     3] loss: 1.385
[9,     3] loss: 1.387
[10,     3] loss: 1.384
[11,     3] loss: 1.387
[12,     3] loss: 1.382
[13,     3] loss: 1.387
[14,     3] loss: 1.391
[15,     3] loss: 1.382
[16,     3] loss: 1.382
[17,     3] loss: 1.389
[18,     3] loss: 1.385
[19,     3] loss: 1.382
[20,     3] loss: 1.392
[21,     3] loss: 1.384
[22,     3] loss: 1.369
[23,     3] loss: 1.364
[24,     3] loss: 1.300
[25,     3] loss: 1.258
[26,     3] loss: 1.307
[27,     3] loss: 1.251
[28,     3] loss: 1.316
[29,     3] loss: 1.219
[30,     3] loss: 1.227
[31,     3] loss: 1.210
[32,     3] loss: 1.150
[33,     3] loss: 1.251
[34,     3] loss: 1.228
[35,     3] loss: 1.103
[36,     3] loss: 1.014
[37,     3] loss: 1.081
[38,     3] loss: 1.053
[39,     3] loss: 1.074
[40,     3] loss: 0.983
[41,     3] loss: 0.977
[42,     3] loss: 0.980
[43,     3] loss: 1.011
[44,     3] loss: 1.106
[45,     3] loss: 1.119
[46,     3] loss: 1.143
[47,     3] loss: 1.114
[48,     3] loss: 0.961
[49,     3] loss: 1.049
[50,     3] loss: 1.053
[51,     3] loss: 1.026
[52,     3] loss: 0.992
[53,     3] loss: 0.966
[54,     3] loss: 1.046
[55,     3] loss: 1.034
[56,     3] loss: 0.962
[57,     3] loss: 0.928
[58,     3] loss: 1.279
[59,     3] loss: 1.078
[60,     3] loss: 1.140
[61,     3] loss: 1.018
[62,     3] loss: 1.264
[63,     3] loss: 1.058
[64,     3] loss: 1.044
[65,     3] loss: 1.071
[66,     3] loss: 1.000
[67,     3] loss: 0.909
[68,     3] loss: 0.834
[69,     3] loss: 0.772
[70,     3] loss: 0.786
[71,     3] loss: 0.901
[72,     3] loss: 1.414
[73,     3] loss: 1.131
[74,     3] loss: 1.150
[75,     3] loss: 1.078
[76,     3] loss: 1.150
[77,     3] loss: 1.040
[78,     3] loss: 1.097
[79,     3] loss: 1.168
[80,     3] loss: 0.996
[81,     3] loss: 0.962
[82,     3] loss: 0.927
[83,     3] loss: 0.828
[84,     3] loss: 0.851
[85,     3] loss: 1.172
[86,     3] loss: 1.056
[87,     3] loss: 1.002
[88,     3] loss: 1.184
[89,     3] loss: 1.146
Early stopping applied (best metric=0.5153990983963013)
Finished Training
Total time taken: 25.85839819908142
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.396
[3,     3] loss: 1.388
[4,     3] loss: 1.393
[5,     3] loss: 1.391
[6,     3] loss: 1.388
[7,     3] loss: 1.388
[8,     3] loss: 1.387
[9,     3] loss: 1.389
[10,     3] loss: 1.390
[11,     3] loss: 1.385
[12,     3] loss: 1.388
[13,     3] loss: 1.385
[14,     3] loss: 1.388
[15,     3] loss: 1.385
[16,     3] loss: 1.386
[17,     3] loss: 1.382
[18,     3] loss: 1.382
[19,     3] loss: 1.382
[20,     3] loss: 1.379
[21,     3] loss: 1.390
[22,     3] loss: 1.365
[23,     3] loss: 1.334
[24,     3] loss: 1.289
[25,     3] loss: 1.300
[26,     3] loss: 1.253
[27,     3] loss: 1.366
[28,     3] loss: 1.323
[29,     3] loss: 1.258
[30,     3] loss: 1.187
[31,     3] loss: 1.149
[32,     3] loss: 1.141
[33,     3] loss: 1.084
[34,     3] loss: 1.065
[35,     3] loss: 1.131
[36,     3] loss: 1.059
[37,     3] loss: 0.967
[38,     3] loss: 1.136
[39,     3] loss: 1.066
[40,     3] loss: 1.090
[41,     3] loss: 1.025
[42,     3] loss: 1.060
[43,     3] loss: 1.022
[44,     3] loss: 0.946
[45,     3] loss: 0.872
[46,     3] loss: 0.902
[47,     3] loss: 0.992
[48,     3] loss: 0.897
[49,     3] loss: 1.212
[50,     3] loss: 1.196
[51,     3] loss: 1.188
[52,     3] loss: 1.164
[53,     3] loss: 1.052
[54,     3] loss: 1.093
[55,     3] loss: 0.965
[56,     3] loss: 0.913
[57,     3] loss: 1.029
[58,     3] loss: 0.951
[59,     3] loss: 1.006
[60,     3] loss: 0.889
[61,     3] loss: 1.016
[62,     3] loss: 1.030
[63,     3] loss: 1.044
[64,     3] loss: 0.990
[65,     3] loss: 0.946
[66,     3] loss: 0.953
[67,     3] loss: 0.997
[68,     3] loss: 0.975
[69,     3] loss: 0.899
[70,     3] loss: 0.893
[71,     3] loss: 1.007
[72,     3] loss: 2.326
[73,     3] loss: 1.389
[74,     3] loss: 1.386
[75,     3] loss: 1.388
[76,     3] loss: 1.388
[77,     3] loss: 1.386
[78,     3] loss: 1.387
[79,     3] loss: 1.389
[80,     3] loss: 1.384
Early stopping applied (best metric=0.47882282733917236)
Finished Training
Total time taken: 22.92394232749939
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.386
[3,     3] loss: 1.390
[4,     3] loss: 1.382
[5,     3] loss: 1.385
[6,     3] loss: 1.381
[7,     3] loss: 1.376
[8,     3] loss: 1.358
[9,     3] loss: 1.368
[10,     3] loss: 1.325
[11,     3] loss: 1.302
[12,     3] loss: 1.245
[13,     3] loss: 1.187
[14,     3] loss: 1.289
[15,     3] loss: 1.063
[16,     3] loss: 1.242
[17,     3] loss: 1.124
[18,     3] loss: 1.079
[19,     3] loss: 1.075
[20,     3] loss: 1.042
[21,     3] loss: 1.074
[22,     3] loss: 1.145
[23,     3] loss: 1.103
[24,     3] loss: 1.087
[25,     3] loss: 0.999
[26,     3] loss: 0.914
[27,     3] loss: 0.887
[28,     3] loss: 1.302
[29,     3] loss: 1.349
[30,     3] loss: 1.169
[31,     3] loss: 1.202
[32,     3] loss: 1.165
[33,     3] loss: 1.250
[34,     3] loss: 1.144
[35,     3] loss: 1.062
[36,     3] loss: 0.940
[37,     3] loss: 0.896
[38,     3] loss: 0.947
[39,     3] loss: 1.193
[40,     3] loss: 1.273
[41,     3] loss: 1.322
[42,     3] loss: 1.234
[43,     3] loss: 1.245
[44,     3] loss: 1.264
[45,     3] loss: 1.230
[46,     3] loss: 1.106
[47,     3] loss: 1.063
[48,     3] loss: 1.033
[49,     3] loss: 1.097
[50,     3] loss: 1.068
[51,     3] loss: 1.118
[52,     3] loss: 1.062
[53,     3] loss: 1.064
[54,     3] loss: 0.953
[55,     3] loss: 0.868
[56,     3] loss: 0.952
[57,     3] loss: 0.918
[58,     3] loss: 0.938
[59,     3] loss: 0.943
[60,     3] loss: 0.843
[61,     3] loss: 0.815
[62,     3] loss: 1.433
[63,     3] loss: 1.287
Early stopping applied (best metric=0.5455295443534851)
Finished Training
Total time taken: 18.63871741294861
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.400
[3,     3] loss: 1.386
[4,     3] loss: 1.389
[5,     3] loss: 1.383
[6,     3] loss: 1.389
[7,     3] loss: 1.387
[8,     3] loss: 1.389
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.385
[12,     3] loss: 1.388
[13,     3] loss: 1.383
[14,     3] loss: 1.383
[15,     3] loss: 1.388
[16,     3] loss: 1.387
[17,     3] loss: 1.380
[18,     3] loss: 1.353
[19,     3] loss: 1.330
[20,     3] loss: 1.254
[21,     3] loss: 1.291
[22,     3] loss: 1.229
[23,     3] loss: 1.226
[24,     3] loss: 1.240
[25,     3] loss: 1.235
[26,     3] loss: 1.226
[27,     3] loss: 1.106
[28,     3] loss: 1.096
[29,     3] loss: 1.112
[30,     3] loss: 1.034
[31,     3] loss: 1.066
[32,     3] loss: 1.092
[33,     3] loss: 1.100
[34,     3] loss: 1.060
[35,     3] loss: 1.025
[36,     3] loss: 1.067
[37,     3] loss: 1.005
[38,     3] loss: 0.929
[39,     3] loss: 1.033
[40,     3] loss: 1.285
[41,     3] loss: 1.079
[42,     3] loss: 1.086
[43,     3] loss: 1.165
[44,     3] loss: 1.114
[45,     3] loss: 0.989
[46,     3] loss: 0.986
[47,     3] loss: 1.008
[48,     3] loss: 1.170
[49,     3] loss: 1.021
[50,     3] loss: 0.895
[51,     3] loss: 1.000
[52,     3] loss: 0.972
[53,     3] loss: 0.931
[54,     3] loss: 1.015
[55,     3] loss: 1.058
[56,     3] loss: 0.966
[57,     3] loss: 0.926
[58,     3] loss: 0.806
[59,     3] loss: 0.875
[60,     3] loss: 0.958
[61,     3] loss: 0.872
[62,     3] loss: 0.937
[63,     3] loss: 1.008
[64,     3] loss: 0.883
[65,     3] loss: 0.988
[66,     3] loss: 0.897
[67,     3] loss: 0.857
[68,     3] loss: 0.928
[69,     3] loss: 1.176
[70,     3] loss: 1.022
[71,     3] loss: 0.996
[72,     3] loss: 0.925
[73,     3] loss: 0.771
[74,     3] loss: 1.025
[75,     3] loss: 0.961
[76,     3] loss: 0.978
[77,     3] loss: 1.002
[78,     3] loss: 0.968
[79,     3] loss: 0.900
[80,     3] loss: 0.913
[81,     3] loss: 0.817
[82,     3] loss: 0.810
[83,     3] loss: 0.955
[84,     3] loss: 0.902
[85,     3] loss: 1.161
[86,     3] loss: 1.056
[87,     3] loss: 1.023
[88,     3] loss: 0.931
[89,     3] loss: 0.882
[90,     3] loss: 0.881
[91,     3] loss: 0.808
[92,     3] loss: 0.865
[93,     3] loss: 0.830
[94,     3] loss: 0.940
Early stopping applied (best metric=0.5358877778053284)
Finished Training
Total time taken: 27.158759593963623
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.391
[3,     3] loss: 1.389
[4,     3] loss: 1.387
[5,     3] loss: 1.382
[6,     3] loss: 1.384
[7,     3] loss: 1.388
[8,     3] loss: 1.388
[9,     3] loss: 1.394
[10,     3] loss: 1.380
[11,     3] loss: 1.385
[12,     3] loss: 1.376
[13,     3] loss: 1.368
[14,     3] loss: 1.341
[15,     3] loss: 1.291
[16,     3] loss: 1.263
[17,     3] loss: 1.212
[18,     3] loss: 1.122
[19,     3] loss: 1.031
[20,     3] loss: 1.104
[21,     3] loss: 1.166
[22,     3] loss: 1.072
[23,     3] loss: 1.120
[24,     3] loss: 1.051
[25,     3] loss: 0.920
[26,     3] loss: 0.930
[27,     3] loss: 1.185
[28,     3] loss: 1.070
[29,     3] loss: 1.103
[30,     3] loss: 1.040
[31,     3] loss: 1.147
[32,     3] loss: 1.106
[33,     3] loss: 1.088
[34,     3] loss: 1.012
[35,     3] loss: 0.962
[36,     3] loss: 0.980
[37,     3] loss: 0.873
[38,     3] loss: 0.976
[39,     3] loss: 0.956
[40,     3] loss: 0.881
[41,     3] loss: 0.891
[42,     3] loss: 0.913
[43,     3] loss: 0.980
[44,     3] loss: 0.963
[45,     3] loss: 0.982
[46,     3] loss: 0.914
[47,     3] loss: 0.889
[48,     3] loss: 0.865
[49,     3] loss: 0.892
[50,     3] loss: 1.030
[51,     3] loss: 0.905
[52,     3] loss: 0.902
[53,     3] loss: 0.840
[54,     3] loss: 0.899
[55,     3] loss: 0.784
[56,     3] loss: 0.882
[57,     3] loss: 0.989
[58,     3] loss: 0.980
[59,     3] loss: 0.911
[60,     3] loss: 0.949
[61,     3] loss: 0.995
[62,     3] loss: 1.001
[63,     3] loss: 0.882
[64,     3] loss: 0.840
[65,     3] loss: 0.800
[66,     3] loss: 0.984
[67,     3] loss: 0.839
[68,     3] loss: 0.894
[69,     3] loss: 0.919
[70,     3] loss: 0.871
[71,     3] loss: 0.860
[72,     3] loss: 1.390
[73,     3] loss: 1.195
[74,     3] loss: 1.248
[75,     3] loss: 1.226
Early stopping applied (best metric=0.5330675840377808)
Finished Training
Total time taken: 23.334230661392212
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.388
[3,     3] loss: 1.385
[4,     3] loss: 1.388
[5,     3] loss: 1.386
[6,     3] loss: 1.389
[7,     3] loss: 1.394
[8,     3] loss: 1.384
[9,     3] loss: 1.388
[10,     3] loss: 1.390
[11,     3] loss: 1.387
[12,     3] loss: 1.383
[13,     3] loss: 1.386
[14,     3] loss: 1.387
[15,     3] loss: 1.389
[16,     3] loss: 1.387
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.390
[21,     3] loss: 1.386
[22,     3] loss: 1.385
[23,     3] loss: 1.383
[24,     3] loss: 1.379
[25,     3] loss: 1.366
[26,     3] loss: 1.340
[27,     3] loss: 1.304
[28,     3] loss: 1.262
[29,     3] loss: 1.198
[30,     3] loss: 1.333
[31,     3] loss: 1.204
[32,     3] loss: 1.133
[33,     3] loss: 1.144
[34,     3] loss: 1.173
[35,     3] loss: 1.086
[36,     3] loss: 1.007
[37,     3] loss: 1.025
[38,     3] loss: 1.377
[39,     3] loss: 1.371
[40,     3] loss: 1.233
[41,     3] loss: 1.209
[42,     3] loss: 1.140
[43,     3] loss: 1.156
[44,     3] loss: 1.126
[45,     3] loss: 1.165
[46,     3] loss: 1.209
[47,     3] loss: 1.045
[48,     3] loss: 1.025
[49,     3] loss: 0.951
[50,     3] loss: 1.210
[51,     3] loss: 1.070
[52,     3] loss: 0.977
[53,     3] loss: 0.974
[54,     3] loss: 1.405
[55,     3] loss: 1.108
[56,     3] loss: 0.997
[57,     3] loss: 1.089
[58,     3] loss: 1.039
[59,     3] loss: 1.006
[60,     3] loss: 1.036
[61,     3] loss: 0.986
[62,     3] loss: 0.841
[63,     3] loss: 1.073
[64,     3] loss: 1.117
[65,     3] loss: 1.043
[66,     3] loss: 0.984
[67,     3] loss: 0.998
[68,     3] loss: 0.943
[69,     3] loss: 0.940
[70,     3] loss: 0.958
[71,     3] loss: 0.990
[72,     3] loss: 0.978
[73,     3] loss: 0.992
[74,     3] loss: 0.916
[75,     3] loss: 0.911
[76,     3] loss: 0.996
[77,     3] loss: 0.895
[78,     3] loss: 0.932
[79,     3] loss: 0.899
[80,     3] loss: 0.838
[81,     3] loss: 0.817
[82,     3] loss: 0.877
[83,     3] loss: 0.809
[84,     3] loss: 0.991
[85,     3] loss: 1.366
[86,     3] loss: 1.118
[87,     3] loss: 1.106
[88,     3] loss: 1.037
[89,     3] loss: 1.070
[90,     3] loss: 1.152
[91,     3] loss: 0.950
[92,     3] loss: 0.967
[93,     3] loss: 1.104
[94,     3] loss: 0.937
[95,     3] loss: 0.879
[96,     3] loss: 0.917
[97,     3] loss: 0.828
[98,     3] loss: 1.066
[99,     3] loss: 1.002
[100,     3] loss: 1.116
[101,     3] loss: 0.994
[102,     3] loss: 1.006
[103,     3] loss: 0.998
[104,     3] loss: 1.099
[105,     3] loss: 1.202
[106,     3] loss: 1.138
[107,     3] loss: 1.071
[108,     3] loss: 1.111
[109,     3] loss: 0.942
[110,     3] loss: 0.903
[111,     3] loss: 1.085
[112,     3] loss: 1.018
[113,     3] loss: 1.015
[114,     3] loss: 0.873
[115,     3] loss: 1.113
[116,     3] loss: 0.993
[117,     3] loss: 1.198
[118,     3] loss: 1.055
[119,     3] loss: 1.051
[120,     3] loss: 1.131
[121,     3] loss: 1.023
[122,     3] loss: 0.980
[123,     3] loss: 0.926
[124,     3] loss: 0.882
[125,     3] loss: 0.961
[126,     3] loss: 0.884
[127,     3] loss: 0.871
[128,     3] loss: 0.910
[129,     3] loss: 0.952
[130,     3] loss: 0.845
[131,     3] loss: 0.878
[132,     3] loss: 0.945
[133,     3] loss: 0.893
[134,     3] loss: 0.886
[135,     3] loss: 0.973
[136,     3] loss: 0.936
[137,     3] loss: 0.948
[138,     3] loss: 0.919
[139,     3] loss: 0.902
[140,     3] loss: 0.926
[141,     3] loss: 0.880
[142,     3] loss: 1.004
[143,     3] loss: 0.968
[144,     3] loss: 0.903
[145,     3] loss: 0.827
Early stopping applied (best metric=0.5182747840881348)
Finished Training
Total time taken: 47.77023220062256
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.397
[3,     3] loss: 1.393
[4,     3] loss: 1.390
[5,     3] loss: 1.384
[6,     3] loss: 1.386
[7,     3] loss: 1.393
[8,     3] loss: 1.386
[9,     3] loss: 1.379
[10,     3] loss: 1.391
[11,     3] loss: 1.384
[12,     3] loss: 1.376
[13,     3] loss: 1.364
[14,     3] loss: 1.384
[15,     3] loss: 1.357
[16,     3] loss: 1.323
[17,     3] loss: 1.248
[18,     3] loss: 1.330
[19,     3] loss: 1.256
[20,     3] loss: 1.268
[21,     3] loss: 1.192
[22,     3] loss: 1.167
[23,     3] loss: 1.220
[24,     3] loss: 1.174
[25,     3] loss: 1.058
[26,     3] loss: 1.272
[27,     3] loss: 1.123
[28,     3] loss: 1.239
[29,     3] loss: 1.332
[30,     3] loss: 1.180
[31,     3] loss: 1.180
[32,     3] loss: 1.120
[33,     3] loss: 1.129
[34,     3] loss: 1.135
[35,     3] loss: 1.064
[36,     3] loss: 1.023
[37,     3] loss: 1.053
[38,     3] loss: 0.940
[39,     3] loss: 0.970
[40,     3] loss: 0.923
[41,     3] loss: 0.928
[42,     3] loss: 1.228
[43,     3] loss: 1.193
[44,     3] loss: 1.123
[45,     3] loss: 1.159
[46,     3] loss: 1.106
[47,     3] loss: 1.008
[48,     3] loss: 1.010
[49,     3] loss: 1.007
[50,     3] loss: 0.977
[51,     3] loss: 1.024
[52,     3] loss: 1.059
[53,     3] loss: 0.955
[54,     3] loss: 0.958
[55,     3] loss: 0.953
[56,     3] loss: 0.880
[57,     3] loss: 0.955
[58,     3] loss: 1.235
[59,     3] loss: 1.028
[60,     3] loss: 1.000
[61,     3] loss: 0.945
[62,     3] loss: 0.905
[63,     3] loss: 0.870
[64,     3] loss: 0.952
[65,     3] loss: 0.849
[66,     3] loss: 0.956
[67,     3] loss: 0.854
[68,     3] loss: 0.834
[69,     3] loss: 1.075
[70,     3] loss: 0.947
[71,     3] loss: 1.001
[72,     3] loss: 0.950
[73,     3] loss: 0.896
[74,     3] loss: 0.986
[75,     3] loss: 0.844
[76,     3] loss: 0.908
[77,     3] loss: 1.253
[78,     3] loss: 1.051
[79,     3] loss: 1.079
[80,     3] loss: 1.050
[81,     3] loss: 0.930
[82,     3] loss: 0.992
[83,     3] loss: 0.970
[84,     3] loss: 0.861
[85,     3] loss: 0.934
Early stopping applied (best metric=0.5214627981185913)
Finished Training
Total time taken: 26.31498408317566
{'S-palmitoylation-C Validation Accuracy': 0.5624107155984885, 'S-palmitoylation-C Validation Sensitivity': 0.42323432343234324, 'S-palmitoylation-C Validation Specificity': 0.5972924351705144, 'S-palmitoylation-C Validation Precision': 0.2253623665876513, 'S-palmitoylation-C AUC ROC': 0.5281411991433607, 'S-palmitoylation-C AUC PR': 0.2169185630273055, 'S-palmitoylation-C MCC': 0.023389340656773856, 'S-palmitoylation-C F1': 0.2362375910995833, 'Validation Loss (S-palmitoylation-C)': 0.5547176003456116, 'Hydroxylation-K Validation Accuracy': 0.5837174940898345, 'Hydroxylation-K Validation Sensitivity': 0.7637037037037037, 'Hydroxylation-K Validation Specificity': 0.5385964912280702, 'Hydroxylation-K Validation Precision': 0.370153813462884, 'Hydroxylation-K AUC ROC': 0.7717641325536062, 'Hydroxylation-K AUC PR': 0.5339499569394192, 'Hydroxylation-K MCC': 0.272280534846515, 'Hydroxylation-K F1': 0.4608644240194781, 'Validation Loss (Hydroxylation-K)': 0.5294664184252421, 'Validation Loss (total)': 1.0841840267181397, 'TimeToTrain': 29.441193723678587}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004084093686585581,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6847911464818431,
 'loss_weight_S-palmitoylation-C': 0.6617215330348348,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2955789207,
 'sample_weights': [0.5907189823488217, 0.21902433417999975],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2966659364278916,
 'weight_decay_Hydroxylation-K': 9.881353996436097,
 'weight_decay_S-palmitoylation-C': 1.3200975682414995}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.379
[3,     3] loss: 1.361
[4,     3] loss: 1.388
[5,     3] loss: 1.380
[6,     3] loss: 1.382
[7,     3] loss: 1.384
[8,     3] loss: 1.387
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.383
[12,     3] loss: 1.385
[13,     3] loss: 1.373
[14,     3] loss: 1.378
[15,     3] loss: 1.367
[16,     3] loss: 1.352
[17,     3] loss: 1.328
[18,     3] loss: 1.289
[19,     3] loss: 1.236
[20,     3] loss: 1.212
[21,     3] loss: 1.117
[22,     3] loss: 1.092
[23,     3] loss: 1.162
[24,     3] loss: 1.156
[25,     3] loss: 1.129
[26,     3] loss: 1.085
[27,     3] loss: 1.014
[28,     3] loss: 1.025
[29,     3] loss: 1.049
[30,     3] loss: 1.025
[31,     3] loss: 1.043
[32,     3] loss: 1.003
[33,     3] loss: 1.006
[34,     3] loss: 1.056
[35,     3] loss: 1.143
[36,     3] loss: 0.931
[37,     3] loss: 0.962
[38,     3] loss: 0.952
[39,     3] loss: 0.869
[40,     3] loss: 1.014
[41,     3] loss: 0.815
[42,     3] loss: 0.863
[43,     3] loss: 0.853
[44,     3] loss: 0.891
[45,     3] loss: 0.880
[46,     3] loss: 0.969
[47,     3] loss: 0.882
[48,     3] loss: 0.950
[49,     3] loss: 0.936
[50,     3] loss: 0.899
[51,     3] loss: 0.885
[52,     3] loss: 0.936
[53,     3] loss: 0.870
[54,     3] loss: 0.816
[55,     3] loss: 0.837
[56,     3] loss: 0.816
[57,     3] loss: 0.791
[58,     3] loss: 0.854
[59,     3] loss: 0.806
[60,     3] loss: 0.858
[61,     3] loss: 0.884
[62,     3] loss: 0.835
[63,     3] loss: 0.814
[64,     3] loss: 0.852
[65,     3] loss: 0.960
[66,     3] loss: 0.879
[67,     3] loss: 0.903
[68,     3] loss: 0.928
[69,     3] loss: 0.840
[70,     3] loss: 0.864
[71,     3] loss: 0.912
[72,     3] loss: 0.947
[73,     3] loss: 0.967
[74,     3] loss: 0.861
[75,     3] loss: 0.856
[76,     3] loss: 0.917
[77,     3] loss: 0.911
[78,     3] loss: 0.869
[79,     3] loss: 0.841
[80,     3] loss: 0.859
[81,     3] loss: 0.865
Early stopping applied (best metric=0.5371682643890381)
Finished Training
Total time taken: 26.216587781906128
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.380
[3,     3] loss: 1.382
[4,     3] loss: 1.386
[5,     3] loss: 1.389
[6,     3] loss: 1.387
[7,     3] loss: 1.384
[8,     3] loss: 1.385
[9,     3] loss: 1.389
[10,     3] loss: 1.387
[11,     3] loss: 1.387
[12,     3] loss: 1.387
[13,     3] loss: 1.385
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.385
[18,     3] loss: 1.386
[19,     3] loss: 1.385
[20,     3] loss: 1.383
[21,     3] loss: 1.383
[22,     3] loss: 1.379
[23,     3] loss: 1.374
[24,     3] loss: 1.343
[25,     3] loss: 1.341
[26,     3] loss: 1.326
[27,     3] loss: 1.225
[28,     3] loss: 1.346
[29,     3] loss: 1.353
[30,     3] loss: 1.209
[31,     3] loss: 1.315
[32,     3] loss: 1.276
[33,     3] loss: 1.185
[34,     3] loss: 1.232
[35,     3] loss: 1.231
[36,     3] loss: 1.165
[37,     3] loss: 1.136
[38,     3] loss: 1.203
[39,     3] loss: 1.158
[40,     3] loss: 1.153
[41,     3] loss: 1.133
[42,     3] loss: 1.056
[43,     3] loss: 1.029
[44,     3] loss: 1.118
[45,     3] loss: 0.994
[46,     3] loss: 1.148
[47,     3] loss: 1.116
[48,     3] loss: 1.058
[49,     3] loss: 1.106
[50,     3] loss: 1.122
[51,     3] loss: 1.038
[52,     3] loss: 1.057
[53,     3] loss: 1.073
[54,     3] loss: 1.148
[55,     3] loss: 0.981
[56,     3] loss: 1.107
[57,     3] loss: 1.073
[58,     3] loss: 1.087
[59,     3] loss: 1.049
[60,     3] loss: 0.950
[61,     3] loss: 1.075
[62,     3] loss: 0.919
[63,     3] loss: 0.915
[64,     3] loss: 0.922
[65,     3] loss: 0.912
[66,     3] loss: 0.898
[67,     3] loss: 0.923
[68,     3] loss: 0.892
[69,     3] loss: 1.064
[70,     3] loss: 1.098
[71,     3] loss: 0.994
[72,     3] loss: 0.962
[73,     3] loss: 0.978
[74,     3] loss: 1.048
[75,     3] loss: 1.027
[76,     3] loss: 1.081
[77,     3] loss: 0.943
[78,     3] loss: 1.054
[79,     3] loss: 0.945
[80,     3] loss: 0.964
[81,     3] loss: 0.919
[82,     3] loss: 0.891
[83,     3] loss: 1.007
[84,     3] loss: 0.896
[85,     3] loss: 0.859
Early stopping applied (best metric=0.5394641160964966)
Finished Training
Total time taken: 28.605414867401123
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.389
[3,     3] loss: 1.384
[4,     3] loss: 1.387
[5,     3] loss: 1.386
[6,     3] loss: 1.385
[7,     3] loss: 1.387
[8,     3] loss: 1.384
[9,     3] loss: 1.389
[10,     3] loss: 1.387
[11,     3] loss: 1.388
[12,     3] loss: 1.385
[13,     3] loss: 1.387
[14,     3] loss: 1.384
[15,     3] loss: 1.386
[16,     3] loss: 1.387
[17,     3] loss: 1.387
[18,     3] loss: 1.385
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.387
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.383
[25,     3] loss: 1.385
[26,     3] loss: 1.382
[27,     3] loss: 1.376
[28,     3] loss: 1.354
[29,     3] loss: 1.335
[30,     3] loss: 1.274
[31,     3] loss: 1.242
[32,     3] loss: 1.198
[33,     3] loss: 1.250
[34,     3] loss: 1.213
[35,     3] loss: 1.185
[36,     3] loss: 1.173
[37,     3] loss: 1.180
[38,     3] loss: 1.115
[39,     3] loss: 1.151
[40,     3] loss: 1.095
[41,     3] loss: 1.072
[42,     3] loss: 1.017
[43,     3] loss: 0.949
[44,     3] loss: 0.948
[45,     3] loss: 0.916
[46,     3] loss: 1.003
[47,     3] loss: 0.996
[48,     3] loss: 0.973
[49,     3] loss: 1.024
[50,     3] loss: 1.021
[51,     3] loss: 1.011
[52,     3] loss: 1.013
[53,     3] loss: 0.940
[54,     3] loss: 0.983
[55,     3] loss: 0.924
[56,     3] loss: 0.994
[57,     3] loss: 0.940
[58,     3] loss: 0.929
[59,     3] loss: 0.953
[60,     3] loss: 0.879
[61,     3] loss: 0.953
[62,     3] loss: 0.877
[63,     3] loss: 0.895
[64,     3] loss: 0.888
[65,     3] loss: 0.884
[66,     3] loss: 0.832
[67,     3] loss: 0.892
[68,     3] loss: 1.060
[69,     3] loss: 1.093
[70,     3] loss: 1.025
[71,     3] loss: 1.050
[72,     3] loss: 1.101
[73,     3] loss: 1.027
[74,     3] loss: 1.078
[75,     3] loss: 0.942
[76,     3] loss: 1.002
[77,     3] loss: 0.939
[78,     3] loss: 0.873
[79,     3] loss: 0.831
[80,     3] loss: 0.849
[81,     3] loss: 0.853
[82,     3] loss: 0.888
[83,     3] loss: 0.854
[84,     3] loss: 0.834
[85,     3] loss: 0.840
[86,     3] loss: 0.845
[87,     3] loss: 0.829
[88,     3] loss: 0.914
[89,     3] loss: 0.868
[90,     3] loss: 0.898
[91,     3] loss: 0.812
Early stopping applied (best metric=0.5503026843070984)
Finished Training
Total time taken: 34.116018772125244
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.384
[3,     3] loss: 1.389
[4,     3] loss: 1.391
[5,     3] loss: 1.390
[6,     3] loss: 1.386
[7,     3] loss: 1.386
[8,     3] loss: 1.388
[9,     3] loss: 1.385
[10,     3] loss: 1.385
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.384
[14,     3] loss: 1.385
[15,     3] loss: 1.387
[16,     3] loss: 1.385
[17,     3] loss: 1.384
[18,     3] loss: 1.389
[19,     3] loss: 1.386
[20,     3] loss: 1.384
[21,     3] loss: 1.386
[22,     3] loss: 1.382
[23,     3] loss: 1.384
[24,     3] loss: 1.379
[25,     3] loss: 1.362
[26,     3] loss: 1.342
[27,     3] loss: 1.312
[28,     3] loss: 1.301
[29,     3] loss: 1.222
[30,     3] loss: 1.188
[31,     3] loss: 1.240
[32,     3] loss: 1.225
[33,     3] loss: 1.185
[34,     3] loss: 1.151
[35,     3] loss: 1.204
[36,     3] loss: 1.194
[37,     3] loss: 1.233
[38,     3] loss: 1.286
[39,     3] loss: 1.177
[40,     3] loss: 1.242
[41,     3] loss: 1.174
[42,     3] loss: 1.147
[43,     3] loss: 1.132
[44,     3] loss: 1.115
[45,     3] loss: 1.057
[46,     3] loss: 1.102
[47,     3] loss: 1.234
[48,     3] loss: 1.052
[49,     3] loss: 1.099
[50,     3] loss: 1.119
[51,     3] loss: 1.108
[52,     3] loss: 1.078
[53,     3] loss: 1.061
[54,     3] loss: 1.029
[55,     3] loss: 1.062
[56,     3] loss: 1.164
[57,     3] loss: 1.154
[58,     3] loss: 1.154
[59,     3] loss: 1.164
[60,     3] loss: 1.129
[61,     3] loss: 1.103
[62,     3] loss: 1.098
[63,     3] loss: 1.136
[64,     3] loss: 1.047
[65,     3] loss: 1.013
[66,     3] loss: 1.015
[67,     3] loss: 0.939
[68,     3] loss: 0.942
[69,     3] loss: 1.059
[70,     3] loss: 0.937
[71,     3] loss: 1.027
[72,     3] loss: 1.024
[73,     3] loss: 1.030
[74,     3] loss: 0.966
[75,     3] loss: 0.997
[76,     3] loss: 0.982
[77,     3] loss: 0.911
[78,     3] loss: 0.913
[79,     3] loss: 0.941
[80,     3] loss: 0.922
[81,     3] loss: 0.916
[82,     3] loss: 0.867
[83,     3] loss: 0.961
[84,     3] loss: 0.907
[85,     3] loss: 0.910
[86,     3] loss: 0.974
Early stopping applied (best metric=0.5160433053970337)
Finished Training
Total time taken: 30.149104356765747
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.391
[3,     3] loss: 1.386
[4,     3] loss: 1.391
[5,     3] loss: 1.390
[6,     3] loss: 1.384
[7,     3] loss: 1.385
[8,     3] loss: 1.385
[9,     3] loss: 1.389
[10,     3] loss: 1.390
[11,     3] loss: 1.389
[12,     3] loss: 1.387
[13,     3] loss: 1.387
[14,     3] loss: 1.387
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.388
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.387
[26,     3] loss: 1.387
[27,     3] loss: 1.387
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.385
[37,     3] loss: 1.385
[38,     3] loss: 1.382
[39,     3] loss: 1.378
[40,     3] loss: 1.361
[41,     3] loss: 1.317
[42,     3] loss: 1.310
[43,     3] loss: 1.346
[44,     3] loss: 1.245
[45,     3] loss: 1.282
[46,     3] loss: 1.272
[47,     3] loss: 1.232
[48,     3] loss: 1.220
[49,     3] loss: 1.262
[50,     3] loss: 1.179
[51,     3] loss: 1.143
[52,     3] loss: 1.089
[53,     3] loss: 1.004
[54,     3] loss: 1.016
[55,     3] loss: 1.251
[56,     3] loss: 1.073
[57,     3] loss: 1.117
[58,     3] loss: 1.055
[59,     3] loss: 1.040
[60,     3] loss: 1.125
[61,     3] loss: 1.173
[62,     3] loss: 1.044
[63,     3] loss: 0.993
[64,     3] loss: 1.018
[65,     3] loss: 0.971
[66,     3] loss: 1.019
[67,     3] loss: 0.971
[68,     3] loss: 0.923
[69,     3] loss: 1.018
[70,     3] loss: 1.041
[71,     3] loss: 0.909
[72,     3] loss: 1.014
[73,     3] loss: 1.069
[74,     3] loss: 1.008
[75,     3] loss: 0.990
[76,     3] loss: 1.132
[77,     3] loss: 0.928
[78,     3] loss: 1.142
[79,     3] loss: 1.158
[80,     3] loss: 1.020
[81,     3] loss: 1.024
[82,     3] loss: 1.011
[83,     3] loss: 0.964
[84,     3] loss: 0.960
[85,     3] loss: 0.939
[86,     3] loss: 0.960
[87,     3] loss: 0.885
[88,     3] loss: 0.895
[89,     3] loss: 0.956
[90,     3] loss: 1.085
[91,     3] loss: 0.929
[92,     3] loss: 0.917
[93,     3] loss: 0.941
[94,     3] loss: 0.976
[95,     3] loss: 1.077
[96,     3] loss: 0.996
[97,     3] loss: 0.942
[98,     3] loss: 1.078
[99,     3] loss: 0.980
[100,     3] loss: 0.928
[101,     3] loss: 0.963
[102,     3] loss: 0.936
[103,     3] loss: 0.869
[104,     3] loss: 0.878
[105,     3] loss: 0.940
[106,     3] loss: 0.917
[107,     3] loss: 0.904
[108,     3] loss: 0.914
[109,     3] loss: 0.899
[110,     3] loss: 0.854
[111,     3] loss: 0.946
[112,     3] loss: 0.922
[113,     3] loss: 1.058
[114,     3] loss: 1.045
[115,     3] loss: 0.984
[116,     3] loss: 1.096
[117,     3] loss: 1.022
[118,     3] loss: 1.124
[119,     3] loss: 1.107
[120,     3] loss: 0.997
[121,     3] loss: 0.997
[122,     3] loss: 0.965
[123,     3] loss: 0.941
[124,     3] loss: 0.906
[125,     3] loss: 0.923
[126,     3] loss: 0.938
[127,     3] loss: 0.909
[128,     3] loss: 1.029
[129,     3] loss: 1.053
[130,     3] loss: 0.972
[131,     3] loss: 1.116
[132,     3] loss: 1.035
[133,     3] loss: 1.174
[134,     3] loss: 1.024
[135,     3] loss: 1.179
[136,     3] loss: 1.096
[137,     3] loss: 1.014
[138,     3] loss: 1.038
[139,     3] loss: 0.993
[140,     3] loss: 0.994
[141,     3] loss: 1.061
[142,     3] loss: 1.141
[143,     3] loss: 1.141
Early stopping applied (best metric=0.5219780802726746)
Finished Training
Total time taken: 40.92756247520447
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.391
[3,     3] loss: 1.384
[4,     3] loss: 1.393
[5,     3] loss: 1.386
[6,     3] loss: 1.386
[7,     3] loss: 1.383
[8,     3] loss: 1.387
[9,     3] loss: 1.389
[10,     3] loss: 1.386
[11,     3] loss: 1.389
[12,     3] loss: 1.384
[13,     3] loss: 1.386
[14,     3] loss: 1.383
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.385
[18,     3] loss: 1.383
[19,     3] loss: 1.381
[20,     3] loss: 1.382
[21,     3] loss: 1.371
[22,     3] loss: 1.339
[23,     3] loss: 1.323
[24,     3] loss: 1.288
[25,     3] loss: 1.184
[26,     3] loss: 1.143
[27,     3] loss: 1.173
[28,     3] loss: 1.221
[29,     3] loss: 1.129
[30,     3] loss: 1.200
[31,     3] loss: 1.316
[32,     3] loss: 1.202
[33,     3] loss: 1.129
[34,     3] loss: 1.064
[35,     3] loss: 1.135
[36,     3] loss: 1.030
[37,     3] loss: 1.014
[38,     3] loss: 0.996
[39,     3] loss: 0.995
[40,     3] loss: 1.078
[41,     3] loss: 1.031
[42,     3] loss: 1.038
[43,     3] loss: 1.059
[44,     3] loss: 1.060
[45,     3] loss: 1.020
[46,     3] loss: 0.994
[47,     3] loss: 1.034
[48,     3] loss: 1.069
[49,     3] loss: 1.062
[50,     3] loss: 0.955
[51,     3] loss: 1.035
[52,     3] loss: 0.978
[53,     3] loss: 0.936
[54,     3] loss: 0.913
[55,     3] loss: 0.849
[56,     3] loss: 0.948
[57,     3] loss: 0.899
[58,     3] loss: 0.838
[59,     3] loss: 0.923
[60,     3] loss: 0.973
[61,     3] loss: 0.930
[62,     3] loss: 1.083
[63,     3] loss: 0.944
[64,     3] loss: 0.984
[65,     3] loss: 0.908
[66,     3] loss: 0.843
[67,     3] loss: 0.852
[68,     3] loss: 0.822
[69,     3] loss: 0.833
[70,     3] loss: 0.801
[71,     3] loss: 0.822
[72,     3] loss: 0.945
[73,     3] loss: 1.072
[74,     3] loss: 0.961
[75,     3] loss: 0.908
[76,     3] loss: 0.863
[77,     3] loss: 0.886
Early stopping applied (best metric=0.519406259059906)
Finished Training
Total time taken: 23.760703802108765
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.381
[3,     3] loss: 1.373
[4,     3] loss: 1.391
[5,     3] loss: 1.389
[6,     3] loss: 1.388
[7,     3] loss: 1.388
[8,     3] loss: 1.390
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.385
[12,     3] loss: 1.384
[13,     3] loss: 1.386
[14,     3] loss: 1.388
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.384
[20,     3] loss: 1.386
[21,     3] loss: 1.379
[22,     3] loss: 1.367
[23,     3] loss: 1.337
[24,     3] loss: 1.321
[25,     3] loss: 1.339
[26,     3] loss: 1.249
[27,     3] loss: 1.205
[28,     3] loss: 1.191
[29,     3] loss: 1.073
[30,     3] loss: 1.165
[31,     3] loss: 1.240
[32,     3] loss: 1.149
[33,     3] loss: 1.110
[34,     3] loss: 1.135
[35,     3] loss: 1.087
[36,     3] loss: 0.982
[37,     3] loss: 1.123
[38,     3] loss: 0.953
[39,     3] loss: 1.114
[40,     3] loss: 0.911
[41,     3] loss: 0.960
[42,     3] loss: 0.984
[43,     3] loss: 0.955
[44,     3] loss: 0.956
[45,     3] loss: 0.977
[46,     3] loss: 1.105
[47,     3] loss: 1.071
[48,     3] loss: 1.022
[49,     3] loss: 0.954
[50,     3] loss: 0.995
[51,     3] loss: 0.908
[52,     3] loss: 0.976
[53,     3] loss: 1.000
[54,     3] loss: 1.038
[55,     3] loss: 0.890
[56,     3] loss: 0.950
[57,     3] loss: 1.014
[58,     3] loss: 0.983
[59,     3] loss: 0.977
[60,     3] loss: 0.939
[61,     3] loss: 0.993
[62,     3] loss: 0.869
[63,     3] loss: 0.996
[64,     3] loss: 0.852
[65,     3] loss: 0.847
[66,     3] loss: 0.852
[67,     3] loss: 0.845
[68,     3] loss: 0.834
[69,     3] loss: 0.783
[70,     3] loss: 0.803
[71,     3] loss: 0.960
[72,     3] loss: 0.906
[73,     3] loss: 0.918
[74,     3] loss: 0.910
[75,     3] loss: 0.944
[76,     3] loss: 0.929
[77,     3] loss: 0.866
[78,     3] loss: 0.911
[79,     3] loss: 0.971
Early stopping applied (best metric=0.5305477976799011)
Finished Training
Total time taken: 23.48976993560791
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.396
[3,     3] loss: 1.391
[4,     3] loss: 1.386
[5,     3] loss: 1.386
[6,     3] loss: 1.387
[7,     3] loss: 1.383
[8,     3] loss: 1.386
[9,     3] loss: 1.389
[10,     3] loss: 1.391
[11,     3] loss: 1.385
[12,     3] loss: 1.385
[13,     3] loss: 1.387
[14,     3] loss: 1.385
[15,     3] loss: 1.388
[16,     3] loss: 1.387
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.387
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.387
[28,     3] loss: 1.385
[29,     3] loss: 1.386
[30,     3] loss: 1.387
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.384
[34,     3] loss: 1.382
[35,     3] loss: 1.373
[36,     3] loss: 1.342
[37,     3] loss: 1.307
[38,     3] loss: 1.220
[39,     3] loss: 1.327
[40,     3] loss: 1.184
[41,     3] loss: 1.161
[42,     3] loss: 1.163
[43,     3] loss: 1.268
[44,     3] loss: 1.089
[45,     3] loss: 1.255
[46,     3] loss: 1.116
[47,     3] loss: 1.128
[48,     3] loss: 1.057
[49,     3] loss: 1.047
[50,     3] loss: 1.015
[51,     3] loss: 0.996
[52,     3] loss: 0.997
[53,     3] loss: 1.077
[54,     3] loss: 1.015
[55,     3] loss: 1.215
[56,     3] loss: 1.091
[57,     3] loss: 1.191
[58,     3] loss: 1.067
[59,     3] loss: 1.085
[60,     3] loss: 1.019
[61,     3] loss: 1.036
[62,     3] loss: 0.947
[63,     3] loss: 0.901
[64,     3] loss: 0.879
[65,     3] loss: 0.933
[66,     3] loss: 1.182
[67,     3] loss: 1.114
[68,     3] loss: 1.102
[69,     3] loss: 1.004
[70,     3] loss: 1.061
[71,     3] loss: 1.092
[72,     3] loss: 0.964
[73,     3] loss: 0.915
[74,     3] loss: 0.932
[75,     3] loss: 0.948
[76,     3] loss: 0.837
[77,     3] loss: 0.838
[78,     3] loss: 0.887
[79,     3] loss: 0.828
[80,     3] loss: 0.881
[81,     3] loss: 1.110
[82,     3] loss: 0.951
[83,     3] loss: 0.921
[84,     3] loss: 0.858
[85,     3] loss: 0.868
[86,     3] loss: 0.841
[87,     3] loss: 0.896
[88,     3] loss: 0.899
[89,     3] loss: 0.817
[90,     3] loss: 0.851
[91,     3] loss: 0.833
[92,     3] loss: 0.833
[93,     3] loss: 0.917
[94,     3] loss: 0.869
[95,     3] loss: 1.001
[96,     3] loss: 0.923
[97,     3] loss: 0.969
[98,     3] loss: 1.007
Early stopping applied (best metric=0.535024881362915)
Finished Training
Total time taken: 29.067396640777588
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.391
[3,     3] loss: 1.392
[4,     3] loss: 1.387
[5,     3] loss: 1.389
[6,     3] loss: 1.389
[7,     3] loss: 1.386
[8,     3] loss: 1.389
[9,     3] loss: 1.384
[10,     3] loss: 1.386
[11,     3] loss: 1.389
[12,     3] loss: 1.388
[13,     3] loss: 1.381
[14,     3] loss: 1.386
[15,     3] loss: 1.385
[16,     3] loss: 1.381
[17,     3] loss: 1.385
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.389
[21,     3] loss: 1.384
[22,     3] loss: 1.386
[23,     3] loss: 1.387
[24,     3] loss: 1.386
[25,     3] loss: 1.385
[26,     3] loss: 1.386
[27,     3] loss: 1.383
[28,     3] loss: 1.383
[29,     3] loss: 1.382
[30,     3] loss: 1.392
[31,     3] loss: 1.391
[32,     3] loss: 1.385
[33,     3] loss: 1.387
[34,     3] loss: 1.386
[35,     3] loss: 1.385
[36,     3] loss: 1.386
[37,     3] loss: 1.387
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.385
[41,     3] loss: 1.387
[42,     3] loss: 1.388
[43,     3] loss: 1.387
[44,     3] loss: 1.387
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.387
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.386
[56,     3] loss: 1.386
Early stopping applied (best metric=0.5434776544570923)
Finished Training
Total time taken: 15.879133462905884
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.401
[3,     3] loss: 1.387
[4,     3] loss: 1.387
[5,     3] loss: 1.381
[6,     3] loss: 1.388
[7,     3] loss: 1.384
[8,     3] loss: 1.382
[9,     3] loss: 1.384
[10,     3] loss: 1.380
[11,     3] loss: 1.382
[12,     3] loss: 1.380
[13,     3] loss: 1.379
[14,     3] loss: 1.372
[15,     3] loss: 1.358
[16,     3] loss: 1.347
[17,     3] loss: 1.309
[18,     3] loss: 1.346
[19,     3] loss: 1.259
[20,     3] loss: 1.204
[21,     3] loss: 1.232
[22,     3] loss: 1.224
[23,     3] loss: 1.220
[24,     3] loss: 1.156
[25,     3] loss: 1.089
[26,     3] loss: 1.178
[27,     3] loss: 1.114
[28,     3] loss: 1.082
[29,     3] loss: 1.071
[30,     3] loss: 1.046
[31,     3] loss: 1.192
[32,     3] loss: 1.131
[33,     3] loss: 1.154
[34,     3] loss: 1.220
[35,     3] loss: 1.111
[36,     3] loss: 1.085
[37,     3] loss: 1.153
[38,     3] loss: 1.082
[39,     3] loss: 1.127
[40,     3] loss: 1.027
[41,     3] loss: 1.056
[42,     3] loss: 1.000
[43,     3] loss: 0.958
[44,     3] loss: 0.928
[45,     3] loss: 0.933
[46,     3] loss: 1.024
[47,     3] loss: 0.877
[48,     3] loss: 0.929
[49,     3] loss: 0.973
[50,     3] loss: 0.907
[51,     3] loss: 0.948
[52,     3] loss: 0.902
[53,     3] loss: 0.922
[54,     3] loss: 0.941
[55,     3] loss: 0.970
[56,     3] loss: 1.058
[57,     3] loss: 0.967
[58,     3] loss: 0.915
[59,     3] loss: 0.909
[60,     3] loss: 0.964
[61,     3] loss: 1.004
[62,     3] loss: 1.092
[63,     3] loss: 0.906
[64,     3] loss: 0.980
[65,     3] loss: 1.012
[66,     3] loss: 0.945
[67,     3] loss: 0.979
[68,     3] loss: 0.937
[69,     3] loss: 0.926
[70,     3] loss: 0.972
[71,     3] loss: 0.880
[72,     3] loss: 0.875
[73,     3] loss: 0.887
[74,     3] loss: 0.843
[75,     3] loss: 0.801
[76,     3] loss: 0.839
[77,     3] loss: 0.865
[78,     3] loss: 0.874
[79,     3] loss: 0.836
[80,     3] loss: 0.808
[81,     3] loss: 0.793
[82,     3] loss: 0.785
[83,     3] loss: 0.791
[84,     3] loss: 0.867
[85,     3] loss: 0.795
[86,     3] loss: 0.794
[87,     3] loss: 0.787
[88,     3] loss: 0.769
[89,     3] loss: 0.763
[90,     3] loss: 0.774
[91,     3] loss: 0.817
[92,     3] loss: 0.802
[93,     3] loss: 0.995
[94,     3] loss: 0.867
[95,     3] loss: 0.864
[96,     3] loss: 0.918
[97,     3] loss: 0.968
[98,     3] loss: 0.969
[99,     3] loss: 0.958
[100,     3] loss: 0.899
[101,     3] loss: 0.969
[102,     3] loss: 1.046
[103,     3] loss: 1.008
[104,     3] loss: 0.936
[105,     3] loss: 0.967
[106,     3] loss: 0.941
[107,     3] loss: 0.955
[108,     3] loss: 0.941
[109,     3] loss: 0.963
[110,     3] loss: 0.910
[111,     3] loss: 0.890
[112,     3] loss: 1.057
[113,     3] loss: 0.862
[114,     3] loss: 0.847
[115,     3] loss: 0.827
[116,     3] loss: 0.801
Early stopping applied (best metric=0.5108761787414551)
Finished Training
Total time taken: 35.79645299911499
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.387
[3,     3] loss: 1.393
[4,     3] loss: 1.386
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.384
[8,     3] loss: 1.389
[9,     3] loss: 1.386
[10,     3] loss: 1.385
[11,     3] loss: 1.382
[12,     3] loss: 1.383
[13,     3] loss: 1.386
[14,     3] loss: 1.382
[15,     3] loss: 1.380
[16,     3] loss: 1.377
[17,     3] loss: 1.362
[18,     3] loss: 1.326
[19,     3] loss: 1.315
[20,     3] loss: 1.242
[21,     3] loss: 1.287
[22,     3] loss: 1.186
[23,     3] loss: 1.172
[24,     3] loss: 1.208
[25,     3] loss: 1.109
[26,     3] loss: 1.147
[27,     3] loss: 1.046
[28,     3] loss: 1.194
[29,     3] loss: 1.028
[30,     3] loss: 1.099
[31,     3] loss: 1.048
[32,     3] loss: 1.002
[33,     3] loss: 1.033
[34,     3] loss: 0.974
[35,     3] loss: 1.009
[36,     3] loss: 1.390
[37,     3] loss: 1.017
[38,     3] loss: 1.103
[39,     3] loss: 1.055
[40,     3] loss: 1.008
[41,     3] loss: 0.978
[42,     3] loss: 0.932
[43,     3] loss: 0.912
[44,     3] loss: 0.873
[45,     3] loss: 0.853
[46,     3] loss: 0.862
[47,     3] loss: 0.860
[48,     3] loss: 0.887
[49,     3] loss: 0.901
[50,     3] loss: 0.850
[51,     3] loss: 0.851
[52,     3] loss: 0.870
[53,     3] loss: 0.854
[54,     3] loss: 0.938
[55,     3] loss: 0.836
[56,     3] loss: 1.008
[57,     3] loss: 0.848
[58,     3] loss: 0.923
[59,     3] loss: 0.835
[60,     3] loss: 0.871
[61,     3] loss: 0.884
[62,     3] loss: 0.963
[63,     3] loss: 0.932
[64,     3] loss: 0.920
[65,     3] loss: 0.970
[66,     3] loss: 0.988
[67,     3] loss: 0.982
[68,     3] loss: 0.909
[69,     3] loss: 0.988
[70,     3] loss: 0.900
[71,     3] loss: 0.941
[72,     3] loss: 0.977
[73,     3] loss: 0.898
[74,     3] loss: 0.832
[75,     3] loss: 0.835
[76,     3] loss: 0.807
Early stopping applied (best metric=0.516868531703949)
Finished Training
Total time taken: 21.877138376235962
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.385
[3,     3] loss: 1.393
[4,     3] loss: 1.387
[5,     3] loss: 1.385
[6,     3] loss: 1.387
[7,     3] loss: 1.389
[8,     3] loss: 1.385
[9,     3] loss: 1.385
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.385
[13,     3] loss: 1.384
[14,     3] loss: 1.391
[15,     3] loss: 1.391
[16,     3] loss: 1.387
[17,     3] loss: 1.387
[18,     3] loss: 1.387
[19,     3] loss: 1.387
[20,     3] loss: 1.387
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.387
[24,     3] loss: 1.387
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.385
[29,     3] loss: 1.385
[30,     3] loss: 1.385
[31,     3] loss: 1.383
[32,     3] loss: 1.387
[33,     3] loss: 1.388
[34,     3] loss: 1.391
[35,     3] loss: 1.388
[36,     3] loss: 1.385
[37,     3] loss: 1.386
[38,     3] loss: 1.387
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.387
[43,     3] loss: 1.387
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.387
Early stopping applied (best metric=0.5594065189361572)
Finished Training
Total time taken: 15.970752716064453
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.385
[3,     3] loss: 1.386
[4,     3] loss: 1.387
[5,     3] loss: 1.388
[6,     3] loss: 1.388
[7,     3] loss: 1.389
[8,     3] loss: 1.387
[9,     3] loss: 1.386
[10,     3] loss: 1.383
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.385
[14,     3] loss: 1.388
[15,     3] loss: 1.383
[16,     3] loss: 1.385
[17,     3] loss: 1.386
[18,     3] loss: 1.385
[19,     3] loss: 1.380
[20,     3] loss: 1.389
[21,     3] loss: 1.379
[22,     3] loss: 1.391
[23,     3] loss: 1.381
[24,     3] loss: 1.391
[25,     3] loss: 1.387
[26,     3] loss: 1.383
[27,     3] loss: 1.385
[28,     3] loss: 1.386
[29,     3] loss: 1.388
[30,     3] loss: 1.384
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.384
[34,     3] loss: 1.387
[35,     3] loss: 1.387
[36,     3] loss: 1.385
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.387
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.385
[44,     3] loss: 1.384
[45,     3] loss: 1.384
[46,     3] loss: 1.382
[47,     3] loss: 1.367
[48,     3] loss: 1.370
[49,     3] loss: 1.365
[50,     3] loss: 1.395
[51,     3] loss: 1.320
[52,     3] loss: 1.327
[53,     3] loss: 1.379
[54,     3] loss: 1.255
[55,     3] loss: 1.310
[56,     3] loss: 1.277
[57,     3] loss: 1.256
[58,     3] loss: 1.156
[59,     3] loss: 1.154
[60,     3] loss: 1.098
[61,     3] loss: 1.206
[62,     3] loss: 1.121
[63,     3] loss: 1.103
[64,     3] loss: 1.082
[65,     3] loss: 1.006
[66,     3] loss: 1.126
[67,     3] loss: 0.986
[68,     3] loss: 1.062
[69,     3] loss: 0.943
[70,     3] loss: 0.962
[71,     3] loss: 0.994
[72,     3] loss: 1.089
[73,     3] loss: 1.096
[74,     3] loss: 1.092
[75,     3] loss: 1.202
[76,     3] loss: 1.112
[77,     3] loss: 1.087
[78,     3] loss: 1.030
[79,     3] loss: 0.981
[80,     3] loss: 0.994
[81,     3] loss: 0.905
[82,     3] loss: 0.987
[83,     3] loss: 0.861
[84,     3] loss: 0.866
[85,     3] loss: 0.904
[86,     3] loss: 0.816
[87,     3] loss: 0.848
[88,     3] loss: 0.808
[89,     3] loss: 0.934
[90,     3] loss: 0.876
[91,     3] loss: 0.884
[92,     3] loss: 0.879
[93,     3] loss: 0.960
[94,     3] loss: 0.935
[95,     3] loss: 1.007
[96,     3] loss: 0.949
[97,     3] loss: 0.870
[98,     3] loss: 0.894
[99,     3] loss: 0.861
[100,     3] loss: 0.843
[101,     3] loss: 0.947
[102,     3] loss: 0.812
[103,     3] loss: 0.822
[104,     3] loss: 0.811
[105,     3] loss: 0.792
[106,     3] loss: 0.799
[107,     3] loss: 0.786
[108,     3] loss: 0.786
Early stopping applied (best metric=0.529487669467926)
Finished Training
Total time taken: 31.303935050964355
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.392
[3,     3] loss: 1.386
[4,     3] loss: 1.390
[5,     3] loss: 1.388
[6,     3] loss: 1.386
[7,     3] loss: 1.386
[8,     3] loss: 1.387
[9,     3] loss: 1.387
[10,     3] loss: 1.386
[11,     3] loss: 1.388
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.385
[18,     3] loss: 1.385
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.383
[24,     3] loss: 1.388
[25,     3] loss: 1.388
[26,     3] loss: 1.385
[27,     3] loss: 1.387
[28,     3] loss: 1.384
[29,     3] loss: 1.387
[30,     3] loss: 1.387
[31,     3] loss: 1.388
[32,     3] loss: 1.387
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.387
[49,     3] loss: 1.385
[50,     3] loss: 1.386
[51,     3] loss: 1.387
[52,     3] loss: 1.386
[53,     3] loss: 1.385
[54,     3] loss: 1.388
[55,     3] loss: 1.387
[56,     3] loss: 1.388
Early stopping applied (best metric=0.5450371503829956)
Finished Training
Total time taken: 16.10423755645752
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.387
[4,     3] loss: 1.384
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.386
[8,     3] loss: 1.391
[9,     3] loss: 1.387
[10,     3] loss: 1.386
[11,     3] loss: 1.389
[12,     3] loss: 1.387
[13,     3] loss: 1.385
[14,     3] loss: 1.387
[15,     3] loss: 1.386
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.387
[19,     3] loss: 1.387
[20,     3] loss: 1.387
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.387
[24,     3] loss: 1.386
[25,     3] loss: 1.387
[26,     3] loss: 1.387
[27,     3] loss: 1.385
[28,     3] loss: 1.387
[29,     3] loss: 1.385
[30,     3] loss: 1.385
[31,     3] loss: 1.385
[32,     3] loss: 1.388
[33,     3] loss: 1.385
[34,     3] loss: 1.384
[35,     3] loss: 1.384
[36,     3] loss: 1.379
[37,     3] loss: 1.368
[38,     3] loss: 1.347
[39,     3] loss: 1.360
[40,     3] loss: 1.330
[41,     3] loss: 1.300
[42,     3] loss: 1.325
[43,     3] loss: 1.239
[44,     3] loss: 1.175
[45,     3] loss: 1.163
[46,     3] loss: 1.091
[47,     3] loss: 1.018
[48,     3] loss: 1.106
[49,     3] loss: 1.100
[50,     3] loss: 1.015
[51,     3] loss: 0.999
[52,     3] loss: 0.972
[53,     3] loss: 0.934
[54,     3] loss: 0.902
[55,     3] loss: 0.960
[56,     3] loss: 0.945
[57,     3] loss: 0.985
[58,     3] loss: 0.928
[59,     3] loss: 0.903
[60,     3] loss: 0.908
[61,     3] loss: 0.847
[62,     3] loss: 1.128
[63,     3] loss: 0.989
[64,     3] loss: 1.022
[65,     3] loss: 0.986
[66,     3] loss: 0.989
[67,     3] loss: 0.902
[68,     3] loss: 0.893
[69,     3] loss: 0.941
[70,     3] loss: 0.986
[71,     3] loss: 0.897
[72,     3] loss: 0.955
[73,     3] loss: 0.961
[74,     3] loss: 0.886
[75,     3] loss: 0.936
[76,     3] loss: 0.811
[77,     3] loss: 0.885
[78,     3] loss: 0.858
[79,     3] loss: 0.809
[80,     3] loss: 0.805
[81,     3] loss: 0.812
[82,     3] loss: 0.780
[83,     3] loss: 0.795
[84,     3] loss: 0.806
[85,     3] loss: 0.803
[86,     3] loss: 0.784
[87,     3] loss: 0.768
[88,     3] loss: 0.809
[89,     3] loss: 0.797
[90,     3] loss: 0.788
[91,     3] loss: 0.753
[92,     3] loss: 0.784
[93,     3] loss: 0.787
[94,     3] loss: 0.872
[95,     3] loss: 1.405
Early stopping applied (best metric=0.49303025007247925)
Finished Training
Total time taken: 27.228360414505005
{'S-palmitoylation-C Validation Accuracy': 0.58229761747229, 'S-palmitoylation-C Validation Sensitivity': 0.39722772277227725, 'S-palmitoylation-C Validation Specificity': 0.6286747769747417, 'S-palmitoylation-C Validation Precision': nan, 'S-palmitoylation-C AUC ROC': 0.532917232290622, 'S-palmitoylation-C AUC PR': 0.22098875203456678, 'S-palmitoylation-C MCC': 0.024855678230260008, 'S-palmitoylation-C F1': 0.23457114165261425, 'Validation Loss (S-palmitoylation-C)': 0.5545101682345073, 'Hydroxylation-K Validation Accuracy': 0.5818853427895981, 'Hydroxylation-K Validation Sensitivity': 0.7681481481481481, 'Hydroxylation-K Validation Specificity': 0.5368421052631579, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.7845711500974659, 'Hydroxylation-K AUC PR': 0.562833003858092, 'Hydroxylation-K MCC': 0.2507309746622808, 'Hydroxylation-K F1': 0.4224108396855894, 'Validation Loss (Hydroxylation-K)': 0.5298746228218079, 'Validation Loss (total)': 1.0843847910563151, 'TimeToTrain': 26.699504613876343}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027471009708205096,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5750689292658631,
 'loss_weight_S-palmitoylation-C': 0.25732094629578756,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 73502941,
 'sample_weights': [0.6617215330348348, 0.6847911464818431],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9876236459294108,
 'weight_decay_Hydroxylation-K': 8.613598946099883,
 'weight_decay_S-palmitoylation-C': 7.864319681110877}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.395
[3,     3] loss: 1.377
[4,     3] loss: 1.392
[5,     3] loss: 1.390
[6,     3] loss: 1.381
[7,     3] loss: 1.386
[8,     3] loss: 1.385
[9,     3] loss: 1.387
[10,     3] loss: 1.384
[11,     3] loss: 1.388
[12,     3] loss: 1.386
[13,     3] loss: 1.385
[14,     3] loss: 1.383
[15,     3] loss: 1.384
[16,     3] loss: 1.382
[17,     3] loss: 1.382
[18,     3] loss: 1.378
[19,     3] loss: 1.376
[20,     3] loss: 1.376
[21,     3] loss: 1.358
[22,     3] loss: 1.354
[23,     3] loss: 1.357
[24,     3] loss: 1.276
[25,     3] loss: 1.333
[26,     3] loss: 1.290
[27,     3] loss: 1.240
[28,     3] loss: 1.249
[29,     3] loss: 1.146
[30,     3] loss: 1.208
[31,     3] loss: 1.220
[32,     3] loss: 1.110
[33,     3] loss: 1.112
[34,     3] loss: 1.063
[35,     3] loss: 1.061
[36,     3] loss: 1.142
[37,     3] loss: 1.055
[38,     3] loss: 1.022
[39,     3] loss: 1.064
[40,     3] loss: 0.962
[41,     3] loss: 1.002
[42,     3] loss: 0.978
[43,     3] loss: 0.937
[44,     3] loss: 0.955
[45,     3] loss: 0.953
[46,     3] loss: 0.897
[47,     3] loss: 0.974
[48,     3] loss: 0.982
[49,     3] loss: 1.073
[50,     3] loss: 1.008
[51,     3] loss: 0.964
[52,     3] loss: 0.914
[53,     3] loss: 0.945
[54,     3] loss: 0.961
[55,     3] loss: 0.899
[56,     3] loss: 0.912
[57,     3] loss: 0.940
[58,     3] loss: 0.945
[59,     3] loss: 0.923
[60,     3] loss: 0.855
[61,     3] loss: 0.919
[62,     3] loss: 0.875
[63,     3] loss: 0.881
[64,     3] loss: 0.919
[65,     3] loss: 0.908
[66,     3] loss: 0.865
[67,     3] loss: 0.824
[68,     3] loss: 0.880
[69,     3] loss: 0.817
[70,     3] loss: 0.819
[71,     3] loss: 0.780
[72,     3] loss: 0.782
[73,     3] loss: 0.768
[74,     3] loss: 0.765
[75,     3] loss: 0.783
[76,     3] loss: 0.753
[77,     3] loss: 0.754
[78,     3] loss: 0.764
[79,     3] loss: 0.743
[80,     3] loss: 0.752
[81,     3] loss: 0.761
[82,     3] loss: 0.736
[83,     3] loss: 0.756
[84,     3] loss: 0.822
[85,     3] loss: 0.768
[86,     3] loss: 0.758
[87,     3] loss: 0.755
[88,     3] loss: 0.781
[89,     3] loss: 0.762
[90,     3] loss: 0.759
[91,     3] loss: 0.773
[92,     3] loss: 0.761
[93,     3] loss: 0.758
[94,     3] loss: 0.750
[95,     3] loss: 0.769
[96,     3] loss: 0.746
[97,     3] loss: 0.763
[98,     3] loss: 0.755
[99,     3] loss: 0.747
[100,     3] loss: 0.763
[101,     3] loss: 0.767
[102,     3] loss: 0.781
[103,     3] loss: 0.750
[104,     3] loss: 0.761
[105,     3] loss: 0.801
[106,     3] loss: 0.750
[107,     3] loss: 0.739
[108,     3] loss: 0.737
Early stopping applied (best metric=0.5361533761024475)
Finished Training
Total time taken: 30.798681259155273
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.388
[3,     3] loss: 1.390
[4,     3] loss: 1.387
[5,     3] loss: 1.389
[6,     3] loss: 1.386
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.385
[10,     3] loss: 1.387
[11,     3] loss: 1.388
[12,     3] loss: 1.387
[13,     3] loss: 1.387
[14,     3] loss: 1.387
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.385
[20,     3] loss: 1.385
[21,     3] loss: 1.385
[22,     3] loss: 1.385
[23,     3] loss: 1.381
[24,     3] loss: 1.382
[25,     3] loss: 1.379
[26,     3] loss: 1.391
[27,     3] loss: 1.379
[28,     3] loss: 1.376
[29,     3] loss: 1.383
[30,     3] loss: 1.376
[31,     3] loss: 1.364
[32,     3] loss: 1.348
[33,     3] loss: 1.333
[34,     3] loss: 1.297
[35,     3] loss: 1.282
[36,     3] loss: 1.221
[37,     3] loss: 1.335
[38,     3] loss: 1.162
[39,     3] loss: 1.245
[40,     3] loss: 1.194
[41,     3] loss: 1.148
[42,     3] loss: 1.042
[43,     3] loss: 1.172
[44,     3] loss: 1.103
[45,     3] loss: 1.084
[46,     3] loss: 1.137
[47,     3] loss: 1.084
[48,     3] loss: 1.016
[49,     3] loss: 0.968
[50,     3] loss: 1.007
[51,     3] loss: 0.945
[52,     3] loss: 0.966
[53,     3] loss: 0.908
[54,     3] loss: 0.923
[55,     3] loss: 0.943
[56,     3] loss: 0.952
[57,     3] loss: 0.854
[58,     3] loss: 0.901
[59,     3] loss: 0.906
[60,     3] loss: 0.947
[61,     3] loss: 0.886
[62,     3] loss: 0.937
[63,     3] loss: 0.862
[64,     3] loss: 0.954
[65,     3] loss: 0.872
[66,     3] loss: 0.887
[67,     3] loss: 0.867
[68,     3] loss: 0.829
[69,     3] loss: 0.835
[70,     3] loss: 0.854
[71,     3] loss: 0.791
[72,     3] loss: 0.808
[73,     3] loss: 0.796
[74,     3] loss: 0.779
[75,     3] loss: 0.792
[76,     3] loss: 0.761
[77,     3] loss: 0.773
[78,     3] loss: 0.739
[79,     3] loss: 0.773
[80,     3] loss: 0.765
[81,     3] loss: 0.763
[82,     3] loss: 0.835
[83,     3] loss: 0.747
[84,     3] loss: 0.777
[85,     3] loss: 0.742
[86,     3] loss: 0.754
[87,     3] loss: 0.741
[88,     3] loss: 0.757
[89,     3] loss: 0.743
[90,     3] loss: 0.743
[91,     3] loss: 0.731
[92,     3] loss: 0.733
[93,     3] loss: 0.749
[94,     3] loss: 0.776
[95,     3] loss: 0.735
[96,     3] loss: 0.765
[97,     3] loss: 0.765
[98,     3] loss: 0.746
[99,     3] loss: 0.755
[100,     3] loss: 0.758
[101,     3] loss: 0.745
Early stopping applied (best metric=0.5257902145385742)
Finished Training
Total time taken: 28.91948175430298
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.383
[3,     3] loss: 1.403
[4,     3] loss: 1.390
[5,     3] loss: 1.388
[6,     3] loss: 1.388
[7,     3] loss: 1.383
[8,     3] loss: 1.384
[9,     3] loss: 1.386
[10,     3] loss: 1.391
[11,     3] loss: 1.386
[12,     3] loss: 1.383
[13,     3] loss: 1.384
[14,     3] loss: 1.381
[15,     3] loss: 1.380
[16,     3] loss: 1.379
[17,     3] loss: 1.379
[18,     3] loss: 1.373
[19,     3] loss: 1.363
[20,     3] loss: 1.349
[21,     3] loss: 1.340
[22,     3] loss: 1.335
[23,     3] loss: 1.315
[24,     3] loss: 1.274
[25,     3] loss: 1.197
[26,     3] loss: 1.212
[27,     3] loss: 1.242
[28,     3] loss: 1.158
[29,     3] loss: 1.186
[30,     3] loss: 1.161
[31,     3] loss: 1.112
[32,     3] loss: 1.118
[33,     3] loss: 1.161
[34,     3] loss: 1.086
[35,     3] loss: 1.075
[36,     3] loss: 1.063
[37,     3] loss: 1.028
[38,     3] loss: 0.999
[39,     3] loss: 1.073
[40,     3] loss: 1.061
[41,     3] loss: 1.069
[42,     3] loss: 1.015
[43,     3] loss: 0.997
[44,     3] loss: 0.952
[45,     3] loss: 1.003
[46,     3] loss: 0.954
[47,     3] loss: 0.901
[48,     3] loss: 1.036
[49,     3] loss: 0.933
[50,     3] loss: 0.993
[51,     3] loss: 0.872
[52,     3] loss: 0.991
[53,     3] loss: 0.912
[54,     3] loss: 0.896
[55,     3] loss: 0.934
[56,     3] loss: 0.927
[57,     3] loss: 0.897
[58,     3] loss: 0.916
[59,     3] loss: 0.974
[60,     3] loss: 0.925
[61,     3] loss: 0.867
[62,     3] loss: 0.890
[63,     3] loss: 0.846
[64,     3] loss: 0.860
[65,     3] loss: 0.844
[66,     3] loss: 0.952
[67,     3] loss: 0.880
[68,     3] loss: 0.842
[69,     3] loss: 0.875
[70,     3] loss: 0.848
[71,     3] loss: 0.850
[72,     3] loss: 0.926
[73,     3] loss: 0.857
[74,     3] loss: 0.864
[75,     3] loss: 0.835
[76,     3] loss: 0.936
[77,     3] loss: 0.856
[78,     3] loss: 0.848
[79,     3] loss: 0.863
[80,     3] loss: 0.839
[81,     3] loss: 0.831
[82,     3] loss: 0.863
[83,     3] loss: 0.838
[84,     3] loss: 0.857
[85,     3] loss: 0.826
[86,     3] loss: 0.789
[87,     3] loss: 0.821
Early stopping applied (best metric=0.5343207120895386)
Finished Training
Total time taken: 25.24143695831299
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.394
[3,     3] loss: 1.386
[4,     3] loss: 1.388
[5,     3] loss: 1.392
[6,     3] loss: 1.387
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.386
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.387
[14,     3] loss: 1.387
[15,     3] loss: 1.386
[16,     3] loss: 1.385
[17,     3] loss: 1.389
[18,     3] loss: 1.385
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.387
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.387
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.387
[32,     3] loss: 1.385
[33,     3] loss: 1.385
[34,     3] loss: 1.385
[35,     3] loss: 1.388
[36,     3] loss: 1.383
[37,     3] loss: 1.384
[38,     3] loss: 1.383
[39,     3] loss: 1.384
[40,     3] loss: 1.376
[41,     3] loss: 1.360
[42,     3] loss: 1.345
[43,     3] loss: 1.352
[44,     3] loss: 1.269
[45,     3] loss: 1.193
[46,     3] loss: 1.212
[47,     3] loss: 1.114
[48,     3] loss: 1.232
[49,     3] loss: 1.086
[50,     3] loss: 1.161
[51,     3] loss: 1.093
[52,     3] loss: 1.134
[53,     3] loss: 1.033
[54,     3] loss: 1.078
[55,     3] loss: 1.031
[56,     3] loss: 1.063
[57,     3] loss: 1.026
[58,     3] loss: 1.077
[59,     3] loss: 0.961
[60,     3] loss: 0.997
[61,     3] loss: 0.958
[62,     3] loss: 0.922
[63,     3] loss: 0.992
[64,     3] loss: 1.046
[65,     3] loss: 0.981
[66,     3] loss: 0.924
[67,     3] loss: 0.978
[68,     3] loss: 0.977
[69,     3] loss: 0.907
[70,     3] loss: 0.927
[71,     3] loss: 0.922
[72,     3] loss: 0.870
[73,     3] loss: 0.971
[74,     3] loss: 0.869
[75,     3] loss: 0.891
[76,     3] loss: 0.900
[77,     3] loss: 0.817
[78,     3] loss: 0.853
[79,     3] loss: 0.863
[80,     3] loss: 0.836
[81,     3] loss: 0.859
[82,     3] loss: 0.803
[83,     3] loss: 0.863
[84,     3] loss: 0.833
[85,     3] loss: 0.801
[86,     3] loss: 0.796
[87,     3] loss: 0.814
[88,     3] loss: 0.805
[89,     3] loss: 0.784
[90,     3] loss: 0.806
[91,     3] loss: 0.771
[92,     3] loss: 0.772
[93,     3] loss: 0.756
[94,     3] loss: 0.755
[95,     3] loss: 0.753
[96,     3] loss: 0.748
[97,     3] loss: 0.763
[98,     3] loss: 0.753
[99,     3] loss: 0.747
[100,     3] loss: 0.744
[101,     3] loss: 0.753
[102,     3] loss: 0.759
[103,     3] loss: 0.756
[104,     3] loss: 0.737
[105,     3] loss: 0.747
[106,     3] loss: 0.738
[107,     3] loss: 0.743
[108,     3] loss: 0.741
[109,     3] loss: 0.723
[110,     3] loss: 0.733
[111,     3] loss: 0.739
[112,     3] loss: 0.744
[113,     3] loss: 0.730
[114,     3] loss: 0.744
[115,     3] loss: 0.738
[116,     3] loss: 0.736
[117,     3] loss: 0.738
[118,     3] loss: 0.729
[119,     3] loss: 0.741
[120,     3] loss: 0.736
[121,     3] loss: 0.779
[122,     3] loss: 0.837
Early stopping applied (best metric=0.5300479531288147)
Finished Training
Total time taken: 35.03368926048279
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.389
[3,     3] loss: 1.380
[4,     3] loss: 1.391
[5,     3] loss: 1.379
[6,     3] loss: 1.388
[7,     3] loss: 1.382
[8,     3] loss: 1.377
[9,     3] loss: 1.383
[10,     3] loss: 1.380
[11,     3] loss: 1.371
[12,     3] loss: 1.361
[13,     3] loss: 1.344
[14,     3] loss: 1.324
[15,     3] loss: 1.311
[16,     3] loss: 1.299
[17,     3] loss: 1.240
[18,     3] loss: 1.295
[19,     3] loss: 1.251
[20,     3] loss: 1.190
[21,     3] loss: 1.185
[22,     3] loss: 1.150
[23,     3] loss: 1.096
[24,     3] loss: 1.147
[25,     3] loss: 1.128
[26,     3] loss: 1.074
[27,     3] loss: 1.062
[28,     3] loss: 1.037
[29,     3] loss: 1.083
[30,     3] loss: 1.052
[31,     3] loss: 1.035
[32,     3] loss: 1.160
[33,     3] loss: 1.087
[34,     3] loss: 1.149
[35,     3] loss: 1.152
[36,     3] loss: 1.066
[37,     3] loss: 1.059
[38,     3] loss: 1.042
[39,     3] loss: 0.960
[40,     3] loss: 0.981
[41,     3] loss: 1.008
[42,     3] loss: 0.906
[43,     3] loss: 0.902
[44,     3] loss: 0.961
[45,     3] loss: 0.875
[46,     3] loss: 0.851
[47,     3] loss: 0.857
[48,     3] loss: 0.905
[49,     3] loss: 0.824
[50,     3] loss: 0.884
[51,     3] loss: 0.860
[52,     3] loss: 0.803
[53,     3] loss: 0.823
[54,     3] loss: 0.837
[55,     3] loss: 0.844
[56,     3] loss: 0.802
[57,     3] loss: 0.873
[58,     3] loss: 0.798
[59,     3] loss: 0.798
[60,     3] loss: 0.847
[61,     3] loss: 0.875
[62,     3] loss: 0.874
[63,     3] loss: 0.817
[64,     3] loss: 0.800
[65,     3] loss: 0.940
[66,     3] loss: 0.931
[67,     3] loss: 0.834
[68,     3] loss: 0.852
[69,     3] loss: 0.832
[70,     3] loss: 0.828
[71,     3] loss: 0.867
[72,     3] loss: 0.833
[73,     3] loss: 0.803
[74,     3] loss: 0.817
[75,     3] loss: 0.771
[76,     3] loss: 0.834
[77,     3] loss: 0.774
[78,     3] loss: 0.902
[79,     3] loss: 0.853
[80,     3] loss: 0.908
[81,     3] loss: 0.834
[82,     3] loss: 0.816
[83,     3] loss: 0.840
[84,     3] loss: 0.818
[85,     3] loss: 0.799
[86,     3] loss: 0.780
[87,     3] loss: 0.780
[88,     3] loss: 0.805
[89,     3] loss: 0.761
[90,     3] loss: 0.772
[91,     3] loss: 0.744
[92,     3] loss: 0.741
[93,     3] loss: 0.753
[94,     3] loss: 0.752
[95,     3] loss: 0.754
[96,     3] loss: 0.733
[97,     3] loss: 0.740
[98,     3] loss: 0.742
[99,     3] loss: 0.739
[100,     3] loss: 0.738
[101,     3] loss: 0.754
[102,     3] loss: 0.755
[103,     3] loss: 0.743
[104,     3] loss: 0.753
Early stopping applied (best metric=0.507147490978241)
Finished Training
Total time taken: 29.812638998031616
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.383
[3,     3] loss: 1.375
[4,     3] loss: 1.401
[5,     3] loss: 1.387
[6,     3] loss: 1.383
[7,     3] loss: 1.382
[8,     3] loss: 1.388
[9,     3] loss: 1.391
[10,     3] loss: 1.385
[11,     3] loss: 1.383
[12,     3] loss: 1.391
[13,     3] loss: 1.386
[14,     3] loss: 1.385
[15,     3] loss: 1.386
[16,     3] loss: 1.384
[17,     3] loss: 1.384
[18,     3] loss: 1.384
[19,     3] loss: 1.382
[20,     3] loss: 1.382
[21,     3] loss: 1.383
[22,     3] loss: 1.378
[23,     3] loss: 1.373
[24,     3] loss: 1.377
[25,     3] loss: 1.354
[26,     3] loss: 1.357
[27,     3] loss: 1.330
[28,     3] loss: 1.294
[29,     3] loss: 1.314
[30,     3] loss: 1.257
[31,     3] loss: 1.234
[32,     3] loss: 1.239
[33,     3] loss: 1.164
[34,     3] loss: 1.200
[35,     3] loss: 1.098
[36,     3] loss: 1.153
[37,     3] loss: 1.096
[38,     3] loss: 1.038
[39,     3] loss: 1.063
[40,     3] loss: 1.012
[41,     3] loss: 1.118
[42,     3] loss: 1.085
[43,     3] loss: 1.081
[44,     3] loss: 0.943
[45,     3] loss: 1.119
[46,     3] loss: 1.007
[47,     3] loss: 0.981
[48,     3] loss: 1.106
[49,     3] loss: 1.126
[50,     3] loss: 0.964
[51,     3] loss: 1.019
[52,     3] loss: 1.019
[53,     3] loss: 0.994
[54,     3] loss: 1.055
[55,     3] loss: 0.970
[56,     3] loss: 0.938
[57,     3] loss: 0.965
[58,     3] loss: 0.937
[59,     3] loss: 1.026
[60,     3] loss: 0.958
[61,     3] loss: 0.864
[62,     3] loss: 0.898
[63,     3] loss: 0.868
[64,     3] loss: 0.916
[65,     3] loss: 0.858
[66,     3] loss: 0.838
[67,     3] loss: 0.947
[68,     3] loss: 0.919
[69,     3] loss: 0.823
[70,     3] loss: 0.897
[71,     3] loss: 0.939
[72,     3] loss: 0.869
[73,     3] loss: 0.863
[74,     3] loss: 0.817
[75,     3] loss: 0.918
[76,     3] loss: 0.935
[77,     3] loss: 0.841
[78,     3] loss: 0.864
[79,     3] loss: 0.859
[80,     3] loss: 0.953
[81,     3] loss: 1.007
[82,     3] loss: 0.928
[83,     3] loss: 0.865
[84,     3] loss: 0.912
[85,     3] loss: 0.960
[86,     3] loss: 0.868
[87,     3] loss: 0.835
[88,     3] loss: 0.852
[89,     3] loss: 0.837
[90,     3] loss: 0.924
[91,     3] loss: 0.849
[92,     3] loss: 0.810
[93,     3] loss: 0.887
[94,     3] loss: 0.834
[95,     3] loss: 0.846
[96,     3] loss: 0.791
[97,     3] loss: 0.802
[98,     3] loss: 0.797
[99,     3] loss: 0.840
[100,     3] loss: 0.796
[101,     3] loss: 0.794
[102,     3] loss: 0.827
Early stopping applied (best metric=0.5328620672225952)
Finished Training
Total time taken: 29.353313446044922
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.409
[3,     3] loss: 1.388
[4,     3] loss: 1.383
[5,     3] loss: 1.383
[6,     3] loss: 1.389
[7,     3] loss: 1.387
[8,     3] loss: 1.384
[9,     3] loss: 1.384
[10,     3] loss: 1.383
[11,     3] loss: 1.385
[12,     3] loss: 1.383
[13,     3] loss: 1.384
[14,     3] loss: 1.381
[15,     3] loss: 1.385
[16,     3] loss: 1.384
[17,     3] loss: 1.380
[18,     3] loss: 1.378
[19,     3] loss: 1.384
[20,     3] loss: 1.370
[21,     3] loss: 1.364
[22,     3] loss: 1.353
[23,     3] loss: 1.326
[24,     3] loss: 1.296
[25,     3] loss: 1.290
[26,     3] loss: 1.225
[27,     3] loss: 1.291
[28,     3] loss: 1.204
[29,     3] loss: 1.205
[30,     3] loss: 1.181
[31,     3] loss: 1.146
[32,     3] loss: 1.066
[33,     3] loss: 1.052
[34,     3] loss: 1.058
[35,     3] loss: 1.061
[36,     3] loss: 1.067
[37,     3] loss: 1.147
[38,     3] loss: 1.099
[39,     3] loss: 1.079
[40,     3] loss: 1.007
[41,     3] loss: 1.012
[42,     3] loss: 1.067
[43,     3] loss: 1.026
[44,     3] loss: 1.003
[45,     3] loss: 0.935
[46,     3] loss: 0.929
[47,     3] loss: 0.964
[48,     3] loss: 0.911
[49,     3] loss: 0.932
[50,     3] loss: 0.930
[51,     3] loss: 0.874
[52,     3] loss: 0.853
[53,     3] loss: 0.876
[54,     3] loss: 0.863
[55,     3] loss: 0.842
[56,     3] loss: 0.852
[57,     3] loss: 0.884
[58,     3] loss: 0.843
[59,     3] loss: 0.823
[60,     3] loss: 0.871
[61,     3] loss: 0.831
[62,     3] loss: 0.814
[63,     3] loss: 0.814
[64,     3] loss: 0.811
[65,     3] loss: 0.847
[66,     3] loss: 0.816
[67,     3] loss: 0.831
[68,     3] loss: 0.796
[69,     3] loss: 0.772
[70,     3] loss: 0.783
[71,     3] loss: 0.848
[72,     3] loss: 0.777
[73,     3] loss: 0.773
[74,     3] loss: 0.818
[75,     3] loss: 0.776
[76,     3] loss: 0.768
[77,     3] loss: 0.770
[78,     3] loss: 0.799
[79,     3] loss: 0.837
[80,     3] loss: 0.786
[81,     3] loss: 0.860
[82,     3] loss: 0.775
[83,     3] loss: 0.826
[84,     3] loss: 0.779
[85,     3] loss: 0.774
[86,     3] loss: 0.779
[87,     3] loss: 0.827
[88,     3] loss: 0.777
[89,     3] loss: 0.750
[90,     3] loss: 0.764
[91,     3] loss: 0.762
[92,     3] loss: 0.748
[93,     3] loss: 0.748
[94,     3] loss: 0.748
[95,     3] loss: 0.751
[96,     3] loss: 0.745
[97,     3] loss: 0.765
[98,     3] loss: 0.739
[99,     3] loss: 0.752
[100,     3] loss: 0.736
[101,     3] loss: 0.754
[102,     3] loss: 0.750
[103,     3] loss: 0.772
[104,     3] loss: 0.781
[105,     3] loss: 0.760
[106,     3] loss: 0.783
[107,     3] loss: 0.779
[108,     3] loss: 0.831
[109,     3] loss: 0.835
[110,     3] loss: 0.800
[111,     3] loss: 0.784
[112,     3] loss: 0.805
[113,     3] loss: 0.806
[114,     3] loss: 0.788
[115,     3] loss: 0.824
[116,     3] loss: 0.815
Early stopping applied (best metric=0.5391445755958557)
Finished Training
Total time taken: 33.38523840904236
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.395
[3,     3] loss: 1.385
[4,     3] loss: 1.389
[5,     3] loss: 1.384
[6,     3] loss: 1.386
[7,     3] loss: 1.388
[8,     3] loss: 1.385
[9,     3] loss: 1.387
[10,     3] loss: 1.386
[11,     3] loss: 1.388
[12,     3] loss: 1.384
[13,     3] loss: 1.385
[14,     3] loss: 1.381
[15,     3] loss: 1.381
[16,     3] loss: 1.384
[17,     3] loss: 1.385
[18,     3] loss: 1.387
[19,     3] loss: 1.380
[20,     3] loss: 1.384
[21,     3] loss: 1.382
[22,     3] loss: 1.376
[23,     3] loss: 1.374
[24,     3] loss: 1.369
[25,     3] loss: 1.371
[26,     3] loss: 1.347
[27,     3] loss: 1.342
[28,     3] loss: 1.302
[29,     3] loss: 1.289
[30,     3] loss: 1.275
[31,     3] loss: 1.202
[32,     3] loss: 1.254
[33,     3] loss: 1.224
[34,     3] loss: 1.231
[35,     3] loss: 1.136
[36,     3] loss: 1.164
[37,     3] loss: 1.145
[38,     3] loss: 1.183
[39,     3] loss: 1.149
[40,     3] loss: 1.161
[41,     3] loss: 1.166
[42,     3] loss: 1.131
[43,     3] loss: 1.021
[44,     3] loss: 1.078
[45,     3] loss: 0.972
[46,     3] loss: 0.942
[47,     3] loss: 0.983
[48,     3] loss: 0.873
[49,     3] loss: 0.974
[50,     3] loss: 0.929
[51,     3] loss: 0.880
[52,     3] loss: 0.915
[53,     3] loss: 0.900
[54,     3] loss: 0.915
[55,     3] loss: 0.933
[56,     3] loss: 0.888
[57,     3] loss: 0.879
[58,     3] loss: 0.850
[59,     3] loss: 0.838
[60,     3] loss: 0.887
[61,     3] loss: 0.840
[62,     3] loss: 0.900
[63,     3] loss: 0.819
[64,     3] loss: 0.843
[65,     3] loss: 0.862
[66,     3] loss: 0.863
[67,     3] loss: 0.816
[68,     3] loss: 0.862
[69,     3] loss: 0.815
[70,     3] loss: 0.832
[71,     3] loss: 0.804
[72,     3] loss: 0.776
[73,     3] loss: 0.809
[74,     3] loss: 0.776
[75,     3] loss: 0.777
[76,     3] loss: 0.798
[77,     3] loss: 0.943
[78,     3] loss: 0.814
[79,     3] loss: 0.792
[80,     3] loss: 0.814
[81,     3] loss: 0.871
[82,     3] loss: 0.872
[83,     3] loss: 0.931
[84,     3] loss: 0.820
[85,     3] loss: 0.784
[86,     3] loss: 0.793
[87,     3] loss: 0.804
[88,     3] loss: 0.764
[89,     3] loss: 0.836
[90,     3] loss: 0.836
[91,     3] loss: 0.798
[92,     3] loss: 0.828
[93,     3] loss: 0.764
Early stopping applied (best metric=0.5283252596855164)
Finished Training
Total time taken: 25.900407075881958
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.383
[3,     3] loss: 1.388
[4,     3] loss: 1.382
[5,     3] loss: 1.386
[6,     3] loss: 1.390
[7,     3] loss: 1.388
[8,     3] loss: 1.382
[9,     3] loss: 1.385
[10,     3] loss: 1.382
[11,     3] loss: 1.388
[12,     3] loss: 1.388
[13,     3] loss: 1.381
[14,     3] loss: 1.384
[15,     3] loss: 1.381
[16,     3] loss: 1.382
[17,     3] loss: 1.377
[18,     3] loss: 1.375
[19,     3] loss: 1.374
[20,     3] loss: 1.364
[21,     3] loss: 1.350
[22,     3] loss: 1.337
[23,     3] loss: 1.340
[24,     3] loss: 1.294
[25,     3] loss: 1.244
[26,     3] loss: 1.259
[27,     3] loss: 1.210
[28,     3] loss: 1.183
[29,     3] loss: 1.240
[30,     3] loss: 1.134
[31,     3] loss: 1.167
[32,     3] loss: 1.112
[33,     3] loss: 1.182
[34,     3] loss: 1.110
[35,     3] loss: 1.119
[36,     3] loss: 1.139
[37,     3] loss: 1.026
[38,     3] loss: 1.089
[39,     3] loss: 0.979
[40,     3] loss: 1.059
[41,     3] loss: 1.049
[42,     3] loss: 1.054
[43,     3] loss: 1.043
[44,     3] loss: 1.054
[45,     3] loss: 0.990
[46,     3] loss: 1.032
[47,     3] loss: 0.998
[48,     3] loss: 0.942
[49,     3] loss: 0.976
[50,     3] loss: 0.929
[51,     3] loss: 0.961
[52,     3] loss: 0.891
[53,     3] loss: 0.900
[54,     3] loss: 0.905
[55,     3] loss: 0.967
[56,     3] loss: 0.904
[57,     3] loss: 1.010
[58,     3] loss: 0.888
[59,     3] loss: 0.914
[60,     3] loss: 0.978
[61,     3] loss: 0.919
[62,     3] loss: 0.948
[63,     3] loss: 0.881
[64,     3] loss: 0.970
[65,     3] loss: 0.858
[66,     3] loss: 0.923
[67,     3] loss: 0.845
[68,     3] loss: 0.960
[69,     3] loss: 0.893
[70,     3] loss: 0.850
[71,     3] loss: 0.919
[72,     3] loss: 0.840
[73,     3] loss: 0.824
[74,     3] loss: 0.860
[75,     3] loss: 0.929
[76,     3] loss: 0.819
[77,     3] loss: 0.899
[78,     3] loss: 0.931
[79,     3] loss: 0.863
[80,     3] loss: 0.849
[81,     3] loss: 0.823
[82,     3] loss: 0.823
[83,     3] loss: 0.815
[84,     3] loss: 0.784
[85,     3] loss: 0.762
[86,     3] loss: 0.791
[87,     3] loss: 0.806
[88,     3] loss: 0.769
[89,     3] loss: 0.796
[90,     3] loss: 0.797
[91,     3] loss: 0.783
Early stopping applied (best metric=0.5038135647773743)
Finished Training
Total time taken: 25.910311460494995
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.390
[3,     3] loss: 1.391
[4,     3] loss: 1.388
[5,     3] loss: 1.387
[6,     3] loss: 1.378
[7,     3] loss: 1.377
[8,     3] loss: 1.380
[9,     3] loss: 1.386
[10,     3] loss: 1.388
[11,     3] loss: 1.396
[12,     3] loss: 1.392
[13,     3] loss: 1.382
[14,     3] loss: 1.386
[15,     3] loss: 1.381
[16,     3] loss: 1.386
[17,     3] loss: 1.388
[18,     3] loss: 1.389
[19,     3] loss: 1.386
[20,     3] loss: 1.385
[21,     3] loss: 1.386
[22,     3] loss: 1.385
[23,     3] loss: 1.386
[24,     3] loss: 1.385
[25,     3] loss: 1.384
[26,     3] loss: 1.385
[27,     3] loss: 1.388
[28,     3] loss: 1.384
[29,     3] loss: 1.383
[30,     3] loss: 1.386
[31,     3] loss: 1.385
[32,     3] loss: 1.385
[33,     3] loss: 1.382
[34,     3] loss: 1.379
[35,     3] loss: 1.379
[36,     3] loss: 1.368
[37,     3] loss: 1.362
[38,     3] loss: 1.342
[39,     3] loss: 1.332
[40,     3] loss: 1.270
[41,     3] loss: 1.239
[42,     3] loss: 1.228
[43,     3] loss: 1.223
[44,     3] loss: 1.141
[45,     3] loss: 1.148
[46,     3] loss: 1.112
[47,     3] loss: 1.212
[48,     3] loss: 1.153
[49,     3] loss: 1.125
[50,     3] loss: 1.122
[51,     3] loss: 1.076
[52,     3] loss: 1.068
[53,     3] loss: 1.005
[54,     3] loss: 1.001
[55,     3] loss: 0.967
[56,     3] loss: 0.975
[57,     3] loss: 1.045
[58,     3] loss: 0.924
[59,     3] loss: 0.937
[60,     3] loss: 0.932
[61,     3] loss: 0.883
[62,     3] loss: 0.936
[63,     3] loss: 0.866
[64,     3] loss: 0.894
[65,     3] loss: 0.935
[66,     3] loss: 0.928
[67,     3] loss: 0.859
[68,     3] loss: 0.867
[69,     3] loss: 0.840
[70,     3] loss: 0.798
[71,     3] loss: 0.853
[72,     3] loss: 0.870
[73,     3] loss: 0.841
[74,     3] loss: 0.823
[75,     3] loss: 0.789
[76,     3] loss: 0.824
[77,     3] loss: 0.801
[78,     3] loss: 0.784
[79,     3] loss: 0.939
[80,     3] loss: 0.803
[81,     3] loss: 0.792
[82,     3] loss: 0.770
[83,     3] loss: 0.801
[84,     3] loss: 0.806
[85,     3] loss: 0.793
[86,     3] loss: 0.771
[87,     3] loss: 0.849
[88,     3] loss: 0.826
[89,     3] loss: 0.796
[90,     3] loss: 0.777
[91,     3] loss: 0.786
[92,     3] loss: 0.770
[93,     3] loss: 0.827
[94,     3] loss: 0.776
[95,     3] loss: 0.870
Early stopping applied (best metric=0.5308994650840759)
Finished Training
Total time taken: 26.750783920288086
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.384
[3,     3] loss: 1.389
[4,     3] loss: 1.388
[5,     3] loss: 1.386
[6,     3] loss: 1.383
[7,     3] loss: 1.385
[8,     3] loss: 1.388
[9,     3] loss: 1.380
[10,     3] loss: 1.383
[11,     3] loss: 1.380
[12,     3] loss: 1.382
[13,     3] loss: 1.380
[14,     3] loss: 1.375
[15,     3] loss: 1.376
[16,     3] loss: 1.378
[17,     3] loss: 1.367
[18,     3] loss: 1.358
[19,     3] loss: 1.350
[20,     3] loss: 1.336
[21,     3] loss: 1.328
[22,     3] loss: 1.271
[23,     3] loss: 1.275
[24,     3] loss: 1.226
[25,     3] loss: 1.196
[26,     3] loss: 1.280
[27,     3] loss: 1.102
[28,     3] loss: 1.059
[29,     3] loss: 1.056
[30,     3] loss: 1.050
[31,     3] loss: 1.036
[32,     3] loss: 1.078
[33,     3] loss: 1.120
[34,     3] loss: 1.120
[35,     3] loss: 1.043
[36,     3] loss: 1.104
[37,     3] loss: 1.065
[38,     3] loss: 1.048
[39,     3] loss: 1.054
[40,     3] loss: 1.069
[41,     3] loss: 1.030
[42,     3] loss: 1.042
[43,     3] loss: 1.091
[44,     3] loss: 0.953
[45,     3] loss: 0.956
[46,     3] loss: 1.049
[47,     3] loss: 1.011
[48,     3] loss: 0.939
[49,     3] loss: 0.939
[50,     3] loss: 0.889
[51,     3] loss: 0.883
[52,     3] loss: 0.815
[53,     3] loss: 0.865
[54,     3] loss: 0.933
[55,     3] loss: 0.866
[56,     3] loss: 0.863
[57,     3] loss: 0.867
[58,     3] loss: 0.843
[59,     3] loss: 0.924
[60,     3] loss: 0.847
[61,     3] loss: 0.881
[62,     3] loss: 0.822
[63,     3] loss: 0.829
[64,     3] loss: 0.799
[65,     3] loss: 0.817
[66,     3] loss: 0.859
[67,     3] loss: 0.823
[68,     3] loss: 0.983
[69,     3] loss: 0.902
[70,     3] loss: 0.879
[71,     3] loss: 0.869
[72,     3] loss: 0.924
[73,     3] loss: 0.909
[74,     3] loss: 0.880
[75,     3] loss: 0.909
[76,     3] loss: 0.860
[77,     3] loss: 0.833
[78,     3] loss: 0.860
[79,     3] loss: 0.820
[80,     3] loss: 0.795
[81,     3] loss: 0.794
[82,     3] loss: 0.764
[83,     3] loss: 0.782
[84,     3] loss: 0.770
[85,     3] loss: 0.758
[86,     3] loss: 0.758
[87,     3] loss: 0.775
[88,     3] loss: 0.782
[89,     3] loss: 0.785
[90,     3] loss: 0.780
[91,     3] loss: 0.803
[92,     3] loss: 0.870
[93,     3] loss: 0.793
[94,     3] loss: 0.771
[95,     3] loss: 0.800
[96,     3] loss: 0.770
[97,     3] loss: 0.828
[98,     3] loss: 0.785
[99,     3] loss: 0.896
[100,     3] loss: 0.778
[101,     3] loss: 0.797
[102,     3] loss: 0.788
[103,     3] loss: 0.806
Early stopping applied (best metric=0.5178637504577637)
Finished Training
Total time taken: 28.46992540359497
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.381
[3,     3] loss: 1.389
[4,     3] loss: 1.378
[5,     3] loss: 1.404
[6,     3] loss: 1.400
[7,     3] loss: 1.385
[8,     3] loss: 1.384
[9,     3] loss: 1.385
[10,     3] loss: 1.385
[11,     3] loss: 1.386
[12,     3] loss: 1.386
[13,     3] loss: 1.387
[14,     3] loss: 1.385
[15,     3] loss: 1.388
[16,     3] loss: 1.383
[17,     3] loss: 1.383
[18,     3] loss: 1.387
[19,     3] loss: 1.384
[20,     3] loss: 1.384
[21,     3] loss: 1.385
[22,     3] loss: 1.382
[23,     3] loss: 1.381
[24,     3] loss: 1.379
[25,     3] loss: 1.375
[26,     3] loss: 1.378
[27,     3] loss: 1.364
[28,     3] loss: 1.342
[29,     3] loss: 1.350
[30,     3] loss: 1.319
[31,     3] loss: 1.254
[32,     3] loss: 1.303
[33,     3] loss: 1.234
[34,     3] loss: 1.188
[35,     3] loss: 1.200
[36,     3] loss: 1.147
[37,     3] loss: 1.047
[38,     3] loss: 1.000
[39,     3] loss: 1.053
[40,     3] loss: 0.972
[41,     3] loss: 1.093
[42,     3] loss: 1.062
[43,     3] loss: 1.004
[44,     3] loss: 1.006
[45,     3] loss: 1.033
[46,     3] loss: 0.968
[47,     3] loss: 0.902
[48,     3] loss: 0.989
[49,     3] loss: 0.916
[50,     3] loss: 1.004
[51,     3] loss: 0.973
[52,     3] loss: 0.900
[53,     3] loss: 1.004
[54,     3] loss: 0.980
[55,     3] loss: 0.927
[56,     3] loss: 0.988
[57,     3] loss: 0.854
[58,     3] loss: 0.892
[59,     3] loss: 0.913
[60,     3] loss: 0.879
[61,     3] loss: 0.902
[62,     3] loss: 0.818
[63,     3] loss: 0.822
[64,     3] loss: 0.830
[65,     3] loss: 0.785
[66,     3] loss: 0.791
[67,     3] loss: 0.776
[68,     3] loss: 0.795
[69,     3] loss: 0.800
[70,     3] loss: 0.768
[71,     3] loss: 0.807
[72,     3] loss: 0.781
[73,     3] loss: 0.795
[74,     3] loss: 0.793
[75,     3] loss: 0.846
[76,     3] loss: 0.865
[77,     3] loss: 0.863
[78,     3] loss: 0.861
[79,     3] loss: 0.861
[80,     3] loss: 0.917
[81,     3] loss: 0.866
[82,     3] loss: 0.846
[83,     3] loss: 0.851
[84,     3] loss: 0.819
[85,     3] loss: 0.801
[86,     3] loss: 0.906
[87,     3] loss: 0.805
[88,     3] loss: 0.793
[89,     3] loss: 0.830
[90,     3] loss: 0.793
[91,     3] loss: 0.770
[92,     3] loss: 0.779
[93,     3] loss: 0.766
[94,     3] loss: 0.797
Early stopping applied (best metric=0.5269759893417358)
Finished Training
Total time taken: 26.21540403366089
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.391
[3,     3] loss: 1.387
[4,     3] loss: 1.385
[5,     3] loss: 1.393
[6,     3] loss: 1.387
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.387
[10,     3] loss: 1.384
[11,     3] loss: 1.385
[12,     3] loss: 1.386
[13,     3] loss: 1.390
[14,     3] loss: 1.382
[15,     3] loss: 1.385
[16,     3] loss: 1.391
[17,     3] loss: 1.385
[18,     3] loss: 1.385
[19,     3] loss: 1.388
[20,     3] loss: 1.384
[21,     3] loss: 1.386
[22,     3] loss: 1.385
[23,     3] loss: 1.385
[24,     3] loss: 1.384
[25,     3] loss: 1.384
[26,     3] loss: 1.385
[27,     3] loss: 1.386
[28,     3] loss: 1.385
[29,     3] loss: 1.384
[30,     3] loss: 1.383
[31,     3] loss: 1.381
[32,     3] loss: 1.380
[33,     3] loss: 1.376
[34,     3] loss: 1.359
[35,     3] loss: 1.338
[36,     3] loss: 1.321
[37,     3] loss: 1.316
[38,     3] loss: 1.257
[39,     3] loss: 1.223
[40,     3] loss: 1.231
[41,     3] loss: 1.175
[42,     3] loss: 1.180
[43,     3] loss: 1.085
[44,     3] loss: 1.121
[45,     3] loss: 1.090
[46,     3] loss: 1.147
[47,     3] loss: 1.117
[48,     3] loss: 1.091
[49,     3] loss: 1.041
[50,     3] loss: 1.068
[51,     3] loss: 1.074
[52,     3] loss: 1.036
[53,     3] loss: 1.003
[54,     3] loss: 1.068
[55,     3] loss: 0.982
[56,     3] loss: 0.887
[57,     3] loss: 0.956
[58,     3] loss: 0.968
[59,     3] loss: 1.052
[60,     3] loss: 1.081
[61,     3] loss: 1.023
[62,     3] loss: 0.974
[63,     3] loss: 0.951
[64,     3] loss: 1.005
[65,     3] loss: 0.939
[66,     3] loss: 0.997
[67,     3] loss: 1.047
[68,     3] loss: 0.913
[69,     3] loss: 1.035
[70,     3] loss: 1.050
[71,     3] loss: 0.995
[72,     3] loss: 0.990
[73,     3] loss: 1.125
[74,     3] loss: 0.923
[75,     3] loss: 0.905
[76,     3] loss: 0.901
[77,     3] loss: 0.975
[78,     3] loss: 0.847
[79,     3] loss: 0.959
[80,     3] loss: 0.853
[81,     3] loss: 0.860
[82,     3] loss: 0.806
[83,     3] loss: 0.810
[84,     3] loss: 0.809
[85,     3] loss: 0.835
[86,     3] loss: 0.826
[87,     3] loss: 0.809
[88,     3] loss: 0.859
[89,     3] loss: 0.815
[90,     3] loss: 0.822
[91,     3] loss: 0.845
[92,     3] loss: 0.844
[93,     3] loss: 0.828
[94,     3] loss: 0.839
[95,     3] loss: 0.781
[96,     3] loss: 0.876
[97,     3] loss: 0.882
[98,     3] loss: 0.856
[99,     3] loss: 0.860
[100,     3] loss: 0.810
[101,     3] loss: 0.811
[102,     3] loss: 0.806
[103,     3] loss: 0.798
[104,     3] loss: 0.831
[105,     3] loss: 0.810
[106,     3] loss: 0.799
[107,     3] loss: 0.755
[108,     3] loss: 0.870
[109,     3] loss: 0.877
[110,     3] loss: 0.781
[111,     3] loss: 0.793
[112,     3] loss: 0.887
[113,     3] loss: 0.891
[114,     3] loss: 0.859
[115,     3] loss: 0.803
[116,     3] loss: 0.789
[117,     3] loss: 0.799
[118,     3] loss: 0.816
[119,     3] loss: 0.801
[120,     3] loss: 0.883
[121,     3] loss: 0.894
[122,     3] loss: 0.919
[123,     3] loss: 0.849
[124,     3] loss: 0.843
[125,     3] loss: 0.876
[126,     3] loss: 0.797
[127,     3] loss: 0.881
[128,     3] loss: 0.875
[129,     3] loss: 0.894
[130,     3] loss: 0.923
[131,     3] loss: 0.920
[132,     3] loss: 0.835
[133,     3] loss: 0.841
[134,     3] loss: 0.915
[135,     3] loss: 0.837
Early stopping applied (best metric=0.5485053062438965)
Finished Training
Total time taken: 37.86943769454956
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.391
[3,     3] loss: 1.399
[4,     3] loss: 1.389
[5,     3] loss: 1.383
[6,     3] loss: 1.392
[7,     3] loss: 1.390
[8,     3] loss: 1.386
[9,     3] loss: 1.390
[10,     3] loss: 1.386
[11,     3] loss: 1.385
[12,     3] loss: 1.387
[13,     3] loss: 1.384
[14,     3] loss: 1.385
[15,     3] loss: 1.385
[16,     3] loss: 1.389
[17,     3] loss: 1.385
[18,     3] loss: 1.385
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.385
[23,     3] loss: 1.387
[24,     3] loss: 1.384
[25,     3] loss: 1.388
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.387
[29,     3] loss: 1.386
[30,     3] loss: 1.384
[31,     3] loss: 1.384
[32,     3] loss: 1.386
[33,     3] loss: 1.388
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.385
[37,     3] loss: 1.384
[38,     3] loss: 1.384
[39,     3] loss: 1.383
[40,     3] loss: 1.380
[41,     3] loss: 1.375
[42,     3] loss: 1.356
[43,     3] loss: 1.337
[44,     3] loss: 1.319
[45,     3] loss: 1.221
[46,     3] loss: 1.180
[47,     3] loss: 1.239
[48,     3] loss: 1.204
[49,     3] loss: 1.156
[50,     3] loss: 1.106
[51,     3] loss: 1.060
[52,     3] loss: 1.139
[53,     3] loss: 1.077
[54,     3] loss: 1.014
[55,     3] loss: 1.039
[56,     3] loss: 1.050
[57,     3] loss: 1.173
[58,     3] loss: 1.120
[59,     3] loss: 1.023
[60,     3] loss: 1.129
[61,     3] loss: 1.036
[62,     3] loss: 1.026
[63,     3] loss: 0.960
[64,     3] loss: 0.960
[65,     3] loss: 1.010
[66,     3] loss: 0.910
[67,     3] loss: 0.969
[68,     3] loss: 1.036
[69,     3] loss: 1.010
[70,     3] loss: 0.960
[71,     3] loss: 0.912
[72,     3] loss: 0.960
[73,     3] loss: 0.979
[74,     3] loss: 0.898
[75,     3] loss: 0.904
[76,     3] loss: 0.887
[77,     3] loss: 0.864
[78,     3] loss: 0.860
[79,     3] loss: 0.798
[80,     3] loss: 0.863
[81,     3] loss: 0.805
[82,     3] loss: 0.841
[83,     3] loss: 0.930
[84,     3] loss: 0.860
[85,     3] loss: 0.909
[86,     3] loss: 0.887
[87,     3] loss: 0.864
[88,     3] loss: 0.889
[89,     3] loss: 0.881
[90,     3] loss: 0.871
[91,     3] loss: 0.897
[92,     3] loss: 0.840
[93,     3] loss: 0.950
[94,     3] loss: 0.858
[95,     3] loss: 0.858
[96,     3] loss: 0.828
[97,     3] loss: 0.836
[98,     3] loss: 0.827
[99,     3] loss: 0.827
[100,     3] loss: 0.809
[101,     3] loss: 0.819
[102,     3] loss: 0.805
[103,     3] loss: 0.784
[104,     3] loss: 0.817
[105,     3] loss: 0.766
[106,     3] loss: 0.842
[107,     3] loss: 0.788
[108,     3] loss: 0.817
[109,     3] loss: 0.800
[110,     3] loss: 0.804
[111,     3] loss: 0.760
[112,     3] loss: 0.776
[113,     3] loss: 0.791
[114,     3] loss: 0.757
[115,     3] loss: 0.840
[116,     3] loss: 0.795
[117,     3] loss: 0.780
[118,     3] loss: 0.875
[119,     3] loss: 0.907
[120,     3] loss: 0.769
[121,     3] loss: 0.795
[122,     3] loss: 0.773
[123,     3] loss: 0.812
[124,     3] loss: 0.793
[125,     3] loss: 0.896
[126,     3] loss: 0.748
[127,     3] loss: 0.763
[128,     3] loss: 0.784
[129,     3] loss: 0.769
[130,     3] loss: 0.766
[131,     3] loss: 0.745
[132,     3] loss: 0.842
[133,     3] loss: 0.783
[134,     3] loss: 0.810
[135,     3] loss: 0.792
[136,     3] loss: 0.758
[137,     3] loss: 0.768
[138,     3] loss: 0.805
[139,     3] loss: 0.742
[140,     3] loss: 0.783
[141,     3] loss: 0.842
[142,     3] loss: 0.785
[143,     3] loss: 0.755
[144,     3] loss: 0.766
[145,     3] loss: 0.761
[146,     3] loss: 0.750
[147,     3] loss: 0.749
[148,     3] loss: 0.757
[149,     3] loss: 0.829
[150,     3] loss: 0.746
[151,     3] loss: 0.753
[152,     3] loss: 0.757
[153,     3] loss: 0.841
[154,     3] loss: 0.780
[155,     3] loss: 0.792
[156,     3] loss: 0.781
[157,     3] loss: 0.869
[158,     3] loss: 0.829
[159,     3] loss: 0.797
[160,     3] loss: 0.778
[161,     3] loss: 0.858
[162,     3] loss: 0.931
[163,     3] loss: 0.797
[164,     3] loss: 0.773
[165,     3] loss: 0.797
[166,     3] loss: 0.788
[167,     3] loss: 0.782
[168,     3] loss: 0.787
[169,     3] loss: 0.778
[170,     3] loss: 0.798
[171,     3] loss: 0.778
[172,     3] loss: 0.826
[173,     3] loss: 0.780
[174,     3] loss: 0.801
[175,     3] loss: 0.766
[176,     3] loss: 0.778
[177,     3] loss: 0.776
[178,     3] loss: 0.814
[179,     3] loss: 0.770
[180,     3] loss: 0.773
[181,     3] loss: 0.764
[182,     3] loss: 0.770
[183,     3] loss: 0.760
[184,     3] loss: 0.764
[185,     3] loss: 0.778
[186,     3] loss: 0.757
[187,     3] loss: 0.764
[188,     3] loss: 0.819
[189,     3] loss: 0.826
[190,     3] loss: 0.777
[191,     3] loss: 0.752
[192,     3] loss: 0.766
[193,     3] loss: 0.752
[194,     3] loss: 0.768
[195,     3] loss: 0.776
[196,     3] loss: 0.732
[197,     3] loss: 0.729
[198,     3] loss: 0.729
[199,     3] loss: 0.737
[200,     3] loss: 0.732
Finished Training
Total time taken: 56.519484758377075
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.388
[3,     3] loss: 1.392
[4,     3] loss: 1.387
[5,     3] loss: 1.381
[6,     3] loss: 1.376
[7,     3] loss: 1.384
[8,     3] loss: 1.385
[9,     3] loss: 1.373
[10,     3] loss: 1.373
[11,     3] loss: 1.375
[12,     3] loss: 1.361
[13,     3] loss: 1.351
[14,     3] loss: 1.336
[15,     3] loss: 1.330
[16,     3] loss: 1.291
[17,     3] loss: 1.271
[18,     3] loss: 1.227
[19,     3] loss: 1.238
[20,     3] loss: 1.226
[21,     3] loss: 1.229
[22,     3] loss: 1.178
[23,     3] loss: 1.137
[24,     3] loss: 1.172
[25,     3] loss: 1.142
[26,     3] loss: 1.146
[27,     3] loss: 1.100
[28,     3] loss: 1.156
[29,     3] loss: 1.029
[30,     3] loss: 1.056
[31,     3] loss: 1.121
[32,     3] loss: 1.240
[33,     3] loss: 1.007
[34,     3] loss: 1.080
[35,     3] loss: 1.059
[36,     3] loss: 1.063
[37,     3] loss: 1.077
[38,     3] loss: 1.021
[39,     3] loss: 1.064
[40,     3] loss: 0.984
[41,     3] loss: 1.050
[42,     3] loss: 1.000
[43,     3] loss: 1.054
[44,     3] loss: 0.971
[45,     3] loss: 0.931
[46,     3] loss: 1.082
[47,     3] loss: 1.014
[48,     3] loss: 1.018
[49,     3] loss: 0.955
[50,     3] loss: 0.924
[51,     3] loss: 0.934
[52,     3] loss: 0.944
[53,     3] loss: 1.040
[54,     3] loss: 0.938
[55,     3] loss: 0.888
[56,     3] loss: 0.852
[57,     3] loss: 0.967
[58,     3] loss: 0.909
[59,     3] loss: 0.870
[60,     3] loss: 0.886
[61,     3] loss: 0.827
[62,     3] loss: 0.874
[63,     3] loss: 0.911
[64,     3] loss: 0.901
[65,     3] loss: 0.930
[66,     3] loss: 0.865
[67,     3] loss: 0.941
[68,     3] loss: 0.852
[69,     3] loss: 0.958
[70,     3] loss: 0.858
[71,     3] loss: 0.840
[72,     3] loss: 0.852
[73,     3] loss: 0.883
[74,     3] loss: 0.836
[75,     3] loss: 0.919
[76,     3] loss: 0.810
[77,     3] loss: 0.895
[78,     3] loss: 0.862
[79,     3] loss: 0.840
[80,     3] loss: 0.859
[81,     3] loss: 0.859
[82,     3] loss: 0.843
[83,     3] loss: 0.822
[84,     3] loss: 0.804
[85,     3] loss: 0.773
[86,     3] loss: 0.786
[87,     3] loss: 0.799
[88,     3] loss: 0.894
[89,     3] loss: 0.856
[90,     3] loss: 0.826
[91,     3] loss: 0.845
[92,     3] loss: 1.004
[93,     3] loss: 0.976
[94,     3] loss: 0.886
[95,     3] loss: 0.858
[96,     3] loss: 0.861
Early stopping applied (best metric=0.5090853571891785)
Finished Training
Total time taken: 27.141469478607178
{'S-palmitoylation-C Validation Accuracy': 0.6808108848938543, 'S-palmitoylation-C Validation Sensitivity': 0.23722772277227722, 'S-palmitoylation-C Validation Specificity': 0.791994582176214, 'S-palmitoylation-C Validation Precision': 0.23962270468380248, 'S-palmitoylation-C AUC ROC': 0.5364597147860545, 'S-palmitoylation-C AUC PR': 0.22557552634492825, 'S-palmitoylation-C MCC': 0.035720178850558795, 'S-palmitoylation-C F1': 0.2046951465630498, 'Validation Loss (S-palmitoylation-C)': 0.5543016870816548, 'Hydroxylation-K Validation Accuracy': 0.6768617021276596, 'Hydroxylation-K Validation Sensitivity': 0.737037037037037, 'Hydroxylation-K Validation Specificity': 0.6631578947368421, 'Hydroxylation-K Validation Precision': 0.4128942034075353, 'Hydroxylation-K AUC ROC': 0.7998245614035088, 'Hydroxylation-K AUC PR': 0.6004802361583454, 'Hydroxylation-K MCC': 0.352624701365146, 'Hydroxylation-K F1': 0.5044196947078035, 'Validation Loss (Hydroxylation-K)': 0.5253335038820902, 'Validation Loss (total)': 1.0796351750691733, 'TimeToTrain': 31.154780260721843}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005738573622197136,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.23607703762140556,
 'loss_weight_S-palmitoylation-C': 0.32014526461574994,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2784646194,
 'sample_weights': [0.25732094629578756, 0.5750689292658631],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.924438686655893,
 'weight_decay_Hydroxylation-K': 8.23514471401518,
 'weight_decay_S-palmitoylation-C': 4.9631635775332406}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.402
[3,     3] loss: 1.386
[4,     3] loss: 1.386
[5,     3] loss: 1.387
[6,     3] loss: 1.386
[7,     3] loss: 1.388
[8,     3] loss: 1.386
[9,     3] loss: 1.384
[10,     3] loss: 1.386
[11,     3] loss: 1.388
[12,     3] loss: 1.387
[13,     3] loss: 1.387
[14,     3] loss: 1.387
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.387
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.387
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.387
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.387
[43,     3] loss: 1.388
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.387
[49,     3] loss: 1.387
[50,     3] loss: 1.387
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.385
[55,     3] loss: 1.386
[56,     3] loss: 1.388
[57,     3] loss: 1.386
[58,     3] loss: 1.386
[59,     3] loss: 1.387
[60,     3] loss: 1.387
[61,     3] loss: 1.387
[62,     3] loss: 1.386
[63,     3] loss: 1.386
[64,     3] loss: 1.387
[65,     3] loss: 1.386
[66,     3] loss: 1.386
Early stopping applied (best metric=0.5628899335861206)
Finished Training
Total time taken: 18.608728647232056
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.386
[3,     3] loss: 1.387
[4,     3] loss: 1.385
[5,     3] loss: 1.398
[6,     3] loss: 1.388
[7,     3] loss: 1.388
[8,     3] loss: 1.387
[9,     3] loss: 1.388
[10,     3] loss: 1.388
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.387
[17,     3] loss: 1.388
[18,     3] loss: 1.387
[19,     3] loss: 1.387
[20,     3] loss: 1.387
[21,     3] loss: 1.387
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.387
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.387
[32,     3] loss: 1.387
[33,     3] loss: 1.386
[34,     3] loss: 1.387
[35,     3] loss: 1.386
[36,     3] loss: 1.387
[37,     3] loss: 1.386
[38,     3] loss: 1.387
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.387
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.387
[52,     3] loss: 1.386
Early stopping applied (best metric=0.5622775554656982)
Finished Training
Total time taken: 14.421151638031006
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.391
[3,     3] loss: 1.387
[4,     3] loss: 1.390
[5,     3] loss: 1.386
[6,     3] loss: 1.389
[7,     3] loss: 1.386
[8,     3] loss: 1.387
[9,     3] loss: 1.388
[10,     3] loss: 1.385
[11,     3] loss: 1.385
[12,     3] loss: 1.387
[13,     3] loss: 1.381
[14,     3] loss: 1.385
[15,     3] loss: 1.385
[16,     3] loss: 1.385
[17,     3] loss: 1.383
[18,     3] loss: 1.379
[19,     3] loss: 1.366
[20,     3] loss: 1.379
[21,     3] loss: 1.327
[22,     3] loss: 1.312
[23,     3] loss: 1.357
[24,     3] loss: 1.298
[25,     3] loss: 1.295
[26,     3] loss: 1.273
[27,     3] loss: 1.272
[28,     3] loss: 1.260
[29,     3] loss: 1.227
[30,     3] loss: 1.180
[31,     3] loss: 1.241
[32,     3] loss: 1.198
[33,     3] loss: 1.139
[34,     3] loss: 1.199
[35,     3] loss: 1.092
[36,     3] loss: 1.136
[37,     3] loss: 1.093
[38,     3] loss: 1.236
[39,     3] loss: 1.196
[40,     3] loss: 1.165
[41,     3] loss: 1.176
[42,     3] loss: 1.163
[43,     3] loss: 1.063
[44,     3] loss: 0.988
[45,     3] loss: 0.950
[46,     3] loss: 1.069
[47,     3] loss: 0.933
[48,     3] loss: 1.108
[49,     3] loss: 1.134
[50,     3] loss: 1.058
[51,     3] loss: 1.038
[52,     3] loss: 0.940
[53,     3] loss: 1.012
[54,     3] loss: 1.209
[55,     3] loss: 1.105
[56,     3] loss: 1.145
[57,     3] loss: 1.046
[58,     3] loss: 1.047
[59,     3] loss: 0.937
[60,     3] loss: 1.052
[61,     3] loss: 1.010
[62,     3] loss: 1.062
[63,     3] loss: 1.153
[64,     3] loss: 1.252
[65,     3] loss: 1.117
[66,     3] loss: 1.060
[67,     3] loss: 1.101
[68,     3] loss: 1.136
[69,     3] loss: 1.096
[70,     3] loss: 1.158
[71,     3] loss: 1.123
[72,     3] loss: 1.108
[73,     3] loss: 0.996
[74,     3] loss: 0.986
[75,     3] loss: 0.887
[76,     3] loss: 0.838
[77,     3] loss: 0.912
[78,     3] loss: 0.880
[79,     3] loss: 1.005
[80,     3] loss: 1.109
[81,     3] loss: 1.046
[82,     3] loss: 0.983
[83,     3] loss: 0.956
[84,     3] loss: 1.034
[85,     3] loss: 1.005
[86,     3] loss: 1.086
[87,     3] loss: 1.023
[88,     3] loss: 1.062
[89,     3] loss: 1.007
[90,     3] loss: 0.951
[91,     3] loss: 1.065
[92,     3] loss: 0.986
[93,     3] loss: 0.947
[94,     3] loss: 0.917
Early stopping applied (best metric=0.5446760654449463)
Finished Training
Total time taken: 26.036295175552368
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.390
[3,     3] loss: 1.386
[4,     3] loss: 1.387
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.385
[8,     3] loss: 1.385
[9,     3] loss: 1.387
[10,     3] loss: 1.386
[11,     3] loss: 1.385
[12,     3] loss: 1.387
[13,     3] loss: 1.388
[14,     3] loss: 1.386
[15,     3] loss: 1.389
[16,     3] loss: 1.386
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.387
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.387
[28,     3] loss: 1.388
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.387
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.387
[39,     3] loss: 1.386
[40,     3] loss: 1.387
[41,     3] loss: 1.387
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.387
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.385
[55,     3] loss: 1.388
[56,     3] loss: 1.387
[57,     3] loss: 1.386
[58,     3] loss: 1.386
[59,     3] loss: 1.387
[60,     3] loss: 1.387
[61,     3] loss: 1.385
[62,     3] loss: 1.386
[63,     3] loss: 1.387
[64,     3] loss: 1.387
[65,     3] loss: 1.386
[66,     3] loss: 1.386
[67,     3] loss: 1.387
[68,     3] loss: 1.386
[69,     3] loss: 1.386
[70,     3] loss: 1.386
[71,     3] loss: 1.386
[72,     3] loss: 1.386
[73,     3] loss: 1.386
[74,     3] loss: 1.386
[75,     3] loss: 1.387
[76,     3] loss: 1.387
[77,     3] loss: 1.387
[78,     3] loss: 1.386
[79,     3] loss: 1.386
[80,     3] loss: 1.386
[81,     3] loss: 1.386
[82,     3] loss: 1.386
[83,     3] loss: 1.386
[84,     3] loss: 1.387
[85,     3] loss: 1.387
[86,     3] loss: 1.387
[87,     3] loss: 1.386
[88,     3] loss: 1.386
[89,     3] loss: 1.386
[90,     3] loss: 1.387
[91,     3] loss: 1.386
[92,     3] loss: 1.386
[93,     3] loss: 1.386
[94,     3] loss: 1.386
[95,     3] loss: 1.386
[96,     3] loss: 1.387
[97,     3] loss: 1.386
Early stopping applied (best metric=0.5454508662223816)
Finished Training
Total time taken: 26.743576765060425
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.391
[3,     3] loss: 1.392
[4,     3] loss: 1.385
[5,     3] loss: 1.390
[6,     3] loss: 1.386
[7,     3] loss: 1.382
[8,     3] loss: 1.386
[9,     3] loss: 1.388
[10,     3] loss: 1.388
[11,     3] loss: 1.387
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.387
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.385
[19,     3] loss: 1.386
[20,     3] loss: 1.388
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.387
[24,     3] loss: 1.385
[25,     3] loss: 1.384
[26,     3] loss: 1.385
[27,     3] loss: 1.373
[28,     3] loss: 1.358
[29,     3] loss: 1.329
[30,     3] loss: 1.293
[31,     3] loss: 1.304
[32,     3] loss: 1.275
[33,     3] loss: 1.267
[34,     3] loss: 1.257
[35,     3] loss: 1.326
[36,     3] loss: 1.260
[37,     3] loss: 1.468
[38,     3] loss: 1.267
[39,     3] loss: 1.301
[40,     3] loss: 1.354
[41,     3] loss: 1.398
[42,     3] loss: 1.264
[43,     3] loss: 1.239
[44,     3] loss: 1.237
[45,     3] loss: 1.236
[46,     3] loss: 1.216
[47,     3] loss: 1.068
[48,     3] loss: 1.256
[49,     3] loss: 1.196
[50,     3] loss: 1.257
[51,     3] loss: 1.131
[52,     3] loss: 1.113
[53,     3] loss: 1.333
[54,     3] loss: 1.111
[55,     3] loss: 1.270
[56,     3] loss: 1.227
[57,     3] loss: 1.104
[58,     3] loss: 1.157
[59,     3] loss: 1.180
[60,     3] loss: 1.179
[61,     3] loss: 1.111
[62,     3] loss: 1.130
[63,     3] loss: 1.076
[64,     3] loss: 1.107
[65,     3] loss: 1.017
[66,     3] loss: 1.110
[67,     3] loss: 1.178
[68,     3] loss: 1.315
[69,     3] loss: 1.204
[70,     3] loss: 1.175
[71,     3] loss: 1.159
[72,     3] loss: 1.093
[73,     3] loss: 1.111
[74,     3] loss: 1.194
[75,     3] loss: 1.132
[76,     3] loss: 1.140
[77,     3] loss: 1.077
[78,     3] loss: 1.108
[79,     3] loss: 1.225
[80,     3] loss: 1.085
[81,     3] loss: 1.107
[82,     3] loss: 1.036
[83,     3] loss: 0.994
[84,     3] loss: 1.135
[85,     3] loss: 1.116
[86,     3] loss: 1.193
[87,     3] loss: 1.209
[88,     3] loss: 1.181
[89,     3] loss: 1.142
[90,     3] loss: 1.079
[91,     3] loss: 0.995
[92,     3] loss: 1.168
[93,     3] loss: 1.188
[94,     3] loss: 1.133
[95,     3] loss: 1.173
[96,     3] loss: 1.154
[97,     3] loss: 1.081
[98,     3] loss: 1.088
[99,     3] loss: 1.045
[100,     3] loss: 1.092
[101,     3] loss: 1.052
[102,     3] loss: 1.010
[103,     3] loss: 1.109
[104,     3] loss: 1.190
[105,     3] loss: 1.122
[106,     3] loss: 1.168
[107,     3] loss: 1.163
[108,     3] loss: 1.141
[109,     3] loss: 1.132
[110,     3] loss: 1.053
[111,     3] loss: 1.012
[112,     3] loss: 1.006
[113,     3] loss: 1.006
[114,     3] loss: 1.309
[115,     3] loss: 1.170
[116,     3] loss: 1.275
[117,     3] loss: 1.248
[118,     3] loss: 1.211
[119,     3] loss: 1.245
[120,     3] loss: 1.133
[121,     3] loss: 1.142
[122,     3] loss: 1.045
[123,     3] loss: 1.287
[124,     3] loss: 1.210
[125,     3] loss: 1.190
[126,     3] loss: 1.224
[127,     3] loss: 1.123
[128,     3] loss: 1.123
[129,     3] loss: 1.068
[130,     3] loss: 1.067
[131,     3] loss: 1.053
[132,     3] loss: 1.075
[133,     3] loss: 1.003
[134,     3] loss: 1.181
[135,     3] loss: 1.083
[136,     3] loss: 1.109
[137,     3] loss: 1.026
[138,     3] loss: 0.985
[139,     3] loss: 1.215
[140,     3] loss: 1.029
[141,     3] loss: 1.013
[142,     3] loss: 1.038
[143,     3] loss: 1.153
[144,     3] loss: 1.109
[145,     3] loss: 1.113
[146,     3] loss: 1.057
[147,     3] loss: 0.967
[148,     3] loss: 1.243
[149,     3] loss: 1.122
[150,     3] loss: 1.211
[151,     3] loss: 1.253
[152,     3] loss: 1.240
[153,     3] loss: 1.208
[154,     3] loss: 1.232
[155,     3] loss: 1.298
[156,     3] loss: 1.152
[157,     3] loss: 1.157
[158,     3] loss: 1.093
[159,     3] loss: 1.126
[160,     3] loss: 0.990
[161,     3] loss: 1.164
[162,     3] loss: 1.063
[163,     3] loss: 1.016
[164,     3] loss: 1.116
[165,     3] loss: 1.032
[166,     3] loss: 1.080
[167,     3] loss: 1.246
[168,     3] loss: 1.095
[169,     3] loss: 1.195
[170,     3] loss: 1.191
[171,     3] loss: 1.107
[172,     3] loss: 1.049
[173,     3] loss: 1.002
[174,     3] loss: 1.112
[175,     3] loss: 1.104
[176,     3] loss: 1.037
[177,     3] loss: 1.043
Early stopping applied (best metric=0.48717278242111206)
Finished Training
Total time taken: 49.977020502090454
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.388
[3,     3] loss: 1.391
[4,     3] loss: 1.382
[5,     3] loss: 1.391
[6,     3] loss: 1.388
[7,     3] loss: 1.386
[8,     3] loss: 1.387
[9,     3] loss: 1.386
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.385
[16,     3] loss: 1.388
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.387
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.385
[26,     3] loss: 1.383
[27,     3] loss: 1.379
[28,     3] loss: 1.330
[29,     3] loss: 1.321
[30,     3] loss: 1.284
[31,     3] loss: 1.253
[32,     3] loss: 1.287
[33,     3] loss: 1.200
[34,     3] loss: 1.270
[35,     3] loss: 1.373
[36,     3] loss: 1.329
[37,     3] loss: 1.285
[38,     3] loss: 1.268
[39,     3] loss: 1.294
[40,     3] loss: 1.239
[41,     3] loss: 1.196
[42,     3] loss: 1.172
[43,     3] loss: 1.273
[44,     3] loss: 1.180
[45,     3] loss: 1.165
[46,     3] loss: 1.181
[47,     3] loss: 1.242
[48,     3] loss: 1.161
[49,     3] loss: 1.155
[50,     3] loss: 1.103
[51,     3] loss: 1.153
[52,     3] loss: 1.210
[53,     3] loss: 1.227
[54,     3] loss: 1.172
[55,     3] loss: 1.168
[56,     3] loss: 1.149
[57,     3] loss: 1.035
[58,     3] loss: 1.103
[59,     3] loss: 1.087
[60,     3] loss: 1.032
[61,     3] loss: 1.069
[62,     3] loss: 1.031
[63,     3] loss: 0.974
[64,     3] loss: 1.184
[65,     3] loss: 1.169
[66,     3] loss: 1.215
[67,     3] loss: 1.136
[68,     3] loss: 1.182
[69,     3] loss: 1.141
[70,     3] loss: 1.050
[71,     3] loss: 1.027
[72,     3] loss: 0.968
[73,     3] loss: 1.419
[74,     3] loss: 1.199
[75,     3] loss: 1.185
[76,     3] loss: 1.174
[77,     3] loss: 1.185
[78,     3] loss: 1.117
[79,     3] loss: 1.077
[80,     3] loss: 1.086
[81,     3] loss: 1.098
[82,     3] loss: 1.058
[83,     3] loss: 1.016
[84,     3] loss: 1.188
[85,     3] loss: 1.107
[86,     3] loss: 1.137
[87,     3] loss: 1.033
[88,     3] loss: 1.084
[89,     3] loss: 1.035
[90,     3] loss: 1.039
[91,     3] loss: 1.028
[92,     3] loss: 1.025
Early stopping applied (best metric=0.5350664854049683)
Finished Training
Total time taken: 25.827282667160034
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.394
[3,     3] loss: 1.389
[4,     3] loss: 1.386
[5,     3] loss: 1.390
[6,     3] loss: 1.385
[7,     3] loss: 1.386
[8,     3] loss: 1.385
[9,     3] loss: 1.387
[10,     3] loss: 1.388
[11,     3] loss: 1.388
[12,     3] loss: 1.385
[13,     3] loss: 1.387
[14,     3] loss: 1.388
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.383
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.387
[25,     3] loss: 1.384
[26,     3] loss: 1.386
[27,     3] loss: 1.384
[28,     3] loss: 1.384
[29,     3] loss: 1.383
[30,     3] loss: 1.390
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.387
[34,     3] loss: 1.389
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.387
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.387
[44,     3] loss: 1.387
[45,     3] loss: 1.386
[46,     3] loss: 1.385
[47,     3] loss: 1.386
[48,     3] loss: 1.387
[49,     3] loss: 1.386
[50,     3] loss: 1.385
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.385
Early stopping applied (best metric=0.5630992650985718)
Finished Training
Total time taken: 15.060157775878906
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.387
[3,     3] loss: 1.383
[4,     3] loss: 1.383
[5,     3] loss: 1.377
[6,     3] loss: 1.389
[7,     3] loss: 1.385
[8,     3] loss: 1.387
[9,     3] loss: 1.389
[10,     3] loss: 1.390
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.385
[21,     3] loss: 1.388
[22,     3] loss: 1.386
[23,     3] loss: 1.382
[24,     3] loss: 1.377
[25,     3] loss: 1.361
[26,     3] loss: 1.354
[27,     3] loss: 1.254
[28,     3] loss: 1.265
[29,     3] loss: 1.225
[30,     3] loss: 1.243
[31,     3] loss: 1.191
[32,     3] loss: 1.127
[33,     3] loss: 1.116
[34,     3] loss: 1.055
[35,     3] loss: 1.141
[36,     3] loss: 1.168
[37,     3] loss: 1.066
[38,     3] loss: 1.017
[39,     3] loss: 1.013
[40,     3] loss: 1.280
[41,     3] loss: 1.251
[42,     3] loss: 1.181
[43,     3] loss: 1.218
[44,     3] loss: 1.077
[45,     3] loss: 1.027
[46,     3] loss: 1.126
[47,     3] loss: 1.071
[48,     3] loss: 1.128
[49,     3] loss: 1.005
[50,     3] loss: 0.963
[51,     3] loss: 0.947
[52,     3] loss: 1.635
[53,     3] loss: 1.301
[54,     3] loss: 1.376
[55,     3] loss: 1.361
[56,     3] loss: 1.362
[57,     3] loss: 1.364
[58,     3] loss: 1.338
[59,     3] loss: 1.320
[60,     3] loss: 1.265
[61,     3] loss: 1.234
[62,     3] loss: 1.181
[63,     3] loss: 1.206
[64,     3] loss: 1.193
[65,     3] loss: 1.207
[66,     3] loss: 1.193
[67,     3] loss: 1.198
[68,     3] loss: 1.201
[69,     3] loss: 1.153
[70,     3] loss: 1.275
[71,     3] loss: 1.158
[72,     3] loss: 1.206
[73,     3] loss: 1.167
[74,     3] loss: 1.092
[75,     3] loss: 1.070
[76,     3] loss: 1.149
[77,     3] loss: 1.122
[78,     3] loss: 1.153
[79,     3] loss: 1.331
[80,     3] loss: 1.255
[81,     3] loss: 1.191
[82,     3] loss: 1.178
[83,     3] loss: 1.150
[84,     3] loss: 1.190
[85,     3] loss: 1.176
Early stopping applied (best metric=0.5486040115356445)
Finished Training
Total time taken: 23.822785139083862
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.388
[3,     3] loss: 1.385
[4,     3] loss: 1.397
[5,     3] loss: 1.384
[6,     3] loss: 1.389
[7,     3] loss: 1.385
[8,     3] loss: 1.389
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.385
[15,     3] loss: 1.385
[16,     3] loss: 1.386
[17,     3] loss: 1.384
[18,     3] loss: 1.383
[19,     3] loss: 1.374
[20,     3] loss: 1.323
[21,     3] loss: 1.392
[22,     3] loss: 1.214
[23,     3] loss: 1.294
[24,     3] loss: 1.194
[25,     3] loss: 1.283
[26,     3] loss: 1.346
[27,     3] loss: 1.268
[28,     3] loss: 1.210
[29,     3] loss: 1.192
[30,     3] loss: 1.214
[31,     3] loss: 1.119
[32,     3] loss: 1.145
[33,     3] loss: 1.109
[34,     3] loss: 1.171
[35,     3] loss: 1.201
[36,     3] loss: 1.157
[37,     3] loss: 1.094
[38,     3] loss: 1.025
[39,     3] loss: 1.301
[40,     3] loss: 1.149
[41,     3] loss: 1.252
[42,     3] loss: 1.254
[43,     3] loss: 1.260
[44,     3] loss: 1.157
[45,     3] loss: 1.111
[46,     3] loss: 1.121
[47,     3] loss: 1.123
[48,     3] loss: 1.119
[49,     3] loss: 1.176
[50,     3] loss: 1.071
[51,     3] loss: 1.032
[52,     3] loss: 1.040
[53,     3] loss: 1.032
[54,     3] loss: 1.184
[55,     3] loss: 1.037
[56,     3] loss: 1.026
[57,     3] loss: 1.068
[58,     3] loss: 0.991
[59,     3] loss: 1.177
[60,     3] loss: 1.064
[61,     3] loss: 1.055
[62,     3] loss: 1.249
[63,     3] loss: 1.130
[64,     3] loss: 1.109
[65,     3] loss: 1.129
[66,     3] loss: 1.033
[67,     3] loss: 1.074
[68,     3] loss: 0.923
[69,     3] loss: 0.920
[70,     3] loss: 1.082
[71,     3] loss: 1.323
[72,     3] loss: 1.278
[73,     3] loss: 1.224
[74,     3] loss: 1.239
[75,     3] loss: 1.217
[76,     3] loss: 1.110
[77,     3] loss: 1.233
[78,     3] loss: 1.183
[79,     3] loss: 1.151
[80,     3] loss: 1.155
[81,     3] loss: 1.141
[82,     3] loss: 1.149
[83,     3] loss: 1.067
[84,     3] loss: 1.078
[85,     3] loss: 1.073
[86,     3] loss: 1.113
[87,     3] loss: 1.209
[88,     3] loss: 1.120
[89,     3] loss: 1.142
[90,     3] loss: 1.073
[91,     3] loss: 1.085
[92,     3] loss: 1.095
[93,     3] loss: 1.052
[94,     3] loss: 1.090
Early stopping applied (best metric=0.5166280269622803)
Finished Training
Total time taken: 26.537748098373413
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.385
[3,     3] loss: 1.393
[4,     3] loss: 1.389
[5,     3] loss: 1.386
[6,     3] loss: 1.386
[7,     3] loss: 1.383
[8,     3] loss: 1.383
[9,     3] loss: 1.395
[10,     3] loss: 1.386
[11,     3] loss: 1.385
[12,     3] loss: 1.386
[13,     3] loss: 1.385
[14,     3] loss: 1.387
[15,     3] loss: 1.386
[16,     3] loss: 1.385
[17,     3] loss: 1.383
[18,     3] loss: 1.380
[19,     3] loss: 1.359
[20,     3] loss: 1.321
[21,     3] loss: 1.304
[22,     3] loss: 1.244
[23,     3] loss: 1.291
[24,     3] loss: 1.244
[25,     3] loss: 1.131
[26,     3] loss: 1.166
[27,     3] loss: 1.184
[28,     3] loss: 1.196
[29,     3] loss: 1.238
[30,     3] loss: 1.207
[31,     3] loss: 1.220
[32,     3] loss: 1.043
[33,     3] loss: 1.016
[34,     3] loss: 1.131
[35,     3] loss: 1.208
[36,     3] loss: 1.245
[37,     3] loss: 1.177
[38,     3] loss: 1.142
[39,     3] loss: 1.002
[40,     3] loss: 1.030
[41,     3] loss: 1.025
[42,     3] loss: 1.054
[43,     3] loss: 1.082
[44,     3] loss: 1.090
[45,     3] loss: 1.117
[46,     3] loss: 1.087
[47,     3] loss: 1.090
[48,     3] loss: 1.130
[49,     3] loss: 1.053
[50,     3] loss: 1.104
[51,     3] loss: 0.994
[52,     3] loss: 1.083
[53,     3] loss: 1.039
[54,     3] loss: 1.068
[55,     3] loss: 1.031
[56,     3] loss: 1.076
[57,     3] loss: 1.006
[58,     3] loss: 0.920
[59,     3] loss: 1.072
[60,     3] loss: 0.941
[61,     3] loss: 1.053
[62,     3] loss: 1.017
[63,     3] loss: 1.014
[64,     3] loss: 1.125
[65,     3] loss: 1.074
[66,     3] loss: 1.023
[67,     3] loss: 1.019
[68,     3] loss: 1.192
[69,     3] loss: 1.248
[70,     3] loss: 1.220
[71,     3] loss: 1.256
[72,     3] loss: 1.266
[73,     3] loss: 1.223
[74,     3] loss: 1.147
[75,     3] loss: 1.194
[76,     3] loss: 1.115
[77,     3] loss: 1.124
[78,     3] loss: 1.634
[79,     3] loss: 1.208
[80,     3] loss: 1.248
[81,     3] loss: 1.158
[82,     3] loss: 1.284
[83,     3] loss: 1.295
[84,     3] loss: 1.211
[85,     3] loss: 1.243
[86,     3] loss: 1.222
[87,     3] loss: 1.197
[88,     3] loss: 1.132
[89,     3] loss: 1.149
[90,     3] loss: 1.188
[91,     3] loss: 1.177
[92,     3] loss: 1.163
[93,     3] loss: 1.179
[94,     3] loss: 1.137
[95,     3] loss: 1.105
[96,     3] loss: 1.203
[97,     3] loss: 1.239
[98,     3] loss: 1.175
[99,     3] loss: 1.110
[100,     3] loss: 1.060
[101,     3] loss: 1.128
[102,     3] loss: 1.139
[103,     3] loss: 1.043
[104,     3] loss: 1.093
[105,     3] loss: 1.096
[106,     3] loss: 1.225
[107,     3] loss: 1.299
[108,     3] loss: 1.242
[109,     3] loss: 1.187
[110,     3] loss: 1.160
[111,     3] loss: 1.013
[112,     3] loss: 1.050
[113,     3] loss: 1.080
[114,     3] loss: 1.078
[115,     3] loss: 1.032
[116,     3] loss: 0.970
[117,     3] loss: 1.448
[118,     3] loss: 1.144
[119,     3] loss: 1.133
[120,     3] loss: 1.118
[121,     3] loss: 1.096
[122,     3] loss: 1.249
[123,     3] loss: 1.138
[124,     3] loss: 1.162
Early stopping applied (best metric=0.5153806209564209)
Finished Training
Total time taken: 35.25189232826233
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.389
[3,     3] loss: 1.386
[4,     3] loss: 1.379
[5,     3] loss: 1.385
[6,     3] loss: 1.390
[7,     3] loss: 1.390
[8,     3] loss: 1.388
[9,     3] loss: 1.383
[10,     3] loss: 1.383
[11,     3] loss: 1.383
[12,     3] loss: 1.379
[13,     3] loss: 1.362
[14,     3] loss: 1.339
[15,     3] loss: 1.266
[16,     3] loss: 1.223
[17,     3] loss: 1.118
[18,     3] loss: 1.192
[19,     3] loss: 1.128
[20,     3] loss: 1.092
[21,     3] loss: 1.149
[22,     3] loss: 1.097
[23,     3] loss: 0.973
[24,     3] loss: 0.969
[25,     3] loss: 0.984
[26,     3] loss: 1.007
[27,     3] loss: 0.995
[28,     3] loss: 1.040
[29,     3] loss: 1.025
[30,     3] loss: 0.998
[31,     3] loss: 0.987
[32,     3] loss: 1.083
[33,     3] loss: 1.047
[34,     3] loss: 1.025
[35,     3] loss: 1.055
[36,     3] loss: 1.041
[37,     3] loss: 0.971
[38,     3] loss: 0.972
[39,     3] loss: 0.960
[40,     3] loss: 1.040
[41,     3] loss: 0.963
[42,     3] loss: 0.915
[43,     3] loss: 0.911
[44,     3] loss: 0.848
[45,     3] loss: 0.981
[46,     3] loss: 1.192
[47,     3] loss: 0.968
[48,     3] loss: 1.013
[49,     3] loss: 1.039
[50,     3] loss: 1.022
[51,     3] loss: 0.924
[52,     3] loss: 0.963
[53,     3] loss: 1.104
[54,     3] loss: 1.103
[55,     3] loss: 1.057
[56,     3] loss: 1.043
[57,     3] loss: 1.061
[58,     3] loss: 1.015
[59,     3] loss: 0.996
[60,     3] loss: 0.990
[61,     3] loss: 0.992
[62,     3] loss: 1.013
[63,     3] loss: 1.040
[64,     3] loss: 1.007
[65,     3] loss: 0.981
[66,     3] loss: 0.975
[67,     3] loss: 0.843
[68,     3] loss: 0.896
Early stopping applied (best metric=0.5533661246299744)
Finished Training
Total time taken: 19.449506998062134
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.384
[4,     3] loss: 1.383
[5,     3] loss: 1.384
[6,     3] loss: 1.392
[7,     3] loss: 1.384
[8,     3] loss: 1.389
[9,     3] loss: 1.387
[10,     3] loss: 1.387
[11,     3] loss: 1.387
[12,     3] loss: 1.385
[13,     3] loss: 1.386
[14,     3] loss: 1.385
[15,     3] loss: 1.385
[16,     3] loss: 1.388
[17,     3] loss: 1.384
[18,     3] loss: 1.387
[19,     3] loss: 1.382
[20,     3] loss: 1.369
[21,     3] loss: 1.327
[22,     3] loss: 1.301
[23,     3] loss: 1.325
[24,     3] loss: 1.370
[25,     3] loss: 1.349
[26,     3] loss: 1.290
[27,     3] loss: 1.213
[28,     3] loss: 1.281
[29,     3] loss: 1.199
[30,     3] loss: 1.212
[31,     3] loss: 1.189
[32,     3] loss: 1.135
[33,     3] loss: 1.009
[34,     3] loss: 1.171
[35,     3] loss: 1.116
[36,     3] loss: 1.076
[37,     3] loss: 1.046
[38,     3] loss: 0.991
[39,     3] loss: 1.106
[40,     3] loss: 1.023
[41,     3] loss: 1.027
[42,     3] loss: 1.044
[43,     3] loss: 1.119
[44,     3] loss: 1.090
[45,     3] loss: 1.115
[46,     3] loss: 1.094
[47,     3] loss: 1.116
[48,     3] loss: 1.038
[49,     3] loss: 0.985
[50,     3] loss: 0.947
[51,     3] loss: 0.998
[52,     3] loss: 0.997
[53,     3] loss: 0.996
[54,     3] loss: 1.088
[55,     3] loss: 0.965
[56,     3] loss: 1.050
[57,     3] loss: 1.477
[58,     3] loss: 1.276
[59,     3] loss: 1.246
[60,     3] loss: 1.297
[61,     3] loss: 1.224
[62,     3] loss: 1.189
[63,     3] loss: 1.228
[64,     3] loss: 1.166
[65,     3] loss: 1.203
[66,     3] loss: 1.256
[67,     3] loss: 1.072
[68,     3] loss: 1.047
[69,     3] loss: 1.312
[70,     3] loss: 1.134
[71,     3] loss: 1.124
[72,     3] loss: 1.074
[73,     3] loss: 1.309
[74,     3] loss: 1.315
[75,     3] loss: 1.260
[76,     3] loss: 1.218
[77,     3] loss: 1.192
[78,     3] loss: 1.149
[79,     3] loss: 1.094
[80,     3] loss: 1.215
[81,     3] loss: 1.175
[82,     3] loss: 1.070
[83,     3] loss: 1.117
[84,     3] loss: 1.030
[85,     3] loss: 1.030
[86,     3] loss: 1.218
[87,     3] loss: 1.386
[88,     3] loss: 1.228
[89,     3] loss: 1.267
[90,     3] loss: 1.309
[91,     3] loss: 1.234
[92,     3] loss: 1.218
[93,     3] loss: 1.288
[94,     3] loss: 1.198
[95,     3] loss: 1.209
[96,     3] loss: 1.134
[97,     3] loss: 1.040
[98,     3] loss: 1.181
[99,     3] loss: 1.154
Early stopping applied (best metric=0.5295761823654175)
Finished Training
Total time taken: 29.239980459213257
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.401
[2,     3] loss: 1.383
[3,     3] loss: 1.381
[4,     3] loss: 1.384
[5,     3] loss: 1.386
[6,     3] loss: 1.386
[7,     3] loss: 1.389
[8,     3] loss: 1.389
[9,     3] loss: 1.386
[10,     3] loss: 1.386
[11,     3] loss: 1.387
[12,     3] loss: 1.385
[13,     3] loss: 1.388
[14,     3] loss: 1.385
[15,     3] loss: 1.385
[16,     3] loss: 1.386
[17,     3] loss: 1.388
[18,     3] loss: 1.386
[19,     3] loss: 1.385
[20,     3] loss: 1.382
[21,     3] loss: 1.350
[22,     3] loss: 1.303
[23,     3] loss: 1.245
[24,     3] loss: 1.319
[25,     3] loss: 1.287
[26,     3] loss: 1.258
[27,     3] loss: 1.322
[28,     3] loss: 1.311
[29,     3] loss: 1.219
[30,     3] loss: 1.192
[31,     3] loss: 1.109
[32,     3] loss: 1.089
[33,     3] loss: 1.142
[34,     3] loss: 1.121
[35,     3] loss: 1.108
[36,     3] loss: 1.089
[37,     3] loss: 1.054
[38,     3] loss: 1.065
[39,     3] loss: 1.078
[40,     3] loss: 1.006
[41,     3] loss: 0.912
[42,     3] loss: 1.056
[43,     3] loss: 1.395
[44,     3] loss: 1.263
[45,     3] loss: 1.292
[46,     3] loss: 1.268
[47,     3] loss: 1.240
[48,     3] loss: 1.191
[49,     3] loss: 1.099
[50,     3] loss: 1.139
[51,     3] loss: 1.120
[52,     3] loss: 1.205
[53,     3] loss: 1.211
[54,     3] loss: 1.252
[55,     3] loss: 1.218
[56,     3] loss: 1.287
[57,     3] loss: 1.261
[58,     3] loss: 1.146
[59,     3] loss: 1.078
[60,     3] loss: 1.003
[61,     3] loss: 1.047
[62,     3] loss: 1.001
[63,     3] loss: 0.999
[64,     3] loss: 0.926
[65,     3] loss: 0.917
[66,     3] loss: 0.951
[67,     3] loss: 1.218
[68,     3] loss: 1.242
[69,     3] loss: 1.174
[70,     3] loss: 1.158
[71,     3] loss: 1.234
[72,     3] loss: 1.223
[73,     3] loss: 1.119
[74,     3] loss: 1.084
[75,     3] loss: 1.022
[76,     3] loss: 0.980
[77,     3] loss: 1.182
[78,     3] loss: 1.138
[79,     3] loss: 1.114
[80,     3] loss: 1.136
[81,     3] loss: 1.090
[82,     3] loss: 1.049
[83,     3] loss: 0.967
[84,     3] loss: 0.975
[85,     3] loss: 1.378
[86,     3] loss: 1.232
[87,     3] loss: 1.241
[88,     3] loss: 1.213
[89,     3] loss: 1.164
[90,     3] loss: 1.188
[91,     3] loss: 1.143
Early stopping applied (best metric=0.5520908236503601)
Finished Training
Total time taken: 26.416968822479248
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.404
[3,     3] loss: 1.386
[4,     3] loss: 1.382
[5,     3] loss: 1.388
[6,     3] loss: 1.384
[7,     3] loss: 1.392
[8,     3] loss: 1.388
[9,     3] loss: 1.384
[10,     3] loss: 1.386
[11,     3] loss: 1.384
[12,     3] loss: 1.386
[13,     3] loss: 1.384
[14,     3] loss: 1.389
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.387
[24,     3] loss: 1.387
[25,     3] loss: 1.386
[26,     3] loss: 1.387
[27,     3] loss: 1.387
[28,     3] loss: 1.387
[29,     3] loss: 1.387
[30,     3] loss: 1.386
[31,     3] loss: 1.387
[32,     3] loss: 1.387
[33,     3] loss: 1.387
[34,     3] loss: 1.387
[35,     3] loss: 1.387
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.387
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.387
[44,     3] loss: 1.387
[45,     3] loss: 1.387
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.387
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.386
[56,     3] loss: 1.386
[57,     3] loss: 1.387
[58,     3] loss: 1.386
[59,     3] loss: 1.386
[60,     3] loss: 1.386
[61,     3] loss: 1.386
[62,     3] loss: 1.387
[63,     3] loss: 1.386
Early stopping applied (best metric=0.545098066329956)
Finished Training
Total time taken: 18.240519762039185
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.376
[3,     3] loss: 1.403
[4,     3] loss: 1.386
[5,     3] loss: 1.387
[6,     3] loss: 1.390
[7,     3] loss: 1.386
[8,     3] loss: 1.388
[9,     3] loss: 1.386
[10,     3] loss: 1.387
[11,     3] loss: 1.385
[12,     3] loss: 1.389
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.388
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.387
[22,     3] loss: 1.386
[23,     3] loss: 1.387
[24,     3] loss: 1.387
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.387
[30,     3] loss: 1.385
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.387
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.387
[37,     3] loss: 1.386
[38,     3] loss: 1.387
[39,     3] loss: 1.385
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.387
[43,     3] loss: 1.385
[44,     3] loss: 1.386
[45,     3] loss: 1.387
[46,     3] loss: 1.385
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.387
[50,     3] loss: 1.387
[51,     3] loss: 1.387
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.385
[55,     3] loss: 1.389
[56,     3] loss: 1.386
[57,     3] loss: 1.386
[58,     3] loss: 1.389
[59,     3] loss: 1.387
[60,     3] loss: 1.386
[61,     3] loss: 1.386
[62,     3] loss: 1.386
[63,     3] loss: 1.386
Early stopping applied (best metric=0.5452591776847839)
Finished Training
Total time taken: 19.102298259735107
{'S-palmitoylation-C Validation Accuracy': 0.5431549745741886, 'S-palmitoylation-C Validation Sensitivity': 0.44765676567656765, 'S-palmitoylation-C Validation Specificity': 0.5670717056699054, 'S-palmitoylation-C Validation Precision': nan, 'S-palmitoylation-C AUC ROC': 0.5335470744824229, 'S-palmitoylation-C AUC PR': 0.24676677580307602, 'S-palmitoylation-C MCC': 0.015786300503623948, 'S-palmitoylation-C F1': 0.21066250236445236, 'Validation Loss (S-palmitoylation-C)': 0.554643698533376, 'Hydroxylation-K Validation Accuracy': 0.5504137115839244, 'Hydroxylation-K Validation Sensitivity': 0.6503703703703704, 'Hydroxylation-K Validation Specificity': 0.5298245614035088, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.7385769980506822, 'Hydroxylation-K AUC PR': 0.5143345705433736, 'Hydroxylation-K MCC': 0.1602309509674354, 'Hydroxylation-K F1': 0.33707186228662334, 'Validation Loss (Hydroxylation-K)': 0.5404423991839091, 'Validation Loss (total)': 1.0950860977172852, 'TimeToTrain': 24.982394202550253}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028904504250639234,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4777331967825346,
 'loss_weight_S-palmitoylation-C': 0.6179113472982104,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3888685500,
 'sample_weights': [0.32014526461574994, 0.23607703762140556],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5936996347463706,
 'weight_decay_Hydroxylation-K': 0.728521234513746,
 'weight_decay_S-palmitoylation-C': 5.382211440936611}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.380
[3,     3] loss: 1.396
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006117776923513213,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5631044652982103,
 'loss_weight_S-palmitoylation-C': 0.7029429229931704,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1248385567,
 'sample_weights': [0.6179113472982104, 0.4777331967825346],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6566298560504003,
 'weight_decay_Hydroxylation-K': 6.3564334393648725,
 'weight_decay_S-palmitoylation-C': 5.46829755253323}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.396
[3,     3] loss: 1.394
[4,     3] loss: 1.390
[5,     3] loss: 1.386
[6,     3] loss: 1.386
[7,     3] loss: 1.388
[8,     3] loss: 1.387
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017386606376221234,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.18591148664051582,
 'loss_weight_S-palmitoylation-C': 0.6389214654063886,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4150745935,
 'sample_weights': [0.7029429229931704, 0.5631044652982103],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.087692245981337,
 'weight_decay_Hydroxylation-K': 1.888164294334258,
 'weight_decay_S-palmitoylation-C': 8.400417229703045}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.395
[3,     3] loss: 1.389
[4,     3] loss: 1.381
[5,     3] loss: 1.384
[6,     3] loss: 1.393
[7,     3] loss: 1.382
[8,     3] loss: 1.385
[9,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00030326082247615394,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4934386071831605,
 'loss_weight_S-palmitoylation-C': 0.08655581844622551,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 90963926,
 'sample_weights': [0.6389214654063886, 0.18591148664051582],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.1486276239831685,
 'weight_decay_Hydroxylation-K': 2.3847130705192665,
 'weight_decay_S-palmitoylation-C': 1.457143679250763}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.389
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009597813563952437,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8319828763374238,
 'loss_weight_S-palmitoylation-C': 0.3884441586227426,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 578432983,
 'sample_weights': [0.08655581844622551, 0.4934386071831605],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.165884834654847,
 'weight_decay_Hydroxylation-K': 9.669036417818056,
 'weight_decay_S-palmitoylation-C': 0.5767408496743309}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.397
[3,     3] loss: 1.388
[4,     3] loss: 1.390
[5,     3] loss: 1.387
[6,     3] loss: 1.386
[7,     3] loss: 1.388
[8,     3] loss: 1.387
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00011787670360399962,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4205529070789664,
 'loss_weight_S-palmitoylation-C': 0.011008516794215776,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 451145452,
 'sample_weights': [0.3884441586227426, 0.8319828763374238],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.743132501056844,
 'weight_decay_Hydroxylation-K': 9.032402179341513,
 'weight_decay_S-palmitoylation-C': 5.676022090928096}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.381
[3,     3] loss: 1.373
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00925276005789607,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.018590793422965407,
 'loss_weight_S-palmitoylation-C': 0.8544274902440503,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 368830497,
 'sample_weights': [0.011008516794215776, 0.4205529070789664],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.59237600482508,
 'weight_decay_Hydroxylation-K': 4.12099707474214,
 'weight_decay_S-palmitoylation-C': 2.3097084664712977}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.400
[3,     3] loss: 1.393
[4,     3] loss: 1.390
[5,     3] loss: 1.391
[6,     3] loss: 1.388
[7,     3] loss: 1.385
[8,     3] loss: 1.391
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013186645477962105,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6105898348756595,
 'loss_weight_S-palmitoylation-C': 0.11639557704118725,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 252222988,
 'sample_weights': [0.8544274902440503, 0.018590793422965407],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.3750444511987885,
 'weight_decay_Hydroxylation-K': 2.7397476139642905,
 'weight_decay_S-palmitoylation-C': 9.282117049053037}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.386
[3,     3] loss: 1.382
[4,     3] loss: 1.379
[5,     3] loss: 1.382
[6,     3] loss: 1.383
[7,     3] loss: 1.394
[8,     3] loss: 1.378
[9,     3] loss: 1.368
[10,     3] loss: 1.366
[11,     3] loss: 1.366
[12,     3] loss: 1.349
[13,     3] loss: 1.325
[14,     3] loss: 1.364
[15,     3] loss: 1.280
[16,     3] loss: 1.248
[17,     3] loss: 1.315
[18,     3] loss: 1.207
[19,     3] loss: 1.189
[20,     3] loss: 1.120
[21,     3] loss: 1.070
[22,     3] loss: 1.003
[23,     3] loss: 1.054
[24,     3] loss: 1.142
[25,     3] loss: 1.114
[26,     3] loss: 1.097
[27,     3] loss: 0.980
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00580181290528123,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3167406814535008,
 'loss_weight_S-palmitoylation-C': 0.23153639050261293,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2640552402,
 'sample_weights': [0.11639557704118725, 0.6105898348756595],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3650812684736024,
 'weight_decay_Hydroxylation-K': 8.524609602931356,
 'weight_decay_S-palmitoylation-C': 8.222322056170109}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.391
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023540151610952826,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5487312131587959,
 'loss_weight_S-palmitoylation-C': 0.38787622602254523,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2353296586,
 'sample_weights': [0.23153639050261293, 0.3167406814535008],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.445690773708401,
 'weight_decay_Hydroxylation-K': 7.4645359285107595,
 'weight_decay_S-palmitoylation-C': 1.4380182650253126}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.390
[3,     3] loss: 1.385
[4,     3] loss: 1.384
[5,     3] loss: 1.385
[6,     3] loss: 1.377
[7,     3] loss: 1.371
[8,     3] loss: 1.358
[9,     3] loss: 1.317
[10,     3] loss: 1.288
[11,     3] loss: 1.240
[12,     3] loss: 1.229
[13,     3] loss: 1.187
[14,     3] loss: 1.224
[15,     3] loss: 1.069
[16,     3] loss: 1.073
[17,     3] loss: 1.091
[18,     3] loss: 1.129
[19,     3] loss: 1.121
[20,     3] loss: 1.006
[21,     3] loss: 1.048
[22,     3] loss: 0.950
[23,     3] loss: 0.962
[24,     3] loss: 0.959
[25,     3] loss: 0.924
[26,     3] loss: 0.954
[27,     3] loss: 1.103
[28,     3] loss: 0.876
[29,     3] loss: 0.911
[30,     3] loss: 1.061
[31,     3] loss: 0.978
[32,     3] loss: 0.931
[33,     3] loss: 0.918
[34,     3] loss: 0.879
[35,     3] loss: 0.910
[36,     3] loss: 1.038
[37,     3] loss: 0.974
[38,     3] loss: 0.970
[39,     3] loss: 0.962
[40,     3] loss: 1.029
[41,     3] loss: 0.987
[42,     3] loss: 0.984
[43,     3] loss: 0.948
[44,     3] loss: 0.928
[45,     3] loss: 0.880
[46,     3] loss: 0.921
[47,     3] loss: 0.881
[48,     3] loss: 0.883
[49,     3] loss: 0.892
[50,     3] loss: 0.914
[51,     3] loss: 0.843
[52,     3] loss: 0.838
[53,     3] loss: 0.925
[54,     3] loss: 0.846
[55,     3] loss: 0.854
[56,     3] loss: 0.842
[57,     3] loss: 0.852
[58,     3] loss: 0.816
[59,     3] loss: 0.873
[60,     3] loss: 0.929
[61,     3] loss: 0.938
[62,     3] loss: 0.846
[63,     3] loss: 0.862
[64,     3] loss: 0.866
[65,     3] loss: 0.853
[66,     3] loss: 1.004
[67,     3] loss: 0.932
[68,     3] loss: 0.945
[69,     3] loss: 0.886
[70,     3] loss: 0.889
[71,     3] loss: 0.954
[72,     3] loss: 0.875
[73,     3] loss: 0.893
[74,     3] loss: 0.852
[75,     3] loss: 0.894
[76,     3] loss: 0.987
[77,     3] loss: 0.962
[78,     3] loss: 0.929
[79,     3] loss: 0.975
[80,     3] loss: 0.957
[81,     3] loss: 0.943
[82,     3] loss: 0.908
[83,     3] loss: 0.853
[84,     3] loss: 0.807
[85,     3] loss: 0.911
[86,     3] loss: 1.001
Early stopping applied (best metric=0.5462772846221924)
Finished Training
Total time taken: 24.389276266098022
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.385
[3,     3] loss: 1.374
[4,     3] loss: 1.385
[5,     3] loss: 1.376
[6,     3] loss: 1.374
[7,     3] loss: 1.365
[8,     3] loss: 1.347
[9,     3] loss: 1.318
[10,     3] loss: 1.296
[11,     3] loss: 1.291
[12,     3] loss: 1.247
[13,     3] loss: 1.163
[14,     3] loss: 1.155
[15,     3] loss: 1.060
[16,     3] loss: 1.042
[17,     3] loss: 1.086
[18,     3] loss: 1.169
[19,     3] loss: 1.108
[20,     3] loss: 1.026
[21,     3] loss: 1.103
[22,     3] loss: 1.015
[23,     3] loss: 1.041
[24,     3] loss: 1.074
[25,     3] loss: 0.996
[26,     3] loss: 0.934
[27,     3] loss: 1.005
[28,     3] loss: 0.965
[29,     3] loss: 0.983
[30,     3] loss: 1.087
[31,     3] loss: 1.008
[32,     3] loss: 0.927
[33,     3] loss: 0.953
[34,     3] loss: 0.931
[35,     3] loss: 0.981
[36,     3] loss: 0.948
[37,     3] loss: 0.971
[38,     3] loss: 1.040
[39,     3] loss: 0.965
[40,     3] loss: 1.002
[41,     3] loss: 0.990
[42,     3] loss: 0.928
[43,     3] loss: 0.864
[44,     3] loss: 0.844
[45,     3] loss: 0.854
[46,     3] loss: 1.012
[47,     3] loss: 1.060
[48,     3] loss: 0.987
[49,     3] loss: 0.955
[50,     3] loss: 0.926
[51,     3] loss: 0.877
[52,     3] loss: 0.837
[53,     3] loss: 0.830
[54,     3] loss: 0.813
[55,     3] loss: 0.806
[56,     3] loss: 1.014
[57,     3] loss: 0.823
[58,     3] loss: 0.841
[59,     3] loss: 0.833
[60,     3] loss: 0.838
[61,     3] loss: 0.907
[62,     3] loss: 0.858
[63,     3] loss: 0.890
Early stopping applied (best metric=0.5266606211662292)
Finished Training
Total time taken: 17.88467574119568
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.385
[3,     3] loss: 1.387
[4,     3] loss: 1.392
[5,     3] loss: 1.384
[6,     3] loss: 1.390
[7,     3] loss: 1.389
[8,     3] loss: 1.380
[9,     3] loss: 1.393
[10,     3] loss: 1.386
[11,     3] loss: 1.385
[12,     3] loss: 1.384
[13,     3] loss: 1.380
[14,     3] loss: 1.376
[15,     3] loss: 1.375
[16,     3] loss: 1.355
[17,     3] loss: 1.305
[18,     3] loss: 1.284
[19,     3] loss: 1.229
[20,     3] loss: 1.243
[21,     3] loss: 1.172
[22,     3] loss: 1.249
[23,     3] loss: 1.227
[24,     3] loss: 1.218
[25,     3] loss: 1.178
[26,     3] loss: 1.121
[27,     3] loss: 1.109
[28,     3] loss: 1.093
[29,     3] loss: 1.041
[30,     3] loss: 1.142
[31,     3] loss: 0.978
[32,     3] loss: 0.983
[33,     3] loss: 1.113
[34,     3] loss: 1.048
[35,     3] loss: 0.951
[36,     3] loss: 0.978
[37,     3] loss: 1.030
[38,     3] loss: 0.945
[39,     3] loss: 1.017
[40,     3] loss: 1.068
[41,     3] loss: 1.085
[42,     3] loss: 1.042
[43,     3] loss: 1.093
[44,     3] loss: 1.158
[45,     3] loss: 1.052
[46,     3] loss: 0.963
[47,     3] loss: 0.935
[48,     3] loss: 1.064
[49,     3] loss: 0.960
[50,     3] loss: 0.952
[51,     3] loss: 1.088
[52,     3] loss: 1.350
[53,     3] loss: 1.276
[54,     3] loss: 1.224
[55,     3] loss: 1.217
[56,     3] loss: 1.244
[57,     3] loss: 1.232
[58,     3] loss: 1.192
[59,     3] loss: 1.199
[60,     3] loss: 1.111
[61,     3] loss: 1.068
[62,     3] loss: 1.107
[63,     3] loss: 1.125
[64,     3] loss: 0.987
[65,     3] loss: 1.152
[66,     3] loss: 1.075
[67,     3] loss: 1.089
[68,     3] loss: 1.104
[69,     3] loss: 1.043
[70,     3] loss: 0.970
[71,     3] loss: 0.937
[72,     3] loss: 0.915
[73,     3] loss: 0.957
[74,     3] loss: 0.965
[75,     3] loss: 0.890
[76,     3] loss: 0.943
[77,     3] loss: 0.892
[78,     3] loss: 0.939
[79,     3] loss: 0.841
[80,     3] loss: 0.847
[81,     3] loss: 0.868
[82,     3] loss: 1.034
[83,     3] loss: 1.163
[84,     3] loss: 1.086
[85,     3] loss: 1.213
Early stopping applied (best metric=0.5278291702270508)
Finished Training
Total time taken: 24.05821967124939
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.398
[3,     3] loss: 1.388
[4,     3] loss: 1.391
[5,     3] loss: 1.399
[6,     3] loss: 1.381
[7,     3] loss: 1.383
[8,     3] loss: 1.396
[9,     3] loss: 1.390
[10,     3] loss: 1.381
[11,     3] loss: 1.388
[12,     3] loss: 1.389
[13,     3] loss: 1.388
[14,     3] loss: 1.387
[15,     3] loss: 1.385
[16,     3] loss: 1.387
[17,     3] loss: 1.388
[18,     3] loss: 1.385
[19,     3] loss: 1.384
[20,     3] loss: 1.384
[21,     3] loss: 1.382
[22,     3] loss: 1.382
[23,     3] loss: 1.377
[24,     3] loss: 1.369
[25,     3] loss: 1.351
[26,     3] loss: 1.308
[27,     3] loss: 1.342
[28,     3] loss: 1.268
[29,     3] loss: 1.313
[30,     3] loss: 1.281
[31,     3] loss: 1.308
[32,     3] loss: 1.242
[33,     3] loss: 1.199
[34,     3] loss: 1.171
[35,     3] loss: 1.105
[36,     3] loss: 1.073
[37,     3] loss: 1.104
[38,     3] loss: 1.115
[39,     3] loss: 1.102
[40,     3] loss: 1.086
[41,     3] loss: 1.007
[42,     3] loss: 1.092
[43,     3] loss: 1.008
[44,     3] loss: 1.056
[45,     3] loss: 0.921
[46,     3] loss: 1.182
[47,     3] loss: 0.953
[48,     3] loss: 0.928
[49,     3] loss: 0.965
[50,     3] loss: 0.926
[51,     3] loss: 0.992
[52,     3] loss: 0.923
[53,     3] loss: 0.954
[54,     3] loss: 0.875
[55,     3] loss: 1.016
[56,     3] loss: 0.983
[57,     3] loss: 1.037
[58,     3] loss: 0.924
[59,     3] loss: 0.982
[60,     3] loss: 0.947
[61,     3] loss: 1.035
[62,     3] loss: 1.137
[63,     3] loss: 1.065
[64,     3] loss: 1.032
[65,     3] loss: 1.006
[66,     3] loss: 1.145
[67,     3] loss: 1.131
[68,     3] loss: 0.991
[69,     3] loss: 0.963
[70,     3] loss: 0.948
[71,     3] loss: 0.944
[72,     3] loss: 0.850
[73,     3] loss: 0.936
[74,     3] loss: 0.869
[75,     3] loss: 0.847
[76,     3] loss: 0.901
[77,     3] loss: 0.901
[78,     3] loss: 0.848
[79,     3] loss: 0.976
[80,     3] loss: 0.901
[81,     3] loss: 0.845
[82,     3] loss: 0.932
[83,     3] loss: 0.977
[84,     3] loss: 0.945
[85,     3] loss: 0.924
[86,     3] loss: 0.871
[87,     3] loss: 0.828
[88,     3] loss: 0.810
[89,     3] loss: 0.810
[90,     3] loss: 0.947
[91,     3] loss: 0.944
[92,     3] loss: 0.855
[93,     3] loss: 0.844
[94,     3] loss: 0.879
[95,     3] loss: 0.872
[96,     3] loss: 0.952
[97,     3] loss: 0.862
[98,     3] loss: 0.918
[99,     3] loss: 0.910
[100,     3] loss: 0.869
[101,     3] loss: 0.994
[102,     3] loss: 1.048
[103,     3] loss: 0.907
[104,     3] loss: 0.912
[105,     3] loss: 0.873
[106,     3] loss: 0.859
[107,     3] loss: 0.874
[108,     3] loss: 0.890
[109,     3] loss: 1.084
[110,     3] loss: 1.027
[111,     3] loss: 1.155
[112,     3] loss: 1.010
[113,     3] loss: 0.994
[114,     3] loss: 0.940
[115,     3] loss: 0.960
[116,     3] loss: 0.871
[117,     3] loss: 0.890
[118,     3] loss: 0.891
[119,     3] loss: 0.830
[120,     3] loss: 0.847
[121,     3] loss: 0.837
[122,     3] loss: 0.857
Early stopping applied (best metric=0.5028848648071289)
Finished Training
Total time taken: 34.40047073364258
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.384
[3,     3] loss: 1.382
[4,     3] loss: 1.377
[5,     3] loss: 1.373
[6,     3] loss: 1.385
[7,     3] loss: 1.369
[8,     3] loss: 1.356
[9,     3] loss: 1.331
[10,     3] loss: 1.273
[11,     3] loss: 1.246
[12,     3] loss: 1.218
[13,     3] loss: 1.296
[14,     3] loss: 1.339
[15,     3] loss: 1.213
[16,     3] loss: 1.194
[17,     3] loss: 1.159
[18,     3] loss: 1.202
[19,     3] loss: 1.152
[20,     3] loss: 1.069
[21,     3] loss: 1.087
[22,     3] loss: 1.054
[23,     3] loss: 1.084
[24,     3] loss: 1.055
[25,     3] loss: 1.142
[26,     3] loss: 1.114
[27,     3] loss: 1.027
[28,     3] loss: 1.000
[29,     3] loss: 1.067
[30,     3] loss: 1.002
[31,     3] loss: 1.111
[32,     3] loss: 1.012
[33,     3] loss: 0.948
[34,     3] loss: 0.942
[35,     3] loss: 0.933
[36,     3] loss: 0.950
[37,     3] loss: 0.913
[38,     3] loss: 0.840
[39,     3] loss: 0.856
[40,     3] loss: 0.882
[41,     3] loss: 0.922
[42,     3] loss: 0.839
[43,     3] loss: 0.873
[44,     3] loss: 1.124
[45,     3] loss: 0.976
[46,     3] loss: 0.947
[47,     3] loss: 0.906
[48,     3] loss: 0.870
[49,     3] loss: 0.929
[50,     3] loss: 0.818
[51,     3] loss: 0.835
[52,     3] loss: 0.883
[53,     3] loss: 0.834
[54,     3] loss: 0.803
[55,     3] loss: 0.817
[56,     3] loss: 0.785
[57,     3] loss: 0.872
[58,     3] loss: 0.802
[59,     3] loss: 0.797
[60,     3] loss: 0.864
[61,     3] loss: 0.868
[62,     3] loss: 0.887
[63,     3] loss: 0.860
[64,     3] loss: 0.886
[65,     3] loss: 0.831
[66,     3] loss: 0.869
[67,     3] loss: 0.892
Early stopping applied (best metric=0.48828038573265076)
Finished Training
Total time taken: 18.91025185585022
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.380
[3,     3] loss: 1.388
[4,     3] loss: 1.374
[5,     3] loss: 1.384
[6,     3] loss: 1.381
[7,     3] loss: 1.386
[8,     3] loss: 1.375
[9,     3] loss: 1.366
[10,     3] loss: 1.349
[11,     3] loss: 1.340
[12,     3] loss: 1.307
[13,     3] loss: 1.255
[14,     3] loss: 1.194
[15,     3] loss: 1.250
[16,     3] loss: 1.086
[17,     3] loss: 1.077
[18,     3] loss: 1.133
[19,     3] loss: 1.073
[20,     3] loss: 1.272
[21,     3] loss: 1.173
[22,     3] loss: 1.155
[23,     3] loss: 1.114
[24,     3] loss: 1.072
[25,     3] loss: 1.204
[26,     3] loss: 1.140
[27,     3] loss: 1.033
[28,     3] loss: 1.011
[29,     3] loss: 1.167
[30,     3] loss: 1.045
[31,     3] loss: 1.011
[32,     3] loss: 0.991
[33,     3] loss: 1.186
[34,     3] loss: 1.051
[35,     3] loss: 1.026
[36,     3] loss: 1.015
[37,     3] loss: 0.940
[38,     3] loss: 1.068
[39,     3] loss: 0.925
[40,     3] loss: 0.912
[41,     3] loss: 0.906
[42,     3] loss: 1.030
[43,     3] loss: 0.963
[44,     3] loss: 0.994
[45,     3] loss: 0.952
[46,     3] loss: 0.909
[47,     3] loss: 0.879
[48,     3] loss: 0.875
[49,     3] loss: 0.898
[50,     3] loss: 0.827
[51,     3] loss: 0.856
[52,     3] loss: 0.873
[53,     3] loss: 0.950
[54,     3] loss: 0.910
[55,     3] loss: 0.959
[56,     3] loss: 0.825
[57,     3] loss: 0.849
[58,     3] loss: 0.845
[59,     3] loss: 0.871
[60,     3] loss: 0.847
[61,     3] loss: 0.883
[62,     3] loss: 0.808
[63,     3] loss: 0.817
[64,     3] loss: 0.795
[65,     3] loss: 0.815
[66,     3] loss: 0.783
Early stopping applied (best metric=0.5214939713478088)
Finished Training
Total time taken: 18.558671951293945
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.403
[2,     3] loss: 1.389
[3,     3] loss: 1.388
[4,     3] loss: 1.383
[5,     3] loss: 1.382
[6,     3] loss: 1.386
[7,     3] loss: 1.394
[8,     3] loss: 1.389
[9,     3] loss: 1.388
[10,     3] loss: 1.389
[11,     3] loss: 1.382
[12,     3] loss: 1.384
[13,     3] loss: 1.389
[14,     3] loss: 1.382
[15,     3] loss: 1.380
[16,     3] loss: 1.374
[17,     3] loss: 1.368
[18,     3] loss: 1.364
[19,     3] loss: 1.341
[20,     3] loss: 1.326
[21,     3] loss: 1.304
[22,     3] loss: 1.325
[23,     3] loss: 1.261
[24,     3] loss: 1.197
[25,     3] loss: 1.192
[26,     3] loss: 1.232
[27,     3] loss: 1.136
[28,     3] loss: 1.151
[29,     3] loss: 1.113
[30,     3] loss: 1.136
[31,     3] loss: 1.091
[32,     3] loss: 1.111
[33,     3] loss: 1.069
[34,     3] loss: 0.997
[35,     3] loss: 1.098
[36,     3] loss: 1.062
[37,     3] loss: 1.001
[38,     3] loss: 0.992
[39,     3] loss: 0.961
[40,     3] loss: 0.899
[41,     3] loss: 0.906
[42,     3] loss: 0.949
[43,     3] loss: 1.095
[44,     3] loss: 0.926
[45,     3] loss: 1.010
[46,     3] loss: 0.966
[47,     3] loss: 0.906
[48,     3] loss: 0.915
[49,     3] loss: 0.854
[50,     3] loss: 1.186
[51,     3] loss: 1.044
[52,     3] loss: 1.003
[53,     3] loss: 1.029
[54,     3] loss: 1.070
[55,     3] loss: 1.007
[56,     3] loss: 1.011
[57,     3] loss: 0.914
[58,     3] loss: 0.947
[59,     3] loss: 1.163
[60,     3] loss: 0.975
[61,     3] loss: 1.007
[62,     3] loss: 0.951
[63,     3] loss: 0.983
[64,     3] loss: 0.970
[65,     3] loss: 0.942
[66,     3] loss: 0.851
[67,     3] loss: 0.943
[68,     3] loss: 0.817
[69,     3] loss: 0.860
[70,     3] loss: 0.866
[71,     3] loss: 0.959
[72,     3] loss: 1.064
[73,     3] loss: 1.025
[74,     3] loss: 0.982
[75,     3] loss: 0.976
[76,     3] loss: 0.940
[77,     3] loss: 0.889
[78,     3] loss: 0.901
[79,     3] loss: 0.900
[80,     3] loss: 0.971
[81,     3] loss: 0.895
[82,     3] loss: 0.899
[83,     3] loss: 0.913
[84,     3] loss: 0.892
[85,     3] loss: 0.880
[86,     3] loss: 0.840
[87,     3] loss: 0.924
[88,     3] loss: 0.906
Early stopping applied (best metric=0.5032028555870056)
Finished Training
Total time taken: 25.114293813705444
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.385
[3,     3] loss: 1.390
[4,     3] loss: 1.389
[5,     3] loss: 1.388
[6,     3] loss: 1.387
[7,     3] loss: 1.379
[8,     3] loss: 1.374
[9,     3] loss: 1.381
[10,     3] loss: 1.372
[11,     3] loss: 1.362
[12,     3] loss: 1.340
[13,     3] loss: 1.282
[14,     3] loss: 1.267
[15,     3] loss: 1.256
[16,     3] loss: 1.229
[17,     3] loss: 1.200
[18,     3] loss: 1.178
[19,     3] loss: 1.175
[20,     3] loss: 1.120
[21,     3] loss: 1.141
[22,     3] loss: 1.119
[23,     3] loss: 1.111
[24,     3] loss: 1.040
[25,     3] loss: 0.997
[26,     3] loss: 1.032
[27,     3] loss: 1.079
[28,     3] loss: 0.965
[29,     3] loss: 1.145
[30,     3] loss: 0.987
[31,     3] loss: 1.086
[32,     3] loss: 0.999
[33,     3] loss: 1.105
[34,     3] loss: 1.092
[35,     3] loss: 0.979
[36,     3] loss: 1.033
[37,     3] loss: 0.988
[38,     3] loss: 0.990
[39,     3] loss: 1.017
[40,     3] loss: 0.984
[41,     3] loss: 0.976
[42,     3] loss: 1.046
[43,     3] loss: 1.125
[44,     3] loss: 0.953
[45,     3] loss: 0.967
[46,     3] loss: 0.905
[47,     3] loss: 0.974
[48,     3] loss: 0.908
[49,     3] loss: 0.956
[50,     3] loss: 1.014
[51,     3] loss: 0.935
[52,     3] loss: 0.982
[53,     3] loss: 0.900
[54,     3] loss: 0.975
[55,     3] loss: 0.885
[56,     3] loss: 0.923
[57,     3] loss: 0.869
[58,     3] loss: 0.917
[59,     3] loss: 0.874
[60,     3] loss: 0.906
[61,     3] loss: 0.900
[62,     3] loss: 1.037
[63,     3] loss: 1.057
[64,     3] loss: 0.938
[65,     3] loss: 0.908
[66,     3] loss: 0.904
[67,     3] loss: 0.967
[68,     3] loss: 0.899
[69,     3] loss: 0.962
[70,     3] loss: 0.992
[71,     3] loss: 0.916
[72,     3] loss: 0.895
Early stopping applied (best metric=0.5221669673919678)
Finished Training
Total time taken: 20.427291870117188
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.380
[3,     3] loss: 1.386
[4,     3] loss: 1.382
[5,     3] loss: 1.392
[6,     3] loss: 1.373
[7,     3] loss: 1.370
[8,     3] loss: 1.362
[9,     3] loss: 1.341
[10,     3] loss: 1.306
[11,     3] loss: 1.324
[12,     3] loss: 1.292
[13,     3] loss: 1.237
[14,     3] loss: 1.185
[15,     3] loss: 1.220
[16,     3] loss: 1.115
[17,     3] loss: 1.159
[18,     3] loss: 1.164
[19,     3] loss: 1.122
[20,     3] loss: 1.013
[21,     3] loss: 1.088
[22,     3] loss: 1.033
[23,     3] loss: 0.981
[24,     3] loss: 0.984
[25,     3] loss: 0.960
[26,     3] loss: 1.061
[27,     3] loss: 1.101
[28,     3] loss: 1.126
[29,     3] loss: 1.045
[30,     3] loss: 1.056
[31,     3] loss: 1.038
[32,     3] loss: 0.967
[33,     3] loss: 0.965
[34,     3] loss: 0.994
[35,     3] loss: 0.907
[36,     3] loss: 0.998
[37,     3] loss: 0.897
[38,     3] loss: 0.979
[39,     3] loss: 0.888
[40,     3] loss: 0.908
[41,     3] loss: 0.966
[42,     3] loss: 0.931
[43,     3] loss: 0.901
[44,     3] loss: 0.883
[45,     3] loss: 0.969
[46,     3] loss: 1.002
[47,     3] loss: 0.963
[48,     3] loss: 0.932
[49,     3] loss: 0.892
[50,     3] loss: 0.870
[51,     3] loss: 0.878
[52,     3] loss: 0.885
[53,     3] loss: 0.853
[54,     3] loss: 0.976
[55,     3] loss: 0.895
[56,     3] loss: 0.898
[57,     3] loss: 0.863
[58,     3] loss: 0.880
[59,     3] loss: 0.903
[60,     3] loss: 0.882
[61,     3] loss: 0.920
[62,     3] loss: 0.976
Early stopping applied (best metric=0.4884738028049469)
Finished Training
Total time taken: 17.586690425872803
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.387
[3,     3] loss: 1.382
[4,     3] loss: 1.384
[5,     3] loss: 1.377
[6,     3] loss: 1.377
[7,     3] loss: 1.368
[8,     3] loss: 1.335
[9,     3] loss: 1.309
[10,     3] loss: 1.280
[11,     3] loss: 1.241
[12,     3] loss: 1.236
[13,     3] loss: 1.192
[14,     3] loss: 1.125
[15,     3] loss: 1.113
[16,     3] loss: 1.058
[17,     3] loss: 1.029
[18,     3] loss: 1.232
[19,     3] loss: 1.208
[20,     3] loss: 1.198
[21,     3] loss: 1.121
[22,     3] loss: 1.187
[23,     3] loss: 1.144
[24,     3] loss: 1.151
[25,     3] loss: 1.138
[26,     3] loss: 1.081
[27,     3] loss: 1.028
[28,     3] loss: 1.127
[29,     3] loss: 1.057
[30,     3] loss: 1.044
[31,     3] loss: 1.000
[32,     3] loss: 1.047
[33,     3] loss: 0.980
[34,     3] loss: 0.972
[35,     3] loss: 0.993
[36,     3] loss: 0.902
[37,     3] loss: 0.963
[38,     3] loss: 1.174
[39,     3] loss: 1.370
[40,     3] loss: 1.239
[41,     3] loss: 1.305
[42,     3] loss: 1.251
[43,     3] loss: 1.238
[44,     3] loss: 1.213
[45,     3] loss: 1.151
[46,     3] loss: 1.151
[47,     3] loss: 1.123
[48,     3] loss: 1.008
[49,     3] loss: 1.138
[50,     3] loss: 1.045
[51,     3] loss: 1.025
[52,     3] loss: 0.944
[53,     3] loss: 0.939
[54,     3] loss: 0.893
[55,     3] loss: 1.071
[56,     3] loss: 1.023
[57,     3] loss: 0.979
[58,     3] loss: 0.987
[59,     3] loss: 0.961
[60,     3] loss: 0.941
[61,     3] loss: 0.969
[62,     3] loss: 0.879
[63,     3] loss: 0.914
[64,     3] loss: 0.873
[65,     3] loss: 0.851
[66,     3] loss: 0.919
[67,     3] loss: 1.020
Early stopping applied (best metric=0.5280645489692688)
Finished Training
Total time taken: 18.730698823928833
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.406
[3,     3] loss: 1.394
[4,     3] loss: 1.388
[5,     3] loss: 1.388
[6,     3] loss: 1.387
[7,     3] loss: 1.387
[8,     3] loss: 1.383
[9,     3] loss: 1.392
[10,     3] loss: 1.390
[11,     3] loss: 1.381
[12,     3] loss: 1.384
[13,     3] loss: 1.383
[14,     3] loss: 1.381
[15,     3] loss: 1.370
[16,     3] loss: 1.366
[17,     3] loss: 1.343
[18,     3] loss: 1.311
[19,     3] loss: 1.279
[20,     3] loss: 1.227
[21,     3] loss: 1.215
[22,     3] loss: 1.146
[23,     3] loss: 1.269
[24,     3] loss: 1.105
[25,     3] loss: 1.133
[26,     3] loss: 1.117
[27,     3] loss: 1.090
[28,     3] loss: 1.103
[29,     3] loss: 0.999
[30,     3] loss: 1.043
[31,     3] loss: 1.032
[32,     3] loss: 1.168
[33,     3] loss: 1.276
[34,     3] loss: 1.244
[35,     3] loss: 1.187
[36,     3] loss: 1.197
[37,     3] loss: 1.148
[38,     3] loss: 1.043
[39,     3] loss: 0.995
[40,     3] loss: 1.013
[41,     3] loss: 1.066
[42,     3] loss: 1.000
[43,     3] loss: 0.946
[44,     3] loss: 0.936
[45,     3] loss: 0.897
[46,     3] loss: 0.840
[47,     3] loss: 0.931
[48,     3] loss: 0.946
[49,     3] loss: 0.872
[50,     3] loss: 0.850
[51,     3] loss: 0.905
[52,     3] loss: 0.929
[53,     3] loss: 0.885
[54,     3] loss: 0.866
[55,     3] loss: 0.976
[56,     3] loss: 0.926
[57,     3] loss: 0.857
[58,     3] loss: 0.836
[59,     3] loss: 0.945
[60,     3] loss: 0.903
[61,     3] loss: 0.920
[62,     3] loss: 0.932
[63,     3] loss: 0.824
[64,     3] loss: 0.853
[65,     3] loss: 0.863
[66,     3] loss: 0.837
[67,     3] loss: 0.867
[68,     3] loss: 0.953
[69,     3] loss: 1.053
Early stopping applied (best metric=0.5108714699745178)
Finished Training
Total time taken: 19.364727020263672
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.384
[3,     3] loss: 1.384
[4,     3] loss: 1.380
[5,     3] loss: 1.375
[6,     3] loss: 1.389
[7,     3] loss: 1.392
[8,     3] loss: 1.372
[9,     3] loss: 1.373
[10,     3] loss: 1.340
[11,     3] loss: 1.314
[12,     3] loss: 1.328
[13,     3] loss: 1.273
[14,     3] loss: 1.265
[15,     3] loss: 1.185
[16,     3] loss: 1.243
[17,     3] loss: 1.134
[18,     3] loss: 1.091
[19,     3] loss: 1.051
[20,     3] loss: 1.033
[21,     3] loss: 1.136
[22,     3] loss: 1.044
[23,     3] loss: 1.123
[24,     3] loss: 1.002
[25,     3] loss: 1.039
[26,     3] loss: 0.968
[27,     3] loss: 0.931
[28,     3] loss: 0.918
[29,     3] loss: 0.985
[30,     3] loss: 0.897
[31,     3] loss: 0.901
[32,     3] loss: 1.009
[33,     3] loss: 0.931
[34,     3] loss: 0.923
[35,     3] loss: 0.901
[36,     3] loss: 0.894
[37,     3] loss: 0.974
[38,     3] loss: 0.904
[39,     3] loss: 0.973
[40,     3] loss: 0.971
[41,     3] loss: 1.028
[42,     3] loss: 0.964
[43,     3] loss: 0.901
[44,     3] loss: 1.059
[45,     3] loss: 1.032
[46,     3] loss: 1.117
[47,     3] loss: 1.034
[48,     3] loss: 1.052
[49,     3] loss: 1.049
[50,     3] loss: 0.934
[51,     3] loss: 0.926
[52,     3] loss: 0.937
[53,     3] loss: 0.885
[54,     3] loss: 0.864
[55,     3] loss: 0.884
[56,     3] loss: 0.946
[57,     3] loss: 0.878
[58,     3] loss: 0.968
[59,     3] loss: 0.925
[60,     3] loss: 0.881
[61,     3] loss: 0.845
[62,     3] loss: 0.870
[63,     3] loss: 0.857
[64,     3] loss: 0.864
[65,     3] loss: 0.956
[66,     3] loss: 0.953
[67,     3] loss: 0.998
[68,     3] loss: 0.972
[69,     3] loss: 1.058
[70,     3] loss: 1.110
[71,     3] loss: 1.029
Early stopping applied (best metric=0.5363118052482605)
Finished Training
Total time taken: 19.682644844055176
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.395
[3,     3] loss: 1.394
[4,     3] loss: 1.388
[5,     3] loss: 1.391
[6,     3] loss: 1.385
[7,     3] loss: 1.387
[8,     3] loss: 1.384
[9,     3] loss: 1.383
[10,     3] loss: 1.385
[11,     3] loss: 1.384
[12,     3] loss: 1.384
[13,     3] loss: 1.372
[14,     3] loss: 1.374
[15,     3] loss: 1.355
[16,     3] loss: 1.360
[17,     3] loss: 1.274
[18,     3] loss: 1.233
[19,     3] loss: 1.211
[20,     3] loss: 1.208
[21,     3] loss: 1.231
[22,     3] loss: 1.195
[23,     3] loss: 1.192
[24,     3] loss: 1.248
[25,     3] loss: 1.095
[26,     3] loss: 1.186
[27,     3] loss: 1.107
[28,     3] loss: 1.219
[29,     3] loss: 1.060
[30,     3] loss: 1.120
[31,     3] loss: 1.032
[32,     3] loss: 0.986
[33,     3] loss: 1.005
[34,     3] loss: 1.066
[35,     3] loss: 1.082
[36,     3] loss: 1.098
[37,     3] loss: 1.073
[38,     3] loss: 1.019
[39,     3] loss: 1.037
[40,     3] loss: 1.066
[41,     3] loss: 1.034
[42,     3] loss: 1.058
[43,     3] loss: 1.055
[44,     3] loss: 0.932
[45,     3] loss: 0.928
[46,     3] loss: 0.928
[47,     3] loss: 0.949
[48,     3] loss: 1.063
[49,     3] loss: 0.880
[50,     3] loss: 0.872
[51,     3] loss: 0.903
[52,     3] loss: 0.868
[53,     3] loss: 0.910
[54,     3] loss: 0.865
[55,     3] loss: 0.971
[56,     3] loss: 1.032
[57,     3] loss: 0.869
[58,     3] loss: 0.922
[59,     3] loss: 0.906
[60,     3] loss: 0.883
[61,     3] loss: 0.927
[62,     3] loss: 0.974
[63,     3] loss: 0.960
[64,     3] loss: 1.000
[65,     3] loss: 0.995
[66,     3] loss: 0.920
[67,     3] loss: 0.916
[68,     3] loss: 0.885
[69,     3] loss: 0.904
[70,     3] loss: 0.892
[71,     3] loss: 0.895
[72,     3] loss: 0.958
[73,     3] loss: 0.885
[74,     3] loss: 0.934
[75,     3] loss: 0.899
[76,     3] loss: 0.962
[77,     3] loss: 1.171
[78,     3] loss: 1.129
[79,     3] loss: 1.028
[80,     3] loss: 1.114
[81,     3] loss: 1.071
[82,     3] loss: 1.066
[83,     3] loss: 1.162
[84,     3] loss: 0.997
[85,     3] loss: 0.995
[86,     3] loss: 0.981
[87,     3] loss: 0.998
[88,     3] loss: 1.009
[89,     3] loss: 0.938
[90,     3] loss: 0.935
[91,     3] loss: 0.886
[92,     3] loss: 0.861
[93,     3] loss: 0.884
[94,     3] loss: 0.850
[95,     3] loss: 0.861
[96,     3] loss: 0.881
[97,     3] loss: 0.833
[98,     3] loss: 0.942
[99,     3] loss: 1.050
[100,     3] loss: 1.002
[101,     3] loss: 0.971
[102,     3] loss: 0.865
[103,     3] loss: 1.042
[104,     3] loss: 1.001
[105,     3] loss: 0.936
Early stopping applied (best metric=0.5294951796531677)
Finished Training
Total time taken: 29.561445236206055
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.388
[3,     3] loss: 1.393
[4,     3] loss: 1.384
[5,     3] loss: 1.384
[6,     3] loss: 1.383
[7,     3] loss: 1.391
[8,     3] loss: 1.387
[9,     3] loss: 1.383
[10,     3] loss: 1.380
[11,     3] loss: 1.382
[12,     3] loss: 1.371
[13,     3] loss: 1.357
[14,     3] loss: 1.357
[15,     3] loss: 1.298
[16,     3] loss: 1.234
[17,     3] loss: 1.227
[18,     3] loss: 1.227
[19,     3] loss: 1.231
[20,     3] loss: 1.225
[21,     3] loss: 1.275
[22,     3] loss: 1.226
[23,     3] loss: 1.185
[24,     3] loss: 1.149
[25,     3] loss: 1.118
[26,     3] loss: 1.096
[27,     3] loss: 1.095
[28,     3] loss: 1.012
[29,     3] loss: 0.994
[30,     3] loss: 0.968
[31,     3] loss: 1.079
[32,     3] loss: 0.948
[33,     3] loss: 1.031
[34,     3] loss: 1.176
[35,     3] loss: 0.988
[36,     3] loss: 0.921
[37,     3] loss: 0.879
[38,     3] loss: 1.086
[39,     3] loss: 1.126
[40,     3] loss: 1.050
[41,     3] loss: 1.089
[42,     3] loss: 1.043
[43,     3] loss: 0.997
[44,     3] loss: 0.989
[45,     3] loss: 0.942
[46,     3] loss: 0.869
[47,     3] loss: 0.844
[48,     3] loss: 0.875
[49,     3] loss: 0.804
[50,     3] loss: 0.858
[51,     3] loss: 0.852
[52,     3] loss: 0.966
[53,     3] loss: 1.106
[54,     3] loss: 1.029
[55,     3] loss: 1.005
[56,     3] loss: 1.034
[57,     3] loss: 1.111
[58,     3] loss: 0.980
[59,     3] loss: 0.908
[60,     3] loss: 0.967
[61,     3] loss: 0.883
[62,     3] loss: 0.846
[63,     3] loss: 0.857
[64,     3] loss: 0.832
Early stopping applied (best metric=0.5194451212882996)
Finished Training
Total time taken: 18.40015196800232
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.390
[3,     3] loss: 1.373
[4,     3] loss: 1.377
[5,     3] loss: 1.384
[6,     3] loss: 1.368
[7,     3] loss: 1.353
[8,     3] loss: 1.356
[9,     3] loss: 1.305
[10,     3] loss: 1.243
[11,     3] loss: 1.281
[12,     3] loss: 1.173
[13,     3] loss: 1.262
[14,     3] loss: 1.083
[15,     3] loss: 1.327
[16,     3] loss: 1.308
[17,     3] loss: 1.193
[18,     3] loss: 1.174
[19,     3] loss: 1.087
[20,     3] loss: 1.095
[21,     3] loss: 1.036
[22,     3] loss: 1.050
[23,     3] loss: 0.958
[24,     3] loss: 0.875
[25,     3] loss: 0.859
[26,     3] loss: 0.992
[27,     3] loss: 1.088
[28,     3] loss: 0.997
[29,     3] loss: 0.994
[30,     3] loss: 0.982
[31,     3] loss: 0.951
[32,     3] loss: 1.032
[33,     3] loss: 1.004
[34,     3] loss: 1.098
[35,     3] loss: 1.001
[36,     3] loss: 1.011
[37,     3] loss: 0.938
[38,     3] loss: 0.885
[39,     3] loss: 0.925
[40,     3] loss: 0.855
[41,     3] loss: 0.965
[42,     3] loss: 0.874
[43,     3] loss: 1.280
[44,     3] loss: 1.371
[45,     3] loss: 1.145
[46,     3] loss: 1.216
[47,     3] loss: 1.202
[48,     3] loss: 1.161
[49,     3] loss: 1.117
[50,     3] loss: 1.080
[51,     3] loss: 1.011
[52,     3] loss: 0.946
[53,     3] loss: 0.943
[54,     3] loss: 0.962
[55,     3] loss: 0.895
[56,     3] loss: 1.039
[57,     3] loss: 0.991
[58,     3] loss: 0.944
[59,     3] loss: 0.957
[60,     3] loss: 0.877
[61,     3] loss: 0.895
[62,     3] loss: 0.887
Early stopping applied (best metric=0.5263688564300537)
Finished Training
Total time taken: 17.52468228340149
{'S-palmitoylation-C Validation Accuracy': 0.640133209827533, 'S-palmitoylation-C Validation Sensitivity': 0.33003300330033003, 'S-palmitoylation-C Validation Specificity': 0.7178708839611553, 'S-palmitoylation-C Validation Precision': 0.2311887414179159, 'S-palmitoylation-C AUC ROC': 0.5484504374349701, 'S-palmitoylation-C AUC PR': 0.2247354640070144, 'S-palmitoylation-C MCC': 0.04440183242848328, 'S-palmitoylation-C F1': 0.2429363391113817, 'Validation Loss (S-palmitoylation-C)': 0.5539466261863708, 'Hydroxylation-K Validation Accuracy': 0.6334219858156028, 'Hydroxylation-K Validation Sensitivity': 0.8081481481481482, 'Hydroxylation-K Validation Specificity': 0.5877192982456141, 'Hydroxylation-K Validation Precision': 0.3501327399203743, 'Hydroxylation-K AUC ROC': 0.8019395711500975, 'Hydroxylation-K AUC PR': 0.5823013371171644, 'Hydroxylation-K MCC': 0.3314493840438494, 'Hydroxylation-K F1': 0.474003448974404, 'Validation Loss (Hydroxylation-K)': 0.5185217936833699, 'Validation Loss (total)': 1.0724684079488118, 'TimeToTrain': 21.639612833658855}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007635452548536463,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.025754367671100883,
 'loss_weight_S-palmitoylation-C': 0.2974823893518626,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2946372285,
 'sample_weights': [0.38787622602254523, 0.5487312131587959],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.626859525138382,
 'weight_decay_Hydroxylation-K': 8.365361537564931,
 'weight_decay_S-palmitoylation-C': 2.3586793198034184}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.378
[3,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005582808627876666,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.535971827437455,
 'loss_weight_S-palmitoylation-C': 0.7075919174029874,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1098213426,
 'sample_weights': [0.2974823893518626, 0.025754367671100883],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3879986127229933,
 'weight_decay_Hydroxylation-K': 2.3357332137097297,
 'weight_decay_S-palmitoylation-C': 3.222588335687923}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.388
[3,     3] loss: 1.412
[4,     3] loss: 1.387
[5,     3] loss: 1.381
[6,     3] loss: 1.388
[7,     3] loss: 1.384
[8,     3] loss: 1.385
[9,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007812649015872933,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7748978194654159,
 'loss_weight_S-palmitoylation-C': 0.2240318047243922,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 743800730,
 'sample_weights': [0.7075919174029874, 0.535971827437455],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.92512274194335,
 'weight_decay_Hydroxylation-K': 2.3372516361368034,
 'weight_decay_S-palmitoylation-C': 6.920372115813109}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.401
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008654341930007692,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8183693098871841,
 'loss_weight_S-palmitoylation-C': 0.6558097437911222,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1213677937,
 'sample_weights': [0.2240318047243922, 0.7748978194654159],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.181365823885967,
 'weight_decay_Hydroxylation-K': 5.72022668705687,
 'weight_decay_S-palmitoylation-C': 3.8306380470593204}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.386
[3,     3] loss: 1.378
[4,     3] loss: 1.401
[5,     3] loss: 1.389
[6,     3] loss: 1.383
[7,     3] loss: 1.387
[8,     3] loss: 1.389
[9,     3] loss: 1.385
[10,     3] loss: 1.386
[11,     3] loss: 1.385
[12,     3] loss: 1.386
[13,     3] loss: 1.389
[14,     3] loss: 1.387
[15,     3] loss: 1.386
[16,     3] loss: 1.387
[17,     3] loss: 1.385
[18,     3] loss: 1.383
[19,     3] loss: 1.341
[20,     3] loss: 1.358
[21,     3] loss: 1.307
[22,     3] loss: 1.264
[23,     3] loss: 1.463
[24,     3] loss: 1.438
[25,     3] loss: 1.355
[26,     3] loss: 1.301
[27,     3] loss: 1.422
[28,     3] loss: 1.357
[29,     3] loss: 1.382
[30,     3] loss: 1.378
[31,     3] loss: 1.381
[32,     3] loss: 1.369
[33,     3] loss: 1.328
[34,     3] loss: 1.348
[35,     3] loss: 1.375
[36,     3] loss: 1.300
[37,     3] loss: 1.345
[38,     3] loss: 1.322
[39,     3] loss: 1.304
[40,     3] loss: 1.219
[41,     3] loss: 1.234
[42,     3] loss: 1.251
[43,     3] loss: 1.214
[44,     3] loss: 1.237
[45,     3] loss: 1.230
[46,     3] loss: 1.142
[47,     3] loss: 1.219
[48,     3] loss: 1.171
[49,     3] loss: 1.134
[50,     3] loss: 1.275
[51,     3] loss: 1.326
[52,     3] loss: 1.262
[53,     3] loss: 1.241
[54,     3] loss: 1.262
[55,     3] loss: 1.105
[56,     3] loss: 1.105
[57,     3] loss: 1.043
[58,     3] loss: 1.332
[59,     3] loss: 1.257
[60,     3] loss: 1.217
[61,     3] loss: 1.183
[62,     3] loss: 1.318
[63,     3] loss: 1.201
[64,     3] loss: 1.163
[65,     3] loss: 1.227
[66,     3] loss: 1.092
[67,     3] loss: 1.259
[68,     3] loss: 1.249
[69,     3] loss: 1.263
[70,     3] loss: 1.226
[71,     3] loss: 1.256
[72,     3] loss: 1.177
[73,     3] loss: 1.106
[74,     3] loss: 1.179
[75,     3] loss: 1.129
[76,     3] loss: 1.067
Early stopping applied (best metric=0.5458309054374695)
Finished Training
Total time taken: 21.015197277069092
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.404
[2,     3] loss: 1.398
[3,     3] loss: 1.390
[4,     3] loss: 1.387
[5,     3] loss: 1.385
[6,     3] loss: 1.388
[7,     3] loss: 1.379
[8,     3] loss: 1.398
[9,     3] loss: 1.390
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.388
[14,     3] loss: 1.386
[15,     3] loss: 1.385
[16,     3] loss: 1.386
[17,     3] loss: 1.387
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.387
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.383
[28,     3] loss: 1.374
[29,     3] loss: 1.341
[30,     3] loss: 1.322
[31,     3] loss: 1.407
[32,     3] loss: 1.324
[33,     3] loss: 1.323
[34,     3] loss: 1.333
[35,     3] loss: 1.274
[36,     3] loss: 1.121
[37,     3] loss: 1.410
[38,     3] loss: 1.175
[39,     3] loss: 1.141
[40,     3] loss: 1.267
[41,     3] loss: 1.156
[42,     3] loss: 1.047
[43,     3] loss: 1.236
[44,     3] loss: 1.416
[45,     3] loss: 1.275
[46,     3] loss: 1.258
[47,     3] loss: 1.188
[48,     3] loss: 1.104
[49,     3] loss: 1.255
[50,     3] loss: 1.229
[51,     3] loss: 1.152
[52,     3] loss: 1.210
[53,     3] loss: 1.062
[54,     3] loss: 1.077
[55,     3] loss: 0.994
[56,     3] loss: 1.063
[57,     3] loss: 0.988
[58,     3] loss: 1.093
[59,     3] loss: 1.018
[60,     3] loss: 1.067
[61,     3] loss: 1.044
[62,     3] loss: 1.043
[63,     3] loss: 0.909
[64,     3] loss: 1.016
[65,     3] loss: 0.982
[66,     3] loss: 1.081
[67,     3] loss: 1.083
[68,     3] loss: 0.987
[69,     3] loss: 1.245
[70,     3] loss: 0.991
[71,     3] loss: 1.140
[72,     3] loss: 0.961
[73,     3] loss: 1.051
[74,     3] loss: 0.960
[75,     3] loss: 0.955
[76,     3] loss: 1.008
[77,     3] loss: 0.915
[78,     3] loss: 0.917
[79,     3] loss: 1.020
[80,     3] loss: 1.070
[81,     3] loss: 1.043
[82,     3] loss: 0.969
[83,     3] loss: 1.115
[84,     3] loss: 1.064
[85,     3] loss: 1.090
[86,     3] loss: 1.073
[87,     3] loss: 0.881
[88,     3] loss: 0.891
[89,     3] loss: 0.979
[90,     3] loss: 1.179
[91,     3] loss: 0.998
[92,     3] loss: 1.088
[93,     3] loss: 1.060
[94,     3] loss: 1.219
[95,     3] loss: 1.118
[96,     3] loss: 1.097
[97,     3] loss: 1.049
[98,     3] loss: 1.013
[99,     3] loss: 0.940
[100,     3] loss: 0.964
[101,     3] loss: 1.030
[102,     3] loss: 1.001
[103,     3] loss: 0.971
[104,     3] loss: 0.917
[105,     3] loss: 0.940
[106,     3] loss: 0.951
[107,     3] loss: 1.211
[108,     3] loss: 1.114
[109,     3] loss: 1.151
[110,     3] loss: 1.104
[111,     3] loss: 1.035
[112,     3] loss: 0.996
[113,     3] loss: 0.991
[114,     3] loss: 1.064
[115,     3] loss: 1.047
[116,     3] loss: 1.060
[117,     3] loss: 1.020
[118,     3] loss: 1.082
[119,     3] loss: 0.946
[120,     3] loss: 0.879
[121,     3] loss: 0.962
Early stopping applied (best metric=0.5359373688697815)
Finished Training
Total time taken: 34.06846046447754
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.388
[3,     3] loss: 1.389
[4,     3] loss: 1.387
[5,     3] loss: 1.388
[6,     3] loss: 1.384
[7,     3] loss: 1.384
[8,     3] loss: 1.387
[9,     3] loss: 1.386
[10,     3] loss: 1.390
[11,     3] loss: 1.386
[12,     3] loss: 1.392
[13,     3] loss: 1.385
[14,     3] loss: 1.384
[15,     3] loss: 1.389
[16,     3] loss: 1.385
[17,     3] loss: 1.387
[18,     3] loss: 1.385
[19,     3] loss: 1.385
[20,     3] loss: 1.388
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.387
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.387
[40,     3] loss: 1.386
[41,     3] loss: 1.387
[42,     3] loss: 1.387
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.387
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.387
[54,     3] loss: 1.386
Early stopping applied (best metric=0.5628043413162231)
Finished Training
Total time taken: 15.091710090637207
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.395
[3,     3] loss: 1.391
[4,     3] loss: 1.392
[5,     3] loss: 1.384
[6,     3] loss: 1.387
[7,     3] loss: 1.390
[8,     3] loss: 1.387
[9,     3] loss: 1.385
[10,     3] loss: 1.383
[11,     3] loss: 1.391
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.385
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.384
[26,     3] loss: 1.387
[27,     3] loss: 1.381
[28,     3] loss: 1.366
[29,     3] loss: 1.381
[30,     3] loss: 1.373
[31,     3] loss: 1.330
[32,     3] loss: 1.366
[33,     3] loss: 1.318
[34,     3] loss: 1.287
[35,     3] loss: 1.284
[36,     3] loss: 1.226
[37,     3] loss: 1.186
[38,     3] loss: 1.091
[39,     3] loss: 1.354
[40,     3] loss: 1.508
[41,     3] loss: 1.388
[42,     3] loss: 1.391
[43,     3] loss: 1.383
[44,     3] loss: 1.390
[45,     3] loss: 1.388
[46,     3] loss: 1.389
[47,     3] loss: 1.386
[48,     3] loss: 1.387
[49,     3] loss: 1.387
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.387
[53,     3] loss: 1.386
[54,     3] loss: 1.387
[55,     3] loss: 1.386
[56,     3] loss: 1.387
[57,     3] loss: 1.386
[58,     3] loss: 1.386
[59,     3] loss: 1.387
[60,     3] loss: 1.385
[61,     3] loss: 1.386
[62,     3] loss: 1.386
[63,     3] loss: 1.386
[64,     3] loss: 1.387
[65,     3] loss: 1.388
[66,     3] loss: 1.386
[67,     3] loss: 1.386
[68,     3] loss: 1.386
[69,     3] loss: 1.386
[70,     3] loss: 1.385
[71,     3] loss: 1.386
[72,     3] loss: 1.388
[73,     3] loss: 1.387
[74,     3] loss: 1.385
[75,     3] loss: 1.388
[76,     3] loss: 1.386
[77,     3] loss: 1.386
[78,     3] loss: 1.386
[79,     3] loss: 1.387
[80,     3] loss: 1.387
[81,     3] loss: 1.386
[82,     3] loss: 1.386
[83,     3] loss: 1.387
[84,     3] loss: 1.387
[85,     3] loss: 1.386
[86,     3] loss: 1.386
[87,     3] loss: 1.386
[88,     3] loss: 1.387
[89,     3] loss: 1.387
Early stopping applied (best metric=0.5422467589378357)
Finished Training
Total time taken: 24.854291439056396
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.397
[3,     3] loss: 1.392
[4,     3] loss: 1.382
[5,     3] loss: 1.392
[6,     3] loss: 1.387
[7,     3] loss: 1.390
[8,     3] loss: 1.386
[9,     3] loss: 1.384
[10,     3] loss: 1.390
[11,     3] loss: 1.389
[12,     3] loss: 1.385
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.388
[16,     3] loss: 1.387
[17,     3] loss: 1.387
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.388
[24,     3] loss: 1.387
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.385
[31,     3] loss: 1.390
[32,     3] loss: 1.387
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.387
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.387
[44,     3] loss: 1.386
[45,     3] loss: 1.387
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.387
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.385
[54,     3] loss: 1.387
[55,     3] loss: 1.388
Early stopping applied (best metric=0.5453765988349915)
Finished Training
Total time taken: 15.214187622070312
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.393
[3,     3] loss: 1.385
[4,     3] loss: 1.392
[5,     3] loss: 1.384
[6,     3] loss: 1.382
[7,     3] loss: 1.393
[8,     3] loss: 1.383
[9,     3] loss: 1.388
[10,     3] loss: 1.389
[11,     3] loss: 1.387
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.388
[17,     3] loss: 1.387
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.387
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.387
[29,     3] loss: 1.387
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.388
[33,     3] loss: 1.385
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.387
[38,     3] loss: 1.388
[39,     3] loss: 1.386
[40,     3] loss: 1.385
[41,     3] loss: 1.386
[42,     3] loss: 1.382
[43,     3] loss: 1.384
[44,     3] loss: 1.390
[45,     3] loss: 1.384
[46,     3] loss: 1.385
[47,     3] loss: 1.387
[48,     3] loss: 1.387
[49,     3] loss: 1.388
[50,     3] loss: 1.388
[51,     3] loss: 1.386
[52,     3] loss: 1.386
Early stopping applied (best metric=0.5621874332427979)
Finished Training
Total time taken: 14.62366533279419
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.396
[3,     3] loss: 1.387
[4,     3] loss: 1.390
[5,     3] loss: 1.387
[6,     3] loss: 1.386
[7,     3] loss: 1.389
[8,     3] loss: 1.386
[9,     3] loss: 1.385
[10,     3] loss: 1.391
[11,     3] loss: 1.387
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.385
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.388
[24,     3] loss: 1.388
[25,     3] loss: 1.387
[26,     3] loss: 1.386
[27,     3] loss: 1.385
[28,     3] loss: 1.385
[29,     3] loss: 1.388
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.388
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.387
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.383
[41,     3] loss: 1.386
[42,     3] loss: 1.387
[43,     3] loss: 1.387
[44,     3] loss: 1.386
[45,     3] loss: 1.388
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.387
[49,     3] loss: 1.386
[50,     3] loss: 1.387
[51,     3] loss: 1.387
[52,     3] loss: 1.387
[53,     3] loss: 1.387
[54,     3] loss: 1.386
[55,     3] loss: 1.386
[56,     3] loss: 1.387
[57,     3] loss: 1.387
[58,     3] loss: 1.386
[59,     3] loss: 1.387
[60,     3] loss: 1.386
Early stopping applied (best metric=0.5629310607910156)
Finished Training
Total time taken: 16.91718339920044
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.391
[3,     3] loss: 1.394
[4,     3] loss: 1.391
[5,     3] loss: 1.387
[6,     3] loss: 1.385
[7,     3] loss: 1.389
[8,     3] loss: 1.387
[9,     3] loss: 1.386
[10,     3] loss: 1.386
[11,     3] loss: 1.382
[12,     3] loss: 1.390
[13,     3] loss: 1.386
[14,     3] loss: 1.384
[15,     3] loss: 1.382
[16,     3] loss: 1.384
[17,     3] loss: 1.366
[18,     3] loss: 1.322
[19,     3] loss: 1.240
[20,     3] loss: 1.302
[21,     3] loss: 1.145
[22,     3] loss: 1.137
[23,     3] loss: 1.019
[24,     3] loss: 1.217
[25,     3] loss: 1.086
[26,     3] loss: 1.225
[27,     3] loss: 1.204
[28,     3] loss: 1.090
[29,     3] loss: 1.055
[30,     3] loss: 1.146
[31,     3] loss: 1.316
[32,     3] loss: 1.393
[33,     3] loss: 1.346
[34,     3] loss: 1.367
[35,     3] loss: 1.364
[36,     3] loss: 1.333
[37,     3] loss: 1.253
[38,     3] loss: 1.304
[39,     3] loss: 1.204
[40,     3] loss: 1.230
[41,     3] loss: 1.169
[42,     3] loss: 1.227
[43,     3] loss: 1.162
[44,     3] loss: 1.167
[45,     3] loss: 1.086
[46,     3] loss: 1.091
[47,     3] loss: 1.092
[48,     3] loss: 1.017
[49,     3] loss: 1.040
[50,     3] loss: 0.929
[51,     3] loss: 1.039
[52,     3] loss: 1.166
[53,     3] loss: 1.120
[54,     3] loss: 1.086
[55,     3] loss: 1.158
[56,     3] loss: 0.982
[57,     3] loss: 1.049
[58,     3] loss: 1.122
[59,     3] loss: 1.121
[60,     3] loss: 1.118
[61,     3] loss: 1.156
[62,     3] loss: 1.108
[63,     3] loss: 1.031
[64,     3] loss: 0.910
[65,     3] loss: 0.983
[66,     3] loss: 0.969
[67,     3] loss: 1.061
[68,     3] loss: 0.993
[69,     3] loss: 1.280
[70,     3] loss: 1.108
[71,     3] loss: 1.133
[72,     3] loss: 1.007
[73,     3] loss: 0.992
[74,     3] loss: 1.002
[75,     3] loss: 1.079
[76,     3] loss: 1.082
[77,     3] loss: 1.034
[78,     3] loss: 1.049
[79,     3] loss: 1.043
[80,     3] loss: 0.948
[81,     3] loss: 0.972
[82,     3] loss: 0.888
[83,     3] loss: 1.073
[84,     3] loss: 1.164
[85,     3] loss: 1.079
[86,     3] loss: 1.146
[87,     3] loss: 1.144
[88,     3] loss: 1.055
[89,     3] loss: 0.964
[90,     3] loss: 0.993
[91,     3] loss: 0.987
[92,     3] loss: 0.893
[93,     3] loss: 0.902
[94,     3] loss: 0.948
[95,     3] loss: 0.923
[96,     3] loss: 0.958
[97,     3] loss: 0.984
[98,     3] loss: 0.940
[99,     3] loss: 1.030
[100,     3] loss: 0.982
[101,     3] loss: 0.887
[102,     3] loss: 0.841
[103,     3] loss: 0.917
[104,     3] loss: 0.959
[105,     3] loss: 1.002
[106,     3] loss: 0.957
[107,     3] loss: 1.061
[108,     3] loss: 1.159
[109,     3] loss: 1.249
[110,     3] loss: 1.281
[111,     3] loss: 1.317
[112,     3] loss: 1.218
[113,     3] loss: 1.098
[114,     3] loss: 1.099
[115,     3] loss: 1.122
[116,     3] loss: 1.027
[117,     3] loss: 1.120
[118,     3] loss: 1.431
[119,     3] loss: 1.250
[120,     3] loss: 1.292
[121,     3] loss: 1.211
[122,     3] loss: 1.205
[123,     3] loss: 1.138
[124,     3] loss: 1.072
[125,     3] loss: 1.224
[126,     3] loss: 1.037
[127,     3] loss: 0.987
[128,     3] loss: 1.141
[129,     3] loss: 1.247
[130,     3] loss: 1.090
[131,     3] loss: 1.358
[132,     3] loss: 1.236
[133,     3] loss: 1.175
[134,     3] loss: 1.093
[135,     3] loss: 1.116
[136,     3] loss: 1.335
[137,     3] loss: 1.264
[138,     3] loss: 1.314
[139,     3] loss: 1.245
[140,     3] loss: 1.317
[141,     3] loss: 1.226
[142,     3] loss: 1.112
[143,     3] loss: 1.190
[144,     3] loss: 1.066
[145,     3] loss: 1.023
[146,     3] loss: 1.013
[147,     3] loss: 1.084
[148,     3] loss: 1.276
[149,     3] loss: 1.379
[150,     3] loss: 1.292
[151,     3] loss: 1.252
[152,     3] loss: 1.242
[153,     3] loss: 1.234
Early stopping applied (best metric=0.5277725458145142)
Finished Training
Total time taken: 43.23508286476135
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.395
[3,     3] loss: 1.389
[4,     3] loss: 1.394
[5,     3] loss: 1.391
[6,     3] loss: 1.386
[7,     3] loss: 1.386
[8,     3] loss: 1.385
[9,     3] loss: 1.382
[10,     3] loss: 1.385
[11,     3] loss: 1.391
[12,     3] loss: 1.392
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.389
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.387
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.387
[29,     3] loss: 1.388
[30,     3] loss: 1.387
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.388
[36,     3] loss: 1.387
[37,     3] loss: 1.386
[38,     3] loss: 1.387
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.385
[50,     3] loss: 1.388
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.386
Early stopping applied (best metric=0.5453192591667175)
Finished Training
Total time taken: 14.846699476242065
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.389
[3,     3] loss: 1.387
[4,     3] loss: 1.383
[5,     3] loss: 1.388
[6,     3] loss: 1.382
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.384
[10,     3] loss: 1.388
[11,     3] loss: 1.389
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.384
[15,     3] loss: 1.385
[16,     3] loss: 1.384
[17,     3] loss: 1.387
[18,     3] loss: 1.384
[19,     3] loss: 1.384
[20,     3] loss: 1.372
[21,     3] loss: 1.311
[22,     3] loss: 1.178
[23,     3] loss: 1.311
[24,     3] loss: 1.177
[25,     3] loss: 1.206
[26,     3] loss: 1.179
[27,     3] loss: 1.149
[28,     3] loss: 1.188
[29,     3] loss: 1.197
[30,     3] loss: 1.114
[31,     3] loss: 1.023
[32,     3] loss: 1.572
[33,     3] loss: 1.340
[34,     3] loss: 1.712
[35,     3] loss: 1.386
[36,     3] loss: 1.387
[37,     3] loss: 1.386
[38,     3] loss: 1.388
[39,     3] loss: 1.387
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.387
[45,     3] loss: 1.387
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.387
[51,     3] loss: 1.387
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.386
[56,     3] loss: 1.386
[57,     3] loss: 1.386
[58,     3] loss: 1.386
[59,     3] loss: 1.386
[60,     3] loss: 1.386
[61,     3] loss: 1.387
[62,     3] loss: 1.387
[63,     3] loss: 1.386
[64,     3] loss: 1.386
[65,     3] loss: 1.386
[66,     3] loss: 1.386
[67,     3] loss: 1.386
[68,     3] loss: 1.386
[69,     3] loss: 1.386
[70,     3] loss: 1.386
[71,     3] loss: 1.387
[72,     3] loss: 1.386
[73,     3] loss: 1.386
[74,     3] loss: 1.387
[75,     3] loss: 1.386
Early stopping applied (best metric=0.4998975098133087)
Finished Training
Total time taken: 21.408270597457886
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.386
[3,     3] loss: 1.390
[4,     3] loss: 1.397
[5,     3] loss: 1.388
[6,     3] loss: 1.389
[7,     3] loss: 1.386
[8,     3] loss: 1.388
[9,     3] loss: 1.386
[10,     3] loss: 1.385
[11,     3] loss: 1.387
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.387
[15,     3] loss: 1.385
[16,     3] loss: 1.386
[17,     3] loss: 1.385
[18,     3] loss: 1.385
[19,     3] loss: 1.384
[20,     3] loss: 1.384
[21,     3] loss: 1.357
[22,     3] loss: 1.370
[23,     3] loss: 1.327
[24,     3] loss: 1.358
[25,     3] loss: 1.329
[26,     3] loss: 1.350
[27,     3] loss: 1.345
[28,     3] loss: 1.286
[29,     3] loss: 1.259
[30,     3] loss: 1.316
[31,     3] loss: 1.318
[32,     3] loss: 1.327
[33,     3] loss: 1.280
[34,     3] loss: 1.207
[35,     3] loss: 1.140
[36,     3] loss: 1.353
[37,     3] loss: 1.247
[38,     3] loss: 1.281
[39,     3] loss: 1.285
[40,     3] loss: 1.310
[41,     3] loss: 1.417
[42,     3] loss: 1.368
[43,     3] loss: 1.366
[44,     3] loss: 1.364
[45,     3] loss: 1.329
[46,     3] loss: 1.217
[47,     3] loss: 1.309
[48,     3] loss: 1.232
[49,     3] loss: 1.389
[50,     3] loss: 1.354
[51,     3] loss: 1.315
[52,     3] loss: 1.294
[53,     3] loss: 1.260
[54,     3] loss: 1.267
[55,     3] loss: 1.291
[56,     3] loss: 1.292
[57,     3] loss: 1.212
[58,     3] loss: 1.160
[59,     3] loss: 1.134
[60,     3] loss: 1.130
[61,     3] loss: 1.173
[62,     3] loss: 1.095
[63,     3] loss: 1.223
[64,     3] loss: 1.160
[65,     3] loss: 1.109
[66,     3] loss: 1.099
[67,     3] loss: 1.314
[68,     3] loss: 1.113
[69,     3] loss: 1.245
[70,     3] loss: 1.177
[71,     3] loss: 1.232
[72,     3] loss: 1.042
[73,     3] loss: 1.064
[74,     3] loss: 1.088
[75,     3] loss: 1.112
[76,     3] loss: 1.097
[77,     3] loss: 1.073
[78,     3] loss: 1.098
[79,     3] loss: 1.238
[80,     3] loss: 1.247
[81,     3] loss: 1.221
[82,     3] loss: 1.240
[83,     3] loss: 1.207
[84,     3] loss: 1.193
[85,     3] loss: 1.105
[86,     3] loss: 1.109
[87,     3] loss: 1.028
[88,     3] loss: 1.057
[89,     3] loss: 1.217
[90,     3] loss: 1.150
[91,     3] loss: 1.093
[92,     3] loss: 1.194
[93,     3] loss: 1.252
[94,     3] loss: 1.133
[95,     3] loss: 1.140
[96,     3] loss: 1.046
[97,     3] loss: 1.151
[98,     3] loss: 1.125
[99,     3] loss: 1.112
[100,     3] loss: 1.259
[101,     3] loss: 1.289
[102,     3] loss: 1.260
[103,     3] loss: 1.195
[104,     3] loss: 1.081
[105,     3] loss: 1.199
[106,     3] loss: 1.252
[107,     3] loss: 1.211
[108,     3] loss: 1.116
[109,     3] loss: 1.080
[110,     3] loss: 1.129
[111,     3] loss: 1.110
[112,     3] loss: 1.179
[113,     3] loss: 1.123
[114,     3] loss: 1.159
[115,     3] loss: 1.102
[116,     3] loss: 1.202
[117,     3] loss: 1.112
[118,     3] loss: 1.182
[119,     3] loss: 1.094
[120,     3] loss: 1.131
[121,     3] loss: 1.082
[122,     3] loss: 1.061
Early stopping applied (best metric=0.5028419494628906)
Finished Training
Total time taken: 35.14704704284668
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.396
[3,     3] loss: 1.391
[4,     3] loss: 1.395
[5,     3] loss: 1.389
[6,     3] loss: 1.393
[7,     3] loss: 1.387
[8,     3] loss: 1.385
[9,     3] loss: 1.387
[10,     3] loss: 1.383
[11,     3] loss: 1.385
[12,     3] loss: 1.385
[13,     3] loss: 1.385
[14,     3] loss: 1.390
[15,     3] loss: 1.386
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.387
[24,     3] loss: 1.386
[25,     3] loss: 1.387
[26,     3] loss: 1.387
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.387
[30,     3] loss: 1.386
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.387
[34,     3] loss: 1.386
[35,     3] loss: 1.387
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.387
[42,     3] loss: 1.387
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.387
[46,     3] loss: 1.387
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.387
Early stopping applied (best metric=0.5627997517585754)
Finished Training
Total time taken: 15.296106576919556
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.390
[3,     3] loss: 1.385
[4,     3] loss: 1.383
[5,     3] loss: 1.393
[6,     3] loss: 1.383
[7,     3] loss: 1.388
[8,     3] loss: 1.391
[9,     3] loss: 1.382
[10,     3] loss: 1.391
[11,     3] loss: 1.385
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.384
[15,     3] loss: 1.381
[16,     3] loss: 1.354
[17,     3] loss: 1.347
[18,     3] loss: 1.215
[19,     3] loss: 1.303
[20,     3] loss: 1.346
[21,     3] loss: 1.269
[22,     3] loss: 1.266
[23,     3] loss: 1.303
[24,     3] loss: 1.171
[25,     3] loss: 1.135
[26,     3] loss: 1.193
[27,     3] loss: 1.197
[28,     3] loss: 1.245
[29,     3] loss: 1.234
[30,     3] loss: 1.242
[31,     3] loss: 1.229
[32,     3] loss: 1.259
[33,     3] loss: 1.259
[34,     3] loss: 1.242
[35,     3] loss: 1.137
[36,     3] loss: 1.230
[37,     3] loss: 1.128
[38,     3] loss: 1.055
[39,     3] loss: 1.231
[40,     3] loss: 1.078
[41,     3] loss: 1.088
[42,     3] loss: 1.122
[43,     3] loss: 1.140
[44,     3] loss: 1.341
[45,     3] loss: 1.206
[46,     3] loss: 1.188
[47,     3] loss: 1.153
[48,     3] loss: 1.014
[49,     3] loss: 1.095
[50,     3] loss: 1.083
[51,     3] loss: 1.187
[52,     3] loss: 1.208
[53,     3] loss: 1.300
[54,     3] loss: 1.182
[55,     3] loss: 1.143
[56,     3] loss: 1.061
[57,     3] loss: 1.015
[58,     3] loss: 1.280
[59,     3] loss: 1.083
[60,     3] loss: 1.120
[61,     3] loss: 1.066
[62,     3] loss: 1.156
[63,     3] loss: 1.128
[64,     3] loss: 1.137
[65,     3] loss: 1.220
[66,     3] loss: 1.227
[67,     3] loss: 1.200
[68,     3] loss: 1.087
[69,     3] loss: 1.127
[70,     3] loss: 1.306
[71,     3] loss: 1.165
[72,     3] loss: 1.186
[73,     3] loss: 1.160
[74,     3] loss: 1.289
[75,     3] loss: 1.168
[76,     3] loss: 1.112
[77,     3] loss: 1.126
[78,     3] loss: 1.086
[79,     3] loss: 1.124
[80,     3] loss: 1.118
[81,     3] loss: 1.063
[82,     3] loss: 0.991
[83,     3] loss: 1.222
[84,     3] loss: 1.059
[85,     3] loss: 1.029
[86,     3] loss: 1.133
[87,     3] loss: 1.214
[88,     3] loss: 1.229
[89,     3] loss: 1.170
[90,     3] loss: 1.022
[91,     3] loss: 1.159
[92,     3] loss: 1.620
[93,     3] loss: 1.373
[94,     3] loss: 1.385
[95,     3] loss: 1.385
[96,     3] loss: 1.386
[97,     3] loss: 1.385
[98,     3] loss: 1.388
[99,     3] loss: 1.386
[100,     3] loss: 1.387
[101,     3] loss: 1.386
[102,     3] loss: 1.386
[103,     3] loss: 1.386
[104,     3] loss: 1.386
[105,     3] loss: 1.386
[106,     3] loss: 1.387
[107,     3] loss: 1.386
[108,     3] loss: 1.386
[109,     3] loss: 1.387
[110,     3] loss: 1.386
[111,     3] loss: 1.386
[112,     3] loss: 1.386
[113,     3] loss: 1.387
[114,     3] loss: 1.386
[115,     3] loss: 1.386
[116,     3] loss: 1.388
[117,     3] loss: 1.386
[118,     3] loss: 1.386
[119,     3] loss: 1.386
Early stopping applied (best metric=0.5264562964439392)
Finished Training
Total time taken: 35.37324094772339
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.403
[3,     3] loss: 1.398
[4,     3] loss: 1.387
[5,     3] loss: 1.387
[6,     3] loss: 1.387
[7,     3] loss: 1.387
[8,     3] loss: 1.387
[9,     3] loss: 1.387
[10,     3] loss: 1.387
[11,     3] loss: 1.387
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.387
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.387
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.387
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.388
[30,     3] loss: 1.387
[31,     3] loss: 1.386
[32,     3] loss: 1.387
[33,     3] loss: 1.386
[34,     3] loss: 1.385
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.387
[38,     3] loss: 1.385
[39,     3] loss: 1.385
[40,     3] loss: 1.388
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.387
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.386
Early stopping applied (best metric=0.5450978875160217)
Finished Training
Total time taken: 14.888100862503052
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.391
[3,     3] loss: 1.385
[4,     3] loss: 1.389
[5,     3] loss: 1.387
[6,     3] loss: 1.386
[7,     3] loss: 1.386
[8,     3] loss: 1.385
[9,     3] loss: 1.391
[10,     3] loss: 1.385
[11,     3] loss: 1.387
[12,     3] loss: 1.387
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.387
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.387
[26,     3] loss: 1.387
[27,     3] loss: 1.387
[28,     3] loss: 1.387
[29,     3] loss: 1.387
[30,     3] loss: 1.387
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.389
[38,     3] loss: 1.387
[39,     3] loss: 1.387
[40,     3] loss: 1.387
[41,     3] loss: 1.387
[42,     3] loss: 1.387
[43,     3] loss: 1.387
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.387
[50,     3] loss: 1.386
[51,     3] loss: 1.387
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.385
[56,     3] loss: 1.387
[57,     3] loss: 1.387
[58,     3] loss: 1.386
[59,     3] loss: 1.386
[60,     3] loss: 1.387
Early stopping applied (best metric=0.5453983545303345)
Finished Training
Total time taken: 16.78511643409729
{'S-palmitoylation-C Validation Accuracy': 0.4821109829843454, 'S-palmitoylation-C Validation Sensitivity': 0.5353135313531353, 'S-palmitoylation-C Validation Specificity': 0.4687504753737896, 'S-palmitoylation-C Validation Precision': nan, 'S-palmitoylation-C AUC ROC': 0.5198936337691618, 'S-palmitoylation-C AUC PR': 0.21170790868813222, 'S-palmitoylation-C MCC': 0.0035684265649237276, 'S-palmitoylation-C F1': 0.22305168062133546, 'Validation Loss (S-palmitoylation-C)': 0.5556806365648905, 'Hydroxylation-K Validation Accuracy': 0.4817375886524823, 'Hydroxylation-K Validation Sensitivity': 0.7318518518518519, 'Hydroxylation-K Validation Specificity': 0.42280701754385963, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.73, 'Hydroxylation-K AUC PR': 0.47123547559539597, 'Hydroxylation-K MCC': 0.13287952273887307, 'Hydroxylation-K F1': 0.32418924957142936, 'Validation Loss (Hydroxylation-K)': 0.5408598681290945, 'Validation Loss (total)': 1.0965405066808065, 'TimeToTrain': 22.58429069519043}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004014706831209003,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2633032325291122,
 'loss_weight_S-palmitoylation-C': 0.4036135428006255,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2641465764,
 'sample_weights': [0.6558097437911222, 0.8183693098871841],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.978071228788249,
 'weight_decay_Hydroxylation-K': 0.15046781175093837,
 'weight_decay_S-palmitoylation-C': 3.1307316774487925}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.391
[3,     3] loss: 1.388
[4,     3] loss: 1.390
[5,     3] loss: 1.378
[6,     3] loss: 1.385
[7,     3] loss: 1.368
[8,     3] loss: 1.373
[9,     3] loss: 1.349
[10,     3] loss: 1.315
[11,     3] loss: 1.297
[12,     3] loss: 1.267
[13,     3] loss: 1.218
[14,     3] loss: 1.320
[15,     3] loss: 1.279
[16,     3] loss: 1.146
[17,     3] loss: 1.141
[18,     3] loss: 1.059
[19,     3] loss: 1.092
[20,     3] loss: 1.208
[21,     3] loss: 1.213
[22,     3] loss: 1.198
[23,     3] loss: 1.192
[24,     3] loss: 1.161
[25,     3] loss: 1.098
[26,     3] loss: 1.111
[27,     3] loss: 1.019
[28,     3] loss: 1.015
[29,     3] loss: 0.986
[30,     3] loss: 1.027
[31,     3] loss: 0.853
[32,     3] loss: 0.929
[33,     3] loss: 1.025
[34,     3] loss: 0.992
[35,     3] loss: 0.969
[36,     3] loss: 0.942
[37,     3] loss: 0.929
[38,     3] loss: 0.918
[39,     3] loss: 0.832
[40,     3] loss: 0.819
[41,     3] loss: 0.860
[42,     3] loss: 0.932
[43,     3] loss: 0.889
[44,     3] loss: 0.928
[45,     3] loss: 0.891
[46,     3] loss: 0.935
[47,     3] loss: 0.943
[48,     3] loss: 0.935
[49,     3] loss: 0.821
[50,     3] loss: 0.819
[51,     3] loss: 0.877
[52,     3] loss: 0.818
[53,     3] loss: 0.857
[54,     3] loss: 0.827
[55,     3] loss: 0.827
[56,     3] loss: 0.838
[57,     3] loss: 0.773
[58,     3] loss: 0.893
[59,     3] loss: 1.010
[60,     3] loss: 0.903
[61,     3] loss: 0.929
[62,     3] loss: 0.811
[63,     3] loss: 0.786
[64,     3] loss: 0.751
[65,     3] loss: 0.753
[66,     3] loss: 0.762
[67,     3] loss: 0.844
[68,     3] loss: 0.928
[69,     3] loss: 0.770
[70,     3] loss: 0.786
[71,     3] loss: 0.764
[72,     3] loss: 0.811
[73,     3] loss: 1.623
[74,     3] loss: 1.129
[75,     3] loss: 1.080
[76,     3] loss: 1.071
[77,     3] loss: 1.015
[78,     3] loss: 1.033
[79,     3] loss: 0.950
[80,     3] loss: 0.897
[81,     3] loss: 0.901
Early stopping applied (best metric=0.5311497449874878)
Finished Training
Total time taken: 23.86216425895691
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.377
[3,     3] loss: 1.408
[4,     3] loss: 1.384
[5,     3] loss: 1.389
[6,     3] loss: 1.382
[7,     3] loss: 1.382
[8,     3] loss: 1.382
[9,     3] loss: 1.377
[10,     3] loss: 1.360
[11,     3] loss: 1.374
[12,     3] loss: 1.354
[13,     3] loss: 1.322
[14,     3] loss: 1.341
[15,     3] loss: 1.243
[16,     3] loss: 1.220
[17,     3] loss: 1.173
[18,     3] loss: 1.235
[19,     3] loss: 1.146
[20,     3] loss: 1.122
[21,     3] loss: 1.104
[22,     3] loss: 1.130
[23,     3] loss: 1.125
[24,     3] loss: 1.067
[25,     3] loss: 1.091
[26,     3] loss: 1.156
[27,     3] loss: 1.055
[28,     3] loss: 1.009
[29,     3] loss: 0.948
[30,     3] loss: 1.083
[31,     3] loss: 0.987
[32,     3] loss: 1.001
[33,     3] loss: 0.975
[34,     3] loss: 1.153
[35,     3] loss: 1.043
[36,     3] loss: 0.915
[37,     3] loss: 1.005
[38,     3] loss: 0.882
[39,     3] loss: 1.030
[40,     3] loss: 0.843
[41,     3] loss: 0.880
[42,     3] loss: 0.821
[43,     3] loss: 1.230
[44,     3] loss: 0.997
[45,     3] loss: 0.957
[46,     3] loss: 0.918
[47,     3] loss: 1.019
[48,     3] loss: 0.933
[49,     3] loss: 0.938
[50,     3] loss: 0.843
[51,     3] loss: 0.865
[52,     3] loss: 0.851
[53,     3] loss: 0.803
[54,     3] loss: 0.898
[55,     3] loss: 0.992
[56,     3] loss: 1.151
[57,     3] loss: 0.948
[58,     3] loss: 0.888
[59,     3] loss: 0.928
[60,     3] loss: 0.829
[61,     3] loss: 0.784
[62,     3] loss: 0.786
[63,     3] loss: 0.778
[64,     3] loss: 0.806
[65,     3] loss: 0.763
[66,     3] loss: 0.741
[67,     3] loss: 0.845
[68,     3] loss: 0.852
[69,     3] loss: 0.814
[70,     3] loss: 1.115
[71,     3] loss: 0.990
[72,     3] loss: 1.005
Early stopping applied (best metric=0.5237419605255127)
Finished Training
Total time taken: 21.387147426605225
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.389
[3,     3] loss: 1.385
[4,     3] loss: 1.387
[5,     3] loss: 1.406
[6,     3] loss: 1.376
[7,     3] loss: 1.368
[8,     3] loss: 1.348
[9,     3] loss: 1.327
[10,     3] loss: 1.317
[11,     3] loss: 1.238
[12,     3] loss: 1.240
[13,     3] loss: 1.142
[14,     3] loss: 1.235
[15,     3] loss: 1.078
[16,     3] loss: 1.020
[17,     3] loss: 1.060
[18,     3] loss: 1.042
[19,     3] loss: 1.084
[20,     3] loss: 1.026
[21,     3] loss: 1.045
[22,     3] loss: 1.020
[23,     3] loss: 1.049
[24,     3] loss: 1.085
[25,     3] loss: 0.915
[26,     3] loss: 0.929
[27,     3] loss: 0.850
[28,     3] loss: 0.863
[29,     3] loss: 0.883
[30,     3] loss: 1.071
[31,     3] loss: 0.944
[32,     3] loss: 0.899
[33,     3] loss: 0.859
[34,     3] loss: 0.893
[35,     3] loss: 0.894
[36,     3] loss: 0.879
[37,     3] loss: 0.937
[38,     3] loss: 1.143
[39,     3] loss: 1.047
[40,     3] loss: 0.988
[41,     3] loss: 0.946
[42,     3] loss: 0.987
[43,     3] loss: 0.882
[44,     3] loss: 0.855
[45,     3] loss: 0.909
[46,     3] loss: 0.867
[47,     3] loss: 0.792
[48,     3] loss: 0.906
[49,     3] loss: 0.983
[50,     3] loss: 0.918
[51,     3] loss: 0.831
[52,     3] loss: 0.851
[53,     3] loss: 0.904
[54,     3] loss: 0.818
[55,     3] loss: 0.801
[56,     3] loss: 0.748
[57,     3] loss: 0.770
[58,     3] loss: 0.731
[59,     3] loss: 0.746
[60,     3] loss: 0.733
[61,     3] loss: 0.781
[62,     3] loss: 0.713
[63,     3] loss: 0.752
[64,     3] loss: 0.747
[65,     3] loss: 0.802
Early stopping applied (best metric=0.5360476970672607)
Finished Training
Total time taken: 18.4631290435791
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.383
[3,     3] loss: 1.388
[4,     3] loss: 1.387
[5,     3] loss: 1.399
[6,     3] loss: 1.387
[7,     3] loss: 1.381
[8,     3] loss: 1.369
[9,     3] loss: 1.370
[10,     3] loss: 1.377
[11,     3] loss: 1.350
[12,     3] loss: 1.288
[13,     3] loss: 1.203
[14,     3] loss: 1.213
[15,     3] loss: 1.253
[16,     3] loss: 1.097
[17,     3] loss: 1.140
[18,     3] loss: 1.061
[19,     3] loss: 1.113
[20,     3] loss: 1.046
[21,     3] loss: 1.083
[22,     3] loss: 1.195
[23,     3] loss: 1.122
[24,     3] loss: 1.039
[25,     3] loss: 1.082
[26,     3] loss: 1.023
[27,     3] loss: 0.969
[28,     3] loss: 1.008
[29,     3] loss: 1.021
[30,     3] loss: 1.024
[31,     3] loss: 0.952
[32,     3] loss: 0.974
[33,     3] loss: 1.152
[34,     3] loss: 0.935
[35,     3] loss: 1.084
[36,     3] loss: 1.145
[37,     3] loss: 0.911
[38,     3] loss: 1.028
[39,     3] loss: 0.941
[40,     3] loss: 0.826
[41,     3] loss: 0.856
[42,     3] loss: 0.908
[43,     3] loss: 0.988
[44,     3] loss: 1.014
[45,     3] loss: 0.980
[46,     3] loss: 0.892
[47,     3] loss: 0.879
[48,     3] loss: 0.829
[49,     3] loss: 0.775
[50,     3] loss: 0.816
[51,     3] loss: 1.111
[52,     3] loss: 1.193
[53,     3] loss: 1.011
[54,     3] loss: 1.120
[55,     3] loss: 1.157
[56,     3] loss: 1.143
[57,     3] loss: 1.040
[58,     3] loss: 1.063
[59,     3] loss: 1.036
[60,     3] loss: 1.029
[61,     3] loss: 0.939
[62,     3] loss: 0.832
[63,     3] loss: 1.205
[64,     3] loss: 0.959
[65,     3] loss: 0.886
[66,     3] loss: 0.993
[67,     3] loss: 0.859
[68,     3] loss: 0.801
[69,     3] loss: 0.885
[70,     3] loss: 1.001
[71,     3] loss: 0.830
[72,     3] loss: 0.807
[73,     3] loss: 0.772
[74,     3] loss: 0.785
[75,     3] loss: 0.763
[76,     3] loss: 0.759
[77,     3] loss: 0.811
[78,     3] loss: 0.793
[79,     3] loss: 0.891
[80,     3] loss: 0.868
[81,     3] loss: 0.824
[82,     3] loss: 0.889
[83,     3] loss: 0.781
[84,     3] loss: 0.755
[85,     3] loss: 0.831
[86,     3] loss: 0.840
[87,     3] loss: 0.911
[88,     3] loss: 1.408
[89,     3] loss: 1.168
[90,     3] loss: 1.115
[91,     3] loss: 1.033
[92,     3] loss: 0.860
[93,     3] loss: 0.905
Early stopping applied (best metric=0.5014620423316956)
Finished Training
Total time taken: 27.75519371032715
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.388
[3,     3] loss: 1.392
[4,     3] loss: 1.391
[5,     3] loss: 1.389
[6,     3] loss: 1.387
[7,     3] loss: 1.378
[8,     3] loss: 1.387
[9,     3] loss: 1.380
[10,     3] loss: 1.387
[11,     3] loss: 1.381
[12,     3] loss: 1.383
[13,     3] loss: 1.379
[14,     3] loss: 1.372
[15,     3] loss: 1.361
[16,     3] loss: 1.350
[17,     3] loss: 1.295
[18,     3] loss: 1.242
[19,     3] loss: 1.279
[20,     3] loss: 1.254
[21,     3] loss: 1.196
[22,     3] loss: 1.142
[23,     3] loss: 1.139
[24,     3] loss: 1.217
[25,     3] loss: 1.118
[26,     3] loss: 1.064
[27,     3] loss: 1.158
[28,     3] loss: 1.102
[29,     3] loss: 1.017
[30,     3] loss: 1.065
[31,     3] loss: 1.145
[32,     3] loss: 1.146
[33,     3] loss: 1.105
[34,     3] loss: 1.032
[35,     3] loss: 1.028
[36,     3] loss: 0.960
[37,     3] loss: 1.079
[38,     3] loss: 0.961
[39,     3] loss: 0.904
[40,     3] loss: 0.911
[41,     3] loss: 0.859
[42,     3] loss: 0.960
[43,     3] loss: 1.000
[44,     3] loss: 0.863
[45,     3] loss: 0.941
[46,     3] loss: 0.927
[47,     3] loss: 0.899
[48,     3] loss: 0.894
[49,     3] loss: 0.926
[50,     3] loss: 0.803
[51,     3] loss: 0.943
[52,     3] loss: 0.866
[53,     3] loss: 0.831
[54,     3] loss: 1.151
[55,     3] loss: 0.861
[56,     3] loss: 0.885
[57,     3] loss: 0.861
[58,     3] loss: 0.822
[59,     3] loss: 0.844
[60,     3] loss: 0.771
[61,     3] loss: 0.905
[62,     3] loss: 0.953
[63,     3] loss: 0.916
[64,     3] loss: 0.862
[65,     3] loss: 0.784
[66,     3] loss: 0.845
[67,     3] loss: 0.814
[68,     3] loss: 0.818
[69,     3] loss: 0.744
[70,     3] loss: 0.763
[71,     3] loss: 1.015
[72,     3] loss: 0.781
[73,     3] loss: 0.851
[74,     3] loss: 0.836
[75,     3] loss: 0.786
[76,     3] loss: 0.798
[77,     3] loss: 0.763
[78,     3] loss: 0.744
[79,     3] loss: 0.742
[80,     3] loss: 0.722
[81,     3] loss: 0.711
Early stopping applied (best metric=0.5310210585594177)
Finished Training
Total time taken: 23.88516354560852
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.382
[3,     3] loss: 1.393
[4,     3] loss: 1.392
[5,     3] loss: 1.391
[6,     3] loss: 1.385
[7,     3] loss: 1.378
[8,     3] loss: 1.379
[9,     3] loss: 1.374
[10,     3] loss: 1.364
[11,     3] loss: 1.348
[12,     3] loss: 1.332
[13,     3] loss: 1.274
[14,     3] loss: 1.238
[15,     3] loss: 1.250
[16,     3] loss: 1.372
[17,     3] loss: 1.167
[18,     3] loss: 1.121
[19,     3] loss: 1.247
[20,     3] loss: 1.162
[21,     3] loss: 1.115
[22,     3] loss: 1.085
[23,     3] loss: 1.186
[24,     3] loss: 1.049
[25,     3] loss: 1.026
[26,     3] loss: 1.093
[27,     3] loss: 0.974
[28,     3] loss: 1.005
[29,     3] loss: 0.915
[30,     3] loss: 0.979
[31,     3] loss: 1.005
[32,     3] loss: 0.948
[33,     3] loss: 0.912
[34,     3] loss: 0.843
[35,     3] loss: 0.870
[36,     3] loss: 0.976
[37,     3] loss: 0.946
[38,     3] loss: 0.913
[39,     3] loss: 0.894
[40,     3] loss: 0.844
[41,     3] loss: 0.818
[42,     3] loss: 0.862
[43,     3] loss: 0.972
[44,     3] loss: 0.958
[45,     3] loss: 0.873
[46,     3] loss: 0.889
[47,     3] loss: 0.877
[48,     3] loss: 0.822
[49,     3] loss: 0.770
[50,     3] loss: 0.741
[51,     3] loss: 0.873
[52,     3] loss: 0.855
[53,     3] loss: 0.747
[54,     3] loss: 0.877
[55,     3] loss: 0.799
[56,     3] loss: 0.859
[57,     3] loss: 0.785
[58,     3] loss: 0.813
[59,     3] loss: 0.763
[60,     3] loss: 0.787
[61,     3] loss: 0.765
[62,     3] loss: 0.740
[63,     3] loss: 0.778
[64,     3] loss: 0.752
[65,     3] loss: 0.724
[66,     3] loss: 0.731
[67,     3] loss: 0.742
[68,     3] loss: 0.716
[69,     3] loss: 0.711
[70,     3] loss: 0.710
[71,     3] loss: 0.742
[72,     3] loss: 1.063
[73,     3] loss: 1.000
[74,     3] loss: 0.969
[75,     3] loss: 0.899
[76,     3] loss: 0.965
[77,     3] loss: 1.095
[78,     3] loss: 1.174
[79,     3] loss: 0.997
[80,     3] loss: 1.049
[81,     3] loss: 0.960
[82,     3] loss: 0.829
[83,     3] loss: 0.861
Early stopping applied (best metric=0.5282132625579834)
Finished Training
Total time taken: 24.860169649124146
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.389
[3,     3] loss: 1.383
[4,     3] loss: 1.383
[5,     3] loss: 1.392
[6,     3] loss: 1.391
[7,     3] loss: 1.383
[8,     3] loss: 1.388
[9,     3] loss: 1.389
[10,     3] loss: 1.384
[11,     3] loss: 1.383
[12,     3] loss: 1.384
[13,     3] loss: 1.374
[14,     3] loss: 1.379
[15,     3] loss: 1.346
[16,     3] loss: 1.325
[17,     3] loss: 1.295
[18,     3] loss: 1.220
[19,     3] loss: 1.303
[20,     3] loss: 1.300
[21,     3] loss: 1.245
[22,     3] loss: 1.229
[23,     3] loss: 1.193
[24,     3] loss: 1.139
[25,     3] loss: 1.221
[26,     3] loss: 1.222
[27,     3] loss: 1.145
[28,     3] loss: 1.018
[29,     3] loss: 1.036
[30,     3] loss: 1.029
[31,     3] loss: 1.071
[32,     3] loss: 1.013
[33,     3] loss: 1.126
[34,     3] loss: 1.090
[35,     3] loss: 1.057
[36,     3] loss: 0.955
[37,     3] loss: 0.911
[38,     3] loss: 1.017
[39,     3] loss: 0.877
[40,     3] loss: 1.091
[41,     3] loss: 0.986
[42,     3] loss: 0.938
[43,     3] loss: 0.968
[44,     3] loss: 0.952
[45,     3] loss: 0.936
[46,     3] loss: 0.844
[47,     3] loss: 0.959
[48,     3] loss: 0.922
[49,     3] loss: 1.043
[50,     3] loss: 0.887
[51,     3] loss: 0.886
[52,     3] loss: 0.898
[53,     3] loss: 0.813
[54,     3] loss: 0.830
[55,     3] loss: 0.813
[56,     3] loss: 0.794
[57,     3] loss: 0.871
[58,     3] loss: 0.939
[59,     3] loss: 1.004
[60,     3] loss: 0.943
[61,     3] loss: 0.940
[62,     3] loss: 0.906
[63,     3] loss: 0.883
[64,     3] loss: 0.820
[65,     3] loss: 0.812
[66,     3] loss: 0.817
[67,     3] loss: 0.892
[68,     3] loss: 0.829
[69,     3] loss: 0.818
[70,     3] loss: 0.775
[71,     3] loss: 0.741
[72,     3] loss: 0.730
[73,     3] loss: 0.727
[74,     3] loss: 0.718
[75,     3] loss: 0.759
[76,     3] loss: 1.092
[77,     3] loss: 0.898
[78,     3] loss: 1.025
[79,     3] loss: 1.014
[80,     3] loss: 1.089
[81,     3] loss: 0.913
[82,     3] loss: 0.872
Early stopping applied (best metric=0.5376464128494263)
Finished Training
Total time taken: 23.69167423248291
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.382
[3,     3] loss: 1.399
[4,     3] loss: 1.384
[5,     3] loss: 1.383
[6,     3] loss: 1.391
[7,     3] loss: 1.386
[8,     3] loss: 1.385
[9,     3] loss: 1.383
[10,     3] loss: 1.377
[11,     3] loss: 1.378
[12,     3] loss: 1.395
[13,     3] loss: 1.354
[14,     3] loss: 1.340
[15,     3] loss: 1.294
[16,     3] loss: 1.220
[17,     3] loss: 1.260
[18,     3] loss: 1.256
[19,     3] loss: 1.201
[20,     3] loss: 1.154
[21,     3] loss: 1.131
[22,     3] loss: 1.253
[23,     3] loss: 1.174
[24,     3] loss: 1.191
[25,     3] loss: 1.123
[26,     3] loss: 1.109
[27,     3] loss: 1.147
[28,     3] loss: 0.993
[29,     3] loss: 1.027
[30,     3] loss: 0.997
[31,     3] loss: 0.970
[32,     3] loss: 1.038
[33,     3] loss: 0.928
[34,     3] loss: 0.835
[35,     3] loss: 0.947
[36,     3] loss: 0.835
[37,     3] loss: 0.858
[38,     3] loss: 0.960
[39,     3] loss: 1.022
[40,     3] loss: 0.840
[41,     3] loss: 0.917
[42,     3] loss: 0.863
[43,     3] loss: 0.922
[44,     3] loss: 0.794
[45,     3] loss: 0.815
[46,     3] loss: 0.843
[47,     3] loss: 1.076
[48,     3] loss: 1.071
[49,     3] loss: 1.135
[50,     3] loss: 0.970
[51,     3] loss: 0.965
[52,     3] loss: 0.856
[53,     3] loss: 0.885
[54,     3] loss: 0.805
[55,     3] loss: 0.791
[56,     3] loss: 0.833
[57,     3] loss: 0.772
[58,     3] loss: 0.757
[59,     3] loss: 0.812
[60,     3] loss: 0.831
[61,     3] loss: 0.898
[62,     3] loss: 0.812
[63,     3] loss: 0.879
[64,     3] loss: 0.778
[65,     3] loss: 0.766
[66,     3] loss: 0.953
[67,     3] loss: 0.809
[68,     3] loss: 0.902
[69,     3] loss: 0.922
[70,     3] loss: 0.855
[71,     3] loss: 0.798
[72,     3] loss: 0.886
[73,     3] loss: 0.829
[74,     3] loss: 0.945
[75,     3] loss: 0.904
[76,     3] loss: 0.923
[77,     3] loss: 0.878
[78,     3] loss: 0.804
Early stopping applied (best metric=0.544603705406189)
Finished Training
Total time taken: 21.96315360069275
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.413
[3,     3] loss: 1.390
[4,     3] loss: 1.394
[5,     3] loss: 1.383
[6,     3] loss: 1.389
[7,     3] loss: 1.382
[8,     3] loss: 1.389
[9,     3] loss: 1.385
[10,     3] loss: 1.395
[11,     3] loss: 1.390
[12,     3] loss: 1.381
[13,     3] loss: 1.383
[14,     3] loss: 1.376
[15,     3] loss: 1.385
[16,     3] loss: 1.385
[17,     3] loss: 1.406
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.384
[21,     3] loss: 1.388
[22,     3] loss: 1.383
[23,     3] loss: 1.382
[24,     3] loss: 1.378
[25,     3] loss: 1.372
[26,     3] loss: 1.351
[27,     3] loss: 1.273
[28,     3] loss: 1.308
[29,     3] loss: 1.222
[30,     3] loss: 1.120
[31,     3] loss: 1.316
[32,     3] loss: 1.163
[33,     3] loss: 1.144
[34,     3] loss: 1.109
[35,     3] loss: 1.052
[36,     3] loss: 1.074
[37,     3] loss: 1.220
[38,     3] loss: 1.065
[39,     3] loss: 1.028
[40,     3] loss: 1.081
[41,     3] loss: 1.025
[42,     3] loss: 0.962
[43,     3] loss: 0.966
[44,     3] loss: 1.070
[45,     3] loss: 1.077
[46,     3] loss: 0.957
[47,     3] loss: 1.032
[48,     3] loss: 0.980
[49,     3] loss: 1.024
[50,     3] loss: 0.956
[51,     3] loss: 0.984
[52,     3] loss: 0.962
[53,     3] loss: 0.935
[54,     3] loss: 1.107
[55,     3] loss: 1.021
[56,     3] loss: 1.025
[57,     3] loss: 1.032
[58,     3] loss: 0.936
[59,     3] loss: 0.893
[60,     3] loss: 0.836
[61,     3] loss: 0.925
[62,     3] loss: 0.878
[63,     3] loss: 0.839
[64,     3] loss: 0.826
[65,     3] loss: 0.859
[66,     3] loss: 0.805
[67,     3] loss: 0.852
[68,     3] loss: 0.786
[69,     3] loss: 0.861
[70,     3] loss: 0.848
[71,     3] loss: 0.889
[72,     3] loss: 0.871
[73,     3] loss: 0.894
[74,     3] loss: 0.814
[75,     3] loss: 0.823
[76,     3] loss: 0.802
[77,     3] loss: 0.778
[78,     3] loss: 0.770
[79,     3] loss: 0.741
[80,     3] loss: 0.747
[81,     3] loss: 1.046
[82,     3] loss: 0.900
[83,     3] loss: 0.841
[84,     3] loss: 0.978
[85,     3] loss: 0.911
[86,     3] loss: 0.832
[87,     3] loss: 0.819
[88,     3] loss: 0.811
[89,     3] loss: 0.782
[90,     3] loss: 0.797
[91,     3] loss: 0.863
[92,     3] loss: 1.052
[93,     3] loss: 0.991
[94,     3] loss: 0.954
[95,     3] loss: 0.994
[96,     3] loss: 0.908
[97,     3] loss: 0.835
[98,     3] loss: 0.774
[99,     3] loss: 0.773
[100,     3] loss: 0.820
[101,     3] loss: 1.734
[102,     3] loss: 1.257
[103,     3] loss: 1.284
[104,     3] loss: 1.250
[105,     3] loss: 1.226
[106,     3] loss: 1.140
[107,     3] loss: 1.087
[108,     3] loss: 0.973
[109,     3] loss: 0.913
[110,     3] loss: 1.070
[111,     3] loss: 0.913
[112,     3] loss: 0.870
Early stopping applied (best metric=0.5054512023925781)
Finished Training
Total time taken: 32.110222816467285
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.396
[3,     3] loss: 1.387
[4,     3] loss: 1.390
[5,     3] loss: 1.380
[6,     3] loss: 1.380
[7,     3] loss: 1.377
[8,     3] loss: 1.402
[9,     3] loss: 1.391
[10,     3] loss: 1.382
[11,     3] loss: 1.389
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.383
[15,     3] loss: 1.383
[16,     3] loss: 1.353
[17,     3] loss: 1.360
[18,     3] loss: 1.304
[19,     3] loss: 1.280
[20,     3] loss: 1.209
[21,     3] loss: 1.264
[22,     3] loss: 1.258
[23,     3] loss: 1.204
[24,     3] loss: 1.156
[25,     3] loss: 1.138
[26,     3] loss: 1.094
[27,     3] loss: 1.069
[28,     3] loss: 1.105
[29,     3] loss: 1.006
[30,     3] loss: 1.064
[31,     3] loss: 1.225
[32,     3] loss: 1.099
[33,     3] loss: 1.011
[34,     3] loss: 1.047
[35,     3] loss: 0.963
[36,     3] loss: 0.974
[37,     3] loss: 0.937
[38,     3] loss: 0.937
[39,     3] loss: 0.890
[40,     3] loss: 0.870
[41,     3] loss: 0.928
[42,     3] loss: 0.864
[43,     3] loss: 0.860
[44,     3] loss: 0.862
[45,     3] loss: 0.839
[46,     3] loss: 1.060
[47,     3] loss: 0.998
[48,     3] loss: 0.995
[49,     3] loss: 0.970
[50,     3] loss: 0.894
[51,     3] loss: 0.927
[52,     3] loss: 0.830
[53,     3] loss: 0.872
[54,     3] loss: 0.833
[55,     3] loss: 0.849
[56,     3] loss: 0.791
[57,     3] loss: 0.808
[58,     3] loss: 0.788
[59,     3] loss: 0.845
[60,     3] loss: 0.851
[61,     3] loss: 0.982
[62,     3] loss: 0.887
[63,     3] loss: 0.950
[64,     3] loss: 0.838
[65,     3] loss: 0.870
[66,     3] loss: 0.849
[67,     3] loss: 0.872
[68,     3] loss: 0.769
[69,     3] loss: 0.756
[70,     3] loss: 0.729
[71,     3] loss: 0.751
[72,     3] loss: 0.908
[73,     3] loss: 0.875
[74,     3] loss: 0.916
[75,     3] loss: 0.902
[76,     3] loss: 0.892
[77,     3] loss: 0.863
[78,     3] loss: 0.890
[79,     3] loss: 0.813
[80,     3] loss: 0.831
[81,     3] loss: 0.750
[82,     3] loss: 0.753
[83,     3] loss: 0.727
[84,     3] loss: 0.718
[85,     3] loss: 0.799
[86,     3] loss: 1.014
[87,     3] loss: 0.863
[88,     3] loss: 0.899
[89,     3] loss: 0.903
[90,     3] loss: 0.801
[91,     3] loss: 0.895
[92,     3] loss: 0.790
[93,     3] loss: 0.761
[94,     3] loss: 0.759
[95,     3] loss: 0.777
[96,     3] loss: 0.735
[97,     3] loss: 0.746
[98,     3] loss: 0.759
[99,     3] loss: 0.759
[100,     3] loss: 1.078
[101,     3] loss: 0.910
[102,     3] loss: 0.955
[103,     3] loss: 1.031
Early stopping applied (best metric=0.510161280632019)
Finished Training
Total time taken: 29.97120690345764
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.377
[3,     3] loss: 1.381
[4,     3] loss: 1.385
[5,     3] loss: 1.393
[6,     3] loss: 1.380
[7,     3] loss: 1.382
[8,     3] loss: 1.380
[9,     3] loss: 1.365
[10,     3] loss: 1.338
[11,     3] loss: 1.364
[12,     3] loss: 1.293
[13,     3] loss: 1.243
[14,     3] loss: 1.285
[15,     3] loss: 1.152
[16,     3] loss: 1.195
[17,     3] loss: 1.245
[18,     3] loss: 1.144
[19,     3] loss: 1.206
[20,     3] loss: 1.059
[21,     3] loss: 1.110
[22,     3] loss: 1.181
[23,     3] loss: 1.044
[24,     3] loss: 1.020
[25,     3] loss: 0.971
[26,     3] loss: 1.018
[27,     3] loss: 1.027
[28,     3] loss: 0.952
[29,     3] loss: 0.891
[30,     3] loss: 0.899
[31,     3] loss: 0.824
[32,     3] loss: 0.829
[33,     3] loss: 0.990
[34,     3] loss: 1.022
[35,     3] loss: 1.175
[36,     3] loss: 1.034
[37,     3] loss: 0.996
[38,     3] loss: 1.036
[39,     3] loss: 0.940
[40,     3] loss: 0.909
[41,     3] loss: 0.888
[42,     3] loss: 0.892
[43,     3] loss: 0.783
[44,     3] loss: 0.795
[45,     3] loss: 0.858
[46,     3] loss: 1.016
[47,     3] loss: 0.893
[48,     3] loss: 0.846
[49,     3] loss: 0.787
[50,     3] loss: 0.839
[51,     3] loss: 0.857
[52,     3] loss: 0.779
[53,     3] loss: 0.754
[54,     3] loss: 0.809
[55,     3] loss: 0.801
[56,     3] loss: 0.737
[57,     3] loss: 0.720
[58,     3] loss: 0.707
[59,     3] loss: 0.738
[60,     3] loss: 0.716
[61,     3] loss: 0.718
[62,     3] loss: 0.731
[63,     3] loss: 0.733
[64,     3] loss: 0.739
[65,     3] loss: 0.933
[66,     3] loss: 0.800
[67,     3] loss: 0.754
[68,     3] loss: 0.755
[69,     3] loss: 0.785
[70,     3] loss: 0.763
[71,     3] loss: 0.761
[72,     3] loss: 0.747
[73,     3] loss: 0.724
[74,     3] loss: 0.838
[75,     3] loss: 0.740
[76,     3] loss: 0.745
[77,     3] loss: 0.721
Early stopping applied (best metric=0.5437521934509277)
Finished Training
Total time taken: 22.90715980529785
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.368
[3,     3] loss: 1.397
[4,     3] loss: 1.385
[5,     3] loss: 1.386
[6,     3] loss: 1.382
[7,     3] loss: 1.374
[8,     3] loss: 1.380
[9,     3] loss: 1.360
[10,     3] loss: 1.340
[11,     3] loss: 1.347
[12,     3] loss: 1.341
[13,     3] loss: 1.244
[14,     3] loss: 1.231
[15,     3] loss: 1.187
[16,     3] loss: 1.125
[17,     3] loss: 1.106
[18,     3] loss: 1.126
[19,     3] loss: 1.107
[20,     3] loss: 1.113
[21,     3] loss: 1.221
[22,     3] loss: 1.312
[23,     3] loss: 1.104
[24,     3] loss: 1.238
[25,     3] loss: 1.036
[26,     3] loss: 0.993
[27,     3] loss: 1.170
[28,     3] loss: 0.953
[29,     3] loss: 0.947
[30,     3] loss: 0.922
[31,     3] loss: 0.953
[32,     3] loss: 0.928
[33,     3] loss: 1.105
[34,     3] loss: 0.934
[35,     3] loss: 0.916
[36,     3] loss: 1.007
[37,     3] loss: 0.871
[38,     3] loss: 1.161
[39,     3] loss: 0.997
[40,     3] loss: 0.922
[41,     3] loss: 0.906
[42,     3] loss: 0.909
[43,     3] loss: 0.848
[44,     3] loss: 0.793
[45,     3] loss: 0.812
[46,     3] loss: 0.794
[47,     3] loss: 0.804
[48,     3] loss: 0.797
[49,     3] loss: 0.796
[50,     3] loss: 0.784
[51,     3] loss: 1.008
[52,     3] loss: 0.901
[53,     3] loss: 0.862
[54,     3] loss: 0.851
[55,     3] loss: 0.808
[56,     3] loss: 0.833
[57,     3] loss: 0.934
[58,     3] loss: 0.819
[59,     3] loss: 0.884
[60,     3] loss: 0.802
[61,     3] loss: 0.852
[62,     3] loss: 0.772
[63,     3] loss: 0.776
[64,     3] loss: 0.881
[65,     3] loss: 0.881
[66,     3] loss: 0.997
[67,     3] loss: 1.002
[68,     3] loss: 1.126
[69,     3] loss: 1.004
[70,     3] loss: 0.978
[71,     3] loss: 0.948
[72,     3] loss: 0.847
[73,     3] loss: 0.795
[74,     3] loss: 0.743
[75,     3] loss: 0.728
[76,     3] loss: 0.737
[77,     3] loss: 0.738
[78,     3] loss: 0.736
[79,     3] loss: 0.716
[80,     3] loss: 0.729
[81,     3] loss: 0.768
[82,     3] loss: 0.957
[83,     3] loss: 0.801
[84,     3] loss: 1.060
[85,     3] loss: 0.974
[86,     3] loss: 0.907
[87,     3] loss: 0.917
[88,     3] loss: 0.916
[89,     3] loss: 0.870
[90,     3] loss: 0.850
[91,     3] loss: 0.820
[92,     3] loss: 0.788
[93,     3] loss: 0.798
[94,     3] loss: 0.756
Early stopping applied (best metric=0.5315479636192322)
Finished Training
Total time taken: 27.63218855857849
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.396
[3,     3] loss: 1.388
[4,     3] loss: 1.384
[5,     3] loss: 1.383
[6,     3] loss: 1.371
[7,     3] loss: 1.370
[8,     3] loss: 1.384
[9,     3] loss: 1.395
[10,     3] loss: 1.375
[11,     3] loss: 1.361
[12,     3] loss: 1.373
[13,     3] loss: 1.374
[14,     3] loss: 1.373
[15,     3] loss: 1.355
[16,     3] loss: 1.275
[17,     3] loss: 1.220
[18,     3] loss: 1.177
[19,     3] loss: 1.243
[20,     3] loss: 1.131
[21,     3] loss: 1.309
[22,     3] loss: 1.161
[23,     3] loss: 1.155
[24,     3] loss: 1.174
[25,     3] loss: 1.153
[26,     3] loss: 1.101
[27,     3] loss: 1.085
[28,     3] loss: 1.068
[29,     3] loss: 1.027
[30,     3] loss: 1.080
[31,     3] loss: 0.986
[32,     3] loss: 0.995
[33,     3] loss: 0.954
[34,     3] loss: 1.021
[35,     3] loss: 1.000
[36,     3] loss: 1.156
[37,     3] loss: 1.099
[38,     3] loss: 0.988
[39,     3] loss: 0.964
[40,     3] loss: 0.881
[41,     3] loss: 1.021
[42,     3] loss: 0.848
[43,     3] loss: 0.819
[44,     3] loss: 0.972
[45,     3] loss: 0.948
[46,     3] loss: 1.009
[47,     3] loss: 1.008
[48,     3] loss: 0.894
[49,     3] loss: 0.891
[50,     3] loss: 0.847
[51,     3] loss: 0.925
[52,     3] loss: 0.816
[53,     3] loss: 0.917
[54,     3] loss: 0.803
[55,     3] loss: 1.008
[56,     3] loss: 0.924
[57,     3] loss: 1.122
[58,     3] loss: 1.232
[59,     3] loss: 1.051
[60,     3] loss: 1.001
[61,     3] loss: 0.956
[62,     3] loss: 0.898
[63,     3] loss: 0.840
[64,     3] loss: 0.862
[65,     3] loss: 0.813
[66,     3] loss: 0.765
[67,     3] loss: 0.759
[68,     3] loss: 0.789
[69,     3] loss: 0.748
[70,     3] loss: 0.774
[71,     3] loss: 1.079
[72,     3] loss: 0.789
[73,     3] loss: 0.832
[74,     3] loss: 0.817
[75,     3] loss: 0.752
[76,     3] loss: 0.832
[77,     3] loss: 0.812
[78,     3] loss: 1.119
[79,     3] loss: 1.002
[80,     3] loss: 0.976
[81,     3] loss: 0.967
[82,     3] loss: 0.989
[83,     3] loss: 0.916
[84,     3] loss: 0.843
[85,     3] loss: 0.757
[86,     3] loss: 0.815
[87,     3] loss: 0.784
[88,     3] loss: 0.876
[89,     3] loss: 0.835
[90,     3] loss: 0.860
Early stopping applied (best metric=0.5238592028617859)
Finished Training
Total time taken: 26.535186290740967
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.410
[3,     3] loss: 1.387
[4,     3] loss: 1.387
[5,     3] loss: 1.387
[6,     3] loss: 1.385
[7,     3] loss: 1.387
[8,     3] loss: 1.382
[9,     3] loss: 1.390
[10,     3] loss: 1.374
[11,     3] loss: 1.393
[12,     3] loss: 1.384
[13,     3] loss: 1.379
[14,     3] loss: 1.384
[15,     3] loss: 1.390
[16,     3] loss: 1.374
[17,     3] loss: 1.358
[18,     3] loss: 1.337
[19,     3] loss: 1.309
[20,     3] loss: 1.239
[21,     3] loss: 1.152
[22,     3] loss: 1.105
[23,     3] loss: 1.049
[24,     3] loss: 1.143
[25,     3] loss: 1.042
[26,     3] loss: 1.113
[27,     3] loss: 1.002
[28,     3] loss: 1.012
[29,     3] loss: 1.008
[30,     3] loss: 0.987
[31,     3] loss: 1.114
[32,     3] loss: 0.990
[33,     3] loss: 0.992
[34,     3] loss: 0.888
[35,     3] loss: 0.896
[36,     3] loss: 0.885
[37,     3] loss: 0.988
[38,     3] loss: 0.792
[39,     3] loss: 0.866
[40,     3] loss: 0.821
[41,     3] loss: 0.784
[42,     3] loss: 0.785
[43,     3] loss: 0.865
[44,     3] loss: 0.968
[45,     3] loss: 0.914
[46,     3] loss: 0.950
[47,     3] loss: 0.901
[48,     3] loss: 0.822
[49,     3] loss: 0.811
[50,     3] loss: 0.785
[51,     3] loss: 0.837
[52,     3] loss: 0.835
[53,     3] loss: 0.876
[54,     3] loss: 0.761
[55,     3] loss: 0.800
[56,     3] loss: 0.820
[57,     3] loss: 1.011
[58,     3] loss: 0.808
[59,     3] loss: 0.842
[60,     3] loss: 0.771
[61,     3] loss: 0.772
[62,     3] loss: 0.843
[63,     3] loss: 0.728
[64,     3] loss: 0.758
[65,     3] loss: 0.908
[66,     3] loss: 0.820
[67,     3] loss: 0.847
[68,     3] loss: 0.774
[69,     3] loss: 0.789
[70,     3] loss: 0.770
[71,     3] loss: 0.736
[72,     3] loss: 0.853
[73,     3] loss: 0.734
[74,     3] loss: 0.814
[75,     3] loss: 0.834
[76,     3] loss: 0.747
[77,     3] loss: 0.856
[78,     3] loss: 0.800
[79,     3] loss: 0.852
[80,     3] loss: 0.922
[81,     3] loss: 0.805
[82,     3] loss: 0.836
[83,     3] loss: 0.793
[84,     3] loss: 0.770
[85,     3] loss: 0.738
[86,     3] loss: 0.723
[87,     3] loss: 0.737
[88,     3] loss: 0.845
[89,     3] loss: 1.080
[90,     3] loss: 0.982
[91,     3] loss: 0.859
[92,     3] loss: 0.912
Early stopping applied (best metric=0.518230676651001)
Finished Training
Total time taken: 27.23718762397766
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.371
[2,     3] loss: 1.387
[3,     3] loss: 1.401
[4,     3] loss: 1.393
[5,     3] loss: 1.389
[6,     3] loss: 1.390
[7,     3] loss: 1.398
[8,     3] loss: 1.387
[9,     3] loss: 1.388
[10,     3] loss: 1.387
[11,     3] loss: 1.394
[12,     3] loss: 1.390
[13,     3] loss: 1.383
[14,     3] loss: 1.389
[15,     3] loss: 1.383
[16,     3] loss: 1.379
[17,     3] loss: 1.386
[18,     3] loss: 1.391
[19,     3] loss: 1.388
[20,     3] loss: 1.379
[21,     3] loss: 1.388
[22,     3] loss: 1.362
[23,     3] loss: 1.333
[24,     3] loss: 1.264
[25,     3] loss: 1.369
[26,     3] loss: 1.260
[27,     3] loss: 1.260
[28,     3] loss: 1.212
[29,     3] loss: 1.188
[30,     3] loss: 1.149
[31,     3] loss: 1.140
[32,     3] loss: 1.206
[33,     3] loss: 1.050
[34,     3] loss: 1.048
[35,     3] loss: 1.029
[36,     3] loss: 0.994
[37,     3] loss: 1.116
[38,     3] loss: 0.950
[39,     3] loss: 1.022
[40,     3] loss: 0.979
[41,     3] loss: 0.950
[42,     3] loss: 0.910
[43,     3] loss: 1.064
[44,     3] loss: 1.027
[45,     3] loss: 0.917
[46,     3] loss: 0.895
[47,     3] loss: 0.853
[48,     3] loss: 0.775
[49,     3] loss: 0.791
[50,     3] loss: 0.873
[51,     3] loss: 1.136
[52,     3] loss: 0.945
[53,     3] loss: 1.083
[54,     3] loss: 1.064
[55,     3] loss: 0.930
[56,     3] loss: 0.902
[57,     3] loss: 0.871
[58,     3] loss: 0.797
[59,     3] loss: 0.810
[60,     3] loss: 0.816
[61,     3] loss: 0.766
[62,     3] loss: 0.763
[63,     3] loss: 0.829
[64,     3] loss: 0.816
[65,     3] loss: 0.800
[66,     3] loss: 0.898
[67,     3] loss: 0.949
[68,     3] loss: 0.932
[69,     3] loss: 0.905
[70,     3] loss: 0.829
[71,     3] loss: 0.845
[72,     3] loss: 0.796
[73,     3] loss: 0.788
[74,     3] loss: 0.760
[75,     3] loss: 0.798
[76,     3] loss: 0.779
[77,     3] loss: 0.976
[78,     3] loss: 0.833
[79,     3] loss: 0.848
[80,     3] loss: 0.827
[81,     3] loss: 0.782
[82,     3] loss: 0.816
[83,     3] loss: 0.741
[84,     3] loss: 0.765
[85,     3] loss: 0.782
[86,     3] loss: 0.973
Early stopping applied (best metric=0.4905097782611847)
Finished Training
Total time taken: 25.311174392700195
{'S-palmitoylation-C Validation Accuracy': 0.5755780827614889, 'S-palmitoylation-C Validation Sensitivity': 0.4223102310231023, 'S-palmitoylation-C Validation Specificity': 0.6139847863959726, 'S-palmitoylation-C Validation Precision': 0.22231647002243143, 'S-palmitoylation-C AUC ROC': 0.5312058356737179, 'S-palmitoylation-C AUC PR': 0.21614350045483108, 'S-palmitoylation-C MCC': 0.033384946537089566, 'S-palmitoylation-C F1': 0.2673188688585474, 'Validation Loss (S-palmitoylation-C)': 0.5546345671017965, 'Hydroxylation-K Validation Accuracy': 0.6084219858156028, 'Hydroxylation-K Validation Sensitivity': 0.8503703703703703, 'Hydroxylation-K Validation Specificity': 0.5491228070175439, 'Hydroxylation-K Validation Precision': 0.3678891032182201, 'Hydroxylation-K AUC ROC': 0.8177972709551656, 'Hydroxylation-K AUC PR': 0.6219658893390985, 'Hydroxylation-K MCC': 0.33915653563363923, 'Hydroxylation-K F1': 0.49249412795134223, 'Validation Loss (Hydroxylation-K)': 0.5238265454769134, 'Validation Loss (total)': 1.0784611145655314, 'TimeToTrain': 25.17147479057312}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005884932330355889,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9695648088296234,
 'loss_weight_S-palmitoylation-C': 0.6589316306660449,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4023858729,
 'sample_weights': [0.4036135428006255, 0.2633032325291122],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.4623522508012683,
 'weight_decay_Hydroxylation-K': 3.911693720353935,
 'weight_decay_S-palmitoylation-C': 2.8817838841773282}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.387
[3,     3] loss: 1.395
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0041212536567466805,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6486743512802569,
 'loss_weight_S-palmitoylation-C': 0.24530841726009878,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 758028395,
 'sample_weights': [0.6589316306660449, 0.9695648088296234],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.651288958363253,
 'weight_decay_Hydroxylation-K': 9.405134346400938,
 'weight_decay_S-palmitoylation-C': 0.7489023312931432}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.379
[2,     3] loss: 1.387
[3,     3] loss: 1.391
[4,     3] loss: 1.389
[5,     3] loss: 1.380
[6,     3] loss: 1.391
[7,     3] loss: 1.396
[8,     3] loss: 1.389
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003908644472141958,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5493180375746554,
 'loss_weight_S-palmitoylation-C': 0.034663423710482685,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3419462582,
 'sample_weights': [0.24530841726009878, 0.6486743512802569],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.559490688791431,
 'weight_decay_Hydroxylation-K': 0.7390128926651269,
 'weight_decay_S-palmitoylation-C': 9.686868284902491}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.386
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 1.1222602353531605e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.40987956290155875,
 'loss_weight_S-palmitoylation-C': 0.8031877847397088,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3027741081,
 'sample_weights': [0.034663423710482685, 0.5493180375746554],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.843834020739779,
 'weight_decay_Hydroxylation-K': 8.519204192986853,
 'weight_decay_S-palmitoylation-C': 3.343129721831218}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.388
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003557400317116536,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.910366047238353,
 'loss_weight_S-palmitoylation-C': 0.3610875569974534,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1029681982,
 'sample_weights': [0.8031877847397088, 0.40987956290155875],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8431958130542838,
 'weight_decay_Hydroxylation-K': 9.403356603443445,
 'weight_decay_S-palmitoylation-C': 1.612659105654607}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.388
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028401856840308713,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9343195329409815,
 'loss_weight_S-palmitoylation-C': 0.7991526458560244,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2944738941,
 'sample_weights': [0.3610875569974534, 0.910366047238353],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.3080719958126537,
 'weight_decay_Hydroxylation-K': 9.02430338224017,
 'weight_decay_S-palmitoylation-C': 1.5100439392687932}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.393
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004363914235226463,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.15929983280754081,
 'loss_weight_S-palmitoylation-C': 0.9617539365359499,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3586671961,
 'sample_weights': [0.7991526458560244, 0.9343195329409815],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.4485381085076954,
 'weight_decay_Hydroxylation-K': 5.719067951476672,
 'weight_decay_S-palmitoylation-C': 8.74673957559527}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.399
[2,     3] loss: 1.387
[3,     3] loss: 1.393
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006304567524564032,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3491188874286132,
 'loss_weight_S-palmitoylation-C': 0.4805742498227614,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3714068500,
 'sample_weights': [0.9617539365359499, 0.15929983280754081],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.953583758951858,
 'weight_decay_Hydroxylation-K': 1.0673271601918144,
 'weight_decay_S-palmitoylation-C': 9.110612904014273}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.386
[3,     3] loss: 1.388
[4,     3] loss: 1.391
[5,     3] loss: 1.390
[6,     3] loss: 1.400
[7,     3] loss: 1.385
[8,     3] loss: 1.380
[9,     3] loss: 1.386
[10,     3] loss: 1.381
[11,     3] loss: 1.373
[12,     3] loss: 1.348
[13,     3] loss: 1.291
[14,     3] loss: 1.253
[15,     3] loss: 1.199
[16,     3] loss: 1.252
[17,     3] loss: 1.308
[18,     3] loss: 1.249
[19,     3] loss: 1.200
[20,     3] loss: 1.169
[21,     3] loss: 1.010
[22,     3] loss: 1.092
[23,     3] loss: 1.197
[24,     3] loss: 1.199
[25,     3] loss: 1.248
[26,     3] loss: 1.153
[27,     3] loss: 1.079
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011369812831311154,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8245005157497431,
 'loss_weight_S-palmitoylation-C': 0.5595777701268705,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2629110487,
 'sample_weights': [0.4805742498227614, 0.3491188874286132],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.291100854121136,
 'weight_decay_Hydroxylation-K': 3.247577885640154,
 'weight_decay_S-palmitoylation-C': 8.756103242156057}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.393
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004405790734792526,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.15083863499706682,
 'loss_weight_S-palmitoylation-C': 0.9571317685282061,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1523719962,
 'sample_weights': [0.5595777701268705, 0.8245005157497431],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1836082311234875,
 'weight_decay_Hydroxylation-K': 4.892969141227471,
 'weight_decay_S-palmitoylation-C': 0.9603292685610665}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.385
[3,     3] loss: 1.398
[4,     3] loss: 1.387
[5,     3] loss: 1.386
[6,     3] loss: 1.393
[7,     3] loss: 1.394
[8,     3] loss: 1.391
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009940564843363779,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2239703814644552,
 'loss_weight_S-palmitoylation-C': 0.8317252596569434,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 813697714,
 'sample_weights': [0.9571317685282061, 0.15083863499706682],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.07230905414019,
 'weight_decay_Hydroxylation-K': 8.372036407589322,
 'weight_decay_S-palmitoylation-C': 6.3225319563637274}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.398
[3,     3] loss: 1.387
[4,     3] loss: 1.390
[5,     3] loss: 1.387
[6,     3] loss: 1.386
[7,     3] loss: 1.385
[8,     3] loss: 1.385
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019346045214067447,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8169697406793907,
 'loss_weight_S-palmitoylation-C': 0.2898969497922366,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3605884833,
 'sample_weights': [0.8317252596569434, 0.2239703814644552],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.342499677898904,
 'weight_decay_Hydroxylation-K': 1.800666340832494,
 'weight_decay_S-palmitoylation-C': 8.665501596668951}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.380
[3,     3] loss: 1.399
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004881131590112853,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7352764147163474,
 'loss_weight_S-palmitoylation-C': 0.010357578889600733,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1241641209,
 'sample_weights': [0.2898969497922366, 0.8169697406793907],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.3786249103635715,
 'weight_decay_Hydroxylation-K': 3.699007329747884,
 'weight_decay_S-palmitoylation-C': 8.463796840731355}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.386
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006288314783327757,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4539209883866132,
 'loss_weight_S-palmitoylation-C': 0.6333784352562397,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1925927002,
 'sample_weights': [0.010357578889600733, 0.7352764147163474],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3348233241624552,
 'weight_decay_Hydroxylation-K': 9.788772248594498,
 'weight_decay_S-palmitoylation-C': 0.8577516799426741}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.403
[2,     3] loss: 1.386
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006001076954952417,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.0015823807970431203,
 'loss_weight_S-palmitoylation-C': 0.22366692842590513,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3310050217,
 'sample_weights': [0.6333784352562397, 0.4539209883866132],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.522489967547921,
 'weight_decay_Hydroxylation-K': 8.009264171750706,
 'weight_decay_S-palmitoylation-C': 5.127964040544508}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.402
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007662889688022973,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1469511947938765,
 'loss_weight_S-palmitoylation-C': 0.7847472184830134,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1503133324,
 'sample_weights': [0.22366692842590513, 0.0015823807970431203],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.43825109880758,
 'weight_decay_Hydroxylation-K': 8.16668844038082,
 'weight_decay_S-palmitoylation-C': 3.904464515769617}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.399
[3,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006203053077999927,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.478248782407826,
 'loss_weight_S-palmitoylation-C': 0.4132164418922921,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1090107526,
 'sample_weights': [0.7847472184830134, 0.1469511947938765],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.1888881933977355,
 'weight_decay_Hydroxylation-K': 8.344978995115355,
 'weight_decay_S-palmitoylation-C': 4.7069039020953705}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004786249771521506,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5268183346000129,
 'loss_weight_S-palmitoylation-C': 0.8277989882022248,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2172338042,
 'sample_weights': [0.4132164418922921, 0.478248782407826],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.490207731047164,
 'weight_decay_Hydroxylation-K': 8.93531591981751,
 'weight_decay_S-palmitoylation-C': 0.6938898981030656}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.396
[3,     3] loss: 1.378
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027527690354943925,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6752003601380326,
 'loss_weight_S-palmitoylation-C': 0.6590435563976231,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3578335777,
 'sample_weights': [0.8277989882022248, 0.5268183346000129],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.483029679342448,
 'weight_decay_Hydroxylation-K': 2.71758426473661,
 'weight_decay_S-palmitoylation-C': 8.76744940854984}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.382
[3,     3] loss: 1.385
[4,     3] loss: 1.372
[5,     3] loss: 1.396
[6,     3] loss: 1.392
[7,     3] loss: 1.395
[8,     3] loss: 1.383
[9,     3] loss: 1.375
[10,     3] loss: 1.371
[11,     3] loss: 1.380
[12,     3] loss: 1.387
[13,     3] loss: 1.390
[14,     3] loss: 1.386
[15,     3] loss: 1.381
[16,     3] loss: 1.380
[17,     3] loss: 1.365
[18,     3] loss: 1.357
[19,     3] loss: 1.344
[20,     3] loss: 1.298
[21,     3] loss: 1.233
[22,     3] loss: 1.283
[23,     3] loss: 1.195
[24,     3] loss: 1.205
[25,     3] loss: 1.252
[26,     3] loss: 1.282
[27,     3] loss: 1.205
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00982223396535834,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.03699120139444878,
 'loss_weight_S-palmitoylation-C': 0.8472870130213698,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2623415149,
 'sample_weights': [0.6590435563976231, 0.6752003601380326],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.77069382790996,
 'weight_decay_Hydroxylation-K': 7.72372039626581,
 'weight_decay_S-palmitoylation-C': 8.016755480452574}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.382
[3,     3] loss: 1.390
[4,     3] loss: 1.390
[5,     3] loss: 1.385
[6,     3] loss: 1.388
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000350999468109837,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4050281306453226,
 'loss_weight_S-palmitoylation-C': 0.44007085891475745,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1356436963,
 'sample_weights': [0.8472870130213698, 0.03699120139444878],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9497890954898174,
 'weight_decay_Hydroxylation-K': 5.370329377769143,
 'weight_decay_S-palmitoylation-C': 9.73529200798487}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.385
[3,     3] loss: 1.380
[4,     3] loss: 1.384
[5,     3] loss: 1.394
[6,     3] loss: 1.386
[7,     3] loss: 1.385
[8,     3] loss: 1.375
[9,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009456951147063258,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8885537682907192,
 'loss_weight_S-palmitoylation-C': 0.026557648831539202,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1153517840,
 'sample_weights': [0.44007085891475745, 0.4050281306453226],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.35263399725749,
 'weight_decay_Hydroxylation-K': 3.032134624660067,
 'weight_decay_S-palmitoylation-C': 5.46077526450894}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.384
[4,     3] loss: 1.384
[5,     3] loss: 1.375
[6,     3] loss: 1.384
[7,     3] loss: 1.366
[8,     3] loss: 1.354
[9,     3] loss: 1.343
[10,     3] loss: 1.319
[11,     3] loss: 1.299
[12,     3] loss: 1.280
[13,     3] loss: 1.268
[14,     3] loss: 1.240
[15,     3] loss: 1.243
[16,     3] loss: 1.310
[17,     3] loss: 1.148
[18,     3] loss: 1.142
[19,     3] loss: 1.138
[20,     3] loss: 1.183
[21,     3] loss: 1.115
[22,     3] loss: 1.086
[23,     3] loss: 1.070
[24,     3] loss: 1.023
[25,     3] loss: 1.008
[26,     3] loss: 1.036
[27,     3] loss: 0.953
[28,     3] loss: 0.956
[29,     3] loss: 0.917
[30,     3] loss: 0.955
[31,     3] loss: 0.880
[32,     3] loss: 0.908
[33,     3] loss: 0.898
[34,     3] loss: 0.964
[35,     3] loss: 0.957
[36,     3] loss: 0.881
[37,     3] loss: 0.882
[38,     3] loss: 0.879
[39,     3] loss: 0.834
[40,     3] loss: 0.876
[41,     3] loss: 0.878
[42,     3] loss: 0.803
[43,     3] loss: 0.804
[44,     3] loss: 0.813
[45,     3] loss: 0.888
[46,     3] loss: 0.968
[47,     3] loss: 0.867
[48,     3] loss: 0.804
[49,     3] loss: 0.852
[50,     3] loss: 0.826
[51,     3] loss: 0.797
[52,     3] loss: 0.793
[53,     3] loss: 0.774
[54,     3] loss: 0.776
[55,     3] loss: 0.875
[56,     3] loss: 0.863
[57,     3] loss: 0.800
[58,     3] loss: 0.815
[59,     3] loss: 0.815
[60,     3] loss: 0.906
[61,     3] loss: 0.807
[62,     3] loss: 0.808
[63,     3] loss: 0.825
[64,     3] loss: 0.883
[65,     3] loss: 0.835
[66,     3] loss: 0.820
[67,     3] loss: 0.853
[68,     3] loss: 0.819
[69,     3] loss: 0.791
[70,     3] loss: 0.808
[71,     3] loss: 0.827
[72,     3] loss: 0.794
Early stopping applied (best metric=0.5266033411026001)
Finished Training
Total time taken: 21.487146139144897
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.383
[3,     3] loss: 1.387
[4,     3] loss: 1.380
[5,     3] loss: 1.378
[6,     3] loss: 1.376
[7,     3] loss: 1.374
[8,     3] loss: 1.376
[9,     3] loss: 1.365
[10,     3] loss: 1.356
[11,     3] loss: 1.322
[12,     3] loss: 1.314
[13,     3] loss: 1.273
[14,     3] loss: 1.238
[15,     3] loss: 1.211
[16,     3] loss: 1.238
[17,     3] loss: 1.234
[18,     3] loss: 1.142
[19,     3] loss: 1.136
[20,     3] loss: 1.095
[21,     3] loss: 1.026
[22,     3] loss: 1.087
[23,     3] loss: 0.991
[24,     3] loss: 0.928
[25,     3] loss: 1.046
[26,     3] loss: 1.072
[27,     3] loss: 1.044
[28,     3] loss: 1.152
[29,     3] loss: 1.092
[30,     3] loss: 1.001
[31,     3] loss: 1.093
[32,     3] loss: 1.037
[33,     3] loss: 0.985
[34,     3] loss: 0.958
[35,     3] loss: 0.974
[36,     3] loss: 0.893
[37,     3] loss: 0.963
[38,     3] loss: 0.879
[39,     3] loss: 0.899
[40,     3] loss: 0.880
[41,     3] loss: 0.911
[42,     3] loss: 0.923
[43,     3] loss: 0.948
[44,     3] loss: 0.872
[45,     3] loss: 0.893
[46,     3] loss: 1.028
[47,     3] loss: 0.929
[48,     3] loss: 1.073
[49,     3] loss: 1.091
[50,     3] loss: 1.009
[51,     3] loss: 0.944
[52,     3] loss: 0.960
[53,     3] loss: 0.867
[54,     3] loss: 0.885
[55,     3] loss: 0.877
[56,     3] loss: 0.835
[57,     3] loss: 0.842
[58,     3] loss: 0.818
[59,     3] loss: 0.803
[60,     3] loss: 0.812
[61,     3] loss: 0.802
[62,     3] loss: 0.789
[63,     3] loss: 0.842
[64,     3] loss: 0.828
[65,     3] loss: 0.857
[66,     3] loss: 0.802
[67,     3] loss: 0.776
[68,     3] loss: 0.785
[69,     3] loss: 0.837
[70,     3] loss: 0.914
[71,     3] loss: 0.808
[72,     3] loss: 0.781
[73,     3] loss: 0.829
[74,     3] loss: 0.778
[75,     3] loss: 0.827
[76,     3] loss: 0.829
Early stopping applied (best metric=0.5297421216964722)
Finished Training
Total time taken: 22.932159900665283
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.384
[3,     3] loss: 1.388
[4,     3] loss: 1.376
[5,     3] loss: 1.369
[6,     3] loss: 1.389
[7,     3] loss: 1.380
[8,     3] loss: 1.364
[9,     3] loss: 1.349
[10,     3] loss: 1.313
[11,     3] loss: 1.288
[12,     3] loss: 1.273
[13,     3] loss: 1.264
[14,     3] loss: 1.236
[15,     3] loss: 1.155
[16,     3] loss: 1.220
[17,     3] loss: 1.160
[18,     3] loss: 1.136
[19,     3] loss: 1.054
[20,     3] loss: 1.113
[21,     3] loss: 1.081
[22,     3] loss: 0.991
[23,     3] loss: 1.126
[24,     3] loss: 1.063
[25,     3] loss: 1.053
[26,     3] loss: 1.023
[27,     3] loss: 1.028
[28,     3] loss: 1.006
[29,     3] loss: 0.950
[30,     3] loss: 1.029
[31,     3] loss: 0.923
[32,     3] loss: 0.912
[33,     3] loss: 1.052
[34,     3] loss: 0.944
[35,     3] loss: 0.950
[36,     3] loss: 0.878
[37,     3] loss: 0.916
[38,     3] loss: 0.906
[39,     3] loss: 0.876
[40,     3] loss: 0.873
[41,     3] loss: 0.896
[42,     3] loss: 0.861
[43,     3] loss: 0.835
[44,     3] loss: 0.910
[45,     3] loss: 0.832
[46,     3] loss: 0.819
[47,     3] loss: 0.950
[48,     3] loss: 1.096
[49,     3] loss: 1.011
[50,     3] loss: 0.950
[51,     3] loss: 0.903
[52,     3] loss: 0.872
[53,     3] loss: 0.894
[54,     3] loss: 0.885
[55,     3] loss: 0.876
[56,     3] loss: 0.844
[57,     3] loss: 0.792
[58,     3] loss: 0.848
[59,     3] loss: 0.806
[60,     3] loss: 0.787
[61,     3] loss: 0.806
[62,     3] loss: 0.796
[63,     3] loss: 0.781
[64,     3] loss: 0.815
[65,     3] loss: 0.763
[66,     3] loss: 0.794
[67,     3] loss: 0.755
[68,     3] loss: 0.800
[69,     3] loss: 0.805
[70,     3] loss: 0.869
[71,     3] loss: 0.802
[72,     3] loss: 0.766
[73,     3] loss: 0.819
[74,     3] loss: 0.846
[75,     3] loss: 0.794
[76,     3] loss: 0.889
[77,     3] loss: 0.779
[78,     3] loss: 0.780
[79,     3] loss: 0.756
Early stopping applied (best metric=0.5402962565422058)
Finished Training
Total time taken: 23.071160554885864
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.391
[3,     3] loss: 1.382
[4,     3] loss: 1.390
[5,     3] loss: 1.386
[6,     3] loss: 1.379
[7,     3] loss: 1.388
[8,     3] loss: 1.381
[9,     3] loss: 1.379
[10,     3] loss: 1.379
[11,     3] loss: 1.365
[12,     3] loss: 1.356
[13,     3] loss: 1.349
[14,     3] loss: 1.314
[15,     3] loss: 1.282
[16,     3] loss: 1.240
[17,     3] loss: 1.256
[18,     3] loss: 1.231
[19,     3] loss: 1.166
[20,     3] loss: 1.161
[21,     3] loss: 1.128
[22,     3] loss: 1.093
[23,     3] loss: 1.118
[24,     3] loss: 0.963
[25,     3] loss: 1.067
[26,     3] loss: 0.995
[27,     3] loss: 1.139
[28,     3] loss: 1.071
[29,     3] loss: 0.948
[30,     3] loss: 0.907
[31,     3] loss: 1.042
[32,     3] loss: 1.074
[33,     3] loss: 1.020
[34,     3] loss: 0.977
[35,     3] loss: 0.992
[36,     3] loss: 0.983
[37,     3] loss: 0.884
[38,     3] loss: 0.923
[39,     3] loss: 0.954
[40,     3] loss: 0.855
[41,     3] loss: 0.869
[42,     3] loss: 0.874
[43,     3] loss: 0.880
[44,     3] loss: 0.924
[45,     3] loss: 0.826
[46,     3] loss: 0.885
[47,     3] loss: 0.885
[48,     3] loss: 0.904
[49,     3] loss: 0.851
[50,     3] loss: 0.820
[51,     3] loss: 0.783
[52,     3] loss: 0.846
[53,     3] loss: 0.843
[54,     3] loss: 0.805
[55,     3] loss: 0.889
[56,     3] loss: 0.886
[57,     3] loss: 0.825
[58,     3] loss: 0.794
[59,     3] loss: 0.777
[60,     3] loss: 0.768
[61,     3] loss: 0.775
[62,     3] loss: 0.773
[63,     3] loss: 0.743
[64,     3] loss: 0.746
[65,     3] loss: 0.737
[66,     3] loss: 0.740
[67,     3] loss: 0.746
[68,     3] loss: 0.737
[69,     3] loss: 0.729
[70,     3] loss: 0.750
[71,     3] loss: 0.730
[72,     3] loss: 0.752
[73,     3] loss: 0.748
[74,     3] loss: 0.739
Early stopping applied (best metric=0.5044295191764832)
Finished Training
Total time taken: 22.337151527404785
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.394
[3,     3] loss: 1.388
[4,     3] loss: 1.379
[5,     3] loss: 1.384
[6,     3] loss: 1.374
[7,     3] loss: 1.391
[8,     3] loss: 1.375
[9,     3] loss: 1.372
[10,     3] loss: 1.382
[11,     3] loss: 1.342
[12,     3] loss: 1.340
[13,     3] loss: 1.337
[14,     3] loss: 1.312
[15,     3] loss: 1.247
[16,     3] loss: 1.272
[17,     3] loss: 1.240
[18,     3] loss: 1.228
[19,     3] loss: 1.207
[20,     3] loss: 1.235
[21,     3] loss: 1.216
[22,     3] loss: 1.165
[23,     3] loss: 1.124
[24,     3] loss: 1.151
[25,     3] loss: 1.002
[26,     3] loss: 1.000
[27,     3] loss: 1.032
[28,     3] loss: 0.981
[29,     3] loss: 0.946
[30,     3] loss: 1.009
[31,     3] loss: 0.972
[32,     3] loss: 0.959
[33,     3] loss: 1.029
[34,     3] loss: 0.931
[35,     3] loss: 1.011
[36,     3] loss: 1.033
[37,     3] loss: 0.972
[38,     3] loss: 0.905
[39,     3] loss: 1.024
[40,     3] loss: 0.937
[41,     3] loss: 0.928
[42,     3] loss: 0.975
[43,     3] loss: 0.941
[44,     3] loss: 0.929
[45,     3] loss: 0.887
[46,     3] loss: 0.819
[47,     3] loss: 0.881
[48,     3] loss: 0.802
[49,     3] loss: 0.829
[50,     3] loss: 0.806
[51,     3] loss: 0.781
[52,     3] loss: 0.822
[53,     3] loss: 0.781
[54,     3] loss: 0.794
[55,     3] loss: 0.830
[56,     3] loss: 0.895
[57,     3] loss: 0.867
[58,     3] loss: 0.780
[59,     3] loss: 0.809
[60,     3] loss: 0.794
[61,     3] loss: 0.772
[62,     3] loss: 0.910
[63,     3] loss: 0.811
[64,     3] loss: 0.759
[65,     3] loss: 0.882
[66,     3] loss: 0.836
[67,     3] loss: 0.842
[68,     3] loss: 0.910
[69,     3] loss: 0.861
[70,     3] loss: 0.813
[71,     3] loss: 0.829
[72,     3] loss: 0.816
[73,     3] loss: 0.801
[74,     3] loss: 0.759
[75,     3] loss: 0.763
[76,     3] loss: 0.774
[77,     3] loss: 0.788
[78,     3] loss: 0.760
Early stopping applied (best metric=0.4840565025806427)
Finished Training
Total time taken: 23.089158535003662
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.396
[3,     3] loss: 1.412
[4,     3] loss: 1.384
[5,     3] loss: 1.378
[6,     3] loss: 1.389
[7,     3] loss: 1.391
[8,     3] loss: 1.381
[9,     3] loss: 1.385
[10,     3] loss: 1.379
[11,     3] loss: 1.381
[12,     3] loss: 1.373
[13,     3] loss: 1.374
[14,     3] loss: 1.373
[15,     3] loss: 1.341
[16,     3] loss: 1.310
[17,     3] loss: 1.295
[18,     3] loss: 1.272
[19,     3] loss: 1.245
[20,     3] loss: 1.220
[21,     3] loss: 1.201
[22,     3] loss: 1.184
[23,     3] loss: 1.264
[24,     3] loss: 1.200
[25,     3] loss: 1.134
[26,     3] loss: 1.133
[27,     3] loss: 1.086
[28,     3] loss: 1.043
[29,     3] loss: 1.039
[30,     3] loss: 1.064
[31,     3] loss: 0.984
[32,     3] loss: 0.987
[33,     3] loss: 0.948
[34,     3] loss: 0.993
[35,     3] loss: 0.987
[36,     3] loss: 0.950
[37,     3] loss: 0.911
[38,     3] loss: 0.949
[39,     3] loss: 0.906
[40,     3] loss: 0.990
[41,     3] loss: 0.907
[42,     3] loss: 0.907
[43,     3] loss: 1.097
[44,     3] loss: 0.970
[45,     3] loss: 0.886
[46,     3] loss: 0.834
[47,     3] loss: 0.842
[48,     3] loss: 0.872
[49,     3] loss: 0.823
[50,     3] loss: 0.864
[51,     3] loss: 0.939
[52,     3] loss: 0.869
[53,     3] loss: 0.905
[54,     3] loss: 0.909
[55,     3] loss: 0.847
[56,     3] loss: 0.796
[57,     3] loss: 0.817
[58,     3] loss: 0.819
[59,     3] loss: 0.819
[60,     3] loss: 0.866
[61,     3] loss: 0.816
[62,     3] loss: 0.883
[63,     3] loss: 0.790
[64,     3] loss: 0.925
[65,     3] loss: 0.807
[66,     3] loss: 0.807
[67,     3] loss: 0.803
[68,     3] loss: 0.766
[69,     3] loss: 0.757
[70,     3] loss: 0.780
[71,     3] loss: 0.775
[72,     3] loss: 0.759
[73,     3] loss: 0.792
[74,     3] loss: 0.790
[75,     3] loss: 0.795
[76,     3] loss: 0.795
[77,     3] loss: 0.859
[78,     3] loss: 0.855
[79,     3] loss: 0.838
[80,     3] loss: 0.805
[81,     3] loss: 0.807
Early stopping applied (best metric=0.5316600203514099)
Finished Training
Total time taken: 24.220168590545654
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.384
[4,     3] loss: 1.391
[5,     3] loss: 1.378
[6,     3] loss: 1.383
[7,     3] loss: 1.381
[8,     3] loss: 1.369
[9,     3] loss: 1.345
[10,     3] loss: 1.355
[11,     3] loss: 1.353
[12,     3] loss: 1.333
[13,     3] loss: 1.307
[14,     3] loss: 1.294
[15,     3] loss: 1.292
[16,     3] loss: 1.317
[17,     3] loss: 1.222
[18,     3] loss: 1.160
[19,     3] loss: 1.113
[20,     3] loss: 1.088
[21,     3] loss: 1.228
[22,     3] loss: 1.230
[23,     3] loss: 1.092
[24,     3] loss: 1.043
[25,     3] loss: 1.079
[26,     3] loss: 1.100
[27,     3] loss: 1.058
[28,     3] loss: 0.986
[29,     3] loss: 0.998
[30,     3] loss: 0.981
[31,     3] loss: 1.231
[32,     3] loss: 1.034
[33,     3] loss: 1.041
[34,     3] loss: 1.061
[35,     3] loss: 0.991
[36,     3] loss: 0.910
[37,     3] loss: 0.936
[38,     3] loss: 0.930
[39,     3] loss: 0.923
[40,     3] loss: 0.914
[41,     3] loss: 0.862
[42,     3] loss: 0.860
[43,     3] loss: 0.837
[44,     3] loss: 0.885
[45,     3] loss: 0.891
[46,     3] loss: 0.852
[47,     3] loss: 0.874
[48,     3] loss: 0.839
[49,     3] loss: 0.832
[50,     3] loss: 0.845
[51,     3] loss: 0.841
[52,     3] loss: 0.874
[53,     3] loss: 0.814
[54,     3] loss: 0.810
[55,     3] loss: 0.817
[56,     3] loss: 0.789
[57,     3] loss: 0.874
[58,     3] loss: 0.928
[59,     3] loss: 0.781
[60,     3] loss: 0.830
[61,     3] loss: 0.859
[62,     3] loss: 0.779
[63,     3] loss: 0.857
[64,     3] loss: 0.807
[65,     3] loss: 0.830
[66,     3] loss: 0.814
[67,     3] loss: 0.813
[68,     3] loss: 0.838
[69,     3] loss: 0.761
[70,     3] loss: 0.772
[71,     3] loss: 0.753
[72,     3] loss: 0.858
[73,     3] loss: 0.778
[74,     3] loss: 0.773
[75,     3] loss: 0.762
[76,     3] loss: 0.741
[77,     3] loss: 0.793
[78,     3] loss: 0.815
Early stopping applied (best metric=0.5092604160308838)
Finished Training
Total time taken: 23.43616247177124
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.382
[3,     3] loss: 1.389
[4,     3] loss: 1.388
[5,     3] loss: 1.384
[6,     3] loss: 1.384
[7,     3] loss: 1.382
[8,     3] loss: 1.380
[9,     3] loss: 1.372
[10,     3] loss: 1.362
[11,     3] loss: 1.386
[12,     3] loss: 1.345
[13,     3] loss: 1.355
[14,     3] loss: 1.295
[15,     3] loss: 1.293
[16,     3] loss: 1.244
[17,     3] loss: 1.198
[18,     3] loss: 1.176
[19,     3] loss: 1.215
[20,     3] loss: 1.171
[21,     3] loss: 1.100
[22,     3] loss: 1.193
[23,     3] loss: 1.079
[24,     3] loss: 1.047
[25,     3] loss: 0.942
[26,     3] loss: 0.985
[27,     3] loss: 0.941
[28,     3] loss: 0.964
[29,     3] loss: 0.975
[30,     3] loss: 0.920
[31,     3] loss: 0.912
[32,     3] loss: 0.840
[33,     3] loss: 0.901
[34,     3] loss: 0.841
[35,     3] loss: 0.837
[36,     3] loss: 0.895
[37,     3] loss: 0.912
[38,     3] loss: 0.964
[39,     3] loss: 0.862
[40,     3] loss: 0.832
[41,     3] loss: 0.866
[42,     3] loss: 0.918
[43,     3] loss: 0.915
[44,     3] loss: 0.893
[45,     3] loss: 0.893
[46,     3] loss: 0.888
[47,     3] loss: 0.862
[48,     3] loss: 0.804
[49,     3] loss: 0.882
[50,     3] loss: 0.796
[51,     3] loss: 0.869
[52,     3] loss: 0.789
[53,     3] loss: 0.860
[54,     3] loss: 0.863
[55,     3] loss: 0.891
[56,     3] loss: 0.859
[57,     3] loss: 0.822
[58,     3] loss: 0.829
[59,     3] loss: 0.768
[60,     3] loss: 0.787
[61,     3] loss: 0.860
[62,     3] loss: 0.790
[63,     3] loss: 0.785
[64,     3] loss: 0.799
[65,     3] loss: 0.810
[66,     3] loss: 0.759
[67,     3] loss: 0.794
[68,     3] loss: 0.830
[69,     3] loss: 0.751
[70,     3] loss: 0.809
[71,     3] loss: 0.754
[72,     3] loss: 0.760
[73,     3] loss: 0.788
[74,     3] loss: 0.781
[75,     3] loss: 0.807
[76,     3] loss: 0.775
[77,     3] loss: 0.818
[78,     3] loss: 0.822
[79,     3] loss: 0.781
[80,     3] loss: 0.799
[81,     3] loss: 0.770
[82,     3] loss: 0.778
[83,     3] loss: 0.749
[84,     3] loss: 0.761
[85,     3] loss: 0.748
[86,     3] loss: 0.827
Early stopping applied (best metric=0.5462521314620972)
Finished Training
Total time taken: 25.949183464050293
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.388
[3,     3] loss: 1.386
[4,     3] loss: 1.386
[5,     3] loss: 1.384
[6,     3] loss: 1.378
[7,     3] loss: 1.388
[8,     3] loss: 1.381
[9,     3] loss: 1.360
[10,     3] loss: 1.360
[11,     3] loss: 1.353
[12,     3] loss: 1.322
[13,     3] loss: 1.303
[14,     3] loss: 1.303
[15,     3] loss: 1.287
[16,     3] loss: 1.253
[17,     3] loss: 1.283
[18,     3] loss: 1.210
[19,     3] loss: 1.205
[20,     3] loss: 1.229
[21,     3] loss: 1.134
[22,     3] loss: 1.230
[23,     3] loss: 1.157
[24,     3] loss: 1.165
[25,     3] loss: 1.101
[26,     3] loss: 1.038
[27,     3] loss: 1.156
[28,     3] loss: 1.039
[29,     3] loss: 0.974
[30,     3] loss: 0.922
[31,     3] loss: 1.064
[32,     3] loss: 1.009
[33,     3] loss: 0.983
[34,     3] loss: 0.947
[35,     3] loss: 0.905
[36,     3] loss: 0.974
[37,     3] loss: 0.951
[38,     3] loss: 0.892
[39,     3] loss: 0.883
[40,     3] loss: 0.850
[41,     3] loss: 0.847
[42,     3] loss: 0.894
[43,     3] loss: 0.865
[44,     3] loss: 0.868
[45,     3] loss: 0.820
[46,     3] loss: 0.790
[47,     3] loss: 0.775
[48,     3] loss: 0.805
[49,     3] loss: 0.848
[50,     3] loss: 0.862
[51,     3] loss: 0.811
[52,     3] loss: 0.764
[53,     3] loss: 0.763
[54,     3] loss: 0.897
[55,     3] loss: 0.859
[56,     3] loss: 0.770
[57,     3] loss: 0.791
[58,     3] loss: 0.916
[59,     3] loss: 0.859
[60,     3] loss: 0.798
[61,     3] loss: 0.811
[62,     3] loss: 0.799
[63,     3] loss: 0.801
[64,     3] loss: 0.783
[65,     3] loss: 0.781
[66,     3] loss: 0.759
[67,     3] loss: 0.756
[68,     3] loss: 0.789
[69,     3] loss: 0.850
[70,     3] loss: 0.812
[71,     3] loss: 0.795
[72,     3] loss: 0.854
[73,     3] loss: 0.952
[74,     3] loss: 0.799
[75,     3] loss: 0.796
[76,     3] loss: 0.822
[77,     3] loss: 0.828
[78,     3] loss: 0.778
Early stopping applied (best metric=0.5125374794006348)
Finished Training
Total time taken: 23.33415961265564
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.387
[3,     3] loss: 1.385
[4,     3] loss: 1.381
[5,     3] loss: 1.383
[6,     3] loss: 1.368
[7,     3] loss: 1.333
[8,     3] loss: 1.320
[9,     3] loss: 1.303
[10,     3] loss: 1.286
[11,     3] loss: 1.335
[12,     3] loss: 1.255
[13,     3] loss: 1.300
[14,     3] loss: 1.177
[15,     3] loss: 1.228
[16,     3] loss: 1.254
[17,     3] loss: 1.186
[18,     3] loss: 1.120
[19,     3] loss: 1.174
[20,     3] loss: 1.222
[21,     3] loss: 1.112
[22,     3] loss: 1.067
[23,     3] loss: 1.125
[24,     3] loss: 1.088
[25,     3] loss: 1.064
[26,     3] loss: 1.034
[27,     3] loss: 1.004
[28,     3] loss: 0.984
[29,     3] loss: 1.067
[30,     3] loss: 0.957
[31,     3] loss: 0.948
[32,     3] loss: 1.051
[33,     3] loss: 0.968
[34,     3] loss: 0.922
[35,     3] loss: 0.884
[36,     3] loss: 0.973
[37,     3] loss: 0.841
[38,     3] loss: 0.903
[39,     3] loss: 0.813
[40,     3] loss: 0.843
[41,     3] loss: 0.864
[42,     3] loss: 0.863
[43,     3] loss: 0.750
[44,     3] loss: 0.801
[45,     3] loss: 0.811
[46,     3] loss: 0.893
[47,     3] loss: 0.801
[48,     3] loss: 0.886
[49,     3] loss: 0.938
[50,     3] loss: 0.902
[51,     3] loss: 0.830
[52,     3] loss: 0.807
[53,     3] loss: 0.791
[54,     3] loss: 0.868
[55,     3] loss: 0.833
[56,     3] loss: 0.857
[57,     3] loss: 0.837
[58,     3] loss: 0.814
[59,     3] loss: 0.877
[60,     3] loss: 1.063
[61,     3] loss: 1.154
[62,     3] loss: 0.871
[63,     3] loss: 1.139
[64,     3] loss: 0.991
[65,     3] loss: 0.929
[66,     3] loss: 1.050
[67,     3] loss: 0.920
[68,     3] loss: 0.972
[69,     3] loss: 0.908
[70,     3] loss: 0.827
[71,     3] loss: 0.873
[72,     3] loss: 0.798
[73,     3] loss: 0.812
[74,     3] loss: 0.783
[75,     3] loss: 0.768
[76,     3] loss: 0.761
[77,     3] loss: 0.760
[78,     3] loss: 0.791
[79,     3] loss: 0.747
[80,     3] loss: 0.761
[81,     3] loss: 0.771
[82,     3] loss: 0.867
[83,     3] loss: 0.924
[84,     3] loss: 0.807
[85,     3] loss: 0.941
[86,     3] loss: 1.011
[87,     3] loss: 0.849
[88,     3] loss: 0.955
[89,     3] loss: 0.833
[90,     3] loss: 0.823
[91,     3] loss: 0.819
[92,     3] loss: 0.781
[93,     3] loss: 0.827
[94,     3] loss: 0.764
[95,     3] loss: 0.835
[96,     3] loss: 0.755
Early stopping applied (best metric=0.5057309865951538)
Finished Training
Total time taken: 28.800201177597046
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.387
[3,     3] loss: 1.383
[4,     3] loss: 1.383
[5,     3] loss: 1.380
[6,     3] loss: 1.374
[7,     3] loss: 1.364
[8,     3] loss: 1.358
[9,     3] loss: 1.345
[10,     3] loss: 1.291
[11,     3] loss: 1.285
[12,     3] loss: 1.250
[13,     3] loss: 1.300
[14,     3] loss: 1.203
[15,     3] loss: 1.202
[16,     3] loss: 1.157
[17,     3] loss: 1.163
[18,     3] loss: 1.166
[19,     3] loss: 1.052
[20,     3] loss: 1.052
[21,     3] loss: 0.987
[22,     3] loss: 1.046
[23,     3] loss: 0.941
[24,     3] loss: 1.015
[25,     3] loss: 0.959
[26,     3] loss: 0.906
[27,     3] loss: 0.919
[28,     3] loss: 0.930
[29,     3] loss: 0.852
[30,     3] loss: 0.997
[31,     3] loss: 0.927
[32,     3] loss: 0.871
[33,     3] loss: 0.954
[34,     3] loss: 0.882
[35,     3] loss: 0.937
[36,     3] loss: 0.883
[37,     3] loss: 0.926
[38,     3] loss: 0.919
[39,     3] loss: 0.858
[40,     3] loss: 0.842
[41,     3] loss: 0.836
[42,     3] loss: 0.835
[43,     3] loss: 0.946
[44,     3] loss: 0.800
[45,     3] loss: 0.778
[46,     3] loss: 0.831
[47,     3] loss: 0.821
[48,     3] loss: 0.752
[49,     3] loss: 0.923
[50,     3] loss: 0.788
[51,     3] loss: 0.786
[52,     3] loss: 0.820
[53,     3] loss: 0.883
[54,     3] loss: 0.762
[55,     3] loss: 0.819
[56,     3] loss: 0.864
[57,     3] loss: 0.778
[58,     3] loss: 0.790
[59,     3] loss: 0.775
[60,     3] loss: 0.774
[61,     3] loss: 0.769
[62,     3] loss: 0.764
[63,     3] loss: 0.757
[64,     3] loss: 0.746
[65,     3] loss: 0.743
[66,     3] loss: 0.771
[67,     3] loss: 0.744
[68,     3] loss: 0.731
[69,     3] loss: 0.801
[70,     3] loss: 0.901
Early stopping applied (best metric=0.5351380705833435)
Finished Training
Total time taken: 21.08314824104309
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.383
[3,     3] loss: 1.381
[4,     3] loss: 1.384
[5,     3] loss: 1.382
[6,     3] loss: 1.367
[7,     3] loss: 1.368
[8,     3] loss: 1.383
[9,     3] loss: 1.369
[10,     3] loss: 1.348
[11,     3] loss: 1.337
[12,     3] loss: 1.349
[13,     3] loss: 1.280
[14,     3] loss: 1.342
[15,     3] loss: 1.217
[16,     3] loss: 1.233
[17,     3] loss: 1.243
[18,     3] loss: 1.170
[19,     3] loss: 1.167
[20,     3] loss: 1.124
[21,     3] loss: 1.111
[22,     3] loss: 1.194
[23,     3] loss: 1.223
[24,     3] loss: 1.070
[25,     3] loss: 1.007
[26,     3] loss: 1.032
[27,     3] loss: 1.016
[28,     3] loss: 0.968
[29,     3] loss: 0.930
[30,     3] loss: 0.921
[31,     3] loss: 0.880
[32,     3] loss: 0.924
[33,     3] loss: 0.993
[34,     3] loss: 0.890
[35,     3] loss: 0.866
[36,     3] loss: 0.930
[37,     3] loss: 0.891
[38,     3] loss: 0.858
[39,     3] loss: 0.897
[40,     3] loss: 1.009
[41,     3] loss: 0.902
[42,     3] loss: 0.864
[43,     3] loss: 0.885
[44,     3] loss: 0.890
[45,     3] loss: 0.804
[46,     3] loss: 0.792
[47,     3] loss: 0.803
[48,     3] loss: 0.788
[49,     3] loss: 0.764
[50,     3] loss: 0.808
[51,     3] loss: 0.877
[52,     3] loss: 0.970
[53,     3] loss: 0.962
[54,     3] loss: 0.818
[55,     3] loss: 0.947
[56,     3] loss: 0.932
[57,     3] loss: 0.832
[58,     3] loss: 0.835
[59,     3] loss: 0.815
[60,     3] loss: 0.842
[61,     3] loss: 0.873
[62,     3] loss: 0.851
[63,     3] loss: 0.814
[64,     3] loss: 0.798
[65,     3] loss: 0.830
[66,     3] loss: 0.842
[67,     3] loss: 0.868
[68,     3] loss: 0.842
[69,     3] loss: 0.787
[70,     3] loss: 0.824
[71,     3] loss: 0.850
Early stopping applied (best metric=0.5165977478027344)
Finished Training
Total time taken: 20.411141633987427
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.386
[3,     3] loss: 1.392
[4,     3] loss: 1.388
[5,     3] loss: 1.387
[6,     3] loss: 1.387
[7,     3] loss: 1.380
[8,     3] loss: 1.386
[9,     3] loss: 1.381
[10,     3] loss: 1.381
[11,     3] loss: 1.386
[12,     3] loss: 1.367
[13,     3] loss: 1.375
[14,     3] loss: 1.353
[15,     3] loss: 1.344
[16,     3] loss: 1.324
[17,     3] loss: 1.369
[18,     3] loss: 1.307
[19,     3] loss: 1.291
[20,     3] loss: 1.264
[21,     3] loss: 1.211
[22,     3] loss: 1.332
[23,     3] loss: 1.181
[24,     3] loss: 1.217
[25,     3] loss: 1.164
[26,     3] loss: 1.073
[27,     3] loss: 1.149
[28,     3] loss: 1.042
[29,     3] loss: 1.034
[30,     3] loss: 1.038
[31,     3] loss: 0.943
[32,     3] loss: 1.008
[33,     3] loss: 1.132
[34,     3] loss: 0.986
[35,     3] loss: 0.971
[36,     3] loss: 0.981
[37,     3] loss: 0.928
[38,     3] loss: 0.944
[39,     3] loss: 0.950
[40,     3] loss: 0.983
[41,     3] loss: 0.845
[42,     3] loss: 0.835
[43,     3] loss: 0.851
[44,     3] loss: 0.879
[45,     3] loss: 0.898
[46,     3] loss: 0.910
[47,     3] loss: 0.892
[48,     3] loss: 0.831
[49,     3] loss: 0.836
[50,     3] loss: 0.869
[51,     3] loss: 0.874
[52,     3] loss: 0.926
[53,     3] loss: 0.833
[54,     3] loss: 0.813
[55,     3] loss: 0.828
[56,     3] loss: 0.875
[57,     3] loss: 0.818
[58,     3] loss: 0.824
[59,     3] loss: 0.805
[60,     3] loss: 0.857
[61,     3] loss: 0.812
[62,     3] loss: 0.771
[63,     3] loss: 0.850
[64,     3] loss: 0.785
[65,     3] loss: 0.760
[66,     3] loss: 0.777
[67,     3] loss: 0.813
[68,     3] loss: 0.797
[69,     3] loss: 0.754
[70,     3] loss: 0.816
[71,     3] loss: 0.853
[72,     3] loss: 0.793
[73,     3] loss: 0.831
[74,     3] loss: 0.756
[75,     3] loss: 0.784
[76,     3] loss: 0.845
[77,     3] loss: 0.851
[78,     3] loss: 0.793
[79,     3] loss: 0.806
[80,     3] loss: 0.828
[81,     3] loss: 0.753
[82,     3] loss: 0.803
[83,     3] loss: 0.822
[84,     3] loss: 0.792
[85,     3] loss: 0.829
[86,     3] loss: 0.841
[87,     3] loss: 0.770
[88,     3] loss: 0.762
[89,     3] loss: 0.756
[90,     3] loss: 0.757
[91,     3] loss: 0.783
[92,     3] loss: 0.748
[93,     3] loss: 0.773
[94,     3] loss: 0.794
[95,     3] loss: 0.762
[96,     3] loss: 0.750
[97,     3] loss: 0.762
Early stopping applied (best metric=0.5365371108055115)
Finished Training
Total time taken: 28.79971146583557
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.390
[3,     3] loss: 1.382
[4,     3] loss: 1.383
[5,     3] loss: 1.382
[6,     3] loss: 1.382
[7,     3] loss: 1.375
[8,     3] loss: 1.358
[9,     3] loss: 1.359
[10,     3] loss: 1.327
[11,     3] loss: 1.337
[12,     3] loss: 1.285
[13,     3] loss: 1.272
[14,     3] loss: 1.227
[15,     3] loss: 1.211
[16,     3] loss: 1.158
[17,     3] loss: 1.133
[18,     3] loss: 1.090
[19,     3] loss: 1.141
[20,     3] loss: 1.105
[21,     3] loss: 1.066
[22,     3] loss: 1.018
[23,     3] loss: 1.033
[24,     3] loss: 1.063
[25,     3] loss: 1.017
[26,     3] loss: 0.974
[27,     3] loss: 1.081
[28,     3] loss: 1.157
[29,     3] loss: 1.106
[30,     3] loss: 1.051
[31,     3] loss: 0.957
[32,     3] loss: 0.938
[33,     3] loss: 0.953
[34,     3] loss: 0.953
[35,     3] loss: 0.873
[36,     3] loss: 0.879
[37,     3] loss: 0.948
[38,     3] loss: 0.946
[39,     3] loss: 0.849
[40,     3] loss: 0.906
[41,     3] loss: 0.862
[42,     3] loss: 0.872
[43,     3] loss: 0.844
[44,     3] loss: 1.017
[45,     3] loss: 0.907
[46,     3] loss: 0.852
[47,     3] loss: 0.833
[48,     3] loss: 0.845
[49,     3] loss: 0.848
[50,     3] loss: 0.877
[51,     3] loss: 0.802
[52,     3] loss: 0.847
[53,     3] loss: 0.815
[54,     3] loss: 0.814
[55,     3] loss: 0.796
[56,     3] loss: 0.808
[57,     3] loss: 0.801
[58,     3] loss: 0.907
[59,     3] loss: 1.069
[60,     3] loss: 0.903
[61,     3] loss: 0.853
[62,     3] loss: 0.865
[63,     3] loss: 0.857
[64,     3] loss: 0.854
[65,     3] loss: 0.862
[66,     3] loss: 0.822
[67,     3] loss: 0.779
[68,     3] loss: 0.790
[69,     3] loss: 0.792
[70,     3] loss: 0.778
[71,     3] loss: 0.773
[72,     3] loss: 0.787
[73,     3] loss: 0.795
[74,     3] loss: 0.799
[75,     3] loss: 0.785
[76,     3] loss: 0.765
[77,     3] loss: 0.766
[78,     3] loss: 0.803
[79,     3] loss: 0.792
[80,     3] loss: 0.795
[81,     3] loss: 0.834
[82,     3] loss: 0.815
[83,     3] loss: 0.844
[84,     3] loss: 0.783
[85,     3] loss: 0.788
[86,     3] loss: 0.793
[87,     3] loss: 0.779
[88,     3] loss: 0.810
[89,     3] loss: 0.780
[90,     3] loss: 0.745
[91,     3] loss: 0.768
[92,     3] loss: 0.750
[93,     3] loss: 0.754
Early stopping applied (best metric=0.5231305956840515)
Finished Training
Total time taken: 26.85312557220459
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.391
[3,     3] loss: 1.387
[4,     3] loss: 1.377
[5,     3] loss: 1.381
[6,     3] loss: 1.382
[7,     3] loss: 1.386
[8,     3] loss: 1.372
[9,     3] loss: 1.372
[10,     3] loss: 1.359
[11,     3] loss: 1.345
[12,     3] loss: 1.348
[13,     3] loss: 1.327
[14,     3] loss: 1.266
[15,     3] loss: 1.305
[16,     3] loss: 1.228
[17,     3] loss: 1.237
[18,     3] loss: 1.281
[19,     3] loss: 1.233
[20,     3] loss: 1.231
[21,     3] loss: 1.192
[22,     3] loss: 1.154
[23,     3] loss: 1.194
[24,     3] loss: 1.121
[25,     3] loss: 1.142
[26,     3] loss: 1.128
[27,     3] loss: 1.212
[28,     3] loss: 1.114
[29,     3] loss: 1.120
[30,     3] loss: 1.064
[31,     3] loss: 1.081
[32,     3] loss: 1.092
[33,     3] loss: 1.026
[34,     3] loss: 1.006
[35,     3] loss: 1.119
[36,     3] loss: 0.987
[37,     3] loss: 0.960
[38,     3] loss: 0.940
[39,     3] loss: 0.947
[40,     3] loss: 0.860
[41,     3] loss: 0.873
[42,     3] loss: 0.814
[43,     3] loss: 0.828
[44,     3] loss: 0.868
[45,     3] loss: 0.823
[46,     3] loss: 0.798
[47,     3] loss: 0.774
[48,     3] loss: 0.803
[49,     3] loss: 0.805
[50,     3] loss: 0.907
[51,     3] loss: 0.801
[52,     3] loss: 0.831
[53,     3] loss: 0.860
[54,     3] loss: 0.860
[55,     3] loss: 0.837
[56,     3] loss: 0.761
[57,     3] loss: 0.802
[58,     3] loss: 0.823
[59,     3] loss: 0.769
[60,     3] loss: 0.788
[61,     3] loss: 0.831
[62,     3] loss: 0.784
[63,     3] loss: 0.764
[64,     3] loss: 0.770
[65,     3] loss: 0.766
[66,     3] loss: 0.752
[67,     3] loss: 0.799
[68,     3] loss: 0.792
[69,     3] loss: 0.780
[70,     3] loss: 0.760
[71,     3] loss: 0.765
[72,     3] loss: 0.757
[73,     3] loss: 0.753
[74,     3] loss: 0.737
[75,     3] loss: 0.750
[76,     3] loss: 0.732
[77,     3] loss: 0.740
Early stopping applied (best metric=0.5008295774459839)
Finished Training
Total time taken: 22.93283247947693
{'S-palmitoylation-C Validation Accuracy': 0.7257199568989962, 'S-palmitoylation-C Validation Sensitivity': 0.1801980198019802, 'S-palmitoylation-C Validation Specificity': 0.8624631056549562, 'S-palmitoylation-C Validation Precision': 0.2549059477384169, 'S-palmitoylation-C AUC ROC': 0.5481312138601353, 'S-palmitoylation-C AUC PR': 0.2285604818458618, 'S-palmitoylation-C MCC': 0.049717310372415724, 'S-palmitoylation-C F1': 0.19300059320306223, 'Validation Loss (S-palmitoylation-C)': 0.5541393955548605, 'Hydroxylation-K Validation Accuracy': 0.7715425531914893, 'Hydroxylation-K Validation Sensitivity': 0.7037037037037037, 'Hydroxylation-K Validation Specificity': 0.7894736842105263, 'Hydroxylation-K Validation Precision': 0.48344570083700517, 'Hydroxylation-K AUC ROC': 0.8225341130604289, 'Hydroxylation-K AUC PR': 0.5752625644067, 'Hydroxylation-K MCC': 0.44159423524453656, 'Hydroxylation-K F1': 0.5586634596514796, 'Validation Loss (Hydroxylation-K)': 0.5201867918173472, 'Validation Loss (total)': 1.074326181411743, 'TimeToTrain': 23.9157740910848}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00972010176460453,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.20006178924684795,
 'loss_weight_S-palmitoylation-C': 0.6941783415567419,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3349712606,
 'sample_weights': [0.026557648831539202, 0.8885537682907192],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.570661724410453,
 'weight_decay_Hydroxylation-K': 8.400636842668998,
 'weight_decay_S-palmitoylation-C': 6.985728701120497}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.389
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0039965890531719495,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9651604182072956,
 'loss_weight_S-palmitoylation-C': 0.2119111250844144,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3638253318,
 'sample_weights': [0.6941783415567419, 0.20006178924684795],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.43546362947041,
 'weight_decay_Hydroxylation-K': 5.344683873435626,
 'weight_decay_S-palmitoylation-C': 7.449013577463234}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009360544284204154,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8890004569882525,
 'loss_weight_S-palmitoylation-C': 0.08449584692043333,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 918712727,
 'sample_weights': [0.2119111250844144, 0.9651604182072956],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.6835730319381845,
 'weight_decay_Hydroxylation-K': 5.22268904801126,
 'weight_decay_S-palmitoylation-C': 3.330293435776908}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.380
[3,     3] loss: 1.388
[4,     3] loss: 1.389
[5,     3] loss: 1.383
[6,     3] loss: 1.387
[7,     3] loss: 1.384
[8,     3] loss: 1.381
[9,     3] loss: 1.383
[10,     3] loss: 1.380
[11,     3] loss: 1.363
[12,     3] loss: 1.374
[13,     3] loss: 1.356
[14,     3] loss: 1.355
[15,     3] loss: 1.308
[16,     3] loss: 1.312
[17,     3] loss: 1.267
[18,     3] loss: 1.231
[19,     3] loss: 1.220
[20,     3] loss: 1.127
[21,     3] loss: 1.110
[22,     3] loss: 1.183
[23,     3] loss: 1.077
[24,     3] loss: 1.196
[25,     3] loss: 1.074
[26,     3] loss: 1.017
[27,     3] loss: 1.058
[28,     3] loss: 1.079
[29,     3] loss: 1.058
[30,     3] loss: 1.043
[31,     3] loss: 0.997
[32,     3] loss: 0.937
[33,     3] loss: 0.922
[34,     3] loss: 0.880
[35,     3] loss: 0.861
[36,     3] loss: 0.908
[37,     3] loss: 0.968
[38,     3] loss: 0.865
[39,     3] loss: 0.826
[40,     3] loss: 0.934
[41,     3] loss: 0.877
[42,     3] loss: 1.040
[43,     3] loss: 1.027
[44,     3] loss: 0.913
[45,     3] loss: 0.938
[46,     3] loss: 0.949
[47,     3] loss: 0.964
[48,     3] loss: 0.872
[49,     3] loss: 0.865
[50,     3] loss: 0.836
[51,     3] loss: 0.901
[52,     3] loss: 0.912
[53,     3] loss: 0.961
[54,     3] loss: 0.952
[55,     3] loss: 0.865
[56,     3] loss: 0.936
[57,     3] loss: 0.896
[58,     3] loss: 0.957
[59,     3] loss: 0.968
[60,     3] loss: 0.837
[61,     3] loss: 0.875
[62,     3] loss: 0.855
[63,     3] loss: 0.797
[64,     3] loss: 0.883
[65,     3] loss: 0.800
[66,     3] loss: 0.896
[67,     3] loss: 0.843
[68,     3] loss: 0.817
[69,     3] loss: 0.800
[70,     3] loss: 0.842
[71,     3] loss: 0.844
[72,     3] loss: 0.836
Early stopping applied (best metric=0.5199353098869324)
Finished Training
Total time taken: 21.653103828430176
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.389
[3,     3] loss: 1.381
[4,     3] loss: 1.386
[5,     3] loss: 1.382
[6,     3] loss: 1.379
[7,     3] loss: 1.358
[8,     3] loss: 1.364
[9,     3] loss: 1.344
[10,     3] loss: 1.330
[11,     3] loss: 1.337
[12,     3] loss: 1.325
[13,     3] loss: 1.293
[14,     3] loss: 1.287
[15,     3] loss: 1.224
[16,     3] loss: 1.237
[17,     3] loss: 1.188
[18,     3] loss: 1.290
[19,     3] loss: 1.256
[20,     3] loss: 1.158
[21,     3] loss: 1.185
[22,     3] loss: 1.084
[23,     3] loss: 1.130
[24,     3] loss: 1.156
[25,     3] loss: 1.091
[26,     3] loss: 1.119
[27,     3] loss: 1.023
[28,     3] loss: 1.020
[29,     3] loss: 1.059
[30,     3] loss: 0.945
[31,     3] loss: 0.986
[32,     3] loss: 0.935
[33,     3] loss: 1.149
[34,     3] loss: 1.084
[35,     3] loss: 1.026
[36,     3] loss: 0.975
[37,     3] loss: 0.980
[38,     3] loss: 1.001
[39,     3] loss: 1.020
[40,     3] loss: 0.949
[41,     3] loss: 1.037
[42,     3] loss: 1.001
[43,     3] loss: 0.987
[44,     3] loss: 0.967
[45,     3] loss: 0.948
[46,     3] loss: 1.012
[47,     3] loss: 0.930
[48,     3] loss: 1.006
[49,     3] loss: 0.966
[50,     3] loss: 0.885
[51,     3] loss: 0.888
[52,     3] loss: 0.939
[53,     3] loss: 0.950
[54,     3] loss: 0.909
[55,     3] loss: 0.832
[56,     3] loss: 0.844
[57,     3] loss: 0.864
[58,     3] loss: 0.872
[59,     3] loss: 0.829
[60,     3] loss: 0.810
[61,     3] loss: 0.874
[62,     3] loss: 0.810
[63,     3] loss: 0.801
[64,     3] loss: 0.830
[65,     3] loss: 0.809
[66,     3] loss: 0.888
[67,     3] loss: 0.798
[68,     3] loss: 0.839
[69,     3] loss: 0.835
[70,     3] loss: 0.784
[71,     3] loss: 0.787
[72,     3] loss: 0.845
[73,     3] loss: 0.788
[74,     3] loss: 0.824
[75,     3] loss: 0.774
[76,     3] loss: 0.834
[77,     3] loss: 0.827
[78,     3] loss: 0.799
[79,     3] loss: 0.800
Early stopping applied (best metric=0.4819360375404358)
Finished Training
Total time taken: 23.28511142730713
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.386
[3,     3] loss: 1.389
[4,     3] loss: 1.376
[5,     3] loss: 1.374
[6,     3] loss: 1.370
[7,     3] loss: 1.366
[8,     3] loss: 1.361
[9,     3] loss: 1.304
[10,     3] loss: 1.335
[11,     3] loss: 1.296
[12,     3] loss: 1.311
[13,     3] loss: 1.273
[14,     3] loss: 1.244
[15,     3] loss: 1.256
[16,     3] loss: 1.182
[17,     3] loss: 1.178
[18,     3] loss: 1.213
[19,     3] loss: 1.217
[20,     3] loss: 1.179
[21,     3] loss: 1.113
[22,     3] loss: 1.164
[23,     3] loss: 1.016
[24,     3] loss: 1.104
[25,     3] loss: 1.105
[26,     3] loss: 1.010
[27,     3] loss: 1.034
[28,     3] loss: 0.985
[29,     3] loss: 1.029
[30,     3] loss: 0.973
[31,     3] loss: 0.923
[32,     3] loss: 0.921
[33,     3] loss: 1.023
[34,     3] loss: 0.970
[35,     3] loss: 0.972
[36,     3] loss: 1.019
[37,     3] loss: 0.909
[38,     3] loss: 0.903
[39,     3] loss: 0.989
[40,     3] loss: 0.887
[41,     3] loss: 0.868
[42,     3] loss: 0.888
[43,     3] loss: 0.874
[44,     3] loss: 0.809
[45,     3] loss: 0.859
[46,     3] loss: 0.812
[47,     3] loss: 0.791
[48,     3] loss: 0.826
[49,     3] loss: 0.845
[50,     3] loss: 0.856
[51,     3] loss: 0.875
[52,     3] loss: 0.804
[53,     3] loss: 0.872
[54,     3] loss: 0.806
[55,     3] loss: 0.879
[56,     3] loss: 0.784
[57,     3] loss: 0.854
[58,     3] loss: 0.901
[59,     3] loss: 0.801
[60,     3] loss: 0.813
[61,     3] loss: 0.819
[62,     3] loss: 0.791
[63,     3] loss: 0.813
[64,     3] loss: 0.841
[65,     3] loss: 0.854
[66,     3] loss: 0.750
[67,     3] loss: 0.785
[68,     3] loss: 0.755
[69,     3] loss: 0.754
[70,     3] loss: 0.752
[71,     3] loss: 0.801
[72,     3] loss: 0.771
[73,     3] loss: 0.801
[74,     3] loss: 0.757
Early stopping applied (best metric=0.5349061489105225)
Finished Training
Total time taken: 22.007107257843018
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.389
[3,     3] loss: 1.390
[4,     3] loss: 1.383
[5,     3] loss: 1.385
[6,     3] loss: 1.384
[7,     3] loss: 1.378
[8,     3] loss: 1.381
[9,     3] loss: 1.370
[10,     3] loss: 1.357
[11,     3] loss: 1.355
[12,     3] loss: 1.343
[13,     3] loss: 1.311
[14,     3] loss: 1.282
[15,     3] loss: 1.262
[16,     3] loss: 1.195
[17,     3] loss: 1.159
[18,     3] loss: 1.198
[19,     3] loss: 1.140
[20,     3] loss: 1.119
[21,     3] loss: 0.993
[22,     3] loss: 1.027
[23,     3] loss: 0.967
[24,     3] loss: 0.941
[25,     3] loss: 1.029
[26,     3] loss: 0.996
[27,     3] loss: 1.015
[28,     3] loss: 0.898
[29,     3] loss: 0.866
[30,     3] loss: 1.013
[31,     3] loss: 0.917
[32,     3] loss: 0.828
[33,     3] loss: 0.851
[34,     3] loss: 0.878
[35,     3] loss: 0.848
[36,     3] loss: 0.811
[37,     3] loss: 0.848
[38,     3] loss: 0.846
[39,     3] loss: 0.858
[40,     3] loss: 0.868
[41,     3] loss: 0.999
[42,     3] loss: 0.897
[43,     3] loss: 0.823
[44,     3] loss: 0.785
[45,     3] loss: 0.874
[46,     3] loss: 0.777
[47,     3] loss: 0.797
[48,     3] loss: 0.797
[49,     3] loss: 0.811
[50,     3] loss: 0.883
[51,     3] loss: 0.830
[52,     3] loss: 0.813
[53,     3] loss: 0.764
[54,     3] loss: 0.791
[55,     3] loss: 0.813
[56,     3] loss: 0.842
[57,     3] loss: 0.762
[58,     3] loss: 0.769
[59,     3] loss: 0.812
[60,     3] loss: 0.816
[61,     3] loss: 0.840
[62,     3] loss: 0.799
[63,     3] loss: 0.802
[64,     3] loss: 0.777
[65,     3] loss: 0.783
[66,     3] loss: 0.773
[67,     3] loss: 0.783
[68,     3] loss: 0.763
[69,     3] loss: 0.750
[70,     3] loss: 0.821
[71,     3] loss: 0.830
Early stopping applied (best metric=0.5274062156677246)
Finished Training
Total time taken: 21.31410264968872
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.389
[3,     3] loss: 1.385
[4,     3] loss: 1.374
[5,     3] loss: 1.379
[6,     3] loss: 1.374
[7,     3] loss: 1.362
[8,     3] loss: 1.356
[9,     3] loss: 1.335
[10,     3] loss: 1.329
[11,     3] loss: 1.296
[12,     3] loss: 1.257
[13,     3] loss: 1.245
[14,     3] loss: 1.205
[15,     3] loss: 1.241
[16,     3] loss: 1.139
[17,     3] loss: 1.124
[18,     3] loss: 1.124
[19,     3] loss: 1.130
[20,     3] loss: 1.114
[21,     3] loss: 0.997
[22,     3] loss: 1.107
[23,     3] loss: 0.966
[24,     3] loss: 1.125
[25,     3] loss: 0.939
[26,     3] loss: 1.001
[27,     3] loss: 0.957
[28,     3] loss: 1.013
[29,     3] loss: 0.963
[30,     3] loss: 0.881
[31,     3] loss: 0.947
[32,     3] loss: 0.964
[33,     3] loss: 1.015
[34,     3] loss: 0.923
[35,     3] loss: 0.936
[36,     3] loss: 0.969
[37,     3] loss: 1.050
[38,     3] loss: 0.960
[39,     3] loss: 0.877
[40,     3] loss: 0.992
[41,     3] loss: 0.951
[42,     3] loss: 0.896
[43,     3] loss: 0.860
[44,     3] loss: 0.852
[45,     3] loss: 0.861
[46,     3] loss: 0.939
[47,     3] loss: 0.890
[48,     3] loss: 0.801
[49,     3] loss: 0.800
[50,     3] loss: 0.823
[51,     3] loss: 0.831
[52,     3] loss: 0.766
[53,     3] loss: 0.799
[54,     3] loss: 0.778
[55,     3] loss: 0.788
[56,     3] loss: 0.789
[57,     3] loss: 0.849
[58,     3] loss: 0.800
[59,     3] loss: 0.757
[60,     3] loss: 0.795
[61,     3] loss: 0.805
[62,     3] loss: 0.764
[63,     3] loss: 0.805
[64,     3] loss: 0.839
[65,     3] loss: 0.922
[66,     3] loss: 0.817
Early stopping applied (best metric=0.5224767327308655)
Finished Training
Total time taken: 19.490095138549805
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.389
[3,     3] loss: 1.383
[4,     3] loss: 1.382
[5,     3] loss: 1.376
[6,     3] loss: 1.385
[7,     3] loss: 1.377
[8,     3] loss: 1.356
[9,     3] loss: 1.350
[10,     3] loss: 1.340
[11,     3] loss: 1.323
[12,     3] loss: 1.334
[13,     3] loss: 1.260
[14,     3] loss: 1.255
[15,     3] loss: 1.277
[16,     3] loss: 1.217
[17,     3] loss: 1.161
[18,     3] loss: 1.146
[19,     3] loss: 1.145
[20,     3] loss: 1.102
[21,     3] loss: 1.180
[22,     3] loss: 1.037
[23,     3] loss: 1.120
[24,     3] loss: 1.074
[25,     3] loss: 1.069
[26,     3] loss: 1.093
[27,     3] loss: 1.014
[28,     3] loss: 0.947
[29,     3] loss: 0.933
[30,     3] loss: 1.085
[31,     3] loss: 1.011
[32,     3] loss: 0.897
[33,     3] loss: 0.984
[34,     3] loss: 0.901
[35,     3] loss: 0.900
[36,     3] loss: 0.904
[37,     3] loss: 1.036
[38,     3] loss: 0.943
[39,     3] loss: 0.907
[40,     3] loss: 0.966
[41,     3] loss: 0.975
[42,     3] loss: 0.910
[43,     3] loss: 0.843
[44,     3] loss: 0.913
[45,     3] loss: 0.990
[46,     3] loss: 0.908
[47,     3] loss: 0.964
[48,     3] loss: 0.921
[49,     3] loss: 1.022
[50,     3] loss: 0.873
[51,     3] loss: 0.891
[52,     3] loss: 0.869
[53,     3] loss: 0.910
[54,     3] loss: 0.884
[55,     3] loss: 0.815
[56,     3] loss: 0.855
[57,     3] loss: 0.856
[58,     3] loss: 0.843
[59,     3] loss: 0.834
[60,     3] loss: 0.856
[61,     3] loss: 0.867
[62,     3] loss: 0.869
[63,     3] loss: 0.847
[64,     3] loss: 0.843
[65,     3] loss: 0.871
[66,     3] loss: 0.787
[67,     3] loss: 0.795
[68,     3] loss: 0.842
[69,     3] loss: 0.793
[70,     3] loss: 0.792
[71,     3] loss: 0.778
[72,     3] loss: 0.790
[73,     3] loss: 0.800
[74,     3] loss: 0.782
[75,     3] loss: 0.797
[76,     3] loss: 0.908
[77,     3] loss: 0.800
[78,     3] loss: 0.775
[79,     3] loss: 0.823
[80,     3] loss: 0.789
[81,     3] loss: 0.789
[82,     3] loss: 0.805
[83,     3] loss: 0.812
[84,     3] loss: 0.809
[85,     3] loss: 0.824
[86,     3] loss: 0.946
[87,     3] loss: 0.962
[88,     3] loss: 0.879
[89,     3] loss: 0.814
[90,     3] loss: 0.853
[91,     3] loss: 0.795
[92,     3] loss: 0.798
[93,     3] loss: 0.781
[94,     3] loss: 0.754
[95,     3] loss: 0.790
[96,     3] loss: 0.810
[97,     3] loss: 0.787
[98,     3] loss: 0.759
[99,     3] loss: 0.765
[100,     3] loss: 0.734
[101,     3] loss: 0.856
[102,     3] loss: 0.796
[103,     3] loss: 0.742
[104,     3] loss: 0.796
[105,     3] loss: 0.851
[106,     3] loss: 0.765
[107,     3] loss: 0.831
[108,     3] loss: 0.806
[109,     3] loss: 0.760
[110,     3] loss: 0.786
[111,     3] loss: 0.765
[112,     3] loss: 0.746
Early stopping applied (best metric=0.5059359669685364)
Finished Training
Total time taken: 33.02015662193298
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.378
[2,     3] loss: 1.399
[3,     3] loss: 1.386
[4,     3] loss: 1.401
[5,     3] loss: 1.386
[6,     3] loss: 1.386
[7,     3] loss: 1.388
[8,     3] loss: 1.374
[9,     3] loss: 1.384
[10,     3] loss: 1.376
[11,     3] loss: 1.380
[12,     3] loss: 1.378
[13,     3] loss: 1.375
[14,     3] loss: 1.368
[15,     3] loss: 1.355
[16,     3] loss: 1.316
[17,     3] loss: 1.271
[18,     3] loss: 1.264
[19,     3] loss: 1.251
[20,     3] loss: 1.209
[21,     3] loss: 1.167
[22,     3] loss: 1.206
[23,     3] loss: 1.116
[24,     3] loss: 1.064
[25,     3] loss: 1.051
[26,     3] loss: 1.051
[27,     3] loss: 1.135
[28,     3] loss: 1.006
[29,     3] loss: 1.047
[30,     3] loss: 1.015
[31,     3] loss: 1.006
[32,     3] loss: 0.925
[33,     3] loss: 0.948
[34,     3] loss: 0.939
[35,     3] loss: 0.890
[36,     3] loss: 0.936
[37,     3] loss: 0.876
[38,     3] loss: 0.879
[39,     3] loss: 0.954
[40,     3] loss: 0.851
[41,     3] loss: 0.868
[42,     3] loss: 0.874
[43,     3] loss: 0.968
[44,     3] loss: 0.965
[45,     3] loss: 0.858
[46,     3] loss: 0.906
[47,     3] loss: 0.937
[48,     3] loss: 0.974
[49,     3] loss: 0.901
[50,     3] loss: 0.871
[51,     3] loss: 0.876
[52,     3] loss: 0.852
[53,     3] loss: 0.920
[54,     3] loss: 0.818
[55,     3] loss: 0.817
[56,     3] loss: 0.850
[57,     3] loss: 0.847
[58,     3] loss: 0.781
[59,     3] loss: 0.825
[60,     3] loss: 0.822
[61,     3] loss: 0.806
[62,     3] loss: 0.778
[63,     3] loss: 0.830
[64,     3] loss: 0.786
[65,     3] loss: 0.813
[66,     3] loss: 0.843
[67,     3] loss: 0.775
[68,     3] loss: 0.798
[69,     3] loss: 0.878
[70,     3] loss: 0.899
[71,     3] loss: 0.808
[72,     3] loss: 0.818
[73,     3] loss: 0.815
[74,     3] loss: 0.805
[75,     3] loss: 0.796
[76,     3] loss: 0.780
[77,     3] loss: 0.767
[78,     3] loss: 0.788
[79,     3] loss: 0.752
[80,     3] loss: 0.878
[81,     3] loss: 0.803
[82,     3] loss: 0.759
[83,     3] loss: 0.761
[84,     3] loss: 0.762
[85,     3] loss: 0.802
[86,     3] loss: 0.750
[87,     3] loss: 0.741
[88,     3] loss: 0.745
Early stopping applied (best metric=0.529863715171814)
Finished Training
Total time taken: 26.46412754058838
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.387
[4,     3] loss: 1.380
[5,     3] loss: 1.388
[6,     3] loss: 1.387
[7,     3] loss: 1.387
[8,     3] loss: 1.390
[9,     3] loss: 1.382
[10,     3] loss: 1.375
[11,     3] loss: 1.380
[12,     3] loss: 1.367
[13,     3] loss: 1.356
[14,     3] loss: 1.352
[15,     3] loss: 1.343
[16,     3] loss: 1.329
[17,     3] loss: 1.296
[18,     3] loss: 1.292
[19,     3] loss: 1.264
[20,     3] loss: 1.296
[21,     3] loss: 1.245
[22,     3] loss: 1.263
[23,     3] loss: 1.155
[24,     3] loss: 1.218
[25,     3] loss: 1.111
[26,     3] loss: 1.103
[27,     3] loss: 1.083
[28,     3] loss: 1.021
[29,     3] loss: 0.977
[30,     3] loss: 1.021
[31,     3] loss: 1.036
[32,     3] loss: 1.116
[33,     3] loss: 1.092
[34,     3] loss: 1.024
[35,     3] loss: 1.059
[36,     3] loss: 1.057
[37,     3] loss: 0.941
[38,     3] loss: 0.982
[39,     3] loss: 0.960
[40,     3] loss: 0.979
[41,     3] loss: 0.961
[42,     3] loss: 1.022
[43,     3] loss: 1.054
[44,     3] loss: 0.956
[45,     3] loss: 0.976
[46,     3] loss: 1.037
[47,     3] loss: 0.953
[48,     3] loss: 0.957
[49,     3] loss: 0.987
[50,     3] loss: 0.901
[51,     3] loss: 0.914
[52,     3] loss: 0.933
[53,     3] loss: 0.875
[54,     3] loss: 0.907
[55,     3] loss: 0.896
[56,     3] loss: 0.844
[57,     3] loss: 0.871
[58,     3] loss: 0.841
[59,     3] loss: 1.002
[60,     3] loss: 0.896
[61,     3] loss: 0.820
[62,     3] loss: 0.923
[63,     3] loss: 0.901
[64,     3] loss: 0.801
[65,     3] loss: 0.858
[66,     3] loss: 0.835
[67,     3] loss: 0.902
[68,     3] loss: 0.814
[69,     3] loss: 0.789
[70,     3] loss: 0.856
[71,     3] loss: 0.759
[72,     3] loss: 0.794
[73,     3] loss: 0.814
[74,     3] loss: 0.776
[75,     3] loss: 0.758
[76,     3] loss: 0.769
[77,     3] loss: 0.757
Early stopping applied (best metric=0.5118954181671143)
Finished Training
Total time taken: 23.363112449645996
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.389
[3,     3] loss: 1.383
[4,     3] loss: 1.389
[5,     3] loss: 1.376
[6,     3] loss: 1.384
[7,     3] loss: 1.379
[8,     3] loss: 1.380
[9,     3] loss: 1.365
[10,     3] loss: 1.354
[11,     3] loss: 1.363
[12,     3] loss: 1.316
[13,     3] loss: 1.332
[14,     3] loss: 1.328
[15,     3] loss: 1.299
[16,     3] loss: 1.246
[17,     3] loss: 1.284
[18,     3] loss: 1.215
[19,     3] loss: 1.249
[20,     3] loss: 1.248
[21,     3] loss: 1.120
[22,     3] loss: 1.115
[23,     3] loss: 1.060
[24,     3] loss: 1.160
[25,     3] loss: 1.044
[26,     3] loss: 1.052
[27,     3] loss: 1.093
[28,     3] loss: 1.005
[29,     3] loss: 1.072
[30,     3] loss: 1.050
[31,     3] loss: 0.956
[32,     3] loss: 1.000
[33,     3] loss: 0.886
[34,     3] loss: 0.894
[35,     3] loss: 1.000
[36,     3] loss: 0.922
[37,     3] loss: 0.903
[38,     3] loss: 1.049
[39,     3] loss: 0.950
[40,     3] loss: 0.878
[41,     3] loss: 0.963
[42,     3] loss: 0.911
[43,     3] loss: 0.843
[44,     3] loss: 0.840
[45,     3] loss: 0.829
[46,     3] loss: 0.941
[47,     3] loss: 0.837
[48,     3] loss: 0.839
[49,     3] loss: 0.820
[50,     3] loss: 0.860
[51,     3] loss: 0.815
[52,     3] loss: 0.910
[53,     3] loss: 0.943
[54,     3] loss: 0.901
[55,     3] loss: 0.877
[56,     3] loss: 0.884
[57,     3] loss: 0.848
[58,     3] loss: 0.883
[59,     3] loss: 0.868
[60,     3] loss: 0.862
[61,     3] loss: 0.826
[62,     3] loss: 0.784
[63,     3] loss: 0.808
[64,     3] loss: 0.788
[65,     3] loss: 0.781
[66,     3] loss: 0.795
[67,     3] loss: 0.772
[68,     3] loss: 0.749
[69,     3] loss: 0.755
[70,     3] loss: 0.741
Early stopping applied (best metric=0.46941739320755005)
Finished Training
Total time taken: 20.898102283477783
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.389
[3,     3] loss: 1.373
[4,     3] loss: 1.400
[5,     3] loss: 1.384
[6,     3] loss: 1.396
[7,     3] loss: 1.382
[8,     3] loss: 1.381
[9,     3] loss: 1.382
[10,     3] loss: 1.388
[11,     3] loss: 1.380
[12,     3] loss: 1.380
[13,     3] loss: 1.379
[14,     3] loss: 1.369
[15,     3] loss: 1.357
[16,     3] loss: 1.353
[17,     3] loss: 1.336
[18,     3] loss: 1.317
[19,     3] loss: 1.313
[20,     3] loss: 1.279
[21,     3] loss: 1.222
[22,     3] loss: 1.274
[23,     3] loss: 1.265
[24,     3] loss: 1.170
[25,     3] loss: 1.158
[26,     3] loss: 1.232
[27,     3] loss: 1.116
[28,     3] loss: 1.098
[29,     3] loss: 1.074
[30,     3] loss: 0.977
[31,     3] loss: 1.093
[32,     3] loss: 0.984
[33,     3] loss: 0.965
[34,     3] loss: 0.941
[35,     3] loss: 0.977
[36,     3] loss: 0.878
[37,     3] loss: 0.850
[38,     3] loss: 0.947
[39,     3] loss: 0.934
[40,     3] loss: 0.991
[41,     3] loss: 0.940
[42,     3] loss: 0.923
[43,     3] loss: 0.890
[44,     3] loss: 0.957
[45,     3] loss: 0.877
[46,     3] loss: 0.916
[47,     3] loss: 0.855
[48,     3] loss: 0.868
[49,     3] loss: 0.942
[50,     3] loss: 0.928
[51,     3] loss: 0.864
[52,     3] loss: 0.867
[53,     3] loss: 0.839
[54,     3] loss: 0.930
[55,     3] loss: 0.827
[56,     3] loss: 0.870
[57,     3] loss: 0.802
[58,     3] loss: 0.806
[59,     3] loss: 0.791
[60,     3] loss: 0.785
[61,     3] loss: 0.797
[62,     3] loss: 0.774
[63,     3] loss: 0.777
[64,     3] loss: 0.768
[65,     3] loss: 0.751
[66,     3] loss: 0.770
[67,     3] loss: 0.762
[68,     3] loss: 0.734
[69,     3] loss: 0.802
[70,     3] loss: 0.816
[71,     3] loss: 0.819
[72,     3] loss: 0.797
[73,     3] loss: 0.752
[74,     3] loss: 0.829
[75,     3] loss: 0.753
[76,     3] loss: 0.751
[77,     3] loss: 0.766
[78,     3] loss: 0.779
[79,     3] loss: 0.782
[80,     3] loss: 0.785
[81,     3] loss: 0.802
[82,     3] loss: 0.777
[83,     3] loss: 0.809
[84,     3] loss: 0.779
[85,     3] loss: 0.787
[86,     3] loss: 0.789
[87,     3] loss: 0.805
[88,     3] loss: 0.753
[89,     3] loss: 0.804
[90,     3] loss: 0.820
[91,     3] loss: 0.778
[92,     3] loss: 0.767
[93,     3] loss: 0.773
[94,     3] loss: 0.753
[95,     3] loss: 0.765
[96,     3] loss: 0.729
[97,     3] loss: 0.751
[98,     3] loss: 0.744
Early stopping applied (best metric=0.5136152505874634)
Finished Training
Total time taken: 28.181137561798096
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.388
[3,     3] loss: 1.389
[4,     3] loss: 1.385
[5,     3] loss: 1.391
[6,     3] loss: 1.388
[7,     3] loss: 1.381
[8,     3] loss: 1.382
[9,     3] loss: 1.386
[10,     3] loss: 1.382
[11,     3] loss: 1.382
[12,     3] loss: 1.382
[13,     3] loss: 1.373
[14,     3] loss: 1.357
[15,     3] loss: 1.346
[16,     3] loss: 1.308
[17,     3] loss: 1.297
[18,     3] loss: 1.257
[19,     3] loss: 1.215
[20,     3] loss: 1.149
[21,     3] loss: 1.117
[22,     3] loss: 1.119
[23,     3] loss: 1.072
[24,     3] loss: 1.028
[25,     3] loss: 0.949
[26,     3] loss: 1.018
[27,     3] loss: 1.134
[28,     3] loss: 1.120
[29,     3] loss: 1.074
[30,     3] loss: 1.077
[31,     3] loss: 0.996
[32,     3] loss: 0.986
[33,     3] loss: 1.033
[34,     3] loss: 1.002
[35,     3] loss: 0.961
[36,     3] loss: 0.898
[37,     3] loss: 0.961
[38,     3] loss: 0.921
[39,     3] loss: 0.813
[40,     3] loss: 0.887
[41,     3] loss: 0.872
[42,     3] loss: 0.818
[43,     3] loss: 0.908
[44,     3] loss: 0.916
[45,     3] loss: 0.898
[46,     3] loss: 0.884
[47,     3] loss: 0.832
[48,     3] loss: 0.827
[49,     3] loss: 0.936
[50,     3] loss: 0.896
[51,     3] loss: 0.846
[52,     3] loss: 0.880
[53,     3] loss: 0.874
[54,     3] loss: 0.882
[55,     3] loss: 0.874
[56,     3] loss: 0.806
[57,     3] loss: 0.904
[58,     3] loss: 0.826
[59,     3] loss: 0.926
[60,     3] loss: 0.899
[61,     3] loss: 0.852
[62,     3] loss: 0.802
[63,     3] loss: 0.938
[64,     3] loss: 0.790
[65,     3] loss: 0.810
[66,     3] loss: 0.797
[67,     3] loss: 0.780
[68,     3] loss: 0.796
[69,     3] loss: 0.771
[70,     3] loss: 0.741
[71,     3] loss: 0.749
[72,     3] loss: 0.742
[73,     3] loss: 0.745
[74,     3] loss: 0.732
[75,     3] loss: 0.744
[76,     3] loss: 0.768
Early stopping applied (best metric=0.5323094725608826)
Finished Training
Total time taken: 22.82911229133606
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.407
[3,     3] loss: 1.394
[4,     3] loss: 1.382
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.386
[8,     3] loss: 1.383
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.384
[12,     3] loss: 1.371
[13,     3] loss: 1.372
[14,     3] loss: 1.360
[15,     3] loss: 1.361
[16,     3] loss: 1.331
[17,     3] loss: 1.341
[18,     3] loss: 1.304
[19,     3] loss: 1.282
[20,     3] loss: 1.243
[21,     3] loss: 1.203
[22,     3] loss: 1.210
[23,     3] loss: 1.151
[24,     3] loss: 1.096
[25,     3] loss: 1.061
[26,     3] loss: 1.102
[27,     3] loss: 1.031
[28,     3] loss: 0.990
[29,     3] loss: 1.041
[30,     3] loss: 1.000
[31,     3] loss: 1.028
[32,     3] loss: 1.120
[33,     3] loss: 1.069
[34,     3] loss: 0.985
[35,     3] loss: 1.041
[36,     3] loss: 1.029
[37,     3] loss: 0.915
[38,     3] loss: 0.901
[39,     3] loss: 0.932
[40,     3] loss: 0.902
[41,     3] loss: 0.885
[42,     3] loss: 0.899
[43,     3] loss: 0.836
[44,     3] loss: 0.890
[45,     3] loss: 0.914
[46,     3] loss: 0.906
[47,     3] loss: 0.900
[48,     3] loss: 0.818
[49,     3] loss: 0.832
[50,     3] loss: 0.854
[51,     3] loss: 0.819
[52,     3] loss: 0.837
[53,     3] loss: 0.814
[54,     3] loss: 0.823
[55,     3] loss: 0.875
[56,     3] loss: 0.823
[57,     3] loss: 0.823
[58,     3] loss: 0.804
[59,     3] loss: 0.820
[60,     3] loss: 0.796
[61,     3] loss: 0.839
[62,     3] loss: 0.961
[63,     3] loss: 1.141
[64,     3] loss: 0.990
[65,     3] loss: 1.054
[66,     3] loss: 0.848
[67,     3] loss: 1.015
[68,     3] loss: 0.910
[69,     3] loss: 0.898
[70,     3] loss: 0.954
[71,     3] loss: 0.848
[72,     3] loss: 0.861
[73,     3] loss: 0.891
[74,     3] loss: 0.857
[75,     3] loss: 0.816
[76,     3] loss: 0.840
[77,     3] loss: 0.822
[78,     3] loss: 0.922
[79,     3] loss: 0.818
[80,     3] loss: 0.779
[81,     3] loss: 0.808
[82,     3] loss: 0.831
[83,     3] loss: 0.807
[84,     3] loss: 0.767
[85,     3] loss: 0.812
[86,     3] loss: 0.808
[87,     3] loss: 0.768
[88,     3] loss: 0.823
[89,     3] loss: 0.804
[90,     3] loss: 0.787
[91,     3] loss: 0.752
[92,     3] loss: 0.771
[93,     3] loss: 0.745
[94,     3] loss: 0.759
[95,     3] loss: 0.728
[96,     3] loss: 0.767
[97,     3] loss: 0.747
Early stopping applied (best metric=0.5385221242904663)
Finished Training
Total time taken: 28.845139265060425
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.386
[3,     3] loss: 1.386
[4,     3] loss: 1.382
[5,     3] loss: 1.387
[6,     3] loss: 1.379
[7,     3] loss: 1.375
[8,     3] loss: 1.376
[9,     3] loss: 1.368
[10,     3] loss: 1.370
[11,     3] loss: 1.363
[12,     3] loss: 1.351
[13,     3] loss: 1.329
[14,     3] loss: 1.313
[15,     3] loss: 1.288
[16,     3] loss: 1.204
[17,     3] loss: 1.236
[18,     3] loss: 1.163
[19,     3] loss: 1.157
[20,     3] loss: 1.083
[21,     3] loss: 1.060
[22,     3] loss: 1.125
[23,     3] loss: 1.064
[24,     3] loss: 1.267
[25,     3] loss: 1.078
[26,     3] loss: 1.150
[27,     3] loss: 1.129
[28,     3] loss: 1.155
[29,     3] loss: 1.035
[30,     3] loss: 1.175
[31,     3] loss: 1.084
[32,     3] loss: 1.105
[33,     3] loss: 0.945
[34,     3] loss: 1.039
[35,     3] loss: 0.952
[36,     3] loss: 0.922
[37,     3] loss: 0.927
[38,     3] loss: 0.914
[39,     3] loss: 0.922
[40,     3] loss: 0.930
[41,     3] loss: 0.874
[42,     3] loss: 0.909
[43,     3] loss: 0.848
[44,     3] loss: 0.941
[45,     3] loss: 0.823
[46,     3] loss: 0.835
[47,     3] loss: 0.818
[48,     3] loss: 0.893
[49,     3] loss: 0.837
[50,     3] loss: 0.842
[51,     3] loss: 0.808
[52,     3] loss: 0.823
[53,     3] loss: 0.848
[54,     3] loss: 0.832
[55,     3] loss: 0.790
[56,     3] loss: 0.821
[57,     3] loss: 0.782
[58,     3] loss: 0.772
[59,     3] loss: 0.817
[60,     3] loss: 0.878
[61,     3] loss: 0.901
[62,     3] loss: 0.879
[63,     3] loss: 0.972
[64,     3] loss: 0.812
[65,     3] loss: 0.881
[66,     3] loss: 0.909
[67,     3] loss: 0.832
[68,     3] loss: 0.870
[69,     3] loss: 0.842
[70,     3] loss: 0.821
[71,     3] loss: 0.808
[72,     3] loss: 0.791
[73,     3] loss: 0.787
[74,     3] loss: 0.801
[75,     3] loss: 0.756
[76,     3] loss: 0.820
[77,     3] loss: 0.795
[78,     3] loss: 0.777
[79,     3] loss: 0.818
[80,     3] loss: 0.821
[81,     3] loss: 0.814
[82,     3] loss: 0.811
[83,     3] loss: 0.784
[84,     3] loss: 0.760
[85,     3] loss: 0.781
[86,     3] loss: 0.808
[87,     3] loss: 0.825
[88,     3] loss: 0.768
Early stopping applied (best metric=0.5244575142860413)
Finished Training
Total time taken: 26.191125631332397
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.380
[3,     3] loss: 1.380
[4,     3] loss: 1.390
[5,     3] loss: 1.391
[6,     3] loss: 1.385
[7,     3] loss: 1.380
[8,     3] loss: 1.373
[9,     3] loss: 1.368
[10,     3] loss: 1.352
[11,     3] loss: 1.332
[12,     3] loss: 1.342
[13,     3] loss: 1.304
[14,     3] loss: 1.302
[15,     3] loss: 1.264
[16,     3] loss: 1.291
[17,     3] loss: 1.247
[18,     3] loss: 1.212
[19,     3] loss: 1.280
[20,     3] loss: 1.175
[21,     3] loss: 1.239
[22,     3] loss: 1.224
[23,     3] loss: 1.159
[24,     3] loss: 1.163
[25,     3] loss: 1.131
[26,     3] loss: 1.063
[27,     3] loss: 1.196
[28,     3] loss: 1.085
[29,     3] loss: 1.013
[30,     3] loss: 1.017
[31,     3] loss: 1.059
[32,     3] loss: 1.017
[33,     3] loss: 0.996
[34,     3] loss: 0.978
[35,     3] loss: 0.944
[36,     3] loss: 0.915
[37,     3] loss: 1.055
[38,     3] loss: 1.114
[39,     3] loss: 0.975
[40,     3] loss: 1.075
[41,     3] loss: 1.035
[42,     3] loss: 1.061
[43,     3] loss: 0.952
[44,     3] loss: 0.957
[45,     3] loss: 0.949
[46,     3] loss: 0.927
[47,     3] loss: 0.997
[48,     3] loss: 0.858
[49,     3] loss: 0.879
[50,     3] loss: 0.859
[51,     3] loss: 0.895
[52,     3] loss: 0.870
[53,     3] loss: 0.893
[54,     3] loss: 0.861
[55,     3] loss: 0.949
[56,     3] loss: 0.887
[57,     3] loss: 0.916
[58,     3] loss: 0.825
[59,     3] loss: 0.854
[60,     3] loss: 0.811
[61,     3] loss: 0.920
[62,     3] loss: 0.871
[63,     3] loss: 0.910
[64,     3] loss: 0.916
[65,     3] loss: 0.822
[66,     3] loss: 0.844
[67,     3] loss: 0.843
[68,     3] loss: 0.836
[69,     3] loss: 0.838
[70,     3] loss: 0.817
[71,     3] loss: 0.792
[72,     3] loss: 0.878
[73,     3] loss: 0.798
Early stopping applied (best metric=0.506814181804657)
Finished Training
Total time taken: 22.003103733062744
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.393
[3,     3] loss: 1.389
[4,     3] loss: 1.384
[5,     3] loss: 1.383
[6,     3] loss: 1.382
[7,     3] loss: 1.381
[8,     3] loss: 1.388
[9,     3] loss: 1.388
[10,     3] loss: 1.374
[11,     3] loss: 1.375
[12,     3] loss: 1.366
[13,     3] loss: 1.359
[14,     3] loss: 1.343
[15,     3] loss: 1.336
[16,     3] loss: 1.362
[17,     3] loss: 1.294
[18,     3] loss: 1.285
[19,     3] loss: 1.205
[20,     3] loss: 1.253
[21,     3] loss: 1.239
[22,     3] loss: 1.232
[23,     3] loss: 1.200
[24,     3] loss: 1.149
[25,     3] loss: 1.199
[26,     3] loss: 1.235
[27,     3] loss: 1.129
[28,     3] loss: 1.181
[29,     3] loss: 1.203
[30,     3] loss: 1.167
[31,     3] loss: 1.113
[32,     3] loss: 1.128
[33,     3] loss: 1.060
[34,     3] loss: 1.086
[35,     3] loss: 0.996
[36,     3] loss: 0.960
[37,     3] loss: 1.001
[38,     3] loss: 0.925
[39,     3] loss: 1.054
[40,     3] loss: 0.897
[41,     3] loss: 0.946
[42,     3] loss: 0.925
[43,     3] loss: 0.918
[44,     3] loss: 0.992
[45,     3] loss: 0.953
[46,     3] loss: 0.956
[47,     3] loss: 0.885
[48,     3] loss: 0.991
[49,     3] loss: 0.972
[50,     3] loss: 0.889
[51,     3] loss: 0.882
[52,     3] loss: 0.941
[53,     3] loss: 0.907
[54,     3] loss: 0.840
[55,     3] loss: 0.853
[56,     3] loss: 0.852
[57,     3] loss: 0.825
[58,     3] loss: 0.862
[59,     3] loss: 0.837
[60,     3] loss: 0.841
[61,     3] loss: 0.843
[62,     3] loss: 0.794
[63,     3] loss: 0.808
[64,     3] loss: 0.783
[65,     3] loss: 0.762
[66,     3] loss: 0.778
[67,     3] loss: 0.787
[68,     3] loss: 0.842
[69,     3] loss: 0.825
[70,     3] loss: 0.790
[71,     3] loss: 0.743
[72,     3] loss: 0.785
[73,     3] loss: 0.752
[74,     3] loss: 0.740
[75,     3] loss: 0.745
[76,     3] loss: 0.738
[77,     3] loss: 0.734
[78,     3] loss: 0.735
[79,     3] loss: 0.734
[80,     3] loss: 0.748
[81,     3] loss: 0.734
[82,     3] loss: 0.751
[83,     3] loss: 0.745
[84,     3] loss: 0.740
[85,     3] loss: 0.823
[86,     3] loss: 0.938
[87,     3] loss: 0.974
[88,     3] loss: 1.011
[89,     3] loss: 0.997
Early stopping applied (best metric=0.47986677289009094)
Finished Training
Total time taken: 26.463125944137573
{'S-palmitoylation-C Validation Accuracy': 0.6977824722584548, 'S-palmitoylation-C Validation Sensitivity': 0.22706270627062708, 'S-palmitoylation-C Validation Specificity': 0.8157767587187454, 'S-palmitoylation-C Validation Precision': 0.24165965897642483, 'S-palmitoylation-C AUC ROC': 0.544784364154503, 'S-palmitoylation-C AUC PR': 0.228364118267073, 'S-palmitoylation-C MCC': 0.04557949913343714, 'S-palmitoylation-C F1': 0.21854853340477362, 'Validation Loss (S-palmitoylation-C)': 0.553963816165924, 'Hydroxylation-K Validation Accuracy': 0.7477836879432624, 'Hydroxylation-K Validation Sensitivity': 0.8059259259259259, 'Hydroxylation-K Validation Specificity': 0.7333333333333333, 'Hydroxylation-K Validation Precision': 0.463490305066506, 'Hydroxylation-K AUC ROC': 0.830896686159844, 'Hydroxylation-K AUC PR': 0.6124871791637572, 'Hydroxylation-K MCC': 0.464948560594265, 'Hydroxylation-K F1': 0.572478128457139, 'Validation Loss (Hydroxylation-K)': 0.5132905503114065, 'Validation Loss (total)': 1.067254368464152, 'TimeToTrain': 24.400517574946086}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017404948990661288,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8481222881356271,
 'loss_weight_S-palmitoylation-C': 0.15686821503348503,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1449420250,
 'sample_weights': [0.08449584692043333, 0.8890004569882525],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.0724515623037485,
 'weight_decay_Hydroxylation-K': 1.7204070490743595,
 'weight_decay_S-palmitoylation-C': 3.7006188784112135}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.387
[3,     3] loss: 1.386
[4,     3] loss: 1.382
[5,     3] loss: 1.377
[6,     3] loss: 1.378
[7,     3] loss: 1.352
[8,     3] loss: 1.346
[9,     3] loss: 1.316
[10,     3] loss: 1.282
[11,     3] loss: 1.230
[12,     3] loss: 1.284
[13,     3] loss: 1.301
[14,     3] loss: 1.296
[15,     3] loss: 1.177
[16,     3] loss: 1.207
[17,     3] loss: 1.127
[18,     3] loss: 1.100
[19,     3] loss: 1.122
[20,     3] loss: 1.161
[21,     3] loss: 1.071
[22,     3] loss: 1.103
[23,     3] loss: 1.022
[24,     3] loss: 0.965
[25,     3] loss: 0.910
[26,     3] loss: 0.922
[27,     3] loss: 0.879
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00036520999397963245,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4496047147011647,
 'loss_weight_S-palmitoylation-C': 0.6237850476146216,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1892575757,
 'sample_weights': [0.15686821503348503, 0.8481222881356271],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.5709464338213035,
 'weight_decay_Hydroxylation-K': 2.1675323258270227,
 'weight_decay_S-palmitoylation-C': 3.2748664456396934}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.389
[3,     3] loss: 1.390
[4,     3] loss: 1.384
[5,     3] loss: 1.379
[6,     3] loss: 1.380
[7,     3] loss: 1.386
[8,     3] loss: 1.378
[9,     3] loss: 1.381
[10,     3] loss: 1.382
[11,     3] loss: 1.376
[12,     3] loss: 1.356
[13,     3] loss: 1.355
[14,     3] loss: 1.346
[15,     3] loss: 1.321
[16,     3] loss: 1.312
[17,     3] loss: 1.310
[18,     3] loss: 1.320
[19,     3] loss: 1.267
[20,     3] loss: 1.260
[21,     3] loss: 1.264
[22,     3] loss: 1.187
[23,     3] loss: 1.177
[24,     3] loss: 1.220
[25,     3] loss: 1.156
[26,     3] loss: 1.094
[27,     3] loss: 1.051
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0026678444616492353,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.520135219610873,
 'loss_weight_S-palmitoylation-C': 0.6730718494622983,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1740163257,
 'sample_weights': [0.6237850476146216, 0.4496047147011647],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.113691617481756,
 'weight_decay_Hydroxylation-K': 6.198824143927643,
 'weight_decay_S-palmitoylation-C': 5.5439434275507224}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.384
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003428594713635572,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9446094435748912,
 'loss_weight_S-palmitoylation-C': 0.285642658721587,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4121731370,
 'sample_weights': [0.6730718494622983, 0.520135219610873],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.543407830057257,
 'weight_decay_Hydroxylation-K': 7.398946951242464,
 'weight_decay_S-palmitoylation-C': 4.175549606117892}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.388
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001767262862972418,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8553524884400098,
 'loss_weight_S-palmitoylation-C': 0.09183050586613858,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1882995147,
 'sample_weights': [0.285642658721587, 0.9446094435748912],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.982582873123789,
 'weight_decay_Hydroxylation-K': 4.885440888572046,
 'weight_decay_S-palmitoylation-C': 4.777109655682609}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.392
[3,     3] loss: 1.387
[4,     3] loss: 1.380
[5,     3] loss: 1.379
[6,     3] loss: 1.377
[7,     3] loss: 1.372
[8,     3] loss: 1.387
[9,     3] loss: 1.373
[10,     3] loss: 1.351
[11,     3] loss: 1.348
[12,     3] loss: 1.321
[13,     3] loss: 1.310
[14,     3] loss: 1.261
[15,     3] loss: 1.213
[16,     3] loss: 1.212
[17,     3] loss: 1.316
[18,     3] loss: 1.145
[19,     3] loss: 1.139
[20,     3] loss: 1.062
[21,     3] loss: 1.149
[22,     3] loss: 1.109
[23,     3] loss: 1.130
[24,     3] loss: 1.122
[25,     3] loss: 1.176
[26,     3] loss: 1.040
[27,     3] loss: 1.099
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006880954498299896,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8602631754816308,
 'loss_weight_S-palmitoylation-C': 0.055620760512970685,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 845944641,
 'sample_weights': [0.09183050586613858, 0.8553524884400098],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.0098108741660528,
 'weight_decay_Hydroxylation-K': 1.7841711500319162,
 'weight_decay_S-palmitoylation-C': 3.0528768581473313}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.388
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0036265040007803276,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.09021380194804662,
 'loss_weight_S-palmitoylation-C': 0.3371044926808528,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3704640792,
 'sample_weights': [0.055620760512970685, 0.8602631754816308],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.950349749098081,
 'weight_decay_Hydroxylation-K': 7.985984634151552,
 'weight_decay_S-palmitoylation-C': 8.754714860708875}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.398
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004971401444828915,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8829166716662906,
 'loss_weight_S-palmitoylation-C': 0.6250174201300147,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3918280461,
 'sample_weights': [0.3371044926808528, 0.09021380194804662],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.302942680068956,
 'weight_decay_Hydroxylation-K': 9.489101936546547,
 'weight_decay_S-palmitoylation-C': 0.5267420235663663}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.376
[2,     3] loss: 1.389
[3,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002217028321820721,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.875532444186968,
 'loss_weight_S-palmitoylation-C': 0.31061381632445517,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3093358010,
 'sample_weights': [0.6250174201300147, 0.8829166716662906],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.211411167901366,
 'weight_decay_Hydroxylation-K': 4.669680865230899,
 'weight_decay_S-palmitoylation-C': 1.2549118926038663}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.382
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 8.66840849799061e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.49487214120845185,
 'loss_weight_S-palmitoylation-C': 0.15976728569185805,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 888890524,
 'sample_weights': [0.31061381632445517, 0.875532444186968],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.2453518243676065,
 'weight_decay_Hydroxylation-K': 4.532545931012324,
 'weight_decay_S-palmitoylation-C': 5.149198767124616}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.389
[3,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00016611542780737426,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8946097170345003,
 'loss_weight_S-palmitoylation-C': 0.14743905663897272,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2447929905,
 'sample_weights': [0.15976728569185805, 0.49487214120845185],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.762615257916411,
 'weight_decay_Hydroxylation-K': 1.5228374478533429,
 'weight_decay_S-palmitoylation-C': 6.597416909969526}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.388
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012040168110479727,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.585031494649761,
 'loss_weight_S-palmitoylation-C': 0.5081625313091138,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1817301010,
 'sample_weights': [0.14743905663897272, 0.8946097170345003],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7048556877747167,
 'weight_decay_Hydroxylation-K': 9.5646694946289,
 'weight_decay_S-palmitoylation-C': 0.4275304116773433}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.383
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009032476801581835,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.49105222107437735,
 'loss_weight_S-palmitoylation-C': 0.8172587577389279,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2211069774,
 'sample_weights': [0.5081625313091138, 0.585031494649761],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.104708607777356,
 'weight_decay_Hydroxylation-K': 9.676131019615324,
 'weight_decay_S-palmitoylation-C': 7.00114750651428}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.414
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004287125916319457,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8573135688142346,
 'loss_weight_S-palmitoylation-C': 0.0523136215149797,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2983216081,
 'sample_weights': [0.8172587577389279, 0.49105222107437735],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.147227691692841,
 'weight_decay_Hydroxylation-K': 1.0726218853027953,
 'weight_decay_S-palmitoylation-C': 3.881991983582803}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.377
[2,     3] loss: 1.377
[3,     3] loss: 1.385
[4,     3] loss: 1.387
[5,     3] loss: 1.377
[6,     3] loss: 1.384
[7,     3] loss: 1.393
[8,     3] loss: 1.373
[9,     3] loss: 1.354
[10,     3] loss: 1.279
[11,     3] loss: 1.259
[12,     3] loss: 1.361
[13,     3] loss: 1.197
[14,     3] loss: 1.205
[15,     3] loss: 1.277
[16,     3] loss: 1.238
[17,     3] loss: 1.205
[18,     3] loss: 1.168
[19,     3] loss: 1.254
[20,     3] loss: 1.120
[21,     3] loss: 1.073
[22,     3] loss: 0.979
[23,     3] loss: 1.059
[24,     3] loss: 1.065
[25,     3] loss: 1.045
[26,     3] loss: 1.128
[27,     3] loss: 1.009
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0002946987484649282,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.967469215832568,
 'loss_weight_S-palmitoylation-C': 0.1587917160839845,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 694686760,
 'sample_weights': [0.0523136215149797, 0.8573135688142346],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.0801226866646605,
 'weight_decay_Hydroxylation-K': 2.8569222169677237,
 'weight_decay_S-palmitoylation-C': 3.9852645795063344}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.386
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017548750151154216,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7302330808398275,
 'loss_weight_S-palmitoylation-C': 0.0211645996413609,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2252684357,
 'sample_weights': [0.1587917160839845, 0.967469215832568],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.058717401456278,
 'weight_decay_Hydroxylation-K': 7.105529315010538,
 'weight_decay_S-palmitoylation-C': 2.1582418708094333}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.382
[3,     3] loss: 1.374
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00482805472350395,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6083148148735462,
 'loss_weight_S-palmitoylation-C': 0.4995418346678471,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 963100800,
 'sample_weights': [0.0211645996413609, 0.7302330808398275],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8777567901825596,
 'weight_decay_Hydroxylation-K': 9.732608568123435,
 'weight_decay_S-palmitoylation-C': 3.0397781529890247}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.392
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007962815453206262,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4067078794821706,
 'loss_weight_S-palmitoylation-C': 0.18746940138504617,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4257571007,
 'sample_weights': [0.4995418346678471, 0.6083148148735462],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.180648822868458,
 'weight_decay_Hydroxylation-K': 8.99401527025643,
 'weight_decay_S-palmitoylation-C': 9.087778441751041}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.388
[4,     3] loss: 1.388
[5,     3] loss: 1.385
[6,     3] loss: 1.389
[7,     3] loss: 1.387
[8,     3] loss: 1.387
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018530144666563646,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.751163890171328,
 'loss_weight_S-palmitoylation-C': 0.16697819470394118,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2128730840,
 'sample_weights': [0.18746940138504617, 0.4067078794821706],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.9879197069049415,
 'weight_decay_Hydroxylation-K': 1.5327816812812927,
 'weight_decay_S-palmitoylation-C': 1.370143023760149}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.392
[3,     3] loss: 1.380
[4,     3] loss: 1.389
[5,     3] loss: 1.389
[6,     3] loss: 1.381
[7,     3] loss: 1.384
[8,     3] loss: 1.383
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035161187985181665,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5163377759614204,
 'loss_weight_S-palmitoylation-C': 0.11374846701023814,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3222098064,
 'sample_weights': [0.16697819470394118, 0.751163890171328],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.1849156899408335,
 'weight_decay_Hydroxylation-K': 9.631202906993307,
 'weight_decay_S-palmitoylation-C': 4.338967918029717}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.403
[2,     3] loss: 1.412
[3,     3] loss: 1.389
[4,     3] loss: 1.382
[5,     3] loss: 1.383
[6,     3] loss: 1.380
[7,     3] loss: 1.392
[8,     3] loss: 1.390
[9,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0029628510924287962,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9362117891208325,
 'loss_weight_S-palmitoylation-C': 0.2854953004265161,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3633503444,
 'sample_weights': [0.11374846701023814, 0.5163377759614204],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.5042037925249243,
 'weight_decay_Hydroxylation-K': 1.4968198495350475,
 'weight_decay_S-palmitoylation-C': 3.1284814138754946}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.392
[3,     3] loss: 1.382
[4,     3] loss: 1.379
[5,     3] loss: 1.367
[6,     3] loss: 1.350
[7,     3] loss: 1.331
[8,     3] loss: 1.303
[9,     3] loss: 1.314
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009732579126247566,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1384064245625422,
 'loss_weight_S-palmitoylation-C': 0.48707416776642304,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3056683727,
 'sample_weights': [0.2854953004265161, 0.9362117891208325],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.151656399111808,
 'weight_decay_Hydroxylation-K': 5.714730594223614,
 'weight_decay_S-palmitoylation-C': 5.425653133482361}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.385
[3,     3] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009845821698794817,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.17542349838431132,
 'loss_weight_S-palmitoylation-C': 0.8657773568780673,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1323563245,
 'sample_weights': [0.48707416776642304, 0.1384064245625422],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.593995858600199,
 'weight_decay_Hydroxylation-K': 4.106492963461612,
 'weight_decay_S-palmitoylation-C': 6.9181125117881885}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.388
[4,     3] loss: 1.388
[5,     3] loss: 1.382
[6,     3] loss: 1.392
[7,     3] loss: 1.387
[8,     3] loss: 1.386
[9,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008446451934835878,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9415081783971174,
 'loss_weight_S-palmitoylation-C': 0.03621703231288396,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1494919849,
 'sample_weights': [0.8657773568780673, 0.17542349838431132],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.4200992765713725,
 'weight_decay_Hydroxylation-K': 5.044953941595776,
 'weight_decay_S-palmitoylation-C': 3.0787073716927416}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.387
[3,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0002843767476899847,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6704624637999608,
 'loss_weight_S-palmitoylation-C': 0.14041824049202495,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1541432318,
 'sample_weights': [0.03621703231288396, 0.9415081783971174],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.634091451620882,
 'weight_decay_Hydroxylation-K': 5.996279198273824,
 'weight_decay_S-palmitoylation-C': 7.780551348324317}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.384
[3,     3] loss: 1.395
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005315556434428377,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24741092411507715,
 'loss_weight_S-palmitoylation-C': 0.5433261539632909,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1525261247,
 'sample_weights': [0.14041824049202495, 0.6704624637999608],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.768132058222031,
 'weight_decay_Hydroxylation-K': 5.003980853547761,
 'weight_decay_S-palmitoylation-C': 1.2987202794003283}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.373
[3,     3] loss: 1.391
[4,     3] loss: 1.392
[5,     3] loss: 1.380
[6,     3] loss: 1.377
[7,     3] loss: 1.394
[8,     3] loss: 1.385
[9,     3] loss: 1.378
[10,     3] loss: 1.355
[11,     3] loss: 1.329
[12,     3] loss: 1.309
[13,     3] loss: 1.223
[14,     3] loss: 1.295
[15,     3] loss: 1.290
[16,     3] loss: 1.186
[17,     3] loss: 1.116
[18,     3] loss: 1.049
[19,     3] loss: 1.314
[20,     3] loss: 1.126
[21,     3] loss: 1.123
[22,     3] loss: 1.065
[23,     3] loss: 1.120
[24,     3] loss: 1.046
[25,     3] loss: 1.056
[26,     3] loss: 1.217
[27,     3] loss: 1.170
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008115955147080539,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9954787324075081,
 'loss_weight_S-palmitoylation-C': 0.1595139117329623,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3712766742,
 'sample_weights': [0.5433261539632909, 0.24741092411507715],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.321330492425528,
 'weight_decay_Hydroxylation-K': 6.241973554909888,
 'weight_decay_S-palmitoylation-C': 2.111829676129858}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.383
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005133346168298159,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7356442829486382,
 'loss_weight_S-palmitoylation-C': 0.9048622409851399,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2343567386,
 'sample_weights': [0.1595139117329623, 0.9954787324075081],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.089996223554976,
 'weight_decay_Hydroxylation-K': 3.515836258910989,
 'weight_decay_S-palmitoylation-C': 1.2477072743948128}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.390
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008467037323136304,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.053743936264298645,
 'loss_weight_S-palmitoylation-C': 0.7564579408537868,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 635898566,
 'sample_weights': [0.9048622409851399, 0.7356442829486382],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.920449790185847,
 'weight_decay_Hydroxylation-K': 8.132881353887294,
 'weight_decay_S-palmitoylation-C': 7.440327100213228}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.374
[3,     3] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007308569752960324,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2544024871745487,
 'loss_weight_S-palmitoylation-C': 0.6359612296446367,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3401354921,
 'sample_weights': [0.7564579408537868, 0.053743936264298645],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.51798505718001,
 'weight_decay_Hydroxylation-K': 3.6610820456513746,
 'weight_decay_S-palmitoylation-C': 8.409200862903983}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.403
[3,     3] loss: 1.390
[4,     3] loss: 1.385
[5,     3] loss: 1.388
[6,     3] loss: 1.387
[7,     3] loss: 1.386
[8,     3] loss: 1.383
[9,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008070895463710549,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.37820944722758076,
 'loss_weight_S-palmitoylation-C': 0.8420494831005592,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2680833938,
 'sample_weights': [0.6359612296446367, 0.2544024871745487],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.4878459486899205,
 'weight_decay_Hydroxylation-K': 6.410499695100491,
 'weight_decay_S-palmitoylation-C': 9.951459602096685}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.386
[4,     3] loss: 1.387
[5,     3] loss: 1.386
[6,     3] loss: 1.390
[7,     3] loss: 1.386
[8,     3] loss: 1.384
[9,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00251741785452066,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5639707612800311,
 'loss_weight_S-palmitoylation-C': 0.27318014657317746,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2844991441,
 'sample_weights': [0.8420494831005592, 0.37820944722758076],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.610699799035701,
 'weight_decay_Hydroxylation-K': 3.8609554187143047,
 'weight_decay_S-palmitoylation-C': 4.1820745782565805}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.396
[3,     3] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006300904979998965,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.035495293455826665,
 'loss_weight_S-palmitoylation-C': 0.45411921672761524,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 431694873,
 'sample_weights': [0.27318014657317746, 0.5639707612800311],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.176854263759733,
 'weight_decay_Hydroxylation-K': 5.377853989722446,
 'weight_decay_S-palmitoylation-C': 3.9100305521449976}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.388
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0050872262474131085,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.07773648895253332,
 'loss_weight_S-palmitoylation-C': 0.17311004601395558,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 437000949,
 'sample_weights': [0.45411921672761524, 0.035495293455826665],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.31032554737847,
 'weight_decay_Hydroxylation-K': 9.077608604663615,
 'weight_decay_S-palmitoylation-C': 2.999331589918355}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.386
[3,     3] loss: 1.391
[4,     3] loss: 1.391
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.387
[8,     3] loss: 1.381
[9,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0048899681916925964,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.44289455044345083,
 'loss_weight_S-palmitoylation-C': 0.5085326871766596,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2572581611,
 'sample_weights': [0.17311004601395558, 0.07773648895253332],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.02431161404416,
 'weight_decay_Hydroxylation-K': 8.356974856305388,
 'weight_decay_S-palmitoylation-C': 2.8922209496693614}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.394
[3,     3] loss: 1.396
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002428712407048281,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7515915373559059,
 'loss_weight_S-palmitoylation-C': 0.22120833295090786,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2265790853,
 'sample_weights': [0.5085326871766596, 0.44289455044345083],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.592177966451208,
 'weight_decay_Hydroxylation-K': 6.519234717937353,
 'weight_decay_S-palmitoylation-C': 5.499222917861812}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.406
[2,     3] loss: 1.383
[3,     3] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007458820535602804,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8414302350315208,
 'loss_weight_S-palmitoylation-C': 0.906230678845845,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 227685819,
 'sample_weights': [0.22120833295090786, 0.7515915373559059],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.044892834869829,
 'weight_decay_Hydroxylation-K': 9.141573149173494,
 'weight_decay_S-palmitoylation-C': 3.968122507261259}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.391
[3,     3] loss: 1.386
[4,     3] loss: 1.386
[5,     3] loss: 1.386
[6,     3] loss: 1.385
[7,     3] loss: 1.385
[8,     3] loss: 1.389
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009359011344531192,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.012700916960875469,
 'loss_weight_S-palmitoylation-C': 0.33353360998222964,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3464827107,
 'sample_weights': [0.906230678845845, 0.8414302350315208],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.153799767863163,
 'weight_decay_Hydroxylation-K': 4.081024575002519,
 'weight_decay_S-palmitoylation-C': 8.474862837341684}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.389
[3,     3] loss: 1.389
[4,     3] loss: 1.392
[5,     3] loss: 1.387
[6,     3] loss: 1.384
[7,     3] loss: 1.384
[8,     3] loss: 1.384
[9,     3] loss: 1.381
[10,     3] loss: 1.383
[11,     3] loss: 1.395
[12,     3] loss: 1.379
[13,     3] loss: 1.381
[14,     3] loss: 1.388
[15,     3] loss: 1.388
[16,     3] loss: 1.386
[17,     3] loss: 1.384
[18,     3] loss: 1.380
[19,     3] loss: 1.374
[20,     3] loss: 1.348
[21,     3] loss: 1.330
[22,     3] loss: 1.329
[23,     3] loss: 1.257
[24,     3] loss: 1.350
[25,     3] loss: 1.222
[26,     3] loss: 1.211
[27,     3] loss: 1.225
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017221913480012776,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8214966141265435,
 'loss_weight_S-palmitoylation-C': 0.011421240762424317,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3361303025,
 'sample_weights': [0.33353360998222964, 0.012700916960875469],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.057481040771494,
 'weight_decay_Hydroxylation-K': 3.846817122424217,
 'weight_decay_S-palmitoylation-C': 5.8821186580041775}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.405
[3,     3] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014275419932352237,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.27897140193487163,
 'loss_weight_S-palmitoylation-C': 0.881447422964597,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1922459984,
 'sample_weights': [0.011421240762424317, 0.8214966141265435],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7359449786942447,
 'weight_decay_Hydroxylation-K': 3.156659797253564,
 'weight_decay_S-palmitoylation-C': 0.05355578536073935}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.376
[3,     3] loss: 1.388
[4,     3] loss: 1.380
[5,     3] loss: 1.372
[6,     3] loss: 1.383
[7,     3] loss: 1.364
[8,     3] loss: 1.339
[9,     3] loss: 1.345
[10,     3] loss: 1.314
[11,     3] loss: 1.326
[12,     3] loss: 1.291
[13,     3] loss: 1.299
[14,     3] loss: 1.309
[15,     3] loss: 1.229
[16,     3] loss: 1.189
[17,     3] loss: 1.156
[18,     3] loss: 1.070
[19,     3] loss: 1.102
[20,     3] loss: 1.072
[21,     3] loss: 1.098
[22,     3] loss: 0.988
[23,     3] loss: 1.015
[24,     3] loss: 1.043
[25,     3] loss: 1.059
[26,     3] loss: 1.040
[27,     3] loss: 1.087
[28,     3] loss: 0.956
[29,     3] loss: 0.968
[30,     3] loss: 1.025
[31,     3] loss: 0.929
[32,     3] loss: 0.957
[33,     3] loss: 0.917
[34,     3] loss: 0.957
[35,     3] loss: 0.996
[36,     3] loss: 0.907
[37,     3] loss: 0.848
[38,     3] loss: 0.934
[39,     3] loss: 0.872
[40,     3] loss: 0.938
[41,     3] loss: 0.832
[42,     3] loss: 0.831
[43,     3] loss: 0.872
[44,     3] loss: 0.792
[45,     3] loss: 0.812
[46,     3] loss: 0.771
[47,     3] loss: 0.864
[48,     3] loss: 0.864
[49,     3] loss: 0.767
[50,     3] loss: 0.869
[51,     3] loss: 0.800
[52,     3] loss: 0.775
[53,     3] loss: 0.840
[54,     3] loss: 0.803
[55,     3] loss: 0.786
[56,     3] loss: 0.812
[57,     3] loss: 0.765
[58,     3] loss: 0.794
[59,     3] loss: 0.782
[60,     3] loss: 0.746
[61,     3] loss: 0.787
[62,     3] loss: 0.757
[63,     3] loss: 0.776
[64,     3] loss: 0.741
[65,     3] loss: 0.726
[66,     3] loss: 0.766
[67,     3] loss: 0.729
[68,     3] loss: 0.745
[69,     3] loss: 0.739
[70,     3] loss: 0.735
Early stopping applied (best metric=0.5194851756095886)
Finished Training
Total time taken: 21.183101654052734
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.390
[3,     3] loss: 1.382
[4,     3] loss: 1.380
[5,     3] loss: 1.372
[6,     3] loss: 1.357
[7,     3] loss: 1.349
[8,     3] loss: 1.285
[9,     3] loss: 1.310
[10,     3] loss: 1.301
[11,     3] loss: 1.206
[12,     3] loss: 1.222
[13,     3] loss: 1.220
[14,     3] loss: 1.137
[15,     3] loss: 1.129
[16,     3] loss: 1.131
[17,     3] loss: 0.995
[18,     3] loss: 0.983
[19,     3] loss: 0.986
[20,     3] loss: 1.009
[21,     3] loss: 1.013
[22,     3] loss: 0.938
[23,     3] loss: 0.985
[24,     3] loss: 0.959
[25,     3] loss: 0.967
[26,     3] loss: 0.935
[27,     3] loss: 0.850
[28,     3] loss: 0.948
[29,     3] loss: 0.947
[30,     3] loss: 0.889
[31,     3] loss: 0.909
[32,     3] loss: 0.900
[33,     3] loss: 0.885
[34,     3] loss: 0.981
[35,     3] loss: 0.935
[36,     3] loss: 0.909
[37,     3] loss: 0.882
[38,     3] loss: 0.920
[39,     3] loss: 0.844
[40,     3] loss: 0.853
[41,     3] loss: 0.892
[42,     3] loss: 0.797
[43,     3] loss: 0.810
[44,     3] loss: 0.780
[45,     3] loss: 0.867
[46,     3] loss: 0.756
[47,     3] loss: 0.787
[48,     3] loss: 0.764
[49,     3] loss: 0.749
[50,     3] loss: 0.758
[51,     3] loss: 0.759
[52,     3] loss: 0.762
[53,     3] loss: 0.766
[54,     3] loss: 0.736
[55,     3] loss: 0.730
[56,     3] loss: 0.766
[57,     3] loss: 0.763
[58,     3] loss: 0.725
[59,     3] loss: 0.754
[60,     3] loss: 0.728
[61,     3] loss: 0.773
[62,     3] loss: 0.762
Early stopping applied (best metric=0.5286935567855835)
Finished Training
Total time taken: 18.229090929031372
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.400
[3,     3] loss: 1.397
[4,     3] loss: 1.388
[5,     3] loss: 1.384
[6,     3] loss: 1.383
[7,     3] loss: 1.386
[8,     3] loss: 1.383
[9,     3] loss: 1.386
[10,     3] loss: 1.382
[11,     3] loss: 1.383
[12,     3] loss: 1.376
[13,     3] loss: 1.381
[14,     3] loss: 1.354
[15,     3] loss: 1.364
[16,     3] loss: 1.353
[17,     3] loss: 1.312
[18,     3] loss: 1.280
[19,     3] loss: 1.277
[20,     3] loss: 1.243
[21,     3] loss: 1.250
[22,     3] loss: 1.141
[23,     3] loss: 1.108
[24,     3] loss: 1.169
[25,     3] loss: 1.166
[26,     3] loss: 1.145
[27,     3] loss: 1.063
[28,     3] loss: 1.077
[29,     3] loss: 1.061
[30,     3] loss: 1.053
[31,     3] loss: 0.956
[32,     3] loss: 0.991
[33,     3] loss: 0.996
[34,     3] loss: 1.049
[35,     3] loss: 0.929
[36,     3] loss: 0.905
[37,     3] loss: 0.889
[38,     3] loss: 0.886
[39,     3] loss: 0.882
[40,     3] loss: 0.952
[41,     3] loss: 0.831
[42,     3] loss: 0.961
[43,     3] loss: 0.993
[44,     3] loss: 0.923
[45,     3] loss: 0.921
[46,     3] loss: 0.934
[47,     3] loss: 1.019
[48,     3] loss: 0.903
[49,     3] loss: 0.856
[50,     3] loss: 0.914
[51,     3] loss: 0.920
[52,     3] loss: 0.983
[53,     3] loss: 0.914
[54,     3] loss: 0.954
[55,     3] loss: 1.030
[56,     3] loss: 0.906
[57,     3] loss: 0.860
[58,     3] loss: 0.974
[59,     3] loss: 0.847
[60,     3] loss: 0.925
[61,     3] loss: 0.805
[62,     3] loss: 0.872
[63,     3] loss: 0.848
[64,     3] loss: 0.860
[65,     3] loss: 0.777
[66,     3] loss: 0.796
[67,     3] loss: 0.824
[68,     3] loss: 0.787
[69,     3] loss: 0.801
[70,     3] loss: 0.769
[71,     3] loss: 0.805
[72,     3] loss: 0.814
[73,     3] loss: 0.760
[74,     3] loss: 0.791
[75,     3] loss: 0.741
[76,     3] loss: 0.821
[77,     3] loss: 0.789
[78,     3] loss: 0.763
[79,     3] loss: 0.794
[80,     3] loss: 0.811
[81,     3] loss: 0.764
[82,     3] loss: 0.776
[83,     3] loss: 0.747
[84,     3] loss: 0.855
[85,     3] loss: 0.838
[86,     3] loss: 0.843
[87,     3] loss: 0.869
[88,     3] loss: 0.782
[89,     3] loss: 0.802
[90,     3] loss: 0.761
[91,     3] loss: 0.793
[92,     3] loss: 0.833
[93,     3] loss: 0.744
[94,     3] loss: 0.744
[95,     3] loss: 0.740
[96,     3] loss: 0.755
[97,     3] loss: 0.800
[98,     3] loss: 0.807
[99,     3] loss: 0.745
[100,     3] loss: 0.845
[101,     3] loss: 0.871
[102,     3] loss: 0.754
[103,     3] loss: 0.768
[104,     3] loss: 0.743
[105,     3] loss: 0.754
[106,     3] loss: 0.754
[107,     3] loss: 0.746
[108,     3] loss: 0.740
[109,     3] loss: 0.768
[110,     3] loss: 0.739
[111,     3] loss: 0.728
[112,     3] loss: 0.815
[113,     3] loss: 0.726
[114,     3] loss: 0.719
[115,     3] loss: 0.765
[116,     3] loss: 0.726
[117,     3] loss: 0.879
[118,     3] loss: 0.798
[119,     3] loss: 0.796
[120,     3] loss: 0.857
[121,     3] loss: 0.762
[122,     3] loss: 0.883
[123,     3] loss: 0.886
[124,     3] loss: 0.833
[125,     3] loss: 0.778
[126,     3] loss: 0.799
[127,     3] loss: 0.765
[128,     3] loss: 0.755
[129,     3] loss: 0.766
Early stopping applied (best metric=0.49961718916893005)
Finished Training
Total time taken: 38.74218416213989
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.389
[3,     3] loss: 1.385
[4,     3] loss: 1.381
[5,     3] loss: 1.384
[6,     3] loss: 1.371
[7,     3] loss: 1.378
[8,     3] loss: 1.367
[9,     3] loss: 1.339
[10,     3] loss: 1.309
[11,     3] loss: 1.323
[12,     3] loss: 1.268
[13,     3] loss: 1.227
[14,     3] loss: 1.218
[15,     3] loss: 1.139
[16,     3] loss: 1.211
[17,     3] loss: 1.291
[18,     3] loss: 1.078
[19,     3] loss: 1.135
[20,     3] loss: 1.110
[21,     3] loss: 1.098
[22,     3] loss: 1.011
[23,     3] loss: 1.094
[24,     3] loss: 1.002
[25,     3] loss: 0.913
[26,     3] loss: 1.001
[27,     3] loss: 0.909
[28,     3] loss: 0.882
[29,     3] loss: 0.886
[30,     3] loss: 0.856
[31,     3] loss: 0.856
[32,     3] loss: 0.917
[33,     3] loss: 0.853
[34,     3] loss: 0.802
[35,     3] loss: 0.966
[36,     3] loss: 0.806
[37,     3] loss: 0.904
[38,     3] loss: 1.066
[39,     3] loss: 0.845
[40,     3] loss: 0.905
[41,     3] loss: 0.890
[42,     3] loss: 0.823
[43,     3] loss: 0.948
[44,     3] loss: 1.010
[45,     3] loss: 0.841
[46,     3] loss: 0.938
[47,     3] loss: 0.844
[48,     3] loss: 0.982
[49,     3] loss: 0.789
[50,     3] loss: 0.948
[51,     3] loss: 0.830
[52,     3] loss: 0.897
[53,     3] loss: 0.787
[54,     3] loss: 0.793
[55,     3] loss: 0.822
[56,     3] loss: 0.777
[57,     3] loss: 0.800
[58,     3] loss: 0.774
[59,     3] loss: 0.769
[60,     3] loss: 0.808
[61,     3] loss: 0.761
[62,     3] loss: 0.766
[63,     3] loss: 0.765
[64,     3] loss: 0.777
[65,     3] loss: 0.735
[66,     3] loss: 0.785
[67,     3] loss: 0.795
Early stopping applied (best metric=0.4962159991264343)
Finished Training
Total time taken: 20.12809705734253
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.379
[3,     3] loss: 1.392
[4,     3] loss: 1.393
[5,     3] loss: 1.377
[6,     3] loss: 1.376
[7,     3] loss: 1.361
[8,     3] loss: 1.365
[9,     3] loss: 1.339
[10,     3] loss: 1.328
[11,     3] loss: 1.268
[12,     3] loss: 1.268
[13,     3] loss: 1.204
[14,     3] loss: 1.176
[15,     3] loss: 1.106
[16,     3] loss: 1.105
[17,     3] loss: 1.075
[18,     3] loss: 1.058
[19,     3] loss: 1.018
[20,     3] loss: 1.129
[21,     3] loss: 1.036
[22,     3] loss: 1.071
[23,     3] loss: 0.935
[24,     3] loss: 0.919
[25,     3] loss: 0.966
[26,     3] loss: 0.982
[27,     3] loss: 0.906
[28,     3] loss: 0.875
[29,     3] loss: 0.873
[30,     3] loss: 0.867
[31,     3] loss: 0.997
[32,     3] loss: 0.891
[33,     3] loss: 0.885
[34,     3] loss: 0.834
[35,     3] loss: 0.975
[36,     3] loss: 0.946
[37,     3] loss: 0.925
[38,     3] loss: 0.940
[39,     3] loss: 0.988
[40,     3] loss: 0.859
[41,     3] loss: 0.874
[42,     3] loss: 0.852
[43,     3] loss: 0.918
[44,     3] loss: 0.840
[45,     3] loss: 0.815
[46,     3] loss: 0.840
[47,     3] loss: 0.857
[48,     3] loss: 0.811
[49,     3] loss: 0.812
[50,     3] loss: 0.739
[51,     3] loss: 0.796
[52,     3] loss: 0.774
[53,     3] loss: 0.743
[54,     3] loss: 0.738
[55,     3] loss: 0.819
[56,     3] loss: 0.742
[57,     3] loss: 0.741
[58,     3] loss: 0.756
[59,     3] loss: 0.747
[60,     3] loss: 0.772
[61,     3] loss: 0.729
[62,     3] loss: 0.731
[63,     3] loss: 0.736
[64,     3] loss: 0.739
[65,     3] loss: 0.738
[66,     3] loss: 0.767
[67,     3] loss: 0.744
[68,     3] loss: 0.726
[69,     3] loss: 0.723
[70,     3] loss: 0.723
[71,     3] loss: 0.742
[72,     3] loss: 0.732
[73,     3] loss: 0.734
[74,     3] loss: 0.735
[75,     3] loss: 0.716
[76,     3] loss: 0.896
[77,     3] loss: 1.008
[78,     3] loss: 0.798
[79,     3] loss: 0.826
[80,     3] loss: 0.923
[81,     3] loss: 0.888
[82,     3] loss: 0.868
[83,     3] loss: 0.799
[84,     3] loss: 0.780
[85,     3] loss: 0.775
[86,     3] loss: 0.784
Early stopping applied (best metric=0.5174341201782227)
Finished Training
Total time taken: 25.74312448501587
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.387
[3,     3] loss: 1.386
[4,     3] loss: 1.386
[5,     3] loss: 1.392
[6,     3] loss: 1.388
[7,     3] loss: 1.390
[8,     3] loss: 1.384
[9,     3] loss: 1.382
[10,     3] loss: 1.384
[11,     3] loss: 1.384
[12,     3] loss: 1.373
[13,     3] loss: 1.384
[14,     3] loss: 1.372
[15,     3] loss: 1.358
[16,     3] loss: 1.341
[17,     3] loss: 1.335
[18,     3] loss: 1.338
[19,     3] loss: 1.295
[20,     3] loss: 1.290
[21,     3] loss: 1.318
[22,     3] loss: 1.206
[23,     3] loss: 1.200
[24,     3] loss: 1.261
[25,     3] loss: 1.192
[26,     3] loss: 1.213
[27,     3] loss: 1.178
[28,     3] loss: 1.082
[29,     3] loss: 1.058
[30,     3] loss: 1.008
[31,     3] loss: 1.052
[32,     3] loss: 1.030
[33,     3] loss: 1.040
[34,     3] loss: 0.967
[35,     3] loss: 1.006
[36,     3] loss: 1.009
[37,     3] loss: 0.997
[38,     3] loss: 1.033
[39,     3] loss: 0.985
[40,     3] loss: 1.000
[41,     3] loss: 0.999
[42,     3] loss: 0.987
[43,     3] loss: 0.904
[44,     3] loss: 0.987
[45,     3] loss: 0.893
[46,     3] loss: 1.088
[47,     3] loss: 0.854
[48,     3] loss: 0.992
[49,     3] loss: 0.925
[50,     3] loss: 0.828
[51,     3] loss: 0.859
[52,     3] loss: 0.820
[53,     3] loss: 0.829
[54,     3] loss: 0.955
[55,     3] loss: 0.912
[56,     3] loss: 0.863
[57,     3] loss: 0.858
[58,     3] loss: 0.884
[59,     3] loss: 0.849
[60,     3] loss: 0.789
[61,     3] loss: 0.789
[62,     3] loss: 0.828
[63,     3] loss: 0.775
[64,     3] loss: 0.820
[65,     3] loss: 0.866
[66,     3] loss: 0.773
[67,     3] loss: 0.936
[68,     3] loss: 0.767
[69,     3] loss: 0.792
[70,     3] loss: 0.778
[71,     3] loss: 0.816
[72,     3] loss: 0.795
Early stopping applied (best metric=0.5190514922142029)
Finished Training
Total time taken: 21.05510187149048
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.394
[3,     3] loss: 1.389
[4,     3] loss: 1.385
[5,     3] loss: 1.384
[6,     3] loss: 1.384
[7,     3] loss: 1.370
[8,     3] loss: 1.373
[9,     3] loss: 1.355
[10,     3] loss: 1.365
[11,     3] loss: 1.338
[12,     3] loss: 1.297
[13,     3] loss: 1.323
[14,     3] loss: 1.279
[15,     3] loss: 1.256
[16,     3] loss: 1.186
[17,     3] loss: 1.182
[18,     3] loss: 1.228
[19,     3] loss: 1.164
[20,     3] loss: 1.131
[21,     3] loss: 1.153
[22,     3] loss: 1.265
[23,     3] loss: 1.113
[24,     3] loss: 1.063
[25,     3] loss: 1.047
[26,     3] loss: 0.991
[27,     3] loss: 0.976
[28,     3] loss: 0.959
[29,     3] loss: 1.015
[30,     3] loss: 1.078
[31,     3] loss: 0.915
[32,     3] loss: 0.957
[33,     3] loss: 1.032
[34,     3] loss: 1.121
[35,     3] loss: 0.930
[36,     3] loss: 0.927
[37,     3] loss: 0.930
[38,     3] loss: 0.913
[39,     3] loss: 0.915
[40,     3] loss: 0.867
[41,     3] loss: 0.904
[42,     3] loss: 0.913
[43,     3] loss: 0.814
[44,     3] loss: 0.887
[45,     3] loss: 0.852
[46,     3] loss: 0.804
[47,     3] loss: 0.796
[48,     3] loss: 0.838
[49,     3] loss: 0.787
[50,     3] loss: 0.818
[51,     3] loss: 0.829
[52,     3] loss: 0.854
[53,     3] loss: 0.761
[54,     3] loss: 0.833
[55,     3] loss: 0.903
[56,     3] loss: 0.869
[57,     3] loss: 0.904
[58,     3] loss: 0.887
[59,     3] loss: 0.859
[60,     3] loss: 0.866
[61,     3] loss: 0.813
[62,     3] loss: 0.836
[63,     3] loss: 0.798
[64,     3] loss: 0.806
[65,     3] loss: 0.817
[66,     3] loss: 0.765
[67,     3] loss: 0.805
[68,     3] loss: 0.789
[69,     3] loss: 0.771
[70,     3] loss: 0.731
Early stopping applied (best metric=0.5071204304695129)
Finished Training
Total time taken: 20.459097862243652
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.380
[3,     3] loss: 1.384
[4,     3] loss: 1.381
[5,     3] loss: 1.386
[6,     3] loss: 1.381
[7,     3] loss: 1.383
[8,     3] loss: 1.383
[9,     3] loss: 1.371
[10,     3] loss: 1.365
[11,     3] loss: 1.364
[12,     3] loss: 1.330
[13,     3] loss: 1.329
[14,     3] loss: 1.325
[15,     3] loss: 1.290
[16,     3] loss: 1.295
[17,     3] loss: 1.228
[18,     3] loss: 1.270
[19,     3] loss: 1.255
[20,     3] loss: 1.129
[21,     3] loss: 1.144
[22,     3] loss: 1.085
[23,     3] loss: 1.043
[24,     3] loss: 1.136
[25,     3] loss: 1.024
[26,     3] loss: 1.023
[27,     3] loss: 0.985
[28,     3] loss: 0.920
[29,     3] loss: 1.081
[30,     3] loss: 0.975
[31,     3] loss: 1.039
[32,     3] loss: 0.942
[33,     3] loss: 0.884
[34,     3] loss: 0.967
[35,     3] loss: 0.946
[36,     3] loss: 0.914
[37,     3] loss: 0.922
[38,     3] loss: 0.845
[39,     3] loss: 0.901
[40,     3] loss: 0.863
[41,     3] loss: 0.858
[42,     3] loss: 0.871
[43,     3] loss: 0.847
[44,     3] loss: 0.843
[45,     3] loss: 0.813
[46,     3] loss: 0.874
[47,     3] loss: 0.799
[48,     3] loss: 0.819
[49,     3] loss: 0.812
[50,     3] loss: 0.800
[51,     3] loss: 0.791
[52,     3] loss: 0.811
[53,     3] loss: 0.758
[54,     3] loss: 0.818
[55,     3] loss: 0.823
[56,     3] loss: 0.832
[57,     3] loss: 0.767
[58,     3] loss: 0.846
[59,     3] loss: 0.854
[60,     3] loss: 0.750
[61,     3] loss: 0.883
[62,     3] loss: 0.818
[63,     3] loss: 0.860
[64,     3] loss: 0.849
[65,     3] loss: 0.912
[66,     3] loss: 0.816
[67,     3] loss: 0.798
[68,     3] loss: 0.822
[69,     3] loss: 0.811
[70,     3] loss: 0.774
[71,     3] loss: 0.784
[72,     3] loss: 0.893
[73,     3] loss: 0.794
[74,     3] loss: 0.830
[75,     3] loss: 0.762
[76,     3] loss: 0.778
[77,     3] loss: 0.765
[78,     3] loss: 0.772
[79,     3] loss: 0.739
[80,     3] loss: 0.747
[81,     3] loss: 0.779
[82,     3] loss: 0.773
[83,     3] loss: 0.747
[84,     3] loss: 0.751
[85,     3] loss: 0.827
Early stopping applied (best metric=0.5036241412162781)
Finished Training
Total time taken: 25.35212206840515
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.399
[3,     3] loss: 1.389
[4,     3] loss: 1.382
[5,     3] loss: 1.387
[6,     3] loss: 1.383
[7,     3] loss: 1.378
[8,     3] loss: 1.371
[9,     3] loss: 1.365
[10,     3] loss: 1.348
[11,     3] loss: 1.306
[12,     3] loss: 1.273
[13,     3] loss: 1.238
[14,     3] loss: 1.213
[15,     3] loss: 1.187
[16,     3] loss: 1.094
[17,     3] loss: 1.114
[18,     3] loss: 1.032
[19,     3] loss: 1.062
[20,     3] loss: 1.071
[21,     3] loss: 1.007
[22,     3] loss: 1.030
[23,     3] loss: 0.949
[24,     3] loss: 0.916
[25,     3] loss: 0.907
[26,     3] loss: 0.965
[27,     3] loss: 0.906
[28,     3] loss: 0.957
[29,     3] loss: 0.896
[30,     3] loss: 0.925
[31,     3] loss: 0.930
[32,     3] loss: 0.920
[33,     3] loss: 0.894
[34,     3] loss: 0.831
[35,     3] loss: 0.983
[36,     3] loss: 0.900
[37,     3] loss: 0.798
[38,     3] loss: 0.896
[39,     3] loss: 0.804
[40,     3] loss: 0.969
[41,     3] loss: 0.867
[42,     3] loss: 0.821
[43,     3] loss: 0.799
[44,     3] loss: 0.787
[45,     3] loss: 0.800
[46,     3] loss: 0.860
[47,     3] loss: 0.851
[48,     3] loss: 0.869
[49,     3] loss: 0.778
[50,     3] loss: 0.799
[51,     3] loss: 0.867
[52,     3] loss: 0.892
[53,     3] loss: 0.839
[54,     3] loss: 0.865
[55,     3] loss: 0.763
[56,     3] loss: 0.799
[57,     3] loss: 0.886
[58,     3] loss: 0.771
[59,     3] loss: 0.760
[60,     3] loss: 0.794
[61,     3] loss: 0.879
[62,     3] loss: 0.768
[63,     3] loss: 0.750
[64,     3] loss: 0.791
[65,     3] loss: 0.818
[66,     3] loss: 0.754
[67,     3] loss: 0.733
[68,     3] loss: 0.741
[69,     3] loss: 0.768
[70,     3] loss: 0.742
[71,     3] loss: 0.732
[72,     3] loss: 0.743
[73,     3] loss: 0.747
[74,     3] loss: 0.733
[75,     3] loss: 0.761
[76,     3] loss: 0.771
[77,     3] loss: 0.725
[78,     3] loss: 0.742
[79,     3] loss: 0.736
[80,     3] loss: 0.868
[81,     3] loss: 0.770
[82,     3] loss: 0.734
[83,     3] loss: 0.776
[84,     3] loss: 0.739
[85,     3] loss: 0.770
[86,     3] loss: 0.772
[87,     3] loss: 0.787
[88,     3] loss: 0.737
[89,     3] loss: 0.754
[90,     3] loss: 0.765
[91,     3] loss: 0.714
[92,     3] loss: 0.731
[93,     3] loss: 0.722
[94,     3] loss: 0.751
[95,     3] loss: 0.779
[96,     3] loss: 0.781
[97,     3] loss: 0.816
[98,     3] loss: 0.773
[99,     3] loss: 0.844
[100,     3] loss: 0.766
[101,     3] loss: 0.741
[102,     3] loss: 0.773
[103,     3] loss: 0.776
[104,     3] loss: 0.824
[105,     3] loss: 0.753
[106,     3] loss: 0.945
[107,     3] loss: 0.825
[108,     3] loss: 0.769
[109,     3] loss: 0.790
[110,     3] loss: 0.758
[111,     3] loss: 0.785
[112,     3] loss: 0.758
[113,     3] loss: 0.750
[114,     3] loss: 0.798
[115,     3] loss: 0.796
[116,     3] loss: 0.754
[117,     3] loss: 0.736
[118,     3] loss: 0.770
[119,     3] loss: 0.738
[120,     3] loss: 0.718
[121,     3] loss: 0.714
[122,     3] loss: 0.716
[123,     3] loss: 0.714
[124,     3] loss: 0.718
[125,     3] loss: 0.732
[126,     3] loss: 0.782
[127,     3] loss: 0.745
[128,     3] loss: 0.726
[129,     3] loss: 0.740
[130,     3] loss: 0.720
[131,     3] loss: 0.761
[132,     3] loss: 0.727
[133,     3] loss: 0.787
[134,     3] loss: 0.754
[135,     3] loss: 0.789
[136,     3] loss: 0.761
[137,     3] loss: 0.731
[138,     3] loss: 0.739
[139,     3] loss: 0.742
[140,     3] loss: 0.810
[141,     3] loss: 0.737
[142,     3] loss: 0.755
[143,     3] loss: 0.769
[144,     3] loss: 0.747
[145,     3] loss: 0.727
[146,     3] loss: 0.721
[147,     3] loss: 0.708
[148,     3] loss: 0.727
[149,     3] loss: 0.717
[150,     3] loss: 0.706
[151,     3] loss: 0.706
[152,     3] loss: 0.710
[153,     3] loss: 0.707
[154,     3] loss: 0.703
[155,     3] loss: 0.701
[156,     3] loss: 0.707
[157,     3] loss: 0.709
Early stopping applied (best metric=0.540649950504303)
Finished Training
Total time taken: 45.22421956062317
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.393
[3,     3] loss: 1.387
[4,     3] loss: 1.389
[5,     3] loss: 1.385
[6,     3] loss: 1.378
[7,     3] loss: 1.379
[8,     3] loss: 1.389
[9,     3] loss: 1.384
[10,     3] loss: 1.361
[11,     3] loss: 1.350
[12,     3] loss: 1.354
[13,     3] loss: 1.325
[14,     3] loss: 1.306
[15,     3] loss: 1.381
[16,     3] loss: 1.282
[17,     3] loss: 1.204
[18,     3] loss: 1.248
[19,     3] loss: 1.179
[20,     3] loss: 1.128
[21,     3] loss: 1.183
[22,     3] loss: 1.084
[23,     3] loss: 1.101
[24,     3] loss: 1.039
[25,     3] loss: 1.073
[26,     3] loss: 1.048
[27,     3] loss: 1.008
[28,     3] loss: 1.055
[29,     3] loss: 0.953
[30,     3] loss: 0.985
[31,     3] loss: 0.945
[32,     3] loss: 0.994
[33,     3] loss: 0.938
[34,     3] loss: 0.923
[35,     3] loss: 0.886
[36,     3] loss: 0.968
[37,     3] loss: 0.983
[38,     3] loss: 0.896
[39,     3] loss: 0.958
[40,     3] loss: 0.989
[41,     3] loss: 0.941
[42,     3] loss: 0.895
[43,     3] loss: 0.919
[44,     3] loss: 0.883
[45,     3] loss: 0.869
[46,     3] loss: 0.880
[47,     3] loss: 0.845
[48,     3] loss: 0.835
[49,     3] loss: 0.846
[50,     3] loss: 0.797
[51,     3] loss: 0.782
[52,     3] loss: 0.798
[53,     3] loss: 0.822
[54,     3] loss: 0.801
[55,     3] loss: 0.765
[56,     3] loss: 0.847
[57,     3] loss: 0.754
[58,     3] loss: 0.775
[59,     3] loss: 0.768
[60,     3] loss: 0.774
[61,     3] loss: 0.793
[62,     3] loss: 0.769
[63,     3] loss: 0.753
[64,     3] loss: 0.764
[65,     3] loss: 0.767
[66,     3] loss: 0.785
[67,     3] loss: 0.784
[68,     3] loss: 0.827
[69,     3] loss: 0.826
[70,     3] loss: 0.784
[71,     3] loss: 0.802
[72,     3] loss: 0.813
Early stopping applied (best metric=0.4841378927230835)
Finished Training
Total time taken: 21.301103115081787
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.386
[3,     3] loss: 1.386
[4,     3] loss: 1.388
[5,     3] loss: 1.372
[6,     3] loss: 1.381
[7,     3] loss: 1.391
[8,     3] loss: 1.386
[9,     3] loss: 1.376
[10,     3] loss: 1.380
[11,     3] loss: 1.374
[12,     3] loss: 1.348
[13,     3] loss: 1.342
[14,     3] loss: 1.331
[15,     3] loss: 1.307
[16,     3] loss: 1.281
[17,     3] loss: 1.212
[18,     3] loss: 1.221
[19,     3] loss: 1.219
[20,     3] loss: 1.169
[21,     3] loss: 1.103
[22,     3] loss: 1.193
[23,     3] loss: 1.111
[24,     3] loss: 1.050
[25,     3] loss: 1.079
[26,     3] loss: 1.061
[27,     3] loss: 1.016
[28,     3] loss: 0.967
[29,     3] loss: 1.012
[30,     3] loss: 0.905
[31,     3] loss: 0.960
[32,     3] loss: 0.872
[33,     3] loss: 0.903
[34,     3] loss: 0.932
[35,     3] loss: 0.984
[36,     3] loss: 1.021
[37,     3] loss: 0.943
[38,     3] loss: 0.933
[39,     3] loss: 0.922
[40,     3] loss: 0.846
[41,     3] loss: 0.917
[42,     3] loss: 0.883
[43,     3] loss: 0.861
[44,     3] loss: 0.915
[45,     3] loss: 0.843
[46,     3] loss: 0.871
[47,     3] loss: 0.862
[48,     3] loss: 0.854
[49,     3] loss: 0.875
[50,     3] loss: 0.789
[51,     3] loss: 0.818
[52,     3] loss: 0.827
[53,     3] loss: 0.786
[54,     3] loss: 0.834
[55,     3] loss: 0.792
[56,     3] loss: 0.807
[57,     3] loss: 0.764
[58,     3] loss: 0.834
[59,     3] loss: 0.797
[60,     3] loss: 0.782
[61,     3] loss: 0.829
[62,     3] loss: 0.904
[63,     3] loss: 0.838
[64,     3] loss: 0.768
[65,     3] loss: 0.826
[66,     3] loss: 0.844
[67,     3] loss: 0.809
[68,     3] loss: 0.839
[69,     3] loss: 0.772
[70,     3] loss: 0.783
[71,     3] loss: 0.793
[72,     3] loss: 0.802
[73,     3] loss: 0.817
Early stopping applied (best metric=0.492576003074646)
Finished Training
Total time taken: 21.500101804733276
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.382
[3,     3] loss: 1.379
[4,     3] loss: 1.381
[5,     3] loss: 1.388
[6,     3] loss: 1.382
[7,     3] loss: 1.380
[8,     3] loss: 1.362
[9,     3] loss: 1.372
[10,     3] loss: 1.367
[11,     3] loss: 1.350
[12,     3] loss: 1.358
[13,     3] loss: 1.313
[14,     3] loss: 1.284
[15,     3] loss: 1.249
[16,     3] loss: 1.227
[17,     3] loss: 1.235
[18,     3] loss: 1.219
[19,     3] loss: 1.198
[20,     3] loss: 1.197
[21,     3] loss: 1.322
[22,     3] loss: 1.140
[23,     3] loss: 1.197
[24,     3] loss: 1.140
[25,     3] loss: 1.105
[26,     3] loss: 1.038
[27,     3] loss: 0.982
[28,     3] loss: 1.037
[29,     3] loss: 0.954
[30,     3] loss: 0.996
[31,     3] loss: 0.939
[32,     3] loss: 0.955
[33,     3] loss: 0.892
[34,     3] loss: 0.887
[35,     3] loss: 0.895
[36,     3] loss: 0.912
[37,     3] loss: 1.038
[38,     3] loss: 1.036
[39,     3] loss: 1.015
[40,     3] loss: 1.099
[41,     3] loss: 0.909
[42,     3] loss: 1.005
[43,     3] loss: 0.930
[44,     3] loss: 0.892
[45,     3] loss: 0.830
[46,     3] loss: 0.917
[47,     3] loss: 0.849
[48,     3] loss: 0.791
[49,     3] loss: 0.915
[50,     3] loss: 0.778
[51,     3] loss: 0.814
[52,     3] loss: 0.923
[53,     3] loss: 0.786
[54,     3] loss: 0.839
[55,     3] loss: 0.820
[56,     3] loss: 0.792
[57,     3] loss: 0.848
[58,     3] loss: 0.812
[59,     3] loss: 0.784
[60,     3] loss: 0.855
[61,     3] loss: 0.792
[62,     3] loss: 0.759
[63,     3] loss: 0.747
[64,     3] loss: 0.817
[65,     3] loss: 0.745
[66,     3] loss: 0.764
[67,     3] loss: 0.755
[68,     3] loss: 0.738
[69,     3] loss: 0.773
[70,     3] loss: 0.755
[71,     3] loss: 0.773
[72,     3] loss: 0.760
[73,     3] loss: 0.733
[74,     3] loss: 0.735
[75,     3] loss: 0.809
[76,     3] loss: 0.739
[77,     3] loss: 0.727
[78,     3] loss: 0.747
[79,     3] loss: 0.752
[80,     3] loss: 0.739
[81,     3] loss: 0.732
[82,     3] loss: 0.796
[83,     3] loss: 0.826
[84,     3] loss: 0.743
[85,     3] loss: 0.792
[86,     3] loss: 0.841
[87,     3] loss: 0.763
[88,     3] loss: 0.810
[89,     3] loss: 0.761
[90,     3] loss: 0.764
[91,     3] loss: 0.754
[92,     3] loss: 0.740
Early stopping applied (best metric=0.5348889827728271)
Finished Training
Total time taken: 27.328132152557373
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.381
[4,     3] loss: 1.372
[5,     3] loss: 1.383
[6,     3] loss: 1.377
[7,     3] loss: 1.369
[8,     3] loss: 1.354
[9,     3] loss: 1.348
[10,     3] loss: 1.324
[11,     3] loss: 1.307
[12,     3] loss: 1.271
[13,     3] loss: 1.287
[14,     3] loss: 1.296
[15,     3] loss: 1.204
[16,     3] loss: 1.194
[17,     3] loss: 1.200
[18,     3] loss: 1.139
[19,     3] loss: 1.079
[20,     3] loss: 1.002
[21,     3] loss: 1.035
[22,     3] loss: 1.114
[23,     3] loss: 1.017
[24,     3] loss: 0.959
[25,     3] loss: 1.014
[26,     3] loss: 0.986
[27,     3] loss: 0.990
[28,     3] loss: 0.916
[29,     3] loss: 1.016
[30,     3] loss: 0.937
[31,     3] loss: 0.999
[32,     3] loss: 1.056
[33,     3] loss: 0.961
[34,     3] loss: 0.857
[35,     3] loss: 0.896
[36,     3] loss: 0.862
[37,     3] loss: 0.849
[38,     3] loss: 0.854
[39,     3] loss: 0.808
[40,     3] loss: 0.790
[41,     3] loss: 0.794
[42,     3] loss: 0.830
[43,     3] loss: 0.852
[44,     3] loss: 0.773
[45,     3] loss: 0.878
[46,     3] loss: 0.796
[47,     3] loss: 0.781
[48,     3] loss: 0.861
[49,     3] loss: 0.918
[50,     3] loss: 1.075
[51,     3] loss: 0.909
[52,     3] loss: 0.827
[53,     3] loss: 0.880
[54,     3] loss: 0.887
[55,     3] loss: 0.958
[56,     3] loss: 0.905
[57,     3] loss: 0.823
[58,     3] loss: 0.875
[59,     3] loss: 0.874
[60,     3] loss: 0.806
[61,     3] loss: 0.792
[62,     3] loss: 0.770
[63,     3] loss: 0.778
[64,     3] loss: 0.796
[65,     3] loss: 0.743
[66,     3] loss: 0.752
[67,     3] loss: 0.746
[68,     3] loss: 0.749
[69,     3] loss: 0.736
[70,     3] loss: 0.743
[71,     3] loss: 0.820
[72,     3] loss: 0.730
[73,     3] loss: 1.067
Early stopping applied (best metric=0.5256776809692383)
Finished Training
Total time taken: 21.759106636047363
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.379
[2,     3] loss: 1.379
[3,     3] loss: 1.371
[4,     3] loss: 1.379
[5,     3] loss: 1.415
[6,     3] loss: 1.372
[7,     3] loss: 1.396
[8,     3] loss: 1.379
[9,     3] loss: 1.385
[10,     3] loss: 1.391
[11,     3] loss: 1.378
[12,     3] loss: 1.382
[13,     3] loss: 1.374
[14,     3] loss: 1.376
[15,     3] loss: 1.367
[16,     3] loss: 1.358
[17,     3] loss: 1.353
[18,     3] loss: 1.315
[19,     3] loss: 1.304
[20,     3] loss: 1.235
[21,     3] loss: 1.221
[22,     3] loss: 1.201
[23,     3] loss: 1.191
[24,     3] loss: 1.136
[25,     3] loss: 1.210
[26,     3] loss: 1.130
[27,     3] loss: 1.071
[28,     3] loss: 1.031
[29,     3] loss: 1.047
[30,     3] loss: 0.901
[31,     3] loss: 1.018
[32,     3] loss: 1.008
[33,     3] loss: 0.972
[34,     3] loss: 0.880
[35,     3] loss: 0.909
[36,     3] loss: 0.902
[37,     3] loss: 0.861
[38,     3] loss: 0.829
[39,     3] loss: 0.876
[40,     3] loss: 0.881
[41,     3] loss: 0.804
[42,     3] loss: 0.837
[43,     3] loss: 0.844
[44,     3] loss: 0.849
[45,     3] loss: 0.926
[46,     3] loss: 0.903
[47,     3] loss: 0.799
[48,     3] loss: 0.850
[49,     3] loss: 0.829
[50,     3] loss: 0.806
[51,     3] loss: 0.878
[52,     3] loss: 0.913
[53,     3] loss: 0.875
[54,     3] loss: 1.011
[55,     3] loss: 0.889
[56,     3] loss: 0.809
[57,     3] loss: 0.834
[58,     3] loss: 0.813
[59,     3] loss: 0.781
[60,     3] loss: 0.893
[61,     3] loss: 0.898
[62,     3] loss: 0.767
[63,     3] loss: 0.825
[64,     3] loss: 0.771
[65,     3] loss: 0.817
[66,     3] loss: 0.803
[67,     3] loss: 0.774
[68,     3] loss: 0.769
[69,     3] loss: 0.862
[70,     3] loss: 0.745
[71,     3] loss: 0.768
[72,     3] loss: 0.774
[73,     3] loss: 0.733
[74,     3] loss: 0.753
[75,     3] loss: 0.818
[76,     3] loss: 0.757
[77,     3] loss: 0.726
[78,     3] loss: 0.731
[79,     3] loss: 0.738
[80,     3] loss: 0.733
[81,     3] loss: 0.741
[82,     3] loss: 0.825
[83,     3] loss: 0.730
[84,     3] loss: 0.754
[85,     3] loss: 0.737
[86,     3] loss: 0.868
[87,     3] loss: 0.728
[88,     3] loss: 0.925
[89,     3] loss: 0.970
[90,     3] loss: 0.770
[91,     3] loss: 0.830
[92,     3] loss: 0.754
[93,     3] loss: 0.829
[94,     3] loss: 0.743
[95,     3] loss: 0.748
[96,     3] loss: 0.766
[97,     3] loss: 0.738
[98,     3] loss: 0.738
[99,     3] loss: 0.723
[100,     3] loss: 0.728
[101,     3] loss: 0.734
Early stopping applied (best metric=0.5144909024238586)
Finished Training
Total time taken: 30.37014389038086
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.407
[2,     3] loss: 1.392
[3,     3] loss: 1.392
[4,     3] loss: 1.389
[5,     3] loss: 1.390
[6,     3] loss: 1.387
[7,     3] loss: 1.389
[8,     3] loss: 1.389
[9,     3] loss: 1.378
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.390
[13,     3] loss: 1.383
[14,     3] loss: 1.376
[15,     3] loss: 1.369
[16,     3] loss: 1.364
[17,     3] loss: 1.356
[18,     3] loss: 1.356
[19,     3] loss: 1.353
[20,     3] loss: 1.346
[21,     3] loss: 1.313
[22,     3] loss: 1.291
[23,     3] loss: 1.234
[24,     3] loss: 1.232
[25,     3] loss: 1.187
[26,     3] loss: 1.167
[27,     3] loss: 1.125
[28,     3] loss: 1.147
[29,     3] loss: 1.145
[30,     3] loss: 1.174
[31,     3] loss: 1.136
[32,     3] loss: 1.092
[33,     3] loss: 1.201
[34,     3] loss: 1.053
[35,     3] loss: 1.009
[36,     3] loss: 1.025
[37,     3] loss: 0.998
[38,     3] loss: 1.048
[39,     3] loss: 0.937
[40,     3] loss: 1.101
[41,     3] loss: 1.008
[42,     3] loss: 0.931
[43,     3] loss: 0.929
[44,     3] loss: 0.926
[45,     3] loss: 0.912
[46,     3] loss: 0.912
[47,     3] loss: 0.902
[48,     3] loss: 0.950
[49,     3] loss: 0.894
[50,     3] loss: 0.840
[51,     3] loss: 0.949
[52,     3] loss: 0.897
[53,     3] loss: 0.886
[54,     3] loss: 1.023
[55,     3] loss: 0.836
[56,     3] loss: 0.839
[57,     3] loss: 0.825
[58,     3] loss: 0.810
[59,     3] loss: 0.867
[60,     3] loss: 0.801
[61,     3] loss: 0.796
[62,     3] loss: 0.800
[63,     3] loss: 0.811
[64,     3] loss: 0.749
[65,     3] loss: 0.752
[66,     3] loss: 0.918
[67,     3] loss: 0.797
[68,     3] loss: 0.772
[69,     3] loss: 0.821
[70,     3] loss: 0.800
[71,     3] loss: 0.810
[72,     3] loss: 0.778
[73,     3] loss: 0.769
[74,     3] loss: 0.860
[75,     3] loss: 0.792
[76,     3] loss: 0.788
[77,     3] loss: 0.793
[78,     3] loss: 0.788
[79,     3] loss: 0.928
[80,     3] loss: 0.938
[81,     3] loss: 0.870
[82,     3] loss: 0.857
[83,     3] loss: 0.798
[84,     3] loss: 0.797
[85,     3] loss: 0.823
Early stopping applied (best metric=0.5150161385536194)
Finished Training
Total time taken: 25.388122081756592
{'S-palmitoylation-C Validation Accuracy': 0.6770322060278392, 'S-palmitoylation-C Validation Sensitivity': 0.2720792079207921, 'S-palmitoylation-C Validation Specificity': 0.7785361854939329, 'S-palmitoylation-C Validation Precision': 0.24190229648019243, 'S-palmitoylation-C AUC ROC': 0.5472351022308906, 'S-palmitoylation-C AUC PR': 0.23181009757758952, 'S-palmitoylation-C MCC': 0.05092390163611148, 'S-palmitoylation-C F1': 0.23454604831629333, 'Validation Loss (S-palmitoylation-C)': 0.5546587785085042, 'Hydroxylation-K Validation Accuracy': 0.6830673758865248, 'Hydroxylation-K Validation Sensitivity': 0.7844444444444444, 'Hydroxylation-K Validation Specificity': 0.6578947368421053, 'Hydroxylation-K Validation Precision': 0.39324023633794264, 'Hydroxylation-K AUC ROC': 0.7794931773879142, 'Hydroxylation-K AUC PR': 0.5548437642678994, 'Hydroxylation-K MCC': 0.3736724005257831, 'Hydroxylation-K F1': 0.5146406089365698, 'Validation Loss (Hydroxylation-K)': 0.513245310386022, 'Validation Loss (total)': 1.0679040988286337, 'TimeToTrain': 25.584189955393473}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009566473594944516,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2569621467859974,
 'loss_weight_S-palmitoylation-C': 0.9892716690093468,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 359165481,
 'sample_weights': [0.881447422964597, 0.27897140193487163],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.095432454952205,
 'weight_decay_Hydroxylation-K': 7.981431086525932,
 'weight_decay_S-palmitoylation-C': 3.937412079304461}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.380
[3,     3] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007249077365538036,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3492428735729832,
 'loss_weight_S-palmitoylation-C': 0.07686264512615454,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 80698423,
 'sample_weights': [0.9892716690093468, 0.2569621467859974],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.062088625961522,
 'weight_decay_Hydroxylation-K': 8.083611585802675,
 'weight_decay_S-palmitoylation-C': 2.1223034529854}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.396
[3,     3] loss: 1.387
[4,     3] loss: 1.387
[5,     3] loss: 1.389
[6,     3] loss: 1.387
[7,     3] loss: 1.388
[8,     3] loss: 1.387
[9,     3] loss: 1.388
[10,     3] loss: 1.388
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.384
[23,     3] loss: 1.385
[24,     3] loss: 1.387
[25,     3] loss: 1.383
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.390
[29,     3] loss: 1.383
[30,     3] loss: 1.384
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.388
[34,     3] loss: 1.386
[35,     3] loss: 1.387
[36,     3] loss: 1.386
[37,     3] loss: 1.387
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.387
[42,     3] loss: 1.387
[43,     3] loss: 1.387
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.383
[50,     3] loss: 1.386
[51,     3] loss: 1.388
[52,     3] loss: 1.386
Early stopping applied (best metric=0.5620157718658447)
Finished Training
Total time taken: 15.207074403762817
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.390
[3,     3] loss: 1.387
[4,     3] loss: 1.384
[5,     3] loss: 1.387
[6,     3] loss: 1.379
[7,     3] loss: 1.380
[8,     3] loss: 1.387
[9,     3] loss: 1.387
[10,     3] loss: 1.377
[11,     3] loss: 1.364
[12,     3] loss: 1.335
[13,     3] loss: 1.332
[14,     3] loss: 1.236
[15,     3] loss: 1.150
[16,     3] loss: 1.179
[17,     3] loss: 1.196
[18,     3] loss: 1.146
[19,     3] loss: 1.151
[20,     3] loss: 1.088
[21,     3] loss: 1.089
[22,     3] loss: 1.011
[23,     3] loss: 1.093
[24,     3] loss: 1.416
[25,     3] loss: 1.233
[26,     3] loss: 1.218
[27,     3] loss: 1.274
[28,     3] loss: 1.246
[29,     3] loss: 1.179
[30,     3] loss: 1.186
[31,     3] loss: 1.218
[32,     3] loss: 1.133
[33,     3] loss: 1.226
[34,     3] loss: 1.187
[35,     3] loss: 1.130
[36,     3] loss: 1.101
[37,     3] loss: 1.178
[38,     3] loss: 1.175
[39,     3] loss: 1.215
[40,     3] loss: 1.188
[41,     3] loss: 1.195
[42,     3] loss: 1.077
[43,     3] loss: 1.231
[44,     3] loss: 1.258
[45,     3] loss: 1.184
[46,     3] loss: 1.111
[47,     3] loss: 1.105
[48,     3] loss: 1.146
[49,     3] loss: 1.089
[50,     3] loss: 1.016
[51,     3] loss: 1.132
[52,     3] loss: 1.210
[53,     3] loss: 1.198
[54,     3] loss: 1.148
[55,     3] loss: 1.007
[56,     3] loss: 1.019
[57,     3] loss: 1.067
[58,     3] loss: 1.172
[59,     3] loss: 1.085
[60,     3] loss: 1.083
[61,     3] loss: 1.020
[62,     3] loss: 0.944
[63,     3] loss: 1.032
[64,     3] loss: 1.009
[65,     3] loss: 1.251
[66,     3] loss: 1.386
[67,     3] loss: 1.310
[68,     3] loss: 1.312
[69,     3] loss: 1.208
[70,     3] loss: 1.289
[71,     3] loss: 1.286
[72,     3] loss: 1.306
[73,     3] loss: 1.264
[74,     3] loss: 1.306
[75,     3] loss: 1.222
[76,     3] loss: 1.230
[77,     3] loss: 1.228
[78,     3] loss: 1.221
[79,     3] loss: 1.164
[80,     3] loss: 1.115
[81,     3] loss: 1.232
[82,     3] loss: 1.063
[83,     3] loss: 1.033
[84,     3] loss: 1.118
[85,     3] loss: 1.062
[86,     3] loss: 1.090
[87,     3] loss: 1.071
[88,     3] loss: 1.052
[89,     3] loss: 1.168
[90,     3] loss: 1.024
[91,     3] loss: 1.022
[92,     3] loss: 1.091
[93,     3] loss: 1.211
[94,     3] loss: 1.201
[95,     3] loss: 1.169
[96,     3] loss: 1.138
[97,     3] loss: 1.110
[98,     3] loss: 1.073
[99,     3] loss: 1.063
[100,     3] loss: 1.135
[101,     3] loss: 1.053
[102,     3] loss: 0.993
[103,     3] loss: 1.201
[104,     3] loss: 1.173
[105,     3] loss: 1.079
[106,     3] loss: 1.149
[107,     3] loss: 1.038
[108,     3] loss: 0.986
[109,     3] loss: 0.910
[110,     3] loss: 1.325
[111,     3] loss: 1.260
[112,     3] loss: 1.198
[113,     3] loss: 1.165
[114,     3] loss: 1.130
[115,     3] loss: 1.103
[116,     3] loss: 1.920
[117,     3] loss: 1.392
[118,     3] loss: 1.388
[119,     3] loss: 1.386
[120,     3] loss: 1.388
[121,     3] loss: 1.384
[122,     3] loss: 1.387
[123,     3] loss: 1.387
[124,     3] loss: 1.387
[125,     3] loss: 1.386
[126,     3] loss: 1.387
[127,     3] loss: 1.386
[128,     3] loss: 1.386
[129,     3] loss: 1.386
[130,     3] loss: 1.386
[131,     3] loss: 1.386
[132,     3] loss: 1.387
[133,     3] loss: 1.387
[134,     3] loss: 1.386
[135,     3] loss: 1.386
[136,     3] loss: 1.387
[137,     3] loss: 1.386
[138,     3] loss: 1.387
[139,     3] loss: 1.387
[140,     3] loss: 1.386
[141,     3] loss: 1.386
Early stopping applied (best metric=0.5305684804916382)
Finished Training
Total time taken: 40.96619963645935
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.388
[3,     3] loss: 1.389
[4,     3] loss: 1.390
[5,     3] loss: 1.385
[6,     3] loss: 1.387
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.388
[10,     3] loss: 1.385
[11,     3] loss: 1.387
[12,     3] loss: 1.386
[13,     3] loss: 1.388
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.385
[19,     3] loss: 1.382
[20,     3] loss: 1.346
[21,     3] loss: 1.334
[22,     3] loss: 1.251
[23,     3] loss: 1.317
[24,     3] loss: 1.227
[25,     3] loss: 1.353
[26,     3] loss: 1.377
[27,     3] loss: 1.320
[28,     3] loss: 1.279
[29,     3] loss: 1.152
[30,     3] loss: 1.148
[31,     3] loss: 1.211
[32,     3] loss: 1.265
[33,     3] loss: 1.222
[34,     3] loss: 1.184
[35,     3] loss: 1.137
[36,     3] loss: 1.221
[37,     3] loss: 1.076
[38,     3] loss: 1.121
[39,     3] loss: 1.031
[40,     3] loss: 0.936
[41,     3] loss: 1.222
[42,     3] loss: 1.041
[43,     3] loss: 1.055
[44,     3] loss: 1.192
[45,     3] loss: 1.178
[46,     3] loss: 1.165
[47,     3] loss: 1.102
[48,     3] loss: 0.949
[49,     3] loss: 0.970
[50,     3] loss: 1.118
[51,     3] loss: 1.150
[52,     3] loss: 1.118
[53,     3] loss: 1.109
[54,     3] loss: 1.014
[55,     3] loss: 1.199
[56,     3] loss: 1.259
[57,     3] loss: 1.235
[58,     3] loss: 1.202
[59,     3] loss: 1.145
[60,     3] loss: 1.072
[61,     3] loss: 0.977
[62,     3] loss: 0.942
[63,     3] loss: 1.351
[64,     3] loss: 1.270
[65,     3] loss: 1.269
[66,     3] loss: 1.316
[67,     3] loss: 1.180
[68,     3] loss: 1.123
[69,     3] loss: 1.064
[70,     3] loss: 1.104
[71,     3] loss: 1.041
[72,     3] loss: 0.972
[73,     3] loss: 0.967
[74,     3] loss: 0.927
[75,     3] loss: 0.954
[76,     3] loss: 1.041
[77,     3] loss: 1.121
[78,     3] loss: 1.153
[79,     3] loss: 1.162
[80,     3] loss: 1.237
[81,     3] loss: 1.075
[82,     3] loss: 1.089
[83,     3] loss: 1.210
[84,     3] loss: 1.112
[85,     3] loss: 1.119
[86,     3] loss: 1.056
Early stopping applied (best metric=0.5356025695800781)
Finished Training
Total time taken: 25.134121656417847
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.385
[3,     3] loss: 1.398
[4,     3] loss: 1.391
[5,     3] loss: 1.387
[6,     3] loss: 1.387
[7,     3] loss: 1.384
[8,     3] loss: 1.392
[9,     3] loss: 1.384
[10,     3] loss: 1.384
[11,     3] loss: 1.388
[12,     3] loss: 1.386
[13,     3] loss: 1.388
[14,     3] loss: 1.385
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.387
[22,     3] loss: 1.386
[23,     3] loss: 1.387
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.387
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.387
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.387
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.387
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.388
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.387
[51,     3] loss: 1.386
[52,     3] loss: 1.387
Early stopping applied (best metric=0.5442038178443909)
Finished Training
Total time taken: 15.5360746383667
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.372
[3,     3] loss: 1.388
[4,     3] loss: 1.389
[5,     3] loss: 1.382
[6,     3] loss: 1.398
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.387
[10,     3] loss: 1.387
[11,     3] loss: 1.388
[12,     3] loss: 1.387
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.387
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.387
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.387
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.387
[33,     3] loss: 1.387
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.387
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.387
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.387
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.387
[49,     3] loss: 1.387
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.387
[54,     3] loss: 1.386
Early stopping applied (best metric=0.5451806783676147)
Finished Training
Total time taken: 15.815077304840088
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.402
[3,     3] loss: 1.391
[4,     3] loss: 1.385
[5,     3] loss: 1.390
[6,     3] loss: 1.386
[7,     3] loss: 1.386
[8,     3] loss: 1.387
[9,     3] loss: 1.388
[10,     3] loss: 1.386
[11,     3] loss: 1.384
[12,     3] loss: 1.386
[13,     3] loss: 1.384
[14,     3] loss: 1.382
[15,     3] loss: 1.386
[16,     3] loss: 1.382
[17,     3] loss: 1.376
[18,     3] loss: 1.352
[19,     3] loss: 1.326
[20,     3] loss: 1.343
[21,     3] loss: 1.362
[22,     3] loss: 1.382
[23,     3] loss: 1.386
[24,     3] loss: 1.344
[25,     3] loss: 1.391
[26,     3] loss: 1.377
[27,     3] loss: 1.377
[28,     3] loss: 1.306
[29,     3] loss: 1.263
[30,     3] loss: 1.238
[31,     3] loss: 1.327
[32,     3] loss: 1.237
[33,     3] loss: 1.169
[34,     3] loss: 1.138
[35,     3] loss: 1.117
[36,     3] loss: 1.237
[37,     3] loss: 1.223
[38,     3] loss: 1.143
[39,     3] loss: 1.122
[40,     3] loss: 1.309
[41,     3] loss: 1.120
[42,     3] loss: 1.149
[43,     3] loss: 1.241
[44,     3] loss: 1.149
[45,     3] loss: 1.141
[46,     3] loss: 1.177
[47,     3] loss: 1.108
[48,     3] loss: 0.995
[49,     3] loss: 1.060
[50,     3] loss: 1.208
[51,     3] loss: 1.159
[52,     3] loss: 1.251
[53,     3] loss: 1.275
[54,     3] loss: 1.274
[55,     3] loss: 1.214
[56,     3] loss: 1.170
[57,     3] loss: 1.218
[58,     3] loss: 1.101
[59,     3] loss: 1.053
[60,     3] loss: 1.144
[61,     3] loss: 1.289
[62,     3] loss: 1.367
[63,     3] loss: 1.326
[64,     3] loss: 1.306
[65,     3] loss: 1.247
[66,     3] loss: 1.294
[67,     3] loss: 1.260
[68,     3] loss: 1.243
[69,     3] loss: 1.183
[70,     3] loss: 1.164
[71,     3] loss: 1.112
[72,     3] loss: 1.201
[73,     3] loss: 1.252
[74,     3] loss: 1.208
[75,     3] loss: 1.211
[76,     3] loss: 1.148
[77,     3] loss: 1.069
[78,     3] loss: 1.116
[79,     3] loss: 1.102
[80,     3] loss: 1.118
[81,     3] loss: 1.119
[82,     3] loss: 1.104
[83,     3] loss: 1.071
[84,     3] loss: 1.066
[85,     3] loss: 1.003
[86,     3] loss: 1.183
[87,     3] loss: 1.102
[88,     3] loss: 1.149
[89,     3] loss: 1.112
[90,     3] loss: 1.184
[91,     3] loss: 1.111
[92,     3] loss: 1.079
[93,     3] loss: 1.360
[94,     3] loss: 1.230
[95,     3] loss: 1.239
[96,     3] loss: 1.174
[97,     3] loss: 1.260
[98,     3] loss: 1.261
[99,     3] loss: 1.237
[100,     3] loss: 1.162
[101,     3] loss: 1.146
[102,     3] loss: 1.180
[103,     3] loss: 1.183
[104,     3] loss: 1.189
[105,     3] loss: 1.223
[106,     3] loss: 1.120
[107,     3] loss: 1.098
[108,     3] loss: 1.057
[109,     3] loss: 1.156
[110,     3] loss: 1.043
[111,     3] loss: 1.106
[112,     3] loss: 1.012
[113,     3] loss: 1.031
[114,     3] loss: 0.955
[115,     3] loss: 1.047
[116,     3] loss: 1.351
[117,     3] loss: 1.255
[118,     3] loss: 1.238
[119,     3] loss: 1.212
[120,     3] loss: 1.261
[121,     3] loss: 1.195
[122,     3] loss: 1.275
[123,     3] loss: 1.258
[124,     3] loss: 1.220
[125,     3] loss: 1.184
[126,     3] loss: 1.287
[127,     3] loss: 1.276
[128,     3] loss: 1.245
[129,     3] loss: 1.149
Early stopping applied (best metric=0.5098671913146973)
Finished Training
Total time taken: 38.189194440841675
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.393
[3,     3] loss: 1.384
[4,     3] loss: 1.392
[5,     3] loss: 1.383
[6,     3] loss: 1.387
[7,     3] loss: 1.389
[8,     3] loss: 1.383
[9,     3] loss: 1.386
[10,     3] loss: 1.390
[11,     3] loss: 1.388
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.385
[15,     3] loss: 1.385
[16,     3] loss: 1.386
[17,     3] loss: 1.387
[18,     3] loss: 1.385
[19,     3] loss: 1.385
[20,     3] loss: 1.386
[21,     3] loss: 1.384
[22,     3] loss: 1.386
[23,     3] loss: 1.383
[24,     3] loss: 1.382
[25,     3] loss: 1.349
[26,     3] loss: 1.347
[27,     3] loss: 1.321
[28,     3] loss: 1.357
[29,     3] loss: 1.338
[30,     3] loss: 1.324
[31,     3] loss: 1.290
[32,     3] loss: 1.237
[33,     3] loss: 1.171
[34,     3] loss: 1.154
[35,     3] loss: 1.140
[36,     3] loss: 1.116
[37,     3] loss: 1.044
[38,     3] loss: 1.401
[39,     3] loss: 1.277
[40,     3] loss: 1.261
[41,     3] loss: 1.243
[42,     3] loss: 1.221
[43,     3] loss: 1.138
[44,     3] loss: 1.106
[45,     3] loss: 1.326
[46,     3] loss: 1.223
[47,     3] loss: 1.272
[48,     3] loss: 1.212
[49,     3] loss: 1.254
[50,     3] loss: 1.084
[51,     3] loss: 1.142
[52,     3] loss: 1.271
[53,     3] loss: 1.271
[54,     3] loss: 1.218
[55,     3] loss: 1.178
[56,     3] loss: 1.274
[57,     3] loss: 1.122
[58,     3] loss: 1.065
[59,     3] loss: 0.948
[60,     3] loss: 1.087
[61,     3] loss: 1.093
[62,     3] loss: 1.074
[63,     3] loss: 1.365
[64,     3] loss: 1.248
[65,     3] loss: 1.195
[66,     3] loss: 1.137
[67,     3] loss: 1.196
[68,     3] loss: 1.285
[69,     3] loss: 1.246
[70,     3] loss: 1.203
[71,     3] loss: 1.165
[72,     3] loss: 1.158
[73,     3] loss: 1.066
[74,     3] loss: 1.113
[75,     3] loss: 1.149
[76,     3] loss: 1.076
[77,     3] loss: 1.054
[78,     3] loss: 0.955
[79,     3] loss: 1.396
[80,     3] loss: 1.161
[81,     3] loss: 1.125
[82,     3] loss: 1.174
[83,     3] loss: 1.135
[84,     3] loss: 1.323
[85,     3] loss: 1.173
[86,     3] loss: 1.151
Early stopping applied (best metric=0.5225210189819336)
Finished Training
Total time taken: 25.407119274139404
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.389
[3,     3] loss: 1.389
[4,     3] loss: 1.385
[5,     3] loss: 1.380
[6,     3] loss: 1.396
[7,     3] loss: 1.389
[8,     3] loss: 1.385
[9,     3] loss: 1.390
[10,     3] loss: 1.387
[11,     3] loss: 1.387
[12,     3] loss: 1.387
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.387
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.387
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.387
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.387
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.387
[43,     3] loss: 1.387
[44,     3] loss: 1.387
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.385
[51,     3] loss: 1.386
[52,     3] loss: 1.388
Early stopping applied (best metric=0.562466025352478)
Finished Training
Total time taken: 15.3750741481781
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.394
[3,     3] loss: 1.389
[4,     3] loss: 1.383
[5,     3] loss: 1.390
[6,     3] loss: 1.386
[7,     3] loss: 1.391
[8,     3] loss: 1.385
[9,     3] loss: 1.388
[10,     3] loss: 1.383
[11,     3] loss: 1.387
[12,     3] loss: 1.383
[13,     3] loss: 1.386
[14,     3] loss: 1.389
[15,     3] loss: 1.385
[16,     3] loss: 1.388
[17,     3] loss: 1.387
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.387
[25,     3] loss: 1.386
[26,     3] loss: 1.387
[27,     3] loss: 1.387
[28,     3] loss: 1.387
[29,     3] loss: 1.386
[30,     3] loss: 1.387
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.387
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.387
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.387
[41,     3] loss: 1.387
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.388
[45,     3] loss: 1.387
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.387
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.387
[56,     3] loss: 1.386
[57,     3] loss: 1.386
[58,     3] loss: 1.386
[59,     3] loss: 1.386
[60,     3] loss: 1.387
Early stopping applied (best metric=0.5451955199241638)
Finished Training
Total time taken: 17.31708574295044
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.386
[3,     3] loss: 1.386
[4,     3] loss: 1.389
[5,     3] loss: 1.391
[6,     3] loss: 1.387
[7,     3] loss: 1.387
[8,     3] loss: 1.385
[9,     3] loss: 1.385
[10,     3] loss: 1.390
[11,     3] loss: 1.390
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.387
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.387
[42,     3] loss: 1.386
[43,     3] loss: 1.388
[44,     3] loss: 1.386
[45,     3] loss: 1.385
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.388
[51,     3] loss: 1.386
[52,     3] loss: 1.387
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.387
[56,     3] loss: 1.387
[57,     3] loss: 1.386
[58,     3] loss: 1.386
[59,     3] loss: 1.387
[60,     3] loss: 1.387
[61,     3] loss: 1.386
Early stopping applied (best metric=0.5451997518539429)
Finished Training
Total time taken: 18.04808759689331
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.387
[3,     3] loss: 1.393
[4,     3] loss: 1.391
[5,     3] loss: 1.388
[6,     3] loss: 1.389
[7,     3] loss: 1.387
[8,     3] loss: 1.386
[9,     3] loss: 1.387
[10,     3] loss: 1.386
[11,     3] loss: 1.384
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.388
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.386
[22,     3] loss: 1.385
[23,     3] loss: 1.383
[24,     3] loss: 1.373
[25,     3] loss: 1.315
[26,     3] loss: 1.331
[27,     3] loss: 1.279
[28,     3] loss: 1.259
[29,     3] loss: 1.224
[30,     3] loss: 1.346
[31,     3] loss: 1.276
[32,     3] loss: 1.275
[33,     3] loss: 1.161
[34,     3] loss: 1.008
[35,     3] loss: 1.417
[36,     3] loss: 1.318
[37,     3] loss: 1.302
[38,     3] loss: 1.277
[39,     3] loss: 1.289
[40,     3] loss: 1.209
[41,     3] loss: 1.142
[42,     3] loss: 1.177
[43,     3] loss: 1.100
[44,     3] loss: 1.067
[45,     3] loss: 1.235
[46,     3] loss: 1.173
[47,     3] loss: 1.134
[48,     3] loss: 1.095
[49,     3] loss: 0.975
[50,     3] loss: 0.948
[51,     3] loss: 1.118
[52,     3] loss: 1.066
[53,     3] loss: 1.089
[54,     3] loss: 1.073
[55,     3] loss: 1.183
[56,     3] loss: 1.133
[57,     3] loss: 1.185
[58,     3] loss: 1.171
[59,     3] loss: 1.095
[60,     3] loss: 1.065
[61,     3] loss: 1.044
[62,     3] loss: 1.121
[63,     3] loss: 1.055
[64,     3] loss: 1.044
[65,     3] loss: 0.979
[66,     3] loss: 1.284
[67,     3] loss: 1.448
[68,     3] loss: 1.319
[69,     3] loss: 1.349
[70,     3] loss: 1.331
[71,     3] loss: 1.361
[72,     3] loss: 1.342
[73,     3] loss: 1.334
[74,     3] loss: 1.300
[75,     3] loss: 1.301
[76,     3] loss: 1.253
[77,     3] loss: 1.211
[78,     3] loss: 1.197
[79,     3] loss: 1.204
[80,     3] loss: 1.224
[81,     3] loss: 1.177
[82,     3] loss: 1.191
[83,     3] loss: 1.155
[84,     3] loss: 1.344
[85,     3] loss: 1.320
[86,     3] loss: 1.236
[87,     3] loss: 1.333
[88,     3] loss: 1.281
[89,     3] loss: 1.278
[90,     3] loss: 1.247
[91,     3] loss: 1.223
[92,     3] loss: 1.208
[93,     3] loss: 1.148
[94,     3] loss: 1.140
[95,     3] loss: 1.166
[96,     3] loss: 1.249
[97,     3] loss: 1.270
[98,     3] loss: 1.233
[99,     3] loss: 1.206
Early stopping applied (best metric=0.5441268682479858)
Finished Training
Total time taken: 29.063599586486816
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.392
[3,     3] loss: 1.387
[4,     3] loss: 1.369
[5,     3] loss: 1.386
[6,     3] loss: 1.393
[7,     3] loss: 1.382
[8,     3] loss: 1.383
[9,     3] loss: 1.375
[10,     3] loss: 1.353
[11,     3] loss: 1.332
[12,     3] loss: 1.282
[13,     3] loss: 1.199
[14,     3] loss: 1.194
[15,     3] loss: 1.174
[16,     3] loss: 1.164
[17,     3] loss: 1.058
[18,     3] loss: 0.982
[19,     3] loss: 1.068
[20,     3] loss: 1.059
[21,     3] loss: 1.012
[22,     3] loss: 0.965
[23,     3] loss: 1.252
[24,     3] loss: 1.212
[25,     3] loss: 1.309
[26,     3] loss: 1.332
[27,     3] loss: 1.336
[28,     3] loss: 1.235
[29,     3] loss: 1.287
[30,     3] loss: 1.261
[31,     3] loss: 1.241
[32,     3] loss: 1.231
[33,     3] loss: 1.189
[34,     3] loss: 1.105
[35,     3] loss: 0.989
[36,     3] loss: 2.049
[37,     3] loss: 1.397
[38,     3] loss: 1.368
[39,     3] loss: 1.367
[40,     3] loss: 1.346
[41,     3] loss: 1.385
[42,     3] loss: 1.356
[43,     3] loss: 1.347
[44,     3] loss: 1.376
[45,     3] loss: 1.352
[46,     3] loss: 1.335
[47,     3] loss: 1.303
[48,     3] loss: 1.298
[49,     3] loss: 1.329
[50,     3] loss: 1.291
[51,     3] loss: 1.176
[52,     3] loss: 1.366
[53,     3] loss: 1.379
[54,     3] loss: 1.310
[55,     3] loss: 1.285
[56,     3] loss: 1.249
[57,     3] loss: 1.225
[58,     3] loss: 1.179
[59,     3] loss: 1.158
[60,     3] loss: 1.247
[61,     3] loss: 1.201
[62,     3] loss: 1.228
[63,     3] loss: 1.209
Early stopping applied (best metric=0.5147616267204285)
Finished Training
Total time taken: 18.055086851119995
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.399
[2,     3] loss: 1.378
[3,     3] loss: 1.410
[4,     3] loss: 1.385
[5,     3] loss: 1.390
[6,     3] loss: 1.383
[7,     3] loss: 1.382
[8,     3] loss: 1.388
[9,     3] loss: 1.389
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.387
[30,     3] loss: 1.387
[31,     3] loss: 1.386
[32,     3] loss: 1.387
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.387
[36,     3] loss: 1.386
[37,     3] loss: 1.387
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.387
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.387
[45,     3] loss: 1.387
[46,     3] loss: 1.387
[47,     3] loss: 1.386
[48,     3] loss: 1.387
[49,     3] loss: 1.387
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.387
[55,     3] loss: 1.385
[56,     3] loss: 1.386
[57,     3] loss: 1.387
[58,     3] loss: 1.387
[59,     3] loss: 1.386
[60,     3] loss: 1.387
Early stopping applied (best metric=0.5628370642662048)
Finished Training
Total time taken: 17.428083896636963
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.386
[3,     3] loss: 1.393
[4,     3] loss: 1.385
[5,     3] loss: 1.383
[6,     3] loss: 1.389
[7,     3] loss: 1.383
[8,     3] loss: 1.390
[9,     3] loss: 1.384
[10,     3] loss: 1.393
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.388
[32,     3] loss: 1.386
[33,     3] loss: 1.385
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.387
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.387
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.388
[54,     3] loss: 1.385
[55,     3] loss: 1.385
[56,     3] loss: 1.388
[57,     3] loss: 1.387
[58,     3] loss: 1.386
[59,     3] loss: 1.385
[60,     3] loss: 1.387
[61,     3] loss: 1.387
[62,     3] loss: 1.387
[63,     3] loss: 1.387
[64,     3] loss: 1.386
[65,     3] loss: 1.387
Early stopping applied (best metric=0.5453211665153503)
Finished Training
Total time taken: 19.53409218788147
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.395
[3,     3] loss: 1.396
[4,     3] loss: 1.387
[5,     3] loss: 1.388
[6,     3] loss: 1.388
[7,     3] loss: 1.391
[8,     3] loss: 1.386
[9,     3] loss: 1.388
[10,     3] loss: 1.386
[11,     3] loss: 1.387
[12,     3] loss: 1.386
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.387
[24,     3] loss: 1.389
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.387
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.387
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.385
[41,     3] loss: 1.385
[42,     3] loss: 1.388
[43,     3] loss: 1.387
[44,     3] loss: 1.385
[45,     3] loss: 1.386
[46,     3] loss: 1.387
[47,     3] loss: 1.386
[48,     3] loss: 1.387
[49,     3] loss: 1.386
[50,     3] loss: 1.387
[51,     3] loss: 1.386
Early stopping applied (best metric=0.5452461838722229)
Finished Training
Total time taken: 14.932069540023804
{'S-palmitoylation-C Validation Accuracy': 0.5401688857802395, 'S-palmitoylation-C Validation Sensitivity': 0.4405280528052805, 'S-palmitoylation-C Validation Specificity': 0.5651272030443636, 'S-palmitoylation-C Validation Precision': nan, 'S-palmitoylation-C AUC ROC': 0.5211902747966488, 'S-palmitoylation-C AUC PR': 0.21275735394265494, 'S-palmitoylation-C MCC': 0.006580104923079622, 'S-palmitoylation-C F1': 0.18665149856968818, 'Validation Loss (S-palmitoylation-C)': 0.5558695117632548, 'Hydroxylation-K Validation Accuracy': 0.5588947990543736, 'Hydroxylation-K Validation Sensitivity': 0.5748148148148148, 'Hydroxylation-K Validation Specificity': 0.5578947368421052, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.7622124756335282, 'Hydroxylation-K AUC PR': 0.5341545539342123, 'Hydroxylation-K MCC': 0.14000889126407273, 'Hydroxylation-K F1': 0.2743545783625744, 'Validation Loss (Hydroxylation-K)': 0.5410075823465983, 'Validation Loss (total)': 1.096877098083496, 'TimeToTrain': 21.733869393666584}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033204728183400933,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.34623751499035615,
 'loss_weight_S-palmitoylation-C': 0.9433725308775951,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2161312377,
 'sample_weights': [0.07686264512615454, 0.3492428735729832],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.087995497071432,
 'weight_decay_Hydroxylation-K': 3.917976004338278,
 'weight_decay_S-palmitoylation-C': 1.129112786884255}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.408
[3,     3] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008904228144479028,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6098760958158882,
 'loss_weight_S-palmitoylation-C': 0.14086091768227732,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3598660593,
 'sample_weights': [0.9433725308775951, 0.34623751499035615],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.450534168662799,
 'weight_decay_Hydroxylation-K': 8.382978447573818,
 'weight_decay_S-palmitoylation-C': 0.7220884773553549}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.394
[3,     3] loss: 1.395
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009115368745371832,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1211829916781444,
 'loss_weight_S-palmitoylation-C': 0.199229095792866,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1642118477,
 'sample_weights': [0.14086091768227732, 0.6098760958158882],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.378216908471856,
 'weight_decay_Hydroxylation-K': 5.532299569898277,
 'weight_decay_S-palmitoylation-C': 3.2841768080084224}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.404
[3,     3] loss: 1.390
[4,     3] loss: 1.386
[5,     3] loss: 1.392
[6,     3] loss: 1.388
[7,     3] loss: 1.387
[8,     3] loss: 1.389
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006540032405669068,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2568718903481228,
 'loss_weight_S-palmitoylation-C': 0.05474278809946103,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1417699203,
 'sample_weights': [0.199229095792866, 0.1211829916781444],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.224020434148526,
 'weight_decay_Hydroxylation-K': 7.909941264197448,
 'weight_decay_S-palmitoylation-C': 1.8335190068417728}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.389
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004181297135386239,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.18297049691055503,
 'loss_weight_S-palmitoylation-C': 0.6943231715417816,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3226303401,
 'sample_weights': [0.05474278809946103, 0.2568718903481228],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.09901574466879892,
 'weight_decay_Hydroxylation-K': 2.5707825266558895,
 'weight_decay_S-palmitoylation-C': 1.0610113912674353}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.391
[3,     3] loss: 1.397
[4,     3] loss: 1.390
[5,     3] loss: 1.390
[6,     3] loss: 1.396
[7,     3] loss: 1.383
[8,     3] loss: 1.384
[9,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001415210187861054,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3156681162394619,
 'loss_weight_S-palmitoylation-C': 0.7841708726277643,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1301955960,
 'sample_weights': [0.6943231715417816, 0.18297049691055503],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.5216701718726586,
 'weight_decay_Hydroxylation-K': 5.050830161899159,
 'weight_decay_S-palmitoylation-C': 0.7104904840488616}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.393
[3,     3] loss: 1.384
[4,     3] loss: 1.385
[5,     3] loss: 1.388
[6,     3] loss: 1.380
[7,     3] loss: 1.389
[8,     3] loss: 1.381
[9,     3] loss: 1.376
[10,     3] loss: 1.385
[11,     3] loss: 1.382
[12,     3] loss: 1.383
[13,     3] loss: 1.371
[14,     3] loss: 1.382
[15,     3] loss: 1.368
[16,     3] loss: 1.351
[17,     3] loss: 1.352
[18,     3] loss: 1.330
[19,     3] loss: 1.338
[20,     3] loss: 1.275
[21,     3] loss: 1.302
[22,     3] loss: 1.259
[23,     3] loss: 1.251
[24,     3] loss: 1.177
[25,     3] loss: 1.156
[26,     3] loss: 1.156
[27,     3] loss: 1.170
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00011473834542044558,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4322647848623734,
 'loss_weight_S-palmitoylation-C': 0.805926808363956,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3919035649,
 'sample_weights': [0.7841708726277643, 0.3156681162394619],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.457288449655399,
 'weight_decay_Hydroxylation-K': 2.0253554847320805,
 'weight_decay_S-palmitoylation-C': 0.15478669928956257}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.392
[3,     3] loss: 1.393
[4,     3] loss: 1.385
[5,     3] loss: 1.392
[6,     3] loss: 1.384
[7,     3] loss: 1.384
[8,     3] loss: 1.383
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0002378858514259616,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.33017308711462773,
 'loss_weight_S-palmitoylation-C': 0.8587443766540367,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2395716766,
 'sample_weights': [0.805926808363956, 0.4322647848623734],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.8085983630976026,
 'weight_decay_Hydroxylation-K': 5.218355903917495,
 'weight_decay_S-palmitoylation-C': 1.56152433359743}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.391
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033293749086660703,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2518189323550115,
 'loss_weight_S-palmitoylation-C': 0.8563278656325843,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 775053777,
 'sample_weights': [0.8587443766540367, 0.33017308711462773],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.294389253520569,
 'weight_decay_Hydroxylation-K': 2.4728998589042974,
 'weight_decay_S-palmitoylation-C': 0.7523410490563264}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.380
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00031356062186350345,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2206441899284129,
 'loss_weight_S-palmitoylation-C': 0.8038530678570068,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3723484875,
 'sample_weights': [0.8563278656325843, 0.2518189323550115],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6837821743727173,
 'weight_decay_Hydroxylation-K': 2.395150391617953,
 'weight_decay_S-palmitoylation-C': 2.157006802748086}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.384
[3,     3] loss: 1.388
[4,     3] loss: 1.387
[5,     3] loss: 1.389
[6,     3] loss: 1.378
[7,     3] loss: 1.380
[8,     3] loss: 1.385
[9,     3] loss: 1.374
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016182624619010908,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.44974638478411005,
 'loss_weight_S-palmitoylation-C': 0.81260438935805,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1382666066,
 'sample_weights': [0.8038530678570068, 0.2206441899284129],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3131530380624428,
 'weight_decay_Hydroxylation-K': 5.371080795312322,
 'weight_decay_S-palmitoylation-C': 0.1679176815211676}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.389
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022570124413137478,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3291704013525924,
 'loss_weight_S-palmitoylation-C': 0.35202723648841355,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2502491968,
 'sample_weights': [0.81260438935805, 0.44974638478411005],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.8056317488050584,
 'weight_decay_Hydroxylation-K': 5.9117278116651,
 'weight_decay_S-palmitoylation-C': 2.426184886087955}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.389
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009674380477837566,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.43366796951607833,
 'loss_weight_S-palmitoylation-C': 0.5907836850365581,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2898643411,
 'sample_weights': [0.35202723648841355, 0.3291704013525924],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.719748231422342,
 'weight_decay_Hydroxylation-K': 0.887693146531755,
 'weight_decay_S-palmitoylation-C': 1.0602461234188365}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.396
[3,     3] loss: 1.392
[4,     3] loss: 1.390
[5,     3] loss: 1.392
[6,     3] loss: 1.383
[7,     3] loss: 1.390
[8,     3] loss: 1.389
[9,     3] loss: 1.387
[10,     3] loss: 1.386
[11,     3] loss: 1.384
[12,     3] loss: 1.393
[13,     3] loss: 1.385
[14,     3] loss: 1.382
[15,     3] loss: 1.381
[16,     3] loss: 1.388
[17,     3] loss: 1.392
[18,     3] loss: 1.386
[19,     3] loss: 1.389
[20,     3] loss: 1.390
[21,     3] loss: 1.388
[22,     3] loss: 1.387
[23,     3] loss: 1.385
[24,     3] loss: 1.383
[25,     3] loss: 1.366
[26,     3] loss: 1.356
[27,     3] loss: 1.324
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002819381472334964,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.10808861180808621,
 'loss_weight_S-palmitoylation-C': 0.7778454721731043,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2977963527,
 'sample_weights': [0.5907836850365581, 0.43366796951607833],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7404015719765367,
 'weight_decay_Hydroxylation-K': 4.986118043776384,
 'weight_decay_S-palmitoylation-C': 1.7889734614973603}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.388
[3,     3] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037313202348923354,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6082174562114504,
 'loss_weight_S-palmitoylation-C': 0.7432185691027741,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1387577944,
 'sample_weights': [0.7778454721731043, 0.10808861180808621],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.0954841704539993,
 'weight_decay_Hydroxylation-K': 9.062252802808352,
 'weight_decay_S-palmitoylation-C': 2.651671169318438}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.394
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007966746464393371,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3970336572739055,
 'loss_weight_S-palmitoylation-C': 0.45985946485148715,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2068078670,
 'sample_weights': [0.7432185691027741, 0.6082174562114504],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.060334830425031,
 'weight_decay_Hydroxylation-K': 0.5279159695034945,
 'weight_decay_S-palmitoylation-C': 2.232856499920217}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.388
[3,     3] loss: 1.405
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012400736582640593,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9925052958705765,
 'loss_weight_S-palmitoylation-C': 0.04882167693280698,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1295419604,
 'sample_weights': [0.45985946485148715, 0.3970336572739055],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.02901953908555,
 'weight_decay_Hydroxylation-K': 4.735982702437859,
 'weight_decay_S-palmitoylation-C': 6.816058454363265}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.372
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008615607275045148,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5248211138782128,
 'loss_weight_S-palmitoylation-C': 0.05722188514256085,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3002836617,
 'sample_weights': [0.04882167693280698, 0.9925052958705765],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.019563850512553,
 'weight_decay_Hydroxylation-K': 0.668638080446365,
 'weight_decay_S-palmitoylation-C': 4.063867292129377}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.389
[3,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00958028977982105,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.26784712509582376,
 'loss_weight_S-palmitoylation-C': 0.2567046069271455,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2719637991,
 'sample_weights': [0.05722188514256085, 0.5248211138782128],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.994434483093759,
 'weight_decay_Hydroxylation-K': 4.916117021242776,
 'weight_decay_S-palmitoylation-C': 1.3064957559557655}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.387
[3,     3] loss: 1.389
[4,     3] loss: 1.378
[5,     3] loss: 1.389
[6,     3] loss: 1.388
[7,     3] loss: 1.389
[8,     3] loss: 1.377
[9,     3] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009690662547129499,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.876451093580383,
 'loss_weight_S-palmitoylation-C': 0.2963924227370781,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3389931682,
 'sample_weights': [0.2567046069271455, 0.26784712509582376],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.149100518346192,
 'weight_decay_Hydroxylation-K': 0.7165655156423965,
 'weight_decay_S-palmitoylation-C': 9.815558186013007}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.389
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009522546155660243,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.10842955755401575,
 'loss_weight_S-palmitoylation-C': 0.9392174385157446,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2356270362,
 'sample_weights': [0.2963924227370781, 0.876451093580383],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.341589120807757,
 'weight_decay_Hydroxylation-K': 9.31826882387721,
 'weight_decay_S-palmitoylation-C': 9.190755293643862}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.384
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005274431838013238,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8905019283761968,
 'loss_weight_S-palmitoylation-C': 0.07254068449363509,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2598076555,
 'sample_weights': [0.9392174385157446, 0.10842955755401575],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.435001670973921,
 'weight_decay_Hydroxylation-K': 4.976578219652249,
 'weight_decay_S-palmitoylation-C': 3.2827280131770227}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.383
[3,     3] loss: 1.395
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005852135049904707,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.713374582487569,
 'loss_weight_S-palmitoylation-C': 0.4479906947593538,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 429181369,
 'sample_weights': [0.07254068449363509, 0.8905019283761968],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.543835903507896,
 'weight_decay_Hydroxylation-K': 1.1838196694900331,
 'weight_decay_S-palmitoylation-C': 4.14927776967569}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.382
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0036557223991405875,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7934142076865913,
 'loss_weight_S-palmitoylation-C': 0.009598918152007418,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 554587802,
 'sample_weights': [0.4479906947593538, 0.713374582487569],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.3983280177411945,
 'weight_decay_Hydroxylation-K': 3.4180305238366806,
 'weight_decay_S-palmitoylation-C': 5.403556742895809}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.381
[3,     3] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0034889638879080686,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3188630306566456,
 'loss_weight_S-palmitoylation-C': 0.7018516583262371,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2399345366,
 'sample_weights': [0.009598918152007418, 0.7934142076865913],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1164225795555605,
 'weight_decay_Hydroxylation-K': 3.9604749272406816,
 'weight_decay_S-palmitoylation-C': 0.17595697248787057}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.393
[3,     3] loss: 1.399
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007918888054609328,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.23994199910589986,
 'loss_weight_S-palmitoylation-C': 0.3015579501198035,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4255228907,
 'sample_weights': [0.7018516583262371, 0.3188630306566456],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.178020545531641,
 'weight_decay_Hydroxylation-K': 7.062233335070218,
 'weight_decay_S-palmitoylation-C': 2.07285262196274}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.389
[3,     3] loss: 1.404
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00646021860815334,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8943217540765521,
 'loss_weight_S-palmitoylation-C': 0.5164666766023084,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1032747375,
 'sample_weights': [0.3015579501198035, 0.23994199910589986],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.1497710332262456,
 'weight_decay_Hydroxylation-K': 9.239442150979876,
 'weight_decay_S-palmitoylation-C': 1.7083627780177078}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.392
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00719633312061671,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.261012425111578,
 'loss_weight_S-palmitoylation-C': 0.13785245404876334,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1567004028,
 'sample_weights': [0.5164666766023084, 0.8943217540765521],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.8935824555689,
 'weight_decay_Hydroxylation-K': 8.693249793247196,
 'weight_decay_S-palmitoylation-C': 5.86105952331685}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.386
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005553615819217653,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3742905494232095,
 'loss_weight_S-palmitoylation-C': 0.30541033784295474,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3595351631,
 'sample_weights': [0.13785245404876334, 0.261012425111578],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.708601298764211,
 'weight_decay_Hydroxylation-K': 7.819698700439384,
 'weight_decay_S-palmitoylation-C': 6.036322019866739}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.390
[3,     3] loss: 1.392
[4,     3] loss: 1.391
[5,     3] loss: 1.396
[6,     3] loss: 1.389
[7,     3] loss: 1.386
[8,     3] loss: 1.384
[9,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007976199436453925,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.29516536892895673,
 'loss_weight_S-palmitoylation-C': 0.9693780675806651,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1289161064,
 'sample_weights': [0.30541033784295474, 0.3742905494232095],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.851233754381969,
 'weight_decay_Hydroxylation-K': 8.102537955897953,
 'weight_decay_S-palmitoylation-C': 6.920121900960957}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.393
[3,     3] loss: 1.399
[4,     3] loss: 1.388
[5,     3] loss: 1.385
[6,     3] loss: 1.388
[7,     3] loss: 1.387
[8,     3] loss: 1.386
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019747884871851532,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.934185577620848,
 'loss_weight_S-palmitoylation-C': 0.2377624463460046,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 668267891,
 'sample_weights': [0.9693780675806651, 0.29516536892895673],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.98826271348174,
 'weight_decay_Hydroxylation-K': 4.178285788729341,
 'weight_decay_S-palmitoylation-C': 4.388912057378558}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.383
[3,     3] loss: 1.377
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002575697591540596,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.10483648013021962,
 'loss_weight_S-palmitoylation-C': 0.7450766276784828,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2245555823,
 'sample_weights': [0.2377624463460046, 0.934185577620848],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.261982320491859,
 'weight_decay_Hydroxylation-K': 0.15371722113138553,
 'weight_decay_S-palmitoylation-C': 7.37265079143065}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.392
[3,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006329265183817715,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.40778804181946415,
 'loss_weight_S-palmitoylation-C': 0.07627607583342325,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1302396590,
 'sample_weights': [0.7450766276784828, 0.10483648013021962],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.189508024314824,
 'weight_decay_Hydroxylation-K': 7.678435225511592,
 'weight_decay_S-palmitoylation-C': 0.014380268285431264}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.379
[2,     3] loss: 1.375
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005544405755851958,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5978145881055298,
 'loss_weight_S-palmitoylation-C': 0.9493241865038078,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 786076992,
 'sample_weights': [0.07627607583342325, 0.40778804181946415],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2819893837962795,
 'weight_decay_Hydroxylation-K': 1.391650506568554,
 'weight_decay_S-palmitoylation-C': 7.139020481084502}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.383
[4,     3] loss: 1.390
[5,     3] loss: 1.393
[6,     3] loss: 1.391
[7,     3] loss: 1.387
[8,     3] loss: 1.388
[9,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009405901325942395,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6262728217666615,
 'loss_weight_S-palmitoylation-C': 0.29547864257430767,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3581814518,
 'sample_weights': [0.9493241865038078, 0.5978145881055298],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.508226520896797,
 'weight_decay_Hydroxylation-K': 3.426799252696252,
 'weight_decay_S-palmitoylation-C': 9.045504691194054}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.378
[2,     3] loss: 1.386
[3,     3] loss: 1.387
[4,     3] loss: 1.380
[5,     3] loss: 1.385
[6,     3] loss: 1.364
[7,     3] loss: 1.379
[8,     3] loss: 1.392
[9,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009411140124958847,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3462538283805423,
 'loss_weight_S-palmitoylation-C': 0.52002354946614,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1879798423,
 'sample_weights': [0.29547864257430767, 0.6262728217666615],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.295218247801678,
 'weight_decay_Hydroxylation-K': 7.808575993452551,
 'weight_decay_S-palmitoylation-C': 7.438495320002385}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.400
[3,     3] loss: 1.377
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007140567691513425,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9615178404419077,
 'loss_weight_S-palmitoylation-C': 0.3581935212862202,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1025111913,
 'sample_weights': [0.52002354946614, 0.3462538283805423],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.5035363848901366,
 'weight_decay_Hydroxylation-K': 5.4280892403326115,
 'weight_decay_S-palmitoylation-C': 9.730600655084324}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.390
[3,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014626340448960233,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.29266436431255743,
 'loss_weight_S-palmitoylation-C': 0.49804077553007153,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3220199610,
 'sample_weights': [0.3581935212862202, 0.9615178404419077],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.229479292986793,
 'weight_decay_Hydroxylation-K': 8.17060722070629,
 'weight_decay_S-palmitoylation-C': 0.8516100167771146}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.385
[3,     3] loss: 1.375
[4,     3] loss: 1.383
[5,     3] loss: 1.377
[6,     3] loss: 1.357
[7,     3] loss: 1.358
[8,     3] loss: 1.336
[9,     3] loss: 1.352
[10,     3] loss: 1.298
[11,     3] loss: 1.312
[12,     3] loss: 1.260
[13,     3] loss: 1.248
[14,     3] loss: 1.208
[15,     3] loss: 1.209
[16,     3] loss: 1.104
[17,     3] loss: 1.210
[18,     3] loss: 1.125
[19,     3] loss: 1.114
[20,     3] loss: 1.153
[21,     3] loss: 1.111
[22,     3] loss: 1.053
[23,     3] loss: 0.978
[24,     3] loss: 1.034
[25,     3] loss: 1.047
[26,     3] loss: 0.984
[27,     3] loss: 1.073
[28,     3] loss: 1.027
[29,     3] loss: 0.978
[30,     3] loss: 1.067
[31,     3] loss: 1.001
[32,     3] loss: 1.061
[33,     3] loss: 0.960
[34,     3] loss: 0.910
[35,     3] loss: 0.997
[36,     3] loss: 0.973
[37,     3] loss: 0.917
[38,     3] loss: 1.027
[39,     3] loss: 1.005
[40,     3] loss: 0.947
[41,     3] loss: 0.889
[42,     3] loss: 0.901
[43,     3] loss: 0.985
[44,     3] loss: 0.881
[45,     3] loss: 0.927
[46,     3] loss: 0.958
[47,     3] loss: 0.870
[48,     3] loss: 0.829
[49,     3] loss: 0.893
[50,     3] loss: 0.902
[51,     3] loss: 0.904
[52,     3] loss: 0.891
[53,     3] loss: 0.890
[54,     3] loss: 0.802
[55,     3] loss: 0.831
[56,     3] loss: 0.840
[57,     3] loss: 0.826
[58,     3] loss: 0.906
[59,     3] loss: 0.910
[60,     3] loss: 0.842
[61,     3] loss: 0.903
[62,     3] loss: 0.817
[63,     3] loss: 0.800
Early stopping applied (best metric=0.5112437009811401)
Finished Training
Total time taken: 18.976089477539062
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.387
[3,     3] loss: 1.384
[4,     3] loss: 1.380
[5,     3] loss: 1.380
[6,     3] loss: 1.398
[7,     3] loss: 1.389
[8,     3] loss: 1.384
[9,     3] loss: 1.386
[10,     3] loss: 1.391
[11,     3] loss: 1.388
[12,     3] loss: 1.382
[13,     3] loss: 1.375
[14,     3] loss: 1.380
[15,     3] loss: 1.376
[16,     3] loss: 1.367
[17,     3] loss: 1.359
[18,     3] loss: 1.332
[19,     3] loss: 1.334
[20,     3] loss: 1.305
[21,     3] loss: 1.247
[22,     3] loss: 1.294
[23,     3] loss: 1.254
[24,     3] loss: 1.190
[25,     3] loss: 1.181
[26,     3] loss: 1.198
[27,     3] loss: 1.031
[28,     3] loss: 1.130
[29,     3] loss: 1.092
[30,     3] loss: 1.036
[31,     3] loss: 1.045
[32,     3] loss: 0.990
[33,     3] loss: 0.942
[34,     3] loss: 0.895
[35,     3] loss: 0.904
[36,     3] loss: 0.896
[37,     3] loss: 1.068
[38,     3] loss: 0.932
[39,     3] loss: 0.956
[40,     3] loss: 0.973
[41,     3] loss: 0.935
[42,     3] loss: 1.030
[43,     3] loss: 0.930
[44,     3] loss: 0.913
[45,     3] loss: 0.944
[46,     3] loss: 0.933
[47,     3] loss: 0.896
[48,     3] loss: 0.911
[49,     3] loss: 0.928
[50,     3] loss: 0.902
[51,     3] loss: 0.885
[52,     3] loss: 0.968
[53,     3] loss: 0.851
[54,     3] loss: 0.862
[55,     3] loss: 0.950
[56,     3] loss: 0.888
[57,     3] loss: 0.856
[58,     3] loss: 0.881
[59,     3] loss: 0.848
[60,     3] loss: 0.850
[61,     3] loss: 0.881
[62,     3] loss: 0.911
[63,     3] loss: 0.952
[64,     3] loss: 0.899
[65,     3] loss: 0.933
[66,     3] loss: 0.968
[67,     3] loss: 0.901
[68,     3] loss: 0.909
[69,     3] loss: 0.883
[70,     3] loss: 0.892
[71,     3] loss: 0.948
[72,     3] loss: 0.866
[73,     3] loss: 0.807
[74,     3] loss: 0.844
[75,     3] loss: 0.837
[76,     3] loss: 0.854
[77,     3] loss: 0.814
[78,     3] loss: 0.804
[79,     3] loss: 0.942
[80,     3] loss: 0.877
[81,     3] loss: 0.830
[82,     3] loss: 0.809
[83,     3] loss: 0.797
[84,     3] loss: 0.782
[85,     3] loss: 0.818
[86,     3] loss: 0.797
Early stopping applied (best metric=0.4976615607738495)
Finished Training
Total time taken: 25.518123865127563
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.388
[3,     3] loss: 1.386
[4,     3] loss: 1.381
[5,     3] loss: 1.379
[6,     3] loss: 1.392
[7,     3] loss: 1.385
[8,     3] loss: 1.386
[9,     3] loss: 1.390
[10,     3] loss: 1.387
[11,     3] loss: 1.375
[12,     3] loss: 1.385
[13,     3] loss: 1.378
[14,     3] loss: 1.374
[15,     3] loss: 1.363
[16,     3] loss: 1.353
[17,     3] loss: 1.322
[18,     3] loss: 1.295
[19,     3] loss: 1.243
[20,     3] loss: 1.240
[21,     3] loss: 1.159
[22,     3] loss: 1.180
[23,     3] loss: 1.253
[24,     3] loss: 1.126
[25,     3] loss: 1.466
[26,     3] loss: 1.126
[27,     3] loss: 1.316
[28,     3] loss: 1.294
[29,     3] loss: 1.188
[30,     3] loss: 1.165
[31,     3] loss: 1.135
[32,     3] loss: 1.181
[33,     3] loss: 1.124
[34,     3] loss: 1.084
[35,     3] loss: 1.038
[36,     3] loss: 1.116
[37,     3] loss: 0.977
[38,     3] loss: 1.060
[39,     3] loss: 1.027
[40,     3] loss: 0.961
[41,     3] loss: 0.961
[42,     3] loss: 0.960
[43,     3] loss: 0.964
[44,     3] loss: 0.933
[45,     3] loss: 0.939
[46,     3] loss: 1.005
[47,     3] loss: 0.924
[48,     3] loss: 0.928
[49,     3] loss: 0.894
[50,     3] loss: 0.852
[51,     3] loss: 0.833
[52,     3] loss: 0.853
[53,     3] loss: 0.836
[54,     3] loss: 0.841
[55,     3] loss: 0.885
[56,     3] loss: 0.850
[57,     3] loss: 0.823
[58,     3] loss: 0.810
[59,     3] loss: 0.794
[60,     3] loss: 0.873
[61,     3] loss: 0.807
[62,     3] loss: 0.871
[63,     3] loss: 0.917
[64,     3] loss: 1.121
[65,     3] loss: 0.890
[66,     3] loss: 0.899
[67,     3] loss: 1.101
[68,     3] loss: 0.947
[69,     3] loss: 0.897
[70,     3] loss: 0.870
[71,     3] loss: 0.855
[72,     3] loss: 0.875
[73,     3] loss: 0.838
[74,     3] loss: 0.827
[75,     3] loss: 0.831
[76,     3] loss: 0.878
[77,     3] loss: 0.846
[78,     3] loss: 0.872
[79,     3] loss: 0.913
[80,     3] loss: 0.861
[81,     3] loss: 0.862
[82,     3] loss: 0.827
[83,     3] loss: 0.824
[84,     3] loss: 0.790
[85,     3] loss: 0.795
[86,     3] loss: 0.788
[87,     3] loss: 0.795
[88,     3] loss: 0.797
[89,     3] loss: 0.777
[90,     3] loss: 0.771
[91,     3] loss: 0.767
[92,     3] loss: 0.780
[93,     3] loss: 0.807
[94,     3] loss: 0.800
[95,     3] loss: 0.789
[96,     3] loss: 0.867
[97,     3] loss: 0.797
[98,     3] loss: 0.828
[99,     3] loss: 0.817
[100,     3] loss: 0.825
[101,     3] loss: 0.884
[102,     3] loss: 0.817
[103,     3] loss: 0.830
[104,     3] loss: 0.884
[105,     3] loss: 0.804
[106,     3] loss: 0.815
[107,     3] loss: 0.791
[108,     3] loss: 0.841
[109,     3] loss: 0.842
[110,     3] loss: 0.913
[111,     3] loss: 0.862
[112,     3] loss: 0.813
[113,     3] loss: 0.791
[114,     3] loss: 0.793
[115,     3] loss: 0.790
[116,     3] loss: 0.814
[117,     3] loss: 0.772
[118,     3] loss: 0.779
[119,     3] loss: 0.777
[120,     3] loss: 0.773
[121,     3] loss: 0.814
[122,     3] loss: 0.789
[123,     3] loss: 0.771
[124,     3] loss: 0.814
[125,     3] loss: 0.801
[126,     3] loss: 0.783
[127,     3] loss: 0.782
[128,     3] loss: 0.781
[129,     3] loss: 0.753
[130,     3] loss: 0.751
Early stopping applied (best metric=0.5437833666801453)
Finished Training
Total time taken: 38.51718544960022
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.387
[3,     3] loss: 1.391
[4,     3] loss: 1.387
[5,     3] loss: 1.384
[6,     3] loss: 1.390
[7,     3] loss: 1.389
[8,     3] loss: 1.389
[9,     3] loss: 1.385
[10,     3] loss: 1.382
[11,     3] loss: 1.381
[12,     3] loss: 1.388
[13,     3] loss: 1.380
[14,     3] loss: 1.377
[15,     3] loss: 1.374
[16,     3] loss: 1.360
[17,     3] loss: 1.341
[18,     3] loss: 1.345
[19,     3] loss: 1.334
[20,     3] loss: 1.259
[21,     3] loss: 1.255
[22,     3] loss: 1.200
[23,     3] loss: 1.220
[24,     3] loss: 1.126
[25,     3] loss: 1.206
[26,     3] loss: 1.133
[27,     3] loss: 1.039
[28,     3] loss: 1.028
[29,     3] loss: 0.944
[30,     3] loss: 1.083
[31,     3] loss: 0.924
[32,     3] loss: 1.170
[33,     3] loss: 1.129
[34,     3] loss: 1.053
[35,     3] loss: 0.985
[36,     3] loss: 1.060
[37,     3] loss: 0.925
[38,     3] loss: 1.011
[39,     3] loss: 0.936
[40,     3] loss: 0.922
[41,     3] loss: 1.034
[42,     3] loss: 0.910
[43,     3] loss: 0.931
[44,     3] loss: 0.876
[45,     3] loss: 0.962
[46,     3] loss: 0.855
[47,     3] loss: 0.869
[48,     3] loss: 1.014
[49,     3] loss: 0.891
[50,     3] loss: 0.878
[51,     3] loss: 0.993
[52,     3] loss: 1.016
[53,     3] loss: 0.904
[54,     3] loss: 0.965
[55,     3] loss: 0.982
[56,     3] loss: 0.928
[57,     3] loss: 0.848
[58,     3] loss: 0.951
[59,     3] loss: 0.928
[60,     3] loss: 0.853
[61,     3] loss: 0.862
[62,     3] loss: 0.836
[63,     3] loss: 0.884
[64,     3] loss: 0.871
[65,     3] loss: 0.809
[66,     3] loss: 0.821
[67,     3] loss: 0.825
[68,     3] loss: 0.851
[69,     3] loss: 0.846
[70,     3] loss: 0.890
[71,     3] loss: 0.782
[72,     3] loss: 0.855
[73,     3] loss: 0.817
[74,     3] loss: 0.804
[75,     3] loss: 0.859
Early stopping applied (best metric=0.5141420960426331)
Finished Training
Total time taken: 21.33310031890869
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.385
[3,     3] loss: 1.385
[4,     3] loss: 1.387
[5,     3] loss: 1.394
[6,     3] loss: 1.389
[7,     3] loss: 1.385
[8,     3] loss: 1.381
[9,     3] loss: 1.381
[10,     3] loss: 1.383
[11,     3] loss: 1.377
[12,     3] loss: 1.376
[13,     3] loss: 1.352
[14,     3] loss: 1.336
[15,     3] loss: 1.324
[16,     3] loss: 1.291
[17,     3] loss: 1.285
[18,     3] loss: 1.219
[19,     3] loss: 1.211
[20,     3] loss: 1.142
[21,     3] loss: 1.114
[22,     3] loss: 1.038
[23,     3] loss: 1.166
[24,     3] loss: 1.080
[25,     3] loss: 1.083
[26,     3] loss: 1.059
[27,     3] loss: 1.065
[28,     3] loss: 1.083
[29,     3] loss: 1.089
[30,     3] loss: 1.162
[31,     3] loss: 1.015
[32,     3] loss: 1.023
[33,     3] loss: 1.089
[34,     3] loss: 1.087
[35,     3] loss: 1.061
[36,     3] loss: 0.986
[37,     3] loss: 0.957
[38,     3] loss: 0.938
[39,     3] loss: 1.020
[40,     3] loss: 0.960
[41,     3] loss: 0.962
[42,     3] loss: 0.954
[43,     3] loss: 0.938
[44,     3] loss: 0.861
[45,     3] loss: 0.898
[46,     3] loss: 0.938
[47,     3] loss: 0.913
[48,     3] loss: 0.938
[49,     3] loss: 0.854
[50,     3] loss: 0.872
[51,     3] loss: 0.865
[52,     3] loss: 0.887
[53,     3] loss: 0.912
[54,     3] loss: 0.841
[55,     3] loss: 0.833
[56,     3] loss: 0.878
[57,     3] loss: 0.924
[58,     3] loss: 0.858
[59,     3] loss: 0.890
[60,     3] loss: 0.836
[61,     3] loss: 0.836
[62,     3] loss: 0.851
[63,     3] loss: 0.812
[64,     3] loss: 0.785
[65,     3] loss: 0.823
[66,     3] loss: 0.801
[67,     3] loss: 0.793
[68,     3] loss: 0.791
Early stopping applied (best metric=0.4827073812484741)
Finished Training
Total time taken: 19.971096992492676
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.403
[2,     3] loss: 1.388
[3,     3] loss: 1.386
[4,     3] loss: 1.389
[5,     3] loss: 1.390
[6,     3] loss: 1.382
[7,     3] loss: 1.387
[8,     3] loss: 1.386
[9,     3] loss: 1.386
[10,     3] loss: 1.389
[11,     3] loss: 1.386
[12,     3] loss: 1.382
[13,     3] loss: 1.386
[14,     3] loss: 1.383
[15,     3] loss: 1.384
[16,     3] loss: 1.381
[17,     3] loss: 1.377
[18,     3] loss: 1.372
[19,     3] loss: 1.357
[20,     3] loss: 1.357
[21,     3] loss: 1.335
[22,     3] loss: 1.309
[23,     3] loss: 1.279
[24,     3] loss: 1.298
[25,     3] loss: 1.231
[26,     3] loss: 1.216
[27,     3] loss: 1.216
[28,     3] loss: 1.099
[29,     3] loss: 1.113
[30,     3] loss: 1.124
[31,     3] loss: 1.030
[32,     3] loss: 1.018
[33,     3] loss: 0.969
[34,     3] loss: 0.967
[35,     3] loss: 0.993
[36,     3] loss: 1.029
[37,     3] loss: 1.013
[38,     3] loss: 1.049
[39,     3] loss: 1.058
[40,     3] loss: 1.099
[41,     3] loss: 0.993
[42,     3] loss: 0.981
[43,     3] loss: 0.967
[44,     3] loss: 0.965
[45,     3] loss: 0.932
[46,     3] loss: 0.922
[47,     3] loss: 0.954
[48,     3] loss: 0.856
[49,     3] loss: 0.908
[50,     3] loss: 0.954
[51,     3] loss: 0.895
[52,     3] loss: 0.873
[53,     3] loss: 0.859
[54,     3] loss: 0.955
[55,     3] loss: 0.797
[56,     3] loss: 0.870
[57,     3] loss: 0.866
[58,     3] loss: 0.923
[59,     3] loss: 0.832
[60,     3] loss: 0.874
[61,     3] loss: 0.851
[62,     3] loss: 0.851
[63,     3] loss: 0.869
[64,     3] loss: 0.829
[65,     3] loss: 0.859
[66,     3] loss: 0.875
[67,     3] loss: 0.900
[68,     3] loss: 0.891
[69,     3] loss: 0.926
[70,     3] loss: 0.881
[71,     3] loss: 0.834
[72,     3] loss: 0.838
[73,     3] loss: 0.817
[74,     3] loss: 0.821
[75,     3] loss: 0.829
[76,     3] loss: 0.842
[77,     3] loss: 0.825
[78,     3] loss: 0.919
[79,     3] loss: 0.877
[80,     3] loss: 0.831
[81,     3] loss: 0.899
[82,     3] loss: 0.834
[83,     3] loss: 0.803
[84,     3] loss: 0.825
[85,     3] loss: 0.800
[86,     3] loss: 0.800
[87,     3] loss: 0.803
[88,     3] loss: 0.769
[89,     3] loss: 0.754
[90,     3] loss: 0.770
[91,     3] loss: 0.780
[92,     3] loss: 0.768
[93,     3] loss: 0.751
[94,     3] loss: 0.775
[95,     3] loss: 0.769
[96,     3] loss: 0.767
[97,     3] loss: 0.797
[98,     3] loss: 0.790
[99,     3] loss: 0.758
[100,     3] loss: 0.755
[101,     3] loss: 0.758
[102,     3] loss: 0.762
[103,     3] loss: 0.760
[104,     3] loss: 0.771
[105,     3] loss: 0.746
[106,     3] loss: 0.741
[107,     3] loss: 0.750
[108,     3] loss: 0.750
Early stopping applied (best metric=0.4855184257030487)
Finished Training
Total time taken: 31.317172527313232
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.387
[4,     3] loss: 1.386
[5,     3] loss: 1.387
[6,     3] loss: 1.382
[7,     3] loss: 1.388
[8,     3] loss: 1.387
[9,     3] loss: 1.384
[10,     3] loss: 1.369
[11,     3] loss: 1.383
[12,     3] loss: 1.370
[13,     3] loss: 1.371
[14,     3] loss: 1.355
[15,     3] loss: 1.349
[16,     3] loss: 1.312
[17,     3] loss: 1.345
[18,     3] loss: 1.292
[19,     3] loss: 1.370
[20,     3] loss: 1.261
[21,     3] loss: 1.288
[22,     3] loss: 1.228
[23,     3] loss: 1.257
[24,     3] loss: 1.218
[25,     3] loss: 1.160
[26,     3] loss: 1.221
[27,     3] loss: 1.118
[28,     3] loss: 1.067
[29,     3] loss: 1.061
[30,     3] loss: 0.981
[31,     3] loss: 1.119
[32,     3] loss: 0.946
[33,     3] loss: 0.979
[34,     3] loss: 0.952
[35,     3] loss: 1.027
[36,     3] loss: 0.992
[37,     3] loss: 0.987
[38,     3] loss: 0.959
[39,     3] loss: 1.011
[40,     3] loss: 0.912
[41,     3] loss: 0.909
[42,     3] loss: 0.897
[43,     3] loss: 0.898
[44,     3] loss: 0.948
[45,     3] loss: 0.851
[46,     3] loss: 0.863
[47,     3] loss: 0.822
[48,     3] loss: 0.831
[49,     3] loss: 0.793
[50,     3] loss: 0.813
[51,     3] loss: 0.820
[52,     3] loss: 0.885
[53,     3] loss: 0.888
[54,     3] loss: 0.840
[55,     3] loss: 0.812
[56,     3] loss: 0.869
[57,     3] loss: 0.862
[58,     3] loss: 0.866
[59,     3] loss: 0.855
[60,     3] loss: 0.823
[61,     3] loss: 0.869
[62,     3] loss: 0.988
[63,     3] loss: 0.814
[64,     3] loss: 0.899
[65,     3] loss: 0.940
[66,     3] loss: 0.979
[67,     3] loss: 0.882
[68,     3] loss: 0.923
[69,     3] loss: 0.833
[70,     3] loss: 0.831
[71,     3] loss: 0.817
[72,     3] loss: 0.810
[73,     3] loss: 0.853
[74,     3] loss: 0.819
Early stopping applied (best metric=0.4981536865234375)
Finished Training
Total time taken: 21.86310338973999
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.393
[3,     3] loss: 1.384
[4,     3] loss: 1.383
[5,     3] loss: 1.382
[6,     3] loss: 1.384
[7,     3] loss: 1.382
[8,     3] loss: 1.374
[9,     3] loss: 1.376
[10,     3] loss: 1.374
[11,     3] loss: 1.348
[12,     3] loss: 1.337
[13,     3] loss: 1.298
[14,     3] loss: 1.288
[15,     3] loss: 1.262
[16,     3] loss: 1.203
[17,     3] loss: 1.200
[18,     3] loss: 1.072
[19,     3] loss: 1.118
[20,     3] loss: 1.021
[21,     3] loss: 1.033
[22,     3] loss: 1.046
[23,     3] loss: 1.103
[24,     3] loss: 0.982
[25,     3] loss: 0.971
[26,     3] loss: 1.020
[27,     3] loss: 0.929
[28,     3] loss: 1.011
[29,     3] loss: 0.907
[30,     3] loss: 0.960
[31,     3] loss: 0.983
[32,     3] loss: 0.953
[33,     3] loss: 0.879
[34,     3] loss: 0.979
[35,     3] loss: 0.945
[36,     3] loss: 0.937
[37,     3] loss: 0.891
[38,     3] loss: 0.926
[39,     3] loss: 0.863
[40,     3] loss: 0.849
[41,     3] loss: 0.830
[42,     3] loss: 0.794
[43,     3] loss: 0.796
[44,     3] loss: 0.791
[45,     3] loss: 0.781
[46,     3] loss: 0.803
[47,     3] loss: 0.833
[48,     3] loss: 0.793
[49,     3] loss: 0.795
[50,     3] loss: 0.843
[51,     3] loss: 0.877
[52,     3] loss: 0.828
[53,     3] loss: 0.854
[54,     3] loss: 0.882
[55,     3] loss: 0.922
[56,     3] loss: 0.795
[57,     3] loss: 0.827
[58,     3] loss: 0.828
[59,     3] loss: 0.792
[60,     3] loss: 0.795
[61,     3] loss: 0.858
[62,     3] loss: 0.815
[63,     3] loss: 0.803
[64,     3] loss: 0.858
[65,     3] loss: 0.831
[66,     3] loss: 0.819
[67,     3] loss: 0.818
[68,     3] loss: 0.857
[69,     3] loss: 0.820
[70,     3] loss: 0.823
[71,     3] loss: 0.838
[72,     3] loss: 0.783
[73,     3] loss: 0.841
[74,     3] loss: 0.778
[75,     3] loss: 0.830
[76,     3] loss: 0.819
[77,     3] loss: 0.783
[78,     3] loss: 0.778
Early stopping applied (best metric=0.5352638959884644)
Finished Training
Total time taken: 22.89911150932312
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.377
[3,     3] loss: 1.388
[4,     3] loss: 1.379
[5,     3] loss: 1.380
[6,     3] loss: 1.378
[7,     3] loss: 1.379
[8,     3] loss: 1.352
[9,     3] loss: 1.343
[10,     3] loss: 1.313
[11,     3] loss: 1.267
[12,     3] loss: 1.235
[13,     3] loss: 1.340
[14,     3] loss: 1.240
[15,     3] loss: 1.167
[16,     3] loss: 1.165
[17,     3] loss: 1.096
[18,     3] loss: 1.104
[19,     3] loss: 1.008
[20,     3] loss: 1.014
[21,     3] loss: 0.963
[22,     3] loss: 0.923
[23,     3] loss: 0.941
[24,     3] loss: 0.922
[25,     3] loss: 1.028
[26,     3] loss: 0.930
[27,     3] loss: 0.860
[28,     3] loss: 0.951
[29,     3] loss: 0.972
[30,     3] loss: 1.023
[31,     3] loss: 0.893
[32,     3] loss: 0.917
[33,     3] loss: 0.910
[34,     3] loss: 0.888
[35,     3] loss: 0.880
[36,     3] loss: 0.880
[37,     3] loss: 0.862
[38,     3] loss: 0.899
[39,     3] loss: 0.871
[40,     3] loss: 0.858
[41,     3] loss: 0.838
[42,     3] loss: 0.867
[43,     3] loss: 0.867
[44,     3] loss: 0.804
[45,     3] loss: 0.831
[46,     3] loss: 0.850
[47,     3] loss: 0.909
[48,     3] loss: 0.867
[49,     3] loss: 0.872
[50,     3] loss: 0.930
[51,     3] loss: 0.876
[52,     3] loss: 0.849
[53,     3] loss: 0.794
[54,     3] loss: 0.826
[55,     3] loss: 0.864
[56,     3] loss: 0.807
[57,     3] loss: 0.830
[58,     3] loss: 0.859
[59,     3] loss: 0.834
[60,     3] loss: 0.831
[61,     3] loss: 0.845
[62,     3] loss: 0.817
[63,     3] loss: 0.794
Early stopping applied (best metric=0.4960848391056061)
Finished Training
Total time taken: 18.80110216140747
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.389
[3,     3] loss: 1.371
[4,     3] loss: 1.406
[5,     3] loss: 1.402
[6,     3] loss: 1.384
[7,     3] loss: 1.388
[8,     3] loss: 1.379
[9,     3] loss: 1.377
[10,     3] loss: 1.388
[11,     3] loss: 1.388
[12,     3] loss: 1.378
[13,     3] loss: 1.370
[14,     3] loss: 1.370
[15,     3] loss: 1.368
[16,     3] loss: 1.354
[17,     3] loss: 1.318
[18,     3] loss: 1.323
[19,     3] loss: 1.292
[20,     3] loss: 1.198
[21,     3] loss: 1.226
[22,     3] loss: 1.154
[23,     3] loss: 1.103
[24,     3] loss: 1.068
[25,     3] loss: 1.014
[26,     3] loss: 1.091
[27,     3] loss: 1.198
[28,     3] loss: 1.183
[29,     3] loss: 1.111
[30,     3] loss: 1.130
[31,     3] loss: 1.053
[32,     3] loss: 1.076
[33,     3] loss: 1.002
[34,     3] loss: 1.003
[35,     3] loss: 1.064
[36,     3] loss: 0.969
[37,     3] loss: 0.979
[38,     3] loss: 1.017
[39,     3] loss: 0.982
[40,     3] loss: 1.004
[41,     3] loss: 0.952
[42,     3] loss: 0.953
[43,     3] loss: 0.967
[44,     3] loss: 0.876
[45,     3] loss: 0.912
[46,     3] loss: 0.900
[47,     3] loss: 0.869
[48,     3] loss: 0.910
[49,     3] loss: 0.943
[50,     3] loss: 0.887
[51,     3] loss: 0.904
[52,     3] loss: 0.933
[53,     3] loss: 0.886
[54,     3] loss: 0.938
[55,     3] loss: 0.896
[56,     3] loss: 0.874
[57,     3] loss: 0.857
[58,     3] loss: 0.848
[59,     3] loss: 0.856
[60,     3] loss: 0.995
[61,     3] loss: 0.823
[62,     3] loss: 0.872
[63,     3] loss: 0.870
[64,     3] loss: 0.912
[65,     3] loss: 0.921
[66,     3] loss: 0.941
[67,     3] loss: 0.847
[68,     3] loss: 0.919
[69,     3] loss: 0.903
[70,     3] loss: 0.815
[71,     3] loss: 0.900
Early stopping applied (best metric=0.47520527243614197)
Finished Training
Total time taken: 20.810102701187134
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.391
[3,     3] loss: 1.382
[4,     3] loss: 1.374
[5,     3] loss: 1.369
[6,     3] loss: 1.375
[7,     3] loss: 1.373
[8,     3] loss: 1.367
[9,     3] loss: 1.358
[10,     3] loss: 1.346
[11,     3] loss: 1.316
[12,     3] loss: 1.276
[13,     3] loss: 1.339
[14,     3] loss: 1.284
[15,     3] loss: 1.297
[16,     3] loss: 1.231
[17,     3] loss: 1.195
[18,     3] loss: 1.215
[19,     3] loss: 1.172
[20,     3] loss: 1.176
[21,     3] loss: 1.268
[22,     3] loss: 1.137
[23,     3] loss: 1.073
[24,     3] loss: 1.040
[25,     3] loss: 1.153
[26,     3] loss: 0.993
[27,     3] loss: 1.155
[28,     3] loss: 1.071
[29,     3] loss: 1.064
[30,     3] loss: 1.070
[31,     3] loss: 1.086
[32,     3] loss: 0.994
[33,     3] loss: 0.976
[34,     3] loss: 0.946
[35,     3] loss: 1.010
[36,     3] loss: 0.973
[37,     3] loss: 0.953
[38,     3] loss: 0.872
[39,     3] loss: 0.960
[40,     3] loss: 0.907
[41,     3] loss: 0.876
[42,     3] loss: 0.869
[43,     3] loss: 0.913
[44,     3] loss: 0.852
[45,     3] loss: 0.898
[46,     3] loss: 0.921
[47,     3] loss: 0.878
[48,     3] loss: 0.930
[49,     3] loss: 0.945
[50,     3] loss: 0.915
[51,     3] loss: 0.970
[52,     3] loss: 0.833
[53,     3] loss: 0.854
[54,     3] loss: 0.954
[55,     3] loss: 0.947
[56,     3] loss: 0.922
[57,     3] loss: 0.991
[58,     3] loss: 0.934
[59,     3] loss: 0.878
[60,     3] loss: 0.877
[61,     3] loss: 0.879
[62,     3] loss: 0.864
[63,     3] loss: 0.813
[64,     3] loss: 0.834
[65,     3] loss: 0.811
[66,     3] loss: 0.850
[67,     3] loss: 0.811
[68,     3] loss: 0.795
[69,     3] loss: 0.838
[70,     3] loss: 0.778
[71,     3] loss: 0.778
[72,     3] loss: 0.785
[73,     3] loss: 0.761
Early stopping applied (best metric=0.510077178478241)
Finished Training
Total time taken: 21.502102375030518
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.384
[3,     3] loss: 1.392
[4,     3] loss: 1.381
[5,     3] loss: 1.386
[6,     3] loss: 1.380
[7,     3] loss: 1.373
[8,     3] loss: 1.355
[9,     3] loss: 1.368
[10,     3] loss: 1.351
[11,     3] loss: 1.318
[12,     3] loss: 1.304
[13,     3] loss: 1.251
[14,     3] loss: 1.231
[15,     3] loss: 1.156
[16,     3] loss: 1.142
[17,     3] loss: 1.193
[18,     3] loss: 1.100
[19,     3] loss: 1.127
[20,     3] loss: 1.095
[21,     3] loss: 1.138
[22,     3] loss: 1.045
[23,     3] loss: 1.045
[24,     3] loss: 1.089
[25,     3] loss: 1.031
[26,     3] loss: 1.028
[27,     3] loss: 1.091
[28,     3] loss: 0.957
[29,     3] loss: 1.012
[30,     3] loss: 1.134
[31,     3] loss: 0.991
[32,     3] loss: 0.993
[33,     3] loss: 1.021
[34,     3] loss: 0.970
[35,     3] loss: 0.952
[36,     3] loss: 0.878
[37,     3] loss: 0.914
[38,     3] loss: 0.930
[39,     3] loss: 0.889
[40,     3] loss: 0.844
[41,     3] loss: 0.863
[42,     3] loss: 0.896
[43,     3] loss: 0.892
[44,     3] loss: 0.923
[45,     3] loss: 0.903
[46,     3] loss: 0.951
[47,     3] loss: 0.961
[48,     3] loss: 0.869
[49,     3] loss: 0.920
[50,     3] loss: 0.840
[51,     3] loss: 0.922
[52,     3] loss: 0.921
[53,     3] loss: 0.859
[54,     3] loss: 0.884
[55,     3] loss: 0.867
[56,     3] loss: 0.826
[57,     3] loss: 0.812
[58,     3] loss: 0.837
[59,     3] loss: 0.826
[60,     3] loss: 0.844
[61,     3] loss: 0.853
[62,     3] loss: 0.936
[63,     3] loss: 0.866
[64,     3] loss: 0.860
[65,     3] loss: 0.901
[66,     3] loss: 0.832
[67,     3] loss: 0.813
[68,     3] loss: 0.827
[69,     3] loss: 0.848
[70,     3] loss: 0.837
[71,     3] loss: 0.903
[72,     3] loss: 0.969
[73,     3] loss: 0.948
[74,     3] loss: 0.839
[75,     3] loss: 0.834
[76,     3] loss: 0.863
[77,     3] loss: 0.847
[78,     3] loss: 0.829
[79,     3] loss: 0.806
[80,     3] loss: 0.857
Early stopping applied (best metric=0.5298863649368286)
Finished Training
Total time taken: 23.66211700439453
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.388
[3,     3] loss: 1.387
[4,     3] loss: 1.384
[5,     3] loss: 1.390
[6,     3] loss: 1.381
[7,     3] loss: 1.379
[8,     3] loss: 1.388
[9,     3] loss: 1.386
[10,     3] loss: 1.390
[11,     3] loss: 1.379
[12,     3] loss: 1.381
[13,     3] loss: 1.372
[14,     3] loss: 1.378
[15,     3] loss: 1.378
[16,     3] loss: 1.364
[17,     3] loss: 1.337
[18,     3] loss: 1.347
[19,     3] loss: 1.341
[20,     3] loss: 1.311
[21,     3] loss: 1.283
[22,     3] loss: 1.256
[23,     3] loss: 1.175
[24,     3] loss: 1.158
[25,     3] loss: 1.180
[26,     3] loss: 1.282
[27,     3] loss: 1.249
[28,     3] loss: 1.059
[29,     3] loss: 1.096
[30,     3] loss: 1.089
[31,     3] loss: 1.028
[32,     3] loss: 1.015
[33,     3] loss: 1.017
[34,     3] loss: 0.957
[35,     3] loss: 0.961
[36,     3] loss: 1.157
[37,     3] loss: 1.042
[38,     3] loss: 1.086
[39,     3] loss: 1.007
[40,     3] loss: 0.958
[41,     3] loss: 0.985
[42,     3] loss: 0.972
[43,     3] loss: 1.020
[44,     3] loss: 0.911
[45,     3] loss: 0.897
[46,     3] loss: 0.874
[47,     3] loss: 0.869
[48,     3] loss: 0.818
[49,     3] loss: 0.859
[50,     3] loss: 0.913
[51,     3] loss: 0.896
[52,     3] loss: 0.879
[53,     3] loss: 0.881
[54,     3] loss: 0.875
[55,     3] loss: 0.829
[56,     3] loss: 0.957
[57,     3] loss: 0.879
[58,     3] loss: 0.871
[59,     3] loss: 0.951
[60,     3] loss: 0.832
[61,     3] loss: 0.864
[62,     3] loss: 0.868
[63,     3] loss: 0.869
[64,     3] loss: 0.869
[65,     3] loss: 0.894
[66,     3] loss: 0.851
[67,     3] loss: 0.857
[68,     3] loss: 0.924
[69,     3] loss: 0.820
[70,     3] loss: 0.865
[71,     3] loss: 0.915
[72,     3] loss: 0.853
[73,     3] loss: 1.049
[74,     3] loss: 0.964
[75,     3] loss: 0.930
[76,     3] loss: 0.869
[77,     3] loss: 0.883
Early stopping applied (best metric=0.49944067001342773)
Finished Training
Total time taken: 23.242114067077637
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.380
[3,     3] loss: 1.379
[4,     3] loss: 1.397
[5,     3] loss: 1.389
[6,     3] loss: 1.379
[7,     3] loss: 1.390
[8,     3] loss: 1.385
[9,     3] loss: 1.383
[10,     3] loss: 1.384
[11,     3] loss: 1.378
[12,     3] loss: 1.377
[13,     3] loss: 1.362
[14,     3] loss: 1.348
[15,     3] loss: 1.323
[16,     3] loss: 1.329
[17,     3] loss: 1.261
[18,     3] loss: 1.237
[19,     3] loss: 1.153
[20,     3] loss: 1.078
[21,     3] loss: 1.150
[22,     3] loss: 1.083
[23,     3] loss: 1.007
[24,     3] loss: 0.986
[25,     3] loss: 1.093
[26,     3] loss: 1.014
[27,     3] loss: 0.972
[28,     3] loss: 1.035
[29,     3] loss: 0.931
[30,     3] loss: 0.929
[31,     3] loss: 0.966
[32,     3] loss: 0.961
[33,     3] loss: 0.970
[34,     3] loss: 1.110
[35,     3] loss: 1.031
[36,     3] loss: 1.017
[37,     3] loss: 0.905
[38,     3] loss: 1.017
[39,     3] loss: 0.954
[40,     3] loss: 0.925
[41,     3] loss: 0.916
[42,     3] loss: 0.942
[43,     3] loss: 1.048
[44,     3] loss: 0.995
[45,     3] loss: 0.893
[46,     3] loss: 0.967
[47,     3] loss: 0.889
[48,     3] loss: 1.008
[49,     3] loss: 0.898
[50,     3] loss: 0.878
[51,     3] loss: 0.861
[52,     3] loss: 0.915
[53,     3] loss: 0.882
[54,     3] loss: 0.925
[55,     3] loss: 0.889
[56,     3] loss: 0.816
[57,     3] loss: 0.846
[58,     3] loss: 0.898
[59,     3] loss: 0.873
[60,     3] loss: 0.935
[61,     3] loss: 0.905
[62,     3] loss: 0.863
[63,     3] loss: 0.833
[64,     3] loss: 0.895
[65,     3] loss: 0.863
[66,     3] loss: 0.906
[67,     3] loss: 0.859
[68,     3] loss: 0.869
[69,     3] loss: 0.857
[70,     3] loss: 0.856
[71,     3] loss: 0.902
[72,     3] loss: 0.873
[73,     3] loss: 0.870
[74,     3] loss: 0.839
[75,     3] loss: 0.858
[76,     3] loss: 0.847
[77,     3] loss: 0.831
[78,     3] loss: 0.838
[79,     3] loss: 0.821
[80,     3] loss: 0.801
[81,     3] loss: 0.834
[82,     3] loss: 0.836
[83,     3] loss: 0.814
[84,     3] loss: 0.873
[85,     3] loss: 0.793
[86,     3] loss: 0.807
[87,     3] loss: 0.792
[88,     3] loss: 0.786
[89,     3] loss: 0.798
[90,     3] loss: 0.761
[91,     3] loss: 0.795
[92,     3] loss: 0.765
[93,     3] loss: 0.760
[94,     3] loss: 0.758
[95,     3] loss: 0.754
[96,     3] loss: 0.736
[97,     3] loss: 0.748
[98,     3] loss: 0.775
[99,     3] loss: 0.814
[100,     3] loss: 0.809
[101,     3] loss: 0.914
[102,     3] loss: 0.812
[103,     3] loss: 0.867
[104,     3] loss: 0.826
[105,     3] loss: 0.820
Early stopping applied (best metric=0.5191185474395752)
Finished Training
Total time taken: 31.131152868270874
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.385
[3,     3] loss: 1.391
[4,     3] loss: 1.385
[5,     3] loss: 1.387
[6,     3] loss: 1.380
[7,     3] loss: 1.378
[8,     3] loss: 1.375
[9,     3] loss: 1.372
[10,     3] loss: 1.358
[11,     3] loss: 1.342
[12,     3] loss: 1.330
[13,     3] loss: 1.335
[14,     3] loss: 1.274
[15,     3] loss: 1.256
[16,     3] loss: 1.323
[17,     3] loss: 1.208
[18,     3] loss: 1.270
[19,     3] loss: 1.166
[20,     3] loss: 1.066
[21,     3] loss: 1.140
[22,     3] loss: 1.078
[23,     3] loss: 1.049
[24,     3] loss: 1.012
[25,     3] loss: 0.991
[26,     3] loss: 0.962
[27,     3] loss: 0.935
[28,     3] loss: 0.988
[29,     3] loss: 0.982
[30,     3] loss: 1.002
[31,     3] loss: 1.071
[32,     3] loss: 0.966
[33,     3] loss: 0.995
[34,     3] loss: 0.914
[35,     3] loss: 0.998
[36,     3] loss: 0.923
[37,     3] loss: 0.873
[38,     3] loss: 0.918
[39,     3] loss: 0.842
[40,     3] loss: 0.832
[41,     3] loss: 0.849
[42,     3] loss: 0.862
[43,     3] loss: 0.829
[44,     3] loss: 0.863
[45,     3] loss: 0.827
[46,     3] loss: 0.869
[47,     3] loss: 0.815
[48,     3] loss: 0.857
[49,     3] loss: 0.866
[50,     3] loss: 0.887
[51,     3] loss: 0.773
[52,     3] loss: 0.817
[53,     3] loss: 0.798
[54,     3] loss: 0.804
[55,     3] loss: 0.798
[56,     3] loss: 0.766
[57,     3] loss: 0.763
[58,     3] loss: 0.758
[59,     3] loss: 0.774
[60,     3] loss: 0.783
[61,     3] loss: 0.743
[62,     3] loss: 0.776
[63,     3] loss: 0.765
[64,     3] loss: 0.758
[65,     3] loss: 0.740
[66,     3] loss: 0.761
[67,     3] loss: 0.743
[68,     3] loss: 0.753
[69,     3] loss: 0.808
[70,     3] loss: 0.808
[71,     3] loss: 0.789
[72,     3] loss: 0.821
[73,     3] loss: 0.831
[74,     3] loss: 0.944
[75,     3] loss: 0.776
Early stopping applied (best metric=0.5246290564537048)
Finished Training
Total time taken: 22.080106735229492
{'S-palmitoylation-C Validation Accuracy': 0.6848458803043955, 'S-palmitoylation-C Validation Sensitivity': 0.2436963696369637, 'S-palmitoylation-C Validation Specificity': 0.7954303005512282, 'S-palmitoylation-C Validation Precision': 0.22868016114334191, 'S-palmitoylation-C AUC ROC': 0.5447451870353057, 'S-palmitoylation-C AUC PR': 0.22656234089244823, 'S-palmitoylation-C MCC': 0.03746536519010302, 'S-palmitoylation-C F1': 0.22489233968819386, 'Validation Loss (S-palmitoylation-C)': 0.5540083090464274, 'Hydroxylation-K Validation Accuracy': 0.7041371158392435, 'Hydroxylation-K Validation Sensitivity': 0.8088888888888889, 'Hydroxylation-K Validation Specificity': 0.6771929824561403, 'Hydroxylation-K Validation Precision': 0.3952190769694518, 'Hydroxylation-K AUC ROC': 0.8144249512670566, 'Hydroxylation-K AUC PR': 0.6088896287607195, 'Hydroxylation-K MCC': 0.40268728707569335, 'Hydroxylation-K F1': 0.5247488650180937, 'Validation Loss (Hydroxylation-K)': 0.5081944028536479, 'Validation Loss (total)': 1.0622027079264322, 'TimeToTrain': 24.108252096176148}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005469551790467535,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6396423184097214,
 'loss_weight_S-palmitoylation-C': 0.4007534502379574,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 880149842,
 'sample_weights': [0.49804077553007153, 0.29266436431255743],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.715572080762808,
 'weight_decay_Hydroxylation-K': 3.481846400352798,
 'weight_decay_S-palmitoylation-C': 0.86803410137819}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.390
[3,     3] loss: 1.390
[4,     3] loss: 1.382
[5,     3] loss: 1.390
[6,     3] loss: 1.386
[7,     3] loss: 1.383
[8,     3] loss: 1.391
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005163992144873064,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7333474766617161,
 'loss_weight_S-palmitoylation-C': 0.544854784429248,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3935752990,
 'sample_weights': [0.4007534502379574, 0.6396423184097214],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.935240744338516,
 'weight_decay_Hydroxylation-K': 4.772660651821635,
 'weight_decay_S-palmitoylation-C': 3.277042458456081}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.401
[3,     3] loss: 1.390
[4,     3] loss: 1.384
[5,     3] loss: 1.386
[6,     3] loss: 1.390
[7,     3] loss: 1.387
[8,     3] loss: 1.391
[9,     3] loss: 1.385
[10,     3] loss: 1.384
[11,     3] loss: 1.383
[12,     3] loss: 1.382
[13,     3] loss: 1.378
[14,     3] loss: 1.366
[15,     3] loss: 1.319
[16,     3] loss: 1.221
[17,     3] loss: 1.366
[18,     3] loss: 1.128
[19,     3] loss: 1.224
[20,     3] loss: 1.155
[21,     3] loss: 1.109
[22,     3] loss: 1.082
[23,     3] loss: 1.204
[24,     3] loss: 1.122
[25,     3] loss: 1.057
[26,     3] loss: 1.121
[27,     3] loss: 1.022
[28,     3] loss: 1.070
[29,     3] loss: 1.036
[30,     3] loss: 1.079
[31,     3] loss: 1.107
[32,     3] loss: 0.943
[33,     3] loss: 0.894
[34,     3] loss: 1.098
[35,     3] loss: 1.127
[36,     3] loss: 1.057
[37,     3] loss: 1.190
[38,     3] loss: 1.165
[39,     3] loss: 1.118
[40,     3] loss: 1.105
[41,     3] loss: 1.091
[42,     3] loss: 1.010
[43,     3] loss: 1.037
[44,     3] loss: 1.086
[45,     3] loss: 1.071
[46,     3] loss: 1.110
[47,     3] loss: 0.988
[48,     3] loss: 0.967
[49,     3] loss: 0.912
[50,     3] loss: 1.017
[51,     3] loss: 1.003
[52,     3] loss: 1.035
[53,     3] loss: 0.957
[54,     3] loss: 0.993
[55,     3] loss: 0.892
[56,     3] loss: 0.877
[57,     3] loss: 0.907
[58,     3] loss: 0.947
[59,     3] loss: 0.920
[60,     3] loss: 0.954
[61,     3] loss: 1.062
[62,     3] loss: 0.894
[63,     3] loss: 1.060
[64,     3] loss: 1.054
[65,     3] loss: 1.042
[66,     3] loss: 1.030
[67,     3] loss: 0.953
[68,     3] loss: 0.956
[69,     3] loss: 0.811
[70,     3] loss: 0.986
[71,     3] loss: 1.111
Early stopping applied (best metric=0.5459762811660767)
Finished Training
Total time taken: 20.74410080909729
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.383
[3,     3] loss: 1.389
[4,     3] loss: 1.393
[5,     3] loss: 1.389
[6,     3] loss: 1.390
[7,     3] loss: 1.388
[8,     3] loss: 1.389
[9,     3] loss: 1.386
[10,     3] loss: 1.381
[11,     3] loss: 1.396
[12,     3] loss: 1.381
[13,     3] loss: 1.380
[14,     3] loss: 1.371
[15,     3] loss: 1.355
[16,     3] loss: 1.268
[17,     3] loss: 1.369
[18,     3] loss: 1.184
[19,     3] loss: 1.248
[20,     3] loss: 1.181
[21,     3] loss: 1.172
[22,     3] loss: 1.219
[23,     3] loss: 1.149
[24,     3] loss: 1.093
[25,     3] loss: 1.081
[26,     3] loss: 1.107
[27,     3] loss: 1.035
[28,     3] loss: 0.994
[29,     3] loss: 1.052
[30,     3] loss: 0.991
[31,     3] loss: 1.021
[32,     3] loss: 1.017
[33,     3] loss: 1.020
[34,     3] loss: 0.953
[35,     3] loss: 1.160
[36,     3] loss: 1.044
[37,     3] loss: 1.089
[38,     3] loss: 1.182
[39,     3] loss: 1.123
[40,     3] loss: 1.199
[41,     3] loss: 1.075
[42,     3] loss: 1.137
[43,     3] loss: 1.046
[44,     3] loss: 1.033
[45,     3] loss: 0.897
[46,     3] loss: 1.107
[47,     3] loss: 1.110
[48,     3] loss: 1.102
[49,     3] loss: 1.002
[50,     3] loss: 1.027
[51,     3] loss: 1.030
[52,     3] loss: 0.939
[53,     3] loss: 0.991
[54,     3] loss: 0.990
[55,     3] loss: 0.990
[56,     3] loss: 0.982
[57,     3] loss: 0.923
[58,     3] loss: 0.881
[59,     3] loss: 0.937
[60,     3] loss: 1.025
[61,     3] loss: 0.972
[62,     3] loss: 0.892
[63,     3] loss: 0.913
[64,     3] loss: 0.992
[65,     3] loss: 0.941
[66,     3] loss: 1.012
Early stopping applied (best metric=0.5215524435043335)
Finished Training
Total time taken: 19.118091821670532
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.397
[3,     3] loss: 1.392
[4,     3] loss: 1.384
[5,     3] loss: 1.401
[6,     3] loss: 1.390
[7,     3] loss: 1.388
[8,     3] loss: 1.382
[9,     3] loss: 1.383
[10,     3] loss: 1.388
[11,     3] loss: 1.383
[12,     3] loss: 1.385
[13,     3] loss: 1.383
[14,     3] loss: 1.378
[15,     3] loss: 1.348
[16,     3] loss: 1.331
[17,     3] loss: 1.297
[18,     3] loss: 1.218
[19,     3] loss: 1.179
[20,     3] loss: 1.319
[21,     3] loss: 1.179
[22,     3] loss: 1.207
[23,     3] loss: 1.128
[24,     3] loss: 1.196
[25,     3] loss: 1.159
[26,     3] loss: 1.032
[27,     3] loss: 1.021
[28,     3] loss: 1.074
[29,     3] loss: 1.224
[30,     3] loss: 1.150
[31,     3] loss: 1.151
[32,     3] loss: 1.125
[33,     3] loss: 1.062
[34,     3] loss: 1.002
[35,     3] loss: 1.014
[36,     3] loss: 0.975
[37,     3] loss: 1.102
[38,     3] loss: 0.988
[39,     3] loss: 0.974
[40,     3] loss: 0.957
[41,     3] loss: 1.156
[42,     3] loss: 1.600
[43,     3] loss: 1.418
[44,     3] loss: 1.364
[45,     3] loss: 1.383
[46,     3] loss: 1.385
[47,     3] loss: 1.385
[48,     3] loss: 1.385
[49,     3] loss: 1.386
[50,     3] loss: 1.385
[51,     3] loss: 1.385
[52,     3] loss: 1.386
[53,     3] loss: 1.385
[54,     3] loss: 1.384
[55,     3] loss: 1.385
[56,     3] loss: 1.381
[57,     3] loss: 1.380
[58,     3] loss: 1.386
[59,     3] loss: 1.379
[60,     3] loss: 1.356
[61,     3] loss: 1.341
[62,     3] loss: 1.342
[63,     3] loss: 1.364
[64,     3] loss: 1.278
Early stopping applied (best metric=0.5540485382080078)
Finished Training
Total time taken: 18.763089895248413
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.388
[3,     3] loss: 1.383
[4,     3] loss: 1.384
[5,     3] loss: 1.382
[6,     3] loss: 1.375
[7,     3] loss: 1.360
[8,     3] loss: 1.369
[9,     3] loss: 1.303
[10,     3] loss: 1.210
[11,     3] loss: 1.222
[12,     3] loss: 1.119
[13,     3] loss: 1.076
[14,     3] loss: 1.118
[15,     3] loss: 1.101
[16,     3] loss: 1.099
[17,     3] loss: 1.051
[18,     3] loss: 1.042
[19,     3] loss: 1.171
[20,     3] loss: 1.064
[21,     3] loss: 1.114
[22,     3] loss: 1.071
[23,     3] loss: 1.030
[24,     3] loss: 1.042
[25,     3] loss: 1.168
[26,     3] loss: 1.231
[27,     3] loss: 1.125
[28,     3] loss: 1.149
[29,     3] loss: 1.092
[30,     3] loss: 1.008
[31,     3] loss: 1.035
[32,     3] loss: 1.134
[33,     3] loss: 1.497
[34,     3] loss: 1.193
[35,     3] loss: 1.315
[36,     3] loss: 1.308
[37,     3] loss: 1.310
[38,     3] loss: 1.218
[39,     3] loss: 1.140
[40,     3] loss: 1.117
[41,     3] loss: 1.104
[42,     3] loss: 1.170
[43,     3] loss: 1.089
[44,     3] loss: 1.158
[45,     3] loss: 1.019
[46,     3] loss: 1.021
[47,     3] loss: 0.998
[48,     3] loss: 1.016
[49,     3] loss: 1.086
[50,     3] loss: 1.104
[51,     3] loss: 1.067
[52,     3] loss: 0.945
[53,     3] loss: 0.939
[54,     3] loss: 1.028
[55,     3] loss: 0.999
[56,     3] loss: 1.068
[57,     3] loss: 1.038
[58,     3] loss: 1.026
[59,     3] loss: 0.951
[60,     3] loss: 0.995
[61,     3] loss: 0.905
[62,     3] loss: 1.065
[63,     3] loss: 0.974
[64,     3] loss: 1.107
[65,     3] loss: 1.000
[66,     3] loss: 0.945
[67,     3] loss: 0.862
[68,     3] loss: 0.826
[69,     3] loss: 0.987
[70,     3] loss: 1.278
[71,     3] loss: 1.251
[72,     3] loss: 1.173
[73,     3] loss: 1.124
[74,     3] loss: 1.074
[75,     3] loss: 1.073
[76,     3] loss: 1.053
[77,     3] loss: 0.957
[78,     3] loss: 0.962
[79,     3] loss: 0.909
[80,     3] loss: 1.079
[81,     3] loss: 1.061
[82,     3] loss: 1.132
[83,     3] loss: 1.067
[84,     3] loss: 1.019
[85,     3] loss: 0.999
[86,     3] loss: 0.983
[87,     3] loss: 1.080
[88,     3] loss: 0.894
[89,     3] loss: 0.925
[90,     3] loss: 0.881
[91,     3] loss: 0.847
[92,     3] loss: 1.015
[93,     3] loss: 0.938
[94,     3] loss: 0.928
[95,     3] loss: 0.965
[96,     3] loss: 0.990
[97,     3] loss: 1.013
[98,     3] loss: 0.983
[99,     3] loss: 0.920
[100,     3] loss: 0.987
[101,     3] loss: 0.882
[102,     3] loss: 0.893
[103,     3] loss: 0.882
[104,     3] loss: 0.899
[105,     3] loss: 1.491
[106,     3] loss: 1.267
[107,     3] loss: 1.279
[108,     3] loss: 1.316
[109,     3] loss: 1.308
[110,     3] loss: 1.208
[111,     3] loss: 1.276
[112,     3] loss: 1.222
[113,     3] loss: 1.155
[114,     3] loss: 1.134
[115,     3] loss: 1.189
[116,     3] loss: 1.157
[117,     3] loss: 1.143
[118,     3] loss: 1.137
[119,     3] loss: 0.999
[120,     3] loss: 0.979
[121,     3] loss: 0.981
[122,     3] loss: 1.263
[123,     3] loss: 1.401
[124,     3] loss: 1.322
[125,     3] loss: 1.326
[126,     3] loss: 1.370
[127,     3] loss: 1.352
[128,     3] loss: 1.364
[129,     3] loss: 1.352
[130,     3] loss: 1.307
[131,     3] loss: 1.325
[132,     3] loss: 1.314
[133,     3] loss: 1.282
[134,     3] loss: 1.298
[135,     3] loss: 1.283
[136,     3] loss: 1.227
[137,     3] loss: 1.157
[138,     3] loss: 1.152
[139,     3] loss: 1.102
[140,     3] loss: 1.043
Early stopping applied (best metric=0.5347610712051392)
Finished Training
Total time taken: 41.60220146179199
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.384
[3,     3] loss: 1.382
[4,     3] loss: 1.394
[5,     3] loss: 1.384
[6,     3] loss: 1.392
[7,     3] loss: 1.392
[8,     3] loss: 1.388
[9,     3] loss: 1.389
[10,     3] loss: 1.385
[11,     3] loss: 1.393
[12,     3] loss: 1.388
[13,     3] loss: 1.383
[14,     3] loss: 1.389
[15,     3] loss: 1.386
[16,     3] loss: 1.385
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.379
[20,     3] loss: 1.373
[21,     3] loss: 1.378
[22,     3] loss: 1.353
[23,     3] loss: 1.292
[24,     3] loss: 1.243
[25,     3] loss: 1.277
[26,     3] loss: 1.253
[27,     3] loss: 1.131
[28,     3] loss: 1.147
[29,     3] loss: 1.186
[30,     3] loss: 1.076
[31,     3] loss: 1.085
[32,     3] loss: 1.057
[33,     3] loss: 1.026
[34,     3] loss: 1.144
[35,     3] loss: 1.033
[36,     3] loss: 0.918
[37,     3] loss: 1.013
[38,     3] loss: 0.989
[39,     3] loss: 1.031
[40,     3] loss: 1.077
[41,     3] loss: 1.063
[42,     3] loss: 0.990
[43,     3] loss: 1.061
[44,     3] loss: 0.903
[45,     3] loss: 0.946
[46,     3] loss: 0.862
[47,     3] loss: 1.084
[48,     3] loss: 1.057
[49,     3] loss: 1.031
[50,     3] loss: 0.952
[51,     3] loss: 1.061
[52,     3] loss: 1.010
[53,     3] loss: 1.159
[54,     3] loss: 1.011
[55,     3] loss: 0.979
[56,     3] loss: 1.097
[57,     3] loss: 0.935
[58,     3] loss: 0.947
[59,     3] loss: 0.936
[60,     3] loss: 0.928
[61,     3] loss: 1.205
[62,     3] loss: 0.989
[63,     3] loss: 1.080
[64,     3] loss: 1.032
[65,     3] loss: 0.902
[66,     3] loss: 0.857
[67,     3] loss: 0.882
[68,     3] loss: 1.235
[69,     3] loss: 1.094
[70,     3] loss: 1.104
[71,     3] loss: 0.942
[72,     3] loss: 0.983
[73,     3] loss: 0.872
[74,     3] loss: 0.881
[75,     3] loss: 0.865
[76,     3] loss: 1.040
[77,     3] loss: 0.996
[78,     3] loss: 1.039
[79,     3] loss: 0.921
[80,     3] loss: 0.936
[81,     3] loss: 0.816
[82,     3] loss: 0.846
[83,     3] loss: 0.906
[84,     3] loss: 0.871
[85,     3] loss: 0.919
[86,     3] loss: 0.977
[87,     3] loss: 1.027
[88,     3] loss: 0.997
[89,     3] loss: 1.079
[90,     3] loss: 0.945
[91,     3] loss: 0.819
[92,     3] loss: 0.880
[93,     3] loss: 0.811
[94,     3] loss: 0.803
[95,     3] loss: 0.868
Early stopping applied (best metric=0.5102183222770691)
Finished Training
Total time taken: 27.966135501861572
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.392
[3,     3] loss: 1.384
[4,     3] loss: 1.390
[5,     3] loss: 1.373
[6,     3] loss: 1.383
[7,     3] loss: 1.387
[8,     3] loss: 1.374
[9,     3] loss: 1.353
[10,     3] loss: 1.343
[11,     3] loss: 1.324
[12,     3] loss: 1.283
[13,     3] loss: 1.231
[14,     3] loss: 1.193
[15,     3] loss: 1.151
[16,     3] loss: 1.123
[17,     3] loss: 1.285
[18,     3] loss: 1.151
[19,     3] loss: 1.133
[20,     3] loss: 1.202
[21,     3] loss: 1.178
[22,     3] loss: 1.142
[23,     3] loss: 1.062
[24,     3] loss: 1.055
[25,     3] loss: 1.137
[26,     3] loss: 1.029
[27,     3] loss: 1.062
[28,     3] loss: 1.013
[29,     3] loss: 1.066
[30,     3] loss: 1.078
[31,     3] loss: 1.078
[32,     3] loss: 1.206
[33,     3] loss: 1.062
[34,     3] loss: 1.000
[35,     3] loss: 0.997
[36,     3] loss: 1.059
[37,     3] loss: 1.352
[38,     3] loss: 1.119
[39,     3] loss: 1.094
[40,     3] loss: 1.025
[41,     3] loss: 1.029
[42,     3] loss: 1.074
[43,     3] loss: 0.971
[44,     3] loss: 1.044
[45,     3] loss: 1.031
[46,     3] loss: 1.020
[47,     3] loss: 1.170
[48,     3] loss: 1.119
[49,     3] loss: 1.111
[50,     3] loss: 1.070
[51,     3] loss: 1.061
[52,     3] loss: 1.003
[53,     3] loss: 1.085
[54,     3] loss: 1.166
[55,     3] loss: 1.154
[56,     3] loss: 1.054
[57,     3] loss: 1.027
[58,     3] loss: 0.956
[59,     3] loss: 1.061
[60,     3] loss: 0.986
[61,     3] loss: 0.895
[62,     3] loss: 0.899
[63,     3] loss: 0.823
[64,     3] loss: 0.958
[65,     3] loss: 1.721
[66,     3] loss: 1.223
[67,     3] loss: 1.455
[68,     3] loss: 1.357
[69,     3] loss: 1.358
[70,     3] loss: 1.388
[71,     3] loss: 1.347
[72,     3] loss: 1.335
[73,     3] loss: 1.343
Early stopping applied (best metric=0.5225530862808228)
Finished Training
Total time taken: 21.627103328704834
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.392
[3,     3] loss: 1.385
[4,     3] loss: 1.390
[5,     3] loss: 1.385
[6,     3] loss: 1.377
[7,     3] loss: 1.387
[8,     3] loss: 1.390
[9,     3] loss: 1.395
[10,     3] loss: 1.389
[11,     3] loss: 1.386
[12,     3] loss: 1.389
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.385
[16,     3] loss: 1.385
[17,     3] loss: 1.378
[18,     3] loss: 1.358
[19,     3] loss: 1.302
[20,     3] loss: 1.279
[21,     3] loss: 1.296
[22,     3] loss: 1.340
[23,     3] loss: 1.301
[24,     3] loss: 1.272
[25,     3] loss: 1.203
[26,     3] loss: 1.177
[27,     3] loss: 1.124
[28,     3] loss: 1.321
[29,     3] loss: 1.291
[30,     3] loss: 1.228
[31,     3] loss: 1.321
[32,     3] loss: 1.226
[33,     3] loss: 1.235
[34,     3] loss: 1.204
[35,     3] loss: 1.232
[36,     3] loss: 1.370
[37,     3] loss: 1.188
[38,     3] loss: 1.231
[39,     3] loss: 1.200
[40,     3] loss: 1.201
[41,     3] loss: 1.109
[42,     3] loss: 1.082
[43,     3] loss: 1.216
[44,     3] loss: 1.148
[45,     3] loss: 1.174
[46,     3] loss: 1.159
[47,     3] loss: 1.251
[48,     3] loss: 1.167
[49,     3] loss: 1.066
[50,     3] loss: 1.153
[51,     3] loss: 1.114
[52,     3] loss: 1.175
[53,     3] loss: 1.085
[54,     3] loss: 1.023
[55,     3] loss: 1.112
[56,     3] loss: 1.157
[57,     3] loss: 0.977
[58,     3] loss: 0.941
[59,     3] loss: 0.927
[60,     3] loss: 0.896
[61,     3] loss: 1.236
[62,     3] loss: 1.125
[63,     3] loss: 1.137
[64,     3] loss: 1.190
[65,     3] loss: 1.124
[66,     3] loss: 1.019
[67,     3] loss: 1.055
[68,     3] loss: 1.018
[69,     3] loss: 1.114
[70,     3] loss: 1.152
[71,     3] loss: 1.183
[72,     3] loss: 1.125
[73,     3] loss: 1.132
[74,     3] loss: 1.017
[75,     3] loss: 0.999
[76,     3] loss: 0.916
[77,     3] loss: 0.929
Early stopping applied (best metric=0.5187438130378723)
Finished Training
Total time taken: 23.289114236831665
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.380
[3,     3] loss: 1.381
[4,     3] loss: 1.383
[5,     3] loss: 1.380
[6,     3] loss: 1.382
[7,     3] loss: 1.395
[8,     3] loss: 1.385
[9,     3] loss: 1.391
[10,     3] loss: 1.385
[11,     3] loss: 1.387
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.380
[15,     3] loss: 1.386
[16,     3] loss: 1.385
[17,     3] loss: 1.372
[18,     3] loss: 1.345
[19,     3] loss: 1.354
[20,     3] loss: 1.328
[21,     3] loss: 1.301
[22,     3] loss: 1.268
[23,     3] loss: 1.298
[24,     3] loss: 1.233
[25,     3] loss: 1.155
[26,     3] loss: 1.145
[27,     3] loss: 1.131
[28,     3] loss: 1.126
[29,     3] loss: 1.228
[30,     3] loss: 1.124
[31,     3] loss: 1.069
[32,     3] loss: 1.105
[33,     3] loss: 1.031
[34,     3] loss: 1.095
[35,     3] loss: 1.041
[36,     3] loss: 1.174
[37,     3] loss: 0.966
[38,     3] loss: 0.980
[39,     3] loss: 1.348
[40,     3] loss: 1.180
[41,     3] loss: 1.108
[42,     3] loss: 1.191
[43,     3] loss: 1.190
[44,     3] loss: 1.204
[45,     3] loss: 1.239
[46,     3] loss: 1.098
[47,     3] loss: 1.158
[48,     3] loss: 1.025
[49,     3] loss: 1.116
[50,     3] loss: 1.250
[51,     3] loss: 1.227
[52,     3] loss: 1.200
[53,     3] loss: 1.137
[54,     3] loss: 1.179
[55,     3] loss: 1.236
[56,     3] loss: 1.186
[57,     3] loss: 1.123
[58,     3] loss: 1.015
[59,     3] loss: 0.965
[60,     3] loss: 1.114
[61,     3] loss: 1.398
[62,     3] loss: 1.172
[63,     3] loss: 1.118
[64,     3] loss: 1.155
[65,     3] loss: 1.106
[66,     3] loss: 1.151
[67,     3] loss: 1.148
[68,     3] loss: 1.067
[69,     3] loss: 1.048
[70,     3] loss: 1.118
[71,     3] loss: 0.947
[72,     3] loss: 1.033
[73,     3] loss: 1.225
[74,     3] loss: 1.183
[75,     3] loss: 1.231
[76,     3] loss: 1.170
[77,     3] loss: 1.094
[78,     3] loss: 1.136
[79,     3] loss: 1.036
[80,     3] loss: 1.016
[81,     3] loss: 0.974
[82,     3] loss: 0.968
Early stopping applied (best metric=0.5195642709732056)
Finished Training
Total time taken: 24.273114919662476
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.381
[3,     3] loss: 1.395
[4,     3] loss: 1.385
[5,     3] loss: 1.392
[6,     3] loss: 1.384
[7,     3] loss: 1.386
[8,     3] loss: 1.372
[9,     3] loss: 1.392
[10,     3] loss: 1.384
[11,     3] loss: 1.344
[12,     3] loss: 1.323
[13,     3] loss: 1.308
[14,     3] loss: 1.284
[15,     3] loss: 1.241
[16,     3] loss: 1.232
[17,     3] loss: 1.273
[18,     3] loss: 1.206
[19,     3] loss: 1.153
[20,     3] loss: 1.166
[21,     3] loss: 1.137
[22,     3] loss: 1.071
[23,     3] loss: 1.258
[24,     3] loss: 1.111
[25,     3] loss: 1.124
[26,     3] loss: 0.996
[27,     3] loss: 1.041
[28,     3] loss: 1.097
[29,     3] loss: 0.979
[30,     3] loss: 1.012
[31,     3] loss: 1.009
[32,     3] loss: 0.994
[33,     3] loss: 0.944
[34,     3] loss: 0.922
[35,     3] loss: 1.017
[36,     3] loss: 0.996
[37,     3] loss: 1.012
[38,     3] loss: 1.070
[39,     3] loss: 0.914
[40,     3] loss: 0.892
[41,     3] loss: 0.876
[42,     3] loss: 1.274
[43,     3] loss: 1.443
[44,     3] loss: 1.242
[45,     3] loss: 1.313
[46,     3] loss: 1.329
[47,     3] loss: 1.343
[48,     3] loss: 1.315
[49,     3] loss: 1.311
[50,     3] loss: 1.289
[51,     3] loss: 1.290
[52,     3] loss: 1.246
[53,     3] loss: 1.302
[54,     3] loss: 1.281
[55,     3] loss: 1.214
[56,     3] loss: 1.151
[57,     3] loss: 1.193
[58,     3] loss: 1.185
[59,     3] loss: 1.180
[60,     3] loss: 1.178
[61,     3] loss: 1.073
[62,     3] loss: 1.049
[63,     3] loss: 1.008
[64,     3] loss: 0.923
[65,     3] loss: 1.012
[66,     3] loss: 1.026
[67,     3] loss: 1.088
[68,     3] loss: 1.029
[69,     3] loss: 0.941
Early stopping applied (best metric=0.5179871916770935)
Finished Training
Total time taken: 19.15309238433838
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.390
[3,     3] loss: 1.390
[4,     3] loss: 1.382
[5,     3] loss: 1.387
[6,     3] loss: 1.381
[7,     3] loss: 1.392
[8,     3] loss: 1.389
[9,     3] loss: 1.381
[10,     3] loss: 1.382
[11,     3] loss: 1.391
[12,     3] loss: 1.378
[13,     3] loss: 1.379
[14,     3] loss: 1.340
[15,     3] loss: 1.307
[16,     3] loss: 1.248
[17,     3] loss: 1.259
[18,     3] loss: 1.239
[19,     3] loss: 1.129
[20,     3] loss: 1.141
[21,     3] loss: 1.179
[22,     3] loss: 1.164
[23,     3] loss: 1.146
[24,     3] loss: 1.143
[25,     3] loss: 1.047
[26,     3] loss: 1.083
[27,     3] loss: 0.991
[28,     3] loss: 1.120
[29,     3] loss: 1.114
[30,     3] loss: 1.084
[31,     3] loss: 1.026
[32,     3] loss: 0.957
[33,     3] loss: 0.947
[34,     3] loss: 1.066
[35,     3] loss: 0.994
[36,     3] loss: 1.151
[37,     3] loss: 1.040
[38,     3] loss: 0.924
[39,     3] loss: 0.916
[40,     3] loss: 1.027
[41,     3] loss: 0.933
[42,     3] loss: 1.084
[43,     3] loss: 1.167
[44,     3] loss: 1.134
[45,     3] loss: 1.047
[46,     3] loss: 1.131
[47,     3] loss: 0.959
[48,     3] loss: 0.988
[49,     3] loss: 0.993
[50,     3] loss: 0.858
[51,     3] loss: 0.858
[52,     3] loss: 0.787
[53,     3] loss: 0.932
[54,     3] loss: 0.951
[55,     3] loss: 0.901
[56,     3] loss: 0.950
[57,     3] loss: 1.048
[58,     3] loss: 0.980
[59,     3] loss: 1.009
[60,     3] loss: 1.002
[61,     3] loss: 0.945
[62,     3] loss: 0.928
[63,     3] loss: 0.939
[64,     3] loss: 1.069
[65,     3] loss: 1.107
[66,     3] loss: 1.144
[67,     3] loss: 1.006
[68,     3] loss: 1.082
[69,     3] loss: 0.914
[70,     3] loss: 0.931
[71,     3] loss: 0.880
[72,     3] loss: 0.929
[73,     3] loss: 1.063
[74,     3] loss: 1.078
[75,     3] loss: 1.050
[76,     3] loss: 0.976
Early stopping applied (best metric=0.500784158706665)
Finished Training
Total time taken: 21.23810338973999
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.383
[3,     3] loss: 1.387
[4,     3] loss: 1.393
[5,     3] loss: 1.383
[6,     3] loss: 1.396
[7,     3] loss: 1.385
[8,     3] loss: 1.388
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.383
[12,     3] loss: 1.388
[13,     3] loss: 1.392
[14,     3] loss: 1.387
[15,     3] loss: 1.385
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.385
[24,     3] loss: 1.387
[25,     3] loss: 1.386
[26,     3] loss: 1.385
[27,     3] loss: 1.386
[28,     3] loss: 1.387
[29,     3] loss: 1.385
[30,     3] loss: 1.388
[31,     3] loss: 1.385
[32,     3] loss: 1.385
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.385
[36,     3] loss: 1.379
[37,     3] loss: 1.343
[38,     3] loss: 1.277
[39,     3] loss: 1.278
[40,     3] loss: 1.283
[41,     3] loss: 1.213
[42,     3] loss: 1.250
[43,     3] loss: 1.287
[44,     3] loss: 1.237
[45,     3] loss: 1.154
[46,     3] loss: 1.209
[47,     3] loss: 1.279
[48,     3] loss: 1.208
[49,     3] loss: 1.082
[50,     3] loss: 1.110
[51,     3] loss: 1.129
[52,     3] loss: 1.120
[53,     3] loss: 1.146
[54,     3] loss: 1.104
[55,     3] loss: 1.058
[56,     3] loss: 1.082
[57,     3] loss: 1.178
[58,     3] loss: 1.048
[59,     3] loss: 1.144
[60,     3] loss: 0.968
[61,     3] loss: 1.025
[62,     3] loss: 0.957
[63,     3] loss: 1.040
[64,     3] loss: 1.053
[65,     3] loss: 1.000
[66,     3] loss: 1.036
[67,     3] loss: 0.901
[68,     3] loss: 1.035
[69,     3] loss: 0.976
[70,     3] loss: 1.239
[71,     3] loss: 1.070
[72,     3] loss: 1.154
[73,     3] loss: 1.141
[74,     3] loss: 1.048
[75,     3] loss: 1.028
[76,     3] loss: 0.964
[77,     3] loss: 1.027
[78,     3] loss: 1.019
[79,     3] loss: 0.963
[80,     3] loss: 1.208
[81,     3] loss: 1.318
[82,     3] loss: 1.322
[83,     3] loss: 1.311
[84,     3] loss: 1.262
[85,     3] loss: 1.203
[86,     3] loss: 1.208
[87,     3] loss: 1.179
[88,     3] loss: 1.215
[89,     3] loss: 1.119
[90,     3] loss: 0.984
[91,     3] loss: 1.040
[92,     3] loss: 1.056
[93,     3] loss: 1.290
[94,     3] loss: 1.070
[95,     3] loss: 1.071
Early stopping applied (best metric=0.5408035516738892)
Finished Training
Total time taken: 26.49612784385681
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.386
[3,     3] loss: 1.390
[4,     3] loss: 1.382
[5,     3] loss: 1.390
[6,     3] loss: 1.385
[7,     3] loss: 1.388
[8,     3] loss: 1.388
[9,     3] loss: 1.390
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.383
[13,     3] loss: 1.383
[14,     3] loss: 1.375
[15,     3] loss: 1.350
[16,     3] loss: 1.301
[17,     3] loss: 1.323
[18,     3] loss: 1.367
[19,     3] loss: 1.227
[20,     3] loss: 1.289
[21,     3] loss: 1.305
[22,     3] loss: 1.316
[23,     3] loss: 1.211
[24,     3] loss: 1.203
[25,     3] loss: 1.161
[26,     3] loss: 1.193
[27,     3] loss: 1.070
[28,     3] loss: 1.087
[29,     3] loss: 1.088
[30,     3] loss: 0.999
[31,     3] loss: 0.993
[32,     3] loss: 1.040
[33,     3] loss: 1.055
[34,     3] loss: 1.119
[35,     3] loss: 1.060
[36,     3] loss: 1.081
[37,     3] loss: 1.054
[38,     3] loss: 1.047
[39,     3] loss: 1.075
[40,     3] loss: 1.189
[41,     3] loss: 1.053
[42,     3] loss: 1.081
[43,     3] loss: 1.067
[44,     3] loss: 1.128
[45,     3] loss: 1.006
[46,     3] loss: 1.212
[47,     3] loss: 1.102
[48,     3] loss: 1.050
[49,     3] loss: 1.044
[50,     3] loss: 1.036
[51,     3] loss: 1.060
[52,     3] loss: 1.006
[53,     3] loss: 1.038
[54,     3] loss: 0.948
[55,     3] loss: 0.974
[56,     3] loss: 0.947
[57,     3] loss: 1.248
[58,     3] loss: 1.026
[59,     3] loss: 1.040
[60,     3] loss: 0.985
[61,     3] loss: 1.035
[62,     3] loss: 0.972
[63,     3] loss: 0.961
[64,     3] loss: 0.967
[65,     3] loss: 0.969
[66,     3] loss: 1.000
[67,     3] loss: 0.940
[68,     3] loss: 0.903
[69,     3] loss: 1.258
[70,     3] loss: 1.033
[71,     3] loss: 1.077
[72,     3] loss: 1.097
[73,     3] loss: 1.002
Early stopping applied (best metric=0.5195006132125854)
Finished Training
Total time taken: 20.527101278305054
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.384
[3,     3] loss: 1.388
[4,     3] loss: 1.382
[5,     3] loss: 1.392
[6,     3] loss: 1.383
[7,     3] loss: 1.392
[8,     3] loss: 1.391
[9,     3] loss: 1.386
[10,     3] loss: 1.387
[11,     3] loss: 1.387
[12,     3] loss: 1.390
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.384
[16,     3] loss: 1.386
[17,     3] loss: 1.384
[18,     3] loss: 1.377
[19,     3] loss: 1.353
[20,     3] loss: 1.332
[21,     3] loss: 1.328
[22,     3] loss: 1.309
[23,     3] loss: 1.243
[24,     3] loss: 1.152
[25,     3] loss: 1.333
[26,     3] loss: 1.286
[27,     3] loss: 1.238
[28,     3] loss: 1.200
[29,     3] loss: 1.192
[30,     3] loss: 1.118
[31,     3] loss: 1.146
[32,     3] loss: 1.041
[33,     3] loss: 1.062
[34,     3] loss: 1.107
[35,     3] loss: 1.120
[36,     3] loss: 1.206
[37,     3] loss: 1.160
[38,     3] loss: 1.150
[39,     3] loss: 1.007
[40,     3] loss: 0.985
[41,     3] loss: 1.035
[42,     3] loss: 1.015
[43,     3] loss: 1.241
[44,     3] loss: 1.055
[45,     3] loss: 1.193
[46,     3] loss: 1.190
[47,     3] loss: 1.221
[48,     3] loss: 1.190
[49,     3] loss: 1.111
[50,     3] loss: 0.995
[51,     3] loss: 0.944
[52,     3] loss: 0.918
[53,     3] loss: 1.374
[54,     3] loss: 1.176
[55,     3] loss: 1.166
[56,     3] loss: 1.134
[57,     3] loss: 1.173
[58,     3] loss: 1.059
[59,     3] loss: 0.982
[60,     3] loss: 1.010
[61,     3] loss: 0.944
[62,     3] loss: 0.947
[63,     3] loss: 0.899
[64,     3] loss: 0.924
[65,     3] loss: 1.037
[66,     3] loss: 1.120
[67,     3] loss: 1.108
[68,     3] loss: 1.096
[69,     3] loss: 1.050
[70,     3] loss: 0.989
[71,     3] loss: 0.943
[72,     3] loss: 0.936
[73,     3] loss: 0.982
[74,     3] loss: 0.941
[75,     3] loss: 1.155
[76,     3] loss: 1.186
[77,     3] loss: 1.132
[78,     3] loss: 1.030
[79,     3] loss: 1.121
[80,     3] loss: 0.965
Early stopping applied (best metric=0.52685546875)
Finished Training
Total time taken: 22.37910795211792
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.404
[3,     3] loss: 1.391
[4,     3] loss: 1.390
[5,     3] loss: 1.388
[6,     3] loss: 1.387
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.387
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.387
[14,     3] loss: 1.387
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.385
[18,     3] loss: 1.386
[19,     3] loss: 1.383
[20,     3] loss: 1.374
[21,     3] loss: 1.374
[22,     3] loss: 1.376
[23,     3] loss: 1.365
[24,     3] loss: 1.346
[25,     3] loss: 1.317
[26,     3] loss: 1.283
[27,     3] loss: 1.221
[28,     3] loss: 1.201
[29,     3] loss: 1.170
[30,     3] loss: 1.160
[31,     3] loss: 1.246
[32,     3] loss: 1.088
[33,     3] loss: 1.049
[34,     3] loss: 1.182
[35,     3] loss: 1.036
[36,     3] loss: 1.056
[37,     3] loss: 1.158
[38,     3] loss: 0.984
[39,     3] loss: 1.052
[40,     3] loss: 1.180
[41,     3] loss: 1.173
[42,     3] loss: 1.105
[43,     3] loss: 1.044
[44,     3] loss: 0.977
[45,     3] loss: 0.920
[46,     3] loss: 0.950
[47,     3] loss: 1.485
[48,     3] loss: 1.156
[49,     3] loss: 1.178
[50,     3] loss: 1.115
[51,     3] loss: 1.200
[52,     3] loss: 1.091
[53,     3] loss: 1.148
[54,     3] loss: 1.135
[55,     3] loss: 1.244
[56,     3] loss: 1.251
[57,     3] loss: 1.216
[58,     3] loss: 1.116
[59,     3] loss: 1.121
[60,     3] loss: 1.088
[61,     3] loss: 1.091
[62,     3] loss: 1.085
[63,     3] loss: 0.956
[64,     3] loss: 1.391
[65,     3] loss: 1.159
[66,     3] loss: 1.125
[67,     3] loss: 1.144
[68,     3] loss: 0.969
[69,     3] loss: 1.098
[70,     3] loss: 0.958
[71,     3] loss: 0.905
[72,     3] loss: 0.961
[73,     3] loss: 0.957
[74,     3] loss: 0.911
[75,     3] loss: 0.942
[76,     3] loss: 1.465
Early stopping applied (best metric=0.503591001033783)
Finished Training
Total time taken: 21.293103218078613
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.389
[3,     3] loss: 1.385
[4,     3] loss: 1.394
[5,     3] loss: 1.384
[6,     3] loss: 1.388
[7,     3] loss: 1.379
[8,     3] loss: 1.378
[9,     3] loss: 1.365
[10,     3] loss: 1.336
[11,     3] loss: 1.303
[12,     3] loss: 1.278
[13,     3] loss: 1.312
[14,     3] loss: 1.214
[15,     3] loss: 1.181
[16,     3] loss: 1.315
[17,     3] loss: 1.276
[18,     3] loss: 1.234
[19,     3] loss: 1.193
[20,     3] loss: 1.142
[21,     3] loss: 1.230
[22,     3] loss: 1.187
[23,     3] loss: 1.119
[24,     3] loss: 1.139
[25,     3] loss: 1.051
[26,     3] loss: 0.992
[27,     3] loss: 0.916
[28,     3] loss: 1.050
[29,     3] loss: 1.143
[30,     3] loss: 1.079
[31,     3] loss: 0.989
[32,     3] loss: 1.036
[33,     3] loss: 1.019
[34,     3] loss: 1.088
[35,     3] loss: 1.015
[36,     3] loss: 1.067
[37,     3] loss: 1.079
[38,     3] loss: 1.073
[39,     3] loss: 1.131
[40,     3] loss: 1.084
[41,     3] loss: 1.042
[42,     3] loss: 0.995
[43,     3] loss: 0.884
[44,     3] loss: 1.038
[45,     3] loss: 0.935
[46,     3] loss: 0.916
[47,     3] loss: 0.877
[48,     3] loss: 0.904
[49,     3] loss: 0.912
[50,     3] loss: 1.249
[51,     3] loss: 1.005
[52,     3] loss: 1.073
[53,     3] loss: 1.092
[54,     3] loss: 0.970
[55,     3] loss: 0.888
[56,     3] loss: 1.142
[57,     3] loss: 1.027
[58,     3] loss: 0.982
[59,     3] loss: 1.019
[60,     3] loss: 1.017
[61,     3] loss: 0.985
[62,     3] loss: 0.948
[63,     3] loss: 0.889
[64,     3] loss: 0.978
[65,     3] loss: 0.953
Early stopping applied (best metric=0.5292916297912598)
Finished Training
Total time taken: 18.246086835861206
{'S-palmitoylation-C Validation Accuracy': 0.6925518965911979, 'S-palmitoylation-C Validation Sensitivity': 0.2099009900990099, 'S-palmitoylation-C Validation Specificity': 0.8135216265299233, 'S-palmitoylation-C Validation Precision': 0.22039976981524026, 'S-palmitoylation-C AUC ROC': 0.5359119754980173, 'S-palmitoylation-C AUC PR': 0.22089737426262343, 'S-palmitoylation-C MCC': 0.025525559155803637, 'S-palmitoylation-C F1': 0.1582811177877712, 'Validation Loss (S-palmitoylation-C)': 0.5556435585021973, 'Hydroxylation-K Validation Accuracy': 0.6976950354609929, 'Hydroxylation-K Validation Sensitivity': 0.6444444444444445, 'Hydroxylation-K Validation Specificity': 0.7140350877192982, 'Hydroxylation-K Validation Precision': 0.44095350147026585, 'Hydroxylation-K AUC ROC': 0.8142495126705653, 'Hydroxylation-K AUC PR': 0.5637176752767481, 'Hydroxylation-K MCC': 0.33809773050245695, 'Hydroxylation-K F1': 0.4771183933697259, 'Validation Loss (Hydroxylation-K)': 0.5244154294331869, 'Validation Loss (total)': 1.0800589799880982, 'TimeToTrain': 23.11437832514445}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00619880829362859,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.47354088311328013,
 'loss_weight_S-palmitoylation-C': 0.08410164359066835,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1948434835,
 'sample_weights': [0.544854784429248, 0.7333474766617161],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.543492289679985,
 'weight_decay_Hydroxylation-K': 4.180182276931056,
 'weight_decay_S-palmitoylation-C': 5.276391369380319}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.389
[3,     3] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008060325952993008,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.09465483790416462,
 'loss_weight_S-palmitoylation-C': 0.9108723294857554,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 273661688,
 'sample_weights': [0.08410164359066835, 0.47354088311328013],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.467594395129343,
 'weight_decay_Hydroxylation-K': 1.3062072013100567,
 'weight_decay_S-palmitoylation-C': 2.997436280271479}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.403
[3,     3] loss: 1.397
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028837818343992842,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5870960196756454,
 'loss_weight_S-palmitoylation-C': 0.25320745805229117,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 984807323,
 'sample_weights': [0.9108723294857554, 0.09465483790416462],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.060420565722705,
 'weight_decay_Hydroxylation-K': 1.3460691951798447,
 'weight_decay_S-palmitoylation-C': 9.711075432995269}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.393
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005057769969024959,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.45789017823582034,
 'loss_weight_S-palmitoylation-C': 0.19398740084297517,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2280747565,
 'sample_weights': [0.25320745805229117, 0.5870960196756454],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.267670573218561,
 'weight_decay_Hydroxylation-K': 1.4074052120949094,
 'weight_decay_S-palmitoylation-C': 0.9481047563258462}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.388
[3,     3] loss: 1.387
[4,     3] loss: 1.399
[5,     3] loss: 1.383
[6,     3] loss: 1.371
[7,     3] loss: 1.380
[8,     3] loss: 1.359
[9,     3] loss: 1.284
[10,     3] loss: 1.287
[11,     3] loss: 1.286
[12,     3] loss: 1.280
[13,     3] loss: 1.231
[14,     3] loss: 1.215
[15,     3] loss: 1.174
[16,     3] loss: 1.086
[17,     3] loss: 1.098
[18,     3] loss: 1.314
[19,     3] loss: 1.180
[20,     3] loss: 1.182
[21,     3] loss: 1.211
[22,     3] loss: 1.095
[23,     3] loss: 1.110
[24,     3] loss: 1.109
[25,     3] loss: 1.066
[26,     3] loss: 1.126
[27,     3] loss: 1.062
[28,     3] loss: 1.102
[29,     3] loss: 1.049
[30,     3] loss: 1.035
[31,     3] loss: 1.087
[32,     3] loss: 0.951
[33,     3] loss: 1.197
[34,     3] loss: 1.117
[35,     3] loss: 1.099
[36,     3] loss: 1.015
[37,     3] loss: 1.034
[38,     3] loss: 1.259
[39,     3] loss: 1.049
[40,     3] loss: 1.077
[41,     3] loss: 1.092
[42,     3] loss: 1.008
[43,     3] loss: 0.958
[44,     3] loss: 1.042
[45,     3] loss: 0.858
[46,     3] loss: 0.978
[47,     3] loss: 0.891
[48,     3] loss: 0.994
[49,     3] loss: 1.201
[50,     3] loss: 1.160
[51,     3] loss: 1.098
[52,     3] loss: 1.117
[53,     3] loss: 1.000
[54,     3] loss: 1.032
[55,     3] loss: 0.970
[56,     3] loss: 1.118
[57,     3] loss: 1.053
[58,     3] loss: 1.048
[59,     3] loss: 1.065
[60,     3] loss: 1.093
[61,     3] loss: 0.991
[62,     3] loss: 0.922
Early stopping applied (best metric=0.5224111080169678)
Finished Training
Total time taken: 17.610082387924194
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.384
[3,     3] loss: 1.388
[4,     3] loss: 1.388
[5,     3] loss: 1.385
[6,     3] loss: 1.393
[7,     3] loss: 1.383
[8,     3] loss: 1.376
[9,     3] loss: 1.344
[10,     3] loss: 1.336
[11,     3] loss: 1.263
[12,     3] loss: 1.193
[13,     3] loss: 1.198
[14,     3] loss: 1.073
[15,     3] loss: 1.320
[16,     3] loss: 1.196
[17,     3] loss: 1.235
[18,     3] loss: 1.143
[19,     3] loss: 1.099
[20,     3] loss: 1.183
[21,     3] loss: 1.113
[22,     3] loss: 1.036
[23,     3] loss: 1.067
[24,     3] loss: 0.954
[25,     3] loss: 1.092
[26,     3] loss: 0.968
[27,     3] loss: 0.938
[28,     3] loss: 1.051
[29,     3] loss: 1.699
[30,     3] loss: 1.244
[31,     3] loss: 1.351
[32,     3] loss: 1.308
[33,     3] loss: 1.308
[34,     3] loss: 1.316
[35,     3] loss: 1.298
[36,     3] loss: 1.181
[37,     3] loss: 1.187
[38,     3] loss: 1.200
[39,     3] loss: 1.270
[40,     3] loss: 1.217
[41,     3] loss: 1.282
[42,     3] loss: 1.181
[43,     3] loss: 1.105
[44,     3] loss: 1.069
[45,     3] loss: 1.035
[46,     3] loss: 1.127
[47,     3] loss: 1.088
[48,     3] loss: 1.358
[49,     3] loss: 1.148
[50,     3] loss: 1.078
[51,     3] loss: 1.234
[52,     3] loss: 1.212
[53,     3] loss: 1.135
[54,     3] loss: 1.137
[55,     3] loss: 1.184
[56,     3] loss: 1.098
[57,     3] loss: 1.030
[58,     3] loss: 1.156
[59,     3] loss: 1.115
[60,     3] loss: 1.162
[61,     3] loss: 1.134
[62,     3] loss: 1.069
[63,     3] loss: 0.968
[64,     3] loss: 1.057
[65,     3] loss: 1.079
[66,     3] loss: 1.014
[67,     3] loss: 1.088
[68,     3] loss: 1.099
[69,     3] loss: 1.093
[70,     3] loss: 1.044
Early stopping applied (best metric=0.5316778421401978)
Finished Training
Total time taken: 19.501094579696655
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.388
[3,     3] loss: 1.399
[4,     3] loss: 1.388
[5,     3] loss: 1.381
[6,     3] loss: 1.387
[7,     3] loss: 1.387
[8,     3] loss: 1.390
[9,     3] loss: 1.385
[10,     3] loss: 1.389
[11,     3] loss: 1.386
[12,     3] loss: 1.388
[13,     3] loss: 1.385
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.387
[18,     3] loss: 1.374
[19,     3] loss: 1.376
[20,     3] loss: 1.332
[21,     3] loss: 1.269
[22,     3] loss: 1.185
[23,     3] loss: 1.480
[24,     3] loss: 1.237
[25,     3] loss: 1.252
[26,     3] loss: 1.179
[27,     3] loss: 1.217
[28,     3] loss: 1.080
[29,     3] loss: 1.114
[30,     3] loss: 1.221
[31,     3] loss: 1.088
[32,     3] loss: 1.156
[33,     3] loss: 1.071
[34,     3] loss: 1.147
[35,     3] loss: 1.130
[36,     3] loss: 1.159
[37,     3] loss: 1.170
[38,     3] loss: 1.125
[39,     3] loss: 1.183
[40,     3] loss: 1.050
[41,     3] loss: 1.002
[42,     3] loss: 0.955
[43,     3] loss: 1.047
[44,     3] loss: 1.072
[45,     3] loss: 1.224
[46,     3] loss: 1.080
[47,     3] loss: 1.033
[48,     3] loss: 1.111
[49,     3] loss: 1.099
[50,     3] loss: 1.100
[51,     3] loss: 1.111
[52,     3] loss: 1.097
[53,     3] loss: 1.281
[54,     3] loss: 1.147
[55,     3] loss: 1.068
[56,     3] loss: 1.038
[57,     3] loss: 1.646
[58,     3] loss: 1.305
[59,     3] loss: 1.285
[60,     3] loss: 1.294
[61,     3] loss: 1.258
[62,     3] loss: 1.153
[63,     3] loss: 1.202
[64,     3] loss: 1.140
[65,     3] loss: 1.065
[66,     3] loss: 1.137
[67,     3] loss: 1.224
[68,     3] loss: 1.269
[69,     3] loss: 1.263
[70,     3] loss: 1.273
[71,     3] loss: 1.247
Early stopping applied (best metric=0.5268583297729492)
Finished Training
Total time taken: 19.88109517097473
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.385
[3,     3] loss: 1.400
[4,     3] loss: 1.388
[5,     3] loss: 1.383
[6,     3] loss: 1.383
[7,     3] loss: 1.387
[8,     3] loss: 1.386
[9,     3] loss: 1.382
[10,     3] loss: 1.371
[11,     3] loss: 1.326
[12,     3] loss: 1.337
[13,     3] loss: 1.343
[14,     3] loss: 1.284
[15,     3] loss: 1.235
[16,     3] loss: 1.131
[17,     3] loss: 1.139
[18,     3] loss: 1.961
[19,     3] loss: 1.401
[20,     3] loss: 1.399
[21,     3] loss: 1.387
[22,     3] loss: 1.382
[23,     3] loss: 1.393
[24,     3] loss: 1.378
[25,     3] loss: 1.380
[26,     3] loss: 1.381
[27,     3] loss: 1.372
[28,     3] loss: 1.302
[29,     3] loss: 1.350
[30,     3] loss: 1.295
[31,     3] loss: 1.292
[32,     3] loss: 1.228
[33,     3] loss: 1.275
[34,     3] loss: 1.170
[35,     3] loss: 1.172
[36,     3] loss: 1.239
[37,     3] loss: 1.193
[38,     3] loss: 1.233
[39,     3] loss: 1.131
[40,     3] loss: 1.005
[41,     3] loss: 1.062
[42,     3] loss: 1.292
[43,     3] loss: 1.048
[44,     3] loss: 1.114
[45,     3] loss: 1.187
[46,     3] loss: 0.995
[47,     3] loss: 0.987
[48,     3] loss: 1.124
[49,     3] loss: 1.093
[50,     3] loss: 1.104
[51,     3] loss: 1.127
[52,     3] loss: 1.048
[53,     3] loss: 1.034
[54,     3] loss: 1.016
[55,     3] loss: 0.973
[56,     3] loss: 1.010
[57,     3] loss: 0.985
[58,     3] loss: 0.991
[59,     3] loss: 1.151
[60,     3] loss: 1.127
[61,     3] loss: 1.104
[62,     3] loss: 1.066
[63,     3] loss: 1.101
[64,     3] loss: 1.033
[65,     3] loss: 1.122
[66,     3] loss: 1.029
Early stopping applied (best metric=0.5006526112556458)
Finished Training
Total time taken: 18.4190890789032
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.381
[3,     3] loss: 1.381
[4,     3] loss: 1.392
[5,     3] loss: 1.398
[6,     3] loss: 1.384
[7,     3] loss: 1.388
[8,     3] loss: 1.395
[9,     3] loss: 1.383
[10,     3] loss: 1.382
[11,     3] loss: 1.376
[12,     3] loss: 1.355
[13,     3] loss: 1.299
[14,     3] loss: 1.228
[15,     3] loss: 1.206
[16,     3] loss: 1.091
[17,     3] loss: 1.234
[18,     3] loss: 1.302
[19,     3] loss: 1.233
[20,     3] loss: 1.214
[21,     3] loss: 1.128
[22,     3] loss: 1.116
[23,     3] loss: 1.129
[24,     3] loss: 1.243
[25,     3] loss: 1.167
[26,     3] loss: 1.167
[27,     3] loss: 1.102
[28,     3] loss: 1.043
[29,     3] loss: 0.971
[30,     3] loss: 1.004
[31,     3] loss: 0.975
[32,     3] loss: 1.008
[33,     3] loss: 1.136
[34,     3] loss: 1.098
[35,     3] loss: 1.099
[36,     3] loss: 0.967
[37,     3] loss: 0.929
[38,     3] loss: 0.848
[39,     3] loss: 1.533
[40,     3] loss: 1.298
[41,     3] loss: 1.307
[42,     3] loss: 1.365
[43,     3] loss: 1.336
[44,     3] loss: 1.373
[45,     3] loss: 1.357
[46,     3] loss: 1.274
[47,     3] loss: 1.298
[48,     3] loss: 1.251
[49,     3] loss: 1.162
[50,     3] loss: 1.164
[51,     3] loss: 1.094
[52,     3] loss: 1.112
[53,     3] loss: 1.473
[54,     3] loss: 1.392
[55,     3] loss: 1.365
[56,     3] loss: 1.368
[57,     3] loss: 1.357
[58,     3] loss: 1.343
[59,     3] loss: 1.324
[60,     3] loss: 1.465
[61,     3] loss: 1.400
[62,     3] loss: 1.399
[63,     3] loss: 1.384
[64,     3] loss: 1.392
Early stopping applied (best metric=0.5033207535743713)
Finished Training
Total time taken: 17.766088008880615
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.389
[3,     3] loss: 1.374
[4,     3] loss: 1.394
[5,     3] loss: 1.381
[6,     3] loss: 1.377
[7,     3] loss: 1.334
[8,     3] loss: 1.334
[9,     3] loss: 1.311
[10,     3] loss: 1.235
[11,     3] loss: 1.311
[12,     3] loss: 1.165
[13,     3] loss: 1.158
[14,     3] loss: 1.061
[15,     3] loss: 1.081
[16,     3] loss: 1.140
[17,     3] loss: 1.280
[18,     3] loss: 1.200
[19,     3] loss: 1.189
[20,     3] loss: 1.167
[21,     3] loss: 1.104
[22,     3] loss: 1.064
[23,     3] loss: 1.134
[24,     3] loss: 1.230
[25,     3] loss: 1.183
[26,     3] loss: 1.102
[27,     3] loss: 1.054
[28,     3] loss: 1.113
[29,     3] loss: 1.087
[30,     3] loss: 1.048
[31,     3] loss: 1.070
[32,     3] loss: 0.949
[33,     3] loss: 1.011
[34,     3] loss: 1.296
[35,     3] loss: 1.109
[36,     3] loss: 1.189
[37,     3] loss: 1.003
[38,     3] loss: 1.039
[39,     3] loss: 1.202
[40,     3] loss: 1.134
[41,     3] loss: 1.124
[42,     3] loss: 1.065
[43,     3] loss: 1.192
[44,     3] loss: 1.143
[45,     3] loss: 1.317
[46,     3] loss: 1.227
[47,     3] loss: 1.237
[48,     3] loss: 1.244
[49,     3] loss: 1.139
[50,     3] loss: 1.069
[51,     3] loss: 1.044
[52,     3] loss: 0.964
[53,     3] loss: 1.056
[54,     3] loss: 0.998
[55,     3] loss: 1.040
[56,     3] loss: 1.108
[57,     3] loss: 1.044
[58,     3] loss: 1.012
[59,     3] loss: 0.960
[60,     3] loss: 1.086
[61,     3] loss: 1.292
[62,     3] loss: 1.169
[63,     3] loss: 1.317
[64,     3] loss: 1.210
Early stopping applied (best metric=0.5450599193572998)
Finished Training
Total time taken: 17.76308536529541
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.400
[3,     3] loss: 1.387
[4,     3] loss: 1.384
[5,     3] loss: 1.387
[6,     3] loss: 1.396
[7,     3] loss: 1.388
[8,     3] loss: 1.382
[9,     3] loss: 1.385
[10,     3] loss: 1.384
[11,     3] loss: 1.381
[12,     3] loss: 1.380
[13,     3] loss: 1.351
[14,     3] loss: 1.379
[15,     3] loss: 1.290
[16,     3] loss: 1.192
[17,     3] loss: 1.285
[18,     3] loss: 1.414
[19,     3] loss: 1.322
[20,     3] loss: 1.258
[21,     3] loss: 1.289
[22,     3] loss: 1.248
[23,     3] loss: 1.276
[24,     3] loss: 1.333
[25,     3] loss: 1.207
[26,     3] loss: 1.221
[27,     3] loss: 1.236
[28,     3] loss: 1.302
[29,     3] loss: 1.108
[30,     3] loss: 1.084
[31,     3] loss: 1.135
[32,     3] loss: 1.138
[33,     3] loss: 1.076
[34,     3] loss: 1.113
[35,     3] loss: 1.071
[36,     3] loss: 1.081
[37,     3] loss: 1.062
[38,     3] loss: 1.061
[39,     3] loss: 1.168
[40,     3] loss: 1.081
[41,     3] loss: 1.094
[42,     3] loss: 0.940
[43,     3] loss: 0.916
[44,     3] loss: 1.169
[45,     3] loss: 0.984
[46,     3] loss: 1.091
[47,     3] loss: 0.985
[48,     3] loss: 1.003
[49,     3] loss: 0.884
[50,     3] loss: 1.045
[51,     3] loss: 1.043
[52,     3] loss: 1.188
[53,     3] loss: 1.093
[54,     3] loss: 1.045
[55,     3] loss: 1.102
[56,     3] loss: 0.969
[57,     3] loss: 0.891
[58,     3] loss: 0.879
[59,     3] loss: 1.468
[60,     3] loss: 1.485
[61,     3] loss: 1.345
[62,     3] loss: 1.377
[63,     3] loss: 1.383
[64,     3] loss: 1.386
[65,     3] loss: 1.387
[66,     3] loss: 1.387
[67,     3] loss: 1.384
[68,     3] loss: 1.384
[69,     3] loss: 1.384
[70,     3] loss: 1.385
[71,     3] loss: 1.384
[72,     3] loss: 1.386
[73,     3] loss: 1.384
[74,     3] loss: 1.385
[75,     3] loss: 1.382
Early stopping applied (best metric=0.5227054953575134)
Finished Training
Total time taken: 21.45610022544861
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.372
[3,     3] loss: 1.380
[4,     3] loss: 1.406
[5,     3] loss: 1.378
[6,     3] loss: 1.381
[7,     3] loss: 1.387
[8,     3] loss: 1.389
[9,     3] loss: 1.385
[10,     3] loss: 1.379
[11,     3] loss: 1.380
[12,     3] loss: 1.372
[13,     3] loss: 1.347
[14,     3] loss: 1.281
[15,     3] loss: 1.219
[16,     3] loss: 1.359
[17,     3] loss: 1.176
[18,     3] loss: 1.301
[19,     3] loss: 1.275
[20,     3] loss: 1.202
[21,     3] loss: 1.131
[22,     3] loss: 1.140
[23,     3] loss: 1.136
[24,     3] loss: 1.077
[25,     3] loss: 1.125
[26,     3] loss: 1.064
[27,     3] loss: 1.009
[28,     3] loss: 0.996
[29,     3] loss: 0.990
[30,     3] loss: 1.119
[31,     3] loss: 1.229
[32,     3] loss: 1.170
[33,     3] loss: 1.148
[34,     3] loss: 1.022
[35,     3] loss: 1.190
[36,     3] loss: 1.208
[37,     3] loss: 1.185
[38,     3] loss: 1.149
[39,     3] loss: 1.130
[40,     3] loss: 1.058
[41,     3] loss: 1.043
[42,     3] loss: 0.994
[43,     3] loss: 0.872
[44,     3] loss: 0.809
[45,     3] loss: 0.802
[46,     3] loss: 1.289
[47,     3] loss: 1.235
[48,     3] loss: 1.223
[49,     3] loss: 1.214
[50,     3] loss: 1.266
[51,     3] loss: 1.185
[52,     3] loss: 1.247
[53,     3] loss: 1.124
[54,     3] loss: 1.033
[55,     3] loss: 1.023
[56,     3] loss: 1.049
[57,     3] loss: 0.913
[58,     3] loss: 0.859
[59,     3] loss: 1.022
[60,     3] loss: 0.940
[61,     3] loss: 0.939
[62,     3] loss: 1.028
[63,     3] loss: 0.918
[64,     3] loss: 0.954
[65,     3] loss: 0.926
[66,     3] loss: 0.846
[67,     3] loss: 1.147
[68,     3] loss: 0.911
[69,     3] loss: 0.927
[70,     3] loss: 0.942
[71,     3] loss: 0.913
[72,     3] loss: 0.917
Early stopping applied (best metric=0.5324341058731079)
Finished Training
Total time taken: 20.0960955619812
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.383
[3,     3] loss: 1.382
[4,     3] loss: 1.404
[5,     3] loss: 1.387
[6,     3] loss: 1.400
[7,     3] loss: 1.385
[8,     3] loss: 1.382
[9,     3] loss: 1.391
[10,     3] loss: 1.377
[11,     3] loss: 1.348
[12,     3] loss: 1.302
[13,     3] loss: 1.303
[14,     3] loss: 1.179
[15,     3] loss: 1.147
[16,     3] loss: 1.349
[17,     3] loss: 1.330
[18,     3] loss: 1.238
[19,     3] loss: 1.245
[20,     3] loss: 1.188
[21,     3] loss: 1.139
[22,     3] loss: 1.125
[23,     3] loss: 1.110
[24,     3] loss: 1.030
[25,     3] loss: 0.947
[26,     3] loss: 1.174
[27,     3] loss: 1.108
[28,     3] loss: 1.192
[29,     3] loss: 1.227
[30,     3] loss: 1.155
[31,     3] loss: 1.030
[32,     3] loss: 1.015
[33,     3] loss: 1.074
[34,     3] loss: 1.022
[35,     3] loss: 1.011
[36,     3] loss: 0.958
[37,     3] loss: 0.900
[38,     3] loss: 0.948
[39,     3] loss: 1.645
[40,     3] loss: 1.279
[41,     3] loss: 1.306
[42,     3] loss: 1.262
[43,     3] loss: 1.222
[44,     3] loss: 1.207
[45,     3] loss: 1.176
[46,     3] loss: 1.153
[47,     3] loss: 1.161
[48,     3] loss: 1.146
[49,     3] loss: 1.307
[50,     3] loss: 1.094
[51,     3] loss: 1.224
[52,     3] loss: 1.155
[53,     3] loss: 1.066
[54,     3] loss: 0.987
[55,     3] loss: 0.988
[56,     3] loss: 1.134
[57,     3] loss: 0.986
[58,     3] loss: 1.293
[59,     3] loss: 1.153
[60,     3] loss: 1.120
[61,     3] loss: 1.067
[62,     3] loss: 1.074
[63,     3] loss: 1.134
[64,     3] loss: 0.990
[65,     3] loss: 1.022
[66,     3] loss: 0.893
[67,     3] loss: 0.851
[68,     3] loss: 0.863
[69,     3] loss: 1.790
[70,     3] loss: 1.324
[71,     3] loss: 1.331
[72,     3] loss: 1.357
[73,     3] loss: 1.348
[74,     3] loss: 1.328
[75,     3] loss: 1.288
Early stopping applied (best metric=0.5009000301361084)
Finished Training
Total time taken: 20.998099088668823
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.387
[3,     3] loss: 1.380
[4,     3] loss: 1.361
[5,     3] loss: 1.373
[6,     3] loss: 1.401
[7,     3] loss: 1.406
[8,     3] loss: 1.381
[9,     3] loss: 1.370
[10,     3] loss: 1.305
[11,     3] loss: 1.298
[12,     3] loss: 1.232
[13,     3] loss: 1.324
[14,     3] loss: 1.405
[15,     3] loss: 1.320
[16,     3] loss: 1.262
[17,     3] loss: 1.168
[18,     3] loss: 1.233
[19,     3] loss: 1.253
[20,     3] loss: 1.221
[21,     3] loss: 1.087
[22,     3] loss: 1.068
[23,     3] loss: 1.352
[24,     3] loss: 1.125
[25,     3] loss: 1.198
[26,     3] loss: 1.196
[27,     3] loss: 1.142
[28,     3] loss: 1.115
[29,     3] loss: 1.258
[30,     3] loss: 1.061
[31,     3] loss: 1.068
[32,     3] loss: 1.001
[33,     3] loss: 1.304
[34,     3] loss: 1.101
[35,     3] loss: 1.134
[36,     3] loss: 1.133
[37,     3] loss: 1.123
[38,     3] loss: 1.048
[39,     3] loss: 0.995
[40,     3] loss: 0.940
[41,     3] loss: 1.030
[42,     3] loss: 1.042
[43,     3] loss: 0.990
[44,     3] loss: 1.151
[45,     3] loss: 1.091
[46,     3] loss: 1.124
[47,     3] loss: 1.062
[48,     3] loss: 0.988
[49,     3] loss: 0.955
[50,     3] loss: 0.842
[51,     3] loss: 0.916
[52,     3] loss: 0.958
[53,     3] loss: 0.931
[54,     3] loss: 0.984
[55,     3] loss: 1.106
[56,     3] loss: 1.064
[57,     3] loss: 1.016
[58,     3] loss: 1.044
[59,     3] loss: 0.948
[60,     3] loss: 0.963
[61,     3] loss: 0.919
[62,     3] loss: 0.909
[63,     3] loss: 0.881
[64,     3] loss: 1.178
[65,     3] loss: 1.193
[66,     3] loss: 1.246
[67,     3] loss: 1.218
[68,     3] loss: 1.258
[69,     3] loss: 1.093
[70,     3] loss: 0.957
[71,     3] loss: 1.025
Early stopping applied (best metric=0.5186833739280701)
Finished Training
Total time taken: 19.647093772888184
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.405
[2,     3] loss: 1.390
[3,     3] loss: 1.391
[4,     3] loss: 1.386
[5,     3] loss: 1.385
[6,     3] loss: 1.389
[7,     3] loss: 1.379
[8,     3] loss: 1.391
[9,     3] loss: 1.389
[10,     3] loss: 1.380
[11,     3] loss: 1.375
[12,     3] loss: 1.357
[13,     3] loss: 1.310
[14,     3] loss: 1.207
[15,     3] loss: 1.176
[16,     3] loss: 1.198
[17,     3] loss: 1.120
[18,     3] loss: 1.114
[19,     3] loss: 1.011
[20,     3] loss: 1.030
[21,     3] loss: 1.119
[22,     3] loss: 1.098
[23,     3] loss: 1.172
[24,     3] loss: 1.077
[25,     3] loss: 1.117
[26,     3] loss: 1.093
[27,     3] loss: 0.985
[28,     3] loss: 1.031
[29,     3] loss: 0.955
[30,     3] loss: 0.936
[31,     3] loss: 1.012
[32,     3] loss: 0.938
[33,     3] loss: 0.995
[34,     3] loss: 0.976
[35,     3] loss: 1.324
[36,     3] loss: 1.265
[37,     3] loss: 1.174
[38,     3] loss: 1.019
[39,     3] loss: 1.058
[40,     3] loss: 1.998
[41,     3] loss: 1.355
[42,     3] loss: 1.238
[43,     3] loss: 1.279
[44,     3] loss: 1.197
[45,     3] loss: 1.211
[46,     3] loss: 1.270
[47,     3] loss: 1.286
[48,     3] loss: 1.081
[49,     3] loss: 1.253
[50,     3] loss: 1.012
[51,     3] loss: 1.154
[52,     3] loss: 1.118
[53,     3] loss: 1.014
[54,     3] loss: 1.023
[55,     3] loss: 1.181
[56,     3] loss: 1.102
[57,     3] loss: 1.238
[58,     3] loss: 1.257
[59,     3] loss: 1.127
[60,     3] loss: 1.110
[61,     3] loss: 1.015
[62,     3] loss: 1.084
[63,     3] loss: 1.020
[64,     3] loss: 1.077
[65,     3] loss: 1.017
[66,     3] loss: 1.144
[67,     3] loss: 1.137
[68,     3] loss: 1.032
[69,     3] loss: 1.029
[70,     3] loss: 1.037
[71,     3] loss: 1.044
[72,     3] loss: 0.933
[73,     3] loss: 0.988
[74,     3] loss: 1.181
[75,     3] loss: 1.030
[76,     3] loss: 1.138
[77,     3] loss: 1.137
[78,     3] loss: 1.066
[79,     3] loss: 0.948
[80,     3] loss: 1.286
[81,     3] loss: 1.137
[82,     3] loss: 1.070
[83,     3] loss: 1.081
[84,     3] loss: 1.003
[85,     3] loss: 0.984
[86,     3] loss: 1.024
[87,     3] loss: 0.944
[88,     3] loss: 0.932
[89,     3] loss: 0.997
[90,     3] loss: 0.991
[91,     3] loss: 0.959
[92,     3] loss: 1.046
[93,     3] loss: 1.275
[94,     3] loss: 1.210
[95,     3] loss: 1.154
[96,     3] loss: 1.153
[97,     3] loss: 1.131
[98,     3] loss: 1.021
[99,     3] loss: 1.024
[100,     3] loss: 1.167
[101,     3] loss: 1.005
[102,     3] loss: 1.022
[103,     3] loss: 0.990
[104,     3] loss: 1.051
[105,     3] loss: 0.918
[106,     3] loss: 0.992
[107,     3] loss: 0.970
[108,     3] loss: 0.933
[109,     3] loss: 0.974
[110,     3] loss: 1.043
[111,     3] loss: 1.538
Early stopping applied (best metric=0.5424827933311462)
Finished Training
Total time taken: 30.13914465904236
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.384
[3,     3] loss: 1.391
[4,     3] loss: 1.380
[5,     3] loss: 1.382
[6,     3] loss: 1.405
[7,     3] loss: 1.379
[8,     3] loss: 1.385
[9,     3] loss: 1.387
[10,     3] loss: 1.389
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.388
[14,     3] loss: 1.385
[15,     3] loss: 1.385
[16,     3] loss: 1.380
[17,     3] loss: 1.371
[18,     3] loss: 1.310
[19,     3] loss: 1.318
[20,     3] loss: 1.292
[21,     3] loss: 1.268
[22,     3] loss: 1.205
[23,     3] loss: 1.152
[24,     3] loss: 1.250
[25,     3] loss: 1.186
[26,     3] loss: 1.173
[27,     3] loss: 1.130
[28,     3] loss: 1.213
[29,     3] loss: 1.069
[30,     3] loss: 1.149
[31,     3] loss: 1.132
[32,     3] loss: 1.088
[33,     3] loss: 1.062
[34,     3] loss: 1.240
[35,     3] loss: 1.133
[36,     3] loss: 1.162
[37,     3] loss: 1.191
[38,     3] loss: 1.135
[39,     3] loss: 1.213
[40,     3] loss: 1.072
[41,     3] loss: 1.138
[42,     3] loss: 1.120
[43,     3] loss: 1.011
[44,     3] loss: 0.983
[45,     3] loss: 0.932
[46,     3] loss: 1.027
[47,     3] loss: 1.159
[48,     3] loss: 1.150
[49,     3] loss: 1.131
[50,     3] loss: 1.101
[51,     3] loss: 0.975
[52,     3] loss: 1.040
[53,     3] loss: 0.919
[54,     3] loss: 0.898
[55,     3] loss: 1.168
[56,     3] loss: 1.129
[57,     3] loss: 1.157
[58,     3] loss: 1.145
[59,     3] loss: 1.086
[60,     3] loss: 1.099
[61,     3] loss: 1.007
[62,     3] loss: 1.044
[63,     3] loss: 1.037
[64,     3] loss: 0.951
[65,     3] loss: 1.144
[66,     3] loss: 1.111
[67,     3] loss: 1.081
[68,     3] loss: 1.046
[69,     3] loss: 1.041
[70,     3] loss: 0.920
[71,     3] loss: 0.936
[72,     3] loss: 1.005
[73,     3] loss: 0.967
[74,     3] loss: 0.975
Early stopping applied (best metric=0.5411350131034851)
Finished Training
Total time taken: 20.290855407714844
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.387
[4,     3] loss: 1.390
[5,     3] loss: 1.390
[6,     3] loss: 1.385
[7,     3] loss: 1.383
[8,     3] loss: 1.376
[9,     3] loss: 1.367
[10,     3] loss: 1.339
[11,     3] loss: 1.249
[12,     3] loss: 1.345
[13,     3] loss: 1.205
[14,     3] loss: 1.172
[15,     3] loss: 1.140
[16,     3] loss: 1.206
[17,     3] loss: 1.051
[18,     3] loss: 1.048
[19,     3] loss: 1.016
[20,     3] loss: 1.019
[21,     3] loss: 1.084
[22,     3] loss: 1.535
[23,     3] loss: 1.388
[24,     3] loss: 1.368
[25,     3] loss: 1.379
[26,     3] loss: 1.377
[27,     3] loss: 1.373
[28,     3] loss: 1.365
[29,     3] loss: 1.344
[30,     3] loss: 1.328
[31,     3] loss: 1.335
[32,     3] loss: 1.318
[33,     3] loss: 1.345
[34,     3] loss: 1.329
[35,     3] loss: 1.384
[36,     3] loss: 1.369
[37,     3] loss: 1.390
[38,     3] loss: 1.377
[39,     3] loss: 1.402
[40,     3] loss: 1.381
[41,     3] loss: 1.376
[42,     3] loss: 1.375
[43,     3] loss: 1.370
[44,     3] loss: 1.360
[45,     3] loss: 1.317
[46,     3] loss: 1.318
[47,     3] loss: 1.279
[48,     3] loss: 1.201
[49,     3] loss: 1.257
[50,     3] loss: 1.245
[51,     3] loss: 1.293
[52,     3] loss: 1.304
[53,     3] loss: 1.193
[54,     3] loss: 1.195
[55,     3] loss: 1.032
[56,     3] loss: 1.170
[57,     3] loss: 1.078
[58,     3] loss: 1.069
[59,     3] loss: 1.032
[60,     3] loss: 1.048
[61,     3] loss: 1.027
[62,     3] loss: 1.068
[63,     3] loss: 0.957
[64,     3] loss: 0.922
[65,     3] loss: 1.132
[66,     3] loss: 1.068
[67,     3] loss: 1.073
[68,     3] loss: 1.311
Early stopping applied (best metric=0.545026421546936)
Finished Training
Total time taken: 18.58108639717102
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.379
[3,     3] loss: 1.389
[4,     3] loss: 1.391
[5,     3] loss: 1.389
[6,     3] loss: 1.389
[7,     3] loss: 1.387
[8,     3] loss: 1.389
[9,     3] loss: 1.381
[10,     3] loss: 1.383
[11,     3] loss: 1.378
[12,     3] loss: 1.414
[13,     3] loss: 1.386
[14,     3] loss: 1.385
[15,     3] loss: 1.389
[16,     3] loss: 1.385
[17,     3] loss: 1.384
[18,     3] loss: 1.386
[19,     3] loss: 1.379
[20,     3] loss: 1.365
[21,     3] loss: 1.336
[22,     3] loss: 1.298
[23,     3] loss: 1.336
[24,     3] loss: 1.276
[25,     3] loss: 1.212
[26,     3] loss: 1.232
[27,     3] loss: 1.194
[28,     3] loss: 1.231
[29,     3] loss: 1.172
[30,     3] loss: 1.121
[31,     3] loss: 1.039
[32,     3] loss: 1.358
[33,     3] loss: 1.162
[34,     3] loss: 1.309
[35,     3] loss: 1.267
[36,     3] loss: 1.184
[37,     3] loss: 1.117
[38,     3] loss: 1.097
[39,     3] loss: 1.177
[40,     3] loss: 1.120
[41,     3] loss: 1.260
[42,     3] loss: 1.160
[43,     3] loss: 1.152
[44,     3] loss: 1.076
[45,     3] loss: 1.017
[46,     3] loss: 1.159
[47,     3] loss: 1.063
[48,     3] loss: 1.189
[49,     3] loss: 1.180
[50,     3] loss: 1.067
[51,     3] loss: 1.015
[52,     3] loss: 1.066
[53,     3] loss: 0.998
[54,     3] loss: 1.033
[55,     3] loss: 1.038
[56,     3] loss: 1.032
[57,     3] loss: 0.986
[58,     3] loss: 1.050
[59,     3] loss: 1.220
[60,     3] loss: 1.125
[61,     3] loss: 1.124
[62,     3] loss: 1.080
[63,     3] loss: 1.032
[64,     3] loss: 0.967
[65,     3] loss: 0.904
[66,     3] loss: 0.894
[67,     3] loss: 0.955
[68,     3] loss: 0.957
[69,     3] loss: 1.041
[70,     3] loss: 0.943
[71,     3] loss: 1.122
[72,     3] loss: 1.033
[73,     3] loss: 1.074
[74,     3] loss: 0.960
[75,     3] loss: 1.077
[76,     3] loss: 1.017
[77,     3] loss: 1.159
[78,     3] loss: 1.070
[79,     3] loss: 1.022
[80,     3] loss: 0.924
[81,     3] loss: 0.874
[82,     3] loss: 1.163
[83,     3] loss: 1.076
[84,     3] loss: 1.141
[85,     3] loss: 1.035
[86,     3] loss: 1.048
[87,     3] loss: 0.955
[88,     3] loss: 1.002
[89,     3] loss: 0.915
[90,     3] loss: 0.935
[91,     3] loss: 0.904
[92,     3] loss: 0.873
[93,     3] loss: 0.860
[94,     3] loss: 1.478
[95,     3] loss: 1.377
[96,     3] loss: 1.408
[97,     3] loss: 1.386
[98,     3] loss: 1.384
[99,     3] loss: 1.382
[100,     3] loss: 1.384
[101,     3] loss: 1.391
[102,     3] loss: 1.383
Early stopping applied (best metric=0.501346230506897)
Finished Training
Total time taken: 27.393131732940674
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.388
[3,     3] loss: 1.381
[4,     3] loss: 1.376
[5,     3] loss: 1.378
[6,     3] loss: 1.363
[7,     3] loss: 1.297
[8,     3] loss: 1.302
[9,     3] loss: 1.375
[10,     3] loss: 1.302
[11,     3] loss: 1.264
[12,     3] loss: 1.254
[13,     3] loss: 1.277
[14,     3] loss: 1.207
[15,     3] loss: 1.164
[16,     3] loss: 1.243
[17,     3] loss: 1.314
[18,     3] loss: 1.245
[19,     3] loss: 1.255
[20,     3] loss: 1.230
[21,     3] loss: 1.125
[22,     3] loss: 1.122
[23,     3] loss: 1.265
[24,     3] loss: 1.197
[25,     3] loss: 1.152
[26,     3] loss: 1.157
[27,     3] loss: 1.080
[28,     3] loss: 1.043
[29,     3] loss: 1.221
[30,     3] loss: 1.177
[31,     3] loss: 1.202
[32,     3] loss: 1.188
[33,     3] loss: 1.208
[34,     3] loss: 1.094
[35,     3] loss: 1.140
[36,     3] loss: 1.068
[37,     3] loss: 1.269
[38,     3] loss: 1.211
[39,     3] loss: 1.114
[40,     3] loss: 1.100
[41,     3] loss: 1.139
[42,     3] loss: 1.140
[43,     3] loss: 1.071
[44,     3] loss: 0.939
[45,     3] loss: 1.001
[46,     3] loss: 1.213
[47,     3] loss: 1.028
[48,     3] loss: 1.137
[49,     3] loss: 1.089
[50,     3] loss: 1.042
[51,     3] loss: 1.023
[52,     3] loss: 1.246
[53,     3] loss: 1.151
[54,     3] loss: 1.151
[55,     3] loss: 1.169
[56,     3] loss: 1.162
[57,     3] loss: 1.034
[58,     3] loss: 0.923
[59,     3] loss: 0.874
[60,     3] loss: 0.944
[61,     3] loss: 1.247
[62,     3] loss: 1.097
[63,     3] loss: 1.060
[64,     3] loss: 1.045
[65,     3] loss: 1.005
[66,     3] loss: 1.068
[67,     3] loss: 0.995
[68,     3] loss: 1.051
[69,     3] loss: 1.010
[70,     3] loss: 1.067
[71,     3] loss: 0.928
[72,     3] loss: 0.901
[73,     3] loss: 0.954
[74,     3] loss: 0.970
[75,     3] loss: 0.993
[76,     3] loss: 1.166
[77,     3] loss: 1.191
[78,     3] loss: 1.061
[79,     3] loss: 0.980
[80,     3] loss: 1.072
[81,     3] loss: 1.055
[82,     3] loss: 0.973
[83,     3] loss: 0.968
[84,     3] loss: 0.963
[85,     3] loss: 0.915
[86,     3] loss: 1.064
[87,     3] loss: 1.137
[88,     3] loss: 1.066
[89,     3] loss: 1.033
[90,     3] loss: 0.951
[91,     3] loss: 0.906
[92,     3] loss: 1.021
[93,     3] loss: 0.844
[94,     3] loss: 0.919
[95,     3] loss: 0.915
Early stopping applied (best metric=0.5007561445236206)
Finished Training
Total time taken: 26.4231276512146
{'S-palmitoylation-C Validation Accuracy': 0.6545394367883451, 'S-palmitoylation-C Validation Sensitivity': 0.27999999999999997, 'S-palmitoylation-C Validation Specificity': 0.7484184899253612, 'S-palmitoylation-C Validation Precision': 0.23216446323501086, 'S-palmitoylation-C AUC ROC': 0.5341721947790423, 'S-palmitoylation-C AUC PR': 0.2187673631120141, 'S-palmitoylation-C MCC': 0.031066789256428314, 'S-palmitoylation-C F1': 0.2236986443028873, 'Validation Loss (S-palmitoylation-C)': 0.5551521062850953, 'Hydroxylation-K Validation Accuracy': 0.670774231678487, 'Hydroxylation-K Validation Sensitivity': 0.8007407407407408, 'Hydroxylation-K Validation Specificity': 0.6385964912280702, 'Hydroxylation-K Validation Precision': 0.37964346464461346, 'Hydroxylation-K AUC ROC': 0.8082261208576998, 'Hydroxylation-K AUC PR': 0.5559112705575407, 'Hydroxylation-K MCC': 0.3706098730950209, 'Hydroxylation-K F1': 0.5017131173921324, 'Validation Loss (Hydroxylation-K)': 0.5223633448282877, 'Validation Loss (total)': 1.077515443166097, 'TimeToTrain': 21.064351272583007}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001991624161433724,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.884034203759529,
 'loss_weight_S-palmitoylation-C': 0.06269550766162693,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3054571652,
 'sample_weights': [0.19398740084297517, 0.45789017823582034],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7406266168955344,
 'weight_decay_Hydroxylation-K': 3.132176830476914,
 'weight_decay_S-palmitoylation-C': 9.080766205445245}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.384
[3,     3] loss: 1.382
[4,     3] loss: 1.380
[5,     3] loss: 1.376
[6,     3] loss: 1.383
[7,     3] loss: 1.359
[8,     3] loss: 1.358
[9,     3] loss: 1.327
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004578367197355825,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4152208527982057,
 'loss_weight_S-palmitoylation-C': 0.17042993881579846,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3862291398,
 'sample_weights': [0.06269550766162693, 0.884034203759529],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.232138323946533,
 'weight_decay_Hydroxylation-K': 0.7285194096046845,
 'weight_decay_S-palmitoylation-C': 1.8945958895148487}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.390
[3,     3] loss: 1.395
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005311914578147814,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7723462084228765,
 'loss_weight_S-palmitoylation-C': 0.3053447753917142,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1905884470,
 'sample_weights': [0.17042993881579846, 0.4152208527982057],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.713857164728864,
 'weight_decay_Hydroxylation-K': 0.9397822085589173,
 'weight_decay_S-palmitoylation-C': 0.198101384887988}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.393
[3,     3] loss: 1.376
[4,     3] loss: 1.396
[5,     3] loss: 1.381
[6,     3] loss: 1.373
[7,     3] loss: 1.363
[8,     3] loss: 1.378
[9,     3] loss: 1.296
[10,     3] loss: 1.254
[11,     3] loss: 1.267
[12,     3] loss: 1.105
[13,     3] loss: 1.368
[14,     3] loss: 1.208
[15,     3] loss: 1.239
[16,     3] loss: 1.139
[17,     3] loss: 1.154
[18,     3] loss: 1.112
[19,     3] loss: 1.001
[20,     3] loss: 1.115
[21,     3] loss: 1.010
[22,     3] loss: 1.010
[23,     3] loss: 1.132
[24,     3] loss: 0.931
[25,     3] loss: 1.086
[26,     3] loss: 1.040
[27,     3] loss: 1.010
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032495236381310196,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.896410805041548,
 'loss_weight_S-palmitoylation-C': 0.21645422381151108,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2326716131,
 'sample_weights': [0.3053447753917142, 0.7723462084228765],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.4009233556655,
 'weight_decay_Hydroxylation-K': 0.43333269932736385,
 'weight_decay_S-palmitoylation-C': 1.3246804861082149}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.388
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011201061910726916,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8242112371251347,
 'loss_weight_S-palmitoylation-C': 0.0671895951629003,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2533963604,
 'sample_weights': [0.21645422381151108, 0.896410805041548],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.194348569610712,
 'weight_decay_Hydroxylation-K': 3.785448485771277,
 'weight_decay_S-palmitoylation-C': 3.84418922898689}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.378
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027466432436645634,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8329700454214393,
 'loss_weight_S-palmitoylation-C': 0.6877538167732523,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1232042523,
 'sample_weights': [0.0671895951629003, 0.8242112371251347],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8991785470585734,
 'weight_decay_Hydroxylation-K': 5.86677307435798,
 'weight_decay_S-palmitoylation-C': 3.714289335869476}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.390
[3,     3] loss: 1.396
[4,     3] loss: 1.389
[5,     3] loss: 1.389
[6,     3] loss: 1.386
[7,     3] loss: 1.389
[8,     3] loss: 1.386
[9,     3] loss: 1.385
[10,     3] loss: 1.384
[11,     3] loss: 1.389
[12,     3] loss: 1.385
[13,     3] loss: 1.384
[14,     3] loss: 1.381
[15,     3] loss: 1.385
[16,     3] loss: 1.375
[17,     3] loss: 1.390
[18,     3] loss: 1.377
[19,     3] loss: 1.384
[20,     3] loss: 1.379
[21,     3] loss: 1.381
[22,     3] loss: 1.372
[23,     3] loss: 1.365
[24,     3] loss: 1.356
[25,     3] loss: 1.322
[26,     3] loss: 1.346
[27,     3] loss: 1.272
[28,     3] loss: 1.223
[29,     3] loss: 1.233
[30,     3] loss: 1.191
[31,     3] loss: 1.136
[32,     3] loss: 1.137
[33,     3] loss: 1.056
[34,     3] loss: 1.062
[35,     3] loss: 1.157
[36,     3] loss: 1.053
[37,     3] loss: 1.032
[38,     3] loss: 1.012
[39,     3] loss: 0.954
[40,     3] loss: 0.951
[41,     3] loss: 0.994
[42,     3] loss: 0.968
[43,     3] loss: 0.924
[44,     3] loss: 1.035
[45,     3] loss: 0.954
[46,     3] loss: 1.002
[47,     3] loss: 0.996
[48,     3] loss: 0.916
[49,     3] loss: 0.985
[50,     3] loss: 0.954
[51,     3] loss: 0.929
[52,     3] loss: 0.967
[53,     3] loss: 0.966
[54,     3] loss: 0.922
[55,     3] loss: 0.950
[56,     3] loss: 0.890
[57,     3] loss: 0.945
[58,     3] loss: 0.841
[59,     3] loss: 0.917
[60,     3] loss: 0.820
[61,     3] loss: 0.857
[62,     3] loss: 0.833
[63,     3] loss: 0.824
[64,     3] loss: 0.855
[65,     3] loss: 0.789
[66,     3] loss: 0.791
[67,     3] loss: 0.781
[68,     3] loss: 0.752
[69,     3] loss: 0.764
[70,     3] loss: 0.881
[71,     3] loss: 0.818
[72,     3] loss: 0.859
[73,     3] loss: 0.831
[74,     3] loss: 0.803
[75,     3] loss: 0.798
[76,     3] loss: 0.879
[77,     3] loss: 0.811
[78,     3] loss: 0.828
[79,     3] loss: 0.848
[80,     3] loss: 0.847
[81,     3] loss: 0.807
[82,     3] loss: 0.797
[83,     3] loss: 0.766
[84,     3] loss: 0.806
[85,     3] loss: 0.792
[86,     3] loss: 0.762
[87,     3] loss: 0.785
[88,     3] loss: 0.756
[89,     3] loss: 0.778
[90,     3] loss: 0.748
[91,     3] loss: 0.782
[92,     3] loss: 0.753
[93,     3] loss: 0.739
[94,     3] loss: 0.783
[95,     3] loss: 0.743
[96,     3] loss: 0.745
[97,     3] loss: 0.761
[98,     3] loss: 0.740
[99,     3] loss: 0.745
[100,     3] loss: 0.753
[101,     3] loss: 0.739
[102,     3] loss: 0.722
[103,     3] loss: 0.725
[104,     3] loss: 0.740
[105,     3] loss: 0.753
Early stopping applied (best metric=0.5206432938575745)
Finished Training
Total time taken: 29.260138750076294
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.389
[3,     3] loss: 1.386
[4,     3] loss: 1.391
[5,     3] loss: 1.394
[6,     3] loss: 1.395
[7,     3] loss: 1.380
[8,     3] loss: 1.388
[9,     3] loss: 1.388
[10,     3] loss: 1.382
[11,     3] loss: 1.381
[12,     3] loss: 1.390
[13,     3] loss: 1.385
[14,     3] loss: 1.392
[15,     3] loss: 1.379
[16,     3] loss: 1.381
[17,     3] loss: 1.378
[18,     3] loss: 1.380
[19,     3] loss: 1.371
[20,     3] loss: 1.369
[21,     3] loss: 1.368
[22,     3] loss: 1.342
[23,     3] loss: 1.332
[24,     3] loss: 1.301
[25,     3] loss: 1.257
[26,     3] loss: 1.232
[27,     3] loss: 1.229
[28,     3] loss: 1.190
[29,     3] loss: 1.147
[30,     3] loss: 1.144
[31,     3] loss: 1.138
[32,     3] loss: 1.082
[33,     3] loss: 1.032
[34,     3] loss: 1.146
[35,     3] loss: 1.027
[36,     3] loss: 1.115
[37,     3] loss: 1.049
[38,     3] loss: 1.039
[39,     3] loss: 0.965
[40,     3] loss: 1.007
[41,     3] loss: 1.099
[42,     3] loss: 1.016
[43,     3] loss: 0.969
[44,     3] loss: 1.008
[45,     3] loss: 0.974
[46,     3] loss: 0.905
[47,     3] loss: 0.925
[48,     3] loss: 1.003
[49,     3] loss: 0.897
[50,     3] loss: 0.930
[51,     3] loss: 0.980
[52,     3] loss: 0.881
[53,     3] loss: 0.956
[54,     3] loss: 0.852
[55,     3] loss: 1.066
[56,     3] loss: 0.862
[57,     3] loss: 0.872
[58,     3] loss: 0.856
[59,     3] loss: 0.860
[60,     3] loss: 0.853
[61,     3] loss: 0.855
[62,     3] loss: 0.866
[63,     3] loss: 0.812
[64,     3] loss: 0.807
[65,     3] loss: 0.812
[66,     3] loss: 0.800
[67,     3] loss: 0.785
[68,     3] loss: 0.797
[69,     3] loss: 0.886
[70,     3] loss: 1.022
[71,     3] loss: 0.959
[72,     3] loss: 0.921
[73,     3] loss: 0.905
[74,     3] loss: 0.910
[75,     3] loss: 0.989
[76,     3] loss: 0.969
[77,     3] loss: 0.850
[78,     3] loss: 0.855
[79,     3] loss: 0.853
[80,     3] loss: 0.829
[81,     3] loss: 0.797
[82,     3] loss: 0.857
[83,     3] loss: 0.784
[84,     3] loss: 0.804
[85,     3] loss: 0.816
[86,     3] loss: 0.756
[87,     3] loss: 0.775
[88,     3] loss: 0.768
Early stopping applied (best metric=0.5012208819389343)
Finished Training
Total time taken: 24.479117155075073
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.387
[3,     3] loss: 1.388
[4,     3] loss: 1.384
[5,     3] loss: 1.388
[6,     3] loss: 1.386
[7,     3] loss: 1.385
[8,     3] loss: 1.385
[9,     3] loss: 1.388
[10,     3] loss: 1.381
[11,     3] loss: 1.385
[12,     3] loss: 1.382
[13,     3] loss: 1.387
[14,     3] loss: 1.382
[15,     3] loss: 1.379
[16,     3] loss: 1.381
[17,     3] loss: 1.377
[18,     3] loss: 1.379
[19,     3] loss: 1.379
[20,     3] loss: 1.380
[21,     3] loss: 1.376
[22,     3] loss: 1.370
[23,     3] loss: 1.357
[24,     3] loss: 1.352
[25,     3] loss: 1.356
[26,     3] loss: 1.309
[27,     3] loss: 1.288
[28,     3] loss: 1.286
[29,     3] loss: 1.242
[30,     3] loss: 1.268
[31,     3] loss: 1.113
[32,     3] loss: 1.204
[33,     3] loss: 1.130
[34,     3] loss: 1.135
[35,     3] loss: 1.098
[36,     3] loss: 1.147
[37,     3] loss: 1.116
[38,     3] loss: 1.091
[39,     3] loss: 1.026
[40,     3] loss: 1.134
[41,     3] loss: 1.004
[42,     3] loss: 0.981
[43,     3] loss: 1.061
[44,     3] loss: 1.008
[45,     3] loss: 1.056
[46,     3] loss: 1.051
[47,     3] loss: 0.979
[48,     3] loss: 0.958
[49,     3] loss: 0.993
[50,     3] loss: 0.914
[51,     3] loss: 0.911
[52,     3] loss: 0.900
[53,     3] loss: 0.906
[54,     3] loss: 0.986
[55,     3] loss: 1.145
[56,     3] loss: 0.875
[57,     3] loss: 1.051
[58,     3] loss: 1.038
[59,     3] loss: 1.010
[60,     3] loss: 0.941
[61,     3] loss: 1.005
[62,     3] loss: 0.899
[63,     3] loss: 0.926
[64,     3] loss: 0.914
[65,     3] loss: 0.895
[66,     3] loss: 0.886
[67,     3] loss: 0.813
[68,     3] loss: 0.787
[69,     3] loss: 0.847
[70,     3] loss: 0.842
[71,     3] loss: 0.837
[72,     3] loss: 0.796
[73,     3] loss: 0.883
[74,     3] loss: 0.816
[75,     3] loss: 0.863
[76,     3] loss: 0.839
[77,     3] loss: 0.809
[78,     3] loss: 0.812
[79,     3] loss: 0.849
[80,     3] loss: 0.850
[81,     3] loss: 0.846
[82,     3] loss: 0.800
[83,     3] loss: 0.896
[84,     3] loss: 0.888
[85,     3] loss: 0.816
[86,     3] loss: 0.808
[87,     3] loss: 0.795
[88,     3] loss: 0.810
[89,     3] loss: 0.795
[90,     3] loss: 0.808
[91,     3] loss: 0.810
[92,     3] loss: 0.817
[93,     3] loss: 0.774
[94,     3] loss: 0.797
[95,     3] loss: 0.804
[96,     3] loss: 0.742
[97,     3] loss: 0.762
[98,     3] loss: 0.749
[99,     3] loss: 0.741
[100,     3] loss: 0.742
[101,     3] loss: 0.758
[102,     3] loss: 0.762
[103,     3] loss: 0.752
[104,     3] loss: 0.740
[105,     3] loss: 0.734
[106,     3] loss: 0.764
[107,     3] loss: 0.766
[108,     3] loss: 0.757
[109,     3] loss: 0.749
[110,     3] loss: 0.793
[111,     3] loss: 0.743
[112,     3] loss: 0.753
[113,     3] loss: 0.752
[114,     3] loss: 0.768
[115,     3] loss: 0.757
[116,     3] loss: 0.773
[117,     3] loss: 0.760
[118,     3] loss: 0.764
Early stopping applied (best metric=0.49368035793304443)
Finished Training
Total time taken: 33.180161237716675
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.385
[3,     3] loss: 1.377
[4,     3] loss: 1.375
[5,     3] loss: 1.389
[6,     3] loss: 1.388
[7,     3] loss: 1.387
[8,     3] loss: 1.381
[9,     3] loss: 1.374
[10,     3] loss: 1.379
[11,     3] loss: 1.376
[12,     3] loss: 1.370
[13,     3] loss: 1.360
[14,     3] loss: 1.344
[15,     3] loss: 1.327
[16,     3] loss: 1.335
[17,     3] loss: 1.270
[18,     3] loss: 1.289
[19,     3] loss: 1.186
[20,     3] loss: 1.216
[21,     3] loss: 1.204
[22,     3] loss: 1.221
[23,     3] loss: 1.248
[24,     3] loss: 1.200
[25,     3] loss: 1.179
[26,     3] loss: 1.129
[27,     3] loss: 1.154
[28,     3] loss: 1.178
[29,     3] loss: 1.216
[30,     3] loss: 1.081
[31,     3] loss: 1.083
[32,     3] loss: 1.020
[33,     3] loss: 1.043
[34,     3] loss: 1.024
[35,     3] loss: 0.987
[36,     3] loss: 0.920
[37,     3] loss: 1.050
[38,     3] loss: 0.935
[39,     3] loss: 0.866
[40,     3] loss: 0.937
[41,     3] loss: 0.999
[42,     3] loss: 0.992
[43,     3] loss: 0.968
[44,     3] loss: 0.900
[45,     3] loss: 0.933
[46,     3] loss: 0.881
[47,     3] loss: 0.866
[48,     3] loss: 0.908
[49,     3] loss: 0.919
[50,     3] loss: 0.974
[51,     3] loss: 0.881
[52,     3] loss: 0.854
[53,     3] loss: 0.878
[54,     3] loss: 0.907
[55,     3] loss: 0.938
[56,     3] loss: 1.028
[57,     3] loss: 0.883
[58,     3] loss: 0.858
[59,     3] loss: 0.884
[60,     3] loss: 0.868
[61,     3] loss: 0.800
[62,     3] loss: 0.895
[63,     3] loss: 0.814
[64,     3] loss: 0.780
[65,     3] loss: 0.818
[66,     3] loss: 0.796
[67,     3] loss: 0.782
[68,     3] loss: 0.832
[69,     3] loss: 0.830
[70,     3] loss: 0.790
[71,     3] loss: 0.857
[72,     3] loss: 0.848
[73,     3] loss: 0.887
[74,     3] loss: 0.879
[75,     3] loss: 0.882
[76,     3] loss: 0.812
[77,     3] loss: 0.849
[78,     3] loss: 0.902
[79,     3] loss: 0.844
[80,     3] loss: 0.823
[81,     3] loss: 0.880
[82,     3] loss: 0.844
[83,     3] loss: 0.954
[84,     3] loss: 0.871
[85,     3] loss: 0.844
[86,     3] loss: 0.872
[87,     3] loss: 0.865
[88,     3] loss: 0.805
[89,     3] loss: 0.826
[90,     3] loss: 0.797
[91,     3] loss: 0.794
[92,     3] loss: 0.790
[93,     3] loss: 0.891
[94,     3] loss: 0.784
[95,     3] loss: 0.807
[96,     3] loss: 0.816
[97,     3] loss: 0.784
[98,     3] loss: 0.831
[99,     3] loss: 0.774
[100,     3] loss: 0.845
[101,     3] loss: 0.866
[102,     3] loss: 0.914
[103,     3] loss: 0.783
[104,     3] loss: 0.841
[105,     3] loss: 0.806
[106,     3] loss: 0.807
[107,     3] loss: 0.829
[108,     3] loss: 0.826
[109,     3] loss: 0.869
[110,     3] loss: 0.847
[111,     3] loss: 0.794
[112,     3] loss: 0.823
Early stopping applied (best metric=0.5078661441802979)
Finished Training
Total time taken: 31.263152837753296
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.390
[3,     3] loss: 1.396
[4,     3] loss: 1.389
[5,     3] loss: 1.385
[6,     3] loss: 1.389
[7,     3] loss: 1.381
[8,     3] loss: 1.389
[9,     3] loss: 1.385
[10,     3] loss: 1.383
[11,     3] loss: 1.387
[12,     3] loss: 1.387
[13,     3] loss: 1.388
[14,     3] loss: 1.381
[15,     3] loss: 1.386
[16,     3] loss: 1.384
[17,     3] loss: 1.386
[18,     3] loss: 1.385
[19,     3] loss: 1.384
[20,     3] loss: 1.382
[21,     3] loss: 1.384
[22,     3] loss: 1.383
[23,     3] loss: 1.383
[24,     3] loss: 1.378
[25,     3] loss: 1.371
[26,     3] loss: 1.375
[27,     3] loss: 1.347
[28,     3] loss: 1.340
[29,     3] loss: 1.320
[30,     3] loss: 1.244
[31,     3] loss: 1.206
[32,     3] loss: 1.232
[33,     3] loss: 1.223
[34,     3] loss: 1.198
[35,     3] loss: 1.172
[36,     3] loss: 1.225
[37,     3] loss: 1.153
[38,     3] loss: 1.121
[39,     3] loss: 1.134
[40,     3] loss: 1.092
[41,     3] loss: 1.128
[42,     3] loss: 0.992
[43,     3] loss: 1.027
[44,     3] loss: 1.120
[45,     3] loss: 0.969
[46,     3] loss: 1.101
[47,     3] loss: 1.072
[48,     3] loss: 1.058
[49,     3] loss: 1.036
[50,     3] loss: 0.988
[51,     3] loss: 1.024
[52,     3] loss: 0.969
[53,     3] loss: 0.934
[54,     3] loss: 0.960
[55,     3] loss: 1.012
[56,     3] loss: 0.934
[57,     3] loss: 0.881
[58,     3] loss: 0.884
[59,     3] loss: 0.894
[60,     3] loss: 0.910
[61,     3] loss: 0.907
[62,     3] loss: 0.844
[63,     3] loss: 0.880
[64,     3] loss: 0.840
[65,     3] loss: 0.885
[66,     3] loss: 0.779
[67,     3] loss: 0.816
[68,     3] loss: 0.813
[69,     3] loss: 0.757
[70,     3] loss: 0.756
[71,     3] loss: 0.761
[72,     3] loss: 0.779
[73,     3] loss: 0.740
[74,     3] loss: 0.788
[75,     3] loss: 0.778
[76,     3] loss: 0.762
[77,     3] loss: 0.773
[78,     3] loss: 0.971
[79,     3] loss: 0.931
[80,     3] loss: 0.765
[81,     3] loss: 0.949
[82,     3] loss: 0.904
[83,     3] loss: 0.842
[84,     3] loss: 0.820
[85,     3] loss: 0.836
[86,     3] loss: 0.797
[87,     3] loss: 0.793
[88,     3] loss: 0.769
[89,     3] loss: 0.753
[90,     3] loss: 0.803
[91,     3] loss: 0.757
[92,     3] loss: 0.783
[93,     3] loss: 0.752
[94,     3] loss: 0.755
[95,     3] loss: 0.736
[96,     3] loss: 0.739
[97,     3] loss: 0.743
[98,     3] loss: 0.733
[99,     3] loss: 0.742
[100,     3] loss: 0.736
[101,     3] loss: 0.748
[102,     3] loss: 0.723
[103,     3] loss: 0.766
[104,     3] loss: 0.740
Early stopping applied (best metric=0.5126296877861023)
Finished Training
Total time taken: 28.777137994766235
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.397
[3,     3] loss: 1.397
[4,     3] loss: 1.388
[5,     3] loss: 1.388
[6,     3] loss: 1.387
[7,     3] loss: 1.391
[8,     3] loss: 1.387
[9,     3] loss: 1.390
[10,     3] loss: 1.386
[11,     3] loss: 1.385
[12,     3] loss: 1.387
[13,     3] loss: 1.384
[14,     3] loss: 1.382
[15,     3] loss: 1.388
[16,     3] loss: 1.386
[17,     3] loss: 1.383
[18,     3] loss: 1.378
[19,     3] loss: 1.384
[20,     3] loss: 1.390
[21,     3] loss: 1.383
[22,     3] loss: 1.383
[23,     3] loss: 1.382
[24,     3] loss: 1.382
[25,     3] loss: 1.383
[26,     3] loss: 1.380
[27,     3] loss: 1.377
[28,     3] loss: 1.367
[29,     3] loss: 1.356
[30,     3] loss: 1.348
[31,     3] loss: 1.311
[32,     3] loss: 1.288
[33,     3] loss: 1.299
[34,     3] loss: 1.272
[35,     3] loss: 1.283
[36,     3] loss: 1.212
[37,     3] loss: 1.203
[38,     3] loss: 1.171
[39,     3] loss: 1.105
[40,     3] loss: 1.111
[41,     3] loss: 1.134
[42,     3] loss: 1.056
[43,     3] loss: 1.035
[44,     3] loss: 1.075
[45,     3] loss: 1.045
[46,     3] loss: 1.004
[47,     3] loss: 0.963
[48,     3] loss: 1.050
[49,     3] loss: 0.987
[50,     3] loss: 0.963
[51,     3] loss: 0.981
[52,     3] loss: 1.144
[53,     3] loss: 0.931
[54,     3] loss: 0.953
[55,     3] loss: 1.087
[56,     3] loss: 1.034
[57,     3] loss: 0.912
[58,     3] loss: 0.944
[59,     3] loss: 0.924
[60,     3] loss: 1.111
[61,     3] loss: 0.963
[62,     3] loss: 0.856
[63,     3] loss: 0.943
[64,     3] loss: 0.850
[65,     3] loss: 0.894
[66,     3] loss: 0.866
[67,     3] loss: 0.808
[68,     3] loss: 0.788
[69,     3] loss: 0.814
[70,     3] loss: 0.843
[71,     3] loss: 0.867
[72,     3] loss: 0.802
[73,     3] loss: 0.959
[74,     3] loss: 0.836
[75,     3] loss: 0.830
[76,     3] loss: 0.814
[77,     3] loss: 0.797
[78,     3] loss: 0.824
[79,     3] loss: 0.820
[80,     3] loss: 0.796
[81,     3] loss: 0.810
[82,     3] loss: 0.786
[83,     3] loss: 0.838
[84,     3] loss: 0.772
[85,     3] loss: 0.789
[86,     3] loss: 0.780
[87,     3] loss: 0.885
[88,     3] loss: 0.779
Early stopping applied (best metric=0.5291274189949036)
Finished Training
Total time taken: 24.613117694854736
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.389
[3,     3] loss: 1.393
[4,     3] loss: 1.385
[5,     3] loss: 1.394
[6,     3] loss: 1.397
[7,     3] loss: 1.394
[8,     3] loss: 1.382
[9,     3] loss: 1.386
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.382
[13,     3] loss: 1.386
[14,     3] loss: 1.388
[15,     3] loss: 1.383
[16,     3] loss: 1.386
[17,     3] loss: 1.387
[18,     3] loss: 1.387
[19,     3] loss: 1.384
[20,     3] loss: 1.384
[21,     3] loss: 1.384
[22,     3] loss: 1.381
[23,     3] loss: 1.380
[24,     3] loss: 1.378
[25,     3] loss: 1.378
[26,     3] loss: 1.366
[27,     3] loss: 1.354
[28,     3] loss: 1.329
[29,     3] loss: 1.296
[30,     3] loss: 1.292
[31,     3] loss: 1.262
[32,     3] loss: 1.201
[33,     3] loss: 1.306
[34,     3] loss: 1.281
[35,     3] loss: 1.249
[36,     3] loss: 1.270
[37,     3] loss: 1.260
[38,     3] loss: 1.198
[39,     3] loss: 1.278
[40,     3] loss: 1.151
[41,     3] loss: 1.169
[42,     3] loss: 1.076
[43,     3] loss: 1.081
[44,     3] loss: 1.094
[45,     3] loss: 1.061
[46,     3] loss: 0.965
[47,     3] loss: 1.009
[48,     3] loss: 1.041
[49,     3] loss: 0.986
[50,     3] loss: 0.921
[51,     3] loss: 0.991
[52,     3] loss: 0.978
[53,     3] loss: 0.992
[54,     3] loss: 0.898
[55,     3] loss: 0.910
[56,     3] loss: 0.957
[57,     3] loss: 0.940
[58,     3] loss: 0.896
[59,     3] loss: 0.893
[60,     3] loss: 0.936
[61,     3] loss: 0.905
[62,     3] loss: 0.861
[63,     3] loss: 0.830
[64,     3] loss: 0.865
[65,     3] loss: 0.916
[66,     3] loss: 1.004
[67,     3] loss: 0.807
[68,     3] loss: 0.858
[69,     3] loss: 0.861
[70,     3] loss: 0.784
[71,     3] loss: 0.906
[72,     3] loss: 0.821
[73,     3] loss: 0.778
[74,     3] loss: 0.790
[75,     3] loss: 0.835
[76,     3] loss: 0.874
[77,     3] loss: 0.785
[78,     3] loss: 0.783
[79,     3] loss: 0.848
[80,     3] loss: 0.893
[81,     3] loss: 0.802
[82,     3] loss: 0.878
[83,     3] loss: 0.804
[84,     3] loss: 0.799
[85,     3] loss: 0.760
[86,     3] loss: 0.798
[87,     3] loss: 0.785
[88,     3] loss: 0.753
[89,     3] loss: 0.744
[90,     3] loss: 0.743
[91,     3] loss: 0.786
[92,     3] loss: 0.750
[93,     3] loss: 0.753
[94,     3] loss: 0.757
[95,     3] loss: 0.736
[96,     3] loss: 0.767
[97,     3] loss: 0.795
[98,     3] loss: 0.739
[99,     3] loss: 0.775
[100,     3] loss: 0.751
[101,     3] loss: 0.753
[102,     3] loss: 0.737
[103,     3] loss: 0.751
Early stopping applied (best metric=0.5238204002380371)
Finished Training
Total time taken: 28.35413384437561
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.388
[3,     3] loss: 1.386
[4,     3] loss: 1.382
[5,     3] loss: 1.392
[6,     3] loss: 1.381
[7,     3] loss: 1.386
[8,     3] loss: 1.383
[9,     3] loss: 1.388
[10,     3] loss: 1.387
[11,     3] loss: 1.387
[12,     3] loss: 1.381
[13,     3] loss: 1.377
[14,     3] loss: 1.377
[15,     3] loss: 1.377
[16,     3] loss: 1.379
[17,     3] loss: 1.364
[18,     3] loss: 1.347
[19,     3] loss: 1.341
[20,     3] loss: 1.324
[21,     3] loss: 1.320
[22,     3] loss: 1.301
[23,     3] loss: 1.224
[24,     3] loss: 1.217
[25,     3] loss: 1.240
[26,     3] loss: 1.217
[27,     3] loss: 1.129
[28,     3] loss: 1.125
[29,     3] loss: 1.038
[30,     3] loss: 1.205
[31,     3] loss: 1.216
[32,     3] loss: 1.114
[33,     3] loss: 1.118
[34,     3] loss: 1.148
[35,     3] loss: 1.055
[36,     3] loss: 1.077
[37,     3] loss: 1.114
[38,     3] loss: 1.074
[39,     3] loss: 1.055
[40,     3] loss: 1.096
[41,     3] loss: 1.057
[42,     3] loss: 0.969
[43,     3] loss: 0.995
[44,     3] loss: 0.977
[45,     3] loss: 0.933
[46,     3] loss: 1.010
[47,     3] loss: 0.953
[48,     3] loss: 0.910
[49,     3] loss: 0.944
[50,     3] loss: 0.903
[51,     3] loss: 0.962
[52,     3] loss: 0.902
[53,     3] loss: 0.908
[54,     3] loss: 0.912
[55,     3] loss: 0.924
[56,     3] loss: 1.000
[57,     3] loss: 0.922
[58,     3] loss: 0.945
[59,     3] loss: 1.040
[60,     3] loss: 0.903
[61,     3] loss: 0.874
[62,     3] loss: 0.888
[63,     3] loss: 0.873
[64,     3] loss: 0.913
[65,     3] loss: 0.796
[66,     3] loss: 0.884
[67,     3] loss: 0.772
[68,     3] loss: 0.890
[69,     3] loss: 0.802
[70,     3] loss: 0.801
[71,     3] loss: 0.889
[72,     3] loss: 0.847
[73,     3] loss: 0.796
[74,     3] loss: 0.856
[75,     3] loss: 0.805
[76,     3] loss: 0.949
[77,     3] loss: 0.952
[78,     3] loss: 0.836
[79,     3] loss: 0.941
[80,     3] loss: 0.879
[81,     3] loss: 0.817
[82,     3] loss: 0.793
[83,     3] loss: 0.860
[84,     3] loss: 0.829
[85,     3] loss: 0.798
[86,     3] loss: 0.795
[87,     3] loss: 0.770
[88,     3] loss: 0.814
[89,     3] loss: 0.776
[90,     3] loss: 0.788
[91,     3] loss: 0.780
[92,     3] loss: 0.753
[93,     3] loss: 0.800
[94,     3] loss: 0.788
[95,     3] loss: 0.748
[96,     3] loss: 0.735
[97,     3] loss: 0.759
[98,     3] loss: 0.760
[99,     3] loss: 0.763
[100,     3] loss: 0.758
[101,     3] loss: 0.736
[102,     3] loss: 0.750
[103,     3] loss: 0.732
[104,     3] loss: 0.827
[105,     3] loss: 0.722
[106,     3] loss: 0.756
[107,     3] loss: 0.751
[108,     3] loss: 0.755
[109,     3] loss: 0.733
[110,     3] loss: 0.739
[111,     3] loss: 0.743
[112,     3] loss: 0.746
[113,     3] loss: 0.725
[114,     3] loss: 0.744
[115,     3] loss: 0.737
[116,     3] loss: 0.737
[117,     3] loss: 0.726
[118,     3] loss: 0.719
[119,     3] loss: 0.746
[120,     3] loss: 0.732
[121,     3] loss: 0.731
[122,     3] loss: 0.723
[123,     3] loss: 0.750
[124,     3] loss: 0.734
[125,     3] loss: 0.730
[126,     3] loss: 0.729
[127,     3] loss: 0.725
Early stopping applied (best metric=0.5318720936775208)
Finished Training
Total time taken: 35.11416840553284
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.382
[3,     3] loss: 1.385
[4,     3] loss: 1.384
[5,     3] loss: 1.384
[6,     3] loss: 1.385
[7,     3] loss: 1.397
[8,     3] loss: 1.385
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.389
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.382
[15,     3] loss: 1.382
[16,     3] loss: 1.388
[17,     3] loss: 1.376
[18,     3] loss: 1.382
[19,     3] loss: 1.373
[20,     3] loss: 1.376
[21,     3] loss: 1.360
[22,     3] loss: 1.352
[23,     3] loss: 1.370
[24,     3] loss: 1.330
[25,     3] loss: 1.307
[26,     3] loss: 1.279
[27,     3] loss: 1.221
[28,     3] loss: 1.241
[29,     3] loss: 1.218
[30,     3] loss: 1.396
[31,     3] loss: 1.314
[32,     3] loss: 1.190
[33,     3] loss: 1.177
[34,     3] loss: 1.140
[35,     3] loss: 1.113
[36,     3] loss: 1.133
[37,     3] loss: 1.183
[38,     3] loss: 1.120
[39,     3] loss: 1.048
[40,     3] loss: 1.028
[41,     3] loss: 1.055
[42,     3] loss: 1.102
[43,     3] loss: 1.039
[44,     3] loss: 1.129
[45,     3] loss: 1.053
[46,     3] loss: 0.991
[47,     3] loss: 0.957
[48,     3] loss: 0.957
[49,     3] loss: 0.964
[50,     3] loss: 1.080
[51,     3] loss: 0.924
[52,     3] loss: 1.042
[53,     3] loss: 0.878
[54,     3] loss: 0.952
[55,     3] loss: 0.962
[56,     3] loss: 0.929
[57,     3] loss: 0.899
[58,     3] loss: 0.903
[59,     3] loss: 0.988
[60,     3] loss: 0.881
[61,     3] loss: 0.933
[62,     3] loss: 0.890
[63,     3] loss: 0.845
[64,     3] loss: 0.852
[65,     3] loss: 0.943
[66,     3] loss: 0.867
[67,     3] loss: 0.955
[68,     3] loss: 0.968
[69,     3] loss: 0.853
[70,     3] loss: 0.861
[71,     3] loss: 0.831
[72,     3] loss: 0.869
[73,     3] loss: 0.812
[74,     3] loss: 0.783
[75,     3] loss: 0.865
[76,     3] loss: 0.795
[77,     3] loss: 0.869
[78,     3] loss: 0.794
[79,     3] loss: 0.805
[80,     3] loss: 0.782
[81,     3] loss: 0.759
[82,     3] loss: 0.780
[83,     3] loss: 0.782
[84,     3] loss: 0.826
[85,     3] loss: 0.781
[86,     3] loss: 0.797
[87,     3] loss: 0.763
[88,     3] loss: 0.832
[89,     3] loss: 0.781
[90,     3] loss: 0.789
[91,     3] loss: 0.800
[92,     3] loss: 0.799
[93,     3] loss: 0.785
[94,     3] loss: 0.772
[95,     3] loss: 0.837
[96,     3] loss: 0.791
[97,     3] loss: 0.800
[98,     3] loss: 0.761
[99,     3] loss: 0.801
Early stopping applied (best metric=0.5068861246109009)
Finished Training
Total time taken: 27.317130088806152
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.401
[3,     3] loss: 1.395
[4,     3] loss: 1.390
[5,     3] loss: 1.380
[6,     3] loss: 1.379
[7,     3] loss: 1.395
[8,     3] loss: 1.386
[9,     3] loss: 1.386
[10,     3] loss: 1.377
[11,     3] loss: 1.390
[12,     3] loss: 1.375
[13,     3] loss: 1.371
[14,     3] loss: 1.375
[15,     3] loss: 1.362
[16,     3] loss: 1.356
[17,     3] loss: 1.347
[18,     3] loss: 1.326
[19,     3] loss: 1.273
[20,     3] loss: 1.272
[21,     3] loss: 1.191
[22,     3] loss: 1.188
[23,     3] loss: 1.135
[24,     3] loss: 1.171
[25,     3] loss: 1.134
[26,     3] loss: 1.065
[27,     3] loss: 1.040
[28,     3] loss: 1.084
[29,     3] loss: 1.051
[30,     3] loss: 0.986
[31,     3] loss: 0.995
[32,     3] loss: 1.048
[33,     3] loss: 1.013
[34,     3] loss: 0.980
[35,     3] loss: 1.099
[36,     3] loss: 0.967
[37,     3] loss: 1.001
[38,     3] loss: 0.921
[39,     3] loss: 0.876
[40,     3] loss: 0.921
[41,     3] loss: 1.047
[42,     3] loss: 0.901
[43,     3] loss: 0.858
[44,     3] loss: 0.872
[45,     3] loss: 0.839
[46,     3] loss: 0.868
[47,     3] loss: 0.828
[48,     3] loss: 0.909
[49,     3] loss: 0.874
[50,     3] loss: 0.867
[51,     3] loss: 0.863
[52,     3] loss: 0.791
[53,     3] loss: 0.820
[54,     3] loss: 0.775
[55,     3] loss: 0.789
[56,     3] loss: 0.788
[57,     3] loss: 0.828
[58,     3] loss: 0.917
[59,     3] loss: 0.810
[60,     3] loss: 0.831
[61,     3] loss: 0.815
[62,     3] loss: 0.859
[63,     3] loss: 0.842
[64,     3] loss: 0.812
[65,     3] loss: 0.792
[66,     3] loss: 0.800
[67,     3] loss: 0.814
[68,     3] loss: 0.833
[69,     3] loss: 0.800
[70,     3] loss: 0.769
[71,     3] loss: 0.815
[72,     3] loss: 0.915
[73,     3] loss: 0.771
[74,     3] loss: 0.969
[75,     3] loss: 0.859
[76,     3] loss: 0.877
[77,     3] loss: 0.828
[78,     3] loss: 0.867
[79,     3] loss: 0.813
Early stopping applied (best metric=0.5155462026596069)
Finished Training
Total time taken: 22.145108938217163
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.379
[3,     3] loss: 1.380
[4,     3] loss: 1.383
[5,     3] loss: 1.392
[6,     3] loss: 1.373
[7,     3] loss: 1.370
[8,     3] loss: 1.374
[9,     3] loss: 1.371
[10,     3] loss: 1.362
[11,     3] loss: 1.340
[12,     3] loss: 1.333
[13,     3] loss: 1.316
[14,     3] loss: 1.322
[15,     3] loss: 1.330
[16,     3] loss: 1.260
[17,     3] loss: 1.245
[18,     3] loss: 1.346
[19,     3] loss: 1.209
[20,     3] loss: 1.200
[21,     3] loss: 1.178
[22,     3] loss: 1.168
[23,     3] loss: 1.207
[24,     3] loss: 1.258
[25,     3] loss: 1.147
[26,     3] loss: 1.119
[27,     3] loss: 1.050
[28,     3] loss: 1.108
[29,     3] loss: 1.001
[30,     3] loss: 0.997
[31,     3] loss: 1.022
[32,     3] loss: 1.002
[33,     3] loss: 1.024
[34,     3] loss: 0.966
[35,     3] loss: 1.071
[36,     3] loss: 0.963
[37,     3] loss: 1.028
[38,     3] loss: 1.035
[39,     3] loss: 1.005
[40,     3] loss: 0.980
[41,     3] loss: 0.925
[42,     3] loss: 0.896
[43,     3] loss: 0.910
[44,     3] loss: 0.889
[45,     3] loss: 0.878
[46,     3] loss: 0.847
[47,     3] loss: 0.880
[48,     3] loss: 0.837
[49,     3] loss: 0.844
[50,     3] loss: 0.830
[51,     3] loss: 0.846
[52,     3] loss: 0.866
[53,     3] loss: 0.898
[54,     3] loss: 0.840
[55,     3] loss: 0.877
[56,     3] loss: 0.900
[57,     3] loss: 0.902
[58,     3] loss: 0.881
[59,     3] loss: 0.860
[60,     3] loss: 0.838
[61,     3] loss: 0.888
[62,     3] loss: 0.841
Early stopping applied (best metric=0.541876494884491)
Finished Training
Total time taken: 17.23708176612854
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.395
[3,     3] loss: 1.383
[4,     3] loss: 1.386
[5,     3] loss: 1.387
[6,     3] loss: 1.387
[7,     3] loss: 1.385
[8,     3] loss: 1.386
[9,     3] loss: 1.382
[10,     3] loss: 1.386
[11,     3] loss: 1.388
[12,     3] loss: 1.387
[13,     3] loss: 1.389
[14,     3] loss: 1.384
[15,     3] loss: 1.383
[16,     3] loss: 1.384
[17,     3] loss: 1.388
[18,     3] loss: 1.390
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.384
[22,     3] loss: 1.388
[23,     3] loss: 1.385
[24,     3] loss: 1.383
[25,     3] loss: 1.378
[26,     3] loss: 1.375
[27,     3] loss: 1.376
[28,     3] loss: 1.377
[29,     3] loss: 1.376
[30,     3] loss: 1.362
[31,     3] loss: 1.356
[32,     3] loss: 1.322
[33,     3] loss: 1.301
[34,     3] loss: 1.239
[35,     3] loss: 1.321
[36,     3] loss: 1.223
[37,     3] loss: 1.242
[38,     3] loss: 1.203
[39,     3] loss: 1.145
[40,     3] loss: 1.154
[41,     3] loss: 1.073
[42,     3] loss: 1.119
[43,     3] loss: 1.031
[44,     3] loss: 1.105
[45,     3] loss: 1.005
[46,     3] loss: 1.051
[47,     3] loss: 0.946
[48,     3] loss: 0.991
[49,     3] loss: 1.093
[50,     3] loss: 1.043
[51,     3] loss: 1.097
[52,     3] loss: 0.973
[53,     3] loss: 1.122
[54,     3] loss: 0.984
[55,     3] loss: 0.969
[56,     3] loss: 1.169
[57,     3] loss: 1.028
[58,     3] loss: 0.926
[59,     3] loss: 0.999
[60,     3] loss: 0.965
[61,     3] loss: 1.002
[62,     3] loss: 1.007
[63,     3] loss: 0.910
[64,     3] loss: 0.890
[65,     3] loss: 0.985
[66,     3] loss: 1.036
[67,     3] loss: 0.907
[68,     3] loss: 1.017
[69,     3] loss: 0.926
[70,     3] loss: 0.926
[71,     3] loss: 0.857
[72,     3] loss: 1.017
[73,     3] loss: 0.832
[74,     3] loss: 1.002
[75,     3] loss: 0.829
[76,     3] loss: 0.830
[77,     3] loss: 0.834
[78,     3] loss: 0.850
[79,     3] loss: 0.824
[80,     3] loss: 0.791
[81,     3] loss: 0.857
[82,     3] loss: 0.816
[83,     3] loss: 0.837
[84,     3] loss: 0.795
[85,     3] loss: 0.777
[86,     3] loss: 0.791
[87,     3] loss: 0.851
[88,     3] loss: 0.789
[89,     3] loss: 0.758
[90,     3] loss: 0.755
[91,     3] loss: 0.763
[92,     3] loss: 0.743
[93,     3] loss: 0.752
[94,     3] loss: 0.740
[95,     3] loss: 0.735
[96,     3] loss: 0.737
[97,     3] loss: 0.727
[98,     3] loss: 0.729
[99,     3] loss: 0.749
[100,     3] loss: 0.733
Early stopping applied (best metric=0.5317162275314331)
Finished Training
Total time taken: 27.82313346862793
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.393
[3,     3] loss: 1.385
[4,     3] loss: 1.381
[5,     3] loss: 1.393
[6,     3] loss: 1.391
[7,     3] loss: 1.381
[8,     3] loss: 1.384
[9,     3] loss: 1.386
[10,     3] loss: 1.383
[11,     3] loss: 1.390
[12,     3] loss: 1.387
[13,     3] loss: 1.385
[14,     3] loss: 1.383
[15,     3] loss: 1.382
[16,     3] loss: 1.385
[17,     3] loss: 1.384
[18,     3] loss: 1.383
[19,     3] loss: 1.385
[20,     3] loss: 1.375
[21,     3] loss: 1.376
[22,     3] loss: 1.369
[23,     3] loss: 1.358
[24,     3] loss: 1.320
[25,     3] loss: 1.344
[26,     3] loss: 1.311
[27,     3] loss: 1.273
[28,     3] loss: 1.201
[29,     3] loss: 1.203
[30,     3] loss: 1.196
[31,     3] loss: 1.254
[32,     3] loss: 1.158
[33,     3] loss: 1.159
[34,     3] loss: 1.254
[35,     3] loss: 1.192
[36,     3] loss: 1.117
[37,     3] loss: 1.160
[38,     3] loss: 1.050
[39,     3] loss: 1.090
[40,     3] loss: 1.147
[41,     3] loss: 1.112
[42,     3] loss: 1.066
[43,     3] loss: 0.982
[44,     3] loss: 0.943
[45,     3] loss: 1.107
[46,     3] loss: 1.049
[47,     3] loss: 1.144
[48,     3] loss: 0.949
[49,     3] loss: 0.973
[50,     3] loss: 0.945
[51,     3] loss: 0.958
[52,     3] loss: 0.975
[53,     3] loss: 0.900
[54,     3] loss: 0.961
[55,     3] loss: 0.886
[56,     3] loss: 0.889
[57,     3] loss: 0.897
[58,     3] loss: 0.956
[59,     3] loss: 0.971
[60,     3] loss: 0.975
[61,     3] loss: 0.978
[62,     3] loss: 0.910
[63,     3] loss: 0.975
[64,     3] loss: 0.893
[65,     3] loss: 0.889
[66,     3] loss: 0.867
[67,     3] loss: 0.849
[68,     3] loss: 0.902
[69,     3] loss: 0.878
[70,     3] loss: 0.864
[71,     3] loss: 0.810
[72,     3] loss: 0.796
[73,     3] loss: 0.810
[74,     3] loss: 0.821
[75,     3] loss: 0.792
[76,     3] loss: 0.767
[77,     3] loss: 0.749
[78,     3] loss: 0.770
[79,     3] loss: 0.856
[80,     3] loss: 0.735
[81,     3] loss: 0.821
[82,     3] loss: 0.856
[83,     3] loss: 0.776
[84,     3] loss: 0.881
[85,     3] loss: 0.786
[86,     3] loss: 0.806
[87,     3] loss: 0.800
[88,     3] loss: 0.785
Early stopping applied (best metric=0.5061847567558289)
Finished Training
Total time taken: 24.53011989593506
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.384
[3,     3] loss: 1.382
[4,     3] loss: 1.391
[5,     3] loss: 1.382
[6,     3] loss: 1.388
[7,     3] loss: 1.391
[8,     3] loss: 1.383
[9,     3] loss: 1.377
[10,     3] loss: 1.381
[11,     3] loss: 1.384
[12,     3] loss: 1.380
[13,     3] loss: 1.370
[14,     3] loss: 1.376
[15,     3] loss: 1.357
[16,     3] loss: 1.373
[17,     3] loss: 1.359
[18,     3] loss: 1.326
[19,     3] loss: 1.304
[20,     3] loss: 1.282
[21,     3] loss: 1.311
[22,     3] loss: 1.289
[23,     3] loss: 1.193
[24,     3] loss: 1.195
[25,     3] loss: 1.216
[26,     3] loss: 1.192
[27,     3] loss: 1.206
[28,     3] loss: 1.126
[29,     3] loss: 1.135
[30,     3] loss: 1.128
[31,     3] loss: 1.109
[32,     3] loss: 1.061
[33,     3] loss: 1.021
[34,     3] loss: 1.016
[35,     3] loss: 1.126
[36,     3] loss: 0.947
[37,     3] loss: 1.085
[38,     3] loss: 0.948
[39,     3] loss: 1.095
[40,     3] loss: 1.115
[41,     3] loss: 1.058
[42,     3] loss: 1.002
[43,     3] loss: 1.025
[44,     3] loss: 0.995
[45,     3] loss: 0.919
[46,     3] loss: 0.993
[47,     3] loss: 0.947
[48,     3] loss: 0.989
[49,     3] loss: 0.960
[50,     3] loss: 1.030
[51,     3] loss: 0.968
[52,     3] loss: 1.174
[53,     3] loss: 1.028
[54,     3] loss: 0.993
[55,     3] loss: 1.045
[56,     3] loss: 1.033
[57,     3] loss: 0.914
[58,     3] loss: 0.981
[59,     3] loss: 0.889
[60,     3] loss: 0.968
[61,     3] loss: 0.884
[62,     3] loss: 0.917
[63,     3] loss: 0.900
[64,     3] loss: 0.895
[65,     3] loss: 0.834
[66,     3] loss: 0.884
[67,     3] loss: 0.797
[68,     3] loss: 0.814
[69,     3] loss: 0.873
[70,     3] loss: 0.822
[71,     3] loss: 0.811
[72,     3] loss: 1.029
[73,     3] loss: 0.802
[74,     3] loss: 0.842
[75,     3] loss: 0.794
[76,     3] loss: 0.906
[77,     3] loss: 0.823
[78,     3] loss: 0.806
[79,     3] loss: 0.778
[80,     3] loss: 0.799
[81,     3] loss: 0.799
[82,     3] loss: 0.748
Early stopping applied (best metric=0.49848607182502747)
Finished Training
Total time taken: 22.781113862991333
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.387
[3,     3] loss: 1.396
[4,     3] loss: 1.383
[5,     3] loss: 1.393
[6,     3] loss: 1.386
[7,     3] loss: 1.383
[8,     3] loss: 1.379
[9,     3] loss: 1.385
[10,     3] loss: 1.388
[11,     3] loss: 1.385
[12,     3] loss: 1.377
[13,     3] loss: 1.378
[14,     3] loss: 1.381
[15,     3] loss: 1.373
[16,     3] loss: 1.370
[17,     3] loss: 1.359
[18,     3] loss: 1.356
[19,     3] loss: 1.320
[20,     3] loss: 1.338
[21,     3] loss: 1.276
[22,     3] loss: 1.291
[23,     3] loss: 1.237
[24,     3] loss: 1.270
[25,     3] loss: 1.226
[26,     3] loss: 1.230
[27,     3] loss: 1.125
[28,     3] loss: 1.151
[29,     3] loss: 1.127
[30,     3] loss: 1.260
[31,     3] loss: 1.207
[32,     3] loss: 1.161
[33,     3] loss: 1.124
[34,     3] loss: 1.210
[35,     3] loss: 1.062
[36,     3] loss: 1.120
[37,     3] loss: 1.111
[38,     3] loss: 1.099
[39,     3] loss: 1.029
[40,     3] loss: 1.115
[41,     3] loss: 1.009
[42,     3] loss: 1.003
[43,     3] loss: 0.937
[44,     3] loss: 0.958
[45,     3] loss: 1.002
[46,     3] loss: 0.929
[47,     3] loss: 0.969
[48,     3] loss: 0.987
[49,     3] loss: 0.959
[50,     3] loss: 0.962
[51,     3] loss: 0.918
[52,     3] loss: 0.933
[53,     3] loss: 0.945
[54,     3] loss: 0.859
[55,     3] loss: 0.959
[56,     3] loss: 0.941
[57,     3] loss: 0.859
[58,     3] loss: 0.879
[59,     3] loss: 0.915
[60,     3] loss: 0.843
[61,     3] loss: 0.885
[62,     3] loss: 0.886
[63,     3] loss: 1.063
[64,     3] loss: 0.816
[65,     3] loss: 0.912
[66,     3] loss: 0.893
[67,     3] loss: 1.098
[68,     3] loss: 0.844
[69,     3] loss: 1.033
[70,     3] loss: 0.914
[71,     3] loss: 0.882
[72,     3] loss: 0.984
[73,     3] loss: 0.904
[74,     3] loss: 0.872
[75,     3] loss: 0.919
[76,     3] loss: 0.898
[77,     3] loss: 0.834
[78,     3] loss: 0.815
[79,     3] loss: 0.823
[80,     3] loss: 0.875
[81,     3] loss: 0.912
Early stopping applied (best metric=0.5084228515625)
Finished Training
Total time taken: 22.38510537147522
{'S-palmitoylation-C Validation Accuracy': 0.6864810298871434, 'S-palmitoylation-C Validation Sensitivity': 0.25306930693069307, 'S-palmitoylation-C Validation Specificity': 0.7951209687686607, 'S-palmitoylation-C Validation Precision': 0.23919195354024456, 'S-palmitoylation-C AUC ROC': 0.5425052318543635, 'S-palmitoylation-C AUC PR': 0.2263660877249885, 'S-palmitoylation-C MCC': 0.04792213485690762, 'S-palmitoylation-C F1': 0.23544634535192718, 'Validation Loss (S-palmitoylation-C)': 0.5541595220565796, 'Hydroxylation-K Validation Accuracy': 0.7195626477541371, 'Hydroxylation-K Validation Sensitivity': 0.7859259259259259, 'Hydroxylation-K Validation Specificity': 0.7035087719298245, 'Hydroxylation-K Validation Precision': 0.41149374975293673, 'Hydroxylation-K AUC ROC': 0.8060038986354776, 'Hydroxylation-K AUC PR': 0.5825504937345553, 'Hydroxylation-K MCC': 0.40855343108064773, 'Hydroxylation-K F1': 0.5333645874711471, 'Validation Loss (Hydroxylation-K)': 0.5153319338957468, 'Validation Loss (total)': 1.069491442044576, 'TimeToTrain': 26.61732808748881}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0097372647114272,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9686021326405868,
 'loss_weight_S-palmitoylation-C': 0.8434471355232694,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3749073698,
 'sample_weights': [0.6877538167732523, 0.8329700454214393],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.725975676867206,
 'weight_decay_Hydroxylation-K': 7.923048255576671,
 'weight_decay_S-palmitoylation-C': 7.796081498797492}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.390
[3,     3] loss: 1.385
[4,     3] loss: 1.385
[5,     3] loss: 1.389
[6,     3] loss: 1.387
[7,     3] loss: 1.386
[8,     3] loss: 1.390
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007763476100826311,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.19986711945965357,
 'loss_weight_S-palmitoylation-C': 0.4200322284204583,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1031641871,
 'sample_weights': [0.8434471355232694, 0.9686021326405868],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.710195804764449,
 'weight_decay_Hydroxylation-K': 4.853029324998418,
 'weight_decay_S-palmitoylation-C': 6.8632126586597355}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.375
[2,     3] loss: 1.392
[3,     3] loss: 1.386
[4,     3] loss: 1.389
[5,     3] loss: 1.391
[6,     3] loss: 1.387
[7,     3] loss: 1.387
[8,     3] loss: 1.389
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037649612208888327,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2777993042656352,
 'loss_weight_S-palmitoylation-C': 0.049903583920190106,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2529426496,
 'sample_weights': [0.4200322284204583, 0.19986711945965357],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.1686501516997603,
 'weight_decay_Hydroxylation-K': 0.062264796664342814,
 'weight_decay_S-palmitoylation-C': 7.848809344217134}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.378
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016018918921905782,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.45985314762594126,
 'loss_weight_S-palmitoylation-C': 0.009705318300696306,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 609564441,
 'sample_weights': [0.049903583920190106, 0.2777993042656352],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.555796583074438,
 'weight_decay_Hydroxylation-K': 3.3737591500880924,
 'weight_decay_S-palmitoylation-C': 7.7145585795034926}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.385
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00035104731149886506,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.12532264315215508,
 'loss_weight_S-palmitoylation-C': 0.7646191942199477,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1063514233,
 'sample_weights': [0.009705318300696306, 0.45985314762594126],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7110930903267145,
 'weight_decay_Hydroxylation-K': 5.959293586011475,
 'weight_decay_S-palmitoylation-C': 0.0990577300312312}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.382
[3,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023194543877254714,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6541235996611832,
 'loss_weight_S-palmitoylation-C': 0.03288009030444233,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1821677139,
 'sample_weights': [0.7646191942199477, 0.12532264315215508],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3720808481886344,
 'weight_decay_Hydroxylation-K': 3.1509632243608525,
 'weight_decay_S-palmitoylation-C': 8.73388767629673}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002124413935286994,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8051449580849108,
 'loss_weight_S-palmitoylation-C': 0.13780887400218464,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 775315964,
 'sample_weights': [0.03288009030444233, 0.6541235996611832],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.3790874277877165,
 'weight_decay_Hydroxylation-K': 1.1372224801862312,
 'weight_decay_S-palmitoylation-C': 4.120274146101859}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.386
[3,     3] loss: 1.393
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006448018025593649,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.12071842449254871,
 'loss_weight_S-palmitoylation-C': 0.9752913148089538,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3248626778,
 'sample_weights': [0.13780887400218464, 0.8051449580849108],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.385878109924549,
 'weight_decay_Hydroxylation-K': 4.461566965682225,
 'weight_decay_S-palmitoylation-C': 9.61263646290223}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.386
[3,     3] loss: 1.378
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007421289115318216,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.44645837838965075,
 'loss_weight_S-palmitoylation-C': 0.2297149087463805,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1221837945,
 'sample_weights': [0.9752913148089538, 0.12071842449254871],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7444380568681392,
 'weight_decay_Hydroxylation-K': 0.005368473805114737,
 'weight_decay_S-palmitoylation-C': 0.18260671028027944}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.387
[3,     3] loss: 1.382
[4,     3] loss: 1.379
[5,     3] loss: 1.396
[6,     3] loss: 1.397
[7,     3] loss: 1.390
[8,     3] loss: 1.389
[9,     3] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003336247962334468,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8726902449362551,
 'loss_weight_S-palmitoylation-C': 0.09960035235830778,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2092491181,
 'sample_weights': [0.2297149087463805, 0.44645837838965075],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.21632436218897,
 'weight_decay_Hydroxylation-K': 1.0052829181128966,
 'weight_decay_S-palmitoylation-C': 7.474805554197966}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.379
[3,     3] loss: 1.373
[4,     3] loss: 1.403
[5,     3] loss: 1.369
[6,     3] loss: 1.357
[7,     3] loss: 1.359
[8,     3] loss: 1.271
[9,     3] loss: 1.240
[10,     3] loss: 1.290
[11,     3] loss: 1.189
[12,     3] loss: 1.129
[13,     3] loss: 1.121
[14,     3] loss: 1.024
[15,     3] loss: 1.121
[16,     3] loss: 1.062
[17,     3] loss: 1.125
[18,     3] loss: 1.078
[19,     3] loss: 1.040
[20,     3] loss: 0.921
[21,     3] loss: 1.162
[22,     3] loss: 1.068
[23,     3] loss: 1.243
[24,     3] loss: 1.122
[25,     3] loss: 1.123
[26,     3] loss: 1.085
[27,     3] loss: 1.044
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006593912978422466,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9877241725264788,
 'loss_weight_S-palmitoylation-C': 0.08382337523435002,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1489303111,
 'sample_weights': [0.09960035235830778, 0.8726902449362551],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8874687542375392,
 'weight_decay_Hydroxylation-K': 0.20698839192473328,
 'weight_decay_S-palmitoylation-C': 2.4251714268266458}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.392
[3,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0052921136671614695,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.899679475691739,
 'loss_weight_S-palmitoylation-C': 0.14968655284079785,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 958425443,
 'sample_weights': [0.08382337523435002, 0.9877241725264788],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.73152033846559,
 'weight_decay_Hydroxylation-K': 0.9190490628969774,
 'weight_decay_S-palmitoylation-C': 7.132859305454463}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.380
[2,     3] loss: 1.406
[3,     3] loss: 1.393
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027851857129692387,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9507223368149647,
 'loss_weight_S-palmitoylation-C': 0.33526504511357946,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3301091095,
 'sample_weights': [0.14968655284079785, 0.899679475691739],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.845856879396187,
 'weight_decay_Hydroxylation-K': 2.050490055170779,
 'weight_decay_S-palmitoylation-C': 7.872135474898325}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.373
[3,     3] loss: 1.413
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022137896170718275,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8415301293997433,
 'loss_weight_S-palmitoylation-C': 0.6468201556639134,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2071342494,
 'sample_weights': [0.33526504511357946, 0.9507223368149647],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8708698435987667,
 'weight_decay_Hydroxylation-K': 7.9426762474652834,
 'weight_decay_S-palmitoylation-C': 2.3438668079726526}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.389
[3,     3] loss: 1.386
[4,     3] loss: 1.385
[5,     3] loss: 1.388
[6,     3] loss: 1.384
[7,     3] loss: 1.390
[8,     3] loss: 1.393
[9,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014043165102565918,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.45056888248504673,
 'loss_weight_S-palmitoylation-C': 0.659853186975911,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4090939003,
 'sample_weights': [0.6468201556639134, 0.8415301293997433],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.503290791867487,
 'weight_decay_Hydroxylation-K': 8.708624251470788,
 'weight_decay_S-palmitoylation-C': 1.3540748481774567}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.386
[3,     3] loss: 1.386
[4,     3] loss: 1.392
[5,     3] loss: 1.388
[6,     3] loss: 1.384
[7,     3] loss: 1.388
[8,     3] loss: 1.381
[9,     3] loss: 1.385
[10,     3] loss: 1.382
[11,     3] loss: 1.381
[12,     3] loss: 1.383
[13,     3] loss: 1.384
[14,     3] loss: 1.370
[15,     3] loss: 1.356
[16,     3] loss: 1.354
[17,     3] loss: 1.327
[18,     3] loss: 1.314
[19,     3] loss: 1.287
[20,     3] loss: 1.264
[21,     3] loss: 1.239
[22,     3] loss: 1.193
[23,     3] loss: 1.183
[24,     3] loss: 1.084
[25,     3] loss: 1.133
[26,     3] loss: 1.104
[27,     3] loss: 1.073
[28,     3] loss: 1.045
[29,     3] loss: 0.997
[30,     3] loss: 1.014
[31,     3] loss: 1.025
[32,     3] loss: 1.110
[33,     3] loss: 0.961
[34,     3] loss: 0.983
[35,     3] loss: 0.920
[36,     3] loss: 0.953
[37,     3] loss: 0.895
[38,     3] loss: 0.920
[39,     3] loss: 0.894
[40,     3] loss: 0.879
[41,     3] loss: 0.894
[42,     3] loss: 0.856
[43,     3] loss: 0.840
[44,     3] loss: 0.917
[45,     3] loss: 1.106
[46,     3] loss: 0.943
[47,     3] loss: 0.884
[48,     3] loss: 0.876
[49,     3] loss: 0.941
[50,     3] loss: 0.974
[51,     3] loss: 0.894
[52,     3] loss: 0.845
[53,     3] loss: 0.904
[54,     3] loss: 0.891
[55,     3] loss: 0.966
[56,     3] loss: 0.961
[57,     3] loss: 0.980
[58,     3] loss: 1.050
[59,     3] loss: 0.999
[60,     3] loss: 0.946
[61,     3] loss: 0.902
[62,     3] loss: 0.985
[63,     3] loss: 0.912
[64,     3] loss: 0.951
[65,     3] loss: 0.826
[66,     3] loss: 0.819
[67,     3] loss: 0.842
[68,     3] loss: 0.827
[69,     3] loss: 0.891
Early stopping applied (best metric=0.5391188859939575)
Finished Training
Total time taken: 19.129089832305908
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.386
[3,     3] loss: 1.386
[4,     3] loss: 1.393
[5,     3] loss: 1.370
[6,     3] loss: 1.371
[7,     3] loss: 1.359
[8,     3] loss: 1.343
[9,     3] loss: 1.325
[10,     3] loss: 1.311
[11,     3] loss: 1.292
[12,     3] loss: 1.255
[13,     3] loss: 1.244
[14,     3] loss: 1.228
[15,     3] loss: 1.247
[16,     3] loss: 1.135
[17,     3] loss: 1.152
[18,     3] loss: 1.075
[19,     3] loss: 1.178
[20,     3] loss: 1.006
[21,     3] loss: 1.057
[22,     3] loss: 1.075
[23,     3] loss: 1.099
[24,     3] loss: 1.311
[25,     3] loss: 1.117
[26,     3] loss: 1.082
[27,     3] loss: 1.170
[28,     3] loss: 1.031
[29,     3] loss: 1.014
[30,     3] loss: 0.988
[31,     3] loss: 1.029
[32,     3] loss: 0.908
[33,     3] loss: 0.924
[34,     3] loss: 0.908
[35,     3] loss: 0.976
[36,     3] loss: 0.916
[37,     3] loss: 0.993
[38,     3] loss: 0.853
[39,     3] loss: 0.901
[40,     3] loss: 0.933
[41,     3] loss: 0.855
[42,     3] loss: 0.922
[43,     3] loss: 0.876
[44,     3] loss: 0.993
[45,     3] loss: 0.839
[46,     3] loss: 0.852
[47,     3] loss: 0.943
[48,     3] loss: 0.927
[49,     3] loss: 0.809
[50,     3] loss: 0.890
[51,     3] loss: 0.835
[52,     3] loss: 0.921
[53,     3] loss: 0.892
[54,     3] loss: 0.826
[55,     3] loss: 0.861
[56,     3] loss: 0.877
[57,     3] loss: 0.924
[58,     3] loss: 0.851
[59,     3] loss: 0.842
[60,     3] loss: 0.821
[61,     3] loss: 0.839
[62,     3] loss: 0.827
[63,     3] loss: 0.803
[64,     3] loss: 0.787
[65,     3] loss: 0.815
[66,     3] loss: 0.786
[67,     3] loss: 0.831
[68,     3] loss: 0.773
[69,     3] loss: 0.828
[70,     3] loss: 0.857
[71,     3] loss: 0.914
[72,     3] loss: 0.839
[73,     3] loss: 0.794
[74,     3] loss: 0.845
[75,     3] loss: 0.794
[76,     3] loss: 0.831
[77,     3] loss: 0.822
[78,     3] loss: 0.785
[79,     3] loss: 0.792
[80,     3] loss: 0.768
[81,     3] loss: 0.798
[82,     3] loss: 0.825
[83,     3] loss: 0.857
[84,     3] loss: 0.874
[85,     3] loss: 0.788
[86,     3] loss: 0.820
[87,     3] loss: 0.869
[88,     3] loss: 0.867
[89,     3] loss: 0.832
[90,     3] loss: 0.814
[91,     3] loss: 0.778
[92,     3] loss: 0.803
[93,     3] loss: 0.773
[94,     3] loss: 0.752
[95,     3] loss: 0.775
[96,     3] loss: 0.749
[97,     3] loss: 0.791
[98,     3] loss: 0.770
[99,     3] loss: 0.748
[100,     3] loss: 0.748
[101,     3] loss: 0.745
[102,     3] loss: 0.743
Early stopping applied (best metric=0.526997447013855)
Finished Training
Total time taken: 28.145138025283813
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.388
[3,     3] loss: 1.382
[4,     3] loss: 1.387
[5,     3] loss: 1.382
[6,     3] loss: 1.373
[7,     3] loss: 1.383
[8,     3] loss: 1.383
[9,     3] loss: 1.359
[10,     3] loss: 1.367
[11,     3] loss: 1.342
[12,     3] loss: 1.345
[13,     3] loss: 1.306
[14,     3] loss: 1.277
[15,     3] loss: 1.277
[16,     3] loss: 1.292
[17,     3] loss: 1.195
[18,     3] loss: 1.160
[19,     3] loss: 1.111
[20,     3] loss: 1.197
[21,     3] loss: 1.065
[22,     3] loss: 1.142
[23,     3] loss: 1.060
[24,     3] loss: 1.005
[25,     3] loss: 1.012
[26,     3] loss: 1.026
[27,     3] loss: 1.029
[28,     3] loss: 0.932
[29,     3] loss: 0.949
[30,     3] loss: 0.902
[31,     3] loss: 0.917
[32,     3] loss: 0.902
[33,     3] loss: 0.904
[34,     3] loss: 0.871
[35,     3] loss: 0.878
[36,     3] loss: 0.869
[37,     3] loss: 0.890
[38,     3] loss: 0.875
[39,     3] loss: 0.913
[40,     3] loss: 0.822
[41,     3] loss: 0.841
[42,     3] loss: 0.924
[43,     3] loss: 0.872
[44,     3] loss: 0.908
[45,     3] loss: 0.902
[46,     3] loss: 0.914
[47,     3] loss: 0.891
[48,     3] loss: 0.819
[49,     3] loss: 0.814
[50,     3] loss: 0.874
[51,     3] loss: 1.017
[52,     3] loss: 0.952
[53,     3] loss: 0.947
[54,     3] loss: 0.845
[55,     3] loss: 0.872
[56,     3] loss: 0.898
[57,     3] loss: 0.839
[58,     3] loss: 0.884
[59,     3] loss: 0.954
[60,     3] loss: 0.830
[61,     3] loss: 0.803
[62,     3] loss: 0.826
[63,     3] loss: 0.843
[64,     3] loss: 0.821
[65,     3] loss: 0.813
[66,     3] loss: 0.812
[67,     3] loss: 0.827
[68,     3] loss: 0.860
[69,     3] loss: 0.814
[70,     3] loss: 0.799
[71,     3] loss: 0.899
[72,     3] loss: 0.840
[73,     3] loss: 0.872
[74,     3] loss: 0.828
Early stopping applied (best metric=0.5277138352394104)
Finished Training
Total time taken: 20.677099466323853
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.393
[3,     3] loss: 1.391
[4,     3] loss: 1.386
[5,     3] loss: 1.384
[6,     3] loss: 1.387
[7,     3] loss: 1.384
[8,     3] loss: 1.383
[9,     3] loss: 1.379
[10,     3] loss: 1.381
[11,     3] loss: 1.378
[12,     3] loss: 1.361
[13,     3] loss: 1.370
[14,     3] loss: 1.337
[15,     3] loss: 1.335
[16,     3] loss: 1.299
[17,     3] loss: 1.234
[18,     3] loss: 1.264
[19,     3] loss: 1.248
[20,     3] loss: 1.276
[21,     3] loss: 1.126
[22,     3] loss: 1.140
[23,     3] loss: 1.174
[24,     3] loss: 1.135
[25,     3] loss: 1.106
[26,     3] loss: 1.105
[27,     3] loss: 0.996
[28,     3] loss: 1.090
[29,     3] loss: 1.032
[30,     3] loss: 1.076
[31,     3] loss: 1.030
[32,     3] loss: 1.026
[33,     3] loss: 1.018
[34,     3] loss: 0.989
[35,     3] loss: 0.928
[36,     3] loss: 0.933
[37,     3] loss: 0.957
[38,     3] loss: 0.887
[39,     3] loss: 0.889
[40,     3] loss: 0.914
[41,     3] loss: 0.933
[42,     3] loss: 0.948
[43,     3] loss: 0.918
[44,     3] loss: 0.917
[45,     3] loss: 0.925
[46,     3] loss: 0.980
[47,     3] loss: 0.913
[48,     3] loss: 0.902
[49,     3] loss: 0.860
[50,     3] loss: 0.970
[51,     3] loss: 0.851
[52,     3] loss: 0.858
[53,     3] loss: 0.882
[54,     3] loss: 0.819
[55,     3] loss: 0.897
[56,     3] loss: 0.851
[57,     3] loss: 0.799
[58,     3] loss: 0.807
[59,     3] loss: 0.827
[60,     3] loss: 0.817
[61,     3] loss: 0.856
[62,     3] loss: 0.894
[63,     3] loss: 0.845
[64,     3] loss: 0.858
[65,     3] loss: 0.827
[66,     3] loss: 0.816
[67,     3] loss: 0.799
[68,     3] loss: 0.829
[69,     3] loss: 0.885
[70,     3] loss: 0.935
[71,     3] loss: 0.903
[72,     3] loss: 0.991
[73,     3] loss: 0.855
[74,     3] loss: 0.968
Early stopping applied (best metric=0.4791603684425354)
Finished Training
Total time taken: 20.47209906578064
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.386
[3,     3] loss: 1.384
[4,     3] loss: 1.381
[5,     3] loss: 1.381
[6,     3] loss: 1.380
[7,     3] loss: 1.377
[8,     3] loss: 1.379
[9,     3] loss: 1.358
[10,     3] loss: 1.346
[11,     3] loss: 1.359
[12,     3] loss: 1.321
[13,     3] loss: 1.262
[14,     3] loss: 1.280
[15,     3] loss: 1.199
[16,     3] loss: 1.241
[17,     3] loss: 1.152
[18,     3] loss: 1.106
[19,     3] loss: 1.095
[20,     3] loss: 1.037
[21,     3] loss: 1.108
[22,     3] loss: 1.049
[23,     3] loss: 1.078
[24,     3] loss: 1.057
[25,     3] loss: 1.028
[26,     3] loss: 1.033
[27,     3] loss: 1.026
[28,     3] loss: 1.033
[29,     3] loss: 1.034
[30,     3] loss: 1.001
[31,     3] loss: 1.034
[32,     3] loss: 0.933
[33,     3] loss: 0.935
[34,     3] loss: 0.985
[35,     3] loss: 0.949
[36,     3] loss: 0.966
[37,     3] loss: 0.988
[38,     3] loss: 0.956
[39,     3] loss: 0.892
[40,     3] loss: 1.015
[41,     3] loss: 0.927
[42,     3] loss: 0.941
[43,     3] loss: 0.926
[44,     3] loss: 0.890
[45,     3] loss: 0.922
[46,     3] loss: 0.979
[47,     3] loss: 0.938
[48,     3] loss: 0.944
[49,     3] loss: 0.883
[50,     3] loss: 0.886
[51,     3] loss: 0.970
[52,     3] loss: 0.876
[53,     3] loss: 0.844
[54,     3] loss: 0.854
[55,     3] loss: 0.952
[56,     3] loss: 0.909
[57,     3] loss: 0.845
[58,     3] loss: 0.854
[59,     3] loss: 0.824
[60,     3] loss: 0.861
[61,     3] loss: 0.868
[62,     3] loss: 0.795
[63,     3] loss: 0.913
[64,     3] loss: 0.846
[65,     3] loss: 0.854
[66,     3] loss: 0.811
[67,     3] loss: 0.910
[68,     3] loss: 0.889
[69,     3] loss: 0.949
[70,     3] loss: 0.976
[71,     3] loss: 0.842
[72,     3] loss: 0.848
[73,     3] loss: 0.845
Early stopping applied (best metric=0.5078797936439514)
Finished Training
Total time taken: 20.219095468521118
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.393
[3,     3] loss: 1.383
[4,     3] loss: 1.387
[5,     3] loss: 1.384
[6,     3] loss: 1.385
[7,     3] loss: 1.384
[8,     3] loss: 1.378
[9,     3] loss: 1.374
[10,     3] loss: 1.371
[11,     3] loss: 1.353
[12,     3] loss: 1.327
[13,     3] loss: 1.322
[14,     3] loss: 1.285
[15,     3] loss: 1.263
[16,     3] loss: 1.198
[17,     3] loss: 1.250
[18,     3] loss: 1.201
[19,     3] loss: 1.070
[20,     3] loss: 1.095
[21,     3] loss: 1.085
[22,     3] loss: 1.041
[23,     3] loss: 1.137
[24,     3] loss: 0.992
[25,     3] loss: 0.966
[26,     3] loss: 1.027
[27,     3] loss: 1.008
[28,     3] loss: 1.080
[29,     3] loss: 0.958
[30,     3] loss: 1.032
[31,     3] loss: 0.990
[32,     3] loss: 0.863
[33,     3] loss: 0.896
[34,     3] loss: 0.892
[35,     3] loss: 0.889
[36,     3] loss: 1.068
[37,     3] loss: 0.918
[38,     3] loss: 1.023
[39,     3] loss: 0.955
[40,     3] loss: 0.886
[41,     3] loss: 0.941
[42,     3] loss: 0.897
[43,     3] loss: 0.862
[44,     3] loss: 0.837
[45,     3] loss: 0.906
[46,     3] loss: 0.819
[47,     3] loss: 0.911
[48,     3] loss: 0.835
[49,     3] loss: 0.830
[50,     3] loss: 0.807
[51,     3] loss: 0.791
[52,     3] loss: 0.806
[53,     3] loss: 0.797
[54,     3] loss: 0.866
[55,     3] loss: 0.787
[56,     3] loss: 0.862
[57,     3] loss: 0.812
[58,     3] loss: 0.902
[59,     3] loss: 0.811
[60,     3] loss: 0.814
[61,     3] loss: 0.786
[62,     3] loss: 0.826
[63,     3] loss: 0.886
[64,     3] loss: 0.927
[65,     3] loss: 0.809
[66,     3] loss: 0.912
[67,     3] loss: 0.861
[68,     3] loss: 0.895
[69,     3] loss: 0.908
[70,     3] loss: 0.871
[71,     3] loss: 0.871
[72,     3] loss: 0.843
[73,     3] loss: 0.909
[74,     3] loss: 0.830
[75,     3] loss: 0.794
Early stopping applied (best metric=0.5283417105674744)
Finished Training
Total time taken: 20.727097511291504
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.397
[3,     3] loss: 1.381
[4,     3] loss: 1.389
[5,     3] loss: 1.386
[6,     3] loss: 1.378
[7,     3] loss: 1.375
[8,     3] loss: 1.354
[9,     3] loss: 1.388
[10,     3] loss: 1.370
[11,     3] loss: 1.361
[12,     3] loss: 1.335
[13,     3] loss: 1.305
[14,     3] loss: 1.276
[15,     3] loss: 1.255
[16,     3] loss: 1.229
[17,     3] loss: 1.133
[18,     3] loss: 1.266
[19,     3] loss: 1.152
[20,     3] loss: 1.118
[21,     3] loss: 1.120
[22,     3] loss: 1.127
[23,     3] loss: 1.040
[24,     3] loss: 1.037
[25,     3] loss: 1.108
[26,     3] loss: 1.001
[27,     3] loss: 1.001
[28,     3] loss: 0.987
[29,     3] loss: 1.045
[30,     3] loss: 0.949
[31,     3] loss: 0.996
[32,     3] loss: 0.974
[33,     3] loss: 1.049
[34,     3] loss: 1.012
[35,     3] loss: 0.999
[36,     3] loss: 1.139
[37,     3] loss: 1.042
[38,     3] loss: 1.017
[39,     3] loss: 1.072
[40,     3] loss: 0.980
[41,     3] loss: 0.958
[42,     3] loss: 0.948
[43,     3] loss: 1.025
[44,     3] loss: 0.929
[45,     3] loss: 0.956
[46,     3] loss: 0.953
[47,     3] loss: 0.962
[48,     3] loss: 0.944
[49,     3] loss: 1.024
[50,     3] loss: 0.959
[51,     3] loss: 0.944
[52,     3] loss: 0.967
[53,     3] loss: 0.942
[54,     3] loss: 0.942
[55,     3] loss: 0.998
[56,     3] loss: 0.889
[57,     3] loss: 0.891
[58,     3] loss: 0.922
[59,     3] loss: 0.899
[60,     3] loss: 0.910
[61,     3] loss: 0.810
[62,     3] loss: 0.890
[63,     3] loss: 0.901
[64,     3] loss: 1.014
[65,     3] loss: 0.843
[66,     3] loss: 1.128
[67,     3] loss: 1.003
[68,     3] loss: 0.955
[69,     3] loss: 0.941
[70,     3] loss: 0.920
[71,     3] loss: 0.890
[72,     3] loss: 0.944
[73,     3] loss: 0.883
[74,     3] loss: 0.913
[75,     3] loss: 0.850
[76,     3] loss: 0.965
[77,     3] loss: 0.905
[78,     3] loss: 0.892
[79,     3] loss: 0.845
[80,     3] loss: 0.861
[81,     3] loss: 0.859
[82,     3] loss: 0.869
[83,     3] loss: 0.811
[84,     3] loss: 0.942
[85,     3] loss: 0.848
[86,     3] loss: 0.944
[87,     3] loss: 0.903
[88,     3] loss: 0.854
[89,     3] loss: 0.865
[90,     3] loss: 0.855
Early stopping applied (best metric=0.5147441625595093)
Finished Training
Total time taken: 24.890321493148804
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.389
[3,     3] loss: 1.387
[4,     3] loss: 1.380
[5,     3] loss: 1.379
[6,     3] loss: 1.381
[7,     3] loss: 1.366
[8,     3] loss: 1.355
[9,     3] loss: 1.356
[10,     3] loss: 1.327
[11,     3] loss: 1.271
[12,     3] loss: 1.291
[13,     3] loss: 1.205
[14,     3] loss: 1.293
[15,     3] loss: 1.219
[16,     3] loss: 1.241
[17,     3] loss: 1.159
[18,     3] loss: 1.140
[19,     3] loss: 1.172
[20,     3] loss: 1.107
[21,     3] loss: 1.131
[22,     3] loss: 1.043
[23,     3] loss: 1.031
[24,     3] loss: 1.069
[25,     3] loss: 0.958
[26,     3] loss: 0.960
[27,     3] loss: 0.919
[28,     3] loss: 0.984
[29,     3] loss: 0.965
[30,     3] loss: 1.043
[31,     3] loss: 0.954
[32,     3] loss: 0.955
[33,     3] loss: 0.913
[34,     3] loss: 0.931
[35,     3] loss: 0.942
[36,     3] loss: 1.070
[37,     3] loss: 0.884
[38,     3] loss: 0.977
[39,     3] loss: 0.989
[40,     3] loss: 1.050
[41,     3] loss: 0.951
[42,     3] loss: 0.975
[43,     3] loss: 0.939
[44,     3] loss: 0.960
[45,     3] loss: 0.985
[46,     3] loss: 0.929
[47,     3] loss: 0.931
[48,     3] loss: 0.892
[49,     3] loss: 0.886
[50,     3] loss: 0.894
[51,     3] loss: 0.918
[52,     3] loss: 0.846
[53,     3] loss: 0.859
[54,     3] loss: 0.899
[55,     3] loss: 0.828
[56,     3] loss: 0.861
[57,     3] loss: 0.877
[58,     3] loss: 0.853
[59,     3] loss: 0.822
[60,     3] loss: 0.825
[61,     3] loss: 0.854
[62,     3] loss: 0.840
[63,     3] loss: 0.771
[64,     3] loss: 0.827
[65,     3] loss: 0.866
[66,     3] loss: 0.820
[67,     3] loss: 0.829
[68,     3] loss: 0.788
[69,     3] loss: 0.806
[70,     3] loss: 0.780
[71,     3] loss: 0.785
[72,     3] loss: 0.779
[73,     3] loss: 0.779
[74,     3] loss: 0.776
[75,     3] loss: 0.794
[76,     3] loss: 0.791
[77,     3] loss: 0.779
[78,     3] loss: 0.815
[79,     3] loss: 0.789
[80,     3] loss: 0.791
[81,     3] loss: 0.808
[82,     3] loss: 0.775
[83,     3] loss: 0.800
[84,     3] loss: 0.828
[85,     3] loss: 0.867
[86,     3] loss: 0.833
[87,     3] loss: 0.780
[88,     3] loss: 0.777
[89,     3] loss: 0.774
[90,     3] loss: 0.792
[91,     3] loss: 0.776
[92,     3] loss: 0.799
[93,     3] loss: 0.806
[94,     3] loss: 0.754
[95,     3] loss: 0.778
[96,     3] loss: 0.891
[97,     3] loss: 0.785
[98,     3] loss: 0.799
[99,     3] loss: 0.787
[100,     3] loss: 0.765
[101,     3] loss: 0.776
[102,     3] loss: 0.759
[103,     3] loss: 0.755
[104,     3] loss: 0.752
[105,     3] loss: 0.748
[106,     3] loss: 0.754
[107,     3] loss: 0.749
[108,     3] loss: 0.742
[109,     3] loss: 0.756
[110,     3] loss: 0.767
[111,     3] loss: 0.746
[112,     3] loss: 0.753
[113,     3] loss: 0.753
[114,     3] loss: 0.749
[115,     3] loss: 0.739
[116,     3] loss: 0.739
[117,     3] loss: 0.748
[118,     3] loss: 0.744
[119,     3] loss: 0.757
Early stopping applied (best metric=0.5206912755966187)
Finished Training
Total time taken: 32.8011577129364
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.391
[3,     3] loss: 1.387
[4,     3] loss: 1.380
[5,     3] loss: 1.389
[6,     3] loss: 1.381
[7,     3] loss: 1.376
[8,     3] loss: 1.373
[9,     3] loss: 1.380
[10,     3] loss: 1.373
[11,     3] loss: 1.377
[12,     3] loss: 1.366
[13,     3] loss: 1.343
[14,     3] loss: 1.333
[15,     3] loss: 1.292
[16,     3] loss: 1.264
[17,     3] loss: 1.254
[18,     3] loss: 1.209
[19,     3] loss: 1.118
[20,     3] loss: 1.192
[21,     3] loss: 1.109
[22,     3] loss: 1.072
[23,     3] loss: 1.046
[24,     3] loss: 1.203
[25,     3] loss: 1.046
[26,     3] loss: 0.980
[27,     3] loss: 0.983
[28,     3] loss: 1.002
[29,     3] loss: 1.038
[30,     3] loss: 1.096
[31,     3] loss: 0.990
[32,     3] loss: 1.013
[33,     3] loss: 1.058
[34,     3] loss: 1.016
[35,     3] loss: 0.989
[36,     3] loss: 1.009
[37,     3] loss: 0.964
[38,     3] loss: 0.997
[39,     3] loss: 0.913
[40,     3] loss: 0.920
[41,     3] loss: 1.031
[42,     3] loss: 0.910
[43,     3] loss: 0.877
[44,     3] loss: 0.911
[45,     3] loss: 0.914
[46,     3] loss: 0.982
[47,     3] loss: 0.861
[48,     3] loss: 0.986
[49,     3] loss: 0.934
[50,     3] loss: 0.996
[51,     3] loss: 1.048
[52,     3] loss: 1.076
[53,     3] loss: 1.097
[54,     3] loss: 0.980
[55,     3] loss: 1.037
[56,     3] loss: 0.990
[57,     3] loss: 1.035
[58,     3] loss: 0.892
[59,     3] loss: 0.987
[60,     3] loss: 0.957
[61,     3] loss: 0.906
[62,     3] loss: 0.922
[63,     3] loss: 0.849
[64,     3] loss: 0.879
[65,     3] loss: 0.832
[66,     3] loss: 0.809
[67,     3] loss: 0.833
[68,     3] loss: 0.820
[69,     3] loss: 0.836
[70,     3] loss: 0.850
[71,     3] loss: 0.866
Early stopping applied (best metric=0.5120397210121155)
Finished Training
Total time taken: 19.778096437454224
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.401
[2,     3] loss: 1.381
[3,     3] loss: 1.396
[4,     3] loss: 1.389
[5,     3] loss: 1.388
[6,     3] loss: 1.384
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.384
[10,     3] loss: 1.381
[11,     3] loss: 1.381
[12,     3] loss: 1.372
[13,     3] loss: 1.364
[14,     3] loss: 1.365
[15,     3] loss: 1.327
[16,     3] loss: 1.309
[17,     3] loss: 1.269
[18,     3] loss: 1.249
[19,     3] loss: 1.156
[20,     3] loss: 1.178
[21,     3] loss: 1.141
[22,     3] loss: 1.175
[23,     3] loss: 1.122
[24,     3] loss: 1.085
[25,     3] loss: 1.064
[26,     3] loss: 1.008
[27,     3] loss: 1.137
[28,     3] loss: 1.171
[29,     3] loss: 1.065
[30,     3] loss: 1.068
[31,     3] loss: 1.064
[32,     3] loss: 1.088
[33,     3] loss: 1.000
[34,     3] loss: 0.977
[35,     3] loss: 0.961
[36,     3] loss: 0.997
[37,     3] loss: 0.893
[38,     3] loss: 0.900
[39,     3] loss: 0.895
[40,     3] loss: 0.911
[41,     3] loss: 0.900
[42,     3] loss: 0.982
[43,     3] loss: 0.885
[44,     3] loss: 1.017
[45,     3] loss: 1.023
[46,     3] loss: 0.987
[47,     3] loss: 0.925
[48,     3] loss: 0.940
[49,     3] loss: 0.929
[50,     3] loss: 0.945
[51,     3] loss: 0.919
[52,     3] loss: 0.861
[53,     3] loss: 0.933
[54,     3] loss: 0.904
[55,     3] loss: 0.935
[56,     3] loss: 0.886
[57,     3] loss: 0.867
[58,     3] loss: 0.860
[59,     3] loss: 0.826
[60,     3] loss: 0.935
[61,     3] loss: 0.914
[62,     3] loss: 0.851
[63,     3] loss: 0.936
[64,     3] loss: 0.867
[65,     3] loss: 0.858
[66,     3] loss: 0.886
[67,     3] loss: 0.845
[68,     3] loss: 0.994
[69,     3] loss: 0.883
[70,     3] loss: 0.831
[71,     3] loss: 0.868
[72,     3] loss: 0.894
Early stopping applied (best metric=0.513357937335968)
Finished Training
Total time taken: 20.092097282409668
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.386
[3,     3] loss: 1.383
[4,     3] loss: 1.377
[5,     3] loss: 1.378
[6,     3] loss: 1.374
[7,     3] loss: 1.360
[8,     3] loss: 1.332
[9,     3] loss: 1.308
[10,     3] loss: 1.299
[11,     3] loss: 1.284
[12,     3] loss: 1.255
[13,     3] loss: 1.254
[14,     3] loss: 1.262
[15,     3] loss: 1.203
[16,     3] loss: 1.183
[17,     3] loss: 1.124
[18,     3] loss: 1.108
[19,     3] loss: 1.067
[20,     3] loss: 1.106
[21,     3] loss: 1.038
[22,     3] loss: 1.072
[23,     3] loss: 1.087
[24,     3] loss: 1.020
[25,     3] loss: 1.025
[26,     3] loss: 0.953
[27,     3] loss: 1.019
[28,     3] loss: 0.977
[29,     3] loss: 0.952
[30,     3] loss: 1.003
[31,     3] loss: 0.925
[32,     3] loss: 0.900
[33,     3] loss: 0.917
[34,     3] loss: 0.932
[35,     3] loss: 0.972
[36,     3] loss: 0.912
[37,     3] loss: 0.982
[38,     3] loss: 0.983
[39,     3] loss: 0.961
[40,     3] loss: 0.933
[41,     3] loss: 1.054
[42,     3] loss: 0.882
[43,     3] loss: 0.953
[44,     3] loss: 0.964
[45,     3] loss: 0.934
[46,     3] loss: 0.926
[47,     3] loss: 0.870
[48,     3] loss: 0.928
[49,     3] loss: 0.924
[50,     3] loss: 0.907
[51,     3] loss: 0.809
[52,     3] loss: 0.802
[53,     3] loss: 0.837
[54,     3] loss: 0.807
[55,     3] loss: 0.794
[56,     3] loss: 0.792
[57,     3] loss: 0.791
[58,     3] loss: 0.861
[59,     3] loss: 0.950
[60,     3] loss: 0.937
[61,     3] loss: 0.896
[62,     3] loss: 0.864
[63,     3] loss: 0.801
[64,     3] loss: 0.821
[65,     3] loss: 0.790
[66,     3] loss: 0.839
[67,     3] loss: 0.771
[68,     3] loss: 0.772
[69,     3] loss: 0.783
[70,     3] loss: 0.771
[71,     3] loss: 0.744
[72,     3] loss: 0.758
[73,     3] loss: 0.763
[74,     3] loss: 0.746
[75,     3] loss: 0.763
[76,     3] loss: 0.753
[77,     3] loss: 0.820
[78,     3] loss: 0.760
[79,     3] loss: 0.784
[80,     3] loss: 0.795
[81,     3] loss: 0.795
[82,     3] loss: 0.780
[83,     3] loss: 0.816
Early stopping applied (best metric=0.5174169540405273)
Finished Training
Total time taken: 23.36211323738098
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.373
[3,     3] loss: 1.389
[4,     3] loss: 1.383
[5,     3] loss: 1.377
[6,     3] loss: 1.374
[7,     3] loss: 1.367
[8,     3] loss: 1.368
[9,     3] loss: 1.354
[10,     3] loss: 1.343
[11,     3] loss: 1.314
[12,     3] loss: 1.287
[13,     3] loss: 1.242
[14,     3] loss: 1.249
[15,     3] loss: 1.297
[16,     3] loss: 1.190
[17,     3] loss: 1.132
[18,     3] loss: 1.123
[19,     3] loss: 1.175
[20,     3] loss: 1.105
[21,     3] loss: 1.100
[22,     3] loss: 1.095
[23,     3] loss: 1.144
[24,     3] loss: 1.099
[25,     3] loss: 1.091
[26,     3] loss: 1.048
[27,     3] loss: 1.094
[28,     3] loss: 1.031
[29,     3] loss: 1.042
[30,     3] loss: 1.136
[31,     3] loss: 0.983
[32,     3] loss: 0.933
[33,     3] loss: 0.992
[34,     3] loss: 0.967
[35,     3] loss: 0.911
[36,     3] loss: 0.880
[37,     3] loss: 0.875
[38,     3] loss: 0.904
[39,     3] loss: 0.963
[40,     3] loss: 0.846
[41,     3] loss: 0.932
[42,     3] loss: 1.002
[43,     3] loss: 0.956
[44,     3] loss: 0.847
[45,     3] loss: 0.850
[46,     3] loss: 0.897
[47,     3] loss: 0.808
[48,     3] loss: 0.819
[49,     3] loss: 0.829
[50,     3] loss: 0.850
[51,     3] loss: 0.846
[52,     3] loss: 0.833
[53,     3] loss: 0.807
[54,     3] loss: 0.849
[55,     3] loss: 0.855
[56,     3] loss: 0.804
[57,     3] loss: 0.800
[58,     3] loss: 0.809
[59,     3] loss: 0.776
[60,     3] loss: 0.831
[61,     3] loss: 0.783
[62,     3] loss: 0.793
[63,     3] loss: 0.775
[64,     3] loss: 0.771
[65,     3] loss: 0.775
[66,     3] loss: 0.797
[67,     3] loss: 0.851
[68,     3] loss: 0.800
Early stopping applied (best metric=0.5286645889282227)
Finished Training
Total time taken: 18.946090936660767
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.388
[3,     3] loss: 1.388
[4,     3] loss: 1.391
[5,     3] loss: 1.388
[6,     3] loss: 1.385
[7,     3] loss: 1.390
[8,     3] loss: 1.383
[9,     3] loss: 1.373
[10,     3] loss: 1.382
[11,     3] loss: 1.389
[12,     3] loss: 1.371
[13,     3] loss: 1.363
[14,     3] loss: 1.347
[15,     3] loss: 1.358
[16,     3] loss: 1.386
[17,     3] loss: 1.352
[18,     3] loss: 1.315
[19,     3] loss: 1.272
[20,     3] loss: 1.295
[21,     3] loss: 1.230
[22,     3] loss: 1.187
[23,     3] loss: 1.144
[24,     3] loss: 1.155
[25,     3] loss: 1.070
[26,     3] loss: 1.045
[27,     3] loss: 1.049
[28,     3] loss: 1.003
[29,     3] loss: 1.024
[30,     3] loss: 0.971
[31,     3] loss: 0.983
[32,     3] loss: 1.008
[33,     3] loss: 0.925
[34,     3] loss: 0.888
[35,     3] loss: 0.954
[36,     3] loss: 0.983
[37,     3] loss: 0.910
[38,     3] loss: 0.903
[39,     3] loss: 0.916
[40,     3] loss: 0.927
[41,     3] loss: 0.932
[42,     3] loss: 0.972
[43,     3] loss: 0.874
[44,     3] loss: 0.932
[45,     3] loss: 0.889
[46,     3] loss: 0.868
[47,     3] loss: 0.929
[48,     3] loss: 1.021
[49,     3] loss: 0.897
[50,     3] loss: 0.888
[51,     3] loss: 0.862
[52,     3] loss: 0.903
[53,     3] loss: 0.889
[54,     3] loss: 0.919
[55,     3] loss: 0.880
[56,     3] loss: 0.930
[57,     3] loss: 0.918
[58,     3] loss: 0.902
[59,     3] loss: 0.883
[60,     3] loss: 0.991
[61,     3] loss: 0.922
[62,     3] loss: 1.037
[63,     3] loss: 1.032
[64,     3] loss: 0.945
[65,     3] loss: 0.946
[66,     3] loss: 0.955
[67,     3] loss: 0.923
[68,     3] loss: 0.964
[69,     3] loss: 0.905
[70,     3] loss: 0.849
[71,     3] loss: 0.983
[72,     3] loss: 0.794
[73,     3] loss: 0.865
[74,     3] loss: 0.823
[75,     3] loss: 0.799
[76,     3] loss: 0.856
[77,     3] loss: 0.798
[78,     3] loss: 0.896
[79,     3] loss: 0.868
[80,     3] loss: 0.956
[81,     3] loss: 0.908
[82,     3] loss: 0.909
[83,     3] loss: 0.880
[84,     3] loss: 0.944
[85,     3] loss: 0.875
[86,     3] loss: 0.816
[87,     3] loss: 0.820
[88,     3] loss: 0.895
[89,     3] loss: 0.860
[90,     3] loss: 0.836
[91,     3] loss: 0.827
[92,     3] loss: 0.823
[93,     3] loss: 0.803
[94,     3] loss: 0.800
[95,     3] loss: 0.818
[96,     3] loss: 0.766
[97,     3] loss: 0.764
[98,     3] loss: 0.767
[99,     3] loss: 0.802
[100,     3] loss: 0.772
[101,     3] loss: 0.765
[102,     3] loss: 0.809
[103,     3] loss: 0.753
[104,     3] loss: 0.766
[105,     3] loss: 0.756
[106,     3] loss: 0.773
[107,     3] loss: 0.759
[108,     3] loss: 0.764
[109,     3] loss: 0.745
[110,     3] loss: 0.783
[111,     3] loss: 0.777
[112,     3] loss: 0.780
[113,     3] loss: 0.779
[114,     3] loss: 0.788
[115,     3] loss: 0.868
[116,     3] loss: 0.917
[117,     3] loss: 0.962
[118,     3] loss: 0.948
[119,     3] loss: 0.827
[120,     3] loss: 0.846
[121,     3] loss: 0.816
[122,     3] loss: 0.796
[123,     3] loss: 0.835
[124,     3] loss: 0.797
[125,     3] loss: 0.773
[126,     3] loss: 0.825
[127,     3] loss: 0.770
[128,     3] loss: 0.799
[129,     3] loss: 0.788
[130,     3] loss: 0.762
[131,     3] loss: 0.857
[132,     3] loss: 0.913
[133,     3] loss: 0.880
[134,     3] loss: 0.822
[135,     3] loss: 0.844
[136,     3] loss: 0.825
[137,     3] loss: 0.808
[138,     3] loss: 0.818
[139,     3] loss: 0.843
[140,     3] loss: 0.789
[141,     3] loss: 0.810
[142,     3] loss: 0.805
[143,     3] loss: 0.770
[144,     3] loss: 0.832
[145,     3] loss: 0.795
[146,     3] loss: 0.763
[147,     3] loss: 0.813
[148,     3] loss: 0.817
[149,     3] loss: 0.803
[150,     3] loss: 0.761
[151,     3] loss: 0.791
[152,     3] loss: 0.793
[153,     3] loss: 0.784
[154,     3] loss: 0.786
[155,     3] loss: 0.766
[156,     3] loss: 0.769
[157,     3] loss: 0.767
[158,     3] loss: 0.766
[159,     3] loss: 0.757
[160,     3] loss: 0.813
[161,     3] loss: 0.760
Early stopping applied (best metric=0.5189391374588013)
Finished Training
Total time taken: 45.5462851524353
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.400
[3,     3] loss: 1.385
[4,     3] loss: 1.387
[5,     3] loss: 1.377
[6,     3] loss: 1.389
[7,     3] loss: 1.390
[8,     3] loss: 1.376
[9,     3] loss: 1.372
[10,     3] loss: 1.382
[11,     3] loss: 1.366
[12,     3] loss: 1.362
[13,     3] loss: 1.354
[14,     3] loss: 1.291
[15,     3] loss: 1.301
[16,     3] loss: 1.245
[17,     3] loss: 1.207
[18,     3] loss: 1.158
[19,     3] loss: 1.148
[20,     3] loss: 1.110
[21,     3] loss: 1.177
[22,     3] loss: 1.174
[23,     3] loss: 1.127
[24,     3] loss: 1.049
[25,     3] loss: 1.130
[26,     3] loss: 0.953
[27,     3] loss: 1.044
[28,     3] loss: 1.152
[29,     3] loss: 1.036
[30,     3] loss: 1.048
[31,     3] loss: 1.203
[32,     3] loss: 1.004
[33,     3] loss: 0.991
[34,     3] loss: 1.023
[35,     3] loss: 1.010
[36,     3] loss: 0.913
[37,     3] loss: 1.155
[38,     3] loss: 1.031
[39,     3] loss: 0.923
[40,     3] loss: 0.895
[41,     3] loss: 0.964
[42,     3] loss: 0.884
[43,     3] loss: 0.873
[44,     3] loss: 0.929
[45,     3] loss: 0.924
[46,     3] loss: 0.865
[47,     3] loss: 0.962
[48,     3] loss: 0.917
[49,     3] loss: 0.964
[50,     3] loss: 0.893
[51,     3] loss: 0.885
[52,     3] loss: 0.888
[53,     3] loss: 0.879
[54,     3] loss: 0.860
[55,     3] loss: 0.824
[56,     3] loss: 0.842
[57,     3] loss: 0.826
[58,     3] loss: 0.831
[59,     3] loss: 0.790
[60,     3] loss: 0.798
[61,     3] loss: 0.768
[62,     3] loss: 0.756
[63,     3] loss: 0.770
[64,     3] loss: 0.833
[65,     3] loss: 0.872
[66,     3] loss: 0.826
[67,     3] loss: 0.796
[68,     3] loss: 0.885
Early stopping applied (best metric=0.4985502362251282)
Finished Training
Total time taken: 20.454100131988525
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.392
[3,     3] loss: 1.393
[4,     3] loss: 1.381
[5,     3] loss: 1.386
[6,     3] loss: 1.387
[7,     3] loss: 1.383
[8,     3] loss: 1.384
[9,     3] loss: 1.389
[10,     3] loss: 1.389
[11,     3] loss: 1.377
[12,     3] loss: 1.382
[13,     3] loss: 1.374
[14,     3] loss: 1.370
[15,     3] loss: 1.353
[16,     3] loss: 1.343
[17,     3] loss: 1.308
[18,     3] loss: 1.321
[19,     3] loss: 1.300
[20,     3] loss: 1.230
[21,     3] loss: 1.227
[22,     3] loss: 1.176
[23,     3] loss: 1.106
[24,     3] loss: 1.092
[25,     3] loss: 1.081
[26,     3] loss: 1.147
[27,     3] loss: 1.050
[28,     3] loss: 1.004
[29,     3] loss: 1.133
[30,     3] loss: 1.141
[31,     3] loss: 1.084
[32,     3] loss: 1.036
[33,     3] loss: 0.994
[34,     3] loss: 1.103
[35,     3] loss: 1.031
[36,     3] loss: 1.010
[37,     3] loss: 1.012
[38,     3] loss: 1.085
[39,     3] loss: 1.103
[40,     3] loss: 1.058
[41,     3] loss: 1.135
[42,     3] loss: 0.966
[43,     3] loss: 1.072
[44,     3] loss: 0.939
[45,     3] loss: 0.983
[46,     3] loss: 1.016
[47,     3] loss: 1.000
[48,     3] loss: 0.945
[49,     3] loss: 1.021
[50,     3] loss: 0.900
[51,     3] loss: 1.026
[52,     3] loss: 0.948
[53,     3] loss: 0.853
[54,     3] loss: 0.962
[55,     3] loss: 0.920
[56,     3] loss: 0.966
[57,     3] loss: 0.930
[58,     3] loss: 0.955
[59,     3] loss: 0.982
[60,     3] loss: 0.885
[61,     3] loss: 0.880
[62,     3] loss: 0.946
[63,     3] loss: 0.943
[64,     3] loss: 0.873
[65,     3] loss: 0.922
[66,     3] loss: 0.879
[67,     3] loss: 0.830
[68,     3] loss: 0.857
[69,     3] loss: 0.846
[70,     3] loss: 0.826
[71,     3] loss: 0.819
[72,     3] loss: 0.782
[73,     3] loss: 0.801
[74,     3] loss: 0.772
[75,     3] loss: 0.788
[76,     3] loss: 0.796
[77,     3] loss: 0.783
[78,     3] loss: 0.777
[79,     3] loss: 0.766
[80,     3] loss: 0.791
[81,     3] loss: 0.791
[82,     3] loss: 0.789
[83,     3] loss: 0.758
[84,     3] loss: 0.764
[85,     3] loss: 0.786
[86,     3] loss: 0.790
[87,     3] loss: 0.764
Early stopping applied (best metric=0.49519139528274536)
Finished Training
Total time taken: 24.626119136810303
{'S-palmitoylation-C Validation Accuracy': 0.7255657846924223, 'S-palmitoylation-C Validation Sensitivity': 0.17544554455445543, 'S-palmitoylation-C Validation Specificity': 0.8634653537725582, 'S-palmitoylation-C Validation Precision': 0.24800945185232592, 'S-palmitoylation-C AUC ROC': 0.547358835480661, 'S-palmitoylation-C AUC PR': 0.2269935002032457, 'S-palmitoylation-C MCC': 0.04524011259981527, 'S-palmitoylation-C F1': 0.19367525115733347, 'Validation Loss (S-palmitoylation-C)': 0.5548969268798828, 'Hydroxylation-K Validation Accuracy': 0.7477836879432624, 'Hydroxylation-K Validation Sensitivity': 0.7422222222222222, 'Hydroxylation-K Validation Specificity': 0.7491228070175439, 'Hydroxylation-K Validation Precision': 0.4592094615624027, 'Hydroxylation-K AUC ROC': 0.8089668615984406, 'Hydroxylation-K AUC PR': 0.5581890773325233, 'Hydroxylation-K MCC': 0.43097005027941343, 'Hydroxylation-K F1': 0.5537655499052819, 'Validation Loss (Hydroxylation-K)': 0.5152538299560547, 'Validation Loss (total)': 1.0701507647832236, 'TimeToTrain': 23.99106672604879}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002477286238089866,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8581684882850581,
 'loss_weight_S-palmitoylation-C': 0.06185537996923643,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1414036996,
 'sample_weights': [0.659853186975911, 0.45056888248504673],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.218967473416155,
 'weight_decay_Hydroxylation-K': 1.5111114328484923,
 'weight_decay_S-palmitoylation-C': 6.078970127348752}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.390
[3,     3] loss: 1.377
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011091455253221332,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.954335472938004,
 'loss_weight_S-palmitoylation-C': 0.4016639990674593,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3483315776,
 'sample_weights': [0.06185537996923643, 0.8581684882850581],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.928374833290643,
 'weight_decay_Hydroxylation-K': 1.7374784828953036,
 'weight_decay_S-palmitoylation-C': 0.10457431620861612}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.384
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0067110233223957065,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2396781469835802,
 'loss_weight_S-palmitoylation-C': 0.017082203554080785,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1483035273,
 'sample_weights': [0.4016639990674593, 0.954335472938004],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7051996319592466,
 'weight_decay_Hydroxylation-K': 7.553527881606854,
 'weight_decay_S-palmitoylation-C': 6.388659355882027}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.392
[3,     3] loss: 1.385
[4,     3] loss: 1.384
[5,     3] loss: 1.389
[6,     3] loss: 1.394
[7,     3] loss: 1.389
[8,     3] loss: 1.384
[9,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00958523455526586,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7605064561792053,
 'loss_weight_S-palmitoylation-C': 0.135012115893196,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3471550743,
 'sample_weights': [0.017082203554080785, 0.2396781469835802],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.2881058929904956,
 'weight_decay_Hydroxylation-K': 7.108754982980119,
 'weight_decay_S-palmitoylation-C': 8.776481450944972}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.376
[3,     3] loss: 1.391
[4,     3] loss: 1.393
[5,     3] loss: 1.388
[6,     3] loss: 1.385
[7,     3] loss: 1.390
[8,     3] loss: 1.386
[9,     3] loss: 1.386
[10,     3] loss: 1.386
[11,     3] loss: 1.385
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.389
[15,     3] loss: 1.386
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.388
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.388
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.388
[31,     3] loss: 1.388
[32,     3] loss: 1.386
[33,     3] loss: 1.385
[34,     3] loss: 1.386
[35,     3] loss: 1.384
[36,     3] loss: 1.386
[37,     3] loss: 1.384
[38,     3] loss: 1.387
[39,     3] loss: 1.387
[40,     3] loss: 1.385
[41,     3] loss: 1.389
[42,     3] loss: 1.385
[43,     3] loss: 1.388
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.387
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.387
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.387
[53,     3] loss: 1.386
[54,     3] loss: 1.386
Early stopping applied (best metric=0.5626174807548523)
Finished Training
Total time taken: 15.043070793151855
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.388
[3,     3] loss: 1.384
[4,     3] loss: 1.394
[5,     3] loss: 1.397
[6,     3] loss: 1.386
[7,     3] loss: 1.387
[8,     3] loss: 1.385
[9,     3] loss: 1.384
[10,     3] loss: 1.388
[11,     3] loss: 1.389
[12,     3] loss: 1.385
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.387
[17,     3] loss: 1.385
[18,     3] loss: 1.387
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.387
[26,     3] loss: 1.387
[27,     3] loss: 1.386
[28,     3] loss: 1.387
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.387
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.387
[37,     3] loss: 1.386
[38,     3] loss: 1.387
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.384
[42,     3] loss: 1.387
[43,     3] loss: 1.389
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.387
[51,     3] loss: 1.387
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.385
[56,     3] loss: 1.385
[57,     3] loss: 1.388
[58,     3] loss: 1.386
[59,     3] loss: 1.389
[60,     3] loss: 1.385
[61,     3] loss: 1.388
[62,     3] loss: 1.386
[63,     3] loss: 1.387
[64,     3] loss: 1.386
[65,     3] loss: 1.387
[66,     3] loss: 1.386
[67,     3] loss: 1.386
[68,     3] loss: 1.386
[69,     3] loss: 1.386
[70,     3] loss: 1.386
[71,     3] loss: 1.386
[72,     3] loss: 1.386
[73,     3] loss: 1.386
[74,     3] loss: 1.387
[75,     3] loss: 1.386
[76,     3] loss: 1.386
[77,     3] loss: 1.387
[78,     3] loss: 1.386
[79,     3] loss: 1.386
[80,     3] loss: 1.386
[81,     3] loss: 1.386
[82,     3] loss: 1.386
[83,     3] loss: 1.386
[84,     3] loss: 1.387
[85,     3] loss: 1.385
[86,     3] loss: 1.386
[87,     3] loss: 1.387
[88,     3] loss: 1.387
[89,     3] loss: 1.387
[90,     3] loss: 1.386
[91,     3] loss: 1.386
[92,     3] loss: 1.386
[93,     3] loss: 1.386
[94,     3] loss: 1.387
[95,     3] loss: 1.386
[96,     3] loss: 1.386
[97,     3] loss: 1.386
Early stopping applied (best metric=0.5629987716674805)
Finished Training
Total time taken: 27.16913151741028
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.387
[3,     3] loss: 1.385
[4,     3] loss: 1.387
[5,     3] loss: 1.384
[6,     3] loss: 1.388
[7,     3] loss: 1.389
[8,     3] loss: 1.386
[9,     3] loss: 1.389
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.384
[18,     3] loss: 1.386
[19,     3] loss: 1.382
[20,     3] loss: 1.379
[21,     3] loss: 1.380
[22,     3] loss: 1.397
[23,     3] loss: 1.388
[24,     3] loss: 1.388
[25,     3] loss: 1.387
[26,     3] loss: 1.385
[27,     3] loss: 1.384
[28,     3] loss: 1.388
[29,     3] loss: 1.385
[30,     3] loss: 1.391
[31,     3] loss: 1.386
[32,     3] loss: 1.388
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.387
[37,     3] loss: 1.387
[38,     3] loss: 1.387
[39,     3] loss: 1.386
[40,     3] loss: 1.385
[41,     3] loss: 1.386
[42,     3] loss: 1.387
[43,     3] loss: 1.387
[44,     3] loss: 1.387
[45,     3] loss: 1.387
[46,     3] loss: 1.387
[47,     3] loss: 1.386
[48,     3] loss: 1.387
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
Early stopping applied (best metric=0.5629260540008545)
Finished Training
Total time taken: 14.458071231842041
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.395
[3,     3] loss: 1.388
[4,     3] loss: 1.388
[5,     3] loss: 1.387
[6,     3] loss: 1.387
[7,     3] loss: 1.387
[8,     3] loss: 1.386
[9,     3] loss: 1.387
[10,     3] loss: 1.386
[11,     3] loss: 1.387
[12,     3] loss: 1.386
[13,     3] loss: 1.388
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.388
[17,     3] loss: 1.388
[18,     3] loss: 1.387
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.384
[24,     3] loss: 1.388
[25,     3] loss: 1.387
[26,     3] loss: 1.387
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.387
[30,     3] loss: 1.387
[31,     3] loss: 1.387
[32,     3] loss: 1.387
[33,     3] loss: 1.386
[34,     3] loss: 1.387
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.385
[42,     3] loss: 1.386
[43,     3] loss: 1.385
[44,     3] loss: 1.387
[45,     3] loss: 1.387
[46,     3] loss: 1.387
[47,     3] loss: 1.385
[48,     3] loss: 1.387
[49,     3] loss: 1.386
[50,     3] loss: 1.388
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.386
Early stopping applied (best metric=0.5452409982681274)
Finished Training
Total time taken: 15.018072843551636
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.386
[3,     3] loss: 1.386
[4,     3] loss: 1.386
[5,     3] loss: 1.393
[6,     3] loss: 1.386
[7,     3] loss: 1.388
[8,     3] loss: 1.386
[9,     3] loss: 1.386
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.388
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.387
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.387
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.387
[34,     3] loss: 1.386
[35,     3] loss: 1.387
[36,     3] loss: 1.387
[37,     3] loss: 1.387
[38,     3] loss: 1.387
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.385
[49,     3] loss: 1.385
[50,     3] loss: 1.384
[51,     3] loss: 1.386
Early stopping applied (best metric=0.5452289581298828)
Finished Training
Total time taken: 14.190066814422607
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.395
[4,     3] loss: 1.389
[5,     3] loss: 1.385
[6,     3] loss: 1.387
[7,     3] loss: 1.389
[8,     3] loss: 1.388
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.388
[12,     3] loss: 1.384
[13,     3] loss: 1.389
[14,     3] loss: 1.386
[15,     3] loss: 1.385
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.387
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.387
[24,     3] loss: 1.387
[25,     3] loss: 1.387
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.387
[30,     3] loss: 1.386
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.385
[36,     3] loss: 1.386
[37,     3] loss: 1.387
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.387
[41,     3] loss: 1.385
[42,     3] loss: 1.385
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.387
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.387
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.387
[55,     3] loss: 1.387
[56,     3] loss: 1.386
[57,     3] loss: 1.386
[58,     3] loss: 1.387
[59,     3] loss: 1.385
[60,     3] loss: 1.388
[61,     3] loss: 1.387
[62,     3] loss: 1.386
[63,     3] loss: 1.387
[64,     3] loss: 1.386
[65,     3] loss: 1.386
[66,     3] loss: 1.386
[67,     3] loss: 1.387
[68,     3] loss: 1.386
[69,     3] loss: 1.386
[70,     3] loss: 1.387
[71,     3] loss: 1.386
[72,     3] loss: 1.387
[73,     3] loss: 1.386
[74,     3] loss: 1.386
[75,     3] loss: 1.387
[76,     3] loss: 1.386
[77,     3] loss: 1.386
[78,     3] loss: 1.386
[79,     3] loss: 1.387
[80,     3] loss: 1.386
[81,     3] loss: 1.387
[82,     3] loss: 1.386
[83,     3] loss: 1.387
[84,     3] loss: 1.386
[85,     3] loss: 1.386
[86,     3] loss: 1.387
[87,     3] loss: 1.386
[88,     3] loss: 1.387
[89,     3] loss: 1.387
[90,     3] loss: 1.386
[91,     3] loss: 1.386
[92,     3] loss: 1.386
[93,     3] loss: 1.386
[94,     3] loss: 1.384
[95,     3] loss: 1.384
[96,     3] loss: 1.385
[97,     3] loss: 1.385
[98,     3] loss: 1.385
[99,     3] loss: 1.383
[100,     3] loss: 1.390
[101,     3] loss: 1.386
[102,     3] loss: 1.390
[103,     3] loss: 1.386
[104,     3] loss: 1.386
[105,     3] loss: 1.387
[106,     3] loss: 1.386
[107,     3] loss: 1.386
[108,     3] loss: 1.387
[109,     3] loss: 1.386
[110,     3] loss: 1.386
[111,     3] loss: 1.387
[112,     3] loss: 1.387
[113,     3] loss: 1.386
[114,     3] loss: 1.386
[115,     3] loss: 1.386
[116,     3] loss: 1.386
[117,     3] loss: 1.387
[118,     3] loss: 1.386
[119,     3] loss: 1.386
[120,     3] loss: 1.385
[121,     3] loss: 1.387
[122,     3] loss: 1.385
[123,     3] loss: 1.384
[124,     3] loss: 1.386
[125,     3] loss: 1.387
[126,     3] loss: 1.387
[127,     3] loss: 1.388
[128,     3] loss: 1.387
[129,     3] loss: 1.387
[130,     3] loss: 1.386
Early stopping applied (best metric=0.5629914999008179)
Finished Training
Total time taken: 35.564173460006714
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.391
[3,     3] loss: 1.394
[4,     3] loss: 1.386
[5,     3] loss: 1.386
[6,     3] loss: 1.386
[7,     3] loss: 1.388
[8,     3] loss: 1.389
[9,     3] loss: 1.386
[10,     3] loss: 1.386
[11,     3] loss: 1.387
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.385
[16,     3] loss: 1.387
[17,     3] loss: 1.385
[18,     3] loss: 1.388
[19,     3] loss: 1.387
[20,     3] loss: 1.387
[21,     3] loss: 1.385
[22,     3] loss: 1.386
[23,     3] loss: 1.388
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.387
[29,     3] loss: 1.385
[30,     3] loss: 1.388
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.387
[35,     3] loss: 1.386
[36,     3] loss: 1.387
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.385
[40,     3] loss: 1.385
[41,     3] loss: 1.386
[42,     3] loss: 1.387
[43,     3] loss: 1.387
[44,     3] loss: 1.386
[45,     3] loss: 1.388
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.387
[51,     3] loss: 1.387
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.386
Early stopping applied (best metric=0.5624295473098755)
Finished Training
Total time taken: 15.115073919296265
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.387
[3,     3] loss: 1.377
[4,     3] loss: 1.394
[5,     3] loss: 1.372
[6,     3] loss: 1.394
[7,     3] loss: 1.386
[8,     3] loss: 1.393
[9,     3] loss: 1.385
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.388
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.387
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.385
[26,     3] loss: 1.386
[27,     3] loss: 1.387
[28,     3] loss: 1.386
[29,     3] loss: 1.384
[30,     3] loss: 1.386
[31,     3] loss: 1.387
[32,     3] loss: 1.387
[33,     3] loss: 1.385
[34,     3] loss: 1.387
[35,     3] loss: 1.386
[36,     3] loss: 1.387
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.385
[41,     3] loss: 1.385
[42,     3] loss: 1.385
[43,     3] loss: 1.391
[44,     3] loss: 1.387
[45,     3] loss: 1.387
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.388
Early stopping applied (best metric=0.5627833604812622)
Finished Training
Total time taken: 14.252068758010864
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.391
[3,     3] loss: 1.378
[4,     3] loss: 1.390
[5,     3] loss: 1.385
[6,     3] loss: 1.387
[7,     3] loss: 1.387
[8,     3] loss: 1.388
[9,     3] loss: 1.386
[10,     3] loss: 1.386
[11,     3] loss: 1.387
[12,     3] loss: 1.386
[13,     3] loss: 1.388
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.387
[22,     3] loss: 1.386
[23,     3] loss: 1.387
[24,     3] loss: 1.387
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.388
[28,     3] loss: 1.387
[29,     3] loss: 1.386
[30,     3] loss: 1.387
[31,     3] loss: 1.385
[32,     3] loss: 1.387
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.389
[36,     3] loss: 1.386
[37,     3] loss: 1.387
[38,     3] loss: 1.386
[39,     3] loss: 1.388
[40,     3] loss: 1.386
[41,     3] loss: 1.385
[42,     3] loss: 1.386
[43,     3] loss: 1.387
[44,     3] loss: 1.387
[45,     3] loss: 1.386
[46,     3] loss: 1.387
[47,     3] loss: 1.386
[48,     3] loss: 1.387
[49,     3] loss: 1.387
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.387
Early stopping applied (best metric=0.5450661778450012)
Finished Training
Total time taken: 14.472071409225464
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.388
[4,     3] loss: 1.387
[5,     3] loss: 1.388
[6,     3] loss: 1.388
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.387
[10,     3] loss: 1.390
[11,     3] loss: 1.385
[12,     3] loss: 1.382
[13,     3] loss: 1.386
[14,     3] loss: 1.389
[15,     3] loss: 1.383
[16,     3] loss: 1.390
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.387
[27,     3] loss: 1.387
[28,     3] loss: 1.387
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.388
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.387
[36,     3] loss: 1.385
[37,     3] loss: 1.387
[38,     3] loss: 1.385
[39,     3] loss: 1.387
[40,     3] loss: 1.387
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.387
[44,     3] loss: 1.386
[45,     3] loss: 1.387
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.387
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.386
[56,     3] loss: 1.388
Early stopping applied (best metric=0.5454037189483643)
Finished Training
Total time taken: 15.23607349395752
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.386
[4,     3] loss: 1.388
[5,     3] loss: 1.386
[6,     3] loss: 1.386
[7,     3] loss: 1.385
[8,     3] loss: 1.385
[9,     3] loss: 1.386
[10,     3] loss: 1.382
[11,     3] loss: 1.392
[12,     3] loss: 1.387
[13,     3] loss: 1.388
[14,     3] loss: 1.387
[15,     3] loss: 1.386
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.387
[22,     3] loss: 1.387
[23,     3] loss: 1.387
[24,     3] loss: 1.387
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.388
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.387
[41,     3] loss: 1.386
[42,     3] loss: 1.387
[43,     3] loss: 1.387
[44,     3] loss: 1.386
[45,     3] loss: 1.387
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.387
[49,     3] loss: 1.385
[50,     3] loss: 1.386
[51,     3] loss: 1.387
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.386
Early stopping applied (best metric=0.5628468990325928)
Finished Training
Total time taken: 14.776073217391968
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.386
[3,     3] loss: 1.383
[4,     3] loss: 1.382
[5,     3] loss: 1.394
[6,     3] loss: 1.385
[7,     3] loss: 1.384
[8,     3] loss: 1.385
[9,     3] loss: 1.388
[10,     3] loss: 1.387
[11,     3] loss: 1.385
[12,     3] loss: 1.386
[13,     3] loss: 1.385
[14,     3] loss: 1.384
[15,     3] loss: 1.386
[16,     3] loss: 1.391
[17,     3] loss: 1.381
[18,     3] loss: 1.384
[19,     3] loss: 1.382
[20,     3] loss: 1.380
[21,     3] loss: 1.390
[22,     3] loss: 1.397
[23,     3] loss: 1.385
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.385
[28,     3] loss: 1.385
[29,     3] loss: 1.387
[30,     3] loss: 1.387
[31,     3] loss: 1.387
[32,     3] loss: 1.387
[33,     3] loss: 1.387
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.387
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.384
[45,     3] loss: 1.388
[46,     3] loss: 1.388
[47,     3] loss: 1.387
[48,     3] loss: 1.387
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.385
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.387
[55,     3] loss: 1.387
[56,     3] loss: 1.386
[57,     3] loss: 1.384
[58,     3] loss: 1.385
[59,     3] loss: 1.386
[60,     3] loss: 1.388
[61,     3] loss: 1.387
[62,     3] loss: 1.387
[63,     3] loss: 1.385
[64,     3] loss: 1.388
[65,     3] loss: 1.385
[66,     3] loss: 1.387
[67,     3] loss: 1.386
[68,     3] loss: 1.386
[69,     3] loss: 1.387
[70,     3] loss: 1.386
[71,     3] loss: 1.386
[72,     3] loss: 1.386
[73,     3] loss: 1.387
[74,     3] loss: 1.387
[75,     3] loss: 1.385
[76,     3] loss: 1.386
[77,     3] loss: 1.386
[78,     3] loss: 1.386
[79,     3] loss: 1.386
[80,     3] loss: 1.388
[81,     3] loss: 1.386
[82,     3] loss: 1.387
[83,     3] loss: 1.387
[84,     3] loss: 1.386
[85,     3] loss: 1.386
[86,     3] loss: 1.386
[87,     3] loss: 1.386
[88,     3] loss: 1.386
[89,     3] loss: 1.387
[90,     3] loss: 1.386
[91,     3] loss: 1.386
[92,     3] loss: 1.386
[93,     3] loss: 1.387
[94,     3] loss: 1.387
[95,     3] loss: 1.387
[96,     3] loss: 1.386
[97,     3] loss: 1.386
[98,     3] loss: 1.386
[99,     3] loss: 1.386
[100,     3] loss: 1.386
[101,     3] loss: 1.386
Early stopping applied (best metric=0.5629407167434692)
Finished Training
Total time taken: 27.992136240005493
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.389
[3,     3] loss: 1.387
[4,     3] loss: 1.386
[5,     3] loss: 1.385
[6,     3] loss: 1.386
[7,     3] loss: 1.394
[8,     3] loss: 1.387
[9,     3] loss: 1.385
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.389
[15,     3] loss: 1.387
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.388
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.385
[28,     3] loss: 1.385
[29,     3] loss: 1.387
[30,     3] loss: 1.389
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.385
[35,     3] loss: 1.387
[36,     3] loss: 1.385
[37,     3] loss: 1.387
[38,     3] loss: 1.389
[39,     3] loss: 1.386
[40,     3] loss: 1.387
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.385
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.387
Early stopping applied (best metric=0.5629940032958984)
Finished Training
Total time taken: 14.736068964004517
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.382
[3,     3] loss: 1.396
[4,     3] loss: 1.385
[5,     3] loss: 1.384
[6,     3] loss: 1.391
[7,     3] loss: 1.382
[8,     3] loss: 1.389
[9,     3] loss: 1.388
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.387
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.385
[22,     3] loss: 1.386
[23,     3] loss: 1.387
[24,     3] loss: 1.388
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.387
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.387
[36,     3] loss: 1.387
[37,     3] loss: 1.387
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.387
[42,     3] loss: 1.387
[43,     3] loss: 1.387
[44,     3] loss: 1.387
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.387
[52,     3] loss: 1.387
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.387
[56,     3] loss: 1.387
[57,     3] loss: 1.387
[58,     3] loss: 1.386
[59,     3] loss: 1.387
[60,     3] loss: 1.386
[61,     3] loss: 1.386
[62,     3] loss: 1.387
[63,     3] loss: 1.387
[64,     3] loss: 1.387
[65,     3] loss: 1.386
[66,     3] loss: 1.386
[67,     3] loss: 1.385
[68,     3] loss: 1.387
[69,     3] loss: 1.387
[70,     3] loss: 1.387
[71,     3] loss: 1.386
[72,     3] loss: 1.386
[73,     3] loss: 1.386
[74,     3] loss: 1.385
[75,     3] loss: 1.386
[76,     3] loss: 1.388
[77,     3] loss: 1.384
[78,     3] loss: 1.386
[79,     3] loss: 1.385
[80,     3] loss: 1.386
[81,     3] loss: 1.388
[82,     3] loss: 1.387
[83,     3] loss: 1.387
[84,     3] loss: 1.386
[85,     3] loss: 1.386
[86,     3] loss: 1.386
[87,     3] loss: 1.386
[88,     3] loss: 1.386
[89,     3] loss: 1.387
[90,     3] loss: 1.386
[91,     3] loss: 1.386
[92,     3] loss: 1.386
[93,     3] loss: 1.387
[94,     3] loss: 1.386
[95,     3] loss: 1.387
[96,     3] loss: 1.386
[97,     3] loss: 1.386
[98,     3] loss: 1.387
[99,     3] loss: 1.386
[100,     3] loss: 1.386
[101,     3] loss: 1.386
[102,     3] loss: 1.386
[103,     3] loss: 1.386
[104,     3] loss: 1.386
[105,     3] loss: 1.386
[106,     3] loss: 1.387
[107,     3] loss: 1.387
[108,     3] loss: 1.386
[109,     3] loss: 1.387
[110,     3] loss: 1.386
[111,     3] loss: 1.386
[112,     3] loss: 1.387
[113,     3] loss: 1.386
[114,     3] loss: 1.386
[115,     3] loss: 1.386
[116,     3] loss: 1.387
[117,     3] loss: 1.385
[118,     3] loss: 1.386
[119,     3] loss: 1.386
[120,     3] loss: 1.387
[121,     3] loss: 1.386
Early stopping applied (best metric=0.5454513430595398)
Finished Training
Total time taken: 33.640159606933594
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.389
[3,     3] loss: 1.396
[4,     3] loss: 1.387
[5,     3] loss: 1.381
[6,     3] loss: 1.390
[7,     3] loss: 1.389
[8,     3] loss: 1.386
[9,     3] loss: 1.390
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.387
[25,     3] loss: 1.387
[26,     3] loss: 1.387
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.387
[44,     3] loss: 1.386
[45,     3] loss: 1.388
[46,     3] loss: 1.387
[47,     3] loss: 1.387
[48,     3] loss: 1.387
[49,     3] loss: 1.386
[50,     3] loss: 1.387
[51,     3] loss: 1.387
[52,     3] loss: 1.387
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.386
[56,     3] loss: 1.384
[57,     3] loss: 1.387
[58,     3] loss: 1.386
[59,     3] loss: 1.383
[60,     3] loss: 1.390
[61,     3] loss: 1.386
[62,     3] loss: 1.389
[63,     3] loss: 1.385
[64,     3] loss: 1.386
[65,     3] loss: 1.387
[66,     3] loss: 1.387
[67,     3] loss: 1.386
[68,     3] loss: 1.387
[69,     3] loss: 1.386
[70,     3] loss: 1.387
[71,     3] loss: 1.386
[72,     3] loss: 1.386
[73,     3] loss: 1.386
[74,     3] loss: 1.386
[75,     3] loss: 1.387
[76,     3] loss: 1.386
[77,     3] loss: 1.386
[78,     3] loss: 1.387
[79,     3] loss: 1.386
[80,     3] loss: 1.386
[81,     3] loss: 1.386
[82,     3] loss: 1.386
[83,     3] loss: 1.386
[84,     3] loss: 1.386
[85,     3] loss: 1.387
[86,     3] loss: 1.387
[87,     3] loss: 1.385
Early stopping applied (best metric=0.5454680323600769)
Finished Training
Total time taken: 24.216116905212402
{'S-palmitoylation-C Validation Accuracy': 0.5691253772913162, 'S-palmitoylation-C Validation Sensitivity': 0.3918151815181518, 'S-palmitoylation-C Validation Specificity': 0.6135385469620022, 'S-palmitoylation-C Validation Precision': nan, 'S-palmitoylation-C AUC ROC': 0.5094669696957794, 'S-palmitoylation-C AUC PR': 0.31393292263382694, 'S-palmitoylation-C MCC': 0.005497107030476324, 'S-palmitoylation-C F1': 0.1344677493228218, 'Validation Loss (S-palmitoylation-C)': 0.5550305406252544, 'Hydroxylation-K Validation Accuracy': 0.5566784869976359, 'Hydroxylation-K Validation Sensitivity': 0.42962962962962964, 'Hydroxylation-K Validation Specificity': 0.5964912280701754, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.5952534113060429, 'Hydroxylation-K AUC PR': 0.42104691161440955, 'Hydroxylation-K MCC': 0.030798738807520064, 'Hydroxylation-K F1': 0.16568691844553915, 'Validation Loss (Hydroxylation-K)': 0.5558258374532064, 'Validation Loss (total)': 1.1108563899993897, 'TimeToTrain': 19.725228611628214}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004177644368133305,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7689731735982661,
 'loss_weight_S-palmitoylation-C': 0.7829615752038049,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2265420661,
 'sample_weights': [0.135012115893196, 0.7605064561792053],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.425418449406637,
 'weight_decay_Hydroxylation-K': 8.08126567833862,
 'weight_decay_S-palmitoylation-C': 0.10105626833109382}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.384
[3,     3] loss: 1.395
[4,     3] loss: 1.390
[5,     3] loss: 1.383
[6,     3] loss: 1.382
[7,     3] loss: 1.387
[8,     3] loss: 1.379
[9,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008885517435730827,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6325025215468544,
 'loss_weight_S-palmitoylation-C': 0.5283898887712025,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4187236293,
 'sample_weights': [0.7829615752038049, 0.7689731735982661],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.9519414074708408,
 'weight_decay_Hydroxylation-K': 9.797019774631986,
 'weight_decay_S-palmitoylation-C': 7.154715965235193}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.397
[3,     3] loss: 1.387
[4,     3] loss: 1.388
[5,     3] loss: 1.387
[6,     3] loss: 1.385
[7,     3] loss: 1.386
[8,     3] loss: 1.385
[9,     3] loss: 1.385
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.388
[13,     3] loss: 1.385
[14,     3] loss: 1.388
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.388
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0059571499862632275,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6275240758343676,
 'loss_weight_S-palmitoylation-C': 0.6319532054656324,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 50193365,
 'sample_weights': [0.5283898887712025, 0.6325025215468544],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.879588990169424,
 'weight_decay_Hydroxylation-K': 9.849449040677419,
 'weight_decay_S-palmitoylation-C': 0.17031070939894977}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.393
[3,     3] loss: 1.385
[4,     3] loss: 1.389
[5,     3] loss: 1.385
[6,     3] loss: 1.386
[7,     3] loss: 1.388
[8,     3] loss: 1.389
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005718934389321293,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7788571616256053,
 'loss_weight_S-palmitoylation-C': 0.47179888455592556,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 207304339,
 'sample_weights': [0.6319532054656324, 0.6275240758343676],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.837237534630216,
 'weight_decay_Hydroxylation-K': 3.1120345039487467,
 'weight_decay_S-palmitoylation-C': 0.4776859322738135}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.390
[3,     3] loss: 1.408
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005824167677156694,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6162947913241621,
 'loss_weight_S-palmitoylation-C': 0.13435709603174245,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 57497461,
 'sample_weights': [0.47179888455592556, 0.7788571616256053],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.273282667878373,
 'weight_decay_Hydroxylation-K': 2.0434552064238427,
 'weight_decay_S-palmitoylation-C': 0.13010103598798306}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.405
[2,     3] loss: 1.394
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005093019607364432,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7472121580627114,
 'loss_weight_S-palmitoylation-C': 0.4004445506257509,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3222957878,
 'sample_weights': [0.13435709603174245, 0.6162947913241621],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.853570643273072,
 'weight_decay_Hydroxylation-K': 0.9376000473477377,
 'weight_decay_S-palmitoylation-C': 3.8398399209972958}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.384
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007327437045591504,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.17309928256796986,
 'loss_weight_S-palmitoylation-C': 0.054461235207377445,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1294225875,
 'sample_weights': [0.4004445506257509, 0.7472121580627114],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.680945525321553,
 'weight_decay_Hydroxylation-K': 3.32755058095482,
 'weight_decay_S-palmitoylation-C': 1.9832338920922408}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.417
[3,     3] loss: 1.385
[4,     3] loss: 1.399
[5,     3] loss: 1.388
[6,     3] loss: 1.387
[7,     3] loss: 1.389
[8,     3] loss: 1.386
[9,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020594530676415197,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1765777466764068,
 'loss_weight_S-palmitoylation-C': 0.7645072417770502,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 301165131,
 'sample_weights': [0.054461235207377445, 0.17309928256796986],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.957225796081019,
 'weight_decay_Hydroxylation-K': 5.527146372806968,
 'weight_decay_S-palmitoylation-C': 0.7335458622074463}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.391
[3,     3] loss: 1.388
[4,     3] loss: 1.391
[5,     3] loss: 1.384
[6,     3] loss: 1.380
[7,     3] loss: 1.379
[8,     3] loss: 1.389
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006998854697574394,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5939716022492337,
 'loss_weight_S-palmitoylation-C': 0.7044503382203062,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4205626200,
 'sample_weights': [0.7645072417770502, 0.1765777466764068],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.671103595593928,
 'weight_decay_Hydroxylation-K': 7.757490637004175,
 'weight_decay_S-palmitoylation-C': 7.857828748817488}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.383
[3,     3] loss: 1.391
[4,     3] loss: 1.388
[5,     3] loss: 1.385
[6,     3] loss: 1.388
[7,     3] loss: 1.384
[8,     3] loss: 1.383
[9,     3] loss: 1.385
[10,     3] loss: 1.384
[11,     3] loss: 1.371
[12,     3] loss: 1.344
[13,     3] loss: 1.307
[14,     3] loss: 1.237
[15,     3] loss: 1.355
[16,     3] loss: 1.271
[17,     3] loss: 1.273
[18,     3] loss: 1.209
[19,     3] loss: 1.246
[20,     3] loss: 1.186
[21,     3] loss: 1.264
[22,     3] loss: 1.105
[23,     3] loss: 1.146
[24,     3] loss: 1.188
[25,     3] loss: 1.265
[26,     3] loss: 1.307
[27,     3] loss: 1.168
[28,     3] loss: 1.132
[29,     3] loss: 1.056
[30,     3] loss: 1.315
[31,     3] loss: 1.201
[32,     3] loss: 1.228
[33,     3] loss: 1.165
[34,     3] loss: 1.152
[35,     3] loss: 1.104
[36,     3] loss: 1.122
[37,     3] loss: 1.168
[38,     3] loss: 1.245
[39,     3] loss: 1.188
[40,     3] loss: 1.176
[41,     3] loss: 1.070
[42,     3] loss: 1.120
[43,     3] loss: 1.094
[44,     3] loss: 1.052
[45,     3] loss: 1.260
[46,     3] loss: 1.176
[47,     3] loss: 1.143
[48,     3] loss: 1.079
[49,     3] loss: 1.094
[50,     3] loss: 1.256
[51,     3] loss: 1.233
[52,     3] loss: 1.185
[53,     3] loss: 1.084
[54,     3] loss: 1.008
[55,     3] loss: 1.024
[56,     3] loss: 1.058
[57,     3] loss: 1.356
[58,     3] loss: 1.232
[59,     3] loss: 1.289
[60,     3] loss: 1.193
[61,     3] loss: 1.200
[62,     3] loss: 1.154
[63,     3] loss: 1.084
[64,     3] loss: 1.137
[65,     3] loss: 1.168
[66,     3] loss: 1.113
[67,     3] loss: 1.185
[68,     3] loss: 1.221
[69,     3] loss: 1.228
[70,     3] loss: 1.144
[71,     3] loss: 1.085
[72,     3] loss: 1.071
[73,     3] loss: 1.095
[74,     3] loss: 1.139
[75,     3] loss: 1.194
[76,     3] loss: 1.316
[77,     3] loss: 1.195
[78,     3] loss: 1.196
[79,     3] loss: 1.079
[80,     3] loss: 1.018
[81,     3] loss: 1.340
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007206264894348368,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.33599869855877096,
 'loss_weight_S-palmitoylation-C': 0.5846191160065585,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2855179242,
 'sample_weights': [0.7044503382203062, 0.5939716022492337],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3227140760221987,
 'weight_decay_Hydroxylation-K': 5.151735659147464,
 'weight_decay_S-palmitoylation-C': 1.6435970900550556}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.375
[2,     3] loss: 1.385
[3,     3] loss: 1.394
[4,     3] loss: 1.388
[5,     3] loss: 1.389
[6,     3] loss: 1.387
[7,     3] loss: 1.388
[8,     3] loss: 1.385
[9,     3] loss: 1.378
[10,     3] loss: 1.377
[11,     3] loss: 1.392
[12,     3] loss: 1.399
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.385
[18,     3] loss: 1.388
[19,     3] loss: 1.386
[20,     3] loss: 1.385
[21,     3] loss: 1.387
[22,     3] loss: 1.384
[23,     3] loss: 1.386
[24,     3] loss: 1.387
[25,     3] loss: 1.388
[26,     3] loss: 1.388
[27,     3] loss: 1.384
[28,     3] loss: 1.389
[29,     3] loss: 1.384
[30,     3] loss: 1.385
[31,     3] loss: 1.376
[32,     3] loss: 1.359
[33,     3] loss: 1.385
[34,     3] loss: 1.388
[35,     3] loss: 1.387
[36,     3] loss: 1.388
[37,     3] loss: 1.384
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.397
[41,     3] loss: 1.386
[42,     3] loss: 1.385
[43,     3] loss: 1.387
[44,     3] loss: 1.387
[45,     3] loss: 1.385
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.385
[49,     3] loss: 1.386
[50,     3] loss: 1.385
[51,     3] loss: 1.387
[52,     3] loss: 1.389
Early stopping applied (best metric=0.5627239942550659)
Finished Training
Total time taken: 14.343067407608032
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.395
[3,     3] loss: 1.389
[4,     3] loss: 1.388
[5,     3] loss: 1.386
[6,     3] loss: 1.376
[7,     3] loss: 1.385
[8,     3] loss: 1.386
[9,     3] loss: 1.384
[10,     3] loss: 1.385
[11,     3] loss: 1.379
[12,     3] loss: 1.386
[13,     3] loss: 1.384
[14,     3] loss: 1.391
[15,     3] loss: 1.388
[16,     3] loss: 1.388
[17,     3] loss: 1.387
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.388
[25,     3] loss: 1.388
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.387
[29,     3] loss: 1.387
[30,     3] loss: 1.386
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.387
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.387
[42,     3] loss: 1.387
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.387
[46,     3] loss: 1.386
[47,     3] loss: 1.386
[48,     3] loss: 1.387
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.387
[53,     3] loss: 1.386
Early stopping applied (best metric=0.5622667074203491)
Finished Training
Total time taken: 14.614072561264038
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.391
[3,     3] loss: 1.387
[4,     3] loss: 1.393
[5,     3] loss: 1.393
[6,     3] loss: 1.389
[7,     3] loss: 1.388
[8,     3] loss: 1.387
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.384
[12,     3] loss: 1.387
[13,     3] loss: 1.385
[14,     3] loss: 1.384
[15,     3] loss: 1.389
[16,     3] loss: 1.386
[17,     3] loss: 1.389
[18,     3] loss: 1.383
[19,     3] loss: 1.388
[20,     3] loss: 1.390
[21,     3] loss: 1.387
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.387
[25,     3] loss: 1.388
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.387
[29,     3] loss: 1.387
[30,     3] loss: 1.386
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.387
[35,     3] loss: 1.386
[36,     3] loss: 1.387
[37,     3] loss: 1.386
[38,     3] loss: 1.387
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.385
[45,     3] loss: 1.386
[46,     3] loss: 1.387
[47,     3] loss: 1.386
[48,     3] loss: 1.388
[49,     3] loss: 1.387
[50,     3] loss: 1.385
[51,     3] loss: 1.386
[52,     3] loss: 1.387
[53,     3] loss: 1.386
[54,     3] loss: 1.387
[55,     3] loss: 1.385
[56,     3] loss: 1.386
Early stopping applied (best metric=0.5618114471435547)
Finished Training
Total time taken: 15.246073961257935
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.398
[3,     3] loss: 1.375
[4,     3] loss: 1.362
[5,     3] loss: 1.393
[6,     3] loss: 1.408
[7,     3] loss: 1.384
[8,     3] loss: 1.394
[9,     3] loss: 1.386
[10,     3] loss: 1.390
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.388
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.387
[25,     3] loss: 1.385
[26,     3] loss: 1.387
[27,     3] loss: 1.386
[28,     3] loss: 1.387
[29,     3] loss: 1.387
[30,     3] loss: 1.385
[31,     3] loss: 1.387
[32,     3] loss: 1.387
[33,     3] loss: 1.386
[34,     3] loss: 1.387
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.387
[40,     3] loss: 1.386
[41,     3] loss: 1.384
[42,     3] loss: 1.387
[43,     3] loss: 1.386
[44,     3] loss: 1.387
[45,     3] loss: 1.386
[46,     3] loss: 1.387
[47,     3] loss: 1.388
[48,     3] loss: 1.387
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.387
[53,     3] loss: 1.387
Early stopping applied (best metric=0.545138955116272)
Finished Training
Total time taken: 14.695072650909424
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.410
[3,     3] loss: 1.391
[4,     3] loss: 1.389
[5,     3] loss: 1.390
[6,     3] loss: 1.387
[7,     3] loss: 1.389
[8,     3] loss: 1.387
[9,     3] loss: 1.386
[10,     3] loss: 1.390
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.388
[14,     3] loss: 1.388
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.387
[18,     3] loss: 1.388
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.387
[22,     3] loss: 1.387
[23,     3] loss: 1.387
[24,     3] loss: 1.385
[25,     3] loss: 1.386
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.387
[31,     3] loss: 1.388
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.387
[35,     3] loss: 1.387
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.387
[39,     3] loss: 1.387
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.385
[46,     3] loss: 1.387
[47,     3] loss: 1.386
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.387
Early stopping applied (best metric=0.5441769361495972)
Finished Training
Total time taken: 15.014073848724365
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.397
[3,     3] loss: 1.393
[4,     3] loss: 1.391
[5,     3] loss: 1.386
[6,     3] loss: 1.389
[7,     3] loss: 1.385
[8,     3] loss: 1.386
[9,     3] loss: 1.384
[10,     3] loss: 1.386
[11,     3] loss: 1.387
[12,     3] loss: 1.388
[13,     3] loss: 1.388
[14,     3] loss: 1.386
[15,     3] loss: 1.388
[16,     3] loss: 1.387
[17,     3] loss: 1.387
[18,     3] loss: 1.385
[19,     3] loss: 1.388
[20,     3] loss: 1.388
[21,     3] loss: 1.387
[22,     3] loss: 1.387
[23,     3] loss: 1.387
[24,     3] loss: 1.386
[25,     3] loss: 1.387
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.387
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.388
[33,     3] loss: 1.385
[34,     3] loss: 1.385
[35,     3] loss: 1.385
[36,     3] loss: 1.380
[37,     3] loss: 1.370
[38,     3] loss: 1.347
[39,     3] loss: 1.416
[40,     3] loss: 1.375
[41,     3] loss: 1.381
[42,     3] loss: 1.336
[43,     3] loss: 1.371
[44,     3] loss: 1.349
[45,     3] loss: 1.336
[46,     3] loss: 1.296
[47,     3] loss: 1.222
[48,     3] loss: 1.248
[49,     3] loss: 1.199
[50,     3] loss: 1.249
[51,     3] loss: 1.103
[52,     3] loss: 1.206
[53,     3] loss: 1.355
[54,     3] loss: 1.256
[55,     3] loss: 1.243
[56,     3] loss: 1.197
[57,     3] loss: 1.158
[58,     3] loss: 1.105
[59,     3] loss: 1.099
[60,     3] loss: 1.138
[61,     3] loss: 1.035
[62,     3] loss: 0.935
[63,     3] loss: 1.284
[64,     3] loss: 1.121
[65,     3] loss: 1.124
[66,     3] loss: 1.064
[67,     3] loss: 1.043
[68,     3] loss: 1.036
[69,     3] loss: 0.989
[70,     3] loss: 0.954
[71,     3] loss: 0.934
[72,     3] loss: 1.030
[73,     3] loss: 1.100
[74,     3] loss: 1.014
[75,     3] loss: 0.998
[76,     3] loss: 1.038
[77,     3] loss: 0.945
[78,     3] loss: 1.082
[79,     3] loss: 1.001
[80,     3] loss: 1.334
[81,     3] loss: 1.219
[82,     3] loss: 1.204
[83,     3] loss: 1.157
[84,     3] loss: 1.152
[85,     3] loss: 1.256
[86,     3] loss: 1.193
[87,     3] loss: 1.094
[88,     3] loss: 1.134
[89,     3] loss: 1.021
[90,     3] loss: 1.012
[91,     3] loss: 0.930
[92,     3] loss: 0.922
[93,     3] loss: 0.850
[94,     3] loss: 0.972
[95,     3] loss: 1.565
[96,     3] loss: 1.230
[97,     3] loss: 1.261
[98,     3] loss: 1.244
Early stopping applied (best metric=0.49352866411209106)
Finished Training
Total time taken: 27.182130813598633
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.387
[3,     3] loss: 1.387
[4,     3] loss: 1.385
[5,     3] loss: 1.383
[6,     3] loss: 1.388
[7,     3] loss: 1.387
[8,     3] loss: 1.386
[9,     3] loss: 1.387
[10,     3] loss: 1.386
[11,     3] loss: 1.389
[12,     3] loss: 1.385
[13,     3] loss: 1.388
[14,     3] loss: 1.386
[15,     3] loss: 1.388
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.387
[22,     3] loss: 1.388
[23,     3] loss: 1.386
[24,     3] loss: 1.384
[25,     3] loss: 1.384
[26,     3] loss: 1.395
[27,     3] loss: 1.387
[28,     3] loss: 1.385
[29,     3] loss: 1.379
[30,     3] loss: 1.382
[31,     3] loss: 1.352
[32,     3] loss: 1.310
[33,     3] loss: 1.224
[34,     3] loss: 1.287
[35,     3] loss: 1.164
[36,     3] loss: 1.134
[37,     3] loss: 1.259
[38,     3] loss: 1.095
[39,     3] loss: 1.128
[40,     3] loss: 1.031
[41,     3] loss: 1.039
[42,     3] loss: 1.078
[43,     3] loss: 1.451
[44,     3] loss: 1.183
[45,     3] loss: 1.159
[46,     3] loss: 1.097
[47,     3] loss: 1.089
[48,     3] loss: 0.980
[49,     3] loss: 0.904
[50,     3] loss: 1.012
[51,     3] loss: 1.075
[52,     3] loss: 1.118
[53,     3] loss: 1.102
[54,     3] loss: 1.039
[55,     3] loss: 0.958
[56,     3] loss: 0.898
[57,     3] loss: 0.868
[58,     3] loss: 0.975
[59,     3] loss: 0.931
[60,     3] loss: 0.939
[61,     3] loss: 0.969
[62,     3] loss: 0.939
[63,     3] loss: 0.850
[64,     3] loss: 0.916
[65,     3] loss: 1.149
[66,     3] loss: 1.080
[67,     3] loss: 1.139
[68,     3] loss: 1.132
[69,     3] loss: 1.147
[70,     3] loss: 0.961
[71,     3] loss: 0.954
[72,     3] loss: 0.986
[73,     3] loss: 1.085
[74,     3] loss: 0.946
[75,     3] loss: 0.925
[76,     3] loss: 0.945
[77,     3] loss: 0.851
[78,     3] loss: 0.846
[79,     3] loss: 0.886
[80,     3] loss: 0.864
[81,     3] loss: 1.003
[82,     3] loss: 1.204
[83,     3] loss: 1.117
[84,     3] loss: 1.095
[85,     3] loss: 1.035
[86,     3] loss: 0.984
[87,     3] loss: 1.001
[88,     3] loss: 1.022
[89,     3] loss: 0.886
[90,     3] loss: 0.860
[91,     3] loss: 0.868
[92,     3] loss: 0.878
[93,     3] loss: 0.926
[94,     3] loss: 0.849
[95,     3] loss: 0.899
[96,     3] loss: 0.895
[97,     3] loss: 0.889
[98,     3] loss: 0.852
[99,     3] loss: 0.983
[100,     3] loss: 0.943
[101,     3] loss: 0.835
[102,     3] loss: 0.855
[103,     3] loss: 0.827
[104,     3] loss: 0.922
[105,     3] loss: 0.896
[106,     3] loss: 1.125
[107,     3] loss: 1.184
[108,     3] loss: 1.083
[109,     3] loss: 1.010
[110,     3] loss: 0.975
Early stopping applied (best metric=0.5367581844329834)
Finished Training
Total time taken: 30.534139156341553
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.415
[3,     3] loss: 1.389
[4,     3] loss: 1.387
[5,     3] loss: 1.387
[6,     3] loss: 1.385
[7,     3] loss: 1.389
[8,     3] loss: 1.389
[9,     3] loss: 1.386
[10,     3] loss: 1.388
[11,     3] loss: 1.386
[12,     3] loss: 1.389
[13,     3] loss: 1.385
[14,     3] loss: 1.389
[15,     3] loss: 1.386
[16,     3] loss: 1.385
[17,     3] loss: 1.386
[18,     3] loss: 1.385
[19,     3] loss: 1.385
[20,     3] loss: 1.388
[21,     3] loss: 1.382
[22,     3] loss: 1.389
[23,     3] loss: 1.389
[24,     3] loss: 1.387
[25,     3] loss: 1.388
[26,     3] loss: 1.387
[27,     3] loss: 1.387
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.387
[34,     3] loss: 1.386
[35,     3] loss: 1.386
[36,     3] loss: 1.387
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.387
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.387
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.385
[48,     3] loss: 1.386
[49,     3] loss: 1.388
[50,     3] loss: 1.387
[51,     3] loss: 1.387
Early stopping applied (best metric=0.562018632888794)
Finished Training
Total time taken: 14.297052145004272
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.390
[3,     3] loss: 1.391
[4,     3] loss: 1.385
[5,     3] loss: 1.390
[6,     3] loss: 1.379
[7,     3] loss: 1.382
[8,     3] loss: 1.398
[9,     3] loss: 1.392
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.385
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.384
[17,     3] loss: 1.385
[18,     3] loss: 1.387
[19,     3] loss: 1.385
[20,     3] loss: 1.386
[21,     3] loss: 1.383
[22,     3] loss: 1.384
[23,     3] loss: 1.380
[24,     3] loss: 1.370
[25,     3] loss: 1.354
[26,     3] loss: 1.339
[27,     3] loss: 1.328
[28,     3] loss: 1.289
[29,     3] loss: 1.328
[30,     3] loss: 1.274
[31,     3] loss: 1.254
[32,     3] loss: 1.235
[33,     3] loss: 1.218
[34,     3] loss: 1.276
[35,     3] loss: 1.208
[36,     3] loss: 1.239
[37,     3] loss: 1.244
[38,     3] loss: 1.274
[39,     3] loss: 1.174
[40,     3] loss: 1.115
[41,     3] loss: 1.182
[42,     3] loss: 1.062
[43,     3] loss: 1.128
[44,     3] loss: 1.019
[45,     3] loss: 1.012
[46,     3] loss: 1.001
[47,     3] loss: 1.015
[48,     3] loss: 1.038
[49,     3] loss: 0.967
[50,     3] loss: 0.963
[51,     3] loss: 0.879
[52,     3] loss: 1.039
[53,     3] loss: 1.133
[54,     3] loss: 1.095
[55,     3] loss: 1.158
[56,     3] loss: 1.129
[57,     3] loss: 1.011
[58,     3] loss: 0.961
[59,     3] loss: 0.927
[60,     3] loss: 0.949
[61,     3] loss: 0.850
[62,     3] loss: 0.915
[63,     3] loss: 0.940
[64,     3] loss: 0.858
[65,     3] loss: 0.952
[66,     3] loss: 0.904
[67,     3] loss: 1.135
[68,     3] loss: 0.995
[69,     3] loss: 0.952
[70,     3] loss: 1.057
[71,     3] loss: 0.960
[72,     3] loss: 0.964
[73,     3] loss: 0.861
[74,     3] loss: 0.820
[75,     3] loss: 0.899
[76,     3] loss: 1.143
[77,     3] loss: 1.370
[78,     3] loss: 1.123
[79,     3] loss: 1.184
[80,     3] loss: 1.126
[81,     3] loss: 1.127
[82,     3] loss: 1.058
[83,     3] loss: 1.025
[84,     3] loss: 0.941
[85,     3] loss: 0.841
[86,     3] loss: 0.844
[87,     3] loss: 0.984
[88,     3] loss: 0.938
Early stopping applied (best metric=0.49465838074684143)
Finished Training
Total time taken: 24.401090621948242
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.389
[3,     3] loss: 1.396
[4,     3] loss: 1.388
[5,     3] loss: 1.388
[6,     3] loss: 1.383
[7,     3] loss: 1.386
[8,     3] loss: 1.387
[9,     3] loss: 1.389
[10,     3] loss: 1.387
[11,     3] loss: 1.387
[12,     3] loss: 1.387
[13,     3] loss: 1.388
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.387
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.388
[20,     3] loss: 1.386
[21,     3] loss: 1.387
[22,     3] loss: 1.386
[23,     3] loss: 1.387
[24,     3] loss: 1.387
[25,     3] loss: 1.386
[26,     3] loss: 1.387
[27,     3] loss: 1.386
[28,     3] loss: 1.387
[29,     3] loss: 1.386
[30,     3] loss: 1.387
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.389
[34,     3] loss: 1.387
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.385
[38,     3] loss: 1.388
[39,     3] loss: 1.386
[40,     3] loss: 1.387
[41,     3] loss: 1.385
[42,     3] loss: 1.386
[43,     3] loss: 1.387
[44,     3] loss: 1.387
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.388
[48,     3] loss: 1.386
[49,     3] loss: 1.387
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.385
[54,     3] loss: 1.386
[55,     3] loss: 1.387
[56,     3] loss: 1.386
[57,     3] loss: 1.387
[58,     3] loss: 1.386
[59,     3] loss: 1.387
[60,     3] loss: 1.385
[61,     3] loss: 1.387
Early stopping applied (best metric=0.5448634624481201)
Finished Training
Total time taken: 16.957064390182495
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.395
[3,     3] loss: 1.390
[4,     3] loss: 1.393
[5,     3] loss: 1.387
[6,     3] loss: 1.389
[7,     3] loss: 1.383
[8,     3] loss: 1.382
[9,     3] loss: 1.386
[10,     3] loss: 1.395
[11,     3] loss: 1.388
[12,     3] loss: 1.390
[13,     3] loss: 1.385
[14,     3] loss: 1.384
[15,     3] loss: 1.388
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.385
[21,     3] loss: 1.384
[22,     3] loss: 1.392
[23,     3] loss: 1.387
[24,     3] loss: 1.386
[25,     3] loss: 1.387
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.387
[30,     3] loss: 1.385
[31,     3] loss: 1.385
[32,     3] loss: 1.374
[33,     3] loss: 1.324
[34,     3] loss: 1.296
[35,     3] loss: 1.337
[36,     3] loss: 1.404
[37,     3] loss: 1.398
[38,     3] loss: 1.388
[39,     3] loss: 1.385
[40,     3] loss: 1.387
[41,     3] loss: 1.386
[42,     3] loss: 1.388
[43,     3] loss: 1.387
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.387
[49,     3] loss: 1.387
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.387
[56,     3] loss: 1.386
[57,     3] loss: 1.388
[58,     3] loss: 1.386
[59,     3] loss: 1.386
[60,     3] loss: 1.386
[61,     3] loss: 1.386
[62,     3] loss: 1.385
[63,     3] loss: 1.387
[64,     3] loss: 1.387
[65,     3] loss: 1.386
[66,     3] loss: 1.388
[67,     3] loss: 1.387
[68,     3] loss: 1.386
[69,     3] loss: 1.386
[70,     3] loss: 1.387
[71,     3] loss: 1.386
[72,     3] loss: 1.386
[73,     3] loss: 1.386
[74,     3] loss: 1.387
[75,     3] loss: 1.387
[76,     3] loss: 1.387
[77,     3] loss: 1.386
[78,     3] loss: 1.387
[79,     3] loss: 1.386
[80,     3] loss: 1.386
[81,     3] loss: 1.387
[82,     3] loss: 1.386
[83,     3] loss: 1.386
[84,     3] loss: 1.387
Early stopping applied (best metric=0.5552815794944763)
Finished Training
Total time taken: 23.316085815429688
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.386
[3,     3] loss: 1.388
[4,     3] loss: 1.396
[5,     3] loss: 1.389
[6,     3] loss: 1.386
[7,     3] loss: 1.385
[8,     3] loss: 1.392
[9,     3] loss: 1.388
[10,     3] loss: 1.385
[11,     3] loss: 1.387
[12,     3] loss: 1.385
[13,     3] loss: 1.385
[14,     3] loss: 1.387
[15,     3] loss: 1.387
[16,     3] loss: 1.384
[17,     3] loss: 1.384
[18,     3] loss: 1.378
[19,     3] loss: 1.370
[20,     3] loss: 1.316
[21,     3] loss: 1.312
[22,     3] loss: 1.202
[23,     3] loss: 1.429
[24,     3] loss: 1.220
[25,     3] loss: 1.287
[26,     3] loss: 1.273
[27,     3] loss: 1.282
[28,     3] loss: 1.183
[29,     3] loss: 1.218
[30,     3] loss: 1.248
[31,     3] loss: 1.197
[32,     3] loss: 1.063
[33,     3] loss: 1.075
[34,     3] loss: 0.984
[35,     3] loss: 0.993
[36,     3] loss: 0.941
[37,     3] loss: 1.073
[38,     3] loss: 1.153
[39,     3] loss: 1.023
[40,     3] loss: 1.031
[41,     3] loss: 1.047
[42,     3] loss: 1.090
[43,     3] loss: 0.969
[44,     3] loss: 0.934
[45,     3] loss: 0.895
[46,     3] loss: 0.926
[47,     3] loss: 1.170
[48,     3] loss: 1.151
[49,     3] loss: 1.104
[50,     3] loss: 1.051
[51,     3] loss: 1.024
[52,     3] loss: 1.027
[53,     3] loss: 0.895
[54,     3] loss: 1.079
[55,     3] loss: 0.919
[56,     3] loss: 0.904
[57,     3] loss: 0.922
[58,     3] loss: 0.946
[59,     3] loss: 1.072
[60,     3] loss: 1.103
[61,     3] loss: 1.035
[62,     3] loss: 0.964
[63,     3] loss: 0.919
[64,     3] loss: 0.986
[65,     3] loss: 1.079
[66,     3] loss: 0.926
[67,     3] loss: 1.018
[68,     3] loss: 1.000
[69,     3] loss: 1.006
[70,     3] loss: 0.999
[71,     3] loss: 0.941
Early stopping applied (best metric=0.539400041103363)
Finished Training
Total time taken: 19.89707350730896
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.384
[3,     3] loss: 1.392
[4,     3] loss: 1.384
[5,     3] loss: 1.386
[6,     3] loss: 1.387
[7,     3] loss: 1.393
[8,     3] loss: 1.383
[9,     3] loss: 1.385
[10,     3] loss: 1.393
[11,     3] loss: 1.386
[12,     3] loss: 1.386
[13,     3] loss: 1.384
[14,     3] loss: 1.389
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.385
[19,     3] loss: 1.386
[20,     3] loss: 1.385
[21,     3] loss: 1.386
[22,     3] loss: 1.385
[23,     3] loss: 1.386
[24,     3] loss: 1.387
[25,     3] loss: 1.385
[26,     3] loss: 1.383
[27,     3] loss: 1.371
[28,     3] loss: 1.340
[29,     3] loss: 1.359
[30,     3] loss: 1.250
[31,     3] loss: 1.316
[32,     3] loss: 1.319
[33,     3] loss: 1.286
[34,     3] loss: 1.267
[35,     3] loss: 1.248
[36,     3] loss: 1.251
[37,     3] loss: 1.154
[38,     3] loss: 1.297
[39,     3] loss: 1.130
[40,     3] loss: 1.163
[41,     3] loss: 1.201
[42,     3] loss: 1.214
[43,     3] loss: 1.102
[44,     3] loss: 1.183
[45,     3] loss: 1.166
[46,     3] loss: 1.095
[47,     3] loss: 1.032
[48,     3] loss: 1.014
[49,     3] loss: 0.982
[50,     3] loss: 0.998
[51,     3] loss: 0.942
[52,     3] loss: 0.967
[53,     3] loss: 1.031
[54,     3] loss: 0.926
[55,     3] loss: 0.969
[56,     3] loss: 0.908
[57,     3] loss: 0.908
[58,     3] loss: 1.029
[59,     3] loss: 1.278
[60,     3] loss: 1.094
[61,     3] loss: 1.239
[62,     3] loss: 1.212
[63,     3] loss: 1.084
[64,     3] loss: 0.958
[65,     3] loss: 0.908
[66,     3] loss: 0.911
[67,     3] loss: 1.255
[68,     3] loss: 0.971
[69,     3] loss: 0.978
[70,     3] loss: 0.917
[71,     3] loss: 0.857
[72,     3] loss: 0.837
[73,     3] loss: 0.964
[74,     3] loss: 0.939
[75,     3] loss: 0.848
[76,     3] loss: 0.841
[77,     3] loss: 0.900
[78,     3] loss: 0.866
[79,     3] loss: 0.815
[80,     3] loss: 0.919
[81,     3] loss: 0.824
[82,     3] loss: 0.990
[83,     3] loss: 0.873
[84,     3] loss: 0.907
[85,     3] loss: 0.969
[86,     3] loss: 1.097
[87,     3] loss: 0.959
[88,     3] loss: 1.081
[89,     3] loss: 1.062
[90,     3] loss: 0.944
[91,     3] loss: 0.903
[92,     3] loss: 0.854
[93,     3] loss: 0.853
[94,     3] loss: 1.140
[95,     3] loss: 0.990
[96,     3] loss: 0.939
[97,     3] loss: 0.927
[98,     3] loss: 0.868
[99,     3] loss: 0.809
[100,     3] loss: 1.000
[101,     3] loss: 0.913
[102,     3] loss: 0.973
Early stopping applied (best metric=0.5348297953605652)
Finished Training
Total time taken: 28.318105459213257
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.378
[3,     3] loss: 1.397
[4,     3] loss: 1.392
[5,     3] loss: 1.385
[6,     3] loss: 1.389
[7,     3] loss: 1.383
[8,     3] loss: 1.388
[9,     3] loss: 1.384
[10,     3] loss: 1.383
[11,     3] loss: 1.386
[12,     3] loss: 1.386
[13,     3] loss: 1.385
[14,     3] loss: 1.385
[15,     3] loss: 1.388
[16,     3] loss: 1.385
[17,     3] loss: 1.387
[18,     3] loss: 1.384
[19,     3] loss: 1.381
[20,     3] loss: 1.370
[21,     3] loss: 1.334
[22,     3] loss: 1.289
[23,     3] loss: 1.271
[24,     3] loss: 1.254
[25,     3] loss: 1.223
[26,     3] loss: 1.230
[27,     3] loss: 1.170
[28,     3] loss: 1.265
[29,     3] loss: 1.249
[30,     3] loss: 1.149
[31,     3] loss: 1.142
[32,     3] loss: 1.143
[33,     3] loss: 1.106
[34,     3] loss: 1.098
[35,     3] loss: 1.113
[36,     3] loss: 1.078
[37,     3] loss: 1.125
[38,     3] loss: 1.029
[39,     3] loss: 1.059
[40,     3] loss: 1.033
[41,     3] loss: 0.986
[42,     3] loss: 1.006
[43,     3] loss: 1.024
[44,     3] loss: 0.959
[45,     3] loss: 0.979
[46,     3] loss: 1.017
[47,     3] loss: 1.061
[48,     3] loss: 1.032
[49,     3] loss: 1.024
[50,     3] loss: 0.958
[51,     3] loss: 0.907
[52,     3] loss: 0.890
[53,     3] loss: 1.364
[54,     3] loss: 1.099
[55,     3] loss: 1.161
[56,     3] loss: 1.123
[57,     3] loss: 1.124
[58,     3] loss: 1.074
[59,     3] loss: 1.011
[60,     3] loss: 0.909
[61,     3] loss: 1.018
[62,     3] loss: 1.108
[63,     3] loss: 0.952
[64,     3] loss: 0.947
[65,     3] loss: 0.926
[66,     3] loss: 0.995
[67,     3] loss: 0.881
[68,     3] loss: 1.012
[69,     3] loss: 0.894
[70,     3] loss: 0.934
[71,     3] loss: 0.929
[72,     3] loss: 0.995
[73,     3] loss: 0.957
[74,     3] loss: 0.981
[75,     3] loss: 1.120
[76,     3] loss: 1.011
[77,     3] loss: 0.979
[78,     3] loss: 0.982
[79,     3] loss: 1.063
[80,     3] loss: 0.924
[81,     3] loss: 1.060
[82,     3] loss: 1.149
[83,     3] loss: 1.055
[84,     3] loss: 0.954
[85,     3] loss: 0.961
[86,     3] loss: 0.869
[87,     3] loss: 0.873
[88,     3] loss: 0.923
Early stopping applied (best metric=0.5092771053314209)
Finished Training
Total time taken: 24.48909068107605
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.389
[3,     3] loss: 1.387
[4,     3] loss: 1.389
[5,     3] loss: 1.388
[6,     3] loss: 1.391
[7,     3] loss: 1.385
[8,     3] loss: 1.380
[9,     3] loss: 1.385
[10,     3] loss: 1.389
[11,     3] loss: 1.384
[12,     3] loss: 1.385
[13,     3] loss: 1.385
[14,     3] loss: 1.389
[15,     3] loss: 1.384
[16,     3] loss: 1.386
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.385
[20,     3] loss: 1.383
[21,     3] loss: 1.379
[22,     3] loss: 1.385
[23,     3] loss: 1.355
[24,     3] loss: 1.342
[25,     3] loss: 1.310
[26,     3] loss: 1.317
[27,     3] loss: 1.386
[28,     3] loss: 1.213
[29,     3] loss: 1.349
[30,     3] loss: 1.306
[31,     3] loss: 1.270
[32,     3] loss: 1.285
[33,     3] loss: 1.246
[34,     3] loss: 1.127
[35,     3] loss: 1.131
[36,     3] loss: 1.173
[37,     3] loss: 1.063
[38,     3] loss: 1.093
[39,     3] loss: 1.084
[40,     3] loss: 1.117
[41,     3] loss: 1.028
[42,     3] loss: 1.128
[43,     3] loss: 1.210
[44,     3] loss: 1.071
[45,     3] loss: 1.056
[46,     3] loss: 1.013
[47,     3] loss: 0.988
[48,     3] loss: 1.027
[49,     3] loss: 0.922
[50,     3] loss: 0.911
[51,     3] loss: 0.938
[52,     3] loss: 1.108
[53,     3] loss: 1.013
[54,     3] loss: 1.111
[55,     3] loss: 1.024
[56,     3] loss: 0.997
[57,     3] loss: 0.970
[58,     3] loss: 0.934
[59,     3] loss: 0.891
[60,     3] loss: 1.005
[61,     3] loss: 0.928
[62,     3] loss: 0.988
[63,     3] loss: 0.976
[64,     3] loss: 0.985
[65,     3] loss: 0.922
[66,     3] loss: 0.896
[67,     3] loss: 0.847
[68,     3] loss: 0.872
[69,     3] loss: 1.218
[70,     3] loss: 0.965
[71,     3] loss: 0.974
[72,     3] loss: 0.980
[73,     3] loss: 1.146
[74,     3] loss: 0.986
[75,     3] loss: 1.012
[76,     3] loss: 0.995
[77,     3] loss: 0.932
[78,     3] loss: 1.114
[79,     3] loss: 0.907
[80,     3] loss: 1.068
[81,     3] loss: 0.923
[82,     3] loss: 0.946
[83,     3] loss: 0.911
[84,     3] loss: 1.141
[85,     3] loss: 1.427
[86,     3] loss: 1.178
[87,     3] loss: 1.205
[88,     3] loss: 1.273
[89,     3] loss: 1.200
[90,     3] loss: 1.160
[91,     3] loss: 1.200
[92,     3] loss: 1.147
[93,     3] loss: 1.136
[94,     3] loss: 1.251
[95,     3] loss: 1.101
[96,     3] loss: 1.086
Early stopping applied (best metric=0.5086138844490051)
Finished Training
Total time taken: 26.732096672058105
{'S-palmitoylation-C Validation Accuracy': 0.5199550191034907, 'S-palmitoylation-C Validation Sensitivity': 0.48316831683168315, 'S-palmitoylation-C Validation Specificity': 0.5291583892077213, 'S-palmitoylation-C Validation Precision': nan, 'S-palmitoylation-C AUC ROC': 0.51897454774542, 'S-palmitoylation-C AUC PR': 0.21289100767259256, 'S-palmitoylation-C MCC': 0.011779977862287003, 'S-palmitoylation-C F1': 0.22892142209905852, 'Validation Loss (S-palmitoylation-C)': 0.555333948135376, 'Hydroxylation-K Validation Accuracy': 0.5244089834515366, 'Hydroxylation-K Validation Sensitivity': 0.7377777777777778, 'Hydroxylation-K Validation Specificity': 0.47368421052631576, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.7480701754385966, 'Hydroxylation-K AUC PR': 0.4862330619927976, 'Hydroxylation-K MCC': 0.17652616549403444, 'Hydroxylation-K F1': 0.36276997162054636, 'Validation Loss (Hydroxylation-K)': 0.5370231846968333, 'Validation Loss (total)': 1.0923571348190309, 'TimeToTrain': 20.66908597946167}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002436477950861881,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.33273227090358964,
 'loss_weight_S-palmitoylation-C': 0.8770110791267755,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1466700779,
 'sample_weights': [0.5846191160065585, 0.33599869855877096],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3139385017869385,
 'weight_decay_Hydroxylation-K': 2.2993708051489907,
 'weight_decay_S-palmitoylation-C': 0.7944539898968188}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.389
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037580567866460123,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5146666583115327,
 'loss_weight_S-palmitoylation-C': 0.5838480573131971,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2534772959,
 'sample_weights': [0.8770110791267755, 0.33273227090358964],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.953945030683563,
 'weight_decay_Hydroxylation-K': 0.13262975281288658,
 'weight_decay_S-palmitoylation-C': 1.3628951154195794}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.379
[2,     3] loss: 1.381
[3,     3] loss: 1.380
[4,     3] loss: 1.394
[5,     3] loss: 1.407
[6,     3] loss: 1.379
[7,     3] loss: 1.382
[8,     3] loss: 1.368
[9,     3] loss: 1.378
[10,     3] loss: 1.408
[11,     3] loss: 1.388
[12,     3] loss: 1.388
[13,     3] loss: 1.393
[14,     3] loss: 1.389
[15,     3] loss: 1.380
[16,     3] loss: 1.371
[17,     3] loss: 1.347
[18,     3] loss: 1.314
[19,     3] loss: 1.218
[20,     3] loss: 1.131
[21,     3] loss: 1.234
[22,     3] loss: 1.266
[23,     3] loss: 1.106
[24,     3] loss: 1.125
[25,     3] loss: 1.012
[26,     3] loss: 1.221
[27,     3] loss: 0.992
[28,     3] loss: 1.035
[29,     3] loss: 1.214
[30,     3] loss: 1.065
[31,     3] loss: 1.080
[32,     3] loss: 1.113
[33,     3] loss: 1.000
[34,     3] loss: 0.941
[35,     3] loss: 0.880
[36,     3] loss: 0.922
[37,     3] loss: 0.863
[38,     3] loss: 1.099
[39,     3] loss: 0.987
[40,     3] loss: 0.945
[41,     3] loss: 0.863
[42,     3] loss: 0.862
[43,     3] loss: 0.843
[44,     3] loss: 0.821
[45,     3] loss: 0.930
[46,     3] loss: 1.214
[47,     3] loss: 1.218
[48,     3] loss: 1.191
[49,     3] loss: 1.110
[50,     3] loss: 1.238
[51,     3] loss: 1.139
[52,     3] loss: 1.082
[53,     3] loss: 1.016
[54,     3] loss: 0.898
[55,     3] loss: 1.081
[56,     3] loss: 0.962
[57,     3] loss: 0.918
[58,     3] loss: 1.003
[59,     3] loss: 1.019
[60,     3] loss: 1.046
[61,     3] loss: 0.927
[62,     3] loss: 0.845
[63,     3] loss: 0.811
[64,     3] loss: 0.794
[65,     3] loss: 0.894
[66,     3] loss: 0.962
[67,     3] loss: 0.903
[68,     3] loss: 0.919
[69,     3] loss: 0.902
[70,     3] loss: 0.868
[71,     3] loss: 0.856
[72,     3] loss: 0.843
[73,     3] loss: 0.802
[74,     3] loss: 0.835
Early stopping applied (best metric=0.5249596834182739)
Finished Training
Total time taken: 20.446075677871704
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.391
[3,     3] loss: 1.388
[4,     3] loss: 1.389
[5,     3] loss: 1.385
[6,     3] loss: 1.390
[7,     3] loss: 1.389
[8,     3] loss: 1.385
[9,     3] loss: 1.388
[10,     3] loss: 1.380
[11,     3] loss: 1.384
[12,     3] loss: 1.384
[13,     3] loss: 1.387
[14,     3] loss: 1.360
[15,     3] loss: 1.295
[16,     3] loss: 1.264
[17,     3] loss: 1.140
[18,     3] loss: 1.421
[19,     3] loss: 1.122
[20,     3] loss: 1.135
[21,     3] loss: 1.095
[22,     3] loss: 1.068
[23,     3] loss: 0.972
[24,     3] loss: 1.003
[25,     3] loss: 1.099
[26,     3] loss: 1.000
[27,     3] loss: 1.033
[28,     3] loss: 1.023
[29,     3] loss: 0.933
[30,     3] loss: 0.922
[31,     3] loss: 0.932
[32,     3] loss: 0.857
[33,     3] loss: 1.014
[34,     3] loss: 0.987
[35,     3] loss: 0.987
[36,     3] loss: 0.897
[37,     3] loss: 1.081
[38,     3] loss: 0.970
[39,     3] loss: 0.952
[40,     3] loss: 0.903
[41,     3] loss: 0.808
[42,     3] loss: 0.778
[43,     3] loss: 0.779
[44,     3] loss: 0.857
[45,     3] loss: 0.910
[46,     3] loss: 0.913
[47,     3] loss: 0.904
[48,     3] loss: 0.902
[49,     3] loss: 0.982
[50,     3] loss: 0.858
[51,     3] loss: 0.829
[52,     3] loss: 0.821
[53,     3] loss: 0.819
[54,     3] loss: 0.764
[55,     3] loss: 0.781
[56,     3] loss: 0.821
[57,     3] loss: 0.753
[58,     3] loss: 0.731
[59,     3] loss: 0.737
[60,     3] loss: 0.727
[61,     3] loss: 0.929
[62,     3] loss: 1.150
[63,     3] loss: 1.062
[64,     3] loss: 1.030
[65,     3] loss: 0.902
[66,     3] loss: 0.839
[67,     3] loss: 0.892
[68,     3] loss: 0.791
[69,     3] loss: 0.897
[70,     3] loss: 0.815
[71,     3] loss: 0.861
[72,     3] loss: 0.809
Early stopping applied (best metric=0.5394885540008545)
Finished Training
Total time taken: 20.269076824188232
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.401
[3,     3] loss: 1.381
[4,     3] loss: 1.383
[5,     3] loss: 1.381
[6,     3] loss: 1.386
[7,     3] loss: 1.380
[8,     3] loss: 1.376
[9,     3] loss: 1.379
[10,     3] loss: 1.377
[11,     3] loss: 1.316
[12,     3] loss: 1.350
[13,     3] loss: 1.288
[14,     3] loss: 1.293
[15,     3] loss: 1.145
[16,     3] loss: 1.192
[17,     3] loss: 1.191
[18,     3] loss: 1.113
[19,     3] loss: 1.061
[20,     3] loss: 1.025
[21,     3] loss: 1.108
[22,     3] loss: 1.022
[23,     3] loss: 0.996
[24,     3] loss: 1.146
[25,     3] loss: 1.236
[26,     3] loss: 1.145
[27,     3] loss: 1.118
[28,     3] loss: 1.070
[29,     3] loss: 0.986
[30,     3] loss: 1.082
[31,     3] loss: 1.028
[32,     3] loss: 0.932
[33,     3] loss: 0.976
[34,     3] loss: 1.012
[35,     3] loss: 0.909
[36,     3] loss: 0.897
[37,     3] loss: 0.846
[38,     3] loss: 0.811
[39,     3] loss: 0.821
[40,     3] loss: 0.803
[41,     3] loss: 1.082
[42,     3] loss: 1.154
[43,     3] loss: 1.040
[44,     3] loss: 1.066
[45,     3] loss: 0.943
[46,     3] loss: 0.986
[47,     3] loss: 0.817
[48,     3] loss: 0.942
[49,     3] loss: 0.829
[50,     3] loss: 0.835
[51,     3] loss: 0.794
[52,     3] loss: 0.859
[53,     3] loss: 0.841
[54,     3] loss: 0.846
[55,     3] loss: 0.799
[56,     3] loss: 0.868
[57,     3] loss: 0.853
[58,     3] loss: 1.303
[59,     3] loss: 1.139
[60,     3] loss: 1.058
[61,     3] loss: 1.170
[62,     3] loss: 1.078
[63,     3] loss: 1.078
[64,     3] loss: 1.017
[65,     3] loss: 0.940
[66,     3] loss: 0.924
[67,     3] loss: 0.881
[68,     3] loss: 1.019
[69,     3] loss: 0.956
[70,     3] loss: 0.894
Early stopping applied (best metric=0.5339148044586182)
Finished Training
Total time taken: 19.565072059631348
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.399
[2,     3] loss: 1.384
[3,     3] loss: 1.387
[4,     3] loss: 1.382
[5,     3] loss: 1.384
[6,     3] loss: 1.378
[7,     3] loss: 1.378
[8,     3] loss: 1.378
[9,     3] loss: 1.376
[10,     3] loss: 1.387
[11,     3] loss: 1.366
[12,     3] loss: 1.349
[13,     3] loss: 1.328
[14,     3] loss: 1.266
[15,     3] loss: 1.241
[16,     3] loss: 1.260
[17,     3] loss: 1.252
[18,     3] loss: 1.208
[19,     3] loss: 1.230
[20,     3] loss: 1.111
[21,     3] loss: 1.155
[22,     3] loss: 1.204
[23,     3] loss: 1.116
[24,     3] loss: 1.048
[25,     3] loss: 1.130
[26,     3] loss: 1.086
[27,     3] loss: 1.064
[28,     3] loss: 1.042
[29,     3] loss: 1.062
[30,     3] loss: 1.029
[31,     3] loss: 1.188
[32,     3] loss: 1.180
[33,     3] loss: 1.049
[34,     3] loss: 1.053
[35,     3] loss: 0.937
[36,     3] loss: 0.918
[37,     3] loss: 0.893
[38,     3] loss: 0.934
[39,     3] loss: 0.853
[40,     3] loss: 1.055
[41,     3] loss: 1.015
[42,     3] loss: 1.052
[43,     3] loss: 1.020
[44,     3] loss: 0.954
[45,     3] loss: 0.957
[46,     3] loss: 0.877
[47,     3] loss: 0.875
[48,     3] loss: 0.872
[49,     3] loss: 0.811
[50,     3] loss: 0.781
[51,     3] loss: 0.857
[52,     3] loss: 0.789
[53,     3] loss: 0.786
[54,     3] loss: 1.253
[55,     3] loss: 0.980
[56,     3] loss: 1.006
[57,     3] loss: 1.111
[58,     3] loss: 1.019
[59,     3] loss: 0.919
[60,     3] loss: 0.950
[61,     3] loss: 1.201
[62,     3] loss: 0.985
[63,     3] loss: 0.978
[64,     3] loss: 0.937
[65,     3] loss: 0.918
[66,     3] loss: 1.023
[67,     3] loss: 0.934
Early stopping applied (best metric=0.5026965737342834)
Finished Training
Total time taken: 18.724066495895386
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.400
[3,     3] loss: 1.384
[4,     3] loss: 1.389
[5,     3] loss: 1.385
[6,     3] loss: 1.385
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.380
[10,     3] loss: 1.377
[11,     3] loss: 1.374
[12,     3] loss: 1.361
[13,     3] loss: 1.311
[14,     3] loss: 1.240
[15,     3] loss: 1.219
[16,     3] loss: 1.257
[17,     3] loss: 1.091
[18,     3] loss: 1.089
[19,     3] loss: 0.963
[20,     3] loss: 0.948
[21,     3] loss: 1.114
[22,     3] loss: 0.931
[23,     3] loss: 1.075
[24,     3] loss: 0.982
[25,     3] loss: 0.883
[26,     3] loss: 0.882
[27,     3] loss: 0.851
[28,     3] loss: 1.017
[29,     3] loss: 0.962
[30,     3] loss: 1.071
[31,     3] loss: 0.965
[32,     3] loss: 1.017
[33,     3] loss: 0.892
[34,     3] loss: 0.883
[35,     3] loss: 0.933
[36,     3] loss: 0.833
[37,     3] loss: 0.819
[38,     3] loss: 1.147
[39,     3] loss: 1.054
[40,     3] loss: 0.982
[41,     3] loss: 0.982
[42,     3] loss: 0.913
[43,     3] loss: 1.001
[44,     3] loss: 0.837
[45,     3] loss: 0.928
[46,     3] loss: 0.883
[47,     3] loss: 0.959
[48,     3] loss: 0.945
[49,     3] loss: 0.809
[50,     3] loss: 0.804
[51,     3] loss: 0.787
[52,     3] loss: 0.847
[53,     3] loss: 0.918
[54,     3] loss: 1.097
[55,     3] loss: 1.095
[56,     3] loss: 0.959
[57,     3] loss: 0.970
[58,     3] loss: 0.947
[59,     3] loss: 0.983
[60,     3] loss: 0.885
[61,     3] loss: 0.907
[62,     3] loss: 0.823
[63,     3] loss: 0.932
[64,     3] loss: 1.063
[65,     3] loss: 0.995
[66,     3] loss: 0.985
[67,     3] loss: 0.911
[68,     3] loss: 0.889
[69,     3] loss: 0.842
Early stopping applied (best metric=0.5373311042785645)
Finished Training
Total time taken: 19.168070554733276
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.388
[3,     3] loss: 1.390
[4,     3] loss: 1.373
[5,     3] loss: 1.394
[6,     3] loss: 1.392
[7,     3] loss: 1.387
[8,     3] loss: 1.387
[9,     3] loss: 1.383
[10,     3] loss: 1.386
[11,     3] loss: 1.391
[12,     3] loss: 1.385
[13,     3] loss: 1.387
[14,     3] loss: 1.378
[15,     3] loss: 1.368
[16,     3] loss: 1.361
[17,     3] loss: 1.312
[18,     3] loss: 1.290
[19,     3] loss: 1.226
[20,     3] loss: 1.330
[21,     3] loss: 1.208
[22,     3] loss: 1.208
[23,     3] loss: 1.127
[24,     3] loss: 1.019
[25,     3] loss: 1.095
[26,     3] loss: 1.089
[27,     3] loss: 1.161
[28,     3] loss: 1.249
[29,     3] loss: 1.203
[30,     3] loss: 1.095
[31,     3] loss: 1.055
[32,     3] loss: 1.019
[33,     3] loss: 0.985
[34,     3] loss: 1.074
[35,     3] loss: 1.205
[36,     3] loss: 1.102
[37,     3] loss: 1.008
[38,     3] loss: 0.985
[39,     3] loss: 0.979
[40,     3] loss: 0.920
[41,     3] loss: 0.996
[42,     3] loss: 0.863
[43,     3] loss: 0.991
[44,     3] loss: 0.875
[45,     3] loss: 0.870
[46,     3] loss: 1.117
[47,     3] loss: 1.041
[48,     3] loss: 1.032
[49,     3] loss: 0.977
[50,     3] loss: 0.902
[51,     3] loss: 0.825
[52,     3] loss: 0.783
[53,     3] loss: 0.949
[54,     3] loss: 0.948
[55,     3] loss: 0.924
[56,     3] loss: 0.962
[57,     3] loss: 0.877
[58,     3] loss: 1.027
[59,     3] loss: 0.897
[60,     3] loss: 0.959
[61,     3] loss: 0.941
[62,     3] loss: 0.923
[63,     3] loss: 0.934
[64,     3] loss: 1.161
[65,     3] loss: 0.924
[66,     3] loss: 0.939
[67,     3] loss: 0.854
[68,     3] loss: 0.990
[69,     3] loss: 0.804
[70,     3] loss: 0.847
[71,     3] loss: 0.843
[72,     3] loss: 0.957
[73,     3] loss: 0.905
[74,     3] loss: 0.893
[75,     3] loss: 0.917
[76,     3] loss: 0.789
[77,     3] loss: 0.792
[78,     3] loss: 0.772
[79,     3] loss: 0.797
[80,     3] loss: 1.204
[81,     3] loss: 1.461
[82,     3] loss: 1.336
Early stopping applied (best metric=0.5172770619392395)
Finished Training
Total time taken: 22.68308401107788
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.414
[3,     3] loss: 1.387
[4,     3] loss: 1.388
[5,     3] loss: 1.390
[6,     3] loss: 1.382
[7,     3] loss: 1.385
[8,     3] loss: 1.389
[9,     3] loss: 1.394
[10,     3] loss: 1.384
[11,     3] loss: 1.396
[12,     3] loss: 1.383
[13,     3] loss: 1.381
[14,     3] loss: 1.377
[15,     3] loss: 1.356
[16,     3] loss: 1.334
[17,     3] loss: 1.272
[18,     3] loss: 1.211
[19,     3] loss: 1.327
[20,     3] loss: 1.180
[21,     3] loss: 1.206
[22,     3] loss: 1.144
[23,     3] loss: 1.057
[24,     3] loss: 1.098
[25,     3] loss: 1.063
[26,     3] loss: 0.977
[27,     3] loss: 1.044
[28,     3] loss: 1.064
[29,     3] loss: 1.096
[30,     3] loss: 1.120
[31,     3] loss: 0.967
[32,     3] loss: 0.950
[33,     3] loss: 1.035
[34,     3] loss: 0.910
[35,     3] loss: 0.940
[36,     3] loss: 1.010
[37,     3] loss: 1.001
[38,     3] loss: 0.938
[39,     3] loss: 0.917
[40,     3] loss: 0.863
[41,     3] loss: 0.842
[42,     3] loss: 0.950
[43,     3] loss: 0.840
[44,     3] loss: 0.807
[45,     3] loss: 0.846
[46,     3] loss: 1.331
[47,     3] loss: 0.986
[48,     3] loss: 1.070
[49,     3] loss: 0.964
[50,     3] loss: 1.108
[51,     3] loss: 0.901
[52,     3] loss: 0.952
[53,     3] loss: 0.903
[54,     3] loss: 0.896
[55,     3] loss: 0.808
[56,     3] loss: 0.828
[57,     3] loss: 0.878
[58,     3] loss: 0.855
[59,     3] loss: 0.875
[60,     3] loss: 0.805
[61,     3] loss: 0.797
[62,     3] loss: 0.940
[63,     3] loss: 1.036
[64,     3] loss: 0.921
[65,     3] loss: 0.954
[66,     3] loss: 0.954
[67,     3] loss: 0.943
[68,     3] loss: 0.882
[69,     3] loss: 0.888
[70,     3] loss: 0.869
[71,     3] loss: 0.811
[72,     3] loss: 0.847
[73,     3] loss: 0.934
[74,     3] loss: 1.117
[75,     3] loss: 1.041
[76,     3] loss: 1.048
[77,     3] loss: 0.915
[78,     3] loss: 0.973
[79,     3] loss: 0.897
[80,     3] loss: 0.886
[81,     3] loss: 0.860
[82,     3] loss: 0.787
[83,     3] loss: 0.785
[84,     3] loss: 0.760
[85,     3] loss: 0.789
[86,     3] loss: 0.983
[87,     3] loss: 0.929
[88,     3] loss: 1.011
[89,     3] loss: 0.979
[90,     3] loss: 0.909
[91,     3] loss: 0.904
[92,     3] loss: 0.917
[93,     3] loss: 0.878
[94,     3] loss: 0.834
Early stopping applied (best metric=0.5411442518234253)
Finished Training
Total time taken: 26.252094984054565
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.387
[3,     3] loss: 1.392
[4,     3] loss: 1.391
[5,     3] loss: 1.378
[6,     3] loss: 1.377
[7,     3] loss: 1.394
[8,     3] loss: 1.375
[9,     3] loss: 1.375
[10,     3] loss: 1.355
[11,     3] loss: 1.351
[12,     3] loss: 1.260
[13,     3] loss: 1.276
[14,     3] loss: 1.201
[15,     3] loss: 1.163
[16,     3] loss: 1.108
[17,     3] loss: 1.123
[18,     3] loss: 1.098
[19,     3] loss: 1.084
[20,     3] loss: 1.038
[21,     3] loss: 1.094
[22,     3] loss: 1.026
[23,     3] loss: 1.015
[24,     3] loss: 0.976
[25,     3] loss: 0.970
[26,     3] loss: 0.953
[27,     3] loss: 0.905
[28,     3] loss: 0.872
[29,     3] loss: 0.902
[30,     3] loss: 1.023
[31,     3] loss: 1.070
[32,     3] loss: 0.912
[33,     3] loss: 0.966
[34,     3] loss: 0.863
[35,     3] loss: 0.858
[36,     3] loss: 0.967
[37,     3] loss: 1.022
[38,     3] loss: 0.902
[39,     3] loss: 0.942
[40,     3] loss: 0.891
[41,     3] loss: 0.807
[42,     3] loss: 0.909
[43,     3] loss: 0.877
[44,     3] loss: 0.785
[45,     3] loss: 0.842
[46,     3] loss: 0.811
[47,     3] loss: 0.820
[48,     3] loss: 0.824
[49,     3] loss: 0.807
[50,     3] loss: 1.173
[51,     3] loss: 0.989
[52,     3] loss: 0.980
[53,     3] loss: 0.977
[54,     3] loss: 0.936
[55,     3] loss: 0.883
[56,     3] loss: 0.793
[57,     3] loss: 0.782
[58,     3] loss: 0.800
[59,     3] loss: 0.825
[60,     3] loss: 0.845
[61,     3] loss: 0.811
[62,     3] loss: 0.938
[63,     3] loss: 1.010
[64,     3] loss: 0.920
[65,     3] loss: 0.891
[66,     3] loss: 0.835
[67,     3] loss: 0.850
[68,     3] loss: 0.860
Early stopping applied (best metric=0.535971462726593)
Finished Training
Total time taken: 18.874070405960083
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.385
[3,     3] loss: 1.388
[4,     3] loss: 1.387
[5,     3] loss: 1.372
[6,     3] loss: 1.408
[7,     3] loss: 1.379
[8,     3] loss: 1.371
[9,     3] loss: 1.337
[10,     3] loss: 1.281
[11,     3] loss: 1.257
[12,     3] loss: 1.204
[13,     3] loss: 1.207
[14,     3] loss: 1.160
[15,     3] loss: 1.139
[16,     3] loss: 1.125
[17,     3] loss: 1.130
[18,     3] loss: 1.148
[19,     3] loss: 1.094
[20,     3] loss: 1.067
[21,     3] loss: 1.096
[22,     3] loss: 1.167
[23,     3] loss: 1.052
[24,     3] loss: 1.104
[25,     3] loss: 0.997
[26,     3] loss: 1.023
[27,     3] loss: 1.031
[28,     3] loss: 0.944
[29,     3] loss: 1.026
[30,     3] loss: 1.040
[31,     3] loss: 1.033
[32,     3] loss: 1.087
[33,     3] loss: 1.017
[34,     3] loss: 0.992
[35,     3] loss: 0.887
[36,     3] loss: 1.047
[37,     3] loss: 1.129
[38,     3] loss: 1.066
[39,     3] loss: 1.003
[40,     3] loss: 0.959
[41,     3] loss: 0.998
[42,     3] loss: 0.909
[43,     3] loss: 0.918
[44,     3] loss: 0.794
[45,     3] loss: 0.800
[46,     3] loss: 0.824
[47,     3] loss: 0.803
[48,     3] loss: 0.894
[49,     3] loss: 0.871
[50,     3] loss: 1.129
[51,     3] loss: 0.974
[52,     3] loss: 1.066
[53,     3] loss: 0.959
[54,     3] loss: 0.903
[55,     3] loss: 0.901
[56,     3] loss: 0.806
[57,     3] loss: 0.768
[58,     3] loss: 0.868
[59,     3] loss: 0.985
[60,     3] loss: 1.001
[61,     3] loss: 0.963
[62,     3] loss: 0.875
[63,     3] loss: 0.845
[64,     3] loss: 0.828
[65,     3] loss: 0.794
[66,     3] loss: 0.754
[67,     3] loss: 0.763
[68,     3] loss: 0.798
[69,     3] loss: 0.744
[70,     3] loss: 0.808
[71,     3] loss: 0.821
[72,     3] loss: 1.069
[73,     3] loss: 0.923
[74,     3] loss: 0.891
[75,     3] loss: 0.852
[76,     3] loss: 0.819
[77,     3] loss: 0.824
[78,     3] loss: 1.031
[79,     3] loss: 0.974
[80,     3] loss: 0.940
[81,     3] loss: 0.955
[82,     3] loss: 0.880
[83,     3] loss: 0.868
[84,     3] loss: 0.836
[85,     3] loss: 0.879
Early stopping applied (best metric=0.5268014669418335)
Finished Training
Total time taken: 23.266085624694824
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.396
[3,     3] loss: 1.390
[4,     3] loss: 1.386
[5,     3] loss: 1.383
[6,     3] loss: 1.379
[7,     3] loss: 1.383
[8,     3] loss: 1.374
[9,     3] loss: 1.376
[10,     3] loss: 1.376
[11,     3] loss: 1.371
[12,     3] loss: 1.347
[13,     3] loss: 1.300
[14,     3] loss: 1.297
[15,     3] loss: 1.269
[16,     3] loss: 1.158
[17,     3] loss: 1.204
[18,     3] loss: 1.122
[19,     3] loss: 1.167
[20,     3] loss: 1.206
[21,     3] loss: 1.030
[22,     3] loss: 1.024
[23,     3] loss: 1.101
[24,     3] loss: 1.132
[25,     3] loss: 0.934
[26,     3] loss: 1.100
[27,     3] loss: 0.981
[28,     3] loss: 0.994
[29,     3] loss: 0.978
[30,     3] loss: 1.042
[31,     3] loss: 0.942
[32,     3] loss: 0.920
[33,     3] loss: 0.937
[34,     3] loss: 0.889
[35,     3] loss: 1.086
[36,     3] loss: 1.072
[37,     3] loss: 1.063
[38,     3] loss: 0.998
[39,     3] loss: 0.952
[40,     3] loss: 0.870
[41,     3] loss: 0.867
[42,     3] loss: 0.850
[43,     3] loss: 1.093
[44,     3] loss: 0.888
[45,     3] loss: 1.027
[46,     3] loss: 0.956
[47,     3] loss: 1.020
[48,     3] loss: 0.994
[49,     3] loss: 1.022
[50,     3] loss: 1.142
[51,     3] loss: 1.070
[52,     3] loss: 1.025
[53,     3] loss: 0.962
[54,     3] loss: 0.951
[55,     3] loss: 0.828
[56,     3] loss: 0.912
[57,     3] loss: 0.878
[58,     3] loss: 0.797
[59,     3] loss: 1.019
[60,     3] loss: 1.066
[61,     3] loss: 1.048
[62,     3] loss: 1.080
[63,     3] loss: 1.105
[64,     3] loss: 1.031
[65,     3] loss: 0.915
[66,     3] loss: 0.879
[67,     3] loss: 0.854
[68,     3] loss: 0.834
[69,     3] loss: 0.942
[70,     3] loss: 0.795
[71,     3] loss: 0.830
[72,     3] loss: 0.874
[73,     3] loss: 0.821
Early stopping applied (best metric=0.5147990584373474)
Finished Training
Total time taken: 20.287076473236084
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.379
[3,     3] loss: 1.401
[4,     3] loss: 1.392
[5,     3] loss: 1.386
[6,     3] loss: 1.379
[7,     3] loss: 1.395
[8,     3] loss: 1.390
[9,     3] loss: 1.384
[10,     3] loss: 1.387
[11,     3] loss: 1.382
[12,     3] loss: 1.384
[13,     3] loss: 1.377
[14,     3] loss: 1.376
[15,     3] loss: 1.365
[16,     3] loss: 1.288
[17,     3] loss: 1.171
[18,     3] loss: 1.180
[19,     3] loss: 1.233
[20,     3] loss: 1.324
[21,     3] loss: 1.280
[22,     3] loss: 1.258
[23,     3] loss: 1.277
[24,     3] loss: 1.187
[25,     3] loss: 1.250
[26,     3] loss: 1.116
[27,     3] loss: 1.175
[28,     3] loss: 0.986
[29,     3] loss: 0.976
[30,     3] loss: 0.998
[31,     3] loss: 1.071
[32,     3] loss: 1.076
[33,     3] loss: 1.101
[34,     3] loss: 1.165
[35,     3] loss: 1.038
[36,     3] loss: 1.118
[37,     3] loss: 1.088
[38,     3] loss: 0.979
[39,     3] loss: 0.915
[40,     3] loss: 0.921
[41,     3] loss: 0.927
[42,     3] loss: 0.924
[43,     3] loss: 1.052
[44,     3] loss: 0.910
[45,     3] loss: 0.922
[46,     3] loss: 0.952
[47,     3] loss: 0.950
[48,     3] loss: 0.933
[49,     3] loss: 0.807
[50,     3] loss: 1.033
[51,     3] loss: 1.075
[52,     3] loss: 1.057
[53,     3] loss: 1.059
[54,     3] loss: 0.968
[55,     3] loss: 1.018
[56,     3] loss: 0.988
[57,     3] loss: 0.902
[58,     3] loss: 0.871
[59,     3] loss: 0.927
[60,     3] loss: 1.214
[61,     3] loss: 1.078
[62,     3] loss: 1.057
[63,     3] loss: 1.028
[64,     3] loss: 0.967
[65,     3] loss: 0.986
[66,     3] loss: 0.869
[67,     3] loss: 0.861
[68,     3] loss: 0.829
[69,     3] loss: 0.824
[70,     3] loss: 0.868
[71,     3] loss: 0.860
[72,     3] loss: 0.841
[73,     3] loss: 0.819
[74,     3] loss: 0.899
[75,     3] loss: 0.910
[76,     3] loss: 0.925
Early stopping applied (best metric=0.49368560314178467)
Finished Training
Total time taken: 21.29908013343811
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.398
[3,     3] loss: 1.385
[4,     3] loss: 1.384
[5,     3] loss: 1.380
[6,     3] loss: 1.388
[7,     3] loss: 1.388
[8,     3] loss: 1.385
[9,     3] loss: 1.379
[10,     3] loss: 1.385
[11,     3] loss: 1.367
[12,     3] loss: 1.348
[13,     3] loss: 1.266
[14,     3] loss: 1.263
[15,     3] loss: 1.194
[16,     3] loss: 1.184
[17,     3] loss: 1.180
[18,     3] loss: 1.186
[19,     3] loss: 1.167
[20,     3] loss: 1.174
[21,     3] loss: 1.080
[22,     3] loss: 1.102
[23,     3] loss: 1.122
[24,     3] loss: 1.042
[25,     3] loss: 1.038
[26,     3] loss: 1.101
[27,     3] loss: 0.970
[28,     3] loss: 1.089
[29,     3] loss: 0.989
[30,     3] loss: 1.138
[31,     3] loss: 1.010
[32,     3] loss: 0.964
[33,     3] loss: 0.942
[34,     3] loss: 1.015
[35,     3] loss: 1.035
[36,     3] loss: 0.935
[37,     3] loss: 0.958
[38,     3] loss: 0.878
[39,     3] loss: 0.902
[40,     3] loss: 1.067
[41,     3] loss: 1.018
[42,     3] loss: 1.172
[43,     3] loss: 1.020
[44,     3] loss: 0.953
[45,     3] loss: 0.883
[46,     3] loss: 0.904
[47,     3] loss: 0.938
[48,     3] loss: 1.173
[49,     3] loss: 1.031
[50,     3] loss: 0.987
[51,     3] loss: 0.975
[52,     3] loss: 1.229
[53,     3] loss: 0.961
[54,     3] loss: 1.017
[55,     3] loss: 0.938
[56,     3] loss: 0.882
[57,     3] loss: 0.815
[58,     3] loss: 0.800
[59,     3] loss: 0.863
[60,     3] loss: 0.893
[61,     3] loss: 0.978
[62,     3] loss: 0.839
[63,     3] loss: 0.793
[64,     3] loss: 0.872
[65,     3] loss: 0.876
[66,     3] loss: 0.884
[67,     3] loss: 0.784
[68,     3] loss: 0.798
[69,     3] loss: 0.853
[70,     3] loss: 0.824
[71,     3] loss: 0.940
Early stopping applied (best metric=0.5390403270721436)
Finished Training
Total time taken: 19.745072603225708
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.397
[3,     3] loss: 1.372
[4,     3] loss: 1.406
[5,     3] loss: 1.395
[6,     3] loss: 1.390
[7,     3] loss: 1.377
[8,     3] loss: 1.398
[9,     3] loss: 1.401
[10,     3] loss: 1.397
[11,     3] loss: 1.387
[12,     3] loss: 1.390
[13,     3] loss: 1.385
[14,     3] loss: 1.391
[15,     3] loss: 1.385
[16,     3] loss: 1.378
[17,     3] loss: 1.382
[18,     3] loss: 1.392
[19,     3] loss: 1.375
[20,     3] loss: 1.354
[21,     3] loss: 1.331
[22,     3] loss: 1.343
[23,     3] loss: 1.263
[24,     3] loss: 1.193
[25,     3] loss: 1.117
[26,     3] loss: 1.204
[27,     3] loss: 1.055
[28,     3] loss: 1.075
[29,     3] loss: 1.082
[30,     3] loss: 1.036
[31,     3] loss: 1.086
[32,     3] loss: 1.227
[33,     3] loss: 1.097
[34,     3] loss: 1.096
[35,     3] loss: 1.009
[36,     3] loss: 0.958
[37,     3] loss: 0.878
[38,     3] loss: 0.989
[39,     3] loss: 0.961
[40,     3] loss: 0.916
[41,     3] loss: 0.911
[42,     3] loss: 0.939
[43,     3] loss: 0.956
[44,     3] loss: 1.166
[45,     3] loss: 1.063
[46,     3] loss: 0.982
[47,     3] loss: 0.985
[48,     3] loss: 1.107
[49,     3] loss: 1.150
[50,     3] loss: 1.011
[51,     3] loss: 1.030
[52,     3] loss: 0.959
[53,     3] loss: 0.838
[54,     3] loss: 0.881
[55,     3] loss: 1.092
[56,     3] loss: 1.086
[57,     3] loss: 0.998
[58,     3] loss: 1.041
[59,     3] loss: 1.045
[60,     3] loss: 1.019
[61,     3] loss: 0.930
[62,     3] loss: 0.878
[63,     3] loss: 0.915
[64,     3] loss: 0.849
[65,     3] loss: 0.822
[66,     3] loss: 0.821
[67,     3] loss: 1.182
[68,     3] loss: 1.116
[69,     3] loss: 1.092
[70,     3] loss: 1.011
[71,     3] loss: 0.933
[72,     3] loss: 1.007
[73,     3] loss: 1.130
[74,     3] loss: 1.017
[75,     3] loss: 0.925
[76,     3] loss: 0.997
[77,     3] loss: 0.939
[78,     3] loss: 0.878
[79,     3] loss: 0.787
[80,     3] loss: 0.778
[81,     3] loss: 0.838
[82,     3] loss: 0.810
[83,     3] loss: 0.830
[84,     3] loss: 0.888
[85,     3] loss: 0.903
[86,     3] loss: 1.038
[87,     3] loss: 1.160
[88,     3] loss: 0.946
[89,     3] loss: 0.994
[90,     3] loss: 0.842
[91,     3] loss: 0.850
[92,     3] loss: 0.949
[93,     3] loss: 0.898
Early stopping applied (best metric=0.5318953990936279)
Finished Training
Total time taken: 26.104097366333008
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.377
[4,     3] loss: 1.394
[5,     3] loss: 1.375
[6,     3] loss: 1.414
[7,     3] loss: 1.374
[8,     3] loss: 1.416
[9,     3] loss: 1.373
[10,     3] loss: 1.386
[11,     3] loss: 1.382
[12,     3] loss: 1.377
[13,     3] loss: 1.348
[14,     3] loss: 1.324
[15,     3] loss: 1.275
[16,     3] loss: 1.326
[17,     3] loss: 1.240
[18,     3] loss: 1.184
[19,     3] loss: 1.170
[20,     3] loss: 1.266
[21,     3] loss: 1.177
[22,     3] loss: 1.128
[23,     3] loss: 1.214
[24,     3] loss: 1.098
[25,     3] loss: 1.103
[26,     3] loss: 1.014
[27,     3] loss: 1.063
[28,     3] loss: 1.145
[29,     3] loss: 0.990
[30,     3] loss: 1.071
[31,     3] loss: 0.984
[32,     3] loss: 0.970
[33,     3] loss: 1.044
[34,     3] loss: 0.958
[35,     3] loss: 1.039
[36,     3] loss: 0.977
[37,     3] loss: 1.065
[38,     3] loss: 1.073
[39,     3] loss: 0.990
[40,     3] loss: 1.005
[41,     3] loss: 0.937
[42,     3] loss: 0.824
[43,     3] loss: 0.925
[44,     3] loss: 0.920
[45,     3] loss: 0.864
[46,     3] loss: 0.830
[47,     3] loss: 0.804
[48,     3] loss: 0.776
[49,     3] loss: 0.812
[50,     3] loss: 0.737
[51,     3] loss: 0.738
[52,     3] loss: 1.168
[53,     3] loss: 1.067
[54,     3] loss: 1.053
[55,     3] loss: 1.001
[56,     3] loss: 0.972
[57,     3] loss: 0.908
[58,     3] loss: 0.844
[59,     3] loss: 0.845
[60,     3] loss: 0.804
[61,     3] loss: 0.841
[62,     3] loss: 0.848
[63,     3] loss: 0.808
[64,     3] loss: 0.870
[65,     3] loss: 0.890
[66,     3] loss: 0.858
[67,     3] loss: 1.020
[68,     3] loss: 1.124
[69,     3] loss: 1.042
[70,     3] loss: 0.981
[71,     3] loss: 0.905
[72,     3] loss: 0.824
[73,     3] loss: 0.894
[74,     3] loss: 0.906
[75,     3] loss: 0.946
[76,     3] loss: 0.900
Early stopping applied (best metric=0.5031499266624451)
Finished Training
Total time taken: 20.98307728767395
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.387
[3,     3] loss: 1.373
[4,     3] loss: 1.399
[5,     3] loss: 1.357
[6,     3] loss: 1.348
[7,     3] loss: 1.330
[8,     3] loss: 1.281
[9,     3] loss: 1.269
[10,     3] loss: 1.195
[11,     3] loss: 1.194
[12,     3] loss: 1.235
[13,     3] loss: 1.125
[14,     3] loss: 1.183
[15,     3] loss: 1.169
[16,     3] loss: 1.124
[17,     3] loss: 1.146
[18,     3] loss: 1.053
[19,     3] loss: 0.974
[20,     3] loss: 1.006
[21,     3] loss: 1.032
[22,     3] loss: 1.039
[23,     3] loss: 1.163
[24,     3] loss: 1.044
[25,     3] loss: 1.044
[26,     3] loss: 1.005
[27,     3] loss: 0.900
[28,     3] loss: 0.963
[29,     3] loss: 1.028
[30,     3] loss: 0.933
[31,     3] loss: 0.926
[32,     3] loss: 0.992
[33,     3] loss: 0.972
[34,     3] loss: 0.868
[35,     3] loss: 0.794
[36,     3] loss: 0.947
[37,     3] loss: 0.827
[38,     3] loss: 0.867
[39,     3] loss: 0.813
[40,     3] loss: 0.944
[41,     3] loss: 0.865
[42,     3] loss: 0.890
[43,     3] loss: 0.865
[44,     3] loss: 0.883
[45,     3] loss: 0.806
[46,     3] loss: 0.900
[47,     3] loss: 0.826
[48,     3] loss: 0.976
[49,     3] loss: 0.909
[50,     3] loss: 0.890
[51,     3] loss: 0.817
[52,     3] loss: 0.794
[53,     3] loss: 0.824
[54,     3] loss: 0.788
[55,     3] loss: 0.741
[56,     3] loss: 0.793
[57,     3] loss: 0.763
[58,     3] loss: 0.778
[59,     3] loss: 1.056
[60,     3] loss: 0.973
[61,     3] loss: 1.012
[62,     3] loss: 0.989
[63,     3] loss: 0.953
[64,     3] loss: 0.848
[65,     3] loss: 0.877
[66,     3] loss: 0.808
[67,     3] loss: 0.809
[68,     3] loss: 0.786
[69,     3] loss: 0.763
[70,     3] loss: 0.822
[71,     3] loss: 0.834
[72,     3] loss: 0.880
[73,     3] loss: 0.898
[74,     3] loss: 0.886
[75,     3] loss: 0.833
[76,     3] loss: 0.792
[77,     3] loss: 0.850
[78,     3] loss: 1.086
Early stopping applied (best metric=0.5281622409820557)
Finished Training
Total time taken: 21.60208034515381
{'S-palmitoylation-C Validation Accuracy': 0.6421560794049878, 'S-palmitoylation-C Validation Sensitivity': 0.30310231023102313, 'S-palmitoylation-C Validation Specificity': 0.7271394695362405, 'S-palmitoylation-C Validation Precision': 0.22296777526899927, 'S-palmitoylation-C AUC ROC': 0.5288345797615188, 'S-palmitoylation-C AUC PR': 0.21744903894207535, 'S-palmitoylation-C MCC': 0.029375559446939786, 'S-palmitoylation-C F1': 0.23163851537580904, 'Validation Loss (S-palmitoylation-C)': 0.5550598939259846, 'Hydroxylation-K Validation Accuracy': 0.6717494089834515, 'Hydroxylation-K Validation Sensitivity': 0.8340740740740741, 'Hydroxylation-K Validation Specificity': 0.631578947368421, 'Hydroxylation-K Validation Precision': 0.39990453264963066, 'Hydroxylation-K AUC ROC': 0.8168421052631579, 'Hydroxylation-K AUC PR': 0.566068324143923, 'Hydroxylation-K MCC': 0.39631413286823336, 'Hydroxylation-K F1': 0.5257770217553556, 'Validation Loss (Hydroxylation-K)': 0.5246878345807393, 'Validation Loss (total)': 1.079747748374939, 'TimeToTrain': 21.284545389811196}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005589325676949412,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5205943940846252,
 'loss_weight_S-palmitoylation-C': 0.09329604833357641,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2781468819,
 'sample_weights': [0.5838480573131971, 0.5146666583115327],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.793848595242059,
 'weight_decay_Hydroxylation-K': 0.2179921090577257,
 'weight_decay_S-palmitoylation-C': 5.135925539460114}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.389
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009963532893019126,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.037282208121685534,
 'loss_weight_S-palmitoylation-C': 0.36745221784721765,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3592195763,
 'sample_weights': [0.09329604833357641, 0.5205943940846252],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.140611028675353,
 'weight_decay_Hydroxylation-K': 1.8816777691098063,
 'weight_decay_S-palmitoylation-C': 8.047392420848023}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.381
[3,     3] loss: 1.374
[4,     3] loss: 1.383
[5,     3] loss: 1.378
[6,     3] loss: 1.394
[7,     3] loss: 1.386
[8,     3] loss: 1.383
[9,     3] loss: 1.386
[10,     3] loss: 1.365
[11,     3] loss: 1.330
[12,     3] loss: 1.313
[13,     3] loss: 1.304
[14,     3] loss: 1.203
[15,     3] loss: 1.120
[16,     3] loss: 1.223
[17,     3] loss: 1.228
[18,     3] loss: 1.121
[19,     3] loss: 1.124
[20,     3] loss: 1.173
[21,     3] loss: 1.247
[22,     3] loss: 1.216
[23,     3] loss: 1.147
[24,     3] loss: 1.196
[25,     3] loss: 1.086
[26,     3] loss: 1.065
[27,     3] loss: 1.069
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005534792873682688,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8850103403762195,
 'loss_weight_S-palmitoylation-C': 0.14677304310091782,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2758886750,
 'sample_weights': [0.36745221784721765, 0.037282208121685534],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.723421419784947,
 'weight_decay_Hydroxylation-K': 1.2843404130832536,
 'weight_decay_S-palmitoylation-C': 1.8027656199581084}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.387
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010949770836315405,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7441431092519151,
 'loss_weight_S-palmitoylation-C': 0.10882743286716763,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 114522194,
 'sample_weights': [0.14677304310091782, 0.8850103403762195],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.969836727811631,
 'weight_decay_Hydroxylation-K': 6.798513066632784,
 'weight_decay_S-palmitoylation-C': 3.9329691610687725}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.385
[3,     3] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002544353844310999,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4719803459250955,
 'loss_weight_S-palmitoylation-C': 0.25682056199505343,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2876224153,
 'sample_weights': [0.10882743286716763, 0.7441431092519151],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.311593672487009,
 'weight_decay_Hydroxylation-K': 6.57513830834004,
 'weight_decay_S-palmitoylation-C': 4.73939435829074}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.392
[3,     3] loss: 1.387
[4,     3] loss: 1.390
[5,     3] loss: 1.388
[6,     3] loss: 1.389
[7,     3] loss: 1.389
[8,     3] loss: 1.386
[9,     3] loss: 1.388
[10,     3] loss: 1.391
[11,     3] loss: 1.387
[12,     3] loss: 1.383
[13,     3] loss: 1.384
[14,     3] loss: 1.384
[15,     3] loss: 1.386
[16,     3] loss: 1.389
[17,     3] loss: 1.385
[18,     3] loss: 1.382
[19,     3] loss: 1.383
[20,     3] loss: 1.386
[21,     3] loss: 1.380
[22,     3] loss: 1.382
[23,     3] loss: 1.379
[24,     3] loss: 1.375
[25,     3] loss: 1.357
[26,     3] loss: 1.334
[27,     3] loss: 1.311
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014619436411432048,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.40658657907497536,
 'loss_weight_S-palmitoylation-C': 0.47934734579209237,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3674720706,
 'sample_weights': [0.25682056199505343, 0.4719803459250955],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.049744470970529,
 'weight_decay_Hydroxylation-K': 0.15928696400621692,
 'weight_decay_S-palmitoylation-C': 4.7030520938222695}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.389
[3,     3] loss: 1.383
[4,     3] loss: 1.384
[5,     3] loss: 1.389
[6,     3] loss: 1.373
[7,     3] loss: 1.372
[8,     3] loss: 1.346
[9,     3] loss: 1.352
[10,     3] loss: 1.311
[11,     3] loss: 1.281
[12,     3] loss: 1.273
[13,     3] loss: 1.202
[14,     3] loss: 1.254
[15,     3] loss: 1.193
[16,     3] loss: 1.210
[17,     3] loss: 1.104
[18,     3] loss: 1.098
[19,     3] loss: 0.998
[20,     3] loss: 1.029
[21,     3] loss: 1.065
[22,     3] loss: 0.980
[23,     3] loss: 0.971
[24,     3] loss: 1.040
[25,     3] loss: 1.082
[26,     3] loss: 1.065
[27,     3] loss: 1.002
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020439496723993113,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.36851022847317827,
 'loss_weight_S-palmitoylation-C': 0.4710267646735417,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3894601353,
 'sample_weights': [0.47934734579209237, 0.40658657907497536],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.272845372717123,
 'weight_decay_Hydroxylation-K': 1.3725121890615932,
 'weight_decay_S-palmitoylation-C': 4.682391971173867}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.408
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033354719035570118,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.816682856431803,
 'loss_weight_S-palmitoylation-C': 0.0740758028804429,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2322709991,
 'sample_weights': [0.4710267646735417, 0.36851022847317827],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.054382562032423,
 'weight_decay_Hydroxylation-K': 0.8468164410853283,
 'weight_decay_S-palmitoylation-C': 4.104506293168307}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.393
[3,     3] loss: 1.390
[4,     3] loss: 1.377
[5,     3] loss: 1.396
[6,     3] loss: 1.368
[7,     3] loss: 1.355
[8,     3] loss: 1.349
[9,     3] loss: 1.295
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003289573915795762,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4582679254508909,
 'loss_weight_S-palmitoylation-C': 0.3560665680018854,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 955978022,
 'sample_weights': [0.0740758028804429, 0.816682856431803],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.9994507224983415,
 'weight_decay_Hydroxylation-K': 9.142774781114468,
 'weight_decay_S-palmitoylation-C': 9.181890521986954}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.383
[3,     3] loss: 1.396
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003927053181071657,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.011768360977008119,
 'loss_weight_S-palmitoylation-C': 0.06830585923342081,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2093987944,
 'sample_weights': [0.3560665680018854, 0.4582679254508909],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.723437507500662,
 'weight_decay_Hydroxylation-K': 3.605191695201306,
 'weight_decay_S-palmitoylation-C': 6.522613721378121}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.383
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009248334149681927,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7289844219000172,
 'loss_weight_S-palmitoylation-C': 0.04179791250595771,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2776035449,
 'sample_weights': [0.06830585923342081, 0.011768360977008119],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8410143696842045,
 'weight_decay_Hydroxylation-K': 4.22432603131161,
 'weight_decay_S-palmitoylation-C': 0.728022459382748}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.397
[3,     3] loss: 1.390
[4,     3] loss: 1.397
[5,     3] loss: 1.385
[6,     3] loss: 1.384
[7,     3] loss: 1.384
[8,     3] loss: 1.392
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012533654158114692,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9249333145400942,
 'loss_weight_S-palmitoylation-C': 0.061913660748526736,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1823078595,
 'sample_weights': [0.04179791250595771, 0.7289844219000172],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.1574538248724755,
 'weight_decay_Hydroxylation-K': 0.03577746883966404,
 'weight_decay_S-palmitoylation-C': 8.5971542992109}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.377
[2,     3] loss: 1.393
[3,     3] loss: 1.397
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010509221988400743,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24143617224856675,
 'loss_weight_S-palmitoylation-C': 0.129746195271892,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2800066736,
 'sample_weights': [0.061913660748526736, 0.9249333145400942],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3934602183348597,
 'weight_decay_Hydroxylation-K': 6.176339568247203,
 'weight_decay_S-palmitoylation-C': 3.8346993064253043}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.403
[3,     3] loss: 1.385
[4,     3] loss: 1.387
[5,     3] loss: 1.382
[6,     3] loss: 1.387
[7,     3] loss: 1.386
[8,     3] loss: 1.384
[9,     3] loss: 1.383
[10,     3] loss: 1.390
[11,     3] loss: 1.387
[12,     3] loss: 1.386
[13,     3] loss: 1.391
[14,     3] loss: 1.380
[15,     3] loss: 1.377
[16,     3] loss: 1.379
[17,     3] loss: 1.365
[18,     3] loss: 1.363
[19,     3] loss: 1.355
[20,     3] loss: 1.309
[21,     3] loss: 1.287
[22,     3] loss: 1.302
[23,     3] loss: 1.246
[24,     3] loss: 1.228
[25,     3] loss: 1.189
[26,     3] loss: 1.081
[27,     3] loss: 1.159
[28,     3] loss: 1.078
[29,     3] loss: 1.167
[30,     3] loss: 1.064
[31,     3] loss: 1.079
[32,     3] loss: 1.149
[33,     3] loss: 1.050
[34,     3] loss: 1.066
[35,     3] loss: 0.992
[36,     3] loss: 0.940
[37,     3] loss: 1.099
[38,     3] loss: 1.087
[39,     3] loss: 1.059
[40,     3] loss: 1.016
[41,     3] loss: 1.036
[42,     3] loss: 0.994
[43,     3] loss: 0.891
[44,     3] loss: 0.913
[45,     3] loss: 0.871
[46,     3] loss: 0.883
[47,     3] loss: 0.869
[48,     3] loss: 1.000
[49,     3] loss: 0.888
[50,     3] loss: 1.051
[51,     3] loss: 0.985
[52,     3] loss: 0.845
[53,     3] loss: 1.036
[54,     3] loss: 0.872
[55,     3] loss: 0.881
[56,     3] loss: 0.924
[57,     3] loss: 0.880
[58,     3] loss: 0.902
[59,     3] loss: 0.845
[60,     3] loss: 0.863
[61,     3] loss: 0.865
[62,     3] loss: 0.875
[63,     3] loss: 0.835
[64,     3] loss: 0.788
[65,     3] loss: 0.808
[66,     3] loss: 0.827
[67,     3] loss: 0.771
[68,     3] loss: 0.766
[69,     3] loss: 0.751
[70,     3] loss: 0.758
[71,     3] loss: 0.740
[72,     3] loss: 0.726
[73,     3] loss: 0.757
[74,     3] loss: 0.754
[75,     3] loss: 0.771
[76,     3] loss: 0.894
[77,     3] loss: 0.913
[78,     3] loss: 0.825
[79,     3] loss: 0.879
[80,     3] loss: 0.877
[81,     3] loss: 0.775
[82,     3] loss: 0.803
[83,     3] loss: 0.745
[84,     3] loss: 0.793
[85,     3] loss: 0.777
[86,     3] loss: 0.760
[87,     3] loss: 0.785
[88,     3] loss: 0.783
[89,     3] loss: 0.741
[90,     3] loss: 0.735
[91,     3] loss: 0.836
[92,     3] loss: 0.781
[93,     3] loss: 0.869
[94,     3] loss: 0.759
[95,     3] loss: 0.866
[96,     3] loss: 0.811
[97,     3] loss: 0.843
[98,     3] loss: 0.835
[99,     3] loss: 0.802
[100,     3] loss: 0.787
[101,     3] loss: 0.831
[102,     3] loss: 0.797
[103,     3] loss: 0.797
[104,     3] loss: 0.773
[105,     3] loss: 0.757
[106,     3] loss: 0.768
[107,     3] loss: 0.800
Early stopping applied (best metric=0.5230686664581299)
Finished Training
Total time taken: 29.990111351013184
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.389
[3,     3] loss: 1.379
[4,     3] loss: 1.383
[5,     3] loss: 1.386
[6,     3] loss: 1.382
[7,     3] loss: 1.375
[8,     3] loss: 1.374
[9,     3] loss: 1.373
[10,     3] loss: 1.343
[11,     3] loss: 1.349
[12,     3] loss: 1.310
[13,     3] loss: 1.296
[14,     3] loss: 1.267
[15,     3] loss: 1.241
[16,     3] loss: 1.288
[17,     3] loss: 1.172
[18,     3] loss: 1.174
[19,     3] loss: 1.141
[20,     3] loss: 1.045
[21,     3] loss: 1.058
[22,     3] loss: 1.033
[23,     3] loss: 0.985
[24,     3] loss: 1.144
[25,     3] loss: 0.968
[26,     3] loss: 1.049
[27,     3] loss: 0.932
[28,     3] loss: 0.963
[29,     3] loss: 0.957
[30,     3] loss: 0.932
[31,     3] loss: 0.963
[32,     3] loss: 0.886
[33,     3] loss: 1.025
[34,     3] loss: 1.064
[35,     3] loss: 0.930
[36,     3] loss: 0.897
[37,     3] loss: 0.973
[38,     3] loss: 0.847
[39,     3] loss: 0.883
[40,     3] loss: 0.984
[41,     3] loss: 0.853
[42,     3] loss: 0.864
[43,     3] loss: 0.855
[44,     3] loss: 0.807
[45,     3] loss: 0.845
[46,     3] loss: 0.839
[47,     3] loss: 0.855
[48,     3] loss: 0.939
[49,     3] loss: 0.802
[50,     3] loss: 0.869
[51,     3] loss: 0.865
[52,     3] loss: 0.874
[53,     3] loss: 0.805
[54,     3] loss: 0.941
[55,     3] loss: 0.976
[56,     3] loss: 0.838
[57,     3] loss: 0.899
[58,     3] loss: 0.853
[59,     3] loss: 0.821
[60,     3] loss: 0.810
[61,     3] loss: 0.870
[62,     3] loss: 0.763
[63,     3] loss: 0.836
[64,     3] loss: 0.772
[65,     3] loss: 0.767
[66,     3] loss: 0.778
[67,     3] loss: 0.755
[68,     3] loss: 0.789
[69,     3] loss: 0.754
[70,     3] loss: 0.768
Early stopping applied (best metric=0.5222153067588806)
Finished Training
Total time taken: 19.34507179260254
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.386
[3,     3] loss: 1.388
[4,     3] loss: 1.383
[5,     3] loss: 1.379
[6,     3] loss: 1.375
[7,     3] loss: 1.380
[8,     3] loss: 1.354
[9,     3] loss: 1.364
[10,     3] loss: 1.346
[11,     3] loss: 1.332
[12,     3] loss: 1.276
[13,     3] loss: 1.283
[14,     3] loss: 1.279
[15,     3] loss: 1.239
[16,     3] loss: 1.153
[17,     3] loss: 1.230
[18,     3] loss: 1.226
[19,     3] loss: 1.166
[20,     3] loss: 1.051
[21,     3] loss: 1.074
[22,     3] loss: 1.119
[23,     3] loss: 1.044
[24,     3] loss: 1.083
[25,     3] loss: 1.099
[26,     3] loss: 0.995
[27,     3] loss: 0.996
[28,     3] loss: 0.987
[29,     3] loss: 0.960
[30,     3] loss: 0.976
[31,     3] loss: 0.977
[32,     3] loss: 0.888
[33,     3] loss: 0.954
[34,     3] loss: 0.967
[35,     3] loss: 1.022
[36,     3] loss: 0.966
[37,     3] loss: 0.937
[38,     3] loss: 0.916
[39,     3] loss: 0.964
[40,     3] loss: 0.864
[41,     3] loss: 0.906
[42,     3] loss: 0.850
[43,     3] loss: 0.955
[44,     3] loss: 0.876
[45,     3] loss: 0.838
[46,     3] loss: 0.823
[47,     3] loss: 0.793
[48,     3] loss: 0.812
[49,     3] loss: 0.840
[50,     3] loss: 0.784
[51,     3] loss: 0.908
[52,     3] loss: 0.888
[53,     3] loss: 0.834
[54,     3] loss: 0.799
[55,     3] loss: 0.808
[56,     3] loss: 0.898
[57,     3] loss: 0.842
[58,     3] loss: 0.792
[59,     3] loss: 0.815
[60,     3] loss: 0.764
[61,     3] loss: 0.796
[62,     3] loss: 0.828
[63,     3] loss: 0.779
[64,     3] loss: 0.854
[65,     3] loss: 0.903
[66,     3] loss: 0.790
[67,     3] loss: 0.884
[68,     3] loss: 0.867
[69,     3] loss: 0.943
Early stopping applied (best metric=0.5261827707290649)
Finished Training
Total time taken: 19.426071643829346
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.377
[2,     3] loss: 1.392
[3,     3] loss: 1.383
[4,     3] loss: 1.377
[5,     3] loss: 1.380
[6,     3] loss: 1.384
[7,     3] loss: 1.367
[8,     3] loss: 1.377
[9,     3] loss: 1.373
[10,     3] loss: 1.349
[11,     3] loss: 1.352
[12,     3] loss: 1.320
[13,     3] loss: 1.287
[14,     3] loss: 1.334
[15,     3] loss: 1.272
[16,     3] loss: 1.230
[17,     3] loss: 1.248
[18,     3] loss: 1.238
[19,     3] loss: 1.196
[20,     3] loss: 1.210
[21,     3] loss: 1.159
[22,     3] loss: 1.107
[23,     3] loss: 1.119
[24,     3] loss: 1.065
[25,     3] loss: 1.064
[26,     3] loss: 1.088
[27,     3] loss: 1.114
[28,     3] loss: 1.044
[29,     3] loss: 1.090
[30,     3] loss: 0.985
[31,     3] loss: 0.998
[32,     3] loss: 1.097
[33,     3] loss: 0.980
[34,     3] loss: 1.023
[35,     3] loss: 1.053
[36,     3] loss: 1.136
[37,     3] loss: 1.062
[38,     3] loss: 1.068
[39,     3] loss: 0.946
[40,     3] loss: 0.964
[41,     3] loss: 0.987
[42,     3] loss: 0.961
[43,     3] loss: 0.938
[44,     3] loss: 0.985
[45,     3] loss: 0.872
[46,     3] loss: 0.907
[47,     3] loss: 0.940
[48,     3] loss: 0.856
[49,     3] loss: 0.927
[50,     3] loss: 1.005
[51,     3] loss: 0.967
[52,     3] loss: 1.011
[53,     3] loss: 0.875
[54,     3] loss: 0.879
[55,     3] loss: 0.880
[56,     3] loss: 0.883
[57,     3] loss: 0.910
[58,     3] loss: 0.867
[59,     3] loss: 0.857
[60,     3] loss: 0.803
[61,     3] loss: 0.836
[62,     3] loss: 0.819
[63,     3] loss: 0.888
[64,     3] loss: 0.849
[65,     3] loss: 0.850
[66,     3] loss: 0.816
[67,     3] loss: 0.816
[68,     3] loss: 0.831
[69,     3] loss: 0.802
[70,     3] loss: 0.854
[71,     3] loss: 0.821
[72,     3] loss: 0.871
[73,     3] loss: 0.825
[74,     3] loss: 0.880
[75,     3] loss: 0.843
[76,     3] loss: 0.879
[77,     3] loss: 0.834
[78,     3] loss: 0.783
Early stopping applied (best metric=0.5078004598617554)
Finished Training
Total time taken: 21.796080827713013
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.386
[3,     3] loss: 1.389
[4,     3] loss: 1.387
[5,     3] loss: 1.394
[6,     3] loss: 1.386
[7,     3] loss: 1.383
[8,     3] loss: 1.382
[9,     3] loss: 1.381
[10,     3] loss: 1.375
[11,     3] loss: 1.378
[12,     3] loss: 1.376
[13,     3] loss: 1.378
[14,     3] loss: 1.358
[15,     3] loss: 1.368
[16,     3] loss: 1.360
[17,     3] loss: 1.332
[18,     3] loss: 1.323
[19,     3] loss: 1.299
[20,     3] loss: 1.283
[21,     3] loss: 1.253
[22,     3] loss: 1.236
[23,     3] loss: 1.148
[24,     3] loss: 1.196
[25,     3] loss: 1.114
[26,     3] loss: 1.149
[27,     3] loss: 1.144
[28,     3] loss: 1.080
[29,     3] loss: 1.101
[30,     3] loss: 1.069
[31,     3] loss: 1.073
[32,     3] loss: 1.105
[33,     3] loss: 0.970
[34,     3] loss: 1.030
[35,     3] loss: 0.981
[36,     3] loss: 1.024
[37,     3] loss: 1.012
[38,     3] loss: 1.028
[39,     3] loss: 1.024
[40,     3] loss: 1.041
[41,     3] loss: 0.910
[42,     3] loss: 1.019
[43,     3] loss: 0.949
[44,     3] loss: 1.006
[45,     3] loss: 0.996
[46,     3] loss: 0.878
[47,     3] loss: 0.968
[48,     3] loss: 0.901
[49,     3] loss: 0.954
[50,     3] loss: 1.002
[51,     3] loss: 1.159
[52,     3] loss: 0.897
[53,     3] loss: 0.950
[54,     3] loss: 0.917
[55,     3] loss: 0.911
[56,     3] loss: 0.868
[57,     3] loss: 0.861
[58,     3] loss: 0.873
[59,     3] loss: 0.822
[60,     3] loss: 0.819
[61,     3] loss: 0.814
[62,     3] loss: 0.801
[63,     3] loss: 0.876
[64,     3] loss: 0.800
[65,     3] loss: 0.861
[66,     3] loss: 0.820
[67,     3] loss: 0.776
[68,     3] loss: 0.772
[69,     3] loss: 0.755
[70,     3] loss: 0.799
[71,     3] loss: 0.773
[72,     3] loss: 0.803
[73,     3] loss: 0.814
[74,     3] loss: 0.778
[75,     3] loss: 0.783
[76,     3] loss: 0.792
[77,     3] loss: 0.760
[78,     3] loss: 0.778
[79,     3] loss: 0.768
[80,     3] loss: 0.748
[81,     3] loss: 0.749
[82,     3] loss: 0.766
[83,     3] loss: 0.736
[84,     3] loss: 0.765
[85,     3] loss: 0.789
[86,     3] loss: 0.746
[87,     3] loss: 0.749
[88,     3] loss: 0.761
[89,     3] loss: 0.754
Early stopping applied (best metric=0.48114514350891113)
Finished Training
Total time taken: 24.86309289932251
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.401
[2,     3] loss: 1.382
[3,     3] loss: 1.388
[4,     3] loss: 1.391
[5,     3] loss: 1.391
[6,     3] loss: 1.380
[7,     3] loss: 1.380
[8,     3] loss: 1.394
[9,     3] loss: 1.381
[10,     3] loss: 1.376
[11,     3] loss: 1.381
[12,     3] loss: 1.380
[13,     3] loss: 1.374
[14,     3] loss: 1.376
[15,     3] loss: 1.366
[16,     3] loss: 1.356
[17,     3] loss: 1.336
[18,     3] loss: 1.336
[19,     3] loss: 1.315
[20,     3] loss: 1.283
[21,     3] loss: 1.294
[22,     3] loss: 1.273
[23,     3] loss: 1.222
[24,     3] loss: 1.226
[25,     3] loss: 1.178
[26,     3] loss: 1.173
[27,     3] loss: 1.134
[28,     3] loss: 1.100
[29,     3] loss: 1.043
[30,     3] loss: 1.089
[31,     3] loss: 1.044
[32,     3] loss: 1.076
[33,     3] loss: 1.155
[34,     3] loss: 1.040
[35,     3] loss: 1.005
[36,     3] loss: 1.065
[37,     3] loss: 1.039
[38,     3] loss: 0.966
[39,     3] loss: 0.930
[40,     3] loss: 0.903
[41,     3] loss: 0.987
[42,     3] loss: 0.996
[43,     3] loss: 0.938
[44,     3] loss: 0.870
[45,     3] loss: 0.872
[46,     3] loss: 0.843
[47,     3] loss: 0.967
[48,     3] loss: 0.972
[49,     3] loss: 0.864
[50,     3] loss: 0.860
[51,     3] loss: 0.844
[52,     3] loss: 0.901
[53,     3] loss: 0.884
[54,     3] loss: 0.817
[55,     3] loss: 0.841
[56,     3] loss: 0.794
[57,     3] loss: 0.787
[58,     3] loss: 0.837
[59,     3] loss: 0.848
[60,     3] loss: 0.881
[61,     3] loss: 0.857
[62,     3] loss: 0.940
[63,     3] loss: 0.830
[64,     3] loss: 0.916
[65,     3] loss: 0.810
[66,     3] loss: 0.920
[67,     3] loss: 0.842
[68,     3] loss: 0.964
[69,     3] loss: 0.835
[70,     3] loss: 0.809
[71,     3] loss: 0.841
[72,     3] loss: 0.801
[73,     3] loss: 0.774
[74,     3] loss: 0.820
[75,     3] loss: 0.806
[76,     3] loss: 0.760
[77,     3] loss: 0.853
[78,     3] loss: 0.865
[79,     3] loss: 0.797
[80,     3] loss: 0.801
[81,     3] loss: 0.816
[82,     3] loss: 0.836
[83,     3] loss: 0.778
[84,     3] loss: 0.784
[85,     3] loss: 0.776
[86,     3] loss: 0.761
[87,     3] loss: 0.765
[88,     3] loss: 0.753
[89,     3] loss: 0.760
[90,     3] loss: 0.758
[91,     3] loss: 0.731
[92,     3] loss: 0.815
[93,     3] loss: 0.738
[94,     3] loss: 0.760
[95,     3] loss: 0.771
[96,     3] loss: 0.820
[97,     3] loss: 0.769
[98,     3] loss: 0.774
Early stopping applied (best metric=0.523186206817627)
Finished Training
Total time taken: 26.967097759246826
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.376
[3,     3] loss: 1.391
[4,     3] loss: 1.391
[5,     3] loss: 1.378
[6,     3] loss: 1.375
[7,     3] loss: 1.366
[8,     3] loss: 1.362
[9,     3] loss: 1.344
[10,     3] loss: 1.342
[11,     3] loss: 1.329
[12,     3] loss: 1.324
[13,     3] loss: 1.371
[14,     3] loss: 1.285
[15,     3] loss: 1.214
[16,     3] loss: 1.152
[17,     3] loss: 1.210
[18,     3] loss: 1.229
[19,     3] loss: 1.169
[20,     3] loss: 1.070
[21,     3] loss: 1.124
[22,     3] loss: 1.017
[23,     3] loss: 1.102
[24,     3] loss: 1.122
[25,     3] loss: 0.952
[26,     3] loss: 0.948
[27,     3] loss: 0.986
[28,     3] loss: 0.959
[29,     3] loss: 0.909
[30,     3] loss: 0.908
[31,     3] loss: 1.045
[32,     3] loss: 0.954
[33,     3] loss: 0.899
[34,     3] loss: 0.912
[35,     3] loss: 0.880
[36,     3] loss: 0.904
[37,     3] loss: 0.893
[38,     3] loss: 0.861
[39,     3] loss: 0.914
[40,     3] loss: 0.897
[41,     3] loss: 0.933
[42,     3] loss: 0.885
[43,     3] loss: 0.883
[44,     3] loss: 0.881
[45,     3] loss: 0.834
[46,     3] loss: 0.873
[47,     3] loss: 0.846
[48,     3] loss: 0.924
[49,     3] loss: 0.848
[50,     3] loss: 0.820
[51,     3] loss: 0.823
[52,     3] loss: 0.809
[53,     3] loss: 0.821
[54,     3] loss: 0.834
[55,     3] loss: 0.834
[56,     3] loss: 0.805
[57,     3] loss: 0.830
[58,     3] loss: 0.846
[59,     3] loss: 0.869
[60,     3] loss: 0.838
[61,     3] loss: 0.828
[62,     3] loss: 0.860
[63,     3] loss: 0.883
[64,     3] loss: 0.840
[65,     3] loss: 0.831
[66,     3] loss: 0.895
[67,     3] loss: 0.868
[68,     3] loss: 0.790
[69,     3] loss: 0.784
[70,     3] loss: 0.767
[71,     3] loss: 0.771
Early stopping applied (best metric=0.521270751953125)
Finished Training
Total time taken: 19.711074590682983
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.387
[3,     3] loss: 1.376
[4,     3] loss: 1.385
[5,     3] loss: 1.376
[6,     3] loss: 1.385
[7,     3] loss: 1.383
[8,     3] loss: 1.379
[9,     3] loss: 1.362
[10,     3] loss: 1.358
[11,     3] loss: 1.352
[12,     3] loss: 1.332
[13,     3] loss: 1.324
[14,     3] loss: 1.317
[15,     3] loss: 1.261
[16,     3] loss: 1.326
[17,     3] loss: 1.263
[18,     3] loss: 1.228
[19,     3] loss: 1.245
[20,     3] loss: 1.177
[21,     3] loss: 1.146
[22,     3] loss: 1.191
[23,     3] loss: 1.168
[24,     3] loss: 1.059
[25,     3] loss: 0.986
[26,     3] loss: 1.029
[27,     3] loss: 1.047
[28,     3] loss: 0.911
[29,     3] loss: 0.978
[30,     3] loss: 1.052
[31,     3] loss: 0.874
[32,     3] loss: 0.938
[33,     3] loss: 0.932
[34,     3] loss: 0.966
[35,     3] loss: 1.070
[36,     3] loss: 0.897
[37,     3] loss: 0.907
[38,     3] loss: 0.846
[39,     3] loss: 0.943
[40,     3] loss: 0.829
[41,     3] loss: 0.917
[42,     3] loss: 0.891
[43,     3] loss: 0.808
[44,     3] loss: 0.866
[45,     3] loss: 0.894
[46,     3] loss: 0.835
[47,     3] loss: 0.877
[48,     3] loss: 0.807
[49,     3] loss: 0.803
[50,     3] loss: 0.825
[51,     3] loss: 0.788
[52,     3] loss: 0.789
[53,     3] loss: 0.804
[54,     3] loss: 0.824
[55,     3] loss: 0.782
[56,     3] loss: 0.837
[57,     3] loss: 0.818
[58,     3] loss: 0.766
[59,     3] loss: 0.774
[60,     3] loss: 0.791
[61,     3] loss: 0.826
[62,     3] loss: 0.759
[63,     3] loss: 0.931
[64,     3] loss: 0.782
[65,     3] loss: 0.831
[66,     3] loss: 0.776
[67,     3] loss: 0.780
[68,     3] loss: 0.905
[69,     3] loss: 0.831
[70,     3] loss: 0.781
[71,     3] loss: 0.788
[72,     3] loss: 0.846
[73,     3] loss: 0.928
[74,     3] loss: 0.861
[75,     3] loss: 0.828
Early stopping applied (best metric=0.526777982711792)
Finished Training
Total time taken: 20.77507710456848
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.392
[3,     3] loss: 1.389
[4,     3] loss: 1.384
[5,     3] loss: 1.381
[6,     3] loss: 1.386
[7,     3] loss: 1.385
[8,     3] loss: 1.384
[9,     3] loss: 1.386
[10,     3] loss: 1.372
[11,     3] loss: 1.371
[12,     3] loss: 1.371
[13,     3] loss: 1.357
[14,     3] loss: 1.345
[15,     3] loss: 1.359
[16,     3] loss: 1.321
[17,     3] loss: 1.298
[18,     3] loss: 1.251
[19,     3] loss: 1.252
[20,     3] loss: 1.212
[21,     3] loss: 1.162
[22,     3] loss: 1.247
[23,     3] loss: 1.205
[24,     3] loss: 1.157
[25,     3] loss: 1.090
[26,     3] loss: 1.066
[27,     3] loss: 1.238
[28,     3] loss: 1.131
[29,     3] loss: 1.090
[30,     3] loss: 1.128
[31,     3] loss: 1.081
[32,     3] loss: 1.064
[33,     3] loss: 1.065
[34,     3] loss: 1.044
[35,     3] loss: 1.020
[36,     3] loss: 1.048
[37,     3] loss: 0.967
[38,     3] loss: 1.082
[39,     3] loss: 1.027
[40,     3] loss: 0.980
[41,     3] loss: 0.967
[42,     3] loss: 0.925
[43,     3] loss: 0.886
[44,     3] loss: 0.912
[45,     3] loss: 0.938
[46,     3] loss: 0.874
[47,     3] loss: 0.953
[48,     3] loss: 0.850
[49,     3] loss: 0.863
[50,     3] loss: 0.905
[51,     3] loss: 0.886
[52,     3] loss: 0.878
[53,     3] loss: 0.889
[54,     3] loss: 0.828
[55,     3] loss: 0.836
[56,     3] loss: 0.864
[57,     3] loss: 0.922
[58,     3] loss: 0.871
[59,     3] loss: 0.808
[60,     3] loss: 0.904
[61,     3] loss: 0.825
[62,     3] loss: 0.828
[63,     3] loss: 0.847
[64,     3] loss: 0.867
[65,     3] loss: 0.867
[66,     3] loss: 0.916
[67,     3] loss: 0.833
[68,     3] loss: 0.874
[69,     3] loss: 0.994
[70,     3] loss: 0.900
[71,     3] loss: 0.830
[72,     3] loss: 0.867
Early stopping applied (best metric=0.49804016947746277)
Finished Training
Total time taken: 20.134073734283447
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.388
[3,     3] loss: 1.386
[4,     3] loss: 1.390
[5,     3] loss: 1.392
[6,     3] loss: 1.381
[7,     3] loss: 1.384
[8,     3] loss: 1.388
[9,     3] loss: 1.383
[10,     3] loss: 1.383
[11,     3] loss: 1.374
[12,     3] loss: 1.376
[13,     3] loss: 1.376
[14,     3] loss: 1.359
[15,     3] loss: 1.344
[16,     3] loss: 1.329
[17,     3] loss: 1.296
[18,     3] loss: 1.293
[19,     3] loss: 1.271
[20,     3] loss: 1.244
[21,     3] loss: 1.308
[22,     3] loss: 1.234
[23,     3] loss: 1.187
[24,     3] loss: 1.195
[25,     3] loss: 1.191
[26,     3] loss: 1.191
[27,     3] loss: 1.155
[28,     3] loss: 1.129
[29,     3] loss: 1.102
[30,     3] loss: 1.076
[31,     3] loss: 1.080
[32,     3] loss: 1.111
[33,     3] loss: 0.971
[34,     3] loss: 0.935
[35,     3] loss: 0.931
[36,     3] loss: 0.940
[37,     3] loss: 0.961
[38,     3] loss: 0.852
[39,     3] loss: 0.894
[40,     3] loss: 0.912
[41,     3] loss: 0.915
[42,     3] loss: 1.007
[43,     3] loss: 0.941
[44,     3] loss: 0.880
[45,     3] loss: 0.961
[46,     3] loss: 0.928
[47,     3] loss: 0.901
[48,     3] loss: 0.931
[49,     3] loss: 0.931
[50,     3] loss: 0.986
[51,     3] loss: 1.008
[52,     3] loss: 0.857
[53,     3] loss: 0.931
[54,     3] loss: 0.914
[55,     3] loss: 0.903
[56,     3] loss: 0.842
[57,     3] loss: 0.839
[58,     3] loss: 0.859
[59,     3] loss: 0.865
[60,     3] loss: 0.919
[61,     3] loss: 0.822
[62,     3] loss: 0.953
[63,     3] loss: 0.884
[64,     3] loss: 0.812
[65,     3] loss: 0.866
[66,     3] loss: 0.913
[67,     3] loss: 0.851
[68,     3] loss: 0.781
[69,     3] loss: 0.847
[70,     3] loss: 0.823
[71,     3] loss: 0.822
[72,     3] loss: 0.851
[73,     3] loss: 0.846
[74,     3] loss: 0.819
[75,     3] loss: 0.789
[76,     3] loss: 0.797
[77,     3] loss: 0.764
[78,     3] loss: 0.778
[79,     3] loss: 0.753
[80,     3] loss: 0.824
[81,     3] loss: 0.813
[82,     3] loss: 0.895
[83,     3] loss: 0.846
[84,     3] loss: 0.892
[85,     3] loss: 0.764
[86,     3] loss: 0.843
[87,     3] loss: 0.798
[88,     3] loss: 0.911
[89,     3] loss: 0.891
[90,     3] loss: 0.876
[91,     3] loss: 0.787
[92,     3] loss: 0.841
[93,     3] loss: 0.812
[94,     3] loss: 0.791
[95,     3] loss: 0.839
[96,     3] loss: 0.766
[97,     3] loss: 0.810
[98,     3] loss: 0.759
[99,     3] loss: 0.838
[100,     3] loss: 0.779
Early stopping applied (best metric=0.5017216205596924)
Finished Training
Total time taken: 27.799105882644653
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.390
[3,     3] loss: 1.385
[4,     3] loss: 1.377
[5,     3] loss: 1.378
[6,     3] loss: 1.376
[7,     3] loss: 1.377
[8,     3] loss: 1.368
[9,     3] loss: 1.363
[10,     3] loss: 1.362
[11,     3] loss: 1.358
[12,     3] loss: 1.326
[13,     3] loss: 1.331
[14,     3] loss: 1.301
[15,     3] loss: 1.319
[16,     3] loss: 1.288
[17,     3] loss: 1.220
[18,     3] loss: 1.223
[19,     3] loss: 1.137
[20,     3] loss: 1.148
[21,     3] loss: 1.117
[22,     3] loss: 1.160
[23,     3] loss: 1.032
[24,     3] loss: 0.998
[25,     3] loss: 1.034
[26,     3] loss: 0.969
[27,     3] loss: 0.902
[28,     3] loss: 0.906
[29,     3] loss: 0.942
[30,     3] loss: 1.006
[31,     3] loss: 1.075
[32,     3] loss: 0.960
[33,     3] loss: 0.879
[34,     3] loss: 1.049
[35,     3] loss: 0.944
[36,     3] loss: 0.958
[37,     3] loss: 0.981
[38,     3] loss: 0.925
[39,     3] loss: 0.933
[40,     3] loss: 0.907
[41,     3] loss: 0.879
[42,     3] loss: 0.911
[43,     3] loss: 0.981
[44,     3] loss: 0.922
[45,     3] loss: 1.011
[46,     3] loss: 0.919
[47,     3] loss: 0.999
[48,     3] loss: 0.888
[49,     3] loss: 0.813
[50,     3] loss: 0.847
[51,     3] loss: 0.818
[52,     3] loss: 0.813
[53,     3] loss: 0.852
[54,     3] loss: 0.782
[55,     3] loss: 0.794
[56,     3] loss: 0.815
[57,     3] loss: 0.796
[58,     3] loss: 0.815
[59,     3] loss: 0.812
[60,     3] loss: 0.797
[61,     3] loss: 0.798
[62,     3] loss: 0.879
[63,     3] loss: 0.756
[64,     3] loss: 0.794
[65,     3] loss: 0.760
[66,     3] loss: 0.862
[67,     3] loss: 0.864
[68,     3] loss: 0.798
[69,     3] loss: 0.834
[70,     3] loss: 0.815
[71,     3] loss: 0.791
Early stopping applied (best metric=0.5214635133743286)
Finished Training
Total time taken: 19.67007279396057
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.382
[3,     3] loss: 1.381
[4,     3] loss: 1.380
[5,     3] loss: 1.397
[6,     3] loss: 1.389
[7,     3] loss: 1.380
[8,     3] loss: 1.385
[9,     3] loss: 1.382
[10,     3] loss: 1.380
[11,     3] loss: 1.379
[12,     3] loss: 1.356
[13,     3] loss: 1.346
[14,     3] loss: 1.345
[15,     3] loss: 1.294
[16,     3] loss: 1.295
[17,     3] loss: 1.281
[18,     3] loss: 1.203
[19,     3] loss: 1.189
[20,     3] loss: 1.151
[21,     3] loss: 1.143
[22,     3] loss: 1.135
[23,     3] loss: 1.085
[24,     3] loss: 1.148
[25,     3] loss: 1.104
[26,     3] loss: 1.064
[27,     3] loss: 1.146
[28,     3] loss: 1.112
[29,     3] loss: 1.019
[30,     3] loss: 1.097
[31,     3] loss: 1.020
[32,     3] loss: 1.068
[33,     3] loss: 1.024
[34,     3] loss: 0.927
[35,     3] loss: 0.983
[36,     3] loss: 1.104
[37,     3] loss: 1.100
[38,     3] loss: 0.951
[39,     3] loss: 0.941
[40,     3] loss: 0.978
[41,     3] loss: 0.960
[42,     3] loss: 0.917
[43,     3] loss: 0.982
[44,     3] loss: 0.987
[45,     3] loss: 0.884
[46,     3] loss: 1.056
[47,     3] loss: 1.060
[48,     3] loss: 0.929
[49,     3] loss: 0.884
[50,     3] loss: 0.933
[51,     3] loss: 0.920
[52,     3] loss: 0.840
[53,     3] loss: 0.880
[54,     3] loss: 1.012
[55,     3] loss: 0.891
[56,     3] loss: 0.873
[57,     3] loss: 0.947
[58,     3] loss: 0.879
[59,     3] loss: 0.870
[60,     3] loss: 0.858
[61,     3] loss: 0.817
[62,     3] loss: 0.836
[63,     3] loss: 0.837
[64,     3] loss: 0.835
[65,     3] loss: 0.890
[66,     3] loss: 0.896
[67,     3] loss: 0.917
[68,     3] loss: 0.955
[69,     3] loss: 1.035
[70,     3] loss: 0.880
[71,     3] loss: 1.168
[72,     3] loss: 1.015
[73,     3] loss: 0.941
[74,     3] loss: 0.974
[75,     3] loss: 0.924
[76,     3] loss: 0.955
[77,     3] loss: 0.874
[78,     3] loss: 0.885
[79,     3] loss: 0.846
[80,     3] loss: 0.808
[81,     3] loss: 0.826
[82,     3] loss: 0.926
[83,     3] loss: 0.801
[84,     3] loss: 0.851
Early stopping applied (best metric=0.5353319644927979)
Finished Training
Total time taken: 23.274086236953735
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.392
[3,     3] loss: 1.389
[4,     3] loss: 1.383
[5,     3] loss: 1.386
[6,     3] loss: 1.385
[7,     3] loss: 1.382
[8,     3] loss: 1.366
[9,     3] loss: 1.394
[10,     3] loss: 1.385
[11,     3] loss: 1.375
[12,     3] loss: 1.371
[13,     3] loss: 1.368
[14,     3] loss: 1.346
[15,     3] loss: 1.323
[16,     3] loss: 1.332
[17,     3] loss: 1.291
[18,     3] loss: 1.297
[19,     3] loss: 1.247
[20,     3] loss: 1.214
[21,     3] loss: 1.162
[22,     3] loss: 1.077
[23,     3] loss: 1.137
[24,     3] loss: 1.097
[25,     3] loss: 1.024
[26,     3] loss: 0.980
[27,     3] loss: 1.074
[28,     3] loss: 1.069
[29,     3] loss: 0.984
[30,     3] loss: 0.999
[31,     3] loss: 1.002
[32,     3] loss: 0.930
[33,     3] loss: 0.953
[34,     3] loss: 0.924
[35,     3] loss: 0.928
[36,     3] loss: 0.970
[37,     3] loss: 0.912
[38,     3] loss: 0.831
[39,     3] loss: 0.948
[40,     3] loss: 0.937
[41,     3] loss: 0.861
[42,     3] loss: 0.898
[43,     3] loss: 0.963
[44,     3] loss: 0.839
[45,     3] loss: 0.834
[46,     3] loss: 0.995
[47,     3] loss: 0.835
[48,     3] loss: 0.810
[49,     3] loss: 0.861
[50,     3] loss: 0.830
[51,     3] loss: 0.806
[52,     3] loss: 0.806
[53,     3] loss: 0.854
[54,     3] loss: 0.851
[55,     3] loss: 0.904
[56,     3] loss: 0.914
[57,     3] loss: 0.834
[58,     3] loss: 0.860
[59,     3] loss: 0.900
[60,     3] loss: 0.944
[61,     3] loss: 0.844
[62,     3] loss: 0.825
[63,     3] loss: 0.832
[64,     3] loss: 0.795
[65,     3] loss: 0.821
[66,     3] loss: 0.830
[67,     3] loss: 0.770
[68,     3] loss: 0.827
[69,     3] loss: 0.785
[70,     3] loss: 0.764
[71,     3] loss: 0.785
[72,     3] loss: 0.777
[73,     3] loss: 0.768
[74,     3] loss: 0.773
[75,     3] loss: 0.748
[76,     3] loss: 0.730
Early stopping applied (best metric=0.5322409272193909)
Finished Training
Total time taken: 21.132076263427734
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.384
[3,     3] loss: 1.386
[4,     3] loss: 1.381
[5,     3] loss: 1.384
[6,     3] loss: 1.381
[7,     3] loss: 1.382
[8,     3] loss: 1.371
[9,     3] loss: 1.368
[10,     3] loss: 1.371
[11,     3] loss: 1.346
[12,     3] loss: 1.347
[13,     3] loss: 1.326
[14,     3] loss: 1.309
[15,     3] loss: 1.313
[16,     3] loss: 1.228
[17,     3] loss: 1.338
[18,     3] loss: 1.289
[19,     3] loss: 1.232
[20,     3] loss: 1.193
[21,     3] loss: 1.222
[22,     3] loss: 1.107
[23,     3] loss: 1.063
[24,     3] loss: 1.175
[25,     3] loss: 1.068
[26,     3] loss: 0.987
[27,     3] loss: 0.976
[28,     3] loss: 1.037
[29,     3] loss: 1.021
[30,     3] loss: 0.953
[31,     3] loss: 0.898
[32,     3] loss: 0.997
[33,     3] loss: 0.987
[34,     3] loss: 1.057
[35,     3] loss: 1.094
[36,     3] loss: 0.996
[37,     3] loss: 1.006
[38,     3] loss: 0.955
[39,     3] loss: 1.034
[40,     3] loss: 0.948
[41,     3] loss: 1.002
[42,     3] loss: 0.927
[43,     3] loss: 1.033
[44,     3] loss: 0.906
[45,     3] loss: 0.965
[46,     3] loss: 0.883
[47,     3] loss: 0.953
[48,     3] loss: 0.948
[49,     3] loss: 0.925
[50,     3] loss: 0.874
[51,     3] loss: 0.848
[52,     3] loss: 0.904
[53,     3] loss: 1.067
[54,     3] loss: 0.834
[55,     3] loss: 0.811
[56,     3] loss: 0.888
[57,     3] loss: 0.817
[58,     3] loss: 0.866
[59,     3] loss: 0.803
[60,     3] loss: 0.837
[61,     3] loss: 0.791
[62,     3] loss: 0.861
[63,     3] loss: 0.795
[64,     3] loss: 0.791
[65,     3] loss: 0.769
[66,     3] loss: 0.800
[67,     3] loss: 0.792
[68,     3] loss: 0.770
[69,     3] loss: 0.764
[70,     3] loss: 0.784
[71,     3] loss: 0.785
[72,     3] loss: 0.789
[73,     3] loss: 0.766
[74,     3] loss: 0.769
[75,     3] loss: 0.799
[76,     3] loss: 0.867
[77,     3] loss: 0.784
Early stopping applied (best metric=0.5022901892662048)
Finished Training
Total time taken: 21.40708303451538
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.385
[3,     3] loss: 1.383
[4,     3] loss: 1.385
[5,     3] loss: 1.382
[6,     3] loss: 1.385
[7,     3] loss: 1.379
[8,     3] loss: 1.379
[9,     3] loss: 1.372
[10,     3] loss: 1.383
[11,     3] loss: 1.385
[12,     3] loss: 1.358
[13,     3] loss: 1.360
[14,     3] loss: 1.327
[15,     3] loss: 1.360
[16,     3] loss: 1.275
[17,     3] loss: 1.331
[18,     3] loss: 1.284
[19,     3] loss: 1.222
[20,     3] loss: 1.233
[21,     3] loss: 1.273
[22,     3] loss: 1.228
[23,     3] loss: 1.176
[24,     3] loss: 1.122
[25,     3] loss: 1.093
[26,     3] loss: 1.208
[27,     3] loss: 1.156
[28,     3] loss: 1.128
[29,     3] loss: 0.976
[30,     3] loss: 1.033
[31,     3] loss: 1.009
[32,     3] loss: 1.040
[33,     3] loss: 1.014
[34,     3] loss: 1.061
[35,     3] loss: 1.050
[36,     3] loss: 0.958
[37,     3] loss: 0.953
[38,     3] loss: 0.963
[39,     3] loss: 0.996
[40,     3] loss: 1.041
[41,     3] loss: 0.910
[42,     3] loss: 0.948
[43,     3] loss: 0.991
[44,     3] loss: 0.896
[45,     3] loss: 0.892
[46,     3] loss: 0.906
[47,     3] loss: 0.882
[48,     3] loss: 0.954
[49,     3] loss: 0.862
[50,     3] loss: 0.926
[51,     3] loss: 0.893
[52,     3] loss: 0.881
[53,     3] loss: 0.976
[54,     3] loss: 0.890
[55,     3] loss: 0.864
[56,     3] loss: 0.837
[57,     3] loss: 0.910
[58,     3] loss: 0.918
[59,     3] loss: 0.805
[60,     3] loss: 0.852
[61,     3] loss: 0.917
[62,     3] loss: 0.891
[63,     3] loss: 0.947
[64,     3] loss: 0.865
[65,     3] loss: 0.837
[66,     3] loss: 0.957
[67,     3] loss: 0.890
[68,     3] loss: 0.987
[69,     3] loss: 0.865
[70,     3] loss: 0.832
[71,     3] loss: 0.869
[72,     3] loss: 0.881
[73,     3] loss: 0.856
[74,     3] loss: 0.792
[75,     3] loss: 0.873
[76,     3] loss: 0.831
[77,     3] loss: 0.806
Early stopping applied (best metric=0.5017666816711426)
Finished Training
Total time taken: 21.418079376220703
{'S-palmitoylation-C Validation Accuracy': 0.7031759894641991, 'S-palmitoylation-C Validation Sensitivity': 0.21544554455445544, 'S-palmitoylation-C Validation Specificity': 0.8254312944212678, 'S-palmitoylation-C Validation Precision': 0.239131180729551, 'S-palmitoylation-C AUC ROC': 0.5436767794915319, 'S-palmitoylation-C AUC PR': 0.2277226379713218, 'S-palmitoylation-C MCC': 0.04336303650035195, 'S-palmitoylation-C F1': 0.21542240282555714, 'Validation Loss (S-palmitoylation-C)': 0.5540374954541524, 'Hydroxylation-K Validation Accuracy': 0.7436170212765958, 'Hydroxylation-K Validation Sensitivity': 0.797037037037037, 'Hydroxylation-K Validation Specificity': 0.7315789473684211, 'Hydroxylation-K Validation Precision': 0.43665411235339896, 'Hydroxylation-K AUC ROC': 0.8306042884990253, 'Hydroxylation-K AUC PR': 0.5720090382711934, 'Hydroxylation-K MCC': 0.4432447448356275, 'Hydroxylation-K F1': 0.5565384734465194, 'Validation Loss (Hydroxylation-K)': 0.5149668236573537, 'Validation Loss (total)': 1.0690043210983275, 'TimeToTrain': 22.513883686065675}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001301984590792745,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.09146078815897934,
 'loss_weight_S-palmitoylation-C': 0.46220378253291483,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2676518245,
 'sample_weights': [0.129746195271892, 0.24143617224856675],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.179686809078171,
 'weight_decay_Hydroxylation-K': 0.23136017869830106,
 'weight_decay_S-palmitoylation-C': 2.8806764687409507}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.399
[2,     3] loss: 1.389
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001570314015872203,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6865371051602273,
 'loss_weight_S-palmitoylation-C': 0.7436571581063138,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2046451683,
 'sample_weights': [0.46220378253291483, 0.09146078815897934],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.134605536920643,
 'weight_decay_Hydroxylation-K': 0.8710463260056075,
 'weight_decay_S-palmitoylation-C': 1.5926468104353295}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.389
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003621329027864057,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9863717051572284,
 'loss_weight_S-palmitoylation-C': 0.1463289673609911,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4207659388,
 'sample_weights': [0.7436571581063138, 0.6865371051602273],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.5508451402093293,
 'weight_decay_Hydroxylation-K': 1.15213393558682,
 'weight_decay_S-palmitoylation-C': 3.9647210654968865}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.414
[3,     3] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013888291904918986,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.692171516232001,
 'loss_weight_S-palmitoylation-C': 0.1489962333703198,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3131139342,
 'sample_weights': [0.1463289673609911, 0.9863717051572284],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.914348762645101,
 'weight_decay_Hydroxylation-K': 0.08380324269479156,
 'weight_decay_S-palmitoylation-C': 5.839790901646616}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.387
[3,     3] loss: 1.391
[4,     3] loss: 1.380
[5,     3] loss: 1.381
[6,     3] loss: 1.384
[7,     3] loss: 1.368
[8,     3] loss: 1.371
[9,     3] loss: 1.350
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004838840838993071,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.40870819083240084,
 'loss_weight_S-palmitoylation-C': 0.5880393586607093,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2073805518,
 'sample_weights': [0.1489962333703198, 0.692171516232001],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.741476334338453,
 'weight_decay_Hydroxylation-K': 0.10986513273286805,
 'weight_decay_S-palmitoylation-C': 1.1843673250184112}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.414
[3,     3] loss: 1.392
[4,     3] loss: 1.401
[5,     3] loss: 1.396
[6,     3] loss: 1.382
[7,     3] loss: 1.386
[8,     3] loss: 1.391
[9,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004421650397624549,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7371947417482083,
 'loss_weight_S-palmitoylation-C': 0.5363225415469732,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4004262029,
 'sample_weights': [0.5880393586607093, 0.40870819083240084],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8092814018805132,
 'weight_decay_Hydroxylation-K': 2.3881023950415754,
 'weight_decay_S-palmitoylation-C': 3.5986244330291814}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.386
[3,     3] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004045259106740221,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6760220997635981,
 'loss_weight_S-palmitoylation-C': 0.46044643611545694,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 845622214,
 'sample_weights': [0.5363225415469732, 0.7371947417482083],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.1440343916654445,
 'weight_decay_Hydroxylation-K': 0.3639809173253995,
 'weight_decay_S-palmitoylation-C': 1.3769320987883658}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.392
[3,     3] loss: 1.402
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0021870405181560735,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9458298837889517,
 'loss_weight_S-palmitoylation-C': 0.335089717765523,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2878568560,
 'sample_weights': [0.46044643611545694, 0.6760220997635981],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3904815865466738,
 'weight_decay_Hydroxylation-K': 2.4134995544297206,
 'weight_decay_S-palmitoylation-C': 2.7975111162176467}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.370
[3,     3] loss: 1.394
[4,     3] loss: 1.390
[5,     3] loss: 1.386
[6,     3] loss: 1.377
[7,     3] loss: 1.374
[8,     3] loss: 1.380
[9,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015405637146624507,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24751295691386482,
 'loss_weight_S-palmitoylation-C': 0.21906211819848986,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3137450080,
 'sample_weights': [0.335089717765523, 0.9458298837889517],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6944744057746495,
 'weight_decay_Hydroxylation-K': 2.9831754167544937,
 'weight_decay_S-palmitoylation-C': 3.15328614390389}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.390
[3,     3] loss: 1.380
[4,     3] loss: 1.383
[5,     3] loss: 1.393
[6,     3] loss: 1.396
[7,     3] loss: 1.387
[8,     3] loss: 1.389
[9,     3] loss: 1.385
[10,     3] loss: 1.389
[11,     3] loss: 1.390
[12,     3] loss: 1.390
[13,     3] loss: 1.391
[14,     3] loss: 1.385
[15,     3] loss: 1.388
[16,     3] loss: 1.386
[17,     3] loss: 1.384
[18,     3] loss: 1.384
[19,     3] loss: 1.386
[20,     3] loss: 1.375
[21,     3] loss: 1.370
[22,     3] loss: 1.363
[23,     3] loss: 1.357
[24,     3] loss: 1.333
[25,     3] loss: 1.322
[26,     3] loss: 1.352
[27,     3] loss: 1.253
[28,     3] loss: 1.353
[29,     3] loss: 1.281
[30,     3] loss: 1.195
[31,     3] loss: 1.184
[32,     3] loss: 1.128
[33,     3] loss: 1.113
[34,     3] loss: 1.076
[35,     3] loss: 1.017
[36,     3] loss: 1.171
[37,     3] loss: 1.225
[38,     3] loss: 1.041
[39,     3] loss: 0.995
[40,     3] loss: 1.056
[41,     3] loss: 1.041
[42,     3] loss: 0.929
[43,     3] loss: 0.938
[44,     3] loss: 0.920
[45,     3] loss: 0.840
[46,     3] loss: 0.907
[47,     3] loss: 0.859
[48,     3] loss: 0.955
[49,     3] loss: 0.871
[50,     3] loss: 0.844
[51,     3] loss: 0.866
[52,     3] loss: 0.835
[53,     3] loss: 0.894
[54,     3] loss: 0.845
[55,     3] loss: 0.845
[56,     3] loss: 0.876
[57,     3] loss: 0.929
[58,     3] loss: 0.886
[59,     3] loss: 0.934
[60,     3] loss: 0.860
[61,     3] loss: 0.899
[62,     3] loss: 0.857
[63,     3] loss: 0.831
[64,     3] loss: 0.810
[65,     3] loss: 0.801
[66,     3] loss: 0.808
[67,     3] loss: 0.800
[68,     3] loss: 0.762
[69,     3] loss: 0.799
[70,     3] loss: 0.777
[71,     3] loss: 0.796
[72,     3] loss: 0.773
[73,     3] loss: 0.781
[74,     3] loss: 0.794
[75,     3] loss: 0.743
[76,     3] loss: 0.753
[77,     3] loss: 0.795
[78,     3] loss: 0.875
[79,     3] loss: 0.847
[80,     3] loss: 0.826
[81,     3] loss: 0.783
[82,     3] loss: 0.777
Early stopping applied (best metric=0.5071697235107422)
Finished Training
Total time taken: 23.00408697128296
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.386
[3,     3] loss: 1.398
[4,     3] loss: 1.391
[5,     3] loss: 1.381
[6,     3] loss: 1.377
[7,     3] loss: 1.384
[8,     3] loss: 1.359
[9,     3] loss: 1.372
[10,     3] loss: 1.319
[11,     3] loss: 1.346
[12,     3] loss: 1.350
[13,     3] loss: 1.285
[14,     3] loss: 1.294
[15,     3] loss: 1.253
[16,     3] loss: 1.203
[17,     3] loss: 1.124
[18,     3] loss: 1.082
[19,     3] loss: 1.048
[20,     3] loss: 0.981
[21,     3] loss: 0.991
[22,     3] loss: 1.066
[23,     3] loss: 0.902
[24,     3] loss: 0.981
[25,     3] loss: 0.906
[26,     3] loss: 0.963
[27,     3] loss: 1.031
[28,     3] loss: 1.060
[29,     3] loss: 0.934
[30,     3] loss: 0.930
[31,     3] loss: 0.873
[32,     3] loss: 0.852
[33,     3] loss: 0.917
[34,     3] loss: 0.874
[35,     3] loss: 0.806
[36,     3] loss: 0.825
[37,     3] loss: 0.885
[38,     3] loss: 0.776
[39,     3] loss: 0.833
[40,     3] loss: 0.794
[41,     3] loss: 0.807
[42,     3] loss: 0.872
[43,     3] loss: 1.014
[44,     3] loss: 0.878
[45,     3] loss: 0.910
[46,     3] loss: 0.975
[47,     3] loss: 0.839
[48,     3] loss: 0.852
[49,     3] loss: 0.848
[50,     3] loss: 0.802
[51,     3] loss: 0.793
[52,     3] loss: 0.843
[53,     3] loss: 0.743
[54,     3] loss: 0.748
[55,     3] loss: 0.771
[56,     3] loss: 0.836
[57,     3] loss: 0.862
[58,     3] loss: 0.760
[59,     3] loss: 0.796
[60,     3] loss: 0.764
[61,     3] loss: 0.839
[62,     3] loss: 0.756
[63,     3] loss: 0.787
[64,     3] loss: 0.863
[65,     3] loss: 0.780
[66,     3] loss: 0.761
[67,     3] loss: 0.775
[68,     3] loss: 0.797
[69,     3] loss: 0.935
[70,     3] loss: 0.839
[71,     3] loss: 0.909
Early stopping applied (best metric=0.5370480418205261)
Finished Training
Total time taken: 19.908074378967285
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.385
[3,     3] loss: 1.393
[4,     3] loss: 1.377
[5,     3] loss: 1.383
[6,     3] loss: 1.374
[7,     3] loss: 1.386
[8,     3] loss: 1.376
[9,     3] loss: 1.374
[10,     3] loss: 1.361
[11,     3] loss: 1.355
[12,     3] loss: 1.315
[13,     3] loss: 1.304
[14,     3] loss: 1.273
[15,     3] loss: 1.229
[16,     3] loss: 1.204
[17,     3] loss: 1.170
[18,     3] loss: 1.147
[19,     3] loss: 1.113
[20,     3] loss: 1.416
[21,     3] loss: 1.177
[22,     3] loss: 1.136
[23,     3] loss: 1.084
[24,     3] loss: 1.059
[25,     3] loss: 1.066
[26,     3] loss: 0.952
[27,     3] loss: 1.072
[28,     3] loss: 0.938
[29,     3] loss: 0.951
[30,     3] loss: 0.920
[31,     3] loss: 1.011
[32,     3] loss: 0.990
[33,     3] loss: 0.984
[34,     3] loss: 1.029
[35,     3] loss: 0.955
[36,     3] loss: 0.990
[37,     3] loss: 1.002
[38,     3] loss: 0.936
[39,     3] loss: 0.859
[40,     3] loss: 0.946
[41,     3] loss: 0.915
[42,     3] loss: 0.941
[43,     3] loss: 0.867
[44,     3] loss: 0.876
[45,     3] loss: 0.829
[46,     3] loss: 0.827
[47,     3] loss: 0.789
[48,     3] loss: 0.852
[49,     3] loss: 0.891
[50,     3] loss: 0.817
[51,     3] loss: 0.821
[52,     3] loss: 0.816
[53,     3] loss: 0.866
[54,     3] loss: 0.917
[55,     3] loss: 0.934
[56,     3] loss: 0.886
[57,     3] loss: 0.835
[58,     3] loss: 0.851
[59,     3] loss: 0.879
[60,     3] loss: 0.907
[61,     3] loss: 0.769
[62,     3] loss: 0.793
[63,     3] loss: 0.782
[64,     3] loss: 0.770
[65,     3] loss: 0.742
[66,     3] loss: 0.760
[67,     3] loss: 0.740
[68,     3] loss: 0.753
[69,     3] loss: 0.749
[70,     3] loss: 0.740
[71,     3] loss: 0.735
[72,     3] loss: 0.729
[73,     3] loss: 0.721
[74,     3] loss: 0.732
[75,     3] loss: 0.730
[76,     3] loss: 0.755
[77,     3] loss: 0.751
[78,     3] loss: 0.743
[79,     3] loss: 0.737
[80,     3] loss: 0.730
[81,     3] loss: 0.743
[82,     3] loss: 0.738
[83,     3] loss: 0.722
[84,     3] loss: 0.765
[85,     3] loss: 0.858
[86,     3] loss: 0.856
[87,     3] loss: 0.896
[88,     3] loss: 0.898
[89,     3] loss: 0.831
[90,     3] loss: 0.946
[91,     3] loss: 0.916
[92,     3] loss: 0.840
[93,     3] loss: 0.815
[94,     3] loss: 0.827
[95,     3] loss: 0.797
[96,     3] loss: 0.782
[97,     3] loss: 0.815
[98,     3] loss: 0.765
[99,     3] loss: 0.739
[100,     3] loss: 0.771
[101,     3] loss: 0.843
[102,     3] loss: 0.754
[103,     3] loss: 0.742
[104,     3] loss: 0.737
[105,     3] loss: 0.752
[106,     3] loss: 0.773
[107,     3] loss: 0.825
[108,     3] loss: 0.738
[109,     3] loss: 0.801
[110,     3] loss: 0.862
[111,     3] loss: 0.765
[112,     3] loss: 0.871
[113,     3] loss: 0.751
[114,     3] loss: 0.815
[115,     3] loss: 0.775
[116,     3] loss: 0.754
[117,     3] loss: 0.787
[118,     3] loss: 0.768
[119,     3] loss: 0.781
[120,     3] loss: 0.854
[121,     3] loss: 0.894
[122,     3] loss: 0.761
[123,     3] loss: 0.787
[124,     3] loss: 0.752
[125,     3] loss: 0.764
[126,     3] loss: 0.737
[127,     3] loss: 0.767
Early stopping applied (best metric=0.5279549360275269)
Finished Training
Total time taken: 35.2571325302124
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.389
[3,     3] loss: 1.378
[4,     3] loss: 1.384
[5,     3] loss: 1.380
[6,     3] loss: 1.385
[7,     3] loss: 1.387
[8,     3] loss: 1.393
[9,     3] loss: 1.385
[10,     3] loss: 1.368
[11,     3] loss: 1.365
[12,     3] loss: 1.344
[13,     3] loss: 1.314
[14,     3] loss: 1.315
[15,     3] loss: 1.313
[16,     3] loss: 1.291
[17,     3] loss: 1.219
[18,     3] loss: 1.246
[19,     3] loss: 1.264
[20,     3] loss: 1.202
[21,     3] loss: 1.128
[22,     3] loss: 1.166
[23,     3] loss: 1.087
[24,     3] loss: 1.104
[25,     3] loss: 1.171
[26,     3] loss: 1.035
[27,     3] loss: 1.086
[28,     3] loss: 1.049
[29,     3] loss: 0.956
[30,     3] loss: 1.081
[31,     3] loss: 0.941
[32,     3] loss: 0.976
[33,     3] loss: 0.993
[34,     3] loss: 0.914
[35,     3] loss: 0.981
[36,     3] loss: 0.951
[37,     3] loss: 0.904
[38,     3] loss: 0.898
[39,     3] loss: 0.814
[40,     3] loss: 0.886
[41,     3] loss: 0.864
[42,     3] loss: 0.867
[43,     3] loss: 0.859
[44,     3] loss: 0.826
[45,     3] loss: 0.864
[46,     3] loss: 0.818
[47,     3] loss: 0.834
[48,     3] loss: 1.034
[49,     3] loss: 0.852
[50,     3] loss: 0.845
[51,     3] loss: 0.838
[52,     3] loss: 0.800
[53,     3] loss: 0.846
[54,     3] loss: 1.050
[55,     3] loss: 0.895
[56,     3] loss: 0.815
[57,     3] loss: 0.866
[58,     3] loss: 0.837
[59,     3] loss: 0.805
[60,     3] loss: 0.791
[61,     3] loss: 0.793
[62,     3] loss: 0.840
[63,     3] loss: 0.782
[64,     3] loss: 0.813
[65,     3] loss: 0.782
[66,     3] loss: 0.774
[67,     3] loss: 0.827
[68,     3] loss: 0.789
[69,     3] loss: 0.756
[70,     3] loss: 0.761
[71,     3] loss: 0.746
[72,     3] loss: 0.742
[73,     3] loss: 0.731
[74,     3] loss: 0.736
[75,     3] loss: 0.721
[76,     3] loss: 0.735
[77,     3] loss: 0.752
[78,     3] loss: 0.726
[79,     3] loss: 0.731
Early stopping applied (best metric=0.5053541660308838)
Finished Training
Total time taken: 22.111084461212158
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.389
[3,     3] loss: 1.405
[4,     3] loss: 1.390
[5,     3] loss: 1.387
[6,     3] loss: 1.375
[7,     3] loss: 1.394
[8,     3] loss: 1.392
[9,     3] loss: 1.382
[10,     3] loss: 1.382
[11,     3] loss: 1.387
[12,     3] loss: 1.391
[13,     3] loss: 1.389
[14,     3] loss: 1.386
[15,     3] loss: 1.383
[16,     3] loss: 1.392
[17,     3] loss: 1.385
[18,     3] loss: 1.384
[19,     3] loss: 1.387
[20,     3] loss: 1.382
[21,     3] loss: 1.384
[22,     3] loss: 1.367
[23,     3] loss: 1.356
[24,     3] loss: 1.345
[25,     3] loss: 1.330
[26,     3] loss: 1.280
[27,     3] loss: 1.306
[28,     3] loss: 1.327
[29,     3] loss: 1.295
[30,     3] loss: 1.299
[31,     3] loss: 1.219
[32,     3] loss: 1.268
[33,     3] loss: 1.105
[34,     3] loss: 1.205
[35,     3] loss: 1.096
[36,     3] loss: 0.976
[37,     3] loss: 1.047
[38,     3] loss: 1.107
[39,     3] loss: 0.939
[40,     3] loss: 0.990
[41,     3] loss: 1.026
[42,     3] loss: 1.088
[43,     3] loss: 0.969
[44,     3] loss: 1.004
[45,     3] loss: 1.019
[46,     3] loss: 0.911
[47,     3] loss: 0.954
[48,     3] loss: 0.934
[49,     3] loss: 1.116
[50,     3] loss: 0.988
[51,     3] loss: 0.949
[52,     3] loss: 0.932
[53,     3] loss: 0.918
[54,     3] loss: 0.858
[55,     3] loss: 0.843
[56,     3] loss: 1.020
[57,     3] loss: 0.814
[58,     3] loss: 0.872
[59,     3] loss: 0.920
[60,     3] loss: 0.807
[61,     3] loss: 0.848
[62,     3] loss: 0.831
[63,     3] loss: 0.798
[64,     3] loss: 0.774
[65,     3] loss: 0.761
[66,     3] loss: 0.814
[67,     3] loss: 0.755
[68,     3] loss: 0.790
[69,     3] loss: 0.845
[70,     3] loss: 0.741
[71,     3] loss: 0.815
[72,     3] loss: 0.904
[73,     3] loss: 0.985
[74,     3] loss: 1.046
[75,     3] loss: 0.777
[76,     3] loss: 0.944
[77,     3] loss: 0.858
[78,     3] loss: 0.814
[79,     3] loss: 0.804
[80,     3] loss: 0.781
[81,     3] loss: 0.767
[82,     3] loss: 0.832
[83,     3] loss: 0.758
[84,     3] loss: 0.763
[85,     3] loss: 0.782
[86,     3] loss: 0.746
[87,     3] loss: 0.725
Early stopping applied (best metric=0.48717331886291504)
Finished Training
Total time taken: 24.371090412139893
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.408
[2,     3] loss: 1.379
[3,     3] loss: 1.388
[4,     3] loss: 1.383
[5,     3] loss: 1.389
[6,     3] loss: 1.388
[7,     3] loss: 1.397
[8,     3] loss: 1.389
[9,     3] loss: 1.393
[10,     3] loss: 1.384
[11,     3] loss: 1.384
[12,     3] loss: 1.382
[13,     3] loss: 1.386
[14,     3] loss: 1.387
[15,     3] loss: 1.375
[16,     3] loss: 1.365
[17,     3] loss: 1.359
[18,     3] loss: 1.364
[19,     3] loss: 1.352
[20,     3] loss: 1.324
[21,     3] loss: 1.286
[22,     3] loss: 1.234
[23,     3] loss: 1.212
[24,     3] loss: 1.186
[25,     3] loss: 1.151
[26,     3] loss: 1.082
[27,     3] loss: 1.112
[28,     3] loss: 1.168
[29,     3] loss: 1.128
[30,     3] loss: 1.081
[31,     3] loss: 1.055
[32,     3] loss: 0.977
[33,     3] loss: 1.042
[34,     3] loss: 1.126
[35,     3] loss: 1.003
[36,     3] loss: 0.955
[37,     3] loss: 0.918
[38,     3] loss: 0.967
[39,     3] loss: 0.909
[40,     3] loss: 1.007
[41,     3] loss: 1.018
[42,     3] loss: 1.006
[43,     3] loss: 0.898
[44,     3] loss: 0.962
[45,     3] loss: 0.953
[46,     3] loss: 0.963
[47,     3] loss: 0.884
[48,     3] loss: 0.993
[49,     3] loss: 0.987
[50,     3] loss: 0.943
[51,     3] loss: 0.960
[52,     3] loss: 0.945
[53,     3] loss: 0.976
[54,     3] loss: 0.953
[55,     3] loss: 0.886
[56,     3] loss: 0.887
[57,     3] loss: 0.843
[58,     3] loss: 0.842
[59,     3] loss: 0.838
[60,     3] loss: 0.778
[61,     3] loss: 0.774
[62,     3] loss: 0.775
[63,     3] loss: 0.806
[64,     3] loss: 0.829
[65,     3] loss: 0.792
[66,     3] loss: 0.846
[67,     3] loss: 0.784
[68,     3] loss: 0.743
[69,     3] loss: 0.741
[70,     3] loss: 0.742
[71,     3] loss: 0.763
[72,     3] loss: 0.785
[73,     3] loss: 0.796
[74,     3] loss: 0.806
[75,     3] loss: 0.771
[76,     3] loss: 0.734
[77,     3] loss: 0.808
[78,     3] loss: 0.790
[79,     3] loss: 0.761
[80,     3] loss: 0.751
[81,     3] loss: 0.774
[82,     3] loss: 0.786
[83,     3] loss: 0.774
[84,     3] loss: 0.828
[85,     3] loss: 0.836
[86,     3] loss: 0.802
[87,     3] loss: 0.767
[88,     3] loss: 0.769
[89,     3] loss: 0.780
[90,     3] loss: 0.746
[91,     3] loss: 0.751
[92,     3] loss: 0.733
Early stopping applied (best metric=0.5123836398124695)
Finished Training
Total time taken: 25.839093923568726
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.376
[3,     3] loss: 1.397
[4,     3] loss: 1.381
[5,     3] loss: 1.383
[6,     3] loss: 1.367
[7,     3] loss: 1.356
[8,     3] loss: 1.370
[9,     3] loss: 1.337
[10,     3] loss: 1.321
[11,     3] loss: 1.264
[12,     3] loss: 1.333
[13,     3] loss: 1.288
[14,     3] loss: 1.216
[15,     3] loss: 1.200
[16,     3] loss: 1.171
[17,     3] loss: 1.182
[18,     3] loss: 1.097
[19,     3] loss: 1.053
[20,     3] loss: 1.141
[21,     3] loss: 1.044
[22,     3] loss: 1.024
[23,     3] loss: 1.119
[24,     3] loss: 0.992
[25,     3] loss: 1.089
[26,     3] loss: 1.049
[27,     3] loss: 0.932
[28,     3] loss: 0.931
[29,     3] loss: 0.968
[30,     3] loss: 0.905
[31,     3] loss: 0.953
[32,     3] loss: 0.909
[33,     3] loss: 0.861
[34,     3] loss: 0.982
[35,     3] loss: 0.936
[36,     3] loss: 1.005
[37,     3] loss: 0.936
[38,     3] loss: 0.875
[39,     3] loss: 0.859
[40,     3] loss: 0.860
[41,     3] loss: 0.937
[42,     3] loss: 0.875
[43,     3] loss: 0.844
[44,     3] loss: 0.844
[45,     3] loss: 1.009
[46,     3] loss: 0.899
[47,     3] loss: 1.032
[48,     3] loss: 0.937
[49,     3] loss: 1.122
[50,     3] loss: 0.899
[51,     3] loss: 1.038
[52,     3] loss: 0.984
[53,     3] loss: 0.908
[54,     3] loss: 0.961
[55,     3] loss: 0.910
[56,     3] loss: 0.900
[57,     3] loss: 0.849
[58,     3] loss: 0.840
[59,     3] loss: 0.814
[60,     3] loss: 0.786
[61,     3] loss: 0.865
[62,     3] loss: 0.839
[63,     3] loss: 0.821
[64,     3] loss: 0.770
[65,     3] loss: 0.811
[66,     3] loss: 0.918
[67,     3] loss: 0.845
[68,     3] loss: 0.803
[69,     3] loss: 0.845
[70,     3] loss: 0.860
Early stopping applied (best metric=0.5251063704490662)
Finished Training
Total time taken: 19.465073347091675
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.389
[3,     3] loss: 1.379
[4,     3] loss: 1.389
[5,     3] loss: 1.390
[6,     3] loss: 1.392
[7,     3] loss: 1.386
[8,     3] loss: 1.385
[9,     3] loss: 1.388
[10,     3] loss: 1.386
[11,     3] loss: 1.380
[12,     3] loss: 1.374
[13,     3] loss: 1.366
[14,     3] loss: 1.375
[15,     3] loss: 1.365
[16,     3] loss: 1.346
[17,     3] loss: 1.337
[18,     3] loss: 1.318
[19,     3] loss: 1.292
[20,     3] loss: 1.253
[21,     3] loss: 1.249
[22,     3] loss: 1.246
[23,     3] loss: 1.140
[24,     3] loss: 1.150
[25,     3] loss: 1.177
[26,     3] loss: 1.120
[27,     3] loss: 1.160
[28,     3] loss: 1.132
[29,     3] loss: 1.185
[30,     3] loss: 1.137
[31,     3] loss: 1.106
[32,     3] loss: 1.163
[33,     3] loss: 1.052
[34,     3] loss: 1.057
[35,     3] loss: 1.019
[36,     3] loss: 0.982
[37,     3] loss: 0.938
[38,     3] loss: 0.979
[39,     3] loss: 0.966
[40,     3] loss: 0.951
[41,     3] loss: 0.944
[42,     3] loss: 0.961
[43,     3] loss: 1.051
[44,     3] loss: 0.819
[45,     3] loss: 0.995
[46,     3] loss: 1.070
[47,     3] loss: 0.914
[48,     3] loss: 1.043
[49,     3] loss: 0.947
[50,     3] loss: 0.860
[51,     3] loss: 0.896
[52,     3] loss: 0.902
[53,     3] loss: 0.958
[54,     3] loss: 0.848
[55,     3] loss: 0.790
[56,     3] loss: 0.823
[57,     3] loss: 0.796
[58,     3] loss: 0.812
[59,     3] loss: 0.784
[60,     3] loss: 0.780
[61,     3] loss: 0.771
[62,     3] loss: 0.780
[63,     3] loss: 0.784
[64,     3] loss: 0.871
[65,     3] loss: 0.858
[66,     3] loss: 0.766
[67,     3] loss: 0.778
[68,     3] loss: 0.777
[69,     3] loss: 0.778
[70,     3] loss: 0.872
[71,     3] loss: 0.791
[72,     3] loss: 0.844
[73,     3] loss: 0.892
[74,     3] loss: 0.833
[75,     3] loss: 0.824
[76,     3] loss: 0.794
[77,     3] loss: 0.781
[78,     3] loss: 0.824
[79,     3] loss: 0.844
[80,     3] loss: 0.847
[81,     3] loss: 0.855
[82,     3] loss: 0.851
[83,     3] loss: 0.765
[84,     3] loss: 0.763
[85,     3] loss: 0.770
[86,     3] loss: 0.757
[87,     3] loss: 0.752
[88,     3] loss: 0.749
[89,     3] loss: 0.751
[90,     3] loss: 0.738
[91,     3] loss: 0.721
[92,     3] loss: 0.717
[93,     3] loss: 0.725
[94,     3] loss: 0.721
[95,     3] loss: 0.733
[96,     3] loss: 0.726
[97,     3] loss: 0.784
[98,     3] loss: 0.773
[99,     3] loss: 0.737
[100,     3] loss: 0.793
[101,     3] loss: 0.803
[102,     3] loss: 0.819
[103,     3] loss: 0.754
[104,     3] loss: 0.733
[105,     3] loss: 0.788
Early stopping applied (best metric=0.5069947838783264)
Finished Training
Total time taken: 29.301109075546265
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.383
[3,     3] loss: 1.382
[4,     3] loss: 1.381
[5,     3] loss: 1.391
[6,     3] loss: 1.381
[7,     3] loss: 1.387
[8,     3] loss: 1.367
[9,     3] loss: 1.360
[10,     3] loss: 1.354
[11,     3] loss: 1.332
[12,     3] loss: 1.301
[13,     3] loss: 1.271
[14,     3] loss: 1.313
[15,     3] loss: 1.232
[16,     3] loss: 1.113
[17,     3] loss: 1.161
[18,     3] loss: 1.073
[19,     3] loss: 1.078
[20,     3] loss: 1.110
[21,     3] loss: 1.120
[22,     3] loss: 1.081
[23,     3] loss: 1.128
[24,     3] loss: 0.983
[25,     3] loss: 0.971
[26,     3] loss: 1.038
[27,     3] loss: 0.975
[28,     3] loss: 0.938
[29,     3] loss: 1.074
[30,     3] loss: 0.983
[31,     3] loss: 0.908
[32,     3] loss: 0.967
[33,     3] loss: 0.942
[34,     3] loss: 0.930
[35,     3] loss: 0.958
[36,     3] loss: 0.872
[37,     3] loss: 0.942
[38,     3] loss: 0.910
[39,     3] loss: 0.807
[40,     3] loss: 0.900
[41,     3] loss: 0.846
[42,     3] loss: 1.018
[43,     3] loss: 0.880
[44,     3] loss: 0.854
[45,     3] loss: 0.852
[46,     3] loss: 0.896
[47,     3] loss: 0.827
[48,     3] loss: 0.880
[49,     3] loss: 0.900
[50,     3] loss: 0.847
[51,     3] loss: 0.981
[52,     3] loss: 0.956
[53,     3] loss: 0.891
[54,     3] loss: 0.848
[55,     3] loss: 0.811
[56,     3] loss: 0.792
[57,     3] loss: 0.839
[58,     3] loss: 0.791
[59,     3] loss: 0.857
[60,     3] loss: 0.901
[61,     3] loss: 0.830
[62,     3] loss: 0.833
[63,     3] loss: 0.787
[64,     3] loss: 0.775
[65,     3] loss: 0.761
[66,     3] loss: 0.747
[67,     3] loss: 0.740
[68,     3] loss: 0.738
[69,     3] loss: 0.775
[70,     3] loss: 0.796
[71,     3] loss: 0.797
[72,     3] loss: 0.793
[73,     3] loss: 0.762
[74,     3] loss: 0.763
[75,     3] loss: 0.805
[76,     3] loss: 0.881
[77,     3] loss: 0.783
[78,     3] loss: 0.782
[79,     3] loss: 0.758
[80,     3] loss: 0.757
[81,     3] loss: 0.746
[82,     3] loss: 0.770
[83,     3] loss: 0.760
[84,     3] loss: 0.763
[85,     3] loss: 0.776
[86,     3] loss: 0.741
[87,     3] loss: 0.743
Early stopping applied (best metric=0.5089555978775024)
Finished Training
Total time taken: 24.12009048461914
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.387
[3,     3] loss: 1.377
[4,     3] loss: 1.389
[5,     3] loss: 1.390
[6,     3] loss: 1.388
[7,     3] loss: 1.377
[8,     3] loss: 1.371
[9,     3] loss: 1.372
[10,     3] loss: 1.386
[11,     3] loss: 1.364
[12,     3] loss: 1.362
[13,     3] loss: 1.365
[14,     3] loss: 1.356
[15,     3] loss: 1.324
[16,     3] loss: 1.306
[17,     3] loss: 1.321
[18,     3] loss: 1.349
[19,     3] loss: 1.263
[20,     3] loss: 1.250
[21,     3] loss: 1.224
[22,     3] loss: 1.215
[23,     3] loss: 1.178
[24,     3] loss: 1.126
[25,     3] loss: 1.081
[26,     3] loss: 1.152
[27,     3] loss: 1.057
[28,     3] loss: 1.137
[29,     3] loss: 1.081
[30,     3] loss: 1.186
[31,     3] loss: 1.018
[32,     3] loss: 0.993
[33,     3] loss: 1.049
[34,     3] loss: 0.975
[35,     3] loss: 1.013
[36,     3] loss: 0.913
[37,     3] loss: 0.962
[38,     3] loss: 1.022
[39,     3] loss: 0.988
[40,     3] loss: 0.925
[41,     3] loss: 0.947
[42,     3] loss: 0.925
[43,     3] loss: 0.927
[44,     3] loss: 0.953
[45,     3] loss: 0.829
[46,     3] loss: 0.909
[47,     3] loss: 0.849
[48,     3] loss: 0.854
[49,     3] loss: 0.862
[50,     3] loss: 0.808
[51,     3] loss: 0.782
[52,     3] loss: 0.973
[53,     3] loss: 0.810
[54,     3] loss: 0.837
[55,     3] loss: 0.803
[56,     3] loss: 0.787
[57,     3] loss: 0.826
[58,     3] loss: 0.830
[59,     3] loss: 0.815
[60,     3] loss: 0.861
[61,     3] loss: 0.879
[62,     3] loss: 0.915
[63,     3] loss: 0.833
[64,     3] loss: 0.931
[65,     3] loss: 0.824
[66,     3] loss: 0.896
[67,     3] loss: 0.793
[68,     3] loss: 0.894
[69,     3] loss: 0.821
[70,     3] loss: 0.827
[71,     3] loss: 0.871
[72,     3] loss: 0.852
[73,     3] loss: 0.936
[74,     3] loss: 0.874
[75,     3] loss: 0.903
[76,     3] loss: 0.873
[77,     3] loss: 0.805
[78,     3] loss: 0.813
[79,     3] loss: 0.806
[80,     3] loss: 0.767
[81,     3] loss: 0.780
Early stopping applied (best metric=0.4881596565246582)
Finished Training
Total time taken: 22.79708218574524
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.376
[3,     3] loss: 1.389
[4,     3] loss: 1.393
[5,     3] loss: 1.375
[6,     3] loss: 1.381
[7,     3] loss: 1.366
[8,     3] loss: 1.386
[9,     3] loss: 1.367
[10,     3] loss: 1.355
[11,     3] loss: 1.315
[12,     3] loss: 1.322
[13,     3] loss: 1.295
[14,     3] loss: 1.228
[15,     3] loss: 1.194
[16,     3] loss: 1.120
[17,     3] loss: 1.157
[18,     3] loss: 1.052
[19,     3] loss: 1.156
[20,     3] loss: 1.065
[21,     3] loss: 1.049
[22,     3] loss: 1.005
[23,     3] loss: 0.981
[24,     3] loss: 1.014
[25,     3] loss: 0.897
[26,     3] loss: 0.981
[27,     3] loss: 0.938
[28,     3] loss: 0.998
[29,     3] loss: 0.918
[30,     3] loss: 1.032
[31,     3] loss: 1.098
[32,     3] loss: 1.064
[33,     3] loss: 0.961
[34,     3] loss: 1.018
[35,     3] loss: 0.996
[36,     3] loss: 0.994
[37,     3] loss: 1.036
[38,     3] loss: 0.883
[39,     3] loss: 0.839
[40,     3] loss: 0.884
[41,     3] loss: 0.879
[42,     3] loss: 0.896
[43,     3] loss: 0.801
[44,     3] loss: 0.794
[45,     3] loss: 0.811
[46,     3] loss: 0.792
[47,     3] loss: 0.804
[48,     3] loss: 0.787
[49,     3] loss: 0.863
[50,     3] loss: 0.776
[51,     3] loss: 0.816
[52,     3] loss: 0.843
[53,     3] loss: 0.745
[54,     3] loss: 0.925
[55,     3] loss: 0.860
[56,     3] loss: 0.955
[57,     3] loss: 0.848
[58,     3] loss: 0.852
[59,     3] loss: 0.799
[60,     3] loss: 0.821
[61,     3] loss: 0.805
[62,     3] loss: 0.808
[63,     3] loss: 0.749
[64,     3] loss: 0.780
[65,     3] loss: 0.858
[66,     3] loss: 0.743
[67,     3] loss: 0.749
[68,     3] loss: 0.786
[69,     3] loss: 0.768
[70,     3] loss: 0.745
[71,     3] loss: 0.731
[72,     3] loss: 0.848
[73,     3] loss: 0.806
[74,     3] loss: 0.789
[75,     3] loss: 0.868
Early stopping applied (best metric=0.5419794321060181)
Finished Training
Total time taken: 20.3610737323761
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.386
[3,     3] loss: 1.383
[4,     3] loss: 1.392
[5,     3] loss: 1.380
[6,     3] loss: 1.381
[7,     3] loss: 1.383
[8,     3] loss: 1.384
[9,     3] loss: 1.368
[10,     3] loss: 1.365
[11,     3] loss: 1.367
[12,     3] loss: 1.352
[13,     3] loss: 1.347
[14,     3] loss: 1.320
[15,     3] loss: 1.315
[16,     3] loss: 1.259
[17,     3] loss: 1.266
[18,     3] loss: 1.180
[19,     3] loss: 1.204
[20,     3] loss: 1.266
[21,     3] loss: 1.124
[22,     3] loss: 1.279
[23,     3] loss: 1.141
[24,     3] loss: 1.158
[25,     3] loss: 1.154
[26,     3] loss: 1.140
[27,     3] loss: 1.106
[28,     3] loss: 1.135
[29,     3] loss: 1.057
[30,     3] loss: 1.086
[31,     3] loss: 1.018
[32,     3] loss: 1.060
[33,     3] loss: 0.985
[34,     3] loss: 0.932
[35,     3] loss: 0.990
[36,     3] loss: 0.865
[37,     3] loss: 1.034
[38,     3] loss: 1.053
[39,     3] loss: 0.888
[40,     3] loss: 0.954
[41,     3] loss: 0.859
[42,     3] loss: 0.878
[43,     3] loss: 0.846
[44,     3] loss: 0.921
[45,     3] loss: 0.849
[46,     3] loss: 0.809
[47,     3] loss: 0.786
[48,     3] loss: 0.811
[49,     3] loss: 0.857
[50,     3] loss: 0.850
[51,     3] loss: 0.915
[52,     3] loss: 1.027
[53,     3] loss: 0.898
[54,     3] loss: 0.953
[55,     3] loss: 0.890
[56,     3] loss: 0.864
[57,     3] loss: 0.838
[58,     3] loss: 0.863
[59,     3] loss: 0.827
[60,     3] loss: 0.812
[61,     3] loss: 0.845
[62,     3] loss: 0.812
[63,     3] loss: 0.842
[64,     3] loss: 0.963
[65,     3] loss: 0.946
[66,     3] loss: 0.925
[67,     3] loss: 0.790
[68,     3] loss: 0.855
[69,     3] loss: 0.799
[70,     3] loss: 0.792
Early stopping applied (best metric=0.5092718601226807)
Finished Training
Total time taken: 19.679070234298706
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.386
[3,     3] loss: 1.395
[4,     3] loss: 1.370
[5,     3] loss: 1.368
[6,     3] loss: 1.401
[7,     3] loss: 1.361
[8,     3] loss: 1.367
[9,     3] loss: 1.332
[10,     3] loss: 1.334
[11,     3] loss: 1.316
[12,     3] loss: 1.317
[13,     3] loss: 1.276
[14,     3] loss: 1.234
[15,     3] loss: 1.209
[16,     3] loss: 1.138
[17,     3] loss: 1.174
[18,     3] loss: 1.065
[19,     3] loss: 1.050
[20,     3] loss: 1.068
[21,     3] loss: 0.975
[22,     3] loss: 0.991
[23,     3] loss: 1.033
[24,     3] loss: 1.021
[25,     3] loss: 0.933
[26,     3] loss: 0.964
[27,     3] loss: 1.034
[28,     3] loss: 1.047
[29,     3] loss: 0.891
[30,     3] loss: 0.905
[31,     3] loss: 0.965
[32,     3] loss: 0.938
[33,     3] loss: 0.981
[34,     3] loss: 1.086
[35,     3] loss: 0.955
[36,     3] loss: 0.925
[37,     3] loss: 0.859
[38,     3] loss: 0.920
[39,     3] loss: 0.882
[40,     3] loss: 0.971
[41,     3] loss: 0.874
[42,     3] loss: 0.924
[43,     3] loss: 0.888
[44,     3] loss: 0.889
[45,     3] loss: 0.964
[46,     3] loss: 0.974
[47,     3] loss: 0.847
[48,     3] loss: 0.916
[49,     3] loss: 0.813
[50,     3] loss: 0.839
[51,     3] loss: 0.812
[52,     3] loss: 0.787
[53,     3] loss: 0.792
[54,     3] loss: 0.786
[55,     3] loss: 0.793
[56,     3] loss: 0.779
[57,     3] loss: 0.742
[58,     3] loss: 0.826
[59,     3] loss: 0.748
[60,     3] loss: 0.731
[61,     3] loss: 0.729
[62,     3] loss: 0.743
[63,     3] loss: 0.755
[64,     3] loss: 0.792
[65,     3] loss: 0.744
[66,     3] loss: 0.776
[67,     3] loss: 0.749
[68,     3] loss: 0.745
[69,     3] loss: 0.761
[70,     3] loss: 0.837
[71,     3] loss: 0.810
[72,     3] loss: 0.795
[73,     3] loss: 0.752
[74,     3] loss: 0.872
Early stopping applied (best metric=0.5228821635246277)
Finished Training
Total time taken: 20.733076095581055
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.388
[3,     3] loss: 1.386
[4,     3] loss: 1.382
[5,     3] loss: 1.385
[6,     3] loss: 1.387
[7,     3] loss: 1.385
[8,     3] loss: 1.390
[9,     3] loss: 1.400
[10,     3] loss: 1.385
[11,     3] loss: 1.377
[12,     3] loss: 1.381
[13,     3] loss: 1.380
[14,     3] loss: 1.372
[15,     3] loss: 1.373
[16,     3] loss: 1.350
[17,     3] loss: 1.364
[18,     3] loss: 1.359
[19,     3] loss: 1.328
[20,     3] loss: 1.323
[21,     3] loss: 1.287
[22,     3] loss: 1.268
[23,     3] loss: 1.275
[24,     3] loss: 1.228
[25,     3] loss: 1.220
[26,     3] loss: 1.122
[27,     3] loss: 1.134
[28,     3] loss: 1.167
[29,     3] loss: 1.147
[30,     3] loss: 1.147
[31,     3] loss: 1.127
[32,     3] loss: 1.135
[33,     3] loss: 1.091
[34,     3] loss: 1.103
[35,     3] loss: 1.033
[36,     3] loss: 1.078
[37,     3] loss: 1.026
[38,     3] loss: 0.993
[39,     3] loss: 0.968
[40,     3] loss: 0.973
[41,     3] loss: 0.948
[42,     3] loss: 1.022
[43,     3] loss: 0.944
[44,     3] loss: 1.172
[45,     3] loss: 1.049
[46,     3] loss: 1.043
[47,     3] loss: 0.960
[48,     3] loss: 0.944
[49,     3] loss: 1.043
[50,     3] loss: 0.882
[51,     3] loss: 0.901
[52,     3] loss: 1.049
[53,     3] loss: 0.949
[54,     3] loss: 0.868
[55,     3] loss: 0.843
[56,     3] loss: 0.850
[57,     3] loss: 0.906
[58,     3] loss: 0.870
[59,     3] loss: 0.898
[60,     3] loss: 1.163
[61,     3] loss: 1.146
[62,     3] loss: 0.956
[63,     3] loss: 0.944
[64,     3] loss: 1.069
[65,     3] loss: 0.890
[66,     3] loss: 1.112
[67,     3] loss: 0.857
[68,     3] loss: 0.952
[69,     3] loss: 0.871
[70,     3] loss: 0.823
[71,     3] loss: 0.889
[72,     3] loss: 0.866
[73,     3] loss: 0.831
[74,     3] loss: 0.854
[75,     3] loss: 0.795
[76,     3] loss: 0.815
[77,     3] loss: 0.792
[78,     3] loss: 0.822
[79,     3] loss: 0.799
Early stopping applied (best metric=0.4791988134384155)
Finished Training
Total time taken: 22.092081546783447
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.402
[2,     3] loss: 1.370
[3,     3] loss: 1.372
[4,     3] loss: 1.377
[5,     3] loss: 1.387
[6,     3] loss: 1.374
[7,     3] loss: 1.374
[8,     3] loss: 1.383
[9,     3] loss: 1.383
[10,     3] loss: 1.365
[11,     3] loss: 1.352
[12,     3] loss: 1.343
[13,     3] loss: 1.284
[14,     3] loss: 1.274
[15,     3] loss: 1.266
[16,     3] loss: 1.257
[17,     3] loss: 1.210
[18,     3] loss: 1.155
[19,     3] loss: 1.161
[20,     3] loss: 1.159
[21,     3] loss: 1.128
[22,     3] loss: 1.092
[23,     3] loss: 1.022
[24,     3] loss: 1.017
[25,     3] loss: 1.070
[26,     3] loss: 1.048
[27,     3] loss: 1.052
[28,     3] loss: 1.000
[29,     3] loss: 0.989
[30,     3] loss: 1.064
[31,     3] loss: 0.981
[32,     3] loss: 0.969
[33,     3] loss: 0.861
[34,     3] loss: 0.959
[35,     3] loss: 0.957
[36,     3] loss: 0.895
[37,     3] loss: 0.818
[38,     3] loss: 0.821
[39,     3] loss: 0.792
[40,     3] loss: 0.816
[41,     3] loss: 0.902
[42,     3] loss: 0.836
[43,     3] loss: 0.792
[44,     3] loss: 0.808
[45,     3] loss: 0.771
[46,     3] loss: 0.768
[47,     3] loss: 0.794
[48,     3] loss: 0.785
[49,     3] loss: 0.763
[50,     3] loss: 0.860
[51,     3] loss: 0.875
[52,     3] loss: 0.983
[53,     3] loss: 0.783
[54,     3] loss: 0.771
[55,     3] loss: 0.789
[56,     3] loss: 0.822
[57,     3] loss: 0.772
[58,     3] loss: 0.799
[59,     3] loss: 0.815
[60,     3] loss: 0.860
[61,     3] loss: 0.862
[62,     3] loss: 0.808
[63,     3] loss: 0.796
[64,     3] loss: 0.812
[65,     3] loss: 0.802
[66,     3] loss: 0.755
[67,     3] loss: 0.778
[68,     3] loss: 0.739
[69,     3] loss: 0.767
[70,     3] loss: 0.840
[71,     3] loss: 0.743
[72,     3] loss: 0.739
[73,     3] loss: 0.792
[74,     3] loss: 0.753
[75,     3] loss: 0.830
[76,     3] loss: 0.875
[77,     3] loss: 0.852
[78,     3] loss: 0.775
[79,     3] loss: 0.813
Early stopping applied (best metric=0.5081011056900024)
Finished Training
Total time taken: 21.972080945968628
{'S-palmitoylation-C Validation Accuracy': 0.6668302383367886, 'S-palmitoylation-C Validation Sensitivity': 0.27947194719471946, 'S-palmitoylation-C Validation Specificity': 0.7639341811619738, 'S-palmitoylation-C Validation Precision': 0.24393424638355185, 'S-palmitoylation-C AUC ROC': 0.54774034621891, 'S-palmitoylation-C AUC PR': 0.22763850871470911, 'S-palmitoylation-C MCC': 0.045574914444861975, 'S-palmitoylation-C F1': 0.2263921891471887, 'Validation Loss (S-palmitoylation-C)': 0.5541670918464661, 'Hydroxylation-K Validation Accuracy': 0.7189420803782506, 'Hydroxylation-K Validation Sensitivity': 0.7999999999999999, 'Hydroxylation-K Validation Specificity': 0.6982456140350877, 'Hydroxylation-K Validation Precision': 0.44590872369307066, 'Hydroxylation-K AUC ROC': 0.8305847953216374, 'Hydroxylation-K AUC PR': 0.6126235344375914, 'Hydroxylation-K MCC': 0.43459682205988304, 'Hydroxylation-K F1': 0.5568983625751507, 'Validation Loss (Hydroxylation-K)': 0.5111822406450908, 'Validation Loss (total)': 1.065349316596985, 'TimeToTrain': 23.400753355026247}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005507433043279362,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9308588071311015,
 'loss_weight_S-palmitoylation-C': 0.13115691468370963,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2217116281,
 'sample_weights': [0.21906211819848986, 0.24751295691386482],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.380785359744165,
 'weight_decay_Hydroxylation-K': 1.8169517787760279,
 'weight_decay_S-palmitoylation-C': 4.113116382832181}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.388
[3,     3] loss: 1.399
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0002605009448041658,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7640562848004591,
 'loss_weight_S-palmitoylation-C': 0.33816019853799695,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3824696078,
 'sample_weights': [0.13115691468370963, 0.9308588071311015],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5884838102452183,
 'weight_decay_Hydroxylation-K': 0.7071976839540806,
 'weight_decay_S-palmitoylation-C': 3.4790146308538104}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.381
[3,     3] loss: 1.382
[4,     3] loss: 1.381
[5,     3] loss: 1.378
[6,     3] loss: 1.380
[7,     3] loss: 1.375
[8,     3] loss: 1.375
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008673598576082223,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22421731040895462,
 'loss_weight_S-palmitoylation-C': 0.8760735928507968,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3191701658,
 'sample_weights': [0.33816019853799695, 0.7640562848004591],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5196395744224067,
 'weight_decay_Hydroxylation-K': 7.986205686908001,
 'weight_decay_S-palmitoylation-C': 6.299545864497599}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.393
[3,     3] loss: 1.387
[4,     3] loss: 1.384
[5,     3] loss: 1.387
[6,     3] loss: 1.389
[7,     3] loss: 1.385
[8,     3] loss: 1.385
[9,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00027261332915400147,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2344294876178232,
 'loss_weight_S-palmitoylation-C': 0.34093324455555507,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 730554160,
 'sample_weights': [0.8760735928507968, 0.22421731040895462],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.233563688334749,
 'weight_decay_Hydroxylation-K': 3.801903560737631,
 'weight_decay_S-palmitoylation-C': 3.2037288081960176}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.388
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005116907905502522,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.35977982722522495,
 'loss_weight_S-palmitoylation-C': 0.18180719547455226,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3697408690,
 'sample_weights': [0.34093324455555507, 0.2344294876178232],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.678937594381538,
 'weight_decay_Hydroxylation-K': 1.5650926780657128,
 'weight_decay_S-palmitoylation-C': 5.813514971104342}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.386
[3,     3] loss: 1.390
[4,     3] loss: 1.389
[5,     3] loss: 1.373
[6,     3] loss: 1.385
[7,     3] loss: 1.375
[8,     3] loss: 1.376
[9,     3] loss: 1.375
[10,     3] loss: 1.380
[11,     3] loss: 1.365
[12,     3] loss: 1.353
[13,     3] loss: 1.353
[14,     3] loss: 1.326
[15,     3] loss: 1.308
[16,     3] loss: 1.289
[17,     3] loss: 1.299
[18,     3] loss: 1.272
[19,     3] loss: 1.291
[20,     3] loss: 1.247
[21,     3] loss: 1.252
[22,     3] loss: 1.192
[23,     3] loss: 1.199
[24,     3] loss: 1.218
[25,     3] loss: 1.149
[26,     3] loss: 1.164
[27,     3] loss: 1.175
[28,     3] loss: 1.093
[29,     3] loss: 1.089
[30,     3] loss: 1.113
[31,     3] loss: 1.033
[32,     3] loss: 1.068
[33,     3] loss: 1.001
[34,     3] loss: 0.951
[35,     3] loss: 0.970
[36,     3] loss: 0.908
[37,     3] loss: 1.061
[38,     3] loss: 0.941
[39,     3] loss: 0.921
[40,     3] loss: 0.890
[41,     3] loss: 0.916
[42,     3] loss: 0.935
[43,     3] loss: 0.864
[44,     3] loss: 1.024
[45,     3] loss: 0.888
[46,     3] loss: 0.868
[47,     3] loss: 0.941
[48,     3] loss: 0.910
[49,     3] loss: 0.952
[50,     3] loss: 0.859
[51,     3] loss: 0.980
[52,     3] loss: 0.951
[53,     3] loss: 0.875
[54,     3] loss: 0.957
[55,     3] loss: 0.855
[56,     3] loss: 0.889
[57,     3] loss: 0.815
[58,     3] loss: 0.818
[59,     3] loss: 0.876
[60,     3] loss: 0.873
[61,     3] loss: 0.775
[62,     3] loss: 0.801
[63,     3] loss: 0.768
[64,     3] loss: 0.800
[65,     3] loss: 0.800
[66,     3] loss: 0.783
[67,     3] loss: 0.787
[68,     3] loss: 0.771
[69,     3] loss: 0.765
[70,     3] loss: 0.749
[71,     3] loss: 0.757
[72,     3] loss: 0.746
[73,     3] loss: 0.782
[74,     3] loss: 0.733
[75,     3] loss: 0.760
[76,     3] loss: 0.726
[77,     3] loss: 0.742
[78,     3] loss: 0.754
[79,     3] loss: 0.802
Early stopping applied (best metric=0.5169939398765564)
Finished Training
Total time taken: 21.908083200454712
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.383
[3,     3] loss: 1.395
[4,     3] loss: 1.385
[5,     3] loss: 1.383
[6,     3] loss: 1.380
[7,     3] loss: 1.373
[8,     3] loss: 1.381
[9,     3] loss: 1.379
[10,     3] loss: 1.368
[11,     3] loss: 1.357
[12,     3] loss: 1.344
[13,     3] loss: 1.351
[14,     3] loss: 1.320
[15,     3] loss: 1.272
[16,     3] loss: 1.255
[17,     3] loss: 1.268
[18,     3] loss: 1.273
[19,     3] loss: 1.213
[20,     3] loss: 1.200
[21,     3] loss: 1.170
[22,     3] loss: 1.149
[23,     3] loss: 1.126
[24,     3] loss: 1.029
[25,     3] loss: 1.026
[26,     3] loss: 1.009
[27,     3] loss: 1.064
[28,     3] loss: 1.009
[29,     3] loss: 0.939
[30,     3] loss: 1.019
[31,     3] loss: 0.906
[32,     3] loss: 0.939
[33,     3] loss: 0.963
[34,     3] loss: 0.903
[35,     3] loss: 0.951
[36,     3] loss: 0.874
[37,     3] loss: 0.921
[38,     3] loss: 0.906
[39,     3] loss: 0.877
[40,     3] loss: 0.898
[41,     3] loss: 0.955
[42,     3] loss: 0.913
[43,     3] loss: 0.821
[44,     3] loss: 0.925
[45,     3] loss: 0.796
[46,     3] loss: 0.820
[47,     3] loss: 0.840
[48,     3] loss: 0.849
[49,     3] loss: 0.766
[50,     3] loss: 0.822
[51,     3] loss: 0.813
[52,     3] loss: 0.795
[53,     3] loss: 0.814
[54,     3] loss: 0.806
[55,     3] loss: 0.845
[56,     3] loss: 0.777
[57,     3] loss: 0.763
[58,     3] loss: 0.788
[59,     3] loss: 0.751
[60,     3] loss: 0.786
[61,     3] loss: 0.753
[62,     3] loss: 0.803
[63,     3] loss: 0.798
[64,     3] loss: 0.758
[65,     3] loss: 0.769
[66,     3] loss: 0.862
[67,     3] loss: 0.786
[68,     3] loss: 0.764
[69,     3] loss: 0.790
[70,     3] loss: 0.775
[71,     3] loss: 0.733
[72,     3] loss: 0.765
[73,     3] loss: 0.791
[74,     3] loss: 0.799
[75,     3] loss: 0.799
[76,     3] loss: 0.773
[77,     3] loss: 0.801
[78,     3] loss: 0.848
[79,     3] loss: 0.765
[80,     3] loss: 0.829
Early stopping applied (best metric=0.5428944826126099)
Finished Training
Total time taken: 22.303082942962646
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.379
[2,     3] loss: 1.383
[3,     3] loss: 1.387
[4,     3] loss: 1.393
[5,     3] loss: 1.386
[6,     3] loss: 1.382
[7,     3] loss: 1.388
[8,     3] loss: 1.382
[9,     3] loss: 1.385
[10,     3] loss: 1.377
[11,     3] loss: 1.367
[12,     3] loss: 1.389
[13,     3] loss: 1.373
[14,     3] loss: 1.387
[15,     3] loss: 1.371
[16,     3] loss: 1.363
[17,     3] loss: 1.359
[18,     3] loss: 1.353
[19,     3] loss: 1.332
[20,     3] loss: 1.331
[21,     3] loss: 1.303
[22,     3] loss: 1.291
[23,     3] loss: 1.257
[24,     3] loss: 1.224
[25,     3] loss: 1.234
[26,     3] loss: 1.198
[27,     3] loss: 1.146
[28,     3] loss: 1.147
[29,     3] loss: 1.178
[30,     3] loss: 1.066
[31,     3] loss: 1.067
[32,     3] loss: 1.027
[33,     3] loss: 1.041
[34,     3] loss: 0.978
[35,     3] loss: 0.942
[36,     3] loss: 1.043
[37,     3] loss: 0.997
[38,     3] loss: 0.962
[39,     3] loss: 1.013
[40,     3] loss: 0.944
[41,     3] loss: 0.921
[42,     3] loss: 0.874
[43,     3] loss: 0.980
[44,     3] loss: 0.944
[45,     3] loss: 0.957
[46,     3] loss: 0.886
[47,     3] loss: 0.874
[48,     3] loss: 0.870
[49,     3] loss: 0.893
[50,     3] loss: 0.960
[51,     3] loss: 0.976
[52,     3] loss: 0.913
[53,     3] loss: 0.853
[54,     3] loss: 0.975
[55,     3] loss: 0.876
[56,     3] loss: 0.912
[57,     3] loss: 1.137
[58,     3] loss: 0.841
[59,     3] loss: 0.998
[60,     3] loss: 0.928
[61,     3] loss: 0.866
[62,     3] loss: 0.834
[63,     3] loss: 0.922
[64,     3] loss: 0.833
[65,     3] loss: 0.849
[66,     3] loss: 0.864
[67,     3] loss: 0.802
[68,     3] loss: 0.785
[69,     3] loss: 0.798
[70,     3] loss: 0.771
[71,     3] loss: 0.788
[72,     3] loss: 0.797
[73,     3] loss: 0.807
[74,     3] loss: 0.754
[75,     3] loss: 0.763
[76,     3] loss: 0.744
[77,     3] loss: 0.726
[78,     3] loss: 0.745
[79,     3] loss: 0.729
[80,     3] loss: 0.727
[81,     3] loss: 0.745
[82,     3] loss: 0.737
[83,     3] loss: 0.746
[84,     3] loss: 0.740
[85,     3] loss: 0.732
[86,     3] loss: 0.734
[87,     3] loss: 0.757
[88,     3] loss: 0.821
[89,     3] loss: 0.725
[90,     3] loss: 0.872
[91,     3] loss: 0.803
[92,     3] loss: 0.783
[93,     3] loss: 0.798
[94,     3] loss: 0.824
[95,     3] loss: 0.855
[96,     3] loss: 0.817
[97,     3] loss: 0.835
[98,     3] loss: 0.789
[99,     3] loss: 0.862
Early stopping applied (best metric=0.5057573914527893)
Finished Training
Total time taken: 27.574100494384766
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.390
[3,     3] loss: 1.392
[4,     3] loss: 1.388
[5,     3] loss: 1.391
[6,     3] loss: 1.381
[7,     3] loss: 1.373
[8,     3] loss: 1.382
[9,     3] loss: 1.381
[10,     3] loss: 1.363
[11,     3] loss: 1.356
[12,     3] loss: 1.364
[13,     3] loss: 1.351
[14,     3] loss: 1.323
[15,     3] loss: 1.292
[16,     3] loss: 1.280
[17,     3] loss: 1.267
[18,     3] loss: 1.234
[19,     3] loss: 1.183
[20,     3] loss: 1.163
[21,     3] loss: 1.209
[22,     3] loss: 1.163
[23,     3] loss: 1.157
[24,     3] loss: 1.186
[25,     3] loss: 1.168
[26,     3] loss: 1.145
[27,     3] loss: 1.089
[28,     3] loss: 1.056
[29,     3] loss: 1.120
[30,     3] loss: 1.063
[31,     3] loss: 1.106
[32,     3] loss: 0.992
[33,     3] loss: 0.927
[34,     3] loss: 0.959
[35,     3] loss: 1.012
[36,     3] loss: 0.930
[37,     3] loss: 0.959
[38,     3] loss: 1.018
[39,     3] loss: 0.917
[40,     3] loss: 0.958
[41,     3] loss: 0.913
[42,     3] loss: 0.843
[43,     3] loss: 0.947
[44,     3] loss: 1.017
[45,     3] loss: 0.942
[46,     3] loss: 0.879
[47,     3] loss: 0.931
[48,     3] loss: 0.870
[49,     3] loss: 0.930
[50,     3] loss: 0.940
[51,     3] loss: 0.795
[52,     3] loss: 0.860
[53,     3] loss: 0.863
[54,     3] loss: 0.844
[55,     3] loss: 1.047
[56,     3] loss: 0.804
[57,     3] loss: 0.914
[58,     3] loss: 0.778
[59,     3] loss: 0.858
[60,     3] loss: 0.813
[61,     3] loss: 0.799
[62,     3] loss: 0.794
[63,     3] loss: 0.846
[64,     3] loss: 0.839
[65,     3] loss: 0.815
[66,     3] loss: 0.906
[67,     3] loss: 0.828
[68,     3] loss: 0.834
[69,     3] loss: 0.771
[70,     3] loss: 0.783
[71,     3] loss: 0.776
[72,     3] loss: 0.798
[73,     3] loss: 0.779
[74,     3] loss: 0.757
[75,     3] loss: 0.759
[76,     3] loss: 0.754
[77,     3] loss: 0.752
[78,     3] loss: 0.776
[79,     3] loss: 0.846
[80,     3] loss: 0.733
[81,     3] loss: 0.742
[82,     3] loss: 0.736
Early stopping applied (best metric=0.49492618441581726)
Finished Training
Total time taken: 23.056086540222168
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.388
[3,     3] loss: 1.380
[4,     3] loss: 1.389
[5,     3] loss: 1.377
[6,     3] loss: 1.390
[7,     3] loss: 1.378
[8,     3] loss: 1.381
[9,     3] loss: 1.374
[10,     3] loss: 1.372
[11,     3] loss: 1.358
[12,     3] loss: 1.378
[13,     3] loss: 1.327
[14,     3] loss: 1.350
[15,     3] loss: 1.314
[16,     3] loss: 1.304
[17,     3] loss: 1.300
[18,     3] loss: 1.274
[19,     3] loss: 1.256
[20,     3] loss: 1.227
[21,     3] loss: 1.287
[22,     3] loss: 1.219
[23,     3] loss: 1.213
[24,     3] loss: 1.106
[25,     3] loss: 1.174
[26,     3] loss: 1.075
[27,     3] loss: 1.097
[28,     3] loss: 1.029
[29,     3] loss: 1.041
[30,     3] loss: 1.036
[31,     3] loss: 1.007
[32,     3] loss: 0.981
[33,     3] loss: 1.007
[34,     3] loss: 0.920
[35,     3] loss: 0.949
[36,     3] loss: 0.899
[37,     3] loss: 0.904
[38,     3] loss: 0.865
[39,     3] loss: 0.844
[40,     3] loss: 0.894
[41,     3] loss: 0.827
[42,     3] loss: 0.829
[43,     3] loss: 0.801
[44,     3] loss: 0.820
[45,     3] loss: 0.869
[46,     3] loss: 0.879
[47,     3] loss: 0.844
[48,     3] loss: 0.870
[49,     3] loss: 0.883
[50,     3] loss: 0.825
[51,     3] loss: 0.838
[52,     3] loss: 0.952
[53,     3] loss: 0.823
[54,     3] loss: 0.782
[55,     3] loss: 0.809
[56,     3] loss: 0.797
[57,     3] loss: 0.825
[58,     3] loss: 0.792
[59,     3] loss: 0.776
[60,     3] loss: 0.816
[61,     3] loss: 0.759
[62,     3] loss: 0.809
[63,     3] loss: 0.772
[64,     3] loss: 0.745
[65,     3] loss: 0.815
[66,     3] loss: 0.751
[67,     3] loss: 0.826
[68,     3] loss: 0.751
[69,     3] loss: 0.955
[70,     3] loss: 0.786
[71,     3] loss: 0.863
[72,     3] loss: 0.975
[73,     3] loss: 0.794
[74,     3] loss: 0.859
[75,     3] loss: 0.774
[76,     3] loss: 0.799
[77,     3] loss: 0.762
[78,     3] loss: 0.777
Early stopping applied (best metric=0.5061410069465637)
Finished Training
Total time taken: 21.726080179214478
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.387
[3,     3] loss: 1.379
[4,     3] loss: 1.380
[5,     3] loss: 1.379
[6,     3] loss: 1.376
[7,     3] loss: 1.362
[8,     3] loss: 1.364
[9,     3] loss: 1.342
[10,     3] loss: 1.314
[11,     3] loss: 1.294
[12,     3] loss: 1.291
[13,     3] loss: 1.250
[14,     3] loss: 1.251
[15,     3] loss: 1.297
[16,     3] loss: 1.227
[17,     3] loss: 1.217
[18,     3] loss: 1.217
[19,     3] loss: 1.270
[20,     3] loss: 1.236
[21,     3] loss: 1.218
[22,     3] loss: 1.128
[23,     3] loss: 1.169
[24,     3] loss: 1.115
[25,     3] loss: 1.066
[26,     3] loss: 1.060
[27,     3] loss: 1.135
[28,     3] loss: 1.050
[29,     3] loss: 0.974
[30,     3] loss: 0.958
[31,     3] loss: 1.087
[32,     3] loss: 0.977
[33,     3] loss: 0.956
[34,     3] loss: 0.906
[35,     3] loss: 1.054
[36,     3] loss: 1.000
[37,     3] loss: 0.891
[38,     3] loss: 0.863
[39,     3] loss: 0.999
[40,     3] loss: 0.869
[41,     3] loss: 0.869
[42,     3] loss: 0.912
[43,     3] loss: 0.900
[44,     3] loss: 0.810
[45,     3] loss: 0.834
[46,     3] loss: 0.840
[47,     3] loss: 0.881
[48,     3] loss: 0.830
[49,     3] loss: 0.889
[50,     3] loss: 0.897
[51,     3] loss: 0.929
[52,     3] loss: 0.936
[53,     3] loss: 0.896
[54,     3] loss: 1.077
[55,     3] loss: 0.860
[56,     3] loss: 0.927
[57,     3] loss: 0.841
[58,     3] loss: 0.826
[59,     3] loss: 0.853
[60,     3] loss: 0.852
[61,     3] loss: 0.810
[62,     3] loss: 0.813
[63,     3] loss: 0.837
[64,     3] loss: 0.815
[65,     3] loss: 0.884
[66,     3] loss: 0.844
[67,     3] loss: 0.828
[68,     3] loss: 0.926
[69,     3] loss: 0.867
[70,     3] loss: 0.814
[71,     3] loss: 0.776
[72,     3] loss: 0.854
[73,     3] loss: 0.818
[74,     3] loss: 0.777
[75,     3] loss: 0.821
[76,     3] loss: 0.768
[77,     3] loss: 0.771
[78,     3] loss: 0.806
[79,     3] loss: 0.816
[80,     3] loss: 0.780
[81,     3] loss: 0.750
[82,     3] loss: 0.803
[83,     3] loss: 0.779
[84,     3] loss: 0.772
[85,     3] loss: 0.736
[86,     3] loss: 0.892
[87,     3] loss: 0.790
[88,     3] loss: 0.845
[89,     3] loss: 0.791
[90,     3] loss: 0.753
[91,     3] loss: 0.762
[92,     3] loss: 0.744
[93,     3] loss: 0.793
[94,     3] loss: 0.781
[95,     3] loss: 0.752
[96,     3] loss: 0.751
[97,     3] loss: 0.731
Early stopping applied (best metric=0.5295230746269226)
Finished Training
Total time taken: 27.077100038528442
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.386
[3,     3] loss: 1.389
[4,     3] loss: 1.384
[5,     3] loss: 1.382
[6,     3] loss: 1.384
[7,     3] loss: 1.385
[8,     3] loss: 1.368
[9,     3] loss: 1.371
[10,     3] loss: 1.362
[11,     3] loss: 1.356
[12,     3] loss: 1.354
[13,     3] loss: 1.340
[14,     3] loss: 1.313
[15,     3] loss: 1.302
[16,     3] loss: 1.300
[17,     3] loss: 1.242
[18,     3] loss: 1.267
[19,     3] loss: 1.321
[20,     3] loss: 1.195
[21,     3] loss: 1.233
[22,     3] loss: 1.227
[23,     3] loss: 1.158
[24,     3] loss: 1.089
[25,     3] loss: 1.078
[26,     3] loss: 1.111
[27,     3] loss: 1.049
[28,     3] loss: 1.061
[29,     3] loss: 1.055
[30,     3] loss: 1.026
[31,     3] loss: 0.982
[32,     3] loss: 0.952
[33,     3] loss: 0.898
[34,     3] loss: 0.962
[35,     3] loss: 0.926
[36,     3] loss: 0.894
[37,     3] loss: 0.914
[38,     3] loss: 0.912
[39,     3] loss: 0.934
[40,     3] loss: 0.876
[41,     3] loss: 0.957
[42,     3] loss: 0.945
[43,     3] loss: 0.983
[44,     3] loss: 0.888
[45,     3] loss: 0.846
[46,     3] loss: 0.910
[47,     3] loss: 0.814
[48,     3] loss: 0.878
[49,     3] loss: 0.834
[50,     3] loss: 0.901
[51,     3] loss: 0.807
[52,     3] loss: 0.863
[53,     3] loss: 0.826
[54,     3] loss: 0.781
[55,     3] loss: 0.834
[56,     3] loss: 0.795
[57,     3] loss: 0.774
[58,     3] loss: 0.884
[59,     3] loss: 0.764
[60,     3] loss: 0.841
[61,     3] loss: 0.752
[62,     3] loss: 0.786
[63,     3] loss: 0.779
[64,     3] loss: 0.749
[65,     3] loss: 0.735
[66,     3] loss: 0.752
[67,     3] loss: 0.751
[68,     3] loss: 0.746
[69,     3] loss: 0.748
[70,     3] loss: 0.758
[71,     3] loss: 0.754
[72,     3] loss: 0.728
[73,     3] loss: 0.736
[74,     3] loss: 0.719
[75,     3] loss: 0.730
[76,     3] loss: 0.732
[77,     3] loss: 0.724
[78,     3] loss: 0.853
[79,     3] loss: 0.772
[80,     3] loss: 0.877
[81,     3] loss: 0.840
[82,     3] loss: 0.891
[83,     3] loss: 0.804
Early stopping applied (best metric=0.522710382938385)
Finished Training
Total time taken: 22.74808382987976
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.386
[3,     3] loss: 1.379
[4,     3] loss: 1.392
[5,     3] loss: 1.387
[6,     3] loss: 1.376
[7,     3] loss: 1.386
[8,     3] loss: 1.391
[9,     3] loss: 1.378
[10,     3] loss: 1.382
[11,     3] loss: 1.379
[12,     3] loss: 1.372
[13,     3] loss: 1.368
[14,     3] loss: 1.377
[15,     3] loss: 1.351
[16,     3] loss: 1.355
[17,     3] loss: 1.336
[18,     3] loss: 1.315
[19,     3] loss: 1.299
[20,     3] loss: 1.292
[21,     3] loss: 1.243
[22,     3] loss: 1.261
[23,     3] loss: 1.186
[24,     3] loss: 1.167
[25,     3] loss: 1.175
[26,     3] loss: 1.060
[27,     3] loss: 1.087
[28,     3] loss: 1.134
[29,     3] loss: 1.066
[30,     3] loss: 1.126
[31,     3] loss: 1.009
[32,     3] loss: 1.089
[33,     3] loss: 0.980
[34,     3] loss: 0.992
[35,     3] loss: 0.974
[36,     3] loss: 1.032
[37,     3] loss: 1.141
[38,     3] loss: 0.895
[39,     3] loss: 1.071
[40,     3] loss: 0.899
[41,     3] loss: 0.937
[42,     3] loss: 0.990
[43,     3] loss: 0.871
[44,     3] loss: 0.855
[45,     3] loss: 0.885
[46,     3] loss: 0.847
[47,     3] loss: 0.824
[48,     3] loss: 0.835
[49,     3] loss: 0.823
[50,     3] loss: 0.922
[51,     3] loss: 0.871
[52,     3] loss: 0.842
[53,     3] loss: 0.809
[54,     3] loss: 0.844
[55,     3] loss: 0.812
[56,     3] loss: 0.961
[57,     3] loss: 0.834
[58,     3] loss: 0.854
[59,     3] loss: 0.786
[60,     3] loss: 0.762
[61,     3] loss: 0.848
[62,     3] loss: 0.755
[63,     3] loss: 0.920
[64,     3] loss: 0.873
[65,     3] loss: 0.762
[66,     3] loss: 0.861
[67,     3] loss: 0.765
[68,     3] loss: 0.800
[69,     3] loss: 0.775
[70,     3] loss: 0.781
[71,     3] loss: 0.815
[72,     3] loss: 0.739
[73,     3] loss: 0.763
[74,     3] loss: 0.746
[75,     3] loss: 0.764
[76,     3] loss: 0.734
[77,     3] loss: 0.744
[78,     3] loss: 0.785
[79,     3] loss: 0.759
[80,     3] loss: 0.759
[81,     3] loss: 0.747
[82,     3] loss: 0.739
[83,     3] loss: 0.773
[84,     3] loss: 0.736
[85,     3] loss: 0.745
[86,     3] loss: 0.740
[87,     3] loss: 0.761
[88,     3] loss: 0.751
[89,     3] loss: 0.790
[90,     3] loss: 0.747
[91,     3] loss: 0.733
[92,     3] loss: 0.745
[93,     3] loss: 0.723
[94,     3] loss: 0.726
[95,     3] loss: 0.740
[96,     3] loss: 0.729
[97,     3] loss: 0.708
Early stopping applied (best metric=0.5216534733772278)
Finished Training
Total time taken: 26.711098432540894
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.389
[3,     3] loss: 1.391
[4,     3] loss: 1.382
[5,     3] loss: 1.391
[6,     3] loss: 1.376
[7,     3] loss: 1.376
[8,     3] loss: 1.379
[9,     3] loss: 1.378
[10,     3] loss: 1.384
[11,     3] loss: 1.381
[12,     3] loss: 1.371
[13,     3] loss: 1.371
[14,     3] loss: 1.358
[15,     3] loss: 1.335
[16,     3] loss: 1.331
[17,     3] loss: 1.339
[18,     3] loss: 1.290
[19,     3] loss: 1.298
[20,     3] loss: 1.299
[21,     3] loss: 1.225
[22,     3] loss: 1.266
[23,     3] loss: 1.221
[24,     3] loss: 1.230
[25,     3] loss: 1.174
[26,     3] loss: 1.218
[27,     3] loss: 1.230
[28,     3] loss: 1.118
[29,     3] loss: 1.151
[30,     3] loss: 1.210
[31,     3] loss: 1.079
[32,     3] loss: 1.079
[33,     3] loss: 1.057
[34,     3] loss: 1.026
[35,     3] loss: 1.135
[36,     3] loss: 1.098
[37,     3] loss: 0.966
[38,     3] loss: 1.002
[39,     3] loss: 1.026
[40,     3] loss: 0.981
[41,     3] loss: 1.015
[42,     3] loss: 0.939
[43,     3] loss: 0.853
[44,     3] loss: 0.887
[45,     3] loss: 0.920
[46,     3] loss: 0.898
[47,     3] loss: 0.861
[48,     3] loss: 0.836
[49,     3] loss: 0.837
[50,     3] loss: 0.886
[51,     3] loss: 0.800
[52,     3] loss: 0.823
[53,     3] loss: 0.840
[54,     3] loss: 0.825
[55,     3] loss: 0.866
[56,     3] loss: 0.822
[57,     3] loss: 0.830
[58,     3] loss: 0.826
[59,     3] loss: 0.824
[60,     3] loss: 0.783
[61,     3] loss: 0.886
[62,     3] loss: 0.870
[63,     3] loss: 0.830
[64,     3] loss: 0.893
[65,     3] loss: 0.794
[66,     3] loss: 0.789
[67,     3] loss: 0.825
[68,     3] loss: 0.770
[69,     3] loss: 0.791
[70,     3] loss: 0.772
[71,     3] loss: 0.764
[72,     3] loss: 0.777
[73,     3] loss: 0.754
[74,     3] loss: 0.750
[75,     3] loss: 0.767
[76,     3] loss: 0.758
[77,     3] loss: 0.736
[78,     3] loss: 0.763
[79,     3] loss: 0.743
[80,     3] loss: 0.801
Early stopping applied (best metric=0.5127716064453125)
Finished Training
Total time taken: 22.038084030151367
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.386
[3,     3] loss: 1.384
[4,     3] loss: 1.389
[5,     3] loss: 1.385
[6,     3] loss: 1.382
[7,     3] loss: 1.382
[8,     3] loss: 1.375
[9,     3] loss: 1.379
[10,     3] loss: 1.373
[11,     3] loss: 1.367
[12,     3] loss: 1.361
[13,     3] loss: 1.342
[14,     3] loss: 1.343
[15,     3] loss: 1.348
[16,     3] loss: 1.336
[17,     3] loss: 1.309
[18,     3] loss: 1.296
[19,     3] loss: 1.281
[20,     3] loss: 1.257
[21,     3] loss: 1.246
[22,     3] loss: 1.188
[23,     3] loss: 1.201
[24,     3] loss: 1.149
[25,     3] loss: 1.231
[26,     3] loss: 1.156
[27,     3] loss: 1.177
[28,     3] loss: 1.050
[29,     3] loss: 1.156
[30,     3] loss: 1.101
[31,     3] loss: 1.007
[32,     3] loss: 1.057
[33,     3] loss: 1.095
[34,     3] loss: 1.017
[35,     3] loss: 0.963
[36,     3] loss: 1.021
[37,     3] loss: 1.019
[38,     3] loss: 0.893
[39,     3] loss: 0.966
[40,     3] loss: 0.872
[41,     3] loss: 0.884
[42,     3] loss: 0.907
[43,     3] loss: 1.051
[44,     3] loss: 0.908
[45,     3] loss: 0.989
[46,     3] loss: 0.897
[47,     3] loss: 0.918
[48,     3] loss: 0.832
[49,     3] loss: 0.826
[50,     3] loss: 0.933
[51,     3] loss: 0.907
[52,     3] loss: 0.863
[53,     3] loss: 0.862
[54,     3] loss: 0.887
[55,     3] loss: 0.859
[56,     3] loss: 0.903
[57,     3] loss: 0.923
[58,     3] loss: 0.810
[59,     3] loss: 0.838
[60,     3] loss: 0.805
[61,     3] loss: 0.808
[62,     3] loss: 0.791
[63,     3] loss: 0.798
[64,     3] loss: 0.812
[65,     3] loss: 0.911
[66,     3] loss: 0.810
[67,     3] loss: 0.838
[68,     3] loss: 0.790
[69,     3] loss: 0.797
[70,     3] loss: 0.822
[71,     3] loss: 0.894
[72,     3] loss: 0.777
[73,     3] loss: 0.808
[74,     3] loss: 0.749
[75,     3] loss: 0.786
[76,     3] loss: 0.773
[77,     3] loss: 0.755
[78,     3] loss: 0.747
[79,     3] loss: 0.762
[80,     3] loss: 0.749
[81,     3] loss: 0.741
[82,     3] loss: 0.743
[83,     3] loss: 0.746
[84,     3] loss: 0.738
[85,     3] loss: 0.736
[86,     3] loss: 0.725
[87,     3] loss: 0.732
[88,     3] loss: 0.749
[89,     3] loss: 0.839
[90,     3] loss: 0.802
[91,     3] loss: 0.766
[92,     3] loss: 0.759
[93,     3] loss: 0.757
Early stopping applied (best metric=0.4975500702857971)
Finished Training
Total time taken: 25.864097118377686
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.402
[2,     3] loss: 1.382
[3,     3] loss: 1.379
[4,     3] loss: 1.381
[5,     3] loss: 1.385
[6,     3] loss: 1.375
[7,     3] loss: 1.378
[8,     3] loss: 1.375
[9,     3] loss: 1.362
[10,     3] loss: 1.354
[11,     3] loss: 1.355
[12,     3] loss: 1.339
[13,     3] loss: 1.311
[14,     3] loss: 1.295
[15,     3] loss: 1.272
[16,     3] loss: 1.277
[17,     3] loss: 1.232
[18,     3] loss: 1.234
[19,     3] loss: 1.161
[20,     3] loss: 1.151
[21,     3] loss: 1.158
[22,     3] loss: 1.144
[23,     3] loss: 1.112
[24,     3] loss: 1.104
[25,     3] loss: 1.041
[26,     3] loss: 1.048
[27,     3] loss: 1.001
[28,     3] loss: 0.971
[29,     3] loss: 0.929
[30,     3] loss: 0.934
[31,     3] loss: 0.907
[32,     3] loss: 0.922
[33,     3] loss: 0.953
[34,     3] loss: 0.879
[35,     3] loss: 0.906
[36,     3] loss: 0.935
[37,     3] loss: 0.876
[38,     3] loss: 0.824
[39,     3] loss: 0.918
[40,     3] loss: 0.865
[41,     3] loss: 0.803
[42,     3] loss: 0.844
[43,     3] loss: 1.005
[44,     3] loss: 0.941
[45,     3] loss: 0.815
[46,     3] loss: 0.839
[47,     3] loss: 0.833
[48,     3] loss: 0.815
[49,     3] loss: 0.897
[50,     3] loss: 0.818
[51,     3] loss: 0.773
[52,     3] loss: 0.879
[53,     3] loss: 0.856
[54,     3] loss: 0.775
[55,     3] loss: 0.896
[56,     3] loss: 0.865
[57,     3] loss: 0.805
[58,     3] loss: 0.825
[59,     3] loss: 0.848
[60,     3] loss: 0.789
[61,     3] loss: 0.862
[62,     3] loss: 0.824
[63,     3] loss: 0.829
[64,     3] loss: 0.861
[65,     3] loss: 0.802
[66,     3] loss: 0.824
[67,     3] loss: 0.766
[68,     3] loss: 0.823
[69,     3] loss: 0.765
[70,     3] loss: 0.783
[71,     3] loss: 0.762
[72,     3] loss: 0.784
[73,     3] loss: 0.813
[74,     3] loss: 0.808
[75,     3] loss: 0.765
[76,     3] loss: 0.828
[77,     3] loss: 0.871
[78,     3] loss: 0.809
[79,     3] loss: 0.740
[80,     3] loss: 0.806
[81,     3] loss: 0.793
[82,     3] loss: 0.761
[83,     3] loss: 0.739
[84,     3] loss: 0.730
[85,     3] loss: 0.766
Early stopping applied (best metric=0.527154803276062)
Finished Training
Total time taken: 23.848087787628174
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.391
[3,     3] loss: 1.388
[4,     3] loss: 1.390
[5,     3] loss: 1.382
[6,     3] loss: 1.381
[7,     3] loss: 1.384
[8,     3] loss: 1.386
[9,     3] loss: 1.374
[10,     3] loss: 1.369
[11,     3] loss: 1.366
[12,     3] loss: 1.359
[13,     3] loss: 1.360
[14,     3] loss: 1.341
[15,     3] loss: 1.326
[16,     3] loss: 1.294
[17,     3] loss: 1.270
[18,     3] loss: 1.261
[19,     3] loss: 1.225
[20,     3] loss: 1.194
[21,     3] loss: 1.167
[22,     3] loss: 1.190
[23,     3] loss: 1.164
[24,     3] loss: 1.068
[25,     3] loss: 1.097
[26,     3] loss: 1.026
[27,     3] loss: 1.055
[28,     3] loss: 1.014
[29,     3] loss: 1.029
[30,     3] loss: 0.968
[31,     3] loss: 0.990
[32,     3] loss: 1.007
[33,     3] loss: 1.030
[34,     3] loss: 0.966
[35,     3] loss: 0.935
[36,     3] loss: 0.904
[37,     3] loss: 0.990
[38,     3] loss: 0.919
[39,     3] loss: 0.852
[40,     3] loss: 0.851
[41,     3] loss: 0.859
[42,     3] loss: 0.910
[43,     3] loss: 0.904
[44,     3] loss: 0.868
[45,     3] loss: 0.955
[46,     3] loss: 0.831
[47,     3] loss: 0.814
[48,     3] loss: 0.870
[49,     3] loss: 0.776
[50,     3] loss: 0.851
[51,     3] loss: 0.894
[52,     3] loss: 0.839
[53,     3] loss: 0.879
[54,     3] loss: 0.877
[55,     3] loss: 0.817
[56,     3] loss: 0.769
[57,     3] loss: 0.798
[58,     3] loss: 0.837
[59,     3] loss: 0.824
[60,     3] loss: 0.762
[61,     3] loss: 0.774
[62,     3] loss: 0.785
[63,     3] loss: 0.757
[64,     3] loss: 0.833
[65,     3] loss: 0.789
[66,     3] loss: 0.876
[67,     3] loss: 0.819
[68,     3] loss: 0.798
[69,     3] loss: 0.782
[70,     3] loss: 0.931
[71,     3] loss: 0.937
[72,     3] loss: 0.815
[73,     3] loss: 0.831
[74,     3] loss: 0.834
[75,     3] loss: 0.761
[76,     3] loss: 0.791
[77,     3] loss: 0.787
[78,     3] loss: 0.816
[79,     3] loss: 0.801
[80,     3] loss: 0.775
Early stopping applied (best metric=0.5265370607376099)
Finished Training
Total time taken: 22.2100830078125
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.385
[3,     3] loss: 1.387
[4,     3] loss: 1.381
[5,     3] loss: 1.379
[6,     3] loss: 1.374
[7,     3] loss: 1.384
[8,     3] loss: 1.380
[9,     3] loss: 1.369
[10,     3] loss: 1.361
[11,     3] loss: 1.351
[12,     3] loss: 1.332
[13,     3] loss: 1.316
[14,     3] loss: 1.289
[15,     3] loss: 1.260
[16,     3] loss: 1.257
[17,     3] loss: 1.294
[18,     3] loss: 1.240
[19,     3] loss: 1.168
[20,     3] loss: 1.185
[21,     3] loss: 1.153
[22,     3] loss: 1.194
[23,     3] loss: 1.087
[24,     3] loss: 1.179
[25,     3] loss: 1.115
[26,     3] loss: 1.136
[27,     3] loss: 1.075
[28,     3] loss: 1.048
[29,     3] loss: 1.040
[30,     3] loss: 1.008
[31,     3] loss: 1.053
[32,     3] loss: 0.985
[33,     3] loss: 1.028
[34,     3] loss: 0.990
[35,     3] loss: 0.945
[36,     3] loss: 1.033
[37,     3] loss: 0.927
[38,     3] loss: 0.961
[39,     3] loss: 0.971
[40,     3] loss: 0.911
[41,     3] loss: 1.076
[42,     3] loss: 0.891
[43,     3] loss: 0.919
[44,     3] loss: 0.892
[45,     3] loss: 0.877
[46,     3] loss: 0.830
[47,     3] loss: 0.995
[48,     3] loss: 0.921
[49,     3] loss: 0.941
[50,     3] loss: 0.904
[51,     3] loss: 0.875
[52,     3] loss: 0.827
[53,     3] loss: 0.861
[54,     3] loss: 0.986
[55,     3] loss: 0.821
[56,     3] loss: 0.867
[57,     3] loss: 0.826
[58,     3] loss: 0.806
[59,     3] loss: 0.808
[60,     3] loss: 0.845
[61,     3] loss: 0.902
[62,     3] loss: 0.858
[63,     3] loss: 0.826
[64,     3] loss: 0.848
[65,     3] loss: 0.790
[66,     3] loss: 0.814
[67,     3] loss: 0.928
[68,     3] loss: 0.808
[69,     3] loss: 0.842
[70,     3] loss: 0.798
[71,     3] loss: 0.911
[72,     3] loss: 0.855
[73,     3] loss: 0.874
[74,     3] loss: 0.887
[75,     3] loss: 0.825
[76,     3] loss: 0.779
[77,     3] loss: 0.772
[78,     3] loss: 0.801
[79,     3] loss: 0.768
[80,     3] loss: 0.807
[81,     3] loss: 0.805
[82,     3] loss: 0.780
[83,     3] loss: 0.769
[84,     3] loss: 0.773
[85,     3] loss: 0.780
[86,     3] loss: 0.754
[87,     3] loss: 0.787
[88,     3] loss: 0.858
[89,     3] loss: 0.747
[90,     3] loss: 0.764
[91,     3] loss: 0.763
[92,     3] loss: 0.780
[93,     3] loss: 0.778
[94,     3] loss: 0.767
[95,     3] loss: 0.775
[96,     3] loss: 0.878
[97,     3] loss: 0.886
[98,     3] loss: 0.773
[99,     3] loss: 0.764
[100,     3] loss: 0.818
[101,     3] loss: 0.789
[102,     3] loss: 0.746
[103,     3] loss: 0.763
Early stopping applied (best metric=0.5380376577377319)
Finished Training
Total time taken: 28.58010697364807
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.390
[3,     3] loss: 1.384
[4,     3] loss: 1.383
[5,     3] loss: 1.385
[6,     3] loss: 1.386
[7,     3] loss: 1.386
[8,     3] loss: 1.389
[9,     3] loss: 1.374
[10,     3] loss: 1.378
[11,     3] loss: 1.371
[12,     3] loss: 1.356
[13,     3] loss: 1.366
[14,     3] loss: 1.335
[15,     3] loss: 1.314
[16,     3] loss: 1.290
[17,     3] loss: 1.266
[18,     3] loss: 1.249
[19,     3] loss: 1.232
[20,     3] loss: 1.207
[21,     3] loss: 1.228
[22,     3] loss: 1.150
[23,     3] loss: 1.136
[24,     3] loss: 1.183
[25,     3] loss: 1.094
[26,     3] loss: 1.119
[27,     3] loss: 1.069
[28,     3] loss: 1.108
[29,     3] loss: 1.045
[30,     3] loss: 1.006
[31,     3] loss: 1.130
[32,     3] loss: 0.984
[33,     3] loss: 0.946
[34,     3] loss: 0.978
[35,     3] loss: 0.908
[36,     3] loss: 0.941
[37,     3] loss: 0.934
[38,     3] loss: 0.917
[39,     3] loss: 0.961
[40,     3] loss: 0.972
[41,     3] loss: 0.888
[42,     3] loss: 0.986
[43,     3] loss: 0.931
[44,     3] loss: 0.869
[45,     3] loss: 0.856
[46,     3] loss: 0.869
[47,     3] loss: 0.897
[48,     3] loss: 0.886
[49,     3] loss: 0.938
[50,     3] loss: 0.888
[51,     3] loss: 0.900
[52,     3] loss: 0.912
[53,     3] loss: 0.809
[54,     3] loss: 0.792
[55,     3] loss: 0.892
[56,     3] loss: 0.991
[57,     3] loss: 1.024
[58,     3] loss: 0.827
[59,     3] loss: 0.848
[60,     3] loss: 0.858
[61,     3] loss: 0.858
[62,     3] loss: 0.862
[63,     3] loss: 0.803
[64,     3] loss: 0.818
[65,     3] loss: 0.854
[66,     3] loss: 0.968
[67,     3] loss: 0.832
[68,     3] loss: 0.820
[69,     3] loss: 0.814
[70,     3] loss: 0.873
[71,     3] loss: 0.828
[72,     3] loss: 0.780
[73,     3] loss: 0.811
[74,     3] loss: 0.755
[75,     3] loss: 0.850
[76,     3] loss: 0.785
[77,     3] loss: 0.766
[78,     3] loss: 0.747
[79,     3] loss: 0.753
[80,     3] loss: 0.750
[81,     3] loss: 0.849
[82,     3] loss: 0.750
[83,     3] loss: 0.749
[84,     3] loss: 0.729
[85,     3] loss: 0.728
[86,     3] loss: 0.746
[87,     3] loss: 0.720
[88,     3] loss: 0.739
[89,     3] loss: 0.730
Early stopping applied (best metric=0.5225006937980652)
Finished Training
Total time taken: 24.696091175079346
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.388
[3,     3] loss: 1.377
[4,     3] loss: 1.383
[5,     3] loss: 1.396
[6,     3] loss: 1.385
[7,     3] loss: 1.380
[8,     3] loss: 1.377
[9,     3] loss: 1.374
[10,     3] loss: 1.383
[11,     3] loss: 1.393
[12,     3] loss: 1.379
[13,     3] loss: 1.382
[14,     3] loss: 1.366
[15,     3] loss: 1.360
[16,     3] loss: 1.362
[17,     3] loss: 1.359
[18,     3] loss: 1.345
[19,     3] loss: 1.328
[20,     3] loss: 1.289
[21,     3] loss: 1.311
[22,     3] loss: 1.266
[23,     3] loss: 1.267
[24,     3] loss: 1.233
[25,     3] loss: 1.248
[26,     3] loss: 1.206
[27,     3] loss: 1.137
[28,     3] loss: 1.217
[29,     3] loss: 1.114
[30,     3] loss: 1.059
[31,     3] loss: 1.099
[32,     3] loss: 1.193
[33,     3] loss: 1.120
[34,     3] loss: 1.017
[35,     3] loss: 1.073
[36,     3] loss: 0.997
[37,     3] loss: 0.993
[38,     3] loss: 0.955
[39,     3] loss: 0.922
[40,     3] loss: 0.967
[41,     3] loss: 1.064
[42,     3] loss: 0.898
[43,     3] loss: 0.865
[44,     3] loss: 0.871
[45,     3] loss: 0.933
[46,     3] loss: 0.869
[47,     3] loss: 0.886
[48,     3] loss: 0.845
[49,     3] loss: 0.845
[50,     3] loss: 0.818
[51,     3] loss: 0.842
[52,     3] loss: 0.829
[53,     3] loss: 0.851
[54,     3] loss: 0.817
[55,     3] loss: 0.797
[56,     3] loss: 0.782
[57,     3] loss: 0.868
[58,     3] loss: 0.884
[59,     3] loss: 0.796
[60,     3] loss: 0.860
[61,     3] loss: 0.821
[62,     3] loss: 0.855
[63,     3] loss: 0.951
[64,     3] loss: 0.755
[65,     3] loss: 0.845
[66,     3] loss: 0.813
[67,     3] loss: 0.790
[68,     3] loss: 0.845
[69,     3] loss: 0.917
[70,     3] loss: 0.958
[71,     3] loss: 0.771
[72,     3] loss: 1.125
[73,     3] loss: 0.779
[74,     3] loss: 0.979
[75,     3] loss: 0.899
[76,     3] loss: 0.814
[77,     3] loss: 0.797
[78,     3] loss: 0.841
[79,     3] loss: 0.798
[80,     3] loss: 0.808
[81,     3] loss: 0.779
[82,     3] loss: 0.746
[83,     3] loss: 0.755
[84,     3] loss: 0.764
[85,     3] loss: 0.760
[86,     3] loss: 0.746
[87,     3] loss: 0.731
[88,     3] loss: 0.749
[89,     3] loss: 0.795
[90,     3] loss: 0.728
[91,     3] loss: 0.784
[92,     3] loss: 0.791
[93,     3] loss: 0.739
[94,     3] loss: 0.726
[95,     3] loss: 0.777
[96,     3] loss: 0.829
[97,     3] loss: 0.740
[98,     3] loss: 0.745
Early stopping applied (best metric=0.4957037568092346)
Finished Training
Total time taken: 27.262098789215088
{'S-palmitoylation-C Validation Accuracy': 0.7102981782894446, 'S-palmitoylation-C Validation Sensitivity': 0.21372937293729372, 'S-palmitoylation-C Validation Specificity': 0.834773097827203, 'S-palmitoylation-C Validation Precision': 0.24554194555595776, 'S-palmitoylation-C AUC ROC': 0.5465080850526671, 'S-palmitoylation-C AUC PR': 0.22923578440282194, 'S-palmitoylation-C MCC': 0.0511162844904748, 'S-palmitoylation-C F1': 0.22313608722548287, 'Validation Loss (S-palmitoylation-C)': 0.5537530859311421, 'Hydroxylation-K Validation Accuracy': 0.7112293144208037, 'Hydroxylation-K Validation Sensitivity': 0.7711111111111111, 'Hydroxylation-K Validation Specificity': 0.6964912280701755, 'Hydroxylation-K Validation Precision': 0.4024959742351047, 'Hydroxylation-K AUC ROC': 0.8176413255360624, 'Hydroxylation-K AUC PR': 0.5787210570216746, 'Hydroxylation-K MCC': 0.3906030052417142, 'Hydroxylation-K F1': 0.522703167303235, 'Validation Loss (Hydroxylation-K)': 0.517390372355779, 'Validation Loss (total)': 1.0711434682210286, 'TimeToTrain': 24.50682430267334}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002715544409748247,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21765920456362192,
 'loss_weight_S-palmitoylation-C': 0.07238994932611409,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3656093788,
 'sample_weights': [0.18180719547455226, 0.35977982722522495],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.126968706038755,
 'weight_decay_Hydroxylation-K': 2.2835221682857876,
 'weight_decay_S-palmitoylation-C': 1.094587887865273}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.395
[3,     3] loss: 1.393
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023563262034718936,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9801125526544474,
 'loss_weight_S-palmitoylation-C': 0.13514653133865318,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 332960284,
 'sample_weights': [0.07238994932611409, 0.21765920456362192],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.410611593108089,
 'weight_decay_Hydroxylation-K': 3.029946257420352,
 'weight_decay_S-palmitoylation-C': 6.089861009124907}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.374
[3,     3] loss: 1.404
[4,     3] loss: 1.389
[5,     3] loss: 1.372
[6,     3] loss: 1.379
[7,     3] loss: 1.361
[8,     3] loss: 1.355
[9,     3] loss: 1.335
[10,     3] loss: 1.267
[11,     3] loss: 1.269
[12,     3] loss: 1.260
[13,     3] loss: 1.185
[14,     3] loss: 1.187
[15,     3] loss: 1.169
[16,     3] loss: 1.112
[17,     3] loss: 1.032
[18,     3] loss: 1.104
[19,     3] loss: 1.012
[20,     3] loss: 1.033
[21,     3] loss: 1.066
[22,     3] loss: 1.086
[23,     3] loss: 1.107
[24,     3] loss: 1.025
[25,     3] loss: 1.108
[26,     3] loss: 1.117
[27,     3] loss: 0.975
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030366304930245142,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5943499529298057,
 'loss_weight_S-palmitoylation-C': 0.6346783067192421,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1922091343,
 'sample_weights': [0.13514653133865318, 0.9801125526544474],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.178888440597774,
 'weight_decay_Hydroxylation-K': 2.4126101529267165,
 'weight_decay_S-palmitoylation-C': 0.04388905716855973}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.385
[3,     3] loss: 1.389
[4,     3] loss: 1.386
[5,     3] loss: 1.383
[6,     3] loss: 1.383
[7,     3] loss: 1.388
[8,     3] loss: 1.386
[9,     3] loss: 1.379
[10,     3] loss: 1.396
[11,     3] loss: 1.384
[12,     3] loss: 1.382
[13,     3] loss: 1.377
[14,     3] loss: 1.345
[15,     3] loss: 1.344
[16,     3] loss: 1.314
[17,     3] loss: 1.265
[18,     3] loss: 1.244
[19,     3] loss: 1.265
[20,     3] loss: 1.151
[21,     3] loss: 1.113
[22,     3] loss: 1.158
[23,     3] loss: 1.291
[24,     3] loss: 1.153
[25,     3] loss: 1.066
[26,     3] loss: 1.037
[27,     3] loss: 1.050
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009752448072702074,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8850975420230548,
 'loss_weight_S-palmitoylation-C': 0.6712956733072399,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 902175988,
 'sample_weights': [0.6346783067192421, 0.5943499529298057],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.638125432690325,
 'weight_decay_Hydroxylation-K': 3.1593845150056925,
 'weight_decay_S-palmitoylation-C': 1.9888982254878114}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.374
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004515808428250363,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.25165203688950255,
 'loss_weight_S-palmitoylation-C': 0.31621115859069665,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3243853179,
 'sample_weights': [0.6712956733072399, 0.8850975420230548],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.992327450901745,
 'weight_decay_Hydroxylation-K': 0.49671274281108946,
 'weight_decay_S-palmitoylation-C': 0.367116006166881}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.396
[3,     3] loss: 1.385
[4,     3] loss: 1.396
[5,     3] loss: 1.380
[6,     3] loss: 1.390
[7,     3] loss: 1.381
[8,     3] loss: 1.374
[9,     3] loss: 1.388
[10,     3] loss: 1.377
[11,     3] loss: 1.385
[12,     3] loss: 1.374
[13,     3] loss: 1.380
[14,     3] loss: 1.373
[15,     3] loss: 1.330
[16,     3] loss: 1.321
[17,     3] loss: 1.317
[18,     3] loss: 1.281
[19,     3] loss: 1.247
[20,     3] loss: 1.145
[21,     3] loss: 1.283
[22,     3] loss: 1.289
[23,     3] loss: 1.253
[24,     3] loss: 1.171
[25,     3] loss: 1.215
[26,     3] loss: 1.096
[27,     3] loss: 1.119
[28,     3] loss: 1.159
[29,     3] loss: 1.089
[30,     3] loss: 0.963
[31,     3] loss: 1.054
[32,     3] loss: 0.957
[33,     3] loss: 1.085
[34,     3] loss: 1.094
[35,     3] loss: 1.085
[36,     3] loss: 0.953
[37,     3] loss: 1.004
[38,     3] loss: 0.977
[39,     3] loss: 0.875
[40,     3] loss: 0.845
[41,     3] loss: 0.861
[42,     3] loss: 0.833
[43,     3] loss: 0.828
[44,     3] loss: 0.754
[45,     3] loss: 0.875
[46,     3] loss: 1.142
[47,     3] loss: 1.060
[48,     3] loss: 0.983
[49,     3] loss: 1.029
[50,     3] loss: 0.950
[51,     3] loss: 0.863
[52,     3] loss: 0.824
[53,     3] loss: 0.840
[54,     3] loss: 0.773
[55,     3] loss: 0.916
[56,     3] loss: 0.818
[57,     3] loss: 0.803
[58,     3] loss: 0.850
[59,     3] loss: 0.832
[60,     3] loss: 0.943
[61,     3] loss: 0.866
[62,     3] loss: 0.871
[63,     3] loss: 0.809
[64,     3] loss: 0.797
[65,     3] loss: 0.801
[66,     3] loss: 0.838
[67,     3] loss: 0.821
[68,     3] loss: 0.785
[69,     3] loss: 0.871
Early stopping applied (best metric=0.5239099860191345)
Finished Training
Total time taken: 19.215071201324463
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.403
[3,     3] loss: 1.392
[4,     3] loss: 1.392
[5,     3] loss: 1.389
[6,     3] loss: 1.385
[7,     3] loss: 1.377
[8,     3] loss: 1.376
[9,     3] loss: 1.391
[10,     3] loss: 1.373
[11,     3] loss: 1.367
[12,     3] loss: 1.396
[13,     3] loss: 1.356
[14,     3] loss: 1.338
[15,     3] loss: 1.333
[16,     3] loss: 1.330
[17,     3] loss: 1.207
[18,     3] loss: 1.227
[19,     3] loss: 1.109
[20,     3] loss: 1.150
[21,     3] loss: 1.065
[22,     3] loss: 1.174
[23,     3] loss: 1.189
[24,     3] loss: 1.152
[25,     3] loss: 1.241
[26,     3] loss: 1.186
[27,     3] loss: 1.127
[28,     3] loss: 1.127
[29,     3] loss: 1.156
[30,     3] loss: 1.019
[31,     3] loss: 0.981
[32,     3] loss: 1.024
[33,     3] loss: 0.940
[34,     3] loss: 1.041
[35,     3] loss: 1.018
[36,     3] loss: 1.056
[37,     3] loss: 0.916
[38,     3] loss: 0.996
[39,     3] loss: 0.933
[40,     3] loss: 0.939
[41,     3] loss: 0.889
[42,     3] loss: 0.840
[43,     3] loss: 0.876
[44,     3] loss: 0.817
[45,     3] loss: 0.824
[46,     3] loss: 0.924
[47,     3] loss: 1.181
[48,     3] loss: 0.924
[49,     3] loss: 1.017
[50,     3] loss: 1.049
[51,     3] loss: 0.936
[52,     3] loss: 0.876
[53,     3] loss: 0.786
[54,     3] loss: 0.827
[55,     3] loss: 0.942
[56,     3] loss: 0.829
[57,     3] loss: 0.835
[58,     3] loss: 1.268
[59,     3] loss: 0.865
[60,     3] loss: 0.919
[61,     3] loss: 0.958
[62,     3] loss: 1.046
[63,     3] loss: 0.911
[64,     3] loss: 0.862
[65,     3] loss: 0.851
[66,     3] loss: 0.804
[67,     3] loss: 0.809
[68,     3] loss: 0.737
[69,     3] loss: 0.753
[70,     3] loss: 0.790
[71,     3] loss: 0.764
[72,     3] loss: 0.769
[73,     3] loss: 0.828
[74,     3] loss: 1.413
[75,     3] loss: 1.082
[76,     3] loss: 1.109
[77,     3] loss: 0.980
[78,     3] loss: 0.966
[79,     3] loss: 1.246
[80,     3] loss: 1.004
[81,     3] loss: 0.983
Early stopping applied (best metric=0.5341572761535645)
Finished Training
Total time taken: 22.530085802078247
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.396
[3,     3] loss: 1.381
[4,     3] loss: 1.389
[5,     3] loss: 1.385
[6,     3] loss: 1.384
[7,     3] loss: 1.390
[8,     3] loss: 1.392
[9,     3] loss: 1.380
[10,     3] loss: 1.394
[11,     3] loss: 1.391
[12,     3] loss: 1.388
[13,     3] loss: 1.386
[14,     3] loss: 1.380
[15,     3] loss: 1.388
[16,     3] loss: 1.400
[17,     3] loss: 1.383
[18,     3] loss: 1.384
[19,     3] loss: 1.378
[20,     3] loss: 1.381
[21,     3] loss: 1.366
[22,     3] loss: 1.336
[23,     3] loss: 1.311
[24,     3] loss: 1.270
[25,     3] loss: 1.270
[26,     3] loss: 1.295
[27,     3] loss: 1.260
[28,     3] loss: 1.223
[29,     3] loss: 1.167
[30,     3] loss: 1.231
[31,     3] loss: 1.198
[32,     3] loss: 1.134
[33,     3] loss: 1.142
[34,     3] loss: 1.116
[35,     3] loss: 1.201
[36,     3] loss: 1.068
[37,     3] loss: 1.049
[38,     3] loss: 1.175
[39,     3] loss: 1.137
[40,     3] loss: 1.100
[41,     3] loss: 0.998
[42,     3] loss: 1.090
[43,     3] loss: 1.031
[44,     3] loss: 0.967
[45,     3] loss: 0.929
[46,     3] loss: 1.135
[47,     3] loss: 1.012
[48,     3] loss: 0.936
[49,     3] loss: 0.966
[50,     3] loss: 0.877
[51,     3] loss: 0.935
[52,     3] loss: 1.032
[53,     3] loss: 1.056
[54,     3] loss: 1.020
[55,     3] loss: 1.084
[56,     3] loss: 1.044
[57,     3] loss: 0.954
[58,     3] loss: 0.971
[59,     3] loss: 0.861
[60,     3] loss: 0.806
[61,     3] loss: 0.786
[62,     3] loss: 0.780
[63,     3] loss: 0.800
[64,     3] loss: 0.948
[65,     3] loss: 0.882
[66,     3] loss: 0.775
[67,     3] loss: 0.786
[68,     3] loss: 0.785
[69,     3] loss: 0.787
[70,     3] loss: 0.764
[71,     3] loss: 0.765
[72,     3] loss: 0.857
[73,     3] loss: 0.848
[74,     3] loss: 0.974
[75,     3] loss: 0.876
[76,     3] loss: 0.906
[77,     3] loss: 0.880
[78,     3] loss: 0.969
[79,     3] loss: 0.990
[80,     3] loss: 0.846
[81,     3] loss: 0.807
[82,     3] loss: 0.811
[83,     3] loss: 0.766
Early stopping applied (best metric=0.5268082022666931)
Finished Training
Total time taken: 23.178085803985596
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.389
[3,     3] loss: 1.385
[4,     3] loss: 1.383
[5,     3] loss: 1.381
[6,     3] loss: 1.387
[7,     3] loss: 1.387
[8,     3] loss: 1.378
[9,     3] loss: 1.394
[10,     3] loss: 1.384
[11,     3] loss: 1.376
[12,     3] loss: 1.377
[13,     3] loss: 1.382
[14,     3] loss: 1.349
[15,     3] loss: 1.336
[16,     3] loss: 1.333
[17,     3] loss: 1.265
[18,     3] loss: 1.223
[19,     3] loss: 1.261
[20,     3] loss: 1.137
[21,     3] loss: 1.167
[22,     3] loss: 1.152
[23,     3] loss: 1.053
[24,     3] loss: 1.140
[25,     3] loss: 1.044
[26,     3] loss: 1.133
[27,     3] loss: 1.090
[28,     3] loss: 1.002
[29,     3] loss: 1.028
[30,     3] loss: 1.022
[31,     3] loss: 0.924
[32,     3] loss: 0.995
[33,     3] loss: 0.947
[34,     3] loss: 0.997
[35,     3] loss: 1.049
[36,     3] loss: 0.986
[37,     3] loss: 0.992
[38,     3] loss: 0.927
[39,     3] loss: 0.944
[40,     3] loss: 1.019
[41,     3] loss: 0.861
[42,     3] loss: 0.849
[43,     3] loss: 0.811
[44,     3] loss: 0.841
[45,     3] loss: 0.829
[46,     3] loss: 0.805
[47,     3] loss: 0.813
[48,     3] loss: 0.880
[49,     3] loss: 0.869
[50,     3] loss: 0.867
[51,     3] loss: 0.832
[52,     3] loss: 0.787
[53,     3] loss: 0.799
[54,     3] loss: 0.780
[55,     3] loss: 1.077
[56,     3] loss: 0.879
[57,     3] loss: 0.822
[58,     3] loss: 0.907
[59,     3] loss: 0.796
[60,     3] loss: 0.782
[61,     3] loss: 0.889
[62,     3] loss: 0.762
[63,     3] loss: 0.815
[64,     3] loss: 0.938
[65,     3] loss: 0.891
[66,     3] loss: 0.860
[67,     3] loss: 0.816
[68,     3] loss: 0.803
[69,     3] loss: 0.848
[70,     3] loss: 0.750
[71,     3] loss: 0.788
[72,     3] loss: 0.761
[73,     3] loss: 0.902
[74,     3] loss: 1.099
[75,     3] loss: 0.896
[76,     3] loss: 0.941
[77,     3] loss: 0.866
[78,     3] loss: 0.935
[79,     3] loss: 0.811
[80,     3] loss: 0.777
Early stopping applied (best metric=0.4940744936466217)
Finished Training
Total time taken: 22.116081714630127
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.405
[3,     3] loss: 1.390
[4,     3] loss: 1.384
[5,     3] loss: 1.383
[6,     3] loss: 1.389
[7,     3] loss: 1.379
[8,     3] loss: 1.385
[9,     3] loss: 1.375
[10,     3] loss: 1.360
[11,     3] loss: 1.358
[12,     3] loss: 1.348
[13,     3] loss: 1.281
[14,     3] loss: 1.282
[15,     3] loss: 1.330
[16,     3] loss: 1.271
[17,     3] loss: 1.238
[18,     3] loss: 1.366
[19,     3] loss: 1.272
[20,     3] loss: 1.249
[21,     3] loss: 1.232
[22,     3] loss: 1.192
[23,     3] loss: 1.206
[24,     3] loss: 1.143
[25,     3] loss: 1.224
[26,     3] loss: 1.139
[27,     3] loss: 1.071
[28,     3] loss: 1.145
[29,     3] loss: 1.181
[30,     3] loss: 1.103
[31,     3] loss: 1.086
[32,     3] loss: 1.035
[33,     3] loss: 1.003
[34,     3] loss: 0.952
[35,     3] loss: 1.002
[36,     3] loss: 0.882
[37,     3] loss: 0.898
[38,     3] loss: 1.019
[39,     3] loss: 0.920
[40,     3] loss: 0.918
[41,     3] loss: 0.997
[42,     3] loss: 0.869
[43,     3] loss: 0.989
[44,     3] loss: 0.889
[45,     3] loss: 0.827
[46,     3] loss: 0.796
[47,     3] loss: 0.794
[48,     3] loss: 0.836
[49,     3] loss: 0.807
[50,     3] loss: 0.876
[51,     3] loss: 1.205
[52,     3] loss: 1.115
[53,     3] loss: 1.081
[54,     3] loss: 0.983
[55,     3] loss: 0.964
[56,     3] loss: 0.964
[57,     3] loss: 0.915
[58,     3] loss: 0.820
[59,     3] loss: 0.783
[60,     3] loss: 0.822
[61,     3] loss: 1.148
[62,     3] loss: 0.802
[63,     3] loss: 0.833
[64,     3] loss: 0.957
[65,     3] loss: 0.935
[66,     3] loss: 0.841
[67,     3] loss: 0.811
[68,     3] loss: 0.790
[69,     3] loss: 0.763
[70,     3] loss: 0.808
[71,     3] loss: 0.738
[72,     3] loss: 0.777
[73,     3] loss: 0.886
[74,     3] loss: 0.847
[75,     3] loss: 0.855
[76,     3] loss: 0.862
[77,     3] loss: 0.772
[78,     3] loss: 0.773
[79,     3] loss: 0.990
[80,     3] loss: 0.795
[81,     3] loss: 0.953
[82,     3] loss: 0.898
[83,     3] loss: 0.832
[84,     3] loss: 0.824
[85,     3] loss: 0.779
Early stopping applied (best metric=0.5049089193344116)
Finished Training
Total time taken: 23.301085710525513
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.378
[3,     3] loss: 1.391
[4,     3] loss: 1.369
[5,     3] loss: 1.377
[6,     3] loss: 1.391
[7,     3] loss: 1.400
[8,     3] loss: 1.395
[9,     3] loss: 1.387
[10,     3] loss: 1.384
[11,     3] loss: 1.388
[12,     3] loss: 1.388
[13,     3] loss: 1.381
[14,     3] loss: 1.381
[15,     3] loss: 1.387
[16,     3] loss: 1.388
[17,     3] loss: 1.373
[18,     3] loss: 1.379
[19,     3] loss: 1.389
[20,     3] loss: 1.379
[21,     3] loss: 1.332
[22,     3] loss: 1.397
[23,     3] loss: 1.347
[24,     3] loss: 1.310
[25,     3] loss: 1.340
[26,     3] loss: 1.278
[27,     3] loss: 1.200
[28,     3] loss: 1.177
[29,     3] loss: 1.171
[30,     3] loss: 1.167
[31,     3] loss: 1.368
[32,     3] loss: 1.221
[33,     3] loss: 1.170
[34,     3] loss: 1.112
[35,     3] loss: 1.128
[36,     3] loss: 1.127
[37,     3] loss: 1.036
[38,     3] loss: 1.117
[39,     3] loss: 1.064
[40,     3] loss: 1.036
[41,     3] loss: 1.086
[42,     3] loss: 0.989
[43,     3] loss: 0.952
[44,     3] loss: 0.912
[45,     3] loss: 0.897
[46,     3] loss: 0.923
[47,     3] loss: 1.076
[48,     3] loss: 1.133
[49,     3] loss: 1.039
[50,     3] loss: 1.062
[51,     3] loss: 1.070
[52,     3] loss: 0.989
[53,     3] loss: 1.033
[54,     3] loss: 1.003
[55,     3] loss: 0.994
[56,     3] loss: 0.928
[57,     3] loss: 0.943
[58,     3] loss: 0.883
[59,     3] loss: 1.010
[60,     3] loss: 0.879
[61,     3] loss: 0.802
[62,     3] loss: 0.867
[63,     3] loss: 0.826
[64,     3] loss: 0.817
[65,     3] loss: 0.868
[66,     3] loss: 0.834
[67,     3] loss: 1.366
[68,     3] loss: 1.129
[69,     3] loss: 1.039
[70,     3] loss: 1.011
[71,     3] loss: 0.957
[72,     3] loss: 1.022
[73,     3] loss: 1.016
[74,     3] loss: 0.881
[75,     3] loss: 0.919
[76,     3] loss: 0.867
[77,     3] loss: 0.834
[78,     3] loss: 0.837
Early stopping applied (best metric=0.5287801027297974)
Finished Training
Total time taken: 21.669077157974243
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.390
[3,     3] loss: 1.385
[4,     3] loss: 1.388
[5,     3] loss: 1.388
[6,     3] loss: 1.376
[7,     3] loss: 1.372
[8,     3] loss: 1.371
[9,     3] loss: 1.422
[10,     3] loss: 1.385
[11,     3] loss: 1.379
[12,     3] loss: 1.385
[13,     3] loss: 1.377
[14,     3] loss: 1.370
[15,     3] loss: 1.342
[16,     3] loss: 1.293
[17,     3] loss: 1.229
[18,     3] loss: 1.170
[19,     3] loss: 1.354
[20,     3] loss: 1.395
[21,     3] loss: 1.338
[22,     3] loss: 1.284
[23,     3] loss: 1.271
[24,     3] loss: 1.259
[25,     3] loss: 1.272
[26,     3] loss: 1.240
[27,     3] loss: 1.250
[28,     3] loss: 1.182
[29,     3] loss: 1.102
[30,     3] loss: 1.125
[31,     3] loss: 1.253
[32,     3] loss: 1.166
[33,     3] loss: 1.110
[34,     3] loss: 1.109
[35,     3] loss: 1.154
[36,     3] loss: 1.056
[37,     3] loss: 1.038
[38,     3] loss: 1.064
[39,     3] loss: 1.033
[40,     3] loss: 1.064
[41,     3] loss: 1.010
[42,     3] loss: 0.942
[43,     3] loss: 1.118
[44,     3] loss: 0.960
[45,     3] loss: 0.971
[46,     3] loss: 0.918
[47,     3] loss: 0.911
[48,     3] loss: 0.902
[49,     3] loss: 0.881
[50,     3] loss: 1.291
[51,     3] loss: 1.119
[52,     3] loss: 1.101
[53,     3] loss: 1.047
[54,     3] loss: 1.044
[55,     3] loss: 0.953
[56,     3] loss: 0.996
[57,     3] loss: 1.005
[58,     3] loss: 0.970
[59,     3] loss: 0.935
[60,     3] loss: 0.841
[61,     3] loss: 0.876
[62,     3] loss: 0.935
[63,     3] loss: 1.020
[64,     3] loss: 0.835
[65,     3] loss: 0.876
[66,     3] loss: 0.870
[67,     3] loss: 0.883
[68,     3] loss: 0.827
[69,     3] loss: 0.815
[70,     3] loss: 0.847
[71,     3] loss: 0.801
[72,     3] loss: 0.828
[73,     3] loss: 0.785
[74,     3] loss: 0.928
[75,     3] loss: 0.936
[76,     3] loss: 0.997
[77,     3] loss: 0.919
[78,     3] loss: 0.888
[79,     3] loss: 0.972
[80,     3] loss: 0.918
[81,     3] loss: 0.801
[82,     3] loss: 0.829
[83,     3] loss: 0.828
[84,     3] loss: 0.802
Early stopping applied (best metric=0.5226691365242004)
Finished Training
Total time taken: 23.210086345672607
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.396
[3,     3] loss: 1.375
[4,     3] loss: 1.374
[5,     3] loss: 1.415
[6,     3] loss: 1.388
[7,     3] loss: 1.400
[8,     3] loss: 1.394
[9,     3] loss: 1.394
[10,     3] loss: 1.385
[11,     3] loss: 1.379
[12,     3] loss: 1.380
[13,     3] loss: 1.384
[14,     3] loss: 1.376
[15,     3] loss: 1.373
[16,     3] loss: 1.377
[17,     3] loss: 1.353
[18,     3] loss: 1.311
[19,     3] loss: 1.208
[20,     3] loss: 1.133
[21,     3] loss: 1.382
[22,     3] loss: 1.141
[23,     3] loss: 1.275
[24,     3] loss: 1.106
[25,     3] loss: 1.120
[26,     3] loss: 1.084
[27,     3] loss: 1.051
[28,     3] loss: 1.134
[29,     3] loss: 1.194
[30,     3] loss: 1.089
[31,     3] loss: 1.054
[32,     3] loss: 1.118
[33,     3] loss: 0.935
[34,     3] loss: 0.998
[35,     3] loss: 0.992
[36,     3] loss: 0.902
[37,     3] loss: 0.949
[38,     3] loss: 0.958
[39,     3] loss: 0.904
[40,     3] loss: 0.980
[41,     3] loss: 0.810
[42,     3] loss: 0.869
[43,     3] loss: 0.975
[44,     3] loss: 0.862
[45,     3] loss: 0.845
[46,     3] loss: 0.929
[47,     3] loss: 0.807
[48,     3] loss: 0.754
[49,     3] loss: 0.794
[50,     3] loss: 1.097
[51,     3] loss: 0.980
[52,     3] loss: 0.926
[53,     3] loss: 0.926
[54,     3] loss: 0.874
[55,     3] loss: 0.957
[56,     3] loss: 0.906
[57,     3] loss: 0.996
[58,     3] loss: 0.979
[59,     3] loss: 0.987
[60,     3] loss: 0.831
[61,     3] loss: 0.801
[62,     3] loss: 0.791
[63,     3] loss: 0.758
[64,     3] loss: 0.781
[65,     3] loss: 0.861
[66,     3] loss: 0.797
[67,     3] loss: 0.840
[68,     3] loss: 1.170
[69,     3] loss: 1.041
Early stopping applied (best metric=0.5392253994941711)
Finished Training
Total time taken: 19.11207103729248
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.395
[3,     3] loss: 1.390
[4,     3] loss: 1.377
[5,     3] loss: 1.383
[6,     3] loss: 1.377
[7,     3] loss: 1.379
[8,     3] loss: 1.378
[9,     3] loss: 1.351
[10,     3] loss: 1.338
[11,     3] loss: 1.323
[12,     3] loss: 1.239
[13,     3] loss: 1.202
[14,     3] loss: 1.295
[15,     3] loss: 1.232
[16,     3] loss: 1.213
[17,     3] loss: 1.274
[18,     3] loss: 1.258
[19,     3] loss: 1.163
[20,     3] loss: 1.146
[21,     3] loss: 1.089
[22,     3] loss: 1.057
[23,     3] loss: 1.033
[24,     3] loss: 0.989
[25,     3] loss: 1.134
[26,     3] loss: 1.050
[27,     3] loss: 1.070
[28,     3] loss: 0.948
[29,     3] loss: 0.938
[30,     3] loss: 0.947
[31,     3] loss: 1.261
[32,     3] loss: 1.242
[33,     3] loss: 1.071
[34,     3] loss: 1.119
[35,     3] loss: 1.098
[36,     3] loss: 1.061
[37,     3] loss: 1.000
[38,     3] loss: 1.021
[39,     3] loss: 0.973
[40,     3] loss: 0.898
[41,     3] loss: 0.877
[42,     3] loss: 0.850
[43,     3] loss: 0.803
[44,     3] loss: 0.804
[45,     3] loss: 0.842
[46,     3] loss: 1.204
[47,     3] loss: 0.974
[48,     3] loss: 1.041
[49,     3] loss: 0.989
[50,     3] loss: 0.968
[51,     3] loss: 0.915
[52,     3] loss: 0.916
[53,     3] loss: 0.869
[54,     3] loss: 0.863
[55,     3] loss: 0.938
[56,     3] loss: 0.825
[57,     3] loss: 0.786
[58,     3] loss: 0.779
[59,     3] loss: 0.758
[60,     3] loss: 0.854
[61,     3] loss: 0.821
[62,     3] loss: 0.814
[63,     3] loss: 0.950
[64,     3] loss: 0.831
[65,     3] loss: 0.854
[66,     3] loss: 0.907
[67,     3] loss: 0.886
[68,     3] loss: 0.815
[69,     3] loss: 0.807
[70,     3] loss: 0.775
[71,     3] loss: 0.800
[72,     3] loss: 0.851
[73,     3] loss: 0.862
[74,     3] loss: 0.817
[75,     3] loss: 0.793
[76,     3] loss: 0.756
[77,     3] loss: 1.706
[78,     3] loss: 1.121
[79,     3] loss: 1.185
[80,     3] loss: 1.188
[81,     3] loss: 1.033
[82,     3] loss: 0.968
[83,     3] loss: 0.969
[84,     3] loss: 1.075
[85,     3] loss: 0.960
[86,     3] loss: 0.957
[87,     3] loss: 0.854
[88,     3] loss: 0.902
Early stopping applied (best metric=0.5214220285415649)
Finished Training
Total time taken: 24.741090297698975
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.402
[3,     3] loss: 1.379
[4,     3] loss: 1.387
[5,     3] loss: 1.390
[6,     3] loss: 1.401
[7,     3] loss: 1.380
[8,     3] loss: 1.383
[9,     3] loss: 1.386
[10,     3] loss: 1.397
[11,     3] loss: 1.387
[12,     3] loss: 1.376
[13,     3] loss: 1.379
[14,     3] loss: 1.373
[15,     3] loss: 1.387
[16,     3] loss: 1.402
[17,     3] loss: 1.365
[18,     3] loss: 1.370
[19,     3] loss: 1.328
[20,     3] loss: 1.303
[21,     3] loss: 1.269
[22,     3] loss: 1.263
[23,     3] loss: 1.294
[24,     3] loss: 1.259
[25,     3] loss: 1.132
[26,     3] loss: 1.163
[27,     3] loss: 1.167
[28,     3] loss: 1.134
[29,     3] loss: 1.107
[30,     3] loss: 1.060
[31,     3] loss: 0.983
[32,     3] loss: 1.128
[33,     3] loss: 1.012
[34,     3] loss: 1.005
[35,     3] loss: 0.959
[36,     3] loss: 0.953
[37,     3] loss: 1.042
[38,     3] loss: 1.048
[39,     3] loss: 0.989
[40,     3] loss: 1.075
[41,     3] loss: 0.973
[42,     3] loss: 0.922
[43,     3] loss: 0.870
[44,     3] loss: 0.856
[45,     3] loss: 0.840
[46,     3] loss: 0.879
[47,     3] loss: 0.879
[48,     3] loss: 0.839
[49,     3] loss: 0.816
[50,     3] loss: 0.824
[51,     3] loss: 0.798
[52,     3] loss: 0.775
[53,     3] loss: 1.711
[54,     3] loss: 0.953
[55,     3] loss: 1.021
[56,     3] loss: 1.020
[57,     3] loss: 0.974
[58,     3] loss: 0.957
[59,     3] loss: 1.026
[60,     3] loss: 0.857
[61,     3] loss: 0.842
[62,     3] loss: 0.864
[63,     3] loss: 0.787
[64,     3] loss: 0.785
[65,     3] loss: 0.750
[66,     3] loss: 0.776
[67,     3] loss: 0.868
[68,     3] loss: 0.826
[69,     3] loss: 0.877
[70,     3] loss: 0.858
[71,     3] loss: 0.844
[72,     3] loss: 0.893
[73,     3] loss: 0.864
[74,     3] loss: 0.840
[75,     3] loss: 0.808
[76,     3] loss: 0.869
[77,     3] loss: 0.980
[78,     3] loss: 0.878
[79,     3] loss: 0.896
[80,     3] loss: 0.896
[81,     3] loss: 0.856
[82,     3] loss: 0.829
[83,     3] loss: 0.817
Early stopping applied (best metric=0.517894983291626)
Finished Training
Total time taken: 23.025084495544434
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.409
[3,     3] loss: 1.390
[4,     3] loss: 1.386
[5,     3] loss: 1.389
[6,     3] loss: 1.388
[7,     3] loss: 1.388
[8,     3] loss: 1.382
[9,     3] loss: 1.385
[10,     3] loss: 1.383
[11,     3] loss: 1.379
[12,     3] loss: 1.365
[13,     3] loss: 1.362
[14,     3] loss: 1.296
[15,     3] loss: 1.276
[16,     3] loss: 1.199
[17,     3] loss: 1.165
[18,     3] loss: 1.210
[19,     3] loss: 1.272
[20,     3] loss: 1.161
[21,     3] loss: 1.175
[22,     3] loss: 1.104
[23,     3] loss: 1.142
[24,     3] loss: 1.129
[25,     3] loss: 1.019
[26,     3] loss: 1.009
[27,     3] loss: 0.951
[28,     3] loss: 1.054
[29,     3] loss: 0.953
[30,     3] loss: 1.127
[31,     3] loss: 1.014
[32,     3] loss: 1.165
[33,     3] loss: 1.033
[34,     3] loss: 1.047
[35,     3] loss: 1.015
[36,     3] loss: 0.884
[37,     3] loss: 0.921
[38,     3] loss: 0.825
[39,     3] loss: 0.938
[40,     3] loss: 0.845
[41,     3] loss: 0.975
[42,     3] loss: 1.090
[43,     3] loss: 0.949
[44,     3] loss: 0.886
[45,     3] loss: 0.865
[46,     3] loss: 0.817
[47,     3] loss: 0.785
[48,     3] loss: 0.779
[49,     3] loss: 0.730
[50,     3] loss: 0.806
[51,     3] loss: 0.712
[52,     3] loss: 0.967
[53,     3] loss: 0.903
[54,     3] loss: 1.213
[55,     3] loss: 0.970
[56,     3] loss: 0.925
[57,     3] loss: 0.866
[58,     3] loss: 0.838
[59,     3] loss: 0.863
[60,     3] loss: 0.809
[61,     3] loss: 0.831
[62,     3] loss: 0.857
[63,     3] loss: 0.801
[64,     3] loss: 0.774
[65,     3] loss: 0.732
[66,     3] loss: 0.723
[67,     3] loss: 0.727
[68,     3] loss: 0.714
[69,     3] loss: 0.752
[70,     3] loss: 0.928
[71,     3] loss: 0.813
[72,     3] loss: 0.761
[73,     3] loss: 0.765
[74,     3] loss: 0.846
[75,     3] loss: 0.841
[76,     3] loss: 0.864
[77,     3] loss: 0.843
[78,     3] loss: 0.806
[79,     3] loss: 0.806
[80,     3] loss: 0.968
[81,     3] loss: 0.904
[82,     3] loss: 0.822
[83,     3] loss: 0.860
[84,     3] loss: 0.788
[85,     3] loss: 0.810
[86,     3] loss: 0.741
[87,     3] loss: 0.771
[88,     3] loss: 0.811
[89,     3] loss: 1.015
[90,     3] loss: 0.943
Early stopping applied (best metric=0.5511093735694885)
Finished Training
Total time taken: 25.066092252731323
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.399
[3,     3] loss: 1.392
[4,     3] loss: 1.389
[5,     3] loss: 1.390
[6,     3] loss: 1.392
[7,     3] loss: 1.385
[8,     3] loss: 1.389
[9,     3] loss: 1.391
[10,     3] loss: 1.386
[11,     3] loss: 1.385
[12,     3] loss: 1.384
[13,     3] loss: 1.386
[14,     3] loss: 1.396
[15,     3] loss: 1.387
[16,     3] loss: 1.385
[17,     3] loss: 1.381
[18,     3] loss: 1.389
[19,     3] loss: 1.380
[20,     3] loss: 1.389
[21,     3] loss: 1.385
[22,     3] loss: 1.386
[23,     3] loss: 1.391
[24,     3] loss: 1.386
[25,     3] loss: 1.387
[26,     3] loss: 1.380
[27,     3] loss: 1.383
[28,     3] loss: 1.370
[29,     3] loss: 1.334
[30,     3] loss: 1.298
[31,     3] loss: 1.280
[32,     3] loss: 1.243
[33,     3] loss: 1.249
[34,     3] loss: 1.239
[35,     3] loss: 1.194
[36,     3] loss: 1.172
[37,     3] loss: 0.988
[38,     3] loss: 1.058
[39,     3] loss: 1.119
[40,     3] loss: 1.232
[41,     3] loss: 1.362
[42,     3] loss: 1.255
[43,     3] loss: 1.151
[44,     3] loss: 1.255
[45,     3] loss: 1.153
[46,     3] loss: 1.170
[47,     3] loss: 1.095
[48,     3] loss: 1.091
[49,     3] loss: 0.940
[50,     3] loss: 1.092
[51,     3] loss: 1.016
[52,     3] loss: 1.044
[53,     3] loss: 1.177
[54,     3] loss: 1.067
[55,     3] loss: 0.989
[56,     3] loss: 0.954
[57,     3] loss: 0.860
[58,     3] loss: 0.862
[59,     3] loss: 1.106
[60,     3] loss: 1.170
[61,     3] loss: 1.230
[62,     3] loss: 1.146
[63,     3] loss: 1.088
[64,     3] loss: 1.127
[65,     3] loss: 1.009
[66,     3] loss: 0.953
[67,     3] loss: 0.899
[68,     3] loss: 0.833
[69,     3] loss: 0.912
[70,     3] loss: 1.063
[71,     3] loss: 0.955
[72,     3] loss: 1.076
[73,     3] loss: 0.899
[74,     3] loss: 1.010
[75,     3] loss: 0.861
[76,     3] loss: 0.895
[77,     3] loss: 0.854
[78,     3] loss: 0.821
[79,     3] loss: 0.786
[80,     3] loss: 0.765
[81,     3] loss: 0.749
[82,     3] loss: 0.767
[83,     3] loss: 0.841
[84,     3] loss: 0.739
[85,     3] loss: 0.843
[86,     3] loss: 0.910
[87,     3] loss: 0.961
[88,     3] loss: 0.915
Early stopping applied (best metric=0.527667760848999)
Finished Training
Total time taken: 24.35309100151062
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.399
[3,     3] loss: 1.386
[4,     3] loss: 1.385
[5,     3] loss: 1.380
[6,     3] loss: 1.400
[7,     3] loss: 1.396
[8,     3] loss: 1.404
[9,     3] loss: 1.401
[10,     3] loss: 1.385
[11,     3] loss: 1.383
[12,     3] loss: 1.380
[13,     3] loss: 1.382
[14,     3] loss: 1.377
[15,     3] loss: 1.371
[16,     3] loss: 1.340
[17,     3] loss: 1.315
[18,     3] loss: 1.247
[19,     3] loss: 1.250
[20,     3] loss: 1.292
[21,     3] loss: 1.255
[22,     3] loss: 1.325
[23,     3] loss: 1.266
[24,     3] loss: 1.257
[25,     3] loss: 1.267
[26,     3] loss: 1.094
[27,     3] loss: 1.126
[28,     3] loss: 1.108
[29,     3] loss: 1.073
[30,     3] loss: 1.123
[31,     3] loss: 1.044
[32,     3] loss: 1.028
[33,     3] loss: 0.965
[34,     3] loss: 1.118
[35,     3] loss: 1.069
[36,     3] loss: 0.997
[37,     3] loss: 1.022
[38,     3] loss: 0.920
[39,     3] loss: 1.001
[40,     3] loss: 1.022
[41,     3] loss: 0.964
[42,     3] loss: 0.984
[43,     3] loss: 0.954
[44,     3] loss: 0.946
[45,     3] loss: 1.058
[46,     3] loss: 0.968
[47,     3] loss: 0.886
[48,     3] loss: 0.900
[49,     3] loss: 0.832
[50,     3] loss: 0.785
[51,     3] loss: 0.751
[52,     3] loss: 0.737
[53,     3] loss: 1.004
[54,     3] loss: 0.888
[55,     3] loss: 0.937
[56,     3] loss: 0.919
[57,     3] loss: 0.870
[58,     3] loss: 0.951
[59,     3] loss: 0.867
[60,     3] loss: 0.871
[61,     3] loss: 0.813
[62,     3] loss: 0.787
[63,     3] loss: 0.736
[64,     3] loss: 0.748
[65,     3] loss: 0.770
[66,     3] loss: 0.998
[67,     3] loss: 0.973
[68,     3] loss: 0.964
[69,     3] loss: 1.129
[70,     3] loss: 1.142
[71,     3] loss: 1.167
[72,     3] loss: 1.076
[73,     3] loss: 0.966
[74,     3] loss: 0.970
[75,     3] loss: 0.889
[76,     3] loss: 0.911
[77,     3] loss: 0.852
[78,     3] loss: 0.770
Early stopping applied (best metric=0.5315117835998535)
Finished Training
Total time taken: 21.786080598831177
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.386
[3,     3] loss: 1.383
[4,     3] loss: 1.401
[5,     3] loss: 1.395
[6,     3] loss: 1.382
[7,     3] loss: 1.388
[8,     3] loss: 1.391
[9,     3] loss: 1.384
[10,     3] loss: 1.387
[11,     3] loss: 1.384
[12,     3] loss: 1.386
[13,     3] loss: 1.385
[14,     3] loss: 1.374
[15,     3] loss: 1.394
[16,     3] loss: 1.390
[17,     3] loss: 1.396
[18,     3] loss: 1.386
[19,     3] loss: 1.392
[20,     3] loss: 1.379
[21,     3] loss: 1.383
[22,     3] loss: 1.360
[23,     3] loss: 1.322
[24,     3] loss: 1.312
[25,     3] loss: 1.182
[26,     3] loss: 1.183
[27,     3] loss: 1.226
[28,     3] loss: 1.225
[29,     3] loss: 1.026
[30,     3] loss: 1.032
[31,     3] loss: 1.045
[32,     3] loss: 1.057
[33,     3] loss: 1.145
[34,     3] loss: 1.096
[35,     3] loss: 1.099
[36,     3] loss: 1.016
[37,     3] loss: 1.092
[38,     3] loss: 0.970
[39,     3] loss: 0.878
[40,     3] loss: 0.896
[41,     3] loss: 0.996
[42,     3] loss: 1.040
[43,     3] loss: 0.986
[44,     3] loss: 1.153
[45,     3] loss: 1.050
[46,     3] loss: 1.025
[47,     3] loss: 0.908
[48,     3] loss: 0.968
[49,     3] loss: 0.951
[50,     3] loss: 0.878
[51,     3] loss: 0.844
[52,     3] loss: 0.890
[53,     3] loss: 0.935
[54,     3] loss: 1.007
[55,     3] loss: 0.998
[56,     3] loss: 0.952
[57,     3] loss: 0.893
[58,     3] loss: 0.884
[59,     3] loss: 0.856
[60,     3] loss: 0.934
[61,     3] loss: 1.011
[62,     3] loss: 0.960
[63,     3] loss: 0.907
[64,     3] loss: 0.869
[65,     3] loss: 0.817
[66,     3] loss: 0.812
[67,     3] loss: 0.849
[68,     3] loss: 0.892
[69,     3] loss: 0.933
[70,     3] loss: 0.892
[71,     3] loss: 0.872
[72,     3] loss: 0.858
[73,     3] loss: 0.917
[74,     3] loss: 0.899
[75,     3] loss: 0.821
Early stopping applied (best metric=0.5108795166015625)
Finished Training
Total time taken: 21.00407886505127
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.398
[3,     3] loss: 1.393
[4,     3] loss: 1.378
[5,     3] loss: 1.372
[6,     3] loss: 1.372
[7,     3] loss: 1.378
[8,     3] loss: 1.363
[9,     3] loss: 1.361
[10,     3] loss: 1.344
[11,     3] loss: 1.296
[12,     3] loss: 1.248
[13,     3] loss: 1.261
[14,     3] loss: 1.204
[15,     3] loss: 1.251
[16,     3] loss: 1.246
[17,     3] loss: 1.208
[18,     3] loss: 1.196
[19,     3] loss: 1.157
[20,     3] loss: 1.058
[21,     3] loss: 1.192
[22,     3] loss: 1.206
[23,     3] loss: 1.149
[24,     3] loss: 1.084
[25,     3] loss: 1.041
[26,     3] loss: 1.029
[27,     3] loss: 1.074
[28,     3] loss: 1.035
[29,     3] loss: 0.944
[30,     3] loss: 0.969
[31,     3] loss: 1.039
[32,     3] loss: 0.872
[33,     3] loss: 1.155
[34,     3] loss: 0.855
[35,     3] loss: 0.845
[36,     3] loss: 0.807
[37,     3] loss: 0.854
[38,     3] loss: 0.964
[39,     3] loss: 0.873
[40,     3] loss: 0.958
[41,     3] loss: 0.934
[42,     3] loss: 0.872
[43,     3] loss: 0.857
[44,     3] loss: 0.819
[45,     3] loss: 0.757
[46,     3] loss: 0.847
[47,     3] loss: 0.747
[48,     3] loss: 0.738
[49,     3] loss: 0.731
[50,     3] loss: 0.761
[51,     3] loss: 0.854
[52,     3] loss: 1.242
[53,     3] loss: 0.894
[54,     3] loss: 1.038
[55,     3] loss: 0.991
[56,     3] loss: 0.903
[57,     3] loss: 0.830
[58,     3] loss: 0.754
[59,     3] loss: 0.777
[60,     3] loss: 0.726
[61,     3] loss: 0.738
[62,     3] loss: 1.030
[63,     3] loss: 0.957
[64,     3] loss: 0.930
[65,     3] loss: 0.898
[66,     3] loss: 0.772
[67,     3] loss: 0.844
[68,     3] loss: 0.855
[69,     3] loss: 0.745
[70,     3] loss: 0.751
[71,     3] loss: 0.770
[72,     3] loss: 0.789
[73,     3] loss: 0.745
[74,     3] loss: 0.732
[75,     3] loss: 0.752
[76,     3] loss: 0.758
[77,     3] loss: 0.804
[78,     3] loss: 0.969
[79,     3] loss: 0.931
[80,     3] loss: 0.787
[81,     3] loss: 0.925
[82,     3] loss: 0.845
[83,     3] loss: 0.812
[84,     3] loss: 0.776
[85,     3] loss: 0.733
[86,     3] loss: 0.731
[87,     3] loss: 0.764
[88,     3] loss: 0.730
[89,     3] loss: 0.832
[90,     3] loss: 0.767
[91,     3] loss: 0.751
[92,     3] loss: 0.773
[93,     3] loss: 0.798
[94,     3] loss: 0.845
[95,     3] loss: 0.817
Early stopping applied (best metric=0.5202663540840149)
Finished Training
Total time taken: 26.1710946559906
{'S-palmitoylation-C Validation Accuracy': 0.6631636178797751, 'S-palmitoylation-C Validation Sensitivity': 0.27762376237623765, 'S-palmitoylation-C Validation Specificity': 0.7597984332994103, 'S-palmitoylation-C Validation Precision': 0.2383859431983491, 'S-palmitoylation-C AUC ROC': 0.541076209826142, 'S-palmitoylation-C AUC PR': 0.22570579747761857, 'S-palmitoylation-C MCC': 0.04040559657906091, 'S-palmitoylation-C F1': 0.22448076631434896, 'Validation Loss (S-palmitoylation-C)': 0.5545080304145813, 'Hydroxylation-K Validation Accuracy': 0.6464539007092198, 'Hydroxylation-K Validation Sensitivity': 0.7718518518518519, 'Hydroxylation-K Validation Specificity': 0.6157894736842106, 'Hydroxylation-K Validation Precision': 0.3577727954469386, 'Hydroxylation-K AUC ROC': 0.7790448343079922, 'Hydroxylation-K AUC PR': 0.5441349930612005, 'Hydroxylation-K MCC': 0.32125972945122067, 'Hydroxylation-K F1': 0.4799413077477594, 'Validation Loss (Hydroxylation-K)': 0.5236856877803803, 'Validation Loss (total)': 1.078193728129069, 'TimeToTrain': 22.69855046272278}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004138360509248541,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5080220705772596,
 'loss_weight_S-palmitoylation-C': 0.8538107517876726,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3721132954,
 'sample_weights': [0.31621115859069665, 0.25165203688950255],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.040834550140088,
 'weight_decay_Hydroxylation-K': 3.602555246700864,
 'weight_decay_S-palmitoylation-C': 0.23896160156470453}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.406
[3,     3] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018522232829822354,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.235288762854278,
 'loss_weight_S-palmitoylation-C': 0.21214910842738033,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2939309850,
 'sample_weights': [0.8538107517876726, 0.5080220705772596],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.875803228936335,
 'weight_decay_Hydroxylation-K': 7.391427201297946,
 'weight_decay_S-palmitoylation-C': 2.3592401528262643}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.401
[2,     3] loss: 1.386
[3,     3] loss: 1.380
[4,     3] loss: 1.381
[5,     3] loss: 1.388
[6,     3] loss: 1.381
[7,     3] loss: 1.388
[8,     3] loss: 1.379
[9,     3] loss: 1.381
[10,     3] loss: 1.378
[11,     3] loss: 1.370
[12,     3] loss: 1.356
[13,     3] loss: 1.355
[14,     3] loss: 1.323
[15,     3] loss: 1.291
[16,     3] loss: 1.266
[17,     3] loss: 1.220
[18,     3] loss: 1.260
[19,     3] loss: 1.128
[20,     3] loss: 1.125
[21,     3] loss: 1.114
[22,     3] loss: 1.201
[23,     3] loss: 1.035
[24,     3] loss: 1.100
[25,     3] loss: 1.045
[26,     3] loss: 1.047
[27,     3] loss: 0.973
[28,     3] loss: 0.957
[29,     3] loss: 1.072
[30,     3] loss: 0.966
[31,     3] loss: 0.970
[32,     3] loss: 0.953
[33,     3] loss: 0.938
[34,     3] loss: 0.937
[35,     3] loss: 1.065
[36,     3] loss: 0.966
[37,     3] loss: 1.045
[38,     3] loss: 1.042
[39,     3] loss: 0.989
[40,     3] loss: 0.966
[41,     3] loss: 0.942
[42,     3] loss: 0.965
[43,     3] loss: 0.932
[44,     3] loss: 0.964
[45,     3] loss: 0.950
[46,     3] loss: 0.881
[47,     3] loss: 0.953
[48,     3] loss: 0.882
[49,     3] loss: 0.857
[50,     3] loss: 0.916
[51,     3] loss: 0.915
[52,     3] loss: 0.907
[53,     3] loss: 0.904
[54,     3] loss: 0.881
[55,     3] loss: 0.923
[56,     3] loss: 0.855
[57,     3] loss: 0.853
[58,     3] loss: 0.935
[59,     3] loss: 0.889
[60,     3] loss: 0.917
[61,     3] loss: 0.883
[62,     3] loss: 0.914
[63,     3] loss: 0.834
[64,     3] loss: 0.874
[65,     3] loss: 0.889
[66,     3] loss: 0.862
[67,     3] loss: 0.960
[68,     3] loss: 0.864
[69,     3] loss: 0.850
[70,     3] loss: 0.831
[71,     3] loss: 0.799
Early stopping applied (best metric=0.48979121446609497)
Finished Training
Total time taken: 19.46107053756714
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.394
[3,     3] loss: 1.381
[4,     3] loss: 1.394
[5,     3] loss: 1.389
[6,     3] loss: 1.382
[7,     3] loss: 1.388
[8,     3] loss: 1.381
[9,     3] loss: 1.379
[10,     3] loss: 1.379
[11,     3] loss: 1.372
[12,     3] loss: 1.363
[13,     3] loss: 1.368
[14,     3] loss: 1.354
[15,     3] loss: 1.338
[16,     3] loss: 1.319
[17,     3] loss: 1.251
[18,     3] loss: 1.287
[19,     3] loss: 1.213
[20,     3] loss: 1.150
[21,     3] loss: 1.139
[22,     3] loss: 1.068
[23,     3] loss: 1.123
[24,     3] loss: 1.120
[25,     3] loss: 1.011
[26,     3] loss: 1.209
[27,     3] loss: 1.182
[28,     3] loss: 1.111
[29,     3] loss: 1.081
[30,     3] loss: 0.993
[31,     3] loss: 0.958
[32,     3] loss: 1.058
[33,     3] loss: 0.912
[34,     3] loss: 0.971
[35,     3] loss: 0.926
[36,     3] loss: 0.985
[37,     3] loss: 1.044
[38,     3] loss: 0.994
[39,     3] loss: 0.933
[40,     3] loss: 0.992
[41,     3] loss: 0.990
[42,     3] loss: 0.995
[43,     3] loss: 0.945
[44,     3] loss: 0.878
[45,     3] loss: 0.847
[46,     3] loss: 0.874
[47,     3] loss: 0.937
[48,     3] loss: 0.893
[49,     3] loss: 0.840
[50,     3] loss: 0.828
[51,     3] loss: 0.829
[52,     3] loss: 0.895
[53,     3] loss: 0.798
[54,     3] loss: 0.829
[55,     3] loss: 0.784
[56,     3] loss: 0.774
[57,     3] loss: 0.787
[58,     3] loss: 0.753
[59,     3] loss: 0.835
[60,     3] loss: 0.963
[61,     3] loss: 0.929
[62,     3] loss: 0.931
[63,     3] loss: 0.902
[64,     3] loss: 0.904
[65,     3] loss: 0.915
[66,     3] loss: 0.867
[67,     3] loss: 0.847
Early stopping applied (best metric=0.5142554044723511)
Finished Training
Total time taken: 18.14406681060791
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.376
[3,     3] loss: 1.400
[4,     3] loss: 1.385
[5,     3] loss: 1.388
[6,     3] loss: 1.388
[7,     3] loss: 1.383
[8,     3] loss: 1.384
[9,     3] loss: 1.386
[10,     3] loss: 1.386
[11,     3] loss: 1.381
[12,     3] loss: 1.379
[13,     3] loss: 1.377
[14,     3] loss: 1.378
[15,     3] loss: 1.378
[16,     3] loss: 1.370
[17,     3] loss: 1.362
[18,     3] loss: 1.352
[19,     3] loss: 1.343
[20,     3] loss: 1.286
[21,     3] loss: 1.293
[22,     3] loss: 1.210
[23,     3] loss: 1.249
[24,     3] loss: 1.182
[25,     3] loss: 1.191
[26,     3] loss: 1.092
[27,     3] loss: 1.133
[28,     3] loss: 1.316
[29,     3] loss: 1.279
[30,     3] loss: 1.132
[31,     3] loss: 1.156
[32,     3] loss: 1.131
[33,     3] loss: 1.086
[34,     3] loss: 1.063
[35,     3] loss: 1.045
[36,     3] loss: 1.073
[37,     3] loss: 1.030
[38,     3] loss: 0.967
[39,     3] loss: 0.972
[40,     3] loss: 0.948
[41,     3] loss: 0.957
[42,     3] loss: 0.919
[43,     3] loss: 0.933
[44,     3] loss: 0.991
[45,     3] loss: 0.880
[46,     3] loss: 0.944
[47,     3] loss: 0.914
[48,     3] loss: 1.023
[49,     3] loss: 0.869
[50,     3] loss: 0.919
[51,     3] loss: 0.903
[52,     3] loss: 0.932
[53,     3] loss: 0.897
[54,     3] loss: 0.866
[55,     3] loss: 0.960
[56,     3] loss: 0.944
[57,     3] loss: 0.936
[58,     3] loss: 0.828
[59,     3] loss: 0.862
[60,     3] loss: 0.838
[61,     3] loss: 0.853
[62,     3] loss: 0.849
[63,     3] loss: 0.846
[64,     3] loss: 0.873
[65,     3] loss: 0.935
[66,     3] loss: 0.930
[67,     3] loss: 1.000
[68,     3] loss: 0.930
[69,     3] loss: 0.870
[70,     3] loss: 0.926
[71,     3] loss: 0.965
[72,     3] loss: 0.935
[73,     3] loss: 0.963
[74,     3] loss: 0.886
[75,     3] loss: 0.847
Early stopping applied (best metric=0.544073224067688)
Finished Training
Total time taken: 19.25507402420044
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.383
[3,     3] loss: 1.380
[4,     3] loss: 1.387
[5,     3] loss: 1.388
[6,     3] loss: 1.380
[7,     3] loss: 1.380
[8,     3] loss: 1.358
[9,     3] loss: 1.369
[10,     3] loss: 1.355
[11,     3] loss: 1.339
[12,     3] loss: 1.305
[13,     3] loss: 1.262
[14,     3] loss: 1.229
[15,     3] loss: 1.195
[16,     3] loss: 1.171
[17,     3] loss: 1.177
[18,     3] loss: 1.139
[19,     3] loss: 1.155
[20,     3] loss: 1.068
[21,     3] loss: 1.115
[22,     3] loss: 0.994
[23,     3] loss: 1.003
[24,     3] loss: 1.080
[25,     3] loss: 0.983
[26,     3] loss: 0.914
[27,     3] loss: 0.896
[28,     3] loss: 0.937
[29,     3] loss: 0.898
[30,     3] loss: 0.941
[31,     3] loss: 0.843
[32,     3] loss: 0.868
[33,     3] loss: 0.948
[34,     3] loss: 0.958
[35,     3] loss: 0.904
[36,     3] loss: 0.887
[37,     3] loss: 0.909
[38,     3] loss: 0.917
[39,     3] loss: 0.891
[40,     3] loss: 0.816
[41,     3] loss: 0.895
[42,     3] loss: 0.859
[43,     3] loss: 0.841
[44,     3] loss: 0.834
[45,     3] loss: 0.811
[46,     3] loss: 0.817
[47,     3] loss: 0.802
[48,     3] loss: 0.832
[49,     3] loss: 0.826
[50,     3] loss: 0.799
[51,     3] loss: 0.789
Early stopping applied (best metric=0.5455924868583679)
Finished Training
Total time taken: 13.633050441741943
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.389
[3,     3] loss: 1.382
[4,     3] loss: 1.383
[5,     3] loss: 1.386
[6,     3] loss: 1.388
[7,     3] loss: 1.383
[8,     3] loss: 1.381
[9,     3] loss: 1.393
[10,     3] loss: 1.388
[11,     3] loss: 1.384
[12,     3] loss: 1.385
[13,     3] loss: 1.384
[14,     3] loss: 1.382
[15,     3] loss: 1.382
[16,     3] loss: 1.379
[17,     3] loss: 1.376
[18,     3] loss: 1.370
[19,     3] loss: 1.353
[20,     3] loss: 1.332
[21,     3] loss: 1.306
[22,     3] loss: 1.289
[23,     3] loss: 1.298
[24,     3] loss: 1.186
[25,     3] loss: 1.173
[26,     3] loss: 1.220
[27,     3] loss: 1.142
[28,     3] loss: 1.160
[29,     3] loss: 1.110
[30,     3] loss: 1.178
[31,     3] loss: 1.158
[32,     3] loss: 1.124
[33,     3] loss: 1.090
[34,     3] loss: 1.077
[35,     3] loss: 1.065
[36,     3] loss: 1.102
[37,     3] loss: 0.966
[38,     3] loss: 1.005
[39,     3] loss: 0.988
[40,     3] loss: 1.006
[41,     3] loss: 0.946
[42,     3] loss: 1.058
[43,     3] loss: 0.928
[44,     3] loss: 1.017
[45,     3] loss: 0.939
[46,     3] loss: 0.907
[47,     3] loss: 0.920
[48,     3] loss: 0.946
[49,     3] loss: 0.951
[50,     3] loss: 0.990
[51,     3] loss: 0.868
[52,     3] loss: 0.971
[53,     3] loss: 0.864
[54,     3] loss: 0.915
[55,     3] loss: 0.868
[56,     3] loss: 0.936
[57,     3] loss: 0.869
[58,     3] loss: 0.908
[59,     3] loss: 0.915
[60,     3] loss: 0.858
[61,     3] loss: 0.939
[62,     3] loss: 0.886
[63,     3] loss: 0.934
[64,     3] loss: 0.949
[65,     3] loss: 0.845
[66,     3] loss: 0.840
[67,     3] loss: 0.811
[68,     3] loss: 0.864
[69,     3] loss: 0.827
[70,     3] loss: 0.857
[71,     3] loss: 0.791
[72,     3] loss: 0.795
[73,     3] loss: 0.840
[74,     3] loss: 0.782
[75,     3] loss: 0.859
[76,     3] loss: 0.942
[77,     3] loss: 0.859
[78,     3] loss: 0.863
Early stopping applied (best metric=0.4973583519458771)
Finished Training
Total time taken: 20.00907611846924
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.389
[3,     3] loss: 1.381
[4,     3] loss: 1.382
[5,     3] loss: 1.373
[6,     3] loss: 1.371
[7,     3] loss: 1.365
[8,     3] loss: 1.341
[9,     3] loss: 1.323
[10,     3] loss: 1.259
[11,     3] loss: 1.282
[12,     3] loss: 1.184
[13,     3] loss: 1.111
[14,     3] loss: 1.167
[15,     3] loss: 1.193
[16,     3] loss: 1.037
[17,     3] loss: 1.115
[18,     3] loss: 1.200
[19,     3] loss: 1.117
[20,     3] loss: 1.092
[21,     3] loss: 1.139
[22,     3] loss: 0.988
[23,     3] loss: 1.051
[24,     3] loss: 1.001
[25,     3] loss: 1.196
[26,     3] loss: 1.075
[27,     3] loss: 0.957
[28,     3] loss: 1.057
[29,     3] loss: 0.919
[30,     3] loss: 0.958
[31,     3] loss: 0.874
[32,     3] loss: 0.980
[33,     3] loss: 0.953
[34,     3] loss: 0.933
[35,     3] loss: 0.933
[36,     3] loss: 1.084
[37,     3] loss: 0.943
[38,     3] loss: 0.927
[39,     3] loss: 0.972
[40,     3] loss: 0.889
[41,     3] loss: 0.899
[42,     3] loss: 0.840
[43,     3] loss: 0.874
[44,     3] loss: 0.891
[45,     3] loss: 0.991
[46,     3] loss: 0.866
[47,     3] loss: 0.883
[48,     3] loss: 0.856
[49,     3] loss: 0.798
[50,     3] loss: 0.896
[51,     3] loss: 0.862
[52,     3] loss: 0.857
[53,     3] loss: 0.875
[54,     3] loss: 0.953
[55,     3] loss: 1.014
[56,     3] loss: 0.843
[57,     3] loss: 0.906
[58,     3] loss: 0.853
[59,     3] loss: 0.842
[60,     3] loss: 0.806
[61,     3] loss: 0.787
[62,     3] loss: 0.790
[63,     3] loss: 0.783
[64,     3] loss: 0.805
[65,     3] loss: 0.800
[66,     3] loss: 0.830
[67,     3] loss: 0.816
[68,     3] loss: 0.787
[69,     3] loss: 0.836
[70,     3] loss: 0.794
[71,     3] loss: 0.839
[72,     3] loss: 0.892
[73,     3] loss: 0.934
[74,     3] loss: 0.896
[75,     3] loss: 0.834
[76,     3] loss: 0.852
[77,     3] loss: 0.811
[78,     3] loss: 0.787
[79,     3] loss: 0.784
[80,     3] loss: 0.762
[81,     3] loss: 0.767
[82,     3] loss: 0.761
[83,     3] loss: 0.766
[84,     3] loss: 0.774
[85,     3] loss: 0.848
[86,     3] loss: 0.849
[87,     3] loss: 0.838
[88,     3] loss: 0.844
[89,     3] loss: 0.890
[90,     3] loss: 0.957
[91,     3] loss: 1.006
[92,     3] loss: 0.913
[93,     3] loss: 0.929
[94,     3] loss: 0.838
[95,     3] loss: 0.939
[96,     3] loss: 0.824
[97,     3] loss: 0.866
[98,     3] loss: 0.818
[99,     3] loss: 0.856
[100,     3] loss: 0.790
[101,     3] loss: 0.793
[102,     3] loss: 0.790
[103,     3] loss: 0.754
[104,     3] loss: 0.748
[105,     3] loss: 0.741
[106,     3] loss: 0.751
[107,     3] loss: 0.749
[108,     3] loss: 0.737
[109,     3] loss: 0.746
[110,     3] loss: 0.731
[111,     3] loss: 0.786
[112,     3] loss: 0.820
[113,     3] loss: 0.787
[114,     3] loss: 0.794
[115,     3] loss: 0.790
[116,     3] loss: 0.797
[117,     3] loss: 0.782
[118,     3] loss: 0.748
[119,     3] loss: 0.757
[120,     3] loss: 0.754
[121,     3] loss: 0.743
[122,     3] loss: 0.751
[123,     3] loss: 0.744
[124,     3] loss: 0.743
[125,     3] loss: 0.752
[126,     3] loss: 0.767
[127,     3] loss: 0.748
[128,     3] loss: 0.751
[129,     3] loss: 0.752
[130,     3] loss: 0.749
[131,     3] loss: 0.756
[132,     3] loss: 0.743
[133,     3] loss: 0.736
[134,     3] loss: 0.741
[135,     3] loss: 0.755
[136,     3] loss: 0.744
Early stopping applied (best metric=0.5469028949737549)
Finished Training
Total time taken: 34.450602531433105
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.371
[2,     3] loss: 1.379
[3,     3] loss: 1.381
[4,     3] loss: 1.389
[5,     3] loss: 1.377
[6,     3] loss: 1.388
[7,     3] loss: 1.392
[8,     3] loss: 1.389
[9,     3] loss: 1.385
[10,     3] loss: 1.384
[11,     3] loss: 1.383
[12,     3] loss: 1.381
[13,     3] loss: 1.376
[14,     3] loss: 1.387
[15,     3] loss: 1.371
[16,     3] loss: 1.368
[17,     3] loss: 1.365
[18,     3] loss: 1.343
[19,     3] loss: 1.340
[20,     3] loss: 1.289
[21,     3] loss: 1.280
[22,     3] loss: 1.268
[23,     3] loss: 1.224
[24,     3] loss: 1.201
[25,     3] loss: 1.157
[26,     3] loss: 1.154
[27,     3] loss: 1.097
[28,     3] loss: 1.149
[29,     3] loss: 1.022
[30,     3] loss: 1.027
[31,     3] loss: 0.996
[32,     3] loss: 1.110
[33,     3] loss: 1.104
[34,     3] loss: 1.078
[35,     3] loss: 1.157
[36,     3] loss: 0.976
[37,     3] loss: 0.977
[38,     3] loss: 0.973
[39,     3] loss: 0.935
[40,     3] loss: 0.994
[41,     3] loss: 0.938
[42,     3] loss: 0.893
[43,     3] loss: 0.984
[44,     3] loss: 1.049
[45,     3] loss: 0.878
[46,     3] loss: 0.907
[47,     3] loss: 0.872
[48,     3] loss: 0.836
[49,     3] loss: 0.946
[50,     3] loss: 0.934
[51,     3] loss: 0.936
[52,     3] loss: 0.878
[53,     3] loss: 0.865
[54,     3] loss: 0.865
[55,     3] loss: 0.818
[56,     3] loss: 0.836
[57,     3] loss: 0.792
[58,     3] loss: 0.933
[59,     3] loss: 0.865
[60,     3] loss: 0.845
[61,     3] loss: 0.811
[62,     3] loss: 0.850
[63,     3] loss: 0.858
[64,     3] loss: 0.823
[65,     3] loss: 0.855
[66,     3] loss: 0.935
[67,     3] loss: 0.959
[68,     3] loss: 0.922
[69,     3] loss: 0.866
[70,     3] loss: 0.816
[71,     3] loss: 0.817
[72,     3] loss: 0.826
[73,     3] loss: 0.771
[74,     3] loss: 0.810
[75,     3] loss: 0.811
[76,     3] loss: 0.843
[77,     3] loss: 0.776
[78,     3] loss: 0.790
[79,     3] loss: 0.787
[80,     3] loss: 0.787
[81,     3] loss: 0.769
[82,     3] loss: 0.759
Early stopping applied (best metric=0.5289556384086609)
Finished Training
Total time taken: 20.98507809638977
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.386
[3,     3] loss: 1.388
[4,     3] loss: 1.387
[5,     3] loss: 1.386
[6,     3] loss: 1.385
[7,     3] loss: 1.383
[8,     3] loss: 1.383
[9,     3] loss: 1.378
[10,     3] loss: 1.370
[11,     3] loss: 1.363
[12,     3] loss: 1.371
[13,     3] loss: 1.341
[14,     3] loss: 1.355
[15,     3] loss: 1.308
[16,     3] loss: 1.259
[17,     3] loss: 1.197
[18,     3] loss: 1.276
[19,     3] loss: 1.150
[20,     3] loss: 1.143
[21,     3] loss: 1.315
[22,     3] loss: 1.133
[23,     3] loss: 1.129
[24,     3] loss: 1.208
[25,     3] loss: 1.067
[26,     3] loss: 1.141
[27,     3] loss: 1.142
[28,     3] loss: 1.095
[29,     3] loss: 1.071
[30,     3] loss: 1.042
[31,     3] loss: 1.043
[32,     3] loss: 1.022
[33,     3] loss: 0.990
[34,     3] loss: 0.962
[35,     3] loss: 0.936
[36,     3] loss: 0.946
[37,     3] loss: 0.924
[38,     3] loss: 0.906
[39,     3] loss: 0.942
[40,     3] loss: 0.910
[41,     3] loss: 0.861
[42,     3] loss: 0.995
[43,     3] loss: 1.049
[44,     3] loss: 1.134
[45,     3] loss: 1.060
[46,     3] loss: 0.937
[47,     3] loss: 0.943
[48,     3] loss: 0.942
[49,     3] loss: 1.062
[50,     3] loss: 0.981
[51,     3] loss: 0.995
[52,     3] loss: 1.051
[53,     3] loss: 0.909
[54,     3] loss: 0.929
[55,     3] loss: 0.896
[56,     3] loss: 0.911
[57,     3] loss: 0.865
[58,     3] loss: 0.857
[59,     3] loss: 0.810
[60,     3] loss: 0.990
[61,     3] loss: 0.873
[62,     3] loss: 0.834
[63,     3] loss: 0.835
[64,     3] loss: 0.886
[65,     3] loss: 0.836
[66,     3] loss: 0.903
[67,     3] loss: 0.852
[68,     3] loss: 0.889
[69,     3] loss: 0.857
[70,     3] loss: 0.874
[71,     3] loss: 0.801
[72,     3] loss: 0.868
[73,     3] loss: 0.809
[74,     3] loss: 0.828
[75,     3] loss: 0.839
[76,     3] loss: 0.894
[77,     3] loss: 0.913
[78,     3] loss: 0.853
[79,     3] loss: 0.824
[80,     3] loss: 0.847
[81,     3] loss: 0.840
[82,     3] loss: 0.821
[83,     3] loss: 0.835
Early stopping applied (best metric=0.5232963562011719)
Finished Training
Total time taken: 21.44008159637451
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.382
[3,     3] loss: 1.389
[4,     3] loss: 1.390
[5,     3] loss: 1.388
[6,     3] loss: 1.387
[7,     3] loss: 1.389
[8,     3] loss: 1.386
[9,     3] loss: 1.383
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.384
[13,     3] loss: 1.390
[14,     3] loss: 1.390
[15,     3] loss: 1.384
[16,     3] loss: 1.387
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.387
[21,     3] loss: 1.385
[22,     3] loss: 1.385
[23,     3] loss: 1.384
[24,     3] loss: 1.382
[25,     3] loss: 1.379
[26,     3] loss: 1.371
[27,     3] loss: 1.360
[28,     3] loss: 1.352
[29,     3] loss: 1.310
[30,     3] loss: 1.310
[31,     3] loss: 1.281
[32,     3] loss: 1.247
[33,     3] loss: 1.228
[34,     3] loss: 1.206
[35,     3] loss: 1.195
[36,     3] loss: 1.204
[37,     3] loss: 1.098
[38,     3] loss: 1.155
[39,     3] loss: 1.160
[40,     3] loss: 1.255
[41,     3] loss: 1.115
[42,     3] loss: 1.041
[43,     3] loss: 1.025
[44,     3] loss: 1.021
[45,     3] loss: 1.009
[46,     3] loss: 1.141
[47,     3] loss: 1.000
[48,     3] loss: 0.975
[49,     3] loss: 1.027
[50,     3] loss: 1.050
[51,     3] loss: 1.052
[52,     3] loss: 0.921
[53,     3] loss: 0.977
[54,     3] loss: 0.912
[55,     3] loss: 1.006
[56,     3] loss: 0.981
[57,     3] loss: 0.956
[58,     3] loss: 0.888
[59,     3] loss: 0.886
[60,     3] loss: 0.907
[61,     3] loss: 0.963
[62,     3] loss: 0.896
[63,     3] loss: 0.924
[64,     3] loss: 0.960
[65,     3] loss: 0.940
[66,     3] loss: 1.056
[67,     3] loss: 0.963
[68,     3] loss: 0.987
[69,     3] loss: 1.000
[70,     3] loss: 0.915
[71,     3] loss: 0.982
[72,     3] loss: 0.888
[73,     3] loss: 0.916
[74,     3] loss: 0.847
[75,     3] loss: 0.889
[76,     3] loss: 0.830
[77,     3] loss: 0.849
[78,     3] loss: 0.824
[79,     3] loss: 0.783
[80,     3] loss: 0.786
[81,     3] loss: 0.767
[82,     3] loss: 0.764
[83,     3] loss: 0.773
[84,     3] loss: 0.750
[85,     3] loss: 0.769
[86,     3] loss: 0.745
[87,     3] loss: 0.745
[88,     3] loss: 0.763
Early stopping applied (best metric=0.5105252265930176)
Finished Training
Total time taken: 23.018083810806274
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.385
[3,     3] loss: 1.386
[4,     3] loss: 1.384
[5,     3] loss: 1.388
[6,     3] loss: 1.382
[7,     3] loss: 1.379
[8,     3] loss: 1.375
[9,     3] loss: 1.362
[10,     3] loss: 1.376
[11,     3] loss: 1.366
[12,     3] loss: 1.340
[13,     3] loss: 1.327
[14,     3] loss: 1.280
[15,     3] loss: 1.271
[16,     3] loss: 1.221
[17,     3] loss: 1.239
[18,     3] loss: 1.109
[19,     3] loss: 1.101
[20,     3] loss: 1.163
[21,     3] loss: 1.111
[22,     3] loss: 1.129
[23,     3] loss: 1.006
[24,     3] loss: 1.024
[25,     3] loss: 1.011
[26,     3] loss: 1.003
[27,     3] loss: 1.205
[28,     3] loss: 0.997
[29,     3] loss: 1.070
[30,     3] loss: 0.972
[31,     3] loss: 0.999
[32,     3] loss: 1.032
[33,     3] loss: 0.995
[34,     3] loss: 1.010
[35,     3] loss: 0.929
[36,     3] loss: 1.011
[37,     3] loss: 0.995
[38,     3] loss: 0.973
[39,     3] loss: 1.130
[40,     3] loss: 0.946
[41,     3] loss: 1.057
[42,     3] loss: 0.977
[43,     3] loss: 0.948
[44,     3] loss: 0.912
[45,     3] loss: 0.977
[46,     3] loss: 0.899
[47,     3] loss: 0.942
[48,     3] loss: 0.850
[49,     3] loss: 0.943
[50,     3] loss: 0.830
[51,     3] loss: 0.850
[52,     3] loss: 0.847
[53,     3] loss: 0.803
[54,     3] loss: 0.836
[55,     3] loss: 0.802
[56,     3] loss: 0.879
[57,     3] loss: 0.864
[58,     3] loss: 0.896
[59,     3] loss: 0.823
[60,     3] loss: 0.854
[61,     3] loss: 0.860
[62,     3] loss: 0.849
[63,     3] loss: 0.834
[64,     3] loss: 0.909
[65,     3] loss: 0.806
[66,     3] loss: 0.806
[67,     3] loss: 0.832
[68,     3] loss: 0.813
[69,     3] loss: 0.848
[70,     3] loss: 0.845
[71,     3] loss: 0.789
[72,     3] loss: 0.929
[73,     3] loss: 0.857
[74,     3] loss: 0.869
[75,     3] loss: 0.786
[76,     3] loss: 0.806
Early stopping applied (best metric=0.5138251185417175)
Finished Training
Total time taken: 19.78607177734375
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.388
[3,     3] loss: 1.390
[4,     3] loss: 1.389
[5,     3] loss: 1.387
[6,     3] loss: 1.385
[7,     3] loss: 1.388
[8,     3] loss: 1.386
[9,     3] loss: 1.381
[10,     3] loss: 1.378
[11,     3] loss: 1.375
[12,     3] loss: 1.355
[13,     3] loss: 1.342
[14,     3] loss: 1.306
[15,     3] loss: 1.298
[16,     3] loss: 1.271
[17,     3] loss: 1.252
[18,     3] loss: 1.195
[19,     3] loss: 1.133
[20,     3] loss: 1.139
[21,     3] loss: 1.162
[22,     3] loss: 1.091
[23,     3] loss: 1.051
[24,     3] loss: 1.073
[25,     3] loss: 1.086
[26,     3] loss: 0.966
[27,     3] loss: 1.040
[28,     3] loss: 1.008
[29,     3] loss: 0.999
[30,     3] loss: 0.914
[31,     3] loss: 0.906
[32,     3] loss: 0.918
[33,     3] loss: 0.903
[34,     3] loss: 0.820
[35,     3] loss: 0.857
[36,     3] loss: 0.826
[37,     3] loss: 0.853
[38,     3] loss: 0.838
[39,     3] loss: 0.844
[40,     3] loss: 0.830
[41,     3] loss: 0.809
[42,     3] loss: 0.805
[43,     3] loss: 0.773
[44,     3] loss: 0.773
[45,     3] loss: 0.828
[46,     3] loss: 0.772
[47,     3] loss: 0.836
[48,     3] loss: 0.797
[49,     3] loss: 0.779
[50,     3] loss: 0.769
[51,     3] loss: 0.778
[52,     3] loss: 0.794
[53,     3] loss: 0.754
[54,     3] loss: 0.800
[55,     3] loss: 0.838
[56,     3] loss: 0.783
[57,     3] loss: 0.796
[58,     3] loss: 0.954
[59,     3] loss: 0.966
[60,     3] loss: 1.032
[61,     3] loss: 0.835
[62,     3] loss: 0.855
[63,     3] loss: 0.920
[64,     3] loss: 0.873
[65,     3] loss: 1.034
[66,     3] loss: 0.833
[67,     3] loss: 0.950
[68,     3] loss: 0.830
[69,     3] loss: 0.884
[70,     3] loss: 0.796
[71,     3] loss: 0.797
[72,     3] loss: 0.774
Early stopping applied (best metric=0.5260499119758606)
Finished Training
Total time taken: 18.600067853927612
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.387
[3,     3] loss: 1.387
[4,     3] loss: 1.403
[5,     3] loss: 1.390
[6,     3] loss: 1.388
[7,     3] loss: 1.387
[8,     3] loss: 1.387
[9,     3] loss: 1.385
[10,     3] loss: 1.384
[11,     3] loss: 1.383
[12,     3] loss: 1.386
[13,     3] loss: 1.378
[14,     3] loss: 1.380
[15,     3] loss: 1.379
[16,     3] loss: 1.370
[17,     3] loss: 1.365
[18,     3] loss: 1.329
[19,     3] loss: 1.289
[20,     3] loss: 1.231
[21,     3] loss: 1.188
[22,     3] loss: 1.142
[23,     3] loss: 1.187
[24,     3] loss: 1.193
[25,     3] loss: 1.076
[26,     3] loss: 1.115
[27,     3] loss: 1.105
[28,     3] loss: 1.085
[29,     3] loss: 1.104
[30,     3] loss: 1.121
[31,     3] loss: 1.091
[32,     3] loss: 1.124
[33,     3] loss: 1.086
[34,     3] loss: 1.020
[35,     3] loss: 1.059
[36,     3] loss: 0.955
[37,     3] loss: 0.975
[38,     3] loss: 1.047
[39,     3] loss: 0.934
[40,     3] loss: 0.955
[41,     3] loss: 0.967
[42,     3] loss: 0.962
[43,     3] loss: 0.905
[44,     3] loss: 0.900
[45,     3] loss: 0.920
[46,     3] loss: 0.987
[47,     3] loss: 0.943
[48,     3] loss: 0.839
[49,     3] loss: 0.872
[50,     3] loss: 0.849
[51,     3] loss: 0.823
[52,     3] loss: 0.884
[53,     3] loss: 0.859
[54,     3] loss: 0.989
[55,     3] loss: 0.816
[56,     3] loss: 0.858
[57,     3] loss: 0.854
[58,     3] loss: 0.878
[59,     3] loss: 0.888
[60,     3] loss: 0.826
[61,     3] loss: 0.881
[62,     3] loss: 0.806
[63,     3] loss: 0.803
[64,     3] loss: 0.794
[65,     3] loss: 0.783
[66,     3] loss: 0.784
[67,     3] loss: 0.816
[68,     3] loss: 0.813
[69,     3] loss: 0.998
[70,     3] loss: 0.780
[71,     3] loss: 0.829
[72,     3] loss: 0.839
[73,     3] loss: 0.824
[74,     3] loss: 0.842
[75,     3] loss: 0.789
[76,     3] loss: 0.845
[77,     3] loss: 0.786
Early stopping applied (best metric=0.5365292429924011)
Finished Training
Total time taken: 19.646070957183838
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.388
[3,     3] loss: 1.392
[4,     3] loss: 1.390
[5,     3] loss: 1.381
[6,     3] loss: 1.388
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.392
[10,     3] loss: 1.386
[11,     3] loss: 1.380
[12,     3] loss: 1.385
[13,     3] loss: 1.383
[14,     3] loss: 1.381
[15,     3] loss: 1.380
[16,     3] loss: 1.385
[17,     3] loss: 1.382
[18,     3] loss: 1.371
[19,     3] loss: 1.372
[20,     3] loss: 1.356
[21,     3] loss: 1.376
[22,     3] loss: 1.345
[23,     3] loss: 1.321
[24,     3] loss: 1.311
[25,     3] loss: 1.258
[26,     3] loss: 1.265
[27,     3] loss: 1.194
[28,     3] loss: 1.248
[29,     3] loss: 1.149
[30,     3] loss: 1.196
[31,     3] loss: 1.210
[32,     3] loss: 1.141
[33,     3] loss: 1.071
[34,     3] loss: 1.074
[35,     3] loss: 1.049
[36,     3] loss: 0.990
[37,     3] loss: 1.020
[38,     3] loss: 0.947
[39,     3] loss: 1.019
[40,     3] loss: 1.072
[41,     3] loss: 0.925
[42,     3] loss: 0.891
[43,     3] loss: 1.018
[44,     3] loss: 0.886
[45,     3] loss: 0.937
[46,     3] loss: 0.893
[47,     3] loss: 0.921
[48,     3] loss: 0.832
[49,     3] loss: 0.949
[50,     3] loss: 0.995
[51,     3] loss: 0.895
[52,     3] loss: 0.978
[53,     3] loss: 0.984
[54,     3] loss: 0.911
[55,     3] loss: 0.855
[56,     3] loss: 0.867
[57,     3] loss: 0.857
[58,     3] loss: 0.822
[59,     3] loss: 0.846
[60,     3] loss: 0.835
[61,     3] loss: 0.895
[62,     3] loss: 0.806
[63,     3] loss: 0.932
[64,     3] loss: 0.865
[65,     3] loss: 0.872
[66,     3] loss: 1.032
[67,     3] loss: 1.034
[68,     3] loss: 1.003
[69,     3] loss: 0.885
[70,     3] loss: 0.884
[71,     3] loss: 0.886
[72,     3] loss: 0.892
[73,     3] loss: 0.834
[74,     3] loss: 0.854
[75,     3] loss: 0.811
[76,     3] loss: 0.830
[77,     3] loss: 0.786
[78,     3] loss: 0.809
[79,     3] loss: 0.845
[80,     3] loss: 0.806
[81,     3] loss: 0.855
[82,     3] loss: 0.815
[83,     3] loss: 0.834
[84,     3] loss: 0.878
[85,     3] loss: 0.941
[86,     3] loss: 0.845
[87,     3] loss: 0.883
[88,     3] loss: 1.073
[89,     3] loss: 0.841
[90,     3] loss: 1.108
[91,     3] loss: 0.999
[92,     3] loss: 0.929
Early stopping applied (best metric=0.5216317772865295)
Finished Training
Total time taken: 23.423089504241943
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.383
[3,     3] loss: 1.398
[4,     3] loss: 1.391
[5,     3] loss: 1.390
[6,     3] loss: 1.384
[7,     3] loss: 1.395
[8,     3] loss: 1.379
[9,     3] loss: 1.383
[10,     3] loss: 1.379
[11,     3] loss: 1.382
[12,     3] loss: 1.376
[13,     3] loss: 1.372
[14,     3] loss: 1.352
[15,     3] loss: 1.357
[16,     3] loss: 1.319
[17,     3] loss: 1.286
[18,     3] loss: 1.240
[19,     3] loss: 1.224
[20,     3] loss: 1.162
[21,     3] loss: 1.129
[22,     3] loss: 1.154
[23,     3] loss: 1.089
[24,     3] loss: 1.170
[25,     3] loss: 1.208
[26,     3] loss: 1.085
[27,     3] loss: 1.228
[28,     3] loss: 1.033
[29,     3] loss: 1.061
[30,     3] loss: 1.037
[31,     3] loss: 1.103
[32,     3] loss: 1.009
[33,     3] loss: 1.094
[34,     3] loss: 0.986
[35,     3] loss: 0.912
[36,     3] loss: 0.995
[37,     3] loss: 1.022
[38,     3] loss: 0.924
[39,     3] loss: 0.933
[40,     3] loss: 0.859
[41,     3] loss: 0.957
[42,     3] loss: 0.878
[43,     3] loss: 0.940
[44,     3] loss: 0.855
[45,     3] loss: 0.821
[46,     3] loss: 0.851
[47,     3] loss: 0.836
[48,     3] loss: 0.901
[49,     3] loss: 0.909
[50,     3] loss: 0.997
[51,     3] loss: 0.949
[52,     3] loss: 1.000
[53,     3] loss: 1.058
[54,     3] loss: 1.030
[55,     3] loss: 0.999
[56,     3] loss: 0.937
[57,     3] loss: 1.046
[58,     3] loss: 0.952
[59,     3] loss: 0.874
[60,     3] loss: 0.932
[61,     3] loss: 0.850
[62,     3] loss: 0.818
[63,     3] loss: 0.811
[64,     3] loss: 0.816
[65,     3] loss: 0.802
[66,     3] loss: 0.788
[67,     3] loss: 0.827
[68,     3] loss: 0.763
[69,     3] loss: 0.785
[70,     3] loss: 0.848
[71,     3] loss: 0.831
[72,     3] loss: 0.896
[73,     3] loss: 0.831
[74,     3] loss: 0.828
[75,     3] loss: 0.772
Early stopping applied (best metric=0.5203049778938293)
Finished Training
Total time taken: 19.32806968688965
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.385
[3,     3] loss: 1.395
[4,     3] loss: 1.381
[5,     3] loss: 1.378
[6,     3] loss: 1.377
[7,     3] loss: 1.372
[8,     3] loss: 1.367
[9,     3] loss: 1.353
[10,     3] loss: 1.352
[11,     3] loss: 1.329
[12,     3] loss: 1.296
[13,     3] loss: 1.285
[14,     3] loss: 1.231
[15,     3] loss: 1.206
[16,     3] loss: 1.302
[17,     3] loss: 1.268
[18,     3] loss: 1.185
[19,     3] loss: 1.095
[20,     3] loss: 1.104
[21,     3] loss: 1.087
[22,     3] loss: 1.150
[23,     3] loss: 1.046
[24,     3] loss: 1.016
[25,     3] loss: 1.038
[26,     3] loss: 1.071
[27,     3] loss: 1.053
[28,     3] loss: 1.117
[29,     3] loss: 0.982
[30,     3] loss: 0.965
[31,     3] loss: 0.954
[32,     3] loss: 0.955
[33,     3] loss: 0.932
[34,     3] loss: 0.902
[35,     3] loss: 0.928
[36,     3] loss: 0.923
[37,     3] loss: 0.912
[38,     3] loss: 0.936
[39,     3] loss: 1.001
[40,     3] loss: 0.921
[41,     3] loss: 1.109
[42,     3] loss: 0.965
[43,     3] loss: 0.886
[44,     3] loss: 0.944
[45,     3] loss: 0.904
[46,     3] loss: 0.922
[47,     3] loss: 0.858
[48,     3] loss: 0.835
[49,     3] loss: 0.831
[50,     3] loss: 0.823
[51,     3] loss: 0.890
[52,     3] loss: 0.801
[53,     3] loss: 0.824
[54,     3] loss: 0.820
[55,     3] loss: 0.817
[56,     3] loss: 0.854
[57,     3] loss: 0.839
[58,     3] loss: 0.940
[59,     3] loss: 0.866
[60,     3] loss: 0.862
[61,     3] loss: 0.841
[62,     3] loss: 0.871
[63,     3] loss: 0.866
[64,     3] loss: 0.829
[65,     3] loss: 0.830
[66,     3] loss: 0.857
[67,     3] loss: 0.844
[68,     3] loss: 0.814
[69,     3] loss: 0.785
[70,     3] loss: 0.809
[71,     3] loss: 0.780
[72,     3] loss: 0.802
[73,     3] loss: 0.774
[74,     3] loss: 0.769
[75,     3] loss: 0.822
[76,     3] loss: 0.793
[77,     3] loss: 0.772
[78,     3] loss: 0.792
[79,     3] loss: 0.876
[80,     3] loss: 0.789
[81,     3] loss: 0.855
[82,     3] loss: 0.863
[83,     3] loss: 0.859
[84,     3] loss: 0.799
[85,     3] loss: 0.806
[86,     3] loss: 0.782
[87,     3] loss: 0.803
[88,     3] loss: 0.817
[89,     3] loss: 0.796
[90,     3] loss: 0.761
[91,     3] loss: 0.808
[92,     3] loss: 0.845
[93,     3] loss: 0.792
[94,     3] loss: 0.910
[95,     3] loss: 0.907
[96,     3] loss: 0.817
[97,     3] loss: 0.811
[98,     3] loss: 0.859
[99,     3] loss: 0.777
[100,     3] loss: 0.787
[101,     3] loss: 0.760
[102,     3] loss: 0.779
[103,     3] loss: 0.835
Early stopping applied (best metric=0.4947088658809662)
Finished Training
Total time taken: 25.900094032287598
{'S-palmitoylation-C Validation Accuracy': 0.6587990846287789, 'S-palmitoylation-C Validation Sensitivity': 0.2872607260726073, 'S-palmitoylation-C Validation Specificity': 0.7519255862395818, 'S-palmitoylation-C Validation Precision': 0.2346798350785039, 'S-palmitoylation-C AUC ROC': 0.5329648307038228, 'S-palmitoylation-C AUC PR': 0.22259079677736485, 'S-palmitoylation-C MCC': 0.040858786880575086, 'S-palmitoylation-C F1': 0.22410443424491497, 'Validation Loss (S-palmitoylation-C)': 0.5550810138384501, 'Hydroxylation-K Validation Accuracy': 0.6914893617021277, 'Hydroxylation-K Validation Sensitivity': 0.7725925925925926, 'Hydroxylation-K Validation Specificity': 0.6719298245614035, 'Hydroxylation-K Validation Precision': 0.4134648923064591, 'Hydroxylation-K AUC ROC': 0.7779922027290449, 'Hydroxylation-K AUC PR': 0.5641246281662072, 'Hydroxylation-K MCC': 0.3836151821775553, 'Hydroxylation-K F1': 0.5177669263473861, 'Validation Loss (Hydroxylation-K)': 0.5209200461705525, 'Validation Loss (total)': 1.0760010719299316, 'TimeToTrain': 21.13864318529765}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003377154946642639,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4739034814196255,
 'loss_weight_S-palmitoylation-C': 0.9108960480603525,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2779429927,
 'sample_weights': [0.21214910842738033, 0.235288762854278],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.34486856573704,
 'weight_decay_Hydroxylation-K': 8.107554035122016,
 'weight_decay_S-palmitoylation-C': 3.2373146983547736}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.384
[3,     3] loss: 1.384
[4,     3] loss: 1.385
[5,     3] loss: 1.380
[6,     3] loss: 1.385
[7,     3] loss: 1.383
[8,     3] loss: 1.378
[9,     3] loss: 1.378
[10,     3] loss: 1.369
[11,     3] loss: 1.379
[12,     3] loss: 1.374
[13,     3] loss: 1.361
[14,     3] loss: 1.359
[15,     3] loss: 1.339
[16,     3] loss: 1.336
[17,     3] loss: 1.341
[18,     3] loss: 1.324
[19,     3] loss: 1.322
[20,     3] loss: 1.294
[21,     3] loss: 1.334
[22,     3] loss: 1.277
[23,     3] loss: 1.263
[24,     3] loss: 1.229
[25,     3] loss: 1.236
[26,     3] loss: 1.158
[27,     3] loss: 1.178
[28,     3] loss: 1.198
[29,     3] loss: 1.185
[30,     3] loss: 1.080
[31,     3] loss: 1.082
[32,     3] loss: 1.032
[33,     3] loss: 1.083
[34,     3] loss: 1.039
[35,     3] loss: 1.036
[36,     3] loss: 1.004
[37,     3] loss: 0.982
[38,     3] loss: 0.940
[39,     3] loss: 0.997
[40,     3] loss: 0.940
[41,     3] loss: 0.927
[42,     3] loss: 0.966
[43,     3] loss: 0.950
[44,     3] loss: 0.909
[45,     3] loss: 0.929
[46,     3] loss: 0.970
[47,     3] loss: 1.024
[48,     3] loss: 1.011
[49,     3] loss: 0.926
[50,     3] loss: 0.919
[51,     3] loss: 0.973
[52,     3] loss: 0.996
[53,     3] loss: 0.882
[54,     3] loss: 0.947
[55,     3] loss: 0.958
[56,     3] loss: 0.944
[57,     3] loss: 0.876
[58,     3] loss: 0.902
[59,     3] loss: 0.874
[60,     3] loss: 0.863
[61,     3] loss: 0.887
[62,     3] loss: 0.894
[63,     3] loss: 0.893
[64,     3] loss: 0.815
[65,     3] loss: 0.826
[66,     3] loss: 0.823
[67,     3] loss: 0.816
[68,     3] loss: 0.785
[69,     3] loss: 0.837
[70,     3] loss: 0.783
[71,     3] loss: 0.780
[72,     3] loss: 0.777
[73,     3] loss: 0.768
[74,     3] loss: 0.794
[75,     3] loss: 0.758
[76,     3] loss: 0.775
[77,     3] loss: 0.772
[78,     3] loss: 0.757
[79,     3] loss: 0.749
[80,     3] loss: 0.758
[81,     3] loss: 0.762
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006471724272984973,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.94590966955154,
 'loss_weight_S-palmitoylation-C': 0.050457896990513305,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 498135497,
 'sample_weights': [0.9108960480603525, 0.4739034814196255],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.36746685115041,
 'weight_decay_Hydroxylation-K': 6.816302205716775,
 'weight_decay_S-palmitoylation-C': 6.099147664949188}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.397
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003180433394099758,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6470336865613826,
 'loss_weight_S-palmitoylation-C': 0.8052649564463596,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3736877128,
 'sample_weights': [0.050457896990513305, 0.94590966955154],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.2607018465842845,
 'weight_decay_Hydroxylation-K': 9.603806322557828,
 'weight_decay_S-palmitoylation-C': 0.06511231498227499}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.393
[3,     3] loss: 1.381
[4,     3] loss: 1.386
[5,     3] loss: 1.385
[6,     3] loss: 1.383
[7,     3] loss: 1.385
[8,     3] loss: 1.385
[9,     3] loss: 1.383
[10,     3] loss: 1.383
[11,     3] loss: 1.384
[12,     3] loss: 1.372
[13,     3] loss: 1.373
[14,     3] loss: 1.365
[15,     3] loss: 1.312
[16,     3] loss: 1.345
[17,     3] loss: 1.217
[18,     3] loss: 1.197
[19,     3] loss: 1.171
[20,     3] loss: 1.131
[21,     3] loss: 1.122
[22,     3] loss: 1.137
[23,     3] loss: 1.086
[24,     3] loss: 1.034
[25,     3] loss: 1.121
[26,     3] loss: 1.113
[27,     3] loss: 1.143
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006268567100173107,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.19179948271645048,
 'loss_weight_S-palmitoylation-C': 0.21820918882197016,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 348082301,
 'sample_weights': [0.8052649564463596, 0.6470336865613826],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.597857503548798,
 'weight_decay_Hydroxylation-K': 0.30214859444830433,
 'weight_decay_S-palmitoylation-C': 1.3268302825059863}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.389
[3,     3] loss: 1.391
[4,     3] loss: 1.400
[5,     3] loss: 1.389
[6,     3] loss: 1.383
[7,     3] loss: 1.387
[8,     3] loss: 1.388
[9,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002689846801503918,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24134933295652683,
 'loss_weight_S-palmitoylation-C': 0.5115265898066627,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2225018274,
 'sample_weights': [0.21820918882197016, 0.19179948271645048],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3988498299199343,
 'weight_decay_Hydroxylation-K': 2.672096134244054,
 'weight_decay_S-palmitoylation-C': 0.922178752345785}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.389
[3,     3] loss: 1.387
[4,     3] loss: 1.381
[5,     3] loss: 1.385
[6,     3] loss: 1.385
[7,     3] loss: 1.388
[8,     3] loss: 1.388
[9,     3] loss: 1.379
[10,     3] loss: 1.366
[11,     3] loss: 1.376
[12,     3] loss: 1.363
[13,     3] loss: 1.341
[14,     3] loss: 1.359
[15,     3] loss: 1.336
[16,     3] loss: 1.289
[17,     3] loss: 1.229
[18,     3] loss: 1.266
[19,     3] loss: 1.185
[20,     3] loss: 1.181
[21,     3] loss: 1.176
[22,     3] loss: 1.242
[23,     3] loss: 1.195
[24,     3] loss: 1.151
[25,     3] loss: 1.146
[26,     3] loss: 1.054
[27,     3] loss: 1.108
[28,     3] loss: 1.062
[29,     3] loss: 1.062
[30,     3] loss: 1.101
[31,     3] loss: 1.037
[32,     3] loss: 1.000
[33,     3] loss: 0.964
[34,     3] loss: 0.976
[35,     3] loss: 1.045
[36,     3] loss: 1.047
[37,     3] loss: 1.132
[38,     3] loss: 1.077
[39,     3] loss: 1.055
[40,     3] loss: 1.041
[41,     3] loss: 1.011
[42,     3] loss: 1.039
[43,     3] loss: 0.997
[44,     3] loss: 0.983
[45,     3] loss: 1.018
[46,     3] loss: 0.877
[47,     3] loss: 0.864
[48,     3] loss: 0.933
[49,     3] loss: 0.801
[50,     3] loss: 0.824
[51,     3] loss: 0.911
[52,     3] loss: 0.776
[53,     3] loss: 0.815
[54,     3] loss: 0.817
[55,     3] loss: 0.768
[56,     3] loss: 0.844
[57,     3] loss: 0.766
[58,     3] loss: 0.973
[59,     3] loss: 0.780
[60,     3] loss: 0.805
[61,     3] loss: 0.842
[62,     3] loss: 0.901
[63,     3] loss: 0.875
[64,     3] loss: 0.773
[65,     3] loss: 0.841
[66,     3] loss: 0.799
[67,     3] loss: 0.776
[68,     3] loss: 0.812
[69,     3] loss: 0.761
[70,     3] loss: 0.819
[71,     3] loss: 0.783
[72,     3] loss: 0.760
[73,     3] loss: 0.813
[74,     3] loss: 0.870
[75,     3] loss: 0.816
[76,     3] loss: 0.784
[77,     3] loss: 0.895
[78,     3] loss: 0.844
[79,     3] loss: 0.871
[80,     3] loss: 0.811
[81,     3] loss: 0.846
[82,     3] loss: 0.802
[83,     3] loss: 0.857
[84,     3] loss: 0.878
[85,     3] loss: 0.802
[86,     3] loss: 0.879
[87,     3] loss: 0.881
[88,     3] loss: 0.759
[89,     3] loss: 0.769
[90,     3] loss: 0.749
[91,     3] loss: 0.732
[92,     3] loss: 0.736
[93,     3] loss: 0.744
Early stopping applied (best metric=0.5171141624450684)
Finished Training
Total time taken: 23.92508816719055
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.399
[2,     3] loss: 1.387
[3,     3] loss: 1.397
[4,     3] loss: 1.392
[5,     3] loss: 1.386
[6,     3] loss: 1.388
[7,     3] loss: 1.385
[8,     3] loss: 1.387
[9,     3] loss: 1.385
[10,     3] loss: 1.391
[11,     3] loss: 1.387
[12,     3] loss: 1.389
[13,     3] loss: 1.381
[14,     3] loss: 1.388
[15,     3] loss: 1.382
[16,     3] loss: 1.383
[17,     3] loss: 1.384
[18,     3] loss: 1.390
[19,     3] loss: 1.381
[20,     3] loss: 1.385
[21,     3] loss: 1.375
[22,     3] loss: 1.381
[23,     3] loss: 1.377
[24,     3] loss: 1.373
[25,     3] loss: 1.375
[26,     3] loss: 1.363
[27,     3] loss: 1.359
[28,     3] loss: 1.322
[29,     3] loss: 1.295
[30,     3] loss: 1.245
[31,     3] loss: 1.225
[32,     3] loss: 1.207
[33,     3] loss: 1.232
[34,     3] loss: 1.212
[35,     3] loss: 1.235
[36,     3] loss: 1.137
[37,     3] loss: 1.198
[38,     3] loss: 1.107
[39,     3] loss: 1.074
[40,     3] loss: 1.098
[41,     3] loss: 1.146
[42,     3] loss: 1.034
[43,     3] loss: 1.090
[44,     3] loss: 1.036
[45,     3] loss: 0.974
[46,     3] loss: 1.014
[47,     3] loss: 0.987
[48,     3] loss: 0.869
[49,     3] loss: 0.958
[50,     3] loss: 0.938
[51,     3] loss: 0.898
[52,     3] loss: 0.904
[53,     3] loss: 0.852
[54,     3] loss: 0.865
[55,     3] loss: 0.856
[56,     3] loss: 0.885
[57,     3] loss: 0.796
[58,     3] loss: 0.900
[59,     3] loss: 0.891
[60,     3] loss: 0.871
[61,     3] loss: 0.848
[62,     3] loss: 0.846
[63,     3] loss: 0.822
[64,     3] loss: 0.916
[65,     3] loss: 0.765
[66,     3] loss: 0.903
[67,     3] loss: 0.800
[68,     3] loss: 0.792
[69,     3] loss: 0.889
[70,     3] loss: 0.788
[71,     3] loss: 0.789
[72,     3] loss: 0.784
[73,     3] loss: 0.769
[74,     3] loss: 0.758
[75,     3] loss: 0.861
[76,     3] loss: 0.872
[77,     3] loss: 0.809
[78,     3] loss: 0.785
[79,     3] loss: 0.805
[80,     3] loss: 0.858
[81,     3] loss: 0.864
[82,     3] loss: 0.803
[83,     3] loss: 0.817
Early stopping applied (best metric=0.5007550716400146)
Finished Training
Total time taken: 21.530078649520874
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.390
[3,     3] loss: 1.388
[4,     3] loss: 1.394
[5,     3] loss: 1.386
[6,     3] loss: 1.388
[7,     3] loss: 1.388
[8,     3] loss: 1.382
[9,     3] loss: 1.384
[10,     3] loss: 1.383
[11,     3] loss: 1.390
[12,     3] loss: 1.392
[13,     3] loss: 1.383
[14,     3] loss: 1.373
[15,     3] loss: 1.370
[16,     3] loss: 1.368
[17,     3] loss: 1.362
[18,     3] loss: 1.349
[19,     3] loss: 1.350
[20,     3] loss: 1.310
[21,     3] loss: 1.313
[22,     3] loss: 1.255
[23,     3] loss: 1.223
[24,     3] loss: 1.242
[25,     3] loss: 1.188
[26,     3] loss: 1.170
[27,     3] loss: 1.066
[28,     3] loss: 1.085
[29,     3] loss: 1.156
[30,     3] loss: 0.998
[31,     3] loss: 1.104
[32,     3] loss: 1.057
[33,     3] loss: 1.075
[34,     3] loss: 1.013
[35,     3] loss: 1.040
[36,     3] loss: 0.979
[37,     3] loss: 1.010
[38,     3] loss: 0.995
[39,     3] loss: 1.068
[40,     3] loss: 0.914
[41,     3] loss: 0.910
[42,     3] loss: 0.905
[43,     3] loss: 0.906
[44,     3] loss: 0.906
[45,     3] loss: 0.904
[46,     3] loss: 0.828
[47,     3] loss: 0.971
[48,     3] loss: 0.896
[49,     3] loss: 0.961
[50,     3] loss: 0.832
[51,     3] loss: 0.858
[52,     3] loss: 0.893
[53,     3] loss: 0.906
[54,     3] loss: 0.863
[55,     3] loss: 0.834
[56,     3] loss: 0.855
[57,     3] loss: 0.782
[58,     3] loss: 0.776
[59,     3] loss: 0.772
[60,     3] loss: 0.857
[61,     3] loss: 0.809
[62,     3] loss: 0.749
[63,     3] loss: 0.742
[64,     3] loss: 0.810
[65,     3] loss: 0.775
[66,     3] loss: 0.823
[67,     3] loss: 0.809
[68,     3] loss: 0.777
[69,     3] loss: 0.768
[70,     3] loss: 0.789
[71,     3] loss: 0.751
[72,     3] loss: 0.729
[73,     3] loss: 0.748
[74,     3] loss: 0.741
[75,     3] loss: 0.782
[76,     3] loss: 0.727
Early stopping applied (best metric=0.5042840242385864)
Finished Training
Total time taken: 20.21507453918457
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.394
[3,     3] loss: 1.391
[4,     3] loss: 1.386
[5,     3] loss: 1.387
[6,     3] loss: 1.389
[7,     3] loss: 1.382
[8,     3] loss: 1.397
[9,     3] loss: 1.388
[10,     3] loss: 1.386
[11,     3] loss: 1.382
[12,     3] loss: 1.384
[13,     3] loss: 1.388
[14,     3] loss: 1.381
[15,     3] loss: 1.386
[16,     3] loss: 1.375
[17,     3] loss: 1.377
[18,     3] loss: 1.377
[19,     3] loss: 1.369
[20,     3] loss: 1.360
[21,     3] loss: 1.354
[22,     3] loss: 1.341
[23,     3] loss: 1.319
[24,     3] loss: 1.317
[25,     3] loss: 1.274
[26,     3] loss: 1.264
[27,     3] loss: 1.152
[28,     3] loss: 1.251
[29,     3] loss: 1.177
[30,     3] loss: 1.159
[31,     3] loss: 1.109
[32,     3] loss: 1.108
[33,     3] loss: 1.152
[34,     3] loss: 1.043
[35,     3] loss: 1.084
[36,     3] loss: 1.080
[37,     3] loss: 1.041
[38,     3] loss: 1.104
[39,     3] loss: 1.099
[40,     3] loss: 1.080
[41,     3] loss: 1.023
[42,     3] loss: 1.070
[43,     3] loss: 1.049
[44,     3] loss: 1.018
[45,     3] loss: 1.071
[46,     3] loss: 1.097
[47,     3] loss: 0.930
[48,     3] loss: 0.978
[49,     3] loss: 1.066
[50,     3] loss: 0.964
[51,     3] loss: 0.940
[52,     3] loss: 0.936
[53,     3] loss: 0.958
[54,     3] loss: 0.897
[55,     3] loss: 0.945
[56,     3] loss: 0.935
[57,     3] loss: 0.898
[58,     3] loss: 0.854
[59,     3] loss: 0.852
[60,     3] loss: 0.897
[61,     3] loss: 0.876
[62,     3] loss: 0.787
[63,     3] loss: 0.824
[64,     3] loss: 0.889
[65,     3] loss: 0.841
[66,     3] loss: 0.767
[67,     3] loss: 0.770
[68,     3] loss: 0.791
[69,     3] loss: 0.794
[70,     3] loss: 0.794
[71,     3] loss: 0.770
[72,     3] loss: 0.755
[73,     3] loss: 0.754
[74,     3] loss: 0.737
[75,     3] loss: 0.752
[76,     3] loss: 0.766
[77,     3] loss: 0.775
[78,     3] loss: 0.792
[79,     3] loss: 0.785
[80,     3] loss: 0.754
[81,     3] loss: 0.730
[82,     3] loss: 0.726
[83,     3] loss: 0.745
[84,     3] loss: 0.735
[85,     3] loss: 0.765
[86,     3] loss: 0.768
[87,     3] loss: 0.745
[88,     3] loss: 0.801
Early stopping applied (best metric=0.4964626133441925)
Finished Training
Total time taken: 22.5850830078125
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.384
[3,     3] loss: 1.386
[4,     3] loss: 1.380
[5,     3] loss: 1.385
[6,     3] loss: 1.388
[7,     3] loss: 1.386
[8,     3] loss: 1.388
[9,     3] loss: 1.386
[10,     3] loss: 1.380
[11,     3] loss: 1.384
[12,     3] loss: 1.383
[13,     3] loss: 1.372
[14,     3] loss: 1.379
[15,     3] loss: 1.371
[16,     3] loss: 1.370
[17,     3] loss: 1.376
[18,     3] loss: 1.344
[19,     3] loss: 1.332
[20,     3] loss: 1.344
[21,     3] loss: 1.304
[22,     3] loss: 1.263
[23,     3] loss: 1.227
[24,     3] loss: 1.277
[25,     3] loss: 1.291
[26,     3] loss: 1.202
[27,     3] loss: 1.254
[28,     3] loss: 1.199
[29,     3] loss: 1.184
[30,     3] loss: 1.226
[31,     3] loss: 1.091
[32,     3] loss: 1.107
[33,     3] loss: 1.150
[34,     3] loss: 1.087
[35,     3] loss: 1.132
[36,     3] loss: 1.068
[37,     3] loss: 1.031
[38,     3] loss: 0.978
[39,     3] loss: 0.935
[40,     3] loss: 0.977
[41,     3] loss: 0.973
[42,     3] loss: 1.027
[43,     3] loss: 0.900
[44,     3] loss: 0.879
[45,     3] loss: 0.863
[46,     3] loss: 0.855
[47,     3] loss: 0.851
[48,     3] loss: 0.963
[49,     3] loss: 0.877
[50,     3] loss: 0.938
[51,     3] loss: 0.939
[52,     3] loss: 0.831
[53,     3] loss: 0.883
[54,     3] loss: 0.884
[55,     3] loss: 0.812
[56,     3] loss: 0.808
[57,     3] loss: 0.849
[58,     3] loss: 0.803
[59,     3] loss: 0.790
[60,     3] loss: 0.830
[61,     3] loss: 0.777
[62,     3] loss: 0.797
[63,     3] loss: 0.807
[64,     3] loss: 0.768
[65,     3] loss: 0.785
[66,     3] loss: 0.920
[67,     3] loss: 0.822
[68,     3] loss: 0.770
[69,     3] loss: 0.770
[70,     3] loss: 0.775
[71,     3] loss: 0.806
[72,     3] loss: 0.731
[73,     3] loss: 0.803
[74,     3] loss: 0.760
[75,     3] loss: 0.767
[76,     3] loss: 0.823
[77,     3] loss: 0.860
[78,     3] loss: 0.782
[79,     3] loss: 0.892
[80,     3] loss: 0.772
[81,     3] loss: 0.777
[82,     3] loss: 0.871
[83,     3] loss: 0.747
[84,     3] loss: 0.767
[85,     3] loss: 0.764
[86,     3] loss: 0.741
[87,     3] loss: 0.789
[88,     3] loss: 0.722
[89,     3] loss: 0.724
[90,     3] loss: 0.715
[91,     3] loss: 0.710
[92,     3] loss: 0.710
[93,     3] loss: 0.726
[94,     3] loss: 0.714
[95,     3] loss: 0.708
[96,     3] loss: 0.729
Early stopping applied (best metric=0.4590933322906494)
Finished Training
Total time taken: 24.697092294692993
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.383
[3,     3] loss: 1.378
[4,     3] loss: 1.374
[5,     3] loss: 1.388
[6,     3] loss: 1.391
[7,     3] loss: 1.381
[8,     3] loss: 1.387
[9,     3] loss: 1.384
[10,     3] loss: 1.390
[11,     3] loss: 1.389
[12,     3] loss: 1.379
[13,     3] loss: 1.389
[14,     3] loss: 1.376
[15,     3] loss: 1.377
[16,     3] loss: 1.378
[17,     3] loss: 1.368
[18,     3] loss: 1.371
[19,     3] loss: 1.371
[20,     3] loss: 1.351
[21,     3] loss: 1.318
[22,     3] loss: 1.320
[23,     3] loss: 1.256
[24,     3] loss: 1.213
[25,     3] loss: 1.215
[26,     3] loss: 1.191
[27,     3] loss: 1.299
[28,     3] loss: 1.200
[29,     3] loss: 1.183
[30,     3] loss: 1.120
[31,     3] loss: 1.141
[32,     3] loss: 1.218
[33,     3] loss: 1.144
[34,     3] loss: 1.219
[35,     3] loss: 1.158
[36,     3] loss: 1.079
[37,     3] loss: 1.101
[38,     3] loss: 1.032
[39,     3] loss: 1.088
[40,     3] loss: 1.070
[41,     3] loss: 0.997
[42,     3] loss: 0.973
[43,     3] loss: 0.984
[44,     3] loss: 0.940
[45,     3] loss: 0.930
[46,     3] loss: 0.882
[47,     3] loss: 0.856
[48,     3] loss: 1.025
[49,     3] loss: 0.908
[50,     3] loss: 0.923
[51,     3] loss: 0.872
[52,     3] loss: 0.834
[53,     3] loss: 0.914
[54,     3] loss: 0.975
[55,     3] loss: 1.146
[56,     3] loss: 0.937
[57,     3] loss: 0.858
[58,     3] loss: 0.932
[59,     3] loss: 0.891
[60,     3] loss: 0.880
[61,     3] loss: 0.898
[62,     3] loss: 0.920
[63,     3] loss: 0.846
[64,     3] loss: 0.823
[65,     3] loss: 0.809
[66,     3] loss: 0.799
[67,     3] loss: 0.885
[68,     3] loss: 0.763
[69,     3] loss: 0.833
[70,     3] loss: 0.779
[71,     3] loss: 0.738
[72,     3] loss: 0.790
[73,     3] loss: 0.751
[74,     3] loss: 0.765
[75,     3] loss: 0.740
[76,     3] loss: 0.803
[77,     3] loss: 0.722
[78,     3] loss: 0.741
[79,     3] loss: 0.864
[80,     3] loss: 0.732
[81,     3] loss: 0.785
[82,     3] loss: 0.748
[83,     3] loss: 0.811
[84,     3] loss: 0.755
[85,     3] loss: 0.853
[86,     3] loss: 0.801
Early stopping applied (best metric=0.5179940462112427)
Finished Training
Total time taken: 22.086080312728882
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.388
[3,     3] loss: 1.396
[4,     3] loss: 1.390
[5,     3] loss: 1.391
[6,     3] loss: 1.383
[7,     3] loss: 1.387
[8,     3] loss: 1.387
[9,     3] loss: 1.386
[10,     3] loss: 1.379
[11,     3] loss: 1.386
[12,     3] loss: 1.382
[13,     3] loss: 1.386
[14,     3] loss: 1.380
[15,     3] loss: 1.373
[16,     3] loss: 1.368
[17,     3] loss: 1.368
[18,     3] loss: 1.359
[19,     3] loss: 1.353
[20,     3] loss: 1.358
[21,     3] loss: 1.319
[22,     3] loss: 1.276
[23,     3] loss: 1.268
[24,     3] loss: 1.221
[25,     3] loss: 1.218
[26,     3] loss: 1.275
[27,     3] loss: 1.168
[28,     3] loss: 1.216
[29,     3] loss: 1.209
[30,     3] loss: 1.145
[31,     3] loss: 1.139
[32,     3] loss: 1.146
[33,     3] loss: 1.085
[34,     3] loss: 1.179
[35,     3] loss: 1.088
[36,     3] loss: 1.131
[37,     3] loss: 1.100
[38,     3] loss: 0.986
[39,     3] loss: 0.975
[40,     3] loss: 1.009
[41,     3] loss: 0.956
[42,     3] loss: 0.995
[43,     3] loss: 0.953
[44,     3] loss: 0.987
[45,     3] loss: 0.943
[46,     3] loss: 0.919
[47,     3] loss: 0.875
[48,     3] loss: 0.935
[49,     3] loss: 0.860
[50,     3] loss: 0.836
[51,     3] loss: 0.941
[52,     3] loss: 0.865
[53,     3] loss: 0.819
[54,     3] loss: 0.881
[55,     3] loss: 0.778
[56,     3] loss: 0.822
[57,     3] loss: 0.974
[58,     3] loss: 0.832
[59,     3] loss: 0.883
[60,     3] loss: 0.857
[61,     3] loss: 0.870
[62,     3] loss: 0.861
[63,     3] loss: 0.875
[64,     3] loss: 0.878
[65,     3] loss: 0.908
[66,     3] loss: 0.916
[67,     3] loss: 0.897
[68,     3] loss: 0.898
[69,     3] loss: 0.855
[70,     3] loss: 0.849
[71,     3] loss: 0.840
[72,     3] loss: 0.856
[73,     3] loss: 0.840
[74,     3] loss: 0.778
[75,     3] loss: 0.762
[76,     3] loss: 0.749
[77,     3] loss: 0.791
[78,     3] loss: 0.738
[79,     3] loss: 0.752
[80,     3] loss: 0.743
[81,     3] loss: 0.776
[82,     3] loss: 0.793
[83,     3] loss: 0.764
[84,     3] loss: 0.740
[85,     3] loss: 0.821
[86,     3] loss: 0.761
[87,     3] loss: 0.819
[88,     3] loss: 0.832
[89,     3] loss: 0.779
[90,     3] loss: 0.840
[91,     3] loss: 0.825
Early stopping applied (best metric=0.5075914263725281)
Finished Training
Total time taken: 23.04608726501465
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.368
[3,     3] loss: 1.409
[4,     3] loss: 1.388
[5,     3] loss: 1.389
[6,     3] loss: 1.369
[7,     3] loss: 1.374
[8,     3] loss: 1.373
[9,     3] loss: 1.346
[10,     3] loss: 1.374
[11,     3] loss: 1.314
[12,     3] loss: 1.312
[13,     3] loss: 1.266
[14,     3] loss: 1.283
[15,     3] loss: 1.196
[16,     3] loss: 1.283
[17,     3] loss: 1.184
[18,     3] loss: 1.180
[19,     3] loss: 1.290
[20,     3] loss: 1.218
[21,     3] loss: 1.257
[22,     3] loss: 1.158
[23,     3] loss: 1.149
[24,     3] loss: 1.180
[25,     3] loss: 1.105
[26,     3] loss: 1.171
[27,     3] loss: 1.052
[28,     3] loss: 1.090
[29,     3] loss: 1.201
[30,     3] loss: 1.219
[31,     3] loss: 1.020
[32,     3] loss: 1.013
[33,     3] loss: 1.104
[34,     3] loss: 1.108
[35,     3] loss: 1.046
[36,     3] loss: 1.088
[37,     3] loss: 1.004
[38,     3] loss: 1.103
[39,     3] loss: 0.961
[40,     3] loss: 0.965
[41,     3] loss: 0.945
[42,     3] loss: 0.970
[43,     3] loss: 0.841
[44,     3] loss: 0.873
[45,     3] loss: 0.880
[46,     3] loss: 0.819
[47,     3] loss: 0.889
[48,     3] loss: 0.839
[49,     3] loss: 0.953
[50,     3] loss: 0.846
[51,     3] loss: 0.850
[52,     3] loss: 0.820
[53,     3] loss: 0.919
[54,     3] loss: 0.866
[55,     3] loss: 0.793
[56,     3] loss: 0.803
[57,     3] loss: 0.774
[58,     3] loss: 0.754
[59,     3] loss: 0.765
[60,     3] loss: 0.784
[61,     3] loss: 0.738
[62,     3] loss: 0.754
[63,     3] loss: 0.766
[64,     3] loss: 0.837
[65,     3] loss: 0.738
[66,     3] loss: 0.778
[67,     3] loss: 0.882
[68,     3] loss: 0.909
[69,     3] loss: 0.941
[70,     3] loss: 0.888
[71,     3] loss: 0.966
[72,     3] loss: 0.875
[73,     3] loss: 0.982
[74,     3] loss: 0.839
[75,     3] loss: 0.851
[76,     3] loss: 0.862
[77,     3] loss: 0.837
[78,     3] loss: 0.842
[79,     3] loss: 0.768
[80,     3] loss: 0.867
[81,     3] loss: 0.823
[82,     3] loss: 0.788
[83,     3] loss: 0.786
[84,     3] loss: 0.769
[85,     3] loss: 0.830
[86,     3] loss: 0.733
[87,     3] loss: 0.794
[88,     3] loss: 0.781
[89,     3] loss: 0.759
[90,     3] loss: 0.756
[91,     3] loss: 0.750
[92,     3] loss: 0.771
[93,     3] loss: 0.736
[94,     3] loss: 0.736
[95,     3] loss: 0.742
Early stopping applied (best metric=0.5177912712097168)
Finished Training
Total time taken: 24.56108784675598
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.390
[3,     3] loss: 1.383
[4,     3] loss: 1.395
[5,     3] loss: 1.384
[6,     3] loss: 1.381
[7,     3] loss: 1.379
[8,     3] loss: 1.387
[9,     3] loss: 1.378
[10,     3] loss: 1.386
[11,     3] loss: 1.392
[12,     3] loss: 1.383
[13,     3] loss: 1.394
[14,     3] loss: 1.387
[15,     3] loss: 1.393
[16,     3] loss: 1.390
[17,     3] loss: 1.382
[18,     3] loss: 1.384
[19,     3] loss: 1.384
[20,     3] loss: 1.379
[21,     3] loss: 1.383
[22,     3] loss: 1.376
[23,     3] loss: 1.358
[24,     3] loss: 1.372
[25,     3] loss: 1.338
[26,     3] loss: 1.323
[27,     3] loss: 1.334
[28,     3] loss: 1.294
[29,     3] loss: 1.250
[30,     3] loss: 1.171
[31,     3] loss: 1.210
[32,     3] loss: 1.191
[33,     3] loss: 1.131
[34,     3] loss: 1.152
[35,     3] loss: 1.165
[36,     3] loss: 1.069
[37,     3] loss: 1.161
[38,     3] loss: 1.039
[39,     3] loss: 1.197
[40,     3] loss: 1.037
[41,     3] loss: 1.033
[42,     3] loss: 1.134
[43,     3] loss: 1.108
[44,     3] loss: 1.053
[45,     3] loss: 0.996
[46,     3] loss: 0.997
[47,     3] loss: 1.002
[48,     3] loss: 1.068
[49,     3] loss: 0.916
[50,     3] loss: 0.929
[51,     3] loss: 0.918
[52,     3] loss: 0.912
[53,     3] loss: 0.871
[54,     3] loss: 0.816
[55,     3] loss: 0.892
[56,     3] loss: 0.837
[57,     3] loss: 0.868
[58,     3] loss: 0.827
[59,     3] loss: 0.911
[60,     3] loss: 0.853
[61,     3] loss: 0.814
[62,     3] loss: 0.855
[63,     3] loss: 0.796
[64,     3] loss: 0.840
[65,     3] loss: 0.793
[66,     3] loss: 0.982
[67,     3] loss: 0.806
[68,     3] loss: 0.872
[69,     3] loss: 0.791
[70,     3] loss: 0.829
[71,     3] loss: 0.831
[72,     3] loss: 0.803
[73,     3] loss: 0.836
[74,     3] loss: 0.762
[75,     3] loss: 0.842
[76,     3] loss: 0.786
[77,     3] loss: 1.034
[78,     3] loss: 0.813
[79,     3] loss: 0.828
[80,     3] loss: 0.893
[81,     3] loss: 0.793
[82,     3] loss: 0.779
[83,     3] loss: 0.842
[84,     3] loss: 0.754
[85,     3] loss: 0.767
[86,     3] loss: 0.748
[87,     3] loss: 0.740
Early stopping applied (best metric=0.4894830584526062)
Finished Training
Total time taken: 22.331084966659546
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.387
[3,     3] loss: 1.388
[4,     3] loss: 1.391
[5,     3] loss: 1.388
[6,     3] loss: 1.389
[7,     3] loss: 1.390
[8,     3] loss: 1.390
[9,     3] loss: 1.388
[10,     3] loss: 1.381
[11,     3] loss: 1.379
[12,     3] loss: 1.384
[13,     3] loss: 1.380
[14,     3] loss: 1.376
[15,     3] loss: 1.383
[16,     3] loss: 1.362
[17,     3] loss: 1.352
[18,     3] loss: 1.321
[19,     3] loss: 1.306
[20,     3] loss: 1.229
[21,     3] loss: 1.233
[22,     3] loss: 1.187
[23,     3] loss: 1.137
[24,     3] loss: 1.094
[25,     3] loss: 1.258
[26,     3] loss: 1.131
[27,     3] loss: 1.111
[28,     3] loss: 1.103
[29,     3] loss: 1.121
[30,     3] loss: 1.057
[31,     3] loss: 1.028
[32,     3] loss: 1.077
[33,     3] loss: 1.124
[34,     3] loss: 1.032
[35,     3] loss: 0.953
[36,     3] loss: 0.957
[37,     3] loss: 1.067
[38,     3] loss: 1.064
[39,     3] loss: 0.966
[40,     3] loss: 0.913
[41,     3] loss: 0.928
[42,     3] loss: 1.021
[43,     3] loss: 0.890
[44,     3] loss: 0.891
[45,     3] loss: 0.916
[46,     3] loss: 0.930
[47,     3] loss: 0.831
[48,     3] loss: 0.878
[49,     3] loss: 0.871
[50,     3] loss: 0.966
[51,     3] loss: 0.847
[52,     3] loss: 0.898
[53,     3] loss: 0.953
[54,     3] loss: 0.833
[55,     3] loss: 0.855
[56,     3] loss: 0.892
[57,     3] loss: 0.829
[58,     3] loss: 0.805
[59,     3] loss: 0.817
[60,     3] loss: 0.794
[61,     3] loss: 0.788
[62,     3] loss: 0.937
[63,     3] loss: 1.008
[64,     3] loss: 0.933
[65,     3] loss: 0.873
[66,     3] loss: 0.860
[67,     3] loss: 0.883
[68,     3] loss: 0.851
[69,     3] loss: 0.812
[70,     3] loss: 0.806
[71,     3] loss: 0.793
[72,     3] loss: 0.800
Early stopping applied (best metric=0.5284768342971802)
Finished Training
Total time taken: 18.27738046646118
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.395
[3,     3] loss: 1.391
[4,     3] loss: 1.391
[5,     3] loss: 1.386
[6,     3] loss: 1.382
[7,     3] loss: 1.382
[8,     3] loss: 1.384
[9,     3] loss: 1.370
[10,     3] loss: 1.372
[11,     3] loss: 1.363
[12,     3] loss: 1.367
[13,     3] loss: 1.343
[14,     3] loss: 1.367
[15,     3] loss: 1.307
[16,     3] loss: 1.258
[17,     3] loss: 1.241
[18,     3] loss: 1.211
[19,     3] loss: 1.198
[20,     3] loss: 1.254
[21,     3] loss: 1.164
[22,     3] loss: 1.211
[23,     3] loss: 1.227
[24,     3] loss: 1.099
[25,     3] loss: 1.230
[26,     3] loss: 1.111
[27,     3] loss: 1.166
[28,     3] loss: 1.118
[29,     3] loss: 1.102
[30,     3] loss: 1.184
[31,     3] loss: 1.043
[32,     3] loss: 1.031
[33,     3] loss: 1.129
[34,     3] loss: 1.032
[35,     3] loss: 1.023
[36,     3] loss: 1.031
[37,     3] loss: 0.997
[38,     3] loss: 1.006
[39,     3] loss: 1.038
[40,     3] loss: 0.998
[41,     3] loss: 0.896
[42,     3] loss: 0.954
[43,     3] loss: 0.997
[44,     3] loss: 0.996
[45,     3] loss: 0.922
[46,     3] loss: 0.964
[47,     3] loss: 0.895
[48,     3] loss: 0.830
[49,     3] loss: 0.823
[50,     3] loss: 0.907
[51,     3] loss: 0.902
[52,     3] loss: 0.860
[53,     3] loss: 0.823
[54,     3] loss: 0.855
[55,     3] loss: 0.837
[56,     3] loss: 0.844
[57,     3] loss: 0.887
[58,     3] loss: 0.857
[59,     3] loss: 0.903
[60,     3] loss: 0.818
[61,     3] loss: 0.845
[62,     3] loss: 0.807
[63,     3] loss: 0.843
[64,     3] loss: 0.795
[65,     3] loss: 0.825
[66,     3] loss: 0.834
[67,     3] loss: 0.773
[68,     3] loss: 0.767
[69,     3] loss: 0.761
[70,     3] loss: 0.755
[71,     3] loss: 0.742
[72,     3] loss: 0.789
[73,     3] loss: 0.747
[74,     3] loss: 0.723
[75,     3] loss: 0.740
[76,     3] loss: 0.727
[77,     3] loss: 0.715
[78,     3] loss: 0.722
[79,     3] loss: 0.713
[80,     3] loss: 0.734
[81,     3] loss: 0.774
[82,     3] loss: 0.757
[83,     3] loss: 0.722
[84,     3] loss: 0.726
[85,     3] loss: 0.735
[86,     3] loss: 0.748
[87,     3] loss: 0.758
[88,     3] loss: 0.767
[89,     3] loss: 0.725
[90,     3] loss: 0.802
[91,     3] loss: 0.848
[92,     3] loss: 0.721
[93,     3] loss: 0.742
[94,     3] loss: 0.723
[95,     3] loss: 0.747
[96,     3] loss: 0.739
[97,     3] loss: 0.731
[98,     3] loss: 0.762
[99,     3] loss: 0.767
[100,     3] loss: 0.797
[101,     3] loss: 0.724
[102,     3] loss: 0.728
[103,     3] loss: 0.733
[104,     3] loss: 0.731
[105,     3] loss: 0.734
[106,     3] loss: 0.730
[107,     3] loss: 0.719
[108,     3] loss: 0.720
[109,     3] loss: 0.715
[110,     3] loss: 0.719
[111,     3] loss: 0.706
[112,     3] loss: 0.715
[113,     3] loss: 0.716
[114,     3] loss: 0.708
[115,     3] loss: 0.711
[116,     3] loss: 0.716
[117,     3] loss: 0.842
[118,     3] loss: 0.823
[119,     3] loss: 0.732
[120,     3] loss: 0.759
[121,     3] loss: 0.747
[122,     3] loss: 0.762
[123,     3] loss: 0.718
[124,     3] loss: 0.734
[125,     3] loss: 0.736
[126,     3] loss: 0.746
[127,     3] loss: 0.735
[128,     3] loss: 0.734
[129,     3] loss: 0.715
[130,     3] loss: 0.832
[131,     3] loss: 0.724
[132,     3] loss: 0.725
[133,     3] loss: 0.725
[134,     3] loss: 0.740
[135,     3] loss: 0.723
[136,     3] loss: 0.916
[137,     3] loss: 0.962
[138,     3] loss: 0.906
[139,     3] loss: 0.752
[140,     3] loss: 0.876
[141,     3] loss: 0.802
Early stopping applied (best metric=0.5459661483764648)
Finished Training
Total time taken: 36.54213547706604
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.384
[3,     3] loss: 1.388
[4,     3] loss: 1.381
[5,     3] loss: 1.378
[6,     3] loss: 1.383
[7,     3] loss: 1.386
[8,     3] loss: 1.361
[9,     3] loss: 1.408
[10,     3] loss: 1.372
[11,     3] loss: 1.361
[12,     3] loss: 1.358
[13,     3] loss: 1.344
[14,     3] loss: 1.346
[15,     3] loss: 1.315
[16,     3] loss: 1.302
[17,     3] loss: 1.271
[18,     3] loss: 1.208
[19,     3] loss: 1.278
[20,     3] loss: 1.183
[21,     3] loss: 1.176
[22,     3] loss: 1.152
[23,     3] loss: 1.196
[24,     3] loss: 1.133
[25,     3] loss: 1.128
[26,     3] loss: 1.090
[27,     3] loss: 1.031
[28,     3] loss: 1.029
[29,     3] loss: 1.061
[30,     3] loss: 1.152
[31,     3] loss: 0.938
[32,     3] loss: 1.131
[33,     3] loss: 0.991
[34,     3] loss: 1.105
[35,     3] loss: 0.983
[36,     3] loss: 1.022
[37,     3] loss: 0.975
[38,     3] loss: 0.984
[39,     3] loss: 0.905
[40,     3] loss: 0.931
[41,     3] loss: 0.993
[42,     3] loss: 0.883
[43,     3] loss: 0.968
[44,     3] loss: 0.927
[45,     3] loss: 0.927
[46,     3] loss: 0.902
[47,     3] loss: 0.904
[48,     3] loss: 0.915
[49,     3] loss: 0.847
[50,     3] loss: 0.817
[51,     3] loss: 0.845
[52,     3] loss: 0.867
[53,     3] loss: 0.849
[54,     3] loss: 0.808
[55,     3] loss: 0.955
[56,     3] loss: 0.783
[57,     3] loss: 0.803
[58,     3] loss: 0.839
[59,     3] loss: 0.781
[60,     3] loss: 0.895
[61,     3] loss: 0.791
[62,     3] loss: 0.789
[63,     3] loss: 0.828
[64,     3] loss: 0.777
[65,     3] loss: 0.836
[66,     3] loss: 0.771
[67,     3] loss: 0.778
[68,     3] loss: 0.793
[69,     3] loss: 0.751
[70,     3] loss: 0.765
[71,     3] loss: 0.747
[72,     3] loss: 0.785
[73,     3] loss: 0.745
[74,     3] loss: 0.750
Early stopping applied (best metric=0.5174535512924194)
Finished Training
Total time taken: 18.71606945991516
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.387
[3,     3] loss: 1.388
[4,     3] loss: 1.388
[5,     3] loss: 1.381
[6,     3] loss: 1.381
[7,     3] loss: 1.389
[8,     3] loss: 1.387
[9,     3] loss: 1.380
[10,     3] loss: 1.381
[11,     3] loss: 1.383
[12,     3] loss: 1.377
[13,     3] loss: 1.368
[14,     3] loss: 1.360
[15,     3] loss: 1.372
[16,     3] loss: 1.361
[17,     3] loss: 1.343
[18,     3] loss: 1.311
[19,     3] loss: 1.286
[20,     3] loss: 1.261
[21,     3] loss: 1.204
[22,     3] loss: 1.176
[23,     3] loss: 1.153
[24,     3] loss: 1.190
[25,     3] loss: 1.097
[26,     3] loss: 1.085
[27,     3] loss: 1.021
[28,     3] loss: 1.002
[29,     3] loss: 0.983
[30,     3] loss: 0.916
[31,     3] loss: 1.043
[32,     3] loss: 0.952
[33,     3] loss: 0.984
[34,     3] loss: 0.970
[35,     3] loss: 0.948
[36,     3] loss: 0.952
[37,     3] loss: 0.863
[38,     3] loss: 0.916
[39,     3] loss: 0.899
[40,     3] loss: 0.890
[41,     3] loss: 0.834
[42,     3] loss: 0.896
[43,     3] loss: 0.936
[44,     3] loss: 0.819
[45,     3] loss: 0.826
[46,     3] loss: 0.822
[47,     3] loss: 0.874
[48,     3] loss: 0.824
[49,     3] loss: 0.815
[50,     3] loss: 0.852
[51,     3] loss: 0.778
[52,     3] loss: 0.801
[53,     3] loss: 0.799
[54,     3] loss: 0.761
[55,     3] loss: 0.803
[56,     3] loss: 0.791
[57,     3] loss: 0.740
[58,     3] loss: 0.747
[59,     3] loss: 0.775
[60,     3] loss: 0.935
[61,     3] loss: 1.169
[62,     3] loss: 1.115
[63,     3] loss: 0.958
[64,     3] loss: 0.977
[65,     3] loss: 0.892
[66,     3] loss: 0.880
[67,     3] loss: 0.850
[68,     3] loss: 0.849
[69,     3] loss: 0.846
[70,     3] loss: 0.774
[71,     3] loss: 0.758
[72,     3] loss: 0.767
[73,     3] loss: 0.783
[74,     3] loss: 0.778
[75,     3] loss: 0.819
[76,     3] loss: 0.723
[77,     3] loss: 0.772
Early stopping applied (best metric=0.5408626794815063)
Finished Training
Total time taken: 19.71407699584961
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.381
[3,     3] loss: 1.400
[4,     3] loss: 1.389
[5,     3] loss: 1.398
[6,     3] loss: 1.384
[7,     3] loss: 1.387
[8,     3] loss: 1.388
[9,     3] loss: 1.386
[10,     3] loss: 1.381
[11,     3] loss: 1.387
[12,     3] loss: 1.383
[13,     3] loss: 1.382
[14,     3] loss: 1.378
[15,     3] loss: 1.379
[16,     3] loss: 1.375
[17,     3] loss: 1.369
[18,     3] loss: 1.372
[19,     3] loss: 1.350
[20,     3] loss: 1.365
[21,     3] loss: 1.308
[22,     3] loss: 1.306
[23,     3] loss: 1.226
[24,     3] loss: 1.226
[25,     3] loss: 1.338
[26,     3] loss: 1.215
[27,     3] loss: 1.280
[28,     3] loss: 1.165
[29,     3] loss: 1.170
[30,     3] loss: 1.174
[31,     3] loss: 1.188
[32,     3] loss: 1.132
[33,     3] loss: 1.143
[34,     3] loss: 1.062
[35,     3] loss: 1.076
[36,     3] loss: 0.988
[37,     3] loss: 1.011
[38,     3] loss: 1.042
[39,     3] loss: 1.044
[40,     3] loss: 0.949
[41,     3] loss: 1.029
[42,     3] loss: 0.955
[43,     3] loss: 0.989
[44,     3] loss: 0.967
[45,     3] loss: 1.081
[46,     3] loss: 0.903
[47,     3] loss: 0.951
[48,     3] loss: 0.890
[49,     3] loss: 0.873
[50,     3] loss: 0.919
[51,     3] loss: 0.998
[52,     3] loss: 0.923
[53,     3] loss: 0.841
[54,     3] loss: 0.807
[55,     3] loss: 0.841
[56,     3] loss: 0.844
[57,     3] loss: 0.843
[58,     3] loss: 0.820
[59,     3] loss: 0.849
[60,     3] loss: 0.794
[61,     3] loss: 0.800
[62,     3] loss: 0.794
[63,     3] loss: 0.806
[64,     3] loss: 0.783
[65,     3] loss: 0.782
[66,     3] loss: 0.806
[67,     3] loss: 0.745
[68,     3] loss: 0.760
[69,     3] loss: 0.772
[70,     3] loss: 0.748
[71,     3] loss: 0.766
[72,     3] loss: 0.716
[73,     3] loss: 0.726
[74,     3] loss: 0.779
[75,     3] loss: 0.857
[76,     3] loss: 0.958
[77,     3] loss: 0.908
[78,     3] loss: 0.791
[79,     3] loss: 0.826
[80,     3] loss: 0.827
[81,     3] loss: 0.829
[82,     3] loss: 0.767
[83,     3] loss: 0.789
Early stopping applied (best metric=0.4618823230266571)
Finished Training
Total time taken: 19.05807113647461
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.377
[3,     3] loss: 1.415
[4,     3] loss: 1.379
[5,     3] loss: 1.387
[6,     3] loss: 1.379
[7,     3] loss: 1.375
[8,     3] loss: 1.371
[9,     3] loss: 1.377
[10,     3] loss: 1.357
[11,     3] loss: 1.326
[12,     3] loss: 1.330
[13,     3] loss: 1.280
[14,     3] loss: 1.264
[15,     3] loss: 1.228
[16,     3] loss: 1.176
[17,     3] loss: 1.211
[18,     3] loss: 1.179
[19,     3] loss: 1.122
[20,     3] loss: 1.222
[21,     3] loss: 1.093
[22,     3] loss: 1.100
[23,     3] loss: 1.091
[24,     3] loss: 1.161
[25,     3] loss: 1.113
[26,     3] loss: 1.157
[27,     3] loss: 1.094
[28,     3] loss: 1.033
[29,     3] loss: 1.071
[30,     3] loss: 1.058
[31,     3] loss: 1.022
[32,     3] loss: 0.968
[33,     3] loss: 1.076
[34,     3] loss: 0.890
[35,     3] loss: 0.985
[36,     3] loss: 0.909
[37,     3] loss: 0.903
[38,     3] loss: 0.909
[39,     3] loss: 0.918
[40,     3] loss: 0.845
[41,     3] loss: 0.921
[42,     3] loss: 0.898
[43,     3] loss: 0.843
[44,     3] loss: 0.979
[45,     3] loss: 1.027
[46,     3] loss: 1.142
[47,     3] loss: 1.089
[48,     3] loss: 0.965
[49,     3] loss: 0.880
[50,     3] loss: 0.889
[51,     3] loss: 0.932
[52,     3] loss: 0.884
[53,     3] loss: 0.927
[54,     3] loss: 0.844
[55,     3] loss: 0.821
[56,     3] loss: 0.869
[57,     3] loss: 0.986
[58,     3] loss: 0.909
[59,     3] loss: 0.884
[60,     3] loss: 0.818
[61,     3] loss: 0.949
[62,     3] loss: 1.060
[63,     3] loss: 0.903
[64,     3] loss: 0.920
[65,     3] loss: 0.927
[66,     3] loss: 0.894
[67,     3] loss: 0.860
[68,     3] loss: 0.936
[69,     3] loss: 0.893
[70,     3] loss: 0.839
[71,     3] loss: 0.786
[72,     3] loss: 0.812
[73,     3] loss: 0.890
[74,     3] loss: 0.789
[75,     3] loss: 0.786
[76,     3] loss: 0.845
[77,     3] loss: 0.813
[78,     3] loss: 0.848
[79,     3] loss: 0.800
[80,     3] loss: 0.791
[81,     3] loss: 0.825
[82,     3] loss: 0.812
[83,     3] loss: 0.859
[84,     3] loss: 0.783
[85,     3] loss: 0.803
[86,     3] loss: 0.884
[87,     3] loss: 0.899
[88,     3] loss: 0.876
[89,     3] loss: 0.994
[90,     3] loss: 0.853
[91,     3] loss: 0.939
[92,     3] loss: 0.812
[93,     3] loss: 0.843
[94,     3] loss: 0.816
[95,     3] loss: 0.782
[96,     3] loss: 0.747
[97,     3] loss: 0.753
[98,     3] loss: 0.733
[99,     3] loss: 0.731
[100,     3] loss: 0.730
[101,     3] loss: 0.718
[102,     3] loss: 0.713
[103,     3] loss: 0.720
[104,     3] loss: 0.724
[105,     3] loss: 0.716
[106,     3] loss: 0.717
[107,     3] loss: 0.717
[108,     3] loss: 0.709
[109,     3] loss: 0.705
[110,     3] loss: 0.705
[111,     3] loss: 0.706
[112,     3] loss: 0.712
[113,     3] loss: 0.707
[114,     3] loss: 0.711
[115,     3] loss: 0.704
[116,     3] loss: 0.714
[117,     3] loss: 0.709
[118,     3] loss: 0.724
[119,     3] loss: 0.706
[120,     3] loss: 0.701
[121,     3] loss: 0.715
[122,     3] loss: 0.729
[123,     3] loss: 0.761
[124,     3] loss: 0.765
[125,     3] loss: 0.746
[126,     3] loss: 0.743
[127,     3] loss: 0.790
[128,     3] loss: 0.951
[129,     3] loss: 0.882
[130,     3] loss: 0.883
[131,     3] loss: 0.772
[132,     3] loss: 0.948
[133,     3] loss: 0.958
[134,     3] loss: 0.767
[135,     3] loss: 0.811
[136,     3] loss: 0.770
[137,     3] loss: 0.753
[138,     3] loss: 0.790
[139,     3] loss: 0.730
[140,     3] loss: 0.767
[141,     3] loss: 0.728
[142,     3] loss: 0.736
[143,     3] loss: 0.711
[144,     3] loss: 0.724
[145,     3] loss: 0.707
[146,     3] loss: 0.714
[147,     3] loss: 0.719
[148,     3] loss: 0.720
[149,     3] loss: 0.712
[150,     3] loss: 0.707
[151,     3] loss: 0.743
[152,     3] loss: 0.723
[153,     3] loss: 0.809
[154,     3] loss: 0.804
[155,     3] loss: 0.741
[156,     3] loss: 0.815
[157,     3] loss: 0.816
[158,     3] loss: 0.767
[159,     3] loss: 0.789
[160,     3] loss: 0.780
[161,     3] loss: 0.784
[162,     3] loss: 0.853
[163,     3] loss: 0.799
[164,     3] loss: 0.766
[165,     3] loss: 0.766
[166,     3] loss: 0.816
[167,     3] loss: 0.813
[168,     3] loss: 0.729
[169,     3] loss: 0.749
[170,     3] loss: 0.722
[171,     3] loss: 0.719
[172,     3] loss: 0.716
[173,     3] loss: 0.719
[174,     3] loss: 0.730
[175,     3] loss: 0.713
[176,     3] loss: 0.716
[177,     3] loss: 0.706
[178,     3] loss: 0.709
[179,     3] loss: 0.716
[180,     3] loss: 0.707
[181,     3] loss: 0.700
[182,     3] loss: 0.706
[183,     3] loss: 0.704
[184,     3] loss: 0.704
[185,     3] loss: 0.700
[186,     3] loss: 0.703
[187,     3] loss: 0.703
[188,     3] loss: 0.720
[189,     3] loss: 0.711
[190,     3] loss: 0.704
[191,     3] loss: 0.702
[192,     3] loss: 0.727
[193,     3] loss: 0.721
[194,     3] loss: 0.706
[195,     3] loss: 0.703
[196,     3] loss: 0.704
[197,     3] loss: 0.703
[198,     3] loss: 0.701
[199,     3] loss: 0.702
[200,     3] loss: 0.708
Finished Training
Total time taken: 44.73116374015808
{'S-palmitoylation-C Validation Accuracy': 0.6948999140920539, 'S-palmitoylation-C Validation Sensitivity': 0.21188118811881188, 'S-palmitoylation-C Validation Specificity': 0.8159794917792164, 'S-palmitoylation-C Validation Precision': 0.22448278436699817, 'S-palmitoylation-C AUC ROC': 0.5313159186255547, 'S-palmitoylation-C AUC PR': 0.2203743797626822, 'S-palmitoylation-C MCC': 0.028639662169670437, 'S-palmitoylation-C F1': 0.20090109519777294, 'Validation Loss (S-palmitoylation-C)': 0.555799933274587, 'Hydroxylation-K Validation Accuracy': 0.7407801418439717, 'Hydroxylation-K Validation Sensitivity': 0.7711111111111111, 'Hydroxylation-K Validation Specificity': 0.7333333333333333, 'Hydroxylation-K Validation Precision': 0.4394560375984525, 'Hydroxylation-K AUC ROC': 0.8072514619883041, 'Hydroxylation-K AUC PR': 0.5917549745559372, 'Hydroxylation-K MCC': 0.43260429449610943, 'Hydroxylation-K F1': 0.5496503685806011, 'Validation Loss (Hydroxylation-K)': 0.507576851050059, 'Validation Loss (total)': 1.0633768002192179, 'TimeToTrain': 24.134376955032348}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002395648528318167,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.27759663375635196,
 'loss_weight_S-palmitoylation-C': 0.4951362282173216,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3184006935,
 'sample_weights': [0.5115265898066627, 0.24134933295652683],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.574943497801078,
 'weight_decay_Hydroxylation-K': 5.2100429529733745,
 'weight_decay_S-palmitoylation-C': 1.0413392215980948}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.379
[2,     3] loss: 1.405
[3,     3] loss: 1.394
[4,     3] loss: 1.387
[5,     3] loss: 1.389
[6,     3] loss: 1.386
[7,     3] loss: 1.386
[8,     3] loss: 1.382
[9,     3] loss: 1.376
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005735390201437382,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.033239634530187245,
 'loss_weight_S-palmitoylation-C': 0.7133480352170519,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2637825158,
 'sample_weights': [0.4951362282173216, 0.27759663375635196],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.3506707457374496,
 'weight_decay_Hydroxylation-K': 2.3904783401464353,
 'weight_decay_S-palmitoylation-C': 1.723972629434489}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.384
[3,     3] loss: 1.380
[4,     3] loss: 1.389
[5,     3] loss: 1.391
[6,     3] loss: 1.387
[7,     3] loss: 1.378
[8,     3] loss: 1.378
[9,     3] loss: 1.402
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001132176835002361,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.47995835452782726,
 'loss_weight_S-palmitoylation-C': 0.7191510151349537,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1660034407,
 'sample_weights': [0.7133480352170519, 0.033239634530187245],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.920422077242199,
 'weight_decay_Hydroxylation-K': 5.480075340289619,
 'weight_decay_S-palmitoylation-C': 0.1294238493315688}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.389
[3,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002971847153026668,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5515491051469574,
 'loss_weight_S-palmitoylation-C': 0.46927630556526667,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2019332582,
 'sample_weights': [0.7191510151349537, 0.47995835452782726],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.745238103704775,
 'weight_decay_Hydroxylation-K': 4.445077352570248,
 'weight_decay_S-palmitoylation-C': 0.03441808495622192}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.379
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007995692783427241,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.284931448786482,
 'loss_weight_S-palmitoylation-C': 0.39366007221779653,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2108931068,
 'sample_weights': [0.46927630556526667, 0.5515491051469574],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.203779284512827,
 'weight_decay_Hydroxylation-K': 7.449617892999994,
 'weight_decay_S-palmitoylation-C': 8.03585826423583}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.389
[3,     3] loss: 1.382
[4,     3] loss: 1.375
[5,     3] loss: 1.379
[6,     3] loss: 1.371
[7,     3] loss: 1.370
[8,     3] loss: 1.352
[9,     3] loss: 1.355
[10,     3] loss: 1.321
[11,     3] loss: 1.291
[12,     3] loss: 1.325
[13,     3] loss: 1.272
[14,     3] loss: 1.242
[15,     3] loss: 1.254
[16,     3] loss: 1.207
[17,     3] loss: 1.202
[18,     3] loss: 1.151
[19,     3] loss: 1.183
[20,     3] loss: 1.110
[21,     3] loss: 1.127
[22,     3] loss: 1.150
[23,     3] loss: 1.084
[24,     3] loss: 1.100
[25,     3] loss: 1.071
[26,     3] loss: 1.056
[27,     3] loss: 1.140
[28,     3] loss: 0.994
[29,     3] loss: 0.983
[30,     3] loss: 1.017
[31,     3] loss: 0.949
[32,     3] loss: 0.959
[33,     3] loss: 1.015
[34,     3] loss: 0.935
[35,     3] loss: 1.019
[36,     3] loss: 0.917
[37,     3] loss: 0.961
[38,     3] loss: 0.934
[39,     3] loss: 0.857
[40,     3] loss: 0.887
[41,     3] loss: 0.858
[42,     3] loss: 0.867
[43,     3] loss: 0.819
[44,     3] loss: 0.842
[45,     3] loss: 0.848
[46,     3] loss: 0.926
[47,     3] loss: 0.843
[48,     3] loss: 1.055
[49,     3] loss: 0.821
[50,     3] loss: 0.909
[51,     3] loss: 0.844
[52,     3] loss: 0.838
[53,     3] loss: 0.826
[54,     3] loss: 0.820
[55,     3] loss: 0.811
[56,     3] loss: 0.873
[57,     3] loss: 0.798
[58,     3] loss: 0.784
[59,     3] loss: 0.837
[60,     3] loss: 0.796
[61,     3] loss: 0.875
[62,     3] loss: 0.822
[63,     3] loss: 0.905
[64,     3] loss: 0.883
[65,     3] loss: 0.837
[66,     3] loss: 0.868
[67,     3] loss: 0.874
[68,     3] loss: 0.816
[69,     3] loss: 0.805
[70,     3] loss: 0.805
[71,     3] loss: 0.772
[72,     3] loss: 0.807
[73,     3] loss: 0.790
[74,     3] loss: 0.808
Early stopping applied (best metric=0.511951208114624)
Finished Training
Total time taken: 16.584754943847656
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.387
[3,     3] loss: 1.391
[4,     3] loss: 1.381
[5,     3] loss: 1.380
[6,     3] loss: 1.379
[7,     3] loss: 1.372
[8,     3] loss: 1.362
[9,     3] loss: 1.342
[10,     3] loss: 1.354
[11,     3] loss: 1.314
[12,     3] loss: 1.333
[13,     3] loss: 1.275
[14,     3] loss: 1.275
[15,     3] loss: 1.255
[16,     3] loss: 1.199
[17,     3] loss: 1.182
[18,     3] loss: 1.247
[19,     3] loss: 1.184
[20,     3] loss: 1.133
[21,     3] loss: 1.132
[22,     3] loss: 1.172
[23,     3] loss: 1.088
[24,     3] loss: 1.046
[25,     3] loss: 1.079
[26,     3] loss: 1.187
[27,     3] loss: 0.984
[28,     3] loss: 1.067
[29,     3] loss: 0.922
[30,     3] loss: 1.169
[31,     3] loss: 0.947
[32,     3] loss: 0.979
[33,     3] loss: 0.928
[34,     3] loss: 0.930
[35,     3] loss: 0.990
[36,     3] loss: 0.961
[37,     3] loss: 0.888
[38,     3] loss: 0.922
[39,     3] loss: 0.933
[40,     3] loss: 0.939
[41,     3] loss: 0.887
[42,     3] loss: 0.909
[43,     3] loss: 0.918
[44,     3] loss: 0.861
[45,     3] loss: 0.873
[46,     3] loss: 0.831
[47,     3] loss: 0.860
[48,     3] loss: 0.862
[49,     3] loss: 0.825
[50,     3] loss: 0.858
[51,     3] loss: 0.835
[52,     3] loss: 0.828
[53,     3] loss: 0.838
[54,     3] loss: 0.831
[55,     3] loss: 0.811
[56,     3] loss: 0.781
[57,     3] loss: 0.790
[58,     3] loss: 0.823
[59,     3] loss: 0.787
[60,     3] loss: 0.819
[61,     3] loss: 0.798
[62,     3] loss: 0.812
[63,     3] loss: 0.841
[64,     3] loss: 0.824
[65,     3] loss: 0.881
[66,     3] loss: 0.995
[67,     3] loss: 0.823
[68,     3] loss: 0.895
[69,     3] loss: 0.894
[70,     3] loss: 0.840
[71,     3] loss: 0.829
[72,     3] loss: 0.839
[73,     3] loss: 0.882
[74,     3] loss: 0.832
[75,     3] loss: 0.806
[76,     3] loss: 0.793
[77,     3] loss: 0.819
[78,     3] loss: 0.826
[79,     3] loss: 0.874
[80,     3] loss: 0.799
[81,     3] loss: 0.816
[82,     3] loss: 0.867
[83,     3] loss: 0.824
[84,     3] loss: 0.793
[85,     3] loss: 0.901
[86,     3] loss: 0.819
[87,     3] loss: 0.857
[88,     3] loss: 0.798
[89,     3] loss: 0.842
[90,     3] loss: 0.933
[91,     3] loss: 0.845
[92,     3] loss: 0.840
[93,     3] loss: 0.818
[94,     3] loss: 0.816
[95,     3] loss: 0.841
[96,     3] loss: 0.785
[97,     3] loss: 0.807
[98,     3] loss: 0.856
[99,     3] loss: 0.788
[100,     3] loss: 0.830
[101,     3] loss: 0.922
[102,     3] loss: 0.815
[103,     3] loss: 0.865
Early stopping applied (best metric=0.5137149691581726)
Finished Training
Total time taken: 23.100083351135254
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.388
[3,     3] loss: 1.385
[4,     3] loss: 1.384
[5,     3] loss: 1.382
[6,     3] loss: 1.385
[7,     3] loss: 1.386
[8,     3] loss: 1.382
[9,     3] loss: 1.383
[10,     3] loss: 1.374
[11,     3] loss: 1.371
[12,     3] loss: 1.357
[13,     3] loss: 1.343
[14,     3] loss: 1.330
[15,     3] loss: 1.286
[16,     3] loss: 1.253
[17,     3] loss: 1.259
[18,     3] loss: 1.271
[19,     3] loss: 1.195
[20,     3] loss: 1.161
[21,     3] loss: 1.174
[22,     3] loss: 1.115
[23,     3] loss: 1.198
[24,     3] loss: 1.186
[25,     3] loss: 1.094
[26,     3] loss: 1.179
[27,     3] loss: 1.053
[28,     3] loss: 1.059
[29,     3] loss: 1.131
[30,     3] loss: 1.177
[31,     3] loss: 1.104
[32,     3] loss: 1.039
[33,     3] loss: 1.032
[34,     3] loss: 1.037
[35,     3] loss: 1.004
[36,     3] loss: 0.987
[37,     3] loss: 0.923
[38,     3] loss: 0.950
[39,     3] loss: 0.923
[40,     3] loss: 0.945
[41,     3] loss: 0.851
[42,     3] loss: 0.854
[43,     3] loss: 0.847
[44,     3] loss: 0.811
[45,     3] loss: 0.848
[46,     3] loss: 0.803
[47,     3] loss: 0.782
[48,     3] loss: 0.843
[49,     3] loss: 0.965
[50,     3] loss: 0.805
[51,     3] loss: 0.794
[52,     3] loss: 0.842
[53,     3] loss: 0.772
[54,     3] loss: 0.784
[55,     3] loss: 0.826
[56,     3] loss: 0.807
[57,     3] loss: 0.800
[58,     3] loss: 0.858
[59,     3] loss: 0.774
[60,     3] loss: 0.800
[61,     3] loss: 0.800
[62,     3] loss: 0.825
[63,     3] loss: 0.895
[64,     3] loss: 0.934
[65,     3] loss: 0.894
[66,     3] loss: 0.979
[67,     3] loss: 0.908
[68,     3] loss: 0.835
[69,     3] loss: 0.853
[70,     3] loss: 0.869
[71,     3] loss: 0.856
[72,     3] loss: 0.827
[73,     3] loss: 0.806
[74,     3] loss: 0.843
[75,     3] loss: 0.801
[76,     3] loss: 0.789
[77,     3] loss: 0.815
[78,     3] loss: 0.799
[79,     3] loss: 0.850
[80,     3] loss: 0.772
[81,     3] loss: 0.923
[82,     3] loss: 0.877
[83,     3] loss: 0.769
[84,     3] loss: 0.851
[85,     3] loss: 0.839
[86,     3] loss: 0.826
[87,     3] loss: 0.843
[88,     3] loss: 0.787
[89,     3] loss: 0.787
[90,     3] loss: 0.786
[91,     3] loss: 0.782
[92,     3] loss: 0.777
[93,     3] loss: 0.772
[94,     3] loss: 0.811
[95,     3] loss: 0.755
[96,     3] loss: 0.781
[97,     3] loss: 0.836
[98,     3] loss: 0.879
[99,     3] loss: 0.842
Early stopping applied (best metric=0.5410642623901367)
Finished Training
Total time taken: 22.08909034729004
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.389
[3,     3] loss: 1.385
[4,     3] loss: 1.386
[5,     3] loss: 1.378
[6,     3] loss: 1.387
[7,     3] loss: 1.382
[8,     3] loss: 1.376
[9,     3] loss: 1.370
[10,     3] loss: 1.373
[11,     3] loss: 1.365
[12,     3] loss: 1.344
[13,     3] loss: 1.346
[14,     3] loss: 1.300
[15,     3] loss: 1.304
[16,     3] loss: 1.291
[17,     3] loss: 1.255
[18,     3] loss: 1.244
[19,     3] loss: 1.205
[20,     3] loss: 1.207
[21,     3] loss: 1.150
[22,     3] loss: 1.183
[23,     3] loss: 1.150
[24,     3] loss: 1.121
[25,     3] loss: 1.121
[26,     3] loss: 1.084
[27,     3] loss: 1.088
[28,     3] loss: 1.056
[29,     3] loss: 0.954
[30,     3] loss: 0.956
[31,     3] loss: 0.963
[32,     3] loss: 1.012
[33,     3] loss: 0.999
[34,     3] loss: 0.883
[35,     3] loss: 0.936
[36,     3] loss: 0.928
[37,     3] loss: 0.907
[38,     3] loss: 0.988
[39,     3] loss: 0.924
[40,     3] loss: 0.904
[41,     3] loss: 0.893
[42,     3] loss: 0.895
[43,     3] loss: 0.905
[44,     3] loss: 0.881
[45,     3] loss: 0.869
[46,     3] loss: 0.911
[47,     3] loss: 0.921
[48,     3] loss: 0.877
[49,     3] loss: 0.899
[50,     3] loss: 0.855
[51,     3] loss: 0.849
[52,     3] loss: 0.814
[53,     3] loss: 0.940
[54,     3] loss: 0.878
[55,     3] loss: 1.011
[56,     3] loss: 0.925
[57,     3] loss: 0.923
[58,     3] loss: 0.947
[59,     3] loss: 0.898
[60,     3] loss: 0.860
[61,     3] loss: 0.872
[62,     3] loss: 0.927
[63,     3] loss: 0.842
[64,     3] loss: 0.877
[65,     3] loss: 0.841
[66,     3] loss: 0.998
[67,     3] loss: 0.839
[68,     3] loss: 0.881
[69,     3] loss: 0.862
[70,     3] loss: 0.883
[71,     3] loss: 0.848
[72,     3] loss: 0.852
Early stopping applied (best metric=0.5165278911590576)
Finished Training
Total time taken: 16.021058082580566
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.388
[3,     3] loss: 1.379
[4,     3] loss: 1.383
[5,     3] loss: 1.379
[6,     3] loss: 1.374
[7,     3] loss: 1.371
[8,     3] loss: 1.364
[9,     3] loss: 1.345
[10,     3] loss: 1.357
[11,     3] loss: 1.295
[12,     3] loss: 1.275
[13,     3] loss: 1.258
[14,     3] loss: 1.237
[15,     3] loss: 1.241
[16,     3] loss: 1.215
[17,     3] loss: 1.169
[18,     3] loss: 1.175
[19,     3] loss: 1.212
[20,     3] loss: 1.219
[21,     3] loss: 1.096
[22,     3] loss: 1.110
[23,     3] loss: 1.056
[24,     3] loss: 1.060
[25,     3] loss: 1.080
[26,     3] loss: 1.063
[27,     3] loss: 0.942
[28,     3] loss: 0.946
[29,     3] loss: 0.984
[30,     3] loss: 0.912
[31,     3] loss: 0.997
[32,     3] loss: 0.900
[33,     3] loss: 0.906
[34,     3] loss: 0.964
[35,     3] loss: 0.965
[36,     3] loss: 0.945
[37,     3] loss: 1.216
[38,     3] loss: 0.872
[39,     3] loss: 0.941
[40,     3] loss: 1.011
[41,     3] loss: 0.860
[42,     3] loss: 0.892
[43,     3] loss: 0.891
[44,     3] loss: 0.895
[45,     3] loss: 0.847
[46,     3] loss: 0.835
[47,     3] loss: 0.836
[48,     3] loss: 0.838
[49,     3] loss: 0.894
[50,     3] loss: 0.902
[51,     3] loss: 0.876
[52,     3] loss: 0.806
[53,     3] loss: 0.861
[54,     3] loss: 0.872
[55,     3] loss: 0.831
[56,     3] loss: 0.900
[57,     3] loss: 0.801
[58,     3] loss: 0.813
[59,     3] loss: 0.830
[60,     3] loss: 0.797
[61,     3] loss: 0.793
[62,     3] loss: 0.803
[63,     3] loss: 0.786
[64,     3] loss: 0.836
[65,     3] loss: 0.760
[66,     3] loss: 0.771
[67,     3] loss: 0.783
[68,     3] loss: 0.789
Early stopping applied (best metric=0.5172418355941772)
Finished Training
Total time taken: 15.178057193756104
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.381
[3,     3] loss: 1.386
[4,     3] loss: 1.387
[5,     3] loss: 1.385
[6,     3] loss: 1.384
[7,     3] loss: 1.366
[8,     3] loss: 1.375
[9,     3] loss: 1.353
[10,     3] loss: 1.367
[11,     3] loss: 1.345
[12,     3] loss: 1.320
[13,     3] loss: 1.311
[14,     3] loss: 1.273
[15,     3] loss: 1.260
[16,     3] loss: 1.204
[17,     3] loss: 1.228
[18,     3] loss: 1.171
[19,     3] loss: 1.216
[20,     3] loss: 1.099
[21,     3] loss: 1.165
[22,     3] loss: 1.104
[23,     3] loss: 1.113
[24,     3] loss: 1.052
[25,     3] loss: 1.123
[26,     3] loss: 0.966
[27,     3] loss: 0.968
[28,     3] loss: 0.956
[29,     3] loss: 0.961
[30,     3] loss: 0.973
[31,     3] loss: 0.918
[32,     3] loss: 0.951
[33,     3] loss: 1.059
[34,     3] loss: 0.929
[35,     3] loss: 0.906
[36,     3] loss: 0.908
[37,     3] loss: 0.922
[38,     3] loss: 0.864
[39,     3] loss: 0.886
[40,     3] loss: 0.881
[41,     3] loss: 0.917
[42,     3] loss: 0.825
[43,     3] loss: 0.900
[44,     3] loss: 0.795
[45,     3] loss: 0.822
[46,     3] loss: 0.807
[47,     3] loss: 0.881
[48,     3] loss: 0.877
[49,     3] loss: 0.819
[50,     3] loss: 0.835
[51,     3] loss: 0.813
[52,     3] loss: 0.870
[53,     3] loss: 0.806
[54,     3] loss: 0.844
[55,     3] loss: 0.793
[56,     3] loss: 0.816
[57,     3] loss: 0.851
[58,     3] loss: 0.788
[59,     3] loss: 0.787
[60,     3] loss: 0.790
[61,     3] loss: 0.809
[62,     3] loss: 0.844
[63,     3] loss: 0.779
[64,     3] loss: 0.783
[65,     3] loss: 0.770
[66,     3] loss: 0.809
[67,     3] loss: 0.822
[68,     3] loss: 0.764
[69,     3] loss: 0.777
[70,     3] loss: 0.832
[71,     3] loss: 0.763
[72,     3] loss: 0.813
[73,     3] loss: 0.766
[74,     3] loss: 0.798
[75,     3] loss: 0.767
[76,     3] loss: 0.772
[77,     3] loss: 0.750
[78,     3] loss: 0.764
[79,     3] loss: 0.773
[80,     3] loss: 0.831
[81,     3] loss: 0.864
Early stopping applied (best metric=0.5253293514251709)
Finished Training
Total time taken: 17.97506594657898
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.389
[3,     3] loss: 1.385
[4,     3] loss: 1.389
[5,     3] loss: 1.377
[6,     3] loss: 1.384
[7,     3] loss: 1.371
[8,     3] loss: 1.366
[9,     3] loss: 1.349
[10,     3] loss: 1.334
[11,     3] loss: 1.351
[12,     3] loss: 1.305
[13,     3] loss: 1.323
[14,     3] loss: 1.267
[15,     3] loss: 1.290
[16,     3] loss: 1.312
[17,     3] loss: 1.251
[18,     3] loss: 1.230
[19,     3] loss: 1.295
[20,     3] loss: 1.202
[21,     3] loss: 1.225
[22,     3] loss: 1.186
[23,     3] loss: 1.148
[24,     3] loss: 1.122
[25,     3] loss: 1.150
[26,     3] loss: 1.175
[27,     3] loss: 1.142
[28,     3] loss: 1.094
[29,     3] loss: 1.052
[30,     3] loss: 1.113
[31,     3] loss: 1.121
[32,     3] loss: 1.023
[33,     3] loss: 0.995
[34,     3] loss: 1.051
[35,     3] loss: 1.043
[36,     3] loss: 1.060
[37,     3] loss: 0.985
[38,     3] loss: 1.021
[39,     3] loss: 0.987
[40,     3] loss: 0.958
[41,     3] loss: 1.029
[42,     3] loss: 0.983
[43,     3] loss: 0.921
[44,     3] loss: 0.972
[45,     3] loss: 0.916
[46,     3] loss: 0.882
[47,     3] loss: 0.939
[48,     3] loss: 0.891
[49,     3] loss: 0.872
[50,     3] loss: 0.946
[51,     3] loss: 0.996
[52,     3] loss: 0.955
[53,     3] loss: 0.870
[54,     3] loss: 0.847
[55,     3] loss: 0.871
[56,     3] loss: 0.884
[57,     3] loss: 0.853
[58,     3] loss: 0.879
[59,     3] loss: 0.876
[60,     3] loss: 0.963
[61,     3] loss: 0.867
[62,     3] loss: 0.915
[63,     3] loss: 0.828
[64,     3] loss: 0.879
[65,     3] loss: 0.942
[66,     3] loss: 0.832
[67,     3] loss: 0.838
[68,     3] loss: 0.861
[69,     3] loss: 0.846
[70,     3] loss: 0.818
[71,     3] loss: 0.950
[72,     3] loss: 0.848
[73,     3] loss: 0.940
[74,     3] loss: 0.857
[75,     3] loss: 0.809
[76,     3] loss: 0.862
[77,     3] loss: 0.877
[78,     3] loss: 0.909
[79,     3] loss: 0.795
[80,     3] loss: 0.821
[81,     3] loss: 0.824
[82,     3] loss: 0.848
[83,     3] loss: 0.833
[84,     3] loss: 0.792
[85,     3] loss: 0.852
[86,     3] loss: 0.787
[87,     3] loss: 0.798
[88,     3] loss: 0.889
[89,     3] loss: 0.812
[90,     3] loss: 0.815
Early stopping applied (best metric=0.5310754179954529)
Finished Training
Total time taken: 20.07607412338257
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.383
[3,     3] loss: 1.388
[4,     3] loss: 1.390
[5,     3] loss: 1.378
[6,     3] loss: 1.389
[7,     3] loss: 1.386
[8,     3] loss: 1.388
[9,     3] loss: 1.377
[10,     3] loss: 1.389
[11,     3] loss: 1.371
[12,     3] loss: 1.376
[13,     3] loss: 1.365
[14,     3] loss: 1.356
[15,     3] loss: 1.336
[16,     3] loss: 1.328
[17,     3] loss: 1.335
[18,     3] loss: 1.319
[19,     3] loss: 1.277
[20,     3] loss: 1.222
[21,     3] loss: 1.202
[22,     3] loss: 1.216
[23,     3] loss: 1.149
[24,     3] loss: 1.063
[25,     3] loss: 1.164
[26,     3] loss: 1.108
[27,     3] loss: 1.069
[28,     3] loss: 1.032
[29,     3] loss: 0.968
[30,     3] loss: 1.043
[31,     3] loss: 0.989
[32,     3] loss: 1.007
[33,     3] loss: 0.945
[34,     3] loss: 1.025
[35,     3] loss: 0.944
[36,     3] loss: 1.025
[37,     3] loss: 0.958
[38,     3] loss: 0.924
[39,     3] loss: 0.973
[40,     3] loss: 0.887
[41,     3] loss: 0.874
[42,     3] loss: 0.919
[43,     3] loss: 0.865
[44,     3] loss: 0.836
[45,     3] loss: 0.814
[46,     3] loss: 0.797
[47,     3] loss: 0.807
[48,     3] loss: 0.817
[49,     3] loss: 0.805
[50,     3] loss: 0.787
[51,     3] loss: 0.817
[52,     3] loss: 0.795
[53,     3] loss: 0.790
[54,     3] loss: 0.774
[55,     3] loss: 0.795
[56,     3] loss: 0.767
[57,     3] loss: 0.773
[58,     3] loss: 0.822
[59,     3] loss: 0.820
[60,     3] loss: 0.791
[61,     3] loss: 0.745
[62,     3] loss: 0.785
[63,     3] loss: 0.766
[64,     3] loss: 0.757
[65,     3] loss: 0.765
[66,     3] loss: 0.791
[67,     3] loss: 0.820
[68,     3] loss: 0.790
[69,     3] loss: 0.819
[70,     3] loss: 0.777
[71,     3] loss: 0.798
[72,     3] loss: 0.798
[73,     3] loss: 0.820
[74,     3] loss: 0.793
[75,     3] loss: 0.819
[76,     3] loss: 0.808
[77,     3] loss: 0.796
Early stopping applied (best metric=0.5254734754562378)
Finished Training
Total time taken: 17.130063772201538
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.384
[3,     3] loss: 1.391
[4,     3] loss: 1.388
[5,     3] loss: 1.384
[6,     3] loss: 1.383
[7,     3] loss: 1.377
[8,     3] loss: 1.371
[9,     3] loss: 1.379
[10,     3] loss: 1.375
[11,     3] loss: 1.355
[12,     3] loss: 1.347
[13,     3] loss: 1.319
[14,     3] loss: 1.298
[15,     3] loss: 1.253
[16,     3] loss: 1.269
[17,     3] loss: 1.235
[18,     3] loss: 1.248
[19,     3] loss: 1.169
[20,     3] loss: 1.179
[21,     3] loss: 1.143
[22,     3] loss: 1.115
[23,     3] loss: 1.077
[24,     3] loss: 1.142
[25,     3] loss: 1.177
[26,     3] loss: 1.178
[27,     3] loss: 1.054
[28,     3] loss: 1.010
[29,     3] loss: 1.129
[30,     3] loss: 1.050
[31,     3] loss: 1.021
[32,     3] loss: 1.007
[33,     3] loss: 1.044
[34,     3] loss: 0.974
[35,     3] loss: 1.228
[36,     3] loss: 0.997
[37,     3] loss: 0.951
[38,     3] loss: 1.057
[39,     3] loss: 0.956
[40,     3] loss: 0.916
[41,     3] loss: 0.944
[42,     3] loss: 0.906
[43,     3] loss: 0.881
[44,     3] loss: 0.954
[45,     3] loss: 0.842
[46,     3] loss: 0.915
[47,     3] loss: 0.949
[48,     3] loss: 0.881
[49,     3] loss: 0.907
[50,     3] loss: 1.018
[51,     3] loss: 0.963
[52,     3] loss: 0.869
[53,     3] loss: 0.917
[54,     3] loss: 0.828
[55,     3] loss: 0.850
[56,     3] loss: 0.837
[57,     3] loss: 0.854
[58,     3] loss: 0.821
[59,     3] loss: 0.812
[60,     3] loss: 0.835
[61,     3] loss: 0.880
[62,     3] loss: 0.857
[63,     3] loss: 0.788
[64,     3] loss: 0.795
[65,     3] loss: 0.765
[66,     3] loss: 0.796
[67,     3] loss: 0.755
[68,     3] loss: 0.771
[69,     3] loss: 0.781
[70,     3] loss: 0.758
Early stopping applied (best metric=0.5109755396842957)
Finished Training
Total time taken: 15.639058589935303
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.383
[3,     3] loss: 1.382
[4,     3] loss: 1.384
[5,     3] loss: 1.381
[6,     3] loss: 1.384
[7,     3] loss: 1.379
[8,     3] loss: 1.382
[9,     3] loss: 1.373
[10,     3] loss: 1.362
[11,     3] loss: 1.356
[12,     3] loss: 1.321
[13,     3] loss: 1.329
[14,     3] loss: 1.272
[15,     3] loss: 1.304
[16,     3] loss: 1.249
[17,     3] loss: 1.249
[18,     3] loss: 1.233
[19,     3] loss: 1.219
[20,     3] loss: 1.169
[21,     3] loss: 1.175
[22,     3] loss: 1.124
[23,     3] loss: 1.150
[24,     3] loss: 1.083
[25,     3] loss: 1.057
[26,     3] loss: 1.097
[27,     3] loss: 0.934
[28,     3] loss: 0.970
[29,     3] loss: 1.001
[30,     3] loss: 0.909
[31,     3] loss: 0.892
[32,     3] loss: 0.962
[33,     3] loss: 1.069
[34,     3] loss: 0.942
[35,     3] loss: 0.939
[36,     3] loss: 0.832
[37,     3] loss: 0.896
[38,     3] loss: 0.841
[39,     3] loss: 0.828
[40,     3] loss: 0.924
[41,     3] loss: 0.848
[42,     3] loss: 0.824
[43,     3] loss: 0.890
[44,     3] loss: 0.821
[45,     3] loss: 0.830
[46,     3] loss: 0.783
[47,     3] loss: 0.805
[48,     3] loss: 0.987
[49,     3] loss: 0.850
[50,     3] loss: 0.789
[51,     3] loss: 0.812
[52,     3] loss: 0.862
[53,     3] loss: 0.837
[54,     3] loss: 0.847
[55,     3] loss: 0.827
[56,     3] loss: 0.921
[57,     3] loss: 0.907
[58,     3] loss: 0.807
[59,     3] loss: 0.844
[60,     3] loss: 0.843
[61,     3] loss: 0.815
[62,     3] loss: 0.803
[63,     3] loss: 0.823
[64,     3] loss: 0.786
[65,     3] loss: 0.783
[66,     3] loss: 0.823
[67,     3] loss: 0.872
[68,     3] loss: 0.812
[69,     3] loss: 0.804
[70,     3] loss: 0.810
[71,     3] loss: 0.856
[72,     3] loss: 0.784
[73,     3] loss: 0.793
[74,     3] loss: 0.814
Early stopping applied (best metric=0.5142849683761597)
Finished Training
Total time taken: 16.527060985565186
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.386
[3,     3] loss: 1.379
[4,     3] loss: 1.383
[5,     3] loss: 1.384
[6,     3] loss: 1.374
[7,     3] loss: 1.373
[8,     3] loss: 1.389
[9,     3] loss: 1.350
[10,     3] loss: 1.357
[11,     3] loss: 1.335
[12,     3] loss: 1.330
[13,     3] loss: 1.281
[14,     3] loss: 1.300
[15,     3] loss: 1.262
[16,     3] loss: 1.259
[17,     3] loss: 1.202
[18,     3] loss: 1.243
[19,     3] loss: 1.110
[20,     3] loss: 1.185
[21,     3] loss: 1.114
[22,     3] loss: 1.058
[23,     3] loss: 1.125
[24,     3] loss: 1.025
[25,     3] loss: 1.201
[26,     3] loss: 1.081
[27,     3] loss: 1.028
[28,     3] loss: 1.035
[29,     3] loss: 1.059
[30,     3] loss: 1.077
[31,     3] loss: 0.998
[32,     3] loss: 1.025
[33,     3] loss: 0.955
[34,     3] loss: 0.984
[35,     3] loss: 0.974
[36,     3] loss: 0.958
[37,     3] loss: 0.915
[38,     3] loss: 0.948
[39,     3] loss: 0.966
[40,     3] loss: 0.932
[41,     3] loss: 0.914
[42,     3] loss: 0.846
[43,     3] loss: 0.924
[44,     3] loss: 0.911
[45,     3] loss: 0.900
[46,     3] loss: 0.860
[47,     3] loss: 0.835
[48,     3] loss: 0.922
[49,     3] loss: 0.928
[50,     3] loss: 0.839
[51,     3] loss: 0.848
[52,     3] loss: 0.848
[53,     3] loss: 0.853
[54,     3] loss: 0.820
[55,     3] loss: 0.890
[56,     3] loss: 0.860
[57,     3] loss: 0.977
[58,     3] loss: 0.858
[59,     3] loss: 0.868
[60,     3] loss: 0.856
[61,     3] loss: 0.817
[62,     3] loss: 0.840
[63,     3] loss: 0.853
[64,     3] loss: 0.832
[65,     3] loss: 1.012
[66,     3] loss: 0.834
[67,     3] loss: 0.914
[68,     3] loss: 0.881
[69,     3] loss: 0.844
[70,     3] loss: 0.823
[71,     3] loss: 0.864
[72,     3] loss: 0.791
[73,     3] loss: 0.770
[74,     3] loss: 0.784
[75,     3] loss: 0.786
[76,     3] loss: 0.791
[77,     3] loss: 0.782
[78,     3] loss: 0.745
[79,     3] loss: 0.775
[80,     3] loss: 0.763
[81,     3] loss: 0.768
Early stopping applied (best metric=0.5269376635551453)
Finished Training
Total time taken: 18.275068521499634
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.386
[3,     3] loss: 1.393
[4,     3] loss: 1.387
[5,     3] loss: 1.386
[6,     3] loss: 1.385
[7,     3] loss: 1.388
[8,     3] loss: 1.383
[9,     3] loss: 1.387
[10,     3] loss: 1.383
[11,     3] loss: 1.383
[12,     3] loss: 1.378
[13,     3] loss: 1.383
[14,     3] loss: 1.370
[15,     3] loss: 1.368
[16,     3] loss: 1.362
[17,     3] loss: 1.341
[18,     3] loss: 1.353
[19,     3] loss: 1.321
[20,     3] loss: 1.298
[21,     3] loss: 1.308
[22,     3] loss: 1.197
[23,     3] loss: 1.250
[24,     3] loss: 1.191
[25,     3] loss: 1.137
[26,     3] loss: 1.103
[27,     3] loss: 1.269
[28,     3] loss: 1.215
[29,     3] loss: 1.067
[30,     3] loss: 1.194
[31,     3] loss: 1.067
[32,     3] loss: 1.139
[33,     3] loss: 1.191
[34,     3] loss: 1.088
[35,     3] loss: 1.033
[36,     3] loss: 1.047
[37,     3] loss: 1.002
[38,     3] loss: 0.988
[39,     3] loss: 0.977
[40,     3] loss: 0.966
[41,     3] loss: 0.902
[42,     3] loss: 0.878
[43,     3] loss: 0.978
[44,     3] loss: 0.955
[45,     3] loss: 1.004
[46,     3] loss: 1.010
[47,     3] loss: 0.925
[48,     3] loss: 0.937
[49,     3] loss: 0.955
[50,     3] loss: 0.960
[51,     3] loss: 0.933
[52,     3] loss: 0.926
[53,     3] loss: 0.998
[54,     3] loss: 1.011
[55,     3] loss: 1.126
[56,     3] loss: 1.000
[57,     3] loss: 1.045
[58,     3] loss: 0.966
[59,     3] loss: 1.201
[60,     3] loss: 0.957
[61,     3] loss: 0.997
[62,     3] loss: 0.924
[63,     3] loss: 0.898
[64,     3] loss: 0.940
[65,     3] loss: 0.959
[66,     3] loss: 0.887
[67,     3] loss: 0.920
[68,     3] loss: 0.872
[69,     3] loss: 0.848
[70,     3] loss: 0.849
[71,     3] loss: 0.875
[72,     3] loss: 0.857
[73,     3] loss: 0.875
[74,     3] loss: 0.824
[75,     3] loss: 0.777
[76,     3] loss: 0.805
[77,     3] loss: 0.822
[78,     3] loss: 0.848
[79,     3] loss: 0.825
[80,     3] loss: 0.836
[81,     3] loss: 0.801
[82,     3] loss: 0.808
[83,     3] loss: 0.809
[84,     3] loss: 0.831
[85,     3] loss: 0.772
[86,     3] loss: 0.787
[87,     3] loss: 0.802
[88,     3] loss: 0.803
[89,     3] loss: 0.769
[90,     3] loss: 0.791
[91,     3] loss: 0.768
[92,     3] loss: 0.815
[93,     3] loss: 0.803
[94,     3] loss: 0.812
[95,     3] loss: 0.799
[96,     3] loss: 0.773
[97,     3] loss: 0.806
[98,     3] loss: 0.763
[99,     3] loss: 0.748
[100,     3] loss: 0.762
Early stopping applied (best metric=0.5352267026901245)
Finished Training
Total time taken: 22.340081214904785
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.384
[3,     3] loss: 1.383
[4,     3] loss: 1.382
[5,     3] loss: 1.382
[6,     3] loss: 1.387
[7,     3] loss: 1.378
[8,     3] loss: 1.371
[9,     3] loss: 1.371
[10,     3] loss: 1.359
[11,     3] loss: 1.349
[12,     3] loss: 1.333
[13,     3] loss: 1.327
[14,     3] loss: 1.322
[15,     3] loss: 1.253
[16,     3] loss: 1.308
[17,     3] loss: 1.235
[18,     3] loss: 1.209
[19,     3] loss: 1.122
[20,     3] loss: 1.123
[21,     3] loss: 1.116
[22,     3] loss: 1.049
[23,     3] loss: 1.088
[24,     3] loss: 0.955
[25,     3] loss: 0.982
[26,     3] loss: 1.001
[27,     3] loss: 1.009
[28,     3] loss: 0.987
[29,     3] loss: 0.912
[30,     3] loss: 1.066
[31,     3] loss: 0.937
[32,     3] loss: 0.938
[33,     3] loss: 1.040
[34,     3] loss: 0.988
[35,     3] loss: 0.937
[36,     3] loss: 0.920
[37,     3] loss: 0.950
[38,     3] loss: 0.884
[39,     3] loss: 0.987
[40,     3] loss: 0.961
[41,     3] loss: 0.877
[42,     3] loss: 0.944
[43,     3] loss: 0.898
[44,     3] loss: 0.953
[45,     3] loss: 0.941
[46,     3] loss: 0.896
[47,     3] loss: 0.921
[48,     3] loss: 0.890
[49,     3] loss: 0.973
[50,     3] loss: 0.872
[51,     3] loss: 0.838
[52,     3] loss: 0.868
[53,     3] loss: 0.897
[54,     3] loss: 0.842
[55,     3] loss: 0.914
[56,     3] loss: 0.852
[57,     3] loss: 0.935
[58,     3] loss: 0.839
[59,     3] loss: 0.874
[60,     3] loss: 0.879
[61,     3] loss: 0.830
[62,     3] loss: 0.808
[63,     3] loss: 0.875
[64,     3] loss: 0.797
[65,     3] loss: 0.776
[66,     3] loss: 0.802
[67,     3] loss: 0.808
[68,     3] loss: 0.806
[69,     3] loss: 0.774
[70,     3] loss: 0.765
[71,     3] loss: 0.754
[72,     3] loss: 0.777
[73,     3] loss: 0.765
Early stopping applied (best metric=0.542115330696106)
Finished Training
Total time taken: 16.280060291290283
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.393
[3,     3] loss: 1.392
[4,     3] loss: 1.397
[5,     3] loss: 1.386
[6,     3] loss: 1.378
[7,     3] loss: 1.386
[8,     3] loss: 1.381
[9,     3] loss: 1.394
[10,     3] loss: 1.387
[11,     3] loss: 1.383
[12,     3] loss: 1.377
[13,     3] loss: 1.377
[14,     3] loss: 1.372
[15,     3] loss: 1.367
[16,     3] loss: 1.356
[17,     3] loss: 1.343
[18,     3] loss: 1.323
[19,     3] loss: 1.316
[20,     3] loss: 1.289
[21,     3] loss: 1.276
[22,     3] loss: 1.199
[23,     3] loss: 1.210
[24,     3] loss: 1.117
[25,     3] loss: 1.139
[26,     3] loss: 1.187
[27,     3] loss: 1.151
[28,     3] loss: 1.148
[29,     3] loss: 1.135
[30,     3] loss: 1.065
[31,     3] loss: 1.044
[32,     3] loss: 1.032
[33,     3] loss: 1.028
[34,     3] loss: 1.025
[35,     3] loss: 1.100
[36,     3] loss: 0.997
[37,     3] loss: 0.946
[38,     3] loss: 1.009
[39,     3] loss: 1.046
[40,     3] loss: 0.957
[41,     3] loss: 0.931
[42,     3] loss: 0.951
[43,     3] loss: 0.902
[44,     3] loss: 0.899
[45,     3] loss: 0.874
[46,     3] loss: 0.893
[47,     3] loss: 0.980
[48,     3] loss: 0.954
[49,     3] loss: 0.982
[50,     3] loss: 0.916
[51,     3] loss: 0.887
[52,     3] loss: 0.907
[53,     3] loss: 0.896
[54,     3] loss: 0.942
[55,     3] loss: 0.895
[56,     3] loss: 0.870
[57,     3] loss: 0.853
[58,     3] loss: 0.874
[59,     3] loss: 0.846
[60,     3] loss: 0.865
[61,     3] loss: 0.860
[62,     3] loss: 0.888
[63,     3] loss: 0.835
[64,     3] loss: 0.827
[65,     3] loss: 0.787
[66,     3] loss: 0.822
[67,     3] loss: 0.812
[68,     3] loss: 0.798
[69,     3] loss: 0.791
[70,     3] loss: 0.812
[71,     3] loss: 0.822
[72,     3] loss: 0.776
[73,     3] loss: 0.789
[74,     3] loss: 0.791
[75,     3] loss: 0.762
[76,     3] loss: 0.795
[77,     3] loss: 0.770
Early stopping applied (best metric=0.5180714130401611)
Finished Training
Total time taken: 17.14406442642212
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.382
[3,     3] loss: 1.381
[4,     3] loss: 1.388
[5,     3] loss: 1.387
[6,     3] loss: 1.384
[7,     3] loss: 1.374
[8,     3] loss: 1.375
[9,     3] loss: 1.372
[10,     3] loss: 1.372
[11,     3] loss: 1.353
[12,     3] loss: 1.348
[13,     3] loss: 1.335
[14,     3] loss: 1.325
[15,     3] loss: 1.310
[16,     3] loss: 1.279
[17,     3] loss: 1.238
[18,     3] loss: 1.239
[19,     3] loss: 1.214
[20,     3] loss: 1.198
[21,     3] loss: 1.116
[22,     3] loss: 1.076
[23,     3] loss: 1.182
[24,     3] loss: 1.072
[25,     3] loss: 1.006
[26,     3] loss: 1.139
[27,     3] loss: 0.968
[28,     3] loss: 1.039
[29,     3] loss: 1.032
[30,     3] loss: 0.951
[31,     3] loss: 0.927
[32,     3] loss: 1.044
[33,     3] loss: 0.896
[34,     3] loss: 0.926
[35,     3] loss: 0.962
[36,     3] loss: 0.951
[37,     3] loss: 0.940
[38,     3] loss: 0.940
[39,     3] loss: 0.928
[40,     3] loss: 0.921
[41,     3] loss: 0.865
[42,     3] loss: 0.908
[43,     3] loss: 0.836
[44,     3] loss: 0.859
[45,     3] loss: 0.871
[46,     3] loss: 0.918
[47,     3] loss: 0.830
[48,     3] loss: 0.960
[49,     3] loss: 0.909
[50,     3] loss: 0.934
[51,     3] loss: 0.881
[52,     3] loss: 0.889
[53,     3] loss: 0.920
[54,     3] loss: 0.880
[55,     3] loss: 0.850
[56,     3] loss: 0.870
[57,     3] loss: 0.885
[58,     3] loss: 0.804
[59,     3] loss: 0.905
[60,     3] loss: 0.807
[61,     3] loss: 0.873
[62,     3] loss: 0.868
[63,     3] loss: 0.835
[64,     3] loss: 0.865
[65,     3] loss: 0.886
[66,     3] loss: 0.856
[67,     3] loss: 0.889
[68,     3] loss: 0.861
[69,     3] loss: 0.822
[70,     3] loss: 0.834
[71,     3] loss: 0.820
[72,     3] loss: 0.801
[73,     3] loss: 0.818
[74,     3] loss: 0.804
Early stopping applied (best metric=0.4945194721221924)
Finished Training
Total time taken: 16.41706085205078
{'S-palmitoylation-C Validation Accuracy': 0.7046082156562506, 'S-palmitoylation-C Validation Sensitivity': 0.22323432343234323, 'S-palmitoylation-C Validation Specificity': 0.8252733101539842, 'S-palmitoylation-C Validation Precision': 0.24392733059061475, 'S-palmitoylation-C AUC ROC': 0.5476713768266834, 'S-palmitoylation-C AUC PR': 0.2314613245842498, 'S-palmitoylation-C MCC': 0.05029168294908203, 'S-palmitoylation-C F1': 0.22602416008679677, 'Validation Loss (S-palmitoylation-C)': 0.5534212748209636, 'Hydroxylation-K Validation Accuracy': 0.7223995271867613, 'Hydroxylation-K Validation Sensitivity': 0.7785185185185185, 'Hydroxylation-K Validation Specificity': 0.7087719298245614, 'Hydroxylation-K Validation Precision': 0.4150296913468269, 'Hydroxylation-K AUC ROC': 0.8132553606237817, 'Hydroxylation-K AUC PR': 0.5414868160643836, 'Hydroxylation-K MCC': 0.40851553308673016, 'Hydroxylation-K F1': 0.5343598810130175, 'Validation Loss (Hydroxylation-K)': 0.5216339667638142, 'Validation Loss (total)': 1.075055233637492, 'TimeToTrain': 18.05178017616272}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00020433811331977694,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8068863295119871,
 'loss_weight_S-palmitoylation-C': 0.20148712136094338,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2495368439,
 'sample_weights': [0.39366007221779653, 0.284931448786482],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.595820765977105,
 'weight_decay_Hydroxylation-K': 4.336835267648394,
 'weight_decay_S-palmitoylation-C': 1.894116072183922}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.385
[3,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014964952688841977,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5012947386055215,
 'loss_weight_S-palmitoylation-C': 0.7006259526712171,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3244629226,
 'sample_weights': [0.20148712136094338, 0.8068863295119871],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.684397468287415,
 'weight_decay_Hydroxylation-K': 4.729821882567845,
 'weight_decay_S-palmitoylation-C': 5.608244102001225}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.380
[2,     3] loss: 1.378
[3,     3] loss: 1.393
[4,     3] loss: 1.380
[5,     3] loss: 1.387
[6,     3] loss: 1.374
[7,     3] loss: 1.386
[8,     3] loss: 1.385
[9,     3] loss: 1.376
[10,     3] loss: 1.377
[11,     3] loss: 1.369
[12,     3] loss: 1.346
[13,     3] loss: 1.320
[14,     3] loss: 1.285
[15,     3] loss: 1.276
[16,     3] loss: 1.274
[17,     3] loss: 1.207
[18,     3] loss: 1.236
[19,     3] loss: 1.182
[20,     3] loss: 1.145
[21,     3] loss: 1.117
[22,     3] loss: 1.203
[23,     3] loss: 1.058
[24,     3] loss: 1.109
[25,     3] loss: 1.005
[26,     3] loss: 0.994
[27,     3] loss: 0.965
[28,     3] loss: 0.958
[29,     3] loss: 0.956
[30,     3] loss: 0.955
[31,     3] loss: 0.981
[32,     3] loss: 0.949
[33,     3] loss: 0.924
[34,     3] loss: 0.888
[35,     3] loss: 0.927
[36,     3] loss: 0.855
[37,     3] loss: 0.906
[38,     3] loss: 0.891
[39,     3] loss: 0.928
[40,     3] loss: 1.078
[41,     3] loss: 0.943
[42,     3] loss: 0.946
[43,     3] loss: 0.991
[44,     3] loss: 1.146
[45,     3] loss: 0.950
[46,     3] loss: 1.080
[47,     3] loss: 0.968
[48,     3] loss: 1.040
[49,     3] loss: 1.014
[50,     3] loss: 0.935
[51,     3] loss: 0.886
[52,     3] loss: 0.911
[53,     3] loss: 0.874
[54,     3] loss: 0.844
[55,     3] loss: 0.828
[56,     3] loss: 0.859
[57,     3] loss: 0.798
[58,     3] loss: 0.814
[59,     3] loss: 0.787
[60,     3] loss: 0.832
[61,     3] loss: 0.963
[62,     3] loss: 0.865
[63,     3] loss: 0.809
[64,     3] loss: 0.823
[65,     3] loss: 0.782
[66,     3] loss: 0.786
[67,     3] loss: 0.783
[68,     3] loss: 0.763
[69,     3] loss: 0.735
[70,     3] loss: 0.785
[71,     3] loss: 0.755
[72,     3] loss: 0.895
[73,     3] loss: 0.767
[74,     3] loss: 0.762
[75,     3] loss: 0.781
[76,     3] loss: 0.780
[77,     3] loss: 0.911
[78,     3] loss: 0.903
[79,     3] loss: 0.829
[80,     3] loss: 0.826
[81,     3] loss: 0.769
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 1.784777058887405e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.685711631966835,
 'loss_weight_S-palmitoylation-C': 0.054509516814650896,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1840574560,
 'sample_weights': [0.7006259526712171, 0.5012947386055215],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7930523253510735,
 'weight_decay_Hydroxylation-K': 4.633638859586852,
 'weight_decay_S-palmitoylation-C': 0.9128190685193847}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.385
[4,     3] loss: 1.393
[5,     3] loss: 1.387
[6,     3] loss: 1.387
[7,     3] loss: 1.386
[8,     3] loss: 1.392
[9,     3] loss: 1.393
[10,     3] loss: 1.383
[11,     3] loss: 1.397
[12,     3] loss: 1.383
[13,     3] loss: 1.393
[14,     3] loss: 1.389
[15,     3] loss: 1.382
[16,     3] loss: 1.387
[17,     3] loss: 1.387
[18,     3] loss: 1.392
[19,     3] loss: 1.381
[20,     3] loss: 1.389
[21,     3] loss: 1.391
[22,     3] loss: 1.388
[23,     3] loss: 1.379
[24,     3] loss: 1.384
[25,     3] loss: 1.388
[26,     3] loss: 1.382
[27,     3] loss: 1.397
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00897634565316231,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.013536501688533709,
 'loss_weight_S-palmitoylation-C': 0.9114346265924858,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1759471444,
 'sample_weights': [0.054509516814650896, 0.685711631966835],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.343776919804111,
 'weight_decay_Hydroxylation-K': 4.063386215497333,
 'weight_decay_S-palmitoylation-C': 1.3942768595294952}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.383
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001867763813688817,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.23727625934468274,
 'loss_weight_S-palmitoylation-C': 0.6249371755927526,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2853931540,
 'sample_weights': [0.9114346265924858, 0.013536501688533709],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5472034710168294,
 'weight_decay_Hydroxylation-K': 0.3055822786437634,
 'weight_decay_S-palmitoylation-C': 0.05733480691908377}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.386
[3,     3] loss: 1.383
[4,     3] loss: 1.394
[5,     3] loss: 1.393
[6,     3] loss: 1.381
[7,     3] loss: 1.378
[8,     3] loss: 1.380
[9,     3] loss: 1.368
[10,     3] loss: 1.368
[11,     3] loss: 1.361
[12,     3] loss: 1.317
[13,     3] loss: 1.309
[14,     3] loss: 1.263
[15,     3] loss: 1.216
[16,     3] loss: 1.329
[17,     3] loss: 1.152
[18,     3] loss: 1.089
[19,     3] loss: 1.113
[20,     3] loss: 1.017
[21,     3] loss: 0.961
[22,     3] loss: 1.027
[23,     3] loss: 1.154
[24,     3] loss: 1.070
[25,     3] loss: 1.046
[26,     3] loss: 0.975
[27,     3] loss: 1.098
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013679976552584017,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.747085109077759,
 'loss_weight_S-palmitoylation-C': 0.13684300655210066,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 930556993,
 'sample_weights': [0.6249371755927526, 0.23727625934468274],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.124214296105633,
 'weight_decay_Hydroxylation-K': 3.1937237425605285,
 'weight_decay_S-palmitoylation-C': 5.48673838745543}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.378
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009677997432851672,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8727869436284794,
 'loss_weight_S-palmitoylation-C': 0.8345275737989701,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2275386614,
 'sample_weights': [0.13684300655210066, 0.747085109077759],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4035133723984945,
 'weight_decay_Hydroxylation-K': 3.0529140542896123,
 'weight_decay_S-palmitoylation-C': 0.48914421686416265}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.395
[3,     3] loss: 1.385
[4,     3] loss: 1.382
[5,     3] loss: 1.382
[6,     3] loss: 1.388
[7,     3] loss: 1.387
[8,     3] loss: 1.398
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001312760847959337,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9733752540509674,
 'loss_weight_S-palmitoylation-C': 0.0720251851062882,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3057497235,
 'sample_weights': [0.8345275737989701, 0.8727869436284794],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.438659955131989,
 'weight_decay_Hydroxylation-K': 3.0369158539566583,
 'weight_decay_S-palmitoylation-C': 5.428359732408481}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.390
[3,     3] loss: 1.382
[4,     3] loss: 1.386
[5,     3] loss: 1.384
[6,     3] loss: 1.369
[7,     3] loss: 1.363
[8,     3] loss: 1.348
[9,     3] loss: 1.344
[10,     3] loss: 1.345
[11,     3] loss: 1.321
[12,     3] loss: 1.298
[13,     3] loss: 1.232
[14,     3] loss: 1.255
[15,     3] loss: 1.211
[16,     3] loss: 1.185
[17,     3] loss: 1.177
[18,     3] loss: 1.236
[19,     3] loss: 1.182
[20,     3] loss: 1.125
[21,     3] loss: 1.138
[22,     3] loss: 1.081
[23,     3] loss: 1.096
[24,     3] loss: 0.979
[25,     3] loss: 1.016
[26,     3] loss: 0.940
[27,     3] loss: 1.048
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002087098163219841,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.976636600939913,
 'loss_weight_S-palmitoylation-C': 0.060012530020339364,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2295790443,
 'sample_weights': [0.0720251851062882, 0.9733752540509674],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.102805412416793,
 'weight_decay_Hydroxylation-K': 4.331205528836773,
 'weight_decay_S-palmitoylation-C': 4.056019952162032}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.382
[3,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005026036824517505,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8674177112031992,
 'loss_weight_S-palmitoylation-C': 0.09277562292086755,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3188200814,
 'sample_weights': [0.060012530020339364, 0.976636600939913],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.807492423211978,
 'weight_decay_Hydroxylation-K': 3.012626095440669,
 'weight_decay_S-palmitoylation-C': 9.21413737766648}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.382
[3,     3] loss: 1.386
[4,     3] loss: 1.395
[5,     3] loss: 1.379
[6,     3] loss: 1.387
[7,     3] loss: 1.392
[8,     3] loss: 1.383
[9,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003610483995249796,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7381378089521999,
 'loss_weight_S-palmitoylation-C': 0.29329421519199933,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1744771830,
 'sample_weights': [0.09277562292086755, 0.8674177112031992],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.910809742279589,
 'weight_decay_Hydroxylation-K': 0.5100878661717747,
 'weight_decay_S-palmitoylation-C': 6.788419177287695}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.384
[3,     3] loss: 1.387
[4,     3] loss: 1.389
[5,     3] loss: 1.377
[6,     3] loss: 1.374
[7,     3] loss: 1.368
[8,     3] loss: 1.361
[9,     3] loss: 1.371
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010568032575271587,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5639016552116842,
 'loss_weight_S-palmitoylation-C': 0.18617284232050635,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 403326362,
 'sample_weights': [0.29329421519199933, 0.7381378089521999],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8788081387766007,
 'weight_decay_Hydroxylation-K': 2.694944921942674,
 'weight_decay_S-palmitoylation-C': 9.766280472976588}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.386
[3,     3] loss: 1.385
[4,     3] loss: 1.383
[5,     3] loss: 1.384
[6,     3] loss: 1.380
[7,     3] loss: 1.384
[8,     3] loss: 1.362
[9,     3] loss: 1.373
[10,     3] loss: 1.336
[11,     3] loss: 1.324
[12,     3] loss: 1.312
[13,     3] loss: 1.262
[14,     3] loss: 1.281
[15,     3] loss: 1.240
[16,     3] loss: 1.158
[17,     3] loss: 1.175
[18,     3] loss: 1.226
[19,     3] loss: 1.209
[20,     3] loss: 1.186
[21,     3] loss: 1.211
[22,     3] loss: 1.150
[23,     3] loss: 1.109
[24,     3] loss: 1.090
[25,     3] loss: 1.090
[26,     3] loss: 1.029
[27,     3] loss: 1.106
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005897483752292578,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9171045967162912,
 'loss_weight_S-palmitoylation-C': 0.06885828750298577,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3238882805,
 'sample_weights': [0.18617284232050635, 0.5639016552116842],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.039968020617543,
 'weight_decay_Hydroxylation-K': 1.041599943509766,
 'weight_decay_S-palmitoylation-C': 4.753209299456339}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.389
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023786063040632252,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.35810394851105226,
 'loss_weight_S-palmitoylation-C': 0.03623667653896645,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2458191140,
 'sample_weights': [0.06885828750298577, 0.9171045967162912],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.71464358818694,
 'weight_decay_Hydroxylation-K': 1.441234117118416,
 'weight_decay_S-palmitoylation-C': 0.04508937845752409}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.386
[3,     3] loss: 1.392
[4,     3] loss: 1.385
[5,     3] loss: 1.380
[6,     3] loss: 1.382
[7,     3] loss: 1.376
[8,     3] loss: 1.370
[9,     3] loss: 1.353
[10,     3] loss: 1.335
[11,     3] loss: 1.306
[12,     3] loss: 1.265
[13,     3] loss: 1.243
[14,     3] loss: 1.227
[15,     3] loss: 1.231
[16,     3] loss: 1.218
[17,     3] loss: 1.163
[18,     3] loss: 1.059
[19,     3] loss: 1.078
[20,     3] loss: 1.039
[21,     3] loss: 1.098
[22,     3] loss: 0.990
[23,     3] loss: 1.072
[24,     3] loss: 0.927
[25,     3] loss: 1.046
[26,     3] loss: 0.949
[27,     3] loss: 0.989
[28,     3] loss: 0.975
[29,     3] loss: 0.892
[30,     3] loss: 0.925
[31,     3] loss: 0.875
[32,     3] loss: 0.876
[33,     3] loss: 0.876
[34,     3] loss: 0.867
[35,     3] loss: 0.823
[36,     3] loss: 0.911
[37,     3] loss: 1.033
[38,     3] loss: 1.279
[39,     3] loss: 1.252
[40,     3] loss: 1.175
[41,     3] loss: 1.088
[42,     3] loss: 1.155
[43,     3] loss: 1.110
[44,     3] loss: 1.025
[45,     3] loss: 1.038
[46,     3] loss: 0.962
[47,     3] loss: 0.946
[48,     3] loss: 1.027
[49,     3] loss: 0.955
[50,     3] loss: 0.838
[51,     3] loss: 0.864
[52,     3] loss: 0.978
[53,     3] loss: 0.802
[54,     3] loss: 0.833
[55,     3] loss: 0.911
[56,     3] loss: 0.823
[57,     3] loss: 0.805
[58,     3] loss: 0.795
[59,     3] loss: 0.875
[60,     3] loss: 0.773
[61,     3] loss: 0.756
[62,     3] loss: 0.771
[63,     3] loss: 0.821
Early stopping applied (best metric=0.515373170375824)
Finished Training
Total time taken: 14.00905179977417
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.410
[3,     3] loss: 1.386
[4,     3] loss: 1.384
[5,     3] loss: 1.387
[6,     3] loss: 1.386
[7,     3] loss: 1.387
[8,     3] loss: 1.390
[9,     3] loss: 1.385
[10,     3] loss: 1.385
[11,     3] loss: 1.386
[12,     3] loss: 1.388
[13,     3] loss: 1.384
[14,     3] loss: 1.383
[15,     3] loss: 1.383
[16,     3] loss: 1.378
[17,     3] loss: 1.386
[18,     3] loss: 1.362
[19,     3] loss: 1.345
[20,     3] loss: 1.304
[21,     3] loss: 1.310
[22,     3] loss: 1.299
[23,     3] loss: 1.282
[24,     3] loss: 1.162
[25,     3] loss: 1.153
[26,     3] loss: 1.236
[27,     3] loss: 1.224
[28,     3] loss: 1.107
[29,     3] loss: 1.242
[30,     3] loss: 1.110
[31,     3] loss: 1.122
[32,     3] loss: 1.017
[33,     3] loss: 1.101
[34,     3] loss: 1.186
[35,     3] loss: 1.085
[36,     3] loss: 1.071
[37,     3] loss: 0.975
[38,     3] loss: 1.087
[39,     3] loss: 1.017
[40,     3] loss: 0.990
[41,     3] loss: 1.011
[42,     3] loss: 0.873
[43,     3] loss: 0.895
[44,     3] loss: 0.826
[45,     3] loss: 0.888
[46,     3] loss: 0.834
[47,     3] loss: 0.862
[48,     3] loss: 0.763
[49,     3] loss: 0.781
[50,     3] loss: 0.898
[51,     3] loss: 0.936
[52,     3] loss: 0.960
[53,     3] loss: 0.866
[54,     3] loss: 0.947
[55,     3] loss: 0.908
[56,     3] loss: 0.931
[57,     3] loss: 0.939
[58,     3] loss: 0.937
[59,     3] loss: 0.921
[60,     3] loss: 0.848
[61,     3] loss: 0.857
[62,     3] loss: 0.785
[63,     3] loss: 0.862
[64,     3] loss: 0.753
[65,     3] loss: 0.749
[66,     3] loss: 0.779
[67,     3] loss: 0.814
[68,     3] loss: 0.797
[69,     3] loss: 0.800
[70,     3] loss: 0.777
[71,     3] loss: 0.761
[72,     3] loss: 0.757
[73,     3] loss: 0.853
[74,     3] loss: 0.839
[75,     3] loss: 0.762
[76,     3] loss: 0.841
Early stopping applied (best metric=0.5314565300941467)
Finished Training
Total time taken: 16.94407820701599
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.388
[3,     3] loss: 1.397
[4,     3] loss: 1.375
[5,     3] loss: 1.393
[6,     3] loss: 1.363
[7,     3] loss: 1.358
[8,     3] loss: 1.342
[9,     3] loss: 1.302
[10,     3] loss: 1.247
[11,     3] loss: 1.281
[12,     3] loss: 1.124
[13,     3] loss: 1.130
[14,     3] loss: 1.038
[15,     3] loss: 1.143
[16,     3] loss: 1.024
[17,     3] loss: 0.975
[18,     3] loss: 0.929
[19,     3] loss: 0.894
[20,     3] loss: 0.884
[21,     3] loss: 0.924
[22,     3] loss: 1.144
[23,     3] loss: 0.968
[24,     3] loss: 0.931
[25,     3] loss: 1.027
[26,     3] loss: 0.965
[27,     3] loss: 1.066
[28,     3] loss: 0.950
[29,     3] loss: 0.934
[30,     3] loss: 0.930
[31,     3] loss: 0.851
[32,     3] loss: 0.847
[33,     3] loss: 0.928
[34,     3] loss: 0.850
[35,     3] loss: 0.950
[36,     3] loss: 0.862
[37,     3] loss: 0.923
[38,     3] loss: 0.855
[39,     3] loss: 0.843
[40,     3] loss: 0.944
[41,     3] loss: 0.889
[42,     3] loss: 0.942
[43,     3] loss: 0.889
[44,     3] loss: 0.866
[45,     3] loss: 0.892
[46,     3] loss: 0.862
[47,     3] loss: 0.884
[48,     3] loss: 0.834
[49,     3] loss: 0.865
[50,     3] loss: 0.775
[51,     3] loss: 0.759
[52,     3] loss: 0.768
[53,     3] loss: 0.752
[54,     3] loss: 0.899
[55,     3] loss: 0.869
[56,     3] loss: 0.849
[57,     3] loss: 0.851
[58,     3] loss: 0.858
[59,     3] loss: 0.769
[60,     3] loss: 0.814
[61,     3] loss: 0.805
[62,     3] loss: 0.842
[63,     3] loss: 0.799
[64,     3] loss: 0.729
[65,     3] loss: 0.765
[66,     3] loss: 0.759
[67,     3] loss: 0.760
[68,     3] loss: 0.804
[69,     3] loss: 0.813
[70,     3] loss: 0.780
[71,     3] loss: 0.853
[72,     3] loss: 0.780
[73,     3] loss: 0.786
[74,     3] loss: 0.796
[75,     3] loss: 1.062
[76,     3] loss: 0.820
[77,     3] loss: 1.041
[78,     3] loss: 1.079
[79,     3] loss: 0.905
[80,     3] loss: 0.937
[81,     3] loss: 0.847
[82,     3] loss: 0.893
[83,     3] loss: 0.891
[84,     3] loss: 0.779
[85,     3] loss: 0.861
[86,     3] loss: 0.772
[87,     3] loss: 0.755
[88,     3] loss: 0.737
[89,     3] loss: 0.813
[90,     3] loss: 1.002
[91,     3] loss: 0.940
[92,     3] loss: 0.847
[93,     3] loss: 0.877
[94,     3] loss: 0.818
[95,     3] loss: 0.816
[96,     3] loss: 0.815
[97,     3] loss: 0.813
[98,     3] loss: 0.754
[99,     3] loss: 0.821
[100,     3] loss: 0.753
[101,     3] loss: 0.740
Early stopping applied (best metric=0.5473229885101318)
Finished Training
Total time taken: 22.4910831451416
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.388
[3,     3] loss: 1.388
[4,     3] loss: 1.382
[5,     3] loss: 1.377
[6,     3] loss: 1.385
[7,     3] loss: 1.383
[8,     3] loss: 1.369
[9,     3] loss: 1.362
[10,     3] loss: 1.350
[11,     3] loss: 1.322
[12,     3] loss: 1.239
[13,     3] loss: 1.251
[14,     3] loss: 1.143
[15,     3] loss: 1.155
[16,     3] loss: 1.372
[17,     3] loss: 1.350
[18,     3] loss: 1.099
[19,     3] loss: 1.220
[20,     3] loss: 1.115
[21,     3] loss: 1.156
[22,     3] loss: 1.147
[23,     3] loss: 1.141
[24,     3] loss: 1.006
[25,     3] loss: 1.142
[26,     3] loss: 1.082
[27,     3] loss: 0.927
[28,     3] loss: 0.935
[29,     3] loss: 1.023
[30,     3] loss: 0.917
[31,     3] loss: 0.923
[32,     3] loss: 0.937
[33,     3] loss: 0.920
[34,     3] loss: 0.965
[35,     3] loss: 0.928
[36,     3] loss: 0.971
[37,     3] loss: 0.936
[38,     3] loss: 0.927
[39,     3] loss: 0.902
[40,     3] loss: 1.137
[41,     3] loss: 1.031
[42,     3] loss: 0.990
[43,     3] loss: 0.994
[44,     3] loss: 0.897
[45,     3] loss: 0.925
[46,     3] loss: 0.849
[47,     3] loss: 0.814
[48,     3] loss: 0.794
[49,     3] loss: 0.825
[50,     3] loss: 0.793
[51,     3] loss: 0.819
[52,     3] loss: 0.761
[53,     3] loss: 0.767
[54,     3] loss: 0.782
[55,     3] loss: 0.778
[56,     3] loss: 0.776
[57,     3] loss: 1.164
[58,     3] loss: 1.080
[59,     3] loss: 1.053
[60,     3] loss: 1.263
[61,     3] loss: 1.093
[62,     3] loss: 1.073
[63,     3] loss: 0.990
[64,     3] loss: 1.099
[65,     3] loss: 0.840
[66,     3] loss: 0.802
[67,     3] loss: 0.840
[68,     3] loss: 0.757
[69,     3] loss: 0.749
[70,     3] loss: 0.744
[71,     3] loss: 0.736
[72,     3] loss: 0.888
[73,     3] loss: 0.746
[74,     3] loss: 0.756
[75,     3] loss: 0.781
[76,     3] loss: 0.781
[77,     3] loss: 0.771
[78,     3] loss: 0.746
[79,     3] loss: 0.762
Early stopping applied (best metric=0.5012139678001404)
Finished Training
Total time taken: 17.64106559753418
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.387
[3,     3] loss: 1.386
[4,     3] loss: 1.388
[5,     3] loss: 1.391
[6,     3] loss: 1.389
[7,     3] loss: 1.377
[8,     3] loss: 1.383
[9,     3] loss: 1.369
[10,     3] loss: 1.369
[11,     3] loss: 1.346
[12,     3] loss: 1.299
[13,     3] loss: 1.335
[14,     3] loss: 1.260
[15,     3] loss: 1.301
[16,     3] loss: 1.168
[17,     3] loss: 1.225
[18,     3] loss: 1.150
[19,     3] loss: 1.051
[20,     3] loss: 1.054
[21,     3] loss: 1.006
[22,     3] loss: 1.025
[23,     3] loss: 0.950
[24,     3] loss: 1.013
[25,     3] loss: 1.064
[26,     3] loss: 0.974
[27,     3] loss: 0.957
[28,     3] loss: 0.930
[29,     3] loss: 1.034
[30,     3] loss: 1.009
[31,     3] loss: 0.990
[32,     3] loss: 0.978
[33,     3] loss: 0.880
[34,     3] loss: 0.873
[35,     3] loss: 0.960
[36,     3] loss: 0.997
[37,     3] loss: 1.008
[38,     3] loss: 0.911
[39,     3] loss: 0.920
[40,     3] loss: 0.968
[41,     3] loss: 0.914
[42,     3] loss: 0.849
[43,     3] loss: 1.054
[44,     3] loss: 0.844
[45,     3] loss: 0.850
[46,     3] loss: 0.830
[47,     3] loss: 0.839
[48,     3] loss: 0.786
[49,     3] loss: 0.863
[50,     3] loss: 0.949
[51,     3] loss: 1.168
[52,     3] loss: 0.958
[53,     3] loss: 0.985
[54,     3] loss: 0.948
[55,     3] loss: 1.020
[56,     3] loss: 0.903
[57,     3] loss: 0.934
[58,     3] loss: 0.903
[59,     3] loss: 0.856
[60,     3] loss: 0.873
[61,     3] loss: 0.820
[62,     3] loss: 0.815
[63,     3] loss: 0.832
[64,     3] loss: 0.893
[65,     3] loss: 1.165
[66,     3] loss: 1.129
[67,     3] loss: 0.972
[68,     3] loss: 1.132
[69,     3] loss: 0.934
[70,     3] loss: 1.075
[71,     3] loss: 1.060
[72,     3] loss: 0.922
[73,     3] loss: 0.890
Early stopping applied (best metric=0.5194768905639648)
Finished Training
Total time taken: 16.244848012924194
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.384
[3,     3] loss: 1.365
[4,     3] loss: 1.386
[5,     3] loss: 1.408
[6,     3] loss: 1.375
[7,     3] loss: 1.381
[8,     3] loss: 1.379
[9,     3] loss: 1.372
[10,     3] loss: 1.346
[11,     3] loss: 1.323
[12,     3] loss: 1.277
[13,     3] loss: 1.237
[14,     3] loss: 1.210
[15,     3] loss: 1.206
[16,     3] loss: 1.188
[17,     3] loss: 1.167
[18,     3] loss: 1.234
[19,     3] loss: 1.063
[20,     3] loss: 1.128
[21,     3] loss: 1.043
[22,     3] loss: 1.009
[23,     3] loss: 1.074
[24,     3] loss: 0.948
[25,     3] loss: 1.057
[26,     3] loss: 1.017
[27,     3] loss: 1.021
[28,     3] loss: 0.976
[29,     3] loss: 0.974
[30,     3] loss: 0.938
[31,     3] loss: 0.862
[32,     3] loss: 0.955
[33,     3] loss: 0.931
[34,     3] loss: 0.871
[35,     3] loss: 0.904
[36,     3] loss: 1.007
[37,     3] loss: 0.905
[38,     3] loss: 0.893
[39,     3] loss: 0.843
[40,     3] loss: 0.901
[41,     3] loss: 0.842
[42,     3] loss: 0.857
[43,     3] loss: 0.834
[44,     3] loss: 0.827
[45,     3] loss: 0.844
[46,     3] loss: 0.868
[47,     3] loss: 0.818
[48,     3] loss: 0.885
[49,     3] loss: 0.860
[50,     3] loss: 0.814
[51,     3] loss: 0.812
[52,     3] loss: 0.878
[53,     3] loss: 0.796
[54,     3] loss: 0.862
[55,     3] loss: 0.794
[56,     3] loss: 0.766
[57,     3] loss: 0.803
[58,     3] loss: 0.767
[59,     3] loss: 0.970
[60,     3] loss: 0.804
[61,     3] loss: 0.874
[62,     3] loss: 0.866
[63,     3] loss: 0.853
[64,     3] loss: 1.034
[65,     3] loss: 0.825
Early stopping applied (best metric=0.48537418246269226)
Finished Training
Total time taken: 14.55206298828125
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.391
[3,     3] loss: 1.387
[4,     3] loss: 1.390
[5,     3] loss: 1.387
[6,     3] loss: 1.383
[7,     3] loss: 1.383
[8,     3] loss: 1.367
[9,     3] loss: 1.367
[10,     3] loss: 1.329
[11,     3] loss: 1.358
[12,     3] loss: 1.311
[13,     3] loss: 1.248
[14,     3] loss: 1.248
[15,     3] loss: 1.227
[16,     3] loss: 1.120
[17,     3] loss: 1.285
[18,     3] loss: 1.090
[19,     3] loss: 1.166
[20,     3] loss: 1.115
[21,     3] loss: 0.993
[22,     3] loss: 1.058
[23,     3] loss: 1.005
[24,     3] loss: 1.099
[25,     3] loss: 1.066
[26,     3] loss: 1.097
[27,     3] loss: 1.184
[28,     3] loss: 1.007
[29,     3] loss: 1.065
[30,     3] loss: 1.075
[31,     3] loss: 0.940
[32,     3] loss: 0.968
[33,     3] loss: 0.937
[34,     3] loss: 0.965
[35,     3] loss: 0.958
[36,     3] loss: 0.923
[37,     3] loss: 0.897
[38,     3] loss: 0.875
[39,     3] loss: 0.891
[40,     3] loss: 0.966
[41,     3] loss: 0.820
[42,     3] loss: 0.903
[43,     3] loss: 0.806
[44,     3] loss: 0.815
[45,     3] loss: 0.790
[46,     3] loss: 0.753
[47,     3] loss: 0.780
[48,     3] loss: 0.762
[49,     3] loss: 0.780
[50,     3] loss: 0.822
[51,     3] loss: 0.841
[52,     3] loss: 0.870
[53,     3] loss: 0.955
[54,     3] loss: 1.024
[55,     3] loss: 0.958
[56,     3] loss: 0.900
[57,     3] loss: 0.894
[58,     3] loss: 0.904
[59,     3] loss: 0.777
[60,     3] loss: 0.793
[61,     3] loss: 0.808
[62,     3] loss: 0.743
[63,     3] loss: 0.726
[64,     3] loss: 0.742
[65,     3] loss: 0.761
[66,     3] loss: 0.746
[67,     3] loss: 0.745
[68,     3] loss: 0.803
[69,     3] loss: 0.756
[70,     3] loss: 0.853
[71,     3] loss: 0.863
[72,     3] loss: 0.847
[73,     3] loss: 0.946
[74,     3] loss: 0.900
[75,     3] loss: 0.824
[76,     3] loss: 0.793
[77,     3] loss: 0.817
[78,     3] loss: 0.916
[79,     3] loss: 0.921
[80,     3] loss: 1.006
[81,     3] loss: 0.952
[82,     3] loss: 0.888
[83,     3] loss: 0.814
Early stopping applied (best metric=0.5058056116104126)
Finished Training
Total time taken: 18.47606921195984
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.368
[3,     3] loss: 1.391
[4,     3] loss: 1.382
[5,     3] loss: 1.393
[6,     3] loss: 1.375
[7,     3] loss: 1.378
[8,     3] loss: 1.384
[9,     3] loss: 1.382
[10,     3] loss: 1.369
[11,     3] loss: 1.347
[12,     3] loss: 1.298
[13,     3] loss: 1.235
[14,     3] loss: 1.241
[15,     3] loss: 1.175
[16,     3] loss: 1.140
[17,     3] loss: 1.228
[18,     3] loss: 1.118
[19,     3] loss: 1.233
[20,     3] loss: 1.011
[21,     3] loss: 0.989
[22,     3] loss: 1.314
[23,     3] loss: 1.087
[24,     3] loss: 1.063
[25,     3] loss: 1.031
[26,     3] loss: 1.090
[27,     3] loss: 0.952
[28,     3] loss: 0.983
[29,     3] loss: 0.955
[30,     3] loss: 1.083
[31,     3] loss: 0.895
[32,     3] loss: 0.928
[33,     3] loss: 0.952
[34,     3] loss: 0.902
[35,     3] loss: 0.867
[36,     3] loss: 0.870
[37,     3] loss: 0.803
[38,     3] loss: 0.806
[39,     3] loss: 0.799
[40,     3] loss: 0.833
[41,     3] loss: 0.916
[42,     3] loss: 0.936
[43,     3] loss: 0.931
[44,     3] loss: 0.860
[45,     3] loss: 0.905
[46,     3] loss: 0.817
[47,     3] loss: 0.940
[48,     3] loss: 0.851
[49,     3] loss: 0.897
[50,     3] loss: 1.040
[51,     3] loss: 0.919
[52,     3] loss: 0.891
[53,     3] loss: 0.917
[54,     3] loss: 0.929
[55,     3] loss: 0.835
[56,     3] loss: 0.877
[57,     3] loss: 0.834
[58,     3] loss: 0.795
[59,     3] loss: 0.817
[60,     3] loss: 0.801
[61,     3] loss: 0.920
[62,     3] loss: 0.861
[63,     3] loss: 0.941
[64,     3] loss: 0.829
[65,     3] loss: 0.840
[66,     3] loss: 0.866
[67,     3] loss: 0.939
[68,     3] loss: 0.984
[69,     3] loss: 0.915
Early stopping applied (best metric=0.5241965055465698)
Finished Training
Total time taken: 15.374058485031128
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.380
[3,     3] loss: 1.384
[4,     3] loss: 1.381
[5,     3] loss: 1.376
[6,     3] loss: 1.347
[7,     3] loss: 1.329
[8,     3] loss: 1.303
[9,     3] loss: 1.280
[10,     3] loss: 1.241
[11,     3] loss: 1.125
[12,     3] loss: 1.192
[13,     3] loss: 1.076
[14,     3] loss: 1.051
[15,     3] loss: 1.091
[16,     3] loss: 1.138
[17,     3] loss: 1.142
[18,     3] loss: 1.083
[19,     3] loss: 1.136
[20,     3] loss: 1.000
[21,     3] loss: 1.046
[22,     3] loss: 0.899
[23,     3] loss: 0.891
[24,     3] loss: 0.984
[25,     3] loss: 0.914
[26,     3] loss: 1.024
[27,     3] loss: 1.054
[28,     3] loss: 1.131
[29,     3] loss: 1.102
[30,     3] loss: 1.129
[31,     3] loss: 1.111
[32,     3] loss: 1.016
[33,     3] loss: 0.970
[34,     3] loss: 0.870
[35,     3] loss: 0.910
[36,     3] loss: 0.910
[37,     3] loss: 0.837
[38,     3] loss: 0.887
[39,     3] loss: 0.879
[40,     3] loss: 0.865
[41,     3] loss: 0.869
[42,     3] loss: 0.933
[43,     3] loss: 0.990
[44,     3] loss: 0.923
[45,     3] loss: 0.927
[46,     3] loss: 0.914
[47,     3] loss: 0.848
[48,     3] loss: 0.972
[49,     3] loss: 0.939
[50,     3] loss: 0.827
[51,     3] loss: 0.800
[52,     3] loss: 0.825
[53,     3] loss: 0.755
[54,     3] loss: 0.752
[55,     3] loss: 0.761
[56,     3] loss: 0.741
[57,     3] loss: 0.728
[58,     3] loss: 0.748
[59,     3] loss: 0.732
[60,     3] loss: 0.717
[61,     3] loss: 0.721
[62,     3] loss: 0.775
[63,     3] loss: 0.931
Early stopping applied (best metric=0.49010685086250305)
Finished Training
Total time taken: 14.170055389404297
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.378
[2,     3] loss: 1.402
[3,     3] loss: 1.393
[4,     3] loss: 1.385
[5,     3] loss: 1.383
[6,     3] loss: 1.376
[7,     3] loss: 1.371
[8,     3] loss: 1.372
[9,     3] loss: 1.362
[10,     3] loss: 1.281
[11,     3] loss: 1.328
[12,     3] loss: 1.241
[13,     3] loss: 1.173
[14,     3] loss: 1.222
[15,     3] loss: 1.181
[16,     3] loss: 1.169
[17,     3] loss: 1.183
[18,     3] loss: 1.149
[19,     3] loss: 1.158
[20,     3] loss: 1.145
[21,     3] loss: 1.251
[22,     3] loss: 1.097
[23,     3] loss: 1.005
[24,     3] loss: 1.025
[25,     3] loss: 1.087
[26,     3] loss: 0.983
[27,     3] loss: 0.941
[28,     3] loss: 1.019
[29,     3] loss: 0.892
[30,     3] loss: 0.925
[31,     3] loss: 0.907
[32,     3] loss: 0.896
[33,     3] loss: 0.984
[34,     3] loss: 0.949
[35,     3] loss: 0.847
[36,     3] loss: 0.855
[37,     3] loss: 0.849
[38,     3] loss: 0.997
[39,     3] loss: 0.957
[40,     3] loss: 0.880
[41,     3] loss: 0.897
[42,     3] loss: 0.842
[43,     3] loss: 0.795
[44,     3] loss: 0.854
[45,     3] loss: 0.900
[46,     3] loss: 1.026
[47,     3] loss: 0.978
[48,     3] loss: 0.953
[49,     3] loss: 0.909
[50,     3] loss: 0.872
[51,     3] loss: 0.813
[52,     3] loss: 0.877
[53,     3] loss: 1.098
[54,     3] loss: 0.930
[55,     3] loss: 0.963
[56,     3] loss: 0.943
[57,     3] loss: 0.952
[58,     3] loss: 0.873
[59,     3] loss: 0.849
[60,     3] loss: 0.863
[61,     3] loss: 0.857
[62,     3] loss: 0.810
[63,     3] loss: 0.873
[64,     3] loss: 0.924
[65,     3] loss: 0.842
[66,     3] loss: 0.840
[67,     3] loss: 0.848
[68,     3] loss: 0.813
[69,     3] loss: 0.815
[70,     3] loss: 0.821
[71,     3] loss: 0.851
[72,     3] loss: 0.819
[73,     3] loss: 0.815
[74,     3] loss: 0.821
[75,     3] loss: 0.796
[76,     3] loss: 0.782
[77,     3] loss: 0.783
[78,     3] loss: 0.762
[79,     3] loss: 0.772
[80,     3] loss: 0.804
[81,     3] loss: 0.813
[82,     3] loss: 0.840
[83,     3] loss: 0.777
[84,     3] loss: 0.816
[85,     3] loss: 0.881
[86,     3] loss: 0.891
[87,     3] loss: 0.908
[88,     3] loss: 0.887
[89,     3] loss: 0.835
[90,     3] loss: 0.797
[91,     3] loss: 0.770
[92,     3] loss: 0.734
[93,     3] loss: 0.716
[94,     3] loss: 0.709
Early stopping applied (best metric=0.508003294467926)
Finished Training
Total time taken: 21.00707769393921
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.389
[3,     3] loss: 1.391
[4,     3] loss: 1.383
[5,     3] loss: 1.384
[6,     3] loss: 1.394
[7,     3] loss: 1.392
[8,     3] loss: 1.383
[9,     3] loss: 1.392
[10,     3] loss: 1.384
[11,     3] loss: 1.387
[12,     3] loss: 1.386
[13,     3] loss: 1.384
[14,     3] loss: 1.377
[15,     3] loss: 1.360
[16,     3] loss: 1.344
[17,     3] loss: 1.320
[18,     3] loss: 1.238
[19,     3] loss: 1.246
[20,     3] loss: 1.207
[21,     3] loss: 1.222
[22,     3] loss: 1.151
[23,     3] loss: 1.075
[24,     3] loss: 1.090
[25,     3] loss: 1.090
[26,     3] loss: 1.281
[27,     3] loss: 1.130
[28,     3] loss: 1.186
[29,     3] loss: 1.145
[30,     3] loss: 1.120
[31,     3] loss: 1.099
[32,     3] loss: 1.061
[33,     3] loss: 1.033
[34,     3] loss: 1.039
[35,     3] loss: 0.956
[36,     3] loss: 1.003
[37,     3] loss: 1.003
[38,     3] loss: 0.972
[39,     3] loss: 1.179
[40,     3] loss: 1.143
[41,     3] loss: 0.997
[42,     3] loss: 0.975
[43,     3] loss: 1.014
[44,     3] loss: 0.989
[45,     3] loss: 0.915
[46,     3] loss: 0.971
[47,     3] loss: 0.873
[48,     3] loss: 0.823
[49,     3] loss: 0.916
[50,     3] loss: 0.962
[51,     3] loss: 0.987
[52,     3] loss: 1.007
[53,     3] loss: 0.970
[54,     3] loss: 0.915
[55,     3] loss: 0.906
[56,     3] loss: 0.841
[57,     3] loss: 0.824
[58,     3] loss: 1.023
[59,     3] loss: 0.853
[60,     3] loss: 0.825
[61,     3] loss: 0.817
[62,     3] loss: 0.857
[63,     3] loss: 0.800
[64,     3] loss: 0.772
[65,     3] loss: 0.813
[66,     3] loss: 0.784
[67,     3] loss: 0.802
[68,     3] loss: 0.757
[69,     3] loss: 0.785
[70,     3] loss: 0.766
[71,     3] loss: 0.810
[72,     3] loss: 0.911
[73,     3] loss: 0.927
[74,     3] loss: 0.877
[75,     3] loss: 0.840
[76,     3] loss: 0.864
[77,     3] loss: 0.842
[78,     3] loss: 0.829
[79,     3] loss: 0.807
[80,     3] loss: 0.794
[81,     3] loss: 0.767
[82,     3] loss: 0.821
[83,     3] loss: 0.899
[84,     3] loss: 0.830
Early stopping applied (best metric=0.515413224697113)
Finished Training
Total time taken: 18.669068336486816
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.388
[3,     3] loss: 1.385
[4,     3] loss: 1.382
[5,     3] loss: 1.388
[6,     3] loss: 1.383
[7,     3] loss: 1.382
[8,     3] loss: 1.379
[9,     3] loss: 1.378
[10,     3] loss: 1.381
[11,     3] loss: 1.367
[12,     3] loss: 1.361
[13,     3] loss: 1.352
[14,     3] loss: 1.317
[15,     3] loss: 1.266
[16,     3] loss: 1.234
[17,     3] loss: 1.206
[18,     3] loss: 1.189
[19,     3] loss: 1.164
[20,     3] loss: 1.112
[21,     3] loss: 1.163
[22,     3] loss: 1.012
[23,     3] loss: 0.981
[24,     3] loss: 0.980
[25,     3] loss: 0.970
[26,     3] loss: 1.159
[27,     3] loss: 0.980
[28,     3] loss: 0.992
[29,     3] loss: 1.007
[30,     3] loss: 0.965
[31,     3] loss: 1.013
[32,     3] loss: 0.987
[33,     3] loss: 0.846
[34,     3] loss: 0.892
[35,     3] loss: 0.848
[36,     3] loss: 0.883
[37,     3] loss: 0.881
[38,     3] loss: 1.143
[39,     3] loss: 1.008
[40,     3] loss: 0.993
[41,     3] loss: 1.046
[42,     3] loss: 1.023
[43,     3] loss: 1.043
[44,     3] loss: 0.985
[45,     3] loss: 0.871
[46,     3] loss: 0.890
[47,     3] loss: 0.856
[48,     3] loss: 0.863
[49,     3] loss: 0.928
[50,     3] loss: 1.037
[51,     3] loss: 1.013
[52,     3] loss: 0.962
[53,     3] loss: 0.919
[54,     3] loss: 0.936
[55,     3] loss: 0.876
[56,     3] loss: 0.837
[57,     3] loss: 0.816
[58,     3] loss: 0.813
[59,     3] loss: 0.915
[60,     3] loss: 0.807
[61,     3] loss: 0.796
[62,     3] loss: 0.791
[63,     3] loss: 0.804
[64,     3] loss: 0.905
[65,     3] loss: 0.845
[66,     3] loss: 0.802
[67,     3] loss: 0.798
[68,     3] loss: 0.813
[69,     3] loss: 0.791
[70,     3] loss: 0.793
[71,     3] loss: 0.789
[72,     3] loss: 0.797
[73,     3] loss: 0.769
[74,     3] loss: 0.979
[75,     3] loss: 0.871
[76,     3] loss: 0.833
[77,     3] loss: 0.789
[78,     3] loss: 0.840
[79,     3] loss: 0.773
[80,     3] loss: 0.889
[81,     3] loss: 0.785
[82,     3] loss: 0.762
[83,     3] loss: 0.842
[84,     3] loss: 0.779
[85,     3] loss: 0.893
[86,     3] loss: 1.093
[87,     3] loss: 1.147
[88,     3] loss: 1.068
[89,     3] loss: 1.030
[90,     3] loss: 1.052
[91,     3] loss: 0.910
[92,     3] loss: 0.890
[93,     3] loss: 0.935
[94,     3] loss: 0.853
[95,     3] loss: 0.820
[96,     3] loss: 0.819
[97,     3] loss: 0.815
[98,     3] loss: 0.764
[99,     3] loss: 0.851
[100,     3] loss: 0.826
[101,     3] loss: 0.806
[102,     3] loss: 0.798
[103,     3] loss: 0.812
[104,     3] loss: 0.836
[105,     3] loss: 0.775
[106,     3] loss: 0.807
Early stopping applied (best metric=0.5284720659255981)
Finished Training
Total time taken: 23.600704669952393
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.383
[3,     3] loss: 1.374
[4,     3] loss: 1.378
[5,     3] loss: 1.397
[6,     3] loss: 1.369
[7,     3] loss: 1.379
[8,     3] loss: 1.377
[9,     3] loss: 1.332
[10,     3] loss: 1.312
[11,     3] loss: 1.358
[12,     3] loss: 1.358
[13,     3] loss: 1.255
[14,     3] loss: 1.262
[15,     3] loss: 1.331
[16,     3] loss: 1.271
[17,     3] loss: 1.222
[18,     3] loss: 1.273
[19,     3] loss: 1.228
[20,     3] loss: 1.193
[21,     3] loss: 1.109
[22,     3] loss: 1.095
[23,     3] loss: 1.155
[24,     3] loss: 1.031
[25,     3] loss: 1.100
[26,     3] loss: 0.962
[27,     3] loss: 0.942
[28,     3] loss: 0.953
[29,     3] loss: 0.947
[30,     3] loss: 1.037
[31,     3] loss: 1.066
[32,     3] loss: 1.000
[33,     3] loss: 1.125
[34,     3] loss: 1.202
[35,     3] loss: 1.135
[36,     3] loss: 1.158
[37,     3] loss: 1.059
[38,     3] loss: 1.114
[39,     3] loss: 0.897
[40,     3] loss: 0.962
[41,     3] loss: 0.903
[42,     3] loss: 0.861
[43,     3] loss: 0.867
[44,     3] loss: 0.839
[45,     3] loss: 0.900
[46,     3] loss: 0.872
[47,     3] loss: 0.861
[48,     3] loss: 0.833
[49,     3] loss: 0.935
[50,     3] loss: 1.061
[51,     3] loss: 0.882
[52,     3] loss: 0.893
[53,     3] loss: 0.932
[54,     3] loss: 0.893
[55,     3] loss: 0.790
[56,     3] loss: 0.802
[57,     3] loss: 0.861
[58,     3] loss: 0.791
[59,     3] loss: 0.949
[60,     3] loss: 1.067
[61,     3] loss: 1.201
[62,     3] loss: 1.093
[63,     3] loss: 1.172
[64,     3] loss: 0.998
[65,     3] loss: 0.928
[66,     3] loss: 0.903
[67,     3] loss: 0.769
[68,     3] loss: 0.776
[69,     3] loss: 0.829
[70,     3] loss: 0.853
[71,     3] loss: 1.048
[72,     3] loss: 0.947
[73,     3] loss: 0.885
[74,     3] loss: 0.957
[75,     3] loss: 0.868
[76,     3] loss: 0.778
[77,     3] loss: 0.804
[78,     3] loss: 0.775
Early stopping applied (best metric=0.4965338706970215)
Finished Training
Total time taken: 17.343066215515137
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.390
[3,     3] loss: 1.392
[4,     3] loss: 1.386
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.384
[8,     3] loss: 1.377
[9,     3] loss: 1.395
[10,     3] loss: 1.378
[11,     3] loss: 1.388
[12,     3] loss: 1.378
[13,     3] loss: 1.356
[14,     3] loss: 1.340
[15,     3] loss: 1.314
[16,     3] loss: 1.337
[17,     3] loss: 1.261
[18,     3] loss: 1.172
[19,     3] loss: 1.163
[20,     3] loss: 1.116
[21,     3] loss: 1.095
[22,     3] loss: 1.157
[23,     3] loss: 1.136
[24,     3] loss: 1.050
[25,     3] loss: 1.071
[26,     3] loss: 1.058
[27,     3] loss: 1.047
[28,     3] loss: 1.048
[29,     3] loss: 1.027
[30,     3] loss: 1.048
[31,     3] loss: 0.962
[32,     3] loss: 0.969
[33,     3] loss: 0.922
[34,     3] loss: 0.991
[35,     3] loss: 1.108
[36,     3] loss: 0.976
[37,     3] loss: 0.939
[38,     3] loss: 0.915
[39,     3] loss: 0.886
[40,     3] loss: 0.863
[41,     3] loss: 0.786
[42,     3] loss: 0.888
[43,     3] loss: 1.255
[44,     3] loss: 0.953
[45,     3] loss: 0.923
[46,     3] loss: 0.975
[47,     3] loss: 0.960
[48,     3] loss: 0.964
[49,     3] loss: 0.847
[50,     3] loss: 0.942
[51,     3] loss: 0.883
[52,     3] loss: 0.886
[53,     3] loss: 0.857
[54,     3] loss: 0.830
[55,     3] loss: 0.881
[56,     3] loss: 0.928
[57,     3] loss: 0.851
[58,     3] loss: 0.805
[59,     3] loss: 0.820
[60,     3] loss: 0.814
[61,     3] loss: 0.836
[62,     3] loss: 0.917
[63,     3] loss: 0.814
[64,     3] loss: 0.915
[65,     3] loss: 0.905
[66,     3] loss: 0.858
[67,     3] loss: 0.846
Early stopping applied (best metric=0.5090180039405823)
Finished Training
Total time taken: 14.986055612564087
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.389
[3,     3] loss: 1.385
[4,     3] loss: 1.392
[5,     3] loss: 1.394
[6,     3] loss: 1.386
[7,     3] loss: 1.387
[8,     3] loss: 1.383
[9,     3] loss: 1.396
[10,     3] loss: 1.388
[11,     3] loss: 1.389
[12,     3] loss: 1.388
[13,     3] loss: 1.386
[14,     3] loss: 1.391
[15,     3] loss: 1.398
[16,     3] loss: 1.386
[17,     3] loss: 1.388
[18,     3] loss: 1.388
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.385
[22,     3] loss: 1.376
[23,     3] loss: 1.373
[24,     3] loss: 1.363
[25,     3] loss: 1.305
[26,     3] loss: 1.267
[27,     3] loss: 1.261
[28,     3] loss: 1.262
[29,     3] loss: 1.244
[30,     3] loss: 1.289
[31,     3] loss: 1.220
[32,     3] loss: 1.181
[33,     3] loss: 1.131
[34,     3] loss: 1.101
[35,     3] loss: 1.042
[36,     3] loss: 1.090
[37,     3] loss: 1.245
[38,     3] loss: 0.988
[39,     3] loss: 1.088
[40,     3] loss: 1.056
[41,     3] loss: 1.002
[42,     3] loss: 1.006
[43,     3] loss: 0.946
[44,     3] loss: 0.894
[45,     3] loss: 1.010
[46,     3] loss: 0.899
[47,     3] loss: 0.955
[48,     3] loss: 1.040
[49,     3] loss: 0.978
[50,     3] loss: 0.894
[51,     3] loss: 0.987
[52,     3] loss: 0.928
[53,     3] loss: 0.967
[54,     3] loss: 0.837
[55,     3] loss: 0.849
[56,     3] loss: 0.895
[57,     3] loss: 0.791
[58,     3] loss: 1.206
[59,     3] loss: 1.240
[60,     3] loss: 1.073
[61,     3] loss: 1.099
[62,     3] loss: 1.070
[63,     3] loss: 1.047
[64,     3] loss: 0.871
[65,     3] loss: 0.967
[66,     3] loss: 0.971
[67,     3] loss: 1.076
[68,     3] loss: 0.963
[69,     3] loss: 0.951
[70,     3] loss: 1.102
[71,     3] loss: 0.992
[72,     3] loss: 0.986
[73,     3] loss: 1.001
[74,     3] loss: 0.903
[75,     3] loss: 0.942
[76,     3] loss: 0.833
[77,     3] loss: 0.794
[78,     3] loss: 0.763
[79,     3] loss: 0.818
[80,     3] loss: 0.872
[81,     3] loss: 0.848
[82,     3] loss: 0.793
[83,     3] loss: 0.787
[84,     3] loss: 0.782
[85,     3] loss: 0.844
[86,     3] loss: 0.978
[87,     3] loss: 0.878
[88,     3] loss: 0.880
[89,     3] loss: 0.917
[90,     3] loss: 0.805
[91,     3] loss: 0.784
Early stopping applied (best metric=0.5148759484291077)
Finished Training
Total time taken: 20.253432750701904
{'S-palmitoylation-C Validation Accuracy': 0.687813726787526, 'S-palmitoylation-C Validation Sensitivity': 0.21821782178217822, 'S-palmitoylation-C Validation Specificity': 0.8055324884616617, 'S-palmitoylation-C Validation Precision': 0.23674979294799178, 'S-palmitoylation-C AUC ROC': 0.5354869073094323, 'S-palmitoylation-C AUC PR': 0.22166203234989657, 'S-palmitoylation-C MCC': 0.030527854447670786, 'S-palmitoylation-C F1': 0.19264124824146966, 'Validation Loss (S-palmitoylation-C)': 0.5547853946685791, 'Hydroxylation-K Validation Accuracy': 0.7300827423167848, 'Hydroxylation-K Validation Sensitivity': 0.7785185185185185, 'Hydroxylation-K Validation Specificity': 0.7175438596491228, 'Hydroxylation-K Validation Precision': 0.460101120800918, 'Hydroxylation-K AUC ROC': 0.8375438596491228, 'Hydroxylation-K AUC PR': 0.6294266648235213, 'Hydroxylation-K MCC': 0.43400964815235327, 'Hydroxylation-K F1': 0.5528034425548168, 'Validation Loss (Hydroxylation-K)': 0.5128428737322489, 'Validation Loss (total)': 1.0676282564798991, 'TimeToTrain': 17.71745187441508}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007677131556214902,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8144427637293367,
 'loss_weight_S-palmitoylation-C': 0.3875465219823181,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3504342972,
 'sample_weights': [0.03623667653896645, 0.35810394851105226],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.808082536856649,
 'weight_decay_Hydroxylation-K': 5.83358575723468,
 'weight_decay_S-palmitoylation-C': 1.8839010546010075}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.387
[3,     3] loss: 1.388
[4,     3] loss: 1.388
[5,     3] loss: 1.388
[6,     3] loss: 1.375
[7,     3] loss: 1.376
[8,     3] loss: 1.378
[9,     3] loss: 1.369
[10,     3] loss: 1.364
[11,     3] loss: 1.366
[12,     3] loss: 1.347
[13,     3] loss: 1.303
[14,     3] loss: 1.330
[15,     3] loss: 1.271
[16,     3] loss: 1.257
[17,     3] loss: 1.230
[18,     3] loss: 1.277
[19,     3] loss: 1.192
[20,     3] loss: 1.139
[21,     3] loss: 1.134
[22,     3] loss: 1.141
[23,     3] loss: 1.180
[24,     3] loss: 1.033
[25,     3] loss: 1.064
[26,     3] loss: 1.016
[27,     3] loss: 1.005
[28,     3] loss: 1.022
[29,     3] loss: 0.937
[30,     3] loss: 0.907
[31,     3] loss: 0.907
[32,     3] loss: 1.006
[33,     3] loss: 1.061
[34,     3] loss: 1.053
[35,     3] loss: 1.052
[36,     3] loss: 1.048
[37,     3] loss: 0.999
[38,     3] loss: 0.963
[39,     3] loss: 0.923
[40,     3] loss: 1.007
[41,     3] loss: 0.966
[42,     3] loss: 0.919
[43,     3] loss: 0.948
[44,     3] loss: 0.893
[45,     3] loss: 0.874
[46,     3] loss: 0.867
[47,     3] loss: 0.840
[48,     3] loss: 0.859
[49,     3] loss: 0.882
[50,     3] loss: 0.839
[51,     3] loss: 0.807
[52,     3] loss: 0.818
[53,     3] loss: 0.803
[54,     3] loss: 0.788
[55,     3] loss: 0.820
[56,     3] loss: 0.854
[57,     3] loss: 0.826
[58,     3] loss: 0.813
[59,     3] loss: 0.781
[60,     3] loss: 0.938
[61,     3] loss: 0.812
[62,     3] loss: 0.873
[63,     3] loss: 0.900
[64,     3] loss: 0.904
[65,     3] loss: 0.816
[66,     3] loss: 0.835
[67,     3] loss: 0.867
[68,     3] loss: 0.780
Early stopping applied (best metric=0.5181822180747986)
Finished Training
Total time taken: 15.140079259872437
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.385
[4,     3] loss: 1.389
[5,     3] loss: 1.383
[6,     3] loss: 1.392
[7,     3] loss: 1.387
[8,     3] loss: 1.379
[9,     3] loss: 1.385
[10,     3] loss: 1.379
[11,     3] loss: 1.371
[12,     3] loss: 1.357
[13,     3] loss: 1.354
[14,     3] loss: 1.375
[15,     3] loss: 1.325
[16,     3] loss: 1.295
[17,     3] loss: 1.296
[18,     3] loss: 1.257
[19,     3] loss: 1.239
[20,     3] loss: 1.149
[21,     3] loss: 1.184
[22,     3] loss: 1.148
[23,     3] loss: 1.111
[24,     3] loss: 1.209
[25,     3] loss: 1.293
[26,     3] loss: 1.138
[27,     3] loss: 1.119
[28,     3] loss: 1.160
[29,     3] loss: 1.178
[30,     3] loss: 1.113
[31,     3] loss: 1.172
[32,     3] loss: 1.151
[33,     3] loss: 1.173
[34,     3] loss: 1.054
[35,     3] loss: 0.972
[36,     3] loss: 1.088
[37,     3] loss: 0.964
[38,     3] loss: 0.965
[39,     3] loss: 1.069
[40,     3] loss: 0.934
[41,     3] loss: 0.992
[42,     3] loss: 1.023
[43,     3] loss: 0.976
[44,     3] loss: 0.995
[45,     3] loss: 0.909
[46,     3] loss: 1.088
[47,     3] loss: 0.915
[48,     3] loss: 0.935
[49,     3] loss: 0.909
[50,     3] loss: 0.966
[51,     3] loss: 0.858
[52,     3] loss: 0.853
[53,     3] loss: 0.837
[54,     3] loss: 0.896
[55,     3] loss: 0.917
[56,     3] loss: 0.843
[57,     3] loss: 0.930
[58,     3] loss: 0.893
[59,     3] loss: 1.011
[60,     3] loss: 1.065
[61,     3] loss: 0.918
[62,     3] loss: 1.021
[63,     3] loss: 0.956
[64,     3] loss: 0.941
[65,     3] loss: 0.928
[66,     3] loss: 0.896
[67,     3] loss: 0.888
[68,     3] loss: 0.914
[69,     3] loss: 0.837
[70,     3] loss: 0.851
[71,     3] loss: 0.857
[72,     3] loss: 0.806
[73,     3] loss: 0.826
[74,     3] loss: 0.828
[75,     3] loss: 0.805
[76,     3] loss: 0.782
[77,     3] loss: 0.768
[78,     3] loss: 0.805
[79,     3] loss: 0.789
[80,     3] loss: 0.757
[81,     3] loss: 0.779
[82,     3] loss: 0.852
[83,     3] loss: 0.791
[84,     3] loss: 0.796
[85,     3] loss: 0.844
[86,     3] loss: 0.885
[87,     3] loss: 0.818
[88,     3] loss: 0.792
Early stopping applied (best metric=0.5006449222564697)
Finished Training
Total time taken: 19.518086671829224
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.387
[3,     3] loss: 1.376
[4,     3] loss: 1.385
[5,     3] loss: 1.375
[6,     3] loss: 1.384
[7,     3] loss: 1.384
[8,     3] loss: 1.374
[9,     3] loss: 1.377
[10,     3] loss: 1.367
[11,     3] loss: 1.356
[12,     3] loss: 1.348
[13,     3] loss: 1.313
[14,     3] loss: 1.301
[15,     3] loss: 1.345
[16,     3] loss: 1.258
[17,     3] loss: 1.285
[18,     3] loss: 1.242
[19,     3] loss: 1.229
[20,     3] loss: 1.187
[21,     3] loss: 1.155
[22,     3] loss: 1.097
[23,     3] loss: 1.132
[24,     3] loss: 1.006
[25,     3] loss: 1.023
[26,     3] loss: 0.989
[27,     3] loss: 1.034
[28,     3] loss: 1.026
[29,     3] loss: 0.924
[30,     3] loss: 0.971
[31,     3] loss: 1.003
[32,     3] loss: 1.068
[33,     3] loss: 0.927
[34,     3] loss: 0.954
[35,     3] loss: 0.903
[36,     3] loss: 0.928
[37,     3] loss: 0.913
[38,     3] loss: 0.954
[39,     3] loss: 0.907
[40,     3] loss: 0.906
[41,     3] loss: 0.823
[42,     3] loss: 0.914
[43,     3] loss: 0.866
[44,     3] loss: 1.016
[45,     3] loss: 0.906
[46,     3] loss: 0.876
[47,     3] loss: 0.891
[48,     3] loss: 0.929
[49,     3] loss: 0.925
[50,     3] loss: 0.870
[51,     3] loss: 0.880
[52,     3] loss: 0.908
[53,     3] loss: 0.814
[54,     3] loss: 0.845
[55,     3] loss: 0.852
[56,     3] loss: 0.850
[57,     3] loss: 0.816
[58,     3] loss: 0.864
[59,     3] loss: 0.832
[60,     3] loss: 0.834
[61,     3] loss: 0.902
[62,     3] loss: 0.801
[63,     3] loss: 0.822
[64,     3] loss: 0.809
[65,     3] loss: 0.790
[66,     3] loss: 0.838
[67,     3] loss: 0.779
[68,     3] loss: 0.771
[69,     3] loss: 0.789
[70,     3] loss: 0.842
[71,     3] loss: 0.780
[72,     3] loss: 0.859
Early stopping applied (best metric=0.5003029704093933)
Finished Training
Total time taken: 16.08330225944519
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.390
[3,     3] loss: 1.383
[4,     3] loss: 1.389
[5,     3] loss: 1.388
[6,     3] loss: 1.369
[7,     3] loss: 1.376
[8,     3] loss: 1.368
[9,     3] loss: 1.361
[10,     3] loss: 1.327
[11,     3] loss: 1.326
[12,     3] loss: 1.290
[13,     3] loss: 1.272
[14,     3] loss: 1.251
[15,     3] loss: 1.337
[16,     3] loss: 1.205
[17,     3] loss: 1.156
[18,     3] loss: 1.160
[19,     3] loss: 1.065
[20,     3] loss: 1.084
[21,     3] loss: 1.073
[22,     3] loss: 1.084
[23,     3] loss: 1.038
[24,     3] loss: 1.061
[25,     3] loss: 1.103
[26,     3] loss: 1.051
[27,     3] loss: 0.990
[28,     3] loss: 1.049
[29,     3] loss: 0.974
[30,     3] loss: 0.929
[31,     3] loss: 0.887
[32,     3] loss: 0.970
[33,     3] loss: 0.939
[34,     3] loss: 0.945
[35,     3] loss: 0.964
[36,     3] loss: 0.892
[37,     3] loss: 0.918
[38,     3] loss: 0.880
[39,     3] loss: 0.894
[40,     3] loss: 0.884
[41,     3] loss: 0.891
[42,     3] loss: 0.862
[43,     3] loss: 0.878
[44,     3] loss: 0.843
[45,     3] loss: 0.840
[46,     3] loss: 0.908
[47,     3] loss: 0.933
[48,     3] loss: 0.857
[49,     3] loss: 0.863
[50,     3] loss: 0.926
[51,     3] loss: 0.898
[52,     3] loss: 0.856
[53,     3] loss: 0.920
[54,     3] loss: 0.884
[55,     3] loss: 0.963
[56,     3] loss: 0.928
[57,     3] loss: 0.863
[58,     3] loss: 0.976
[59,     3] loss: 0.959
[60,     3] loss: 0.949
[61,     3] loss: 0.976
[62,     3] loss: 0.869
[63,     3] loss: 0.893
[64,     3] loss: 0.853
[65,     3] loss: 0.828
[66,     3] loss: 0.851
[67,     3] loss: 0.815
[68,     3] loss: 0.848
[69,     3] loss: 0.812
[70,     3] loss: 0.828
[71,     3] loss: 0.816
[72,     3] loss: 0.800
[73,     3] loss: 0.838
[74,     3] loss: 0.829
[75,     3] loss: 0.917
Early stopping applied (best metric=0.48527735471725464)
Finished Training
Total time taken: 16.652060985565186
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.384
[3,     3] loss: 1.384
[4,     3] loss: 1.379
[5,     3] loss: 1.376
[6,     3] loss: 1.370
[7,     3] loss: 1.374
[8,     3] loss: 1.371
[9,     3] loss: 1.346
[10,     3] loss: 1.359
[11,     3] loss: 1.312
[12,     3] loss: 1.321
[13,     3] loss: 1.299
[14,     3] loss: 1.273
[15,     3] loss: 1.256
[16,     3] loss: 1.248
[17,     3] loss: 1.189
[18,     3] loss: 1.206
[19,     3] loss: 1.109
[20,     3] loss: 1.113
[21,     3] loss: 1.198
[22,     3] loss: 1.044
[23,     3] loss: 1.011
[24,     3] loss: 1.064
[25,     3] loss: 1.061
[26,     3] loss: 0.990
[27,     3] loss: 0.974
[28,     3] loss: 0.908
[29,     3] loss: 0.941
[30,     3] loss: 0.923
[31,     3] loss: 0.969
[32,     3] loss: 0.917
[33,     3] loss: 1.032
[34,     3] loss: 0.885
[35,     3] loss: 0.919
[36,     3] loss: 0.928
[37,     3] loss: 0.940
[38,     3] loss: 0.866
[39,     3] loss: 0.857
[40,     3] loss: 0.913
[41,     3] loss: 0.897
[42,     3] loss: 0.847
[43,     3] loss: 0.949
[44,     3] loss: 0.942
[45,     3] loss: 0.866
[46,     3] loss: 0.843
[47,     3] loss: 0.846
[48,     3] loss: 0.857
[49,     3] loss: 0.815
[50,     3] loss: 0.908
[51,     3] loss: 0.835
[52,     3] loss: 0.869
[53,     3] loss: 0.833
[54,     3] loss: 0.945
[55,     3] loss: 0.881
[56,     3] loss: 1.064
[57,     3] loss: 0.869
[58,     3] loss: 0.828
[59,     3] loss: 0.932
[60,     3] loss: 1.136
[61,     3] loss: 0.923
[62,     3] loss: 0.940
[63,     3] loss: 0.971
[64,     3] loss: 1.039
[65,     3] loss: 0.935
[66,     3] loss: 0.860
[67,     3] loss: 0.906
[68,     3] loss: 0.820
[69,     3] loss: 0.839
[70,     3] loss: 0.811
Early stopping applied (best metric=0.44947922229766846)
Finished Training
Total time taken: 15.648058891296387
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.377
[2,     3] loss: 1.388
[3,     3] loss: 1.385
[4,     3] loss: 1.391
[5,     3] loss: 1.379
[6,     3] loss: 1.378
[7,     3] loss: 1.379
[8,     3] loss: 1.368
[9,     3] loss: 1.365
[10,     3] loss: 1.363
[11,     3] loss: 1.329
[12,     3] loss: 1.312
[13,     3] loss: 1.294
[14,     3] loss: 1.268
[15,     3] loss: 1.238
[16,     3] loss: 1.229
[17,     3] loss: 1.181
[18,     3] loss: 1.125
[19,     3] loss: 1.218
[20,     3] loss: 1.063
[21,     3] loss: 1.101
[22,     3] loss: 1.077
[23,     3] loss: 1.027
[24,     3] loss: 0.988
[25,     3] loss: 0.968
[26,     3] loss: 0.924
[27,     3] loss: 0.976
[28,     3] loss: 1.135
[29,     3] loss: 0.903
[30,     3] loss: 0.951
[31,     3] loss: 0.921
[32,     3] loss: 0.951
[33,     3] loss: 1.040
[34,     3] loss: 0.991
[35,     3] loss: 0.856
[36,     3] loss: 1.073
[37,     3] loss: 0.921
[38,     3] loss: 0.935
[39,     3] loss: 1.002
[40,     3] loss: 0.878
[41,     3] loss: 1.007
[42,     3] loss: 0.916
[43,     3] loss: 0.866
[44,     3] loss: 0.888
[45,     3] loss: 0.878
[46,     3] loss: 0.831
[47,     3] loss: 0.918
[48,     3] loss: 0.840
[49,     3] loss: 0.890
[50,     3] loss: 0.846
[51,     3] loss: 0.810
[52,     3] loss: 0.808
[53,     3] loss: 0.795
[54,     3] loss: 0.787
[55,     3] loss: 0.764
[56,     3] loss: 0.771
[57,     3] loss: 0.776
[58,     3] loss: 0.787
[59,     3] loss: 0.776
[60,     3] loss: 0.802
[61,     3] loss: 0.855
[62,     3] loss: 0.801
[63,     3] loss: 0.779
[64,     3] loss: 0.789
[65,     3] loss: 0.782
[66,     3] loss: 0.856
[67,     3] loss: 0.943
[68,     3] loss: 0.861
[69,     3] loss: 0.866
[70,     3] loss: 0.839
[71,     3] loss: 0.823
Early stopping applied (best metric=0.5308535099029541)
Finished Training
Total time taken: 15.820059061050415
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.379
[3,     3] loss: 1.396
[4,     3] loss: 1.385
[5,     3] loss: 1.384
[6,     3] loss: 1.381
[7,     3] loss: 1.376
[8,     3] loss: 1.378
[9,     3] loss: 1.361
[10,     3] loss: 1.357
[11,     3] loss: 1.336
[12,     3] loss: 1.333
[13,     3] loss: 1.295
[14,     3] loss: 1.302
[15,     3] loss: 1.282
[16,     3] loss: 1.287
[17,     3] loss: 1.239
[18,     3] loss: 1.229
[19,     3] loss: 1.177
[20,     3] loss: 1.202
[21,     3] loss: 1.142
[22,     3] loss: 1.174
[23,     3] loss: 1.247
[24,     3] loss: 1.090
[25,     3] loss: 1.160
[26,     3] loss: 1.091
[27,     3] loss: 1.047
[28,     3] loss: 1.102
[29,     3] loss: 0.977
[30,     3] loss: 1.073
[31,     3] loss: 0.982
[32,     3] loss: 0.964
[33,     3] loss: 0.924
[34,     3] loss: 0.954
[35,     3] loss: 0.919
[36,     3] loss: 0.898
[37,     3] loss: 0.914
[38,     3] loss: 0.905
[39,     3] loss: 0.860
[40,     3] loss: 0.957
[41,     3] loss: 0.965
[42,     3] loss: 0.873
[43,     3] loss: 0.930
[44,     3] loss: 0.919
[45,     3] loss: 0.949
[46,     3] loss: 0.872
[47,     3] loss: 0.913
[48,     3] loss: 0.952
[49,     3] loss: 0.859
[50,     3] loss: 0.951
[51,     3] loss: 0.919
[52,     3] loss: 0.897
[53,     3] loss: 0.976
[54,     3] loss: 0.903
[55,     3] loss: 0.833
[56,     3] loss: 0.839
[57,     3] loss: 0.860
[58,     3] loss: 0.850
[59,     3] loss: 0.909
[60,     3] loss: 0.938
[61,     3] loss: 0.893
[62,     3] loss: 0.881
[63,     3] loss: 0.881
[64,     3] loss: 0.869
[65,     3] loss: 0.841
[66,     3] loss: 0.874
[67,     3] loss: 0.808
[68,     3] loss: 0.848
[69,     3] loss: 0.815
[70,     3] loss: 0.874
[71,     3] loss: 0.770
Early stopping applied (best metric=0.5038689374923706)
Finished Training
Total time taken: 15.832059860229492
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.383
[3,     3] loss: 1.388
[4,     3] loss: 1.379
[5,     3] loss: 1.376
[6,     3] loss: 1.374
[7,     3] loss: 1.384
[8,     3] loss: 1.388
[9,     3] loss: 1.391
[10,     3] loss: 1.378
[11,     3] loss: 1.375
[12,     3] loss: 1.380
[13,     3] loss: 1.369
[14,     3] loss: 1.360
[15,     3] loss: 1.352
[16,     3] loss: 1.354
[17,     3] loss: 1.338
[18,     3] loss: 1.345
[19,     3] loss: 1.302
[20,     3] loss: 1.249
[21,     3] loss: 1.233
[22,     3] loss: 1.183
[23,     3] loss: 1.130
[24,     3] loss: 1.128
[25,     3] loss: 1.086
[26,     3] loss: 1.047
[27,     3] loss: 1.229
[28,     3] loss: 1.177
[29,     3] loss: 1.022
[30,     3] loss: 1.002
[31,     3] loss: 1.015
[32,     3] loss: 1.023
[33,     3] loss: 0.978
[34,     3] loss: 0.977
[35,     3] loss: 0.916
[36,     3] loss: 0.922
[37,     3] loss: 0.904
[38,     3] loss: 0.959
[39,     3] loss: 0.960
[40,     3] loss: 0.900
[41,     3] loss: 0.874
[42,     3] loss: 0.833
[43,     3] loss: 0.929
[44,     3] loss: 0.837
[45,     3] loss: 0.799
[46,     3] loss: 0.858
[47,     3] loss: 0.815
[48,     3] loss: 0.794
[49,     3] loss: 0.884
[50,     3] loss: 0.949
[51,     3] loss: 0.929
[52,     3] loss: 0.866
[53,     3] loss: 0.837
[54,     3] loss: 0.852
[55,     3] loss: 0.873
[56,     3] loss: 0.836
[57,     3] loss: 0.869
[58,     3] loss: 0.892
[59,     3] loss: 0.802
[60,     3] loss: 0.784
[61,     3] loss: 0.805
[62,     3] loss: 0.792
[63,     3] loss: 0.870
[64,     3] loss: 0.794
[65,     3] loss: 0.775
[66,     3] loss: 0.781
[67,     3] loss: 0.790
[68,     3] loss: 0.819
[69,     3] loss: 0.773
[70,     3] loss: 0.766
[71,     3] loss: 0.758
[72,     3] loss: 0.786
[73,     3] loss: 0.756
[74,     3] loss: 0.797
[75,     3] loss: 0.758
Early stopping applied (best metric=0.5184099674224854)
Finished Training
Total time taken: 16.700061321258545
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.383
[3,     3] loss: 1.378
[4,     3] loss: 1.384
[5,     3] loss: 1.377
[6,     3] loss: 1.377
[7,     3] loss: 1.361
[8,     3] loss: 1.358
[9,     3] loss: 1.326
[10,     3] loss: 1.309
[11,     3] loss: 1.307
[12,     3] loss: 1.291
[13,     3] loss: 1.246
[14,     3] loss: 1.216
[15,     3] loss: 1.136
[16,     3] loss: 1.234
[17,     3] loss: 1.125
[18,     3] loss: 1.102
[19,     3] loss: 1.050
[20,     3] loss: 1.054
[21,     3] loss: 0.955
[22,     3] loss: 1.030
[23,     3] loss: 1.058
[24,     3] loss: 1.024
[25,     3] loss: 1.010
[26,     3] loss: 1.045
[27,     3] loss: 0.939
[28,     3] loss: 0.927
[29,     3] loss: 1.052
[30,     3] loss: 1.021
[31,     3] loss: 1.024
[32,     3] loss: 0.956
[33,     3] loss: 0.964
[34,     3] loss: 0.945
[35,     3] loss: 0.943
[36,     3] loss: 0.925
[37,     3] loss: 0.952
[38,     3] loss: 0.922
[39,     3] loss: 0.984
[40,     3] loss: 0.926
[41,     3] loss: 0.871
[42,     3] loss: 0.887
[43,     3] loss: 0.851
[44,     3] loss: 0.845
[45,     3] loss: 0.870
[46,     3] loss: 0.830
[47,     3] loss: 0.809
[48,     3] loss: 0.821
[49,     3] loss: 0.808
[50,     3] loss: 0.804
[51,     3] loss: 0.812
[52,     3] loss: 0.769
[53,     3] loss: 0.790
[54,     3] loss: 0.792
[55,     3] loss: 0.768
[56,     3] loss: 0.785
[57,     3] loss: 0.801
[58,     3] loss: 0.796
[59,     3] loss: 0.821
[60,     3] loss: 0.772
[61,     3] loss: 0.821
[62,     3] loss: 0.843
[63,     3] loss: 0.778
[64,     3] loss: 0.821
[65,     3] loss: 0.870
[66,     3] loss: 0.811
[67,     3] loss: 0.838
[68,     3] loss: 0.829
[69,     3] loss: 0.845
[70,     3] loss: 0.832
[71,     3] loss: 0.872
Early stopping applied (best metric=0.5185572504997253)
Finished Training
Total time taken: 15.753058910369873
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.386
[3,     3] loss: 1.396
[4,     3] loss: 1.384
[5,     3] loss: 1.384
[6,     3] loss: 1.385
[7,     3] loss: 1.383
[8,     3] loss: 1.379
[9,     3] loss: 1.377
[10,     3] loss: 1.375
[11,     3] loss: 1.366
[12,     3] loss: 1.353
[13,     3] loss: 1.321
[14,     3] loss: 1.305
[15,     3] loss: 1.314
[16,     3] loss: 1.292
[17,     3] loss: 1.264
[18,     3] loss: 1.206
[19,     3] loss: 1.263
[20,     3] loss: 1.294
[21,     3] loss: 1.284
[22,     3] loss: 1.156
[23,     3] loss: 1.207
[24,     3] loss: 1.232
[25,     3] loss: 1.171
[26,     3] loss: 1.109
[27,     3] loss: 1.122
[28,     3] loss: 1.127
[29,     3] loss: 1.119
[30,     3] loss: 1.136
[31,     3] loss: 1.060
[32,     3] loss: 1.103
[33,     3] loss: 0.995
[34,     3] loss: 0.999
[35,     3] loss: 1.057
[36,     3] loss: 0.918
[37,     3] loss: 0.952
[38,     3] loss: 1.005
[39,     3] loss: 0.883
[40,     3] loss: 0.925
[41,     3] loss: 1.070
[42,     3] loss: 1.006
[43,     3] loss: 0.948
[44,     3] loss: 0.967
[45,     3] loss: 0.937
[46,     3] loss: 1.022
[47,     3] loss: 0.977
[48,     3] loss: 0.945
[49,     3] loss: 0.965
[50,     3] loss: 0.886
[51,     3] loss: 0.931
[52,     3] loss: 0.862
[53,     3] loss: 0.858
[54,     3] loss: 0.857
[55,     3] loss: 0.853
[56,     3] loss: 0.837
[57,     3] loss: 0.834
[58,     3] loss: 0.843
[59,     3] loss: 0.846
[60,     3] loss: 0.872
[61,     3] loss: 0.821
[62,     3] loss: 0.814
[63,     3] loss: 0.847
[64,     3] loss: 0.810
[65,     3] loss: 0.821
[66,     3] loss: 0.838
Early stopping applied (best metric=0.4618355333805084)
Finished Training
Total time taken: 14.676407098770142
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.383
[3,     3] loss: 1.387
[4,     3] loss: 1.384
[5,     3] loss: 1.379
[6,     3] loss: 1.375
[7,     3] loss: 1.372
[8,     3] loss: 1.358
[9,     3] loss: 1.352
[10,     3] loss: 1.332
[11,     3] loss: 1.316
[12,     3] loss: 1.266
[13,     3] loss: 1.257
[14,     3] loss: 1.221
[15,     3] loss: 1.205
[16,     3] loss: 1.221
[17,     3] loss: 1.120
[18,     3] loss: 1.124
[19,     3] loss: 1.079
[20,     3] loss: 1.112
[21,     3] loss: 1.034
[22,     3] loss: 1.066
[23,     3] loss: 1.063
[24,     3] loss: 1.112
[25,     3] loss: 1.055
[26,     3] loss: 1.110
[27,     3] loss: 1.049
[28,     3] loss: 1.040
[29,     3] loss: 1.021
[30,     3] loss: 0.933
[31,     3] loss: 1.002
[32,     3] loss: 0.963
[33,     3] loss: 0.957
[34,     3] loss: 1.031
[35,     3] loss: 0.926
[36,     3] loss: 0.915
[37,     3] loss: 0.906
[38,     3] loss: 0.882
[39,     3] loss: 0.861
[40,     3] loss: 0.971
[41,     3] loss: 0.871
[42,     3] loss: 1.043
[43,     3] loss: 0.925
[44,     3] loss: 0.891
[45,     3] loss: 0.887
[46,     3] loss: 0.938
[47,     3] loss: 0.917
[48,     3] loss: 0.962
[49,     3] loss: 0.891
[50,     3] loss: 0.926
[51,     3] loss: 0.965
[52,     3] loss: 1.037
[53,     3] loss: 0.894
[54,     3] loss: 0.997
[55,     3] loss: 0.871
[56,     3] loss: 0.886
[57,     3] loss: 0.864
[58,     3] loss: 0.851
[59,     3] loss: 0.889
[60,     3] loss: 0.846
[61,     3] loss: 0.833
[62,     3] loss: 0.808
[63,     3] loss: 0.790
[64,     3] loss: 0.793
[65,     3] loss: 0.805
[66,     3] loss: 0.804
[67,     3] loss: 0.828
[68,     3] loss: 0.834
Early stopping applied (best metric=0.5223905444145203)
Finished Training
Total time taken: 15.157668113708496
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.392
[3,     3] loss: 1.377
[4,     3] loss: 1.393
[5,     3] loss: 1.387
[6,     3] loss: 1.379
[7,     3] loss: 1.382
[8,     3] loss: 1.376
[9,     3] loss: 1.380
[10,     3] loss: 1.375
[11,     3] loss: 1.379
[12,     3] loss: 1.374
[13,     3] loss: 1.364
[14,     3] loss: 1.356
[15,     3] loss: 1.335
[16,     3] loss: 1.318
[17,     3] loss: 1.253
[18,     3] loss: 1.269
[19,     3] loss: 1.198
[20,     3] loss: 1.238
[21,     3] loss: 1.258
[22,     3] loss: 1.139
[23,     3] loss: 1.154
[24,     3] loss: 1.118
[25,     3] loss: 1.069
[26,     3] loss: 1.130
[27,     3] loss: 1.088
[28,     3] loss: 0.994
[29,     3] loss: 1.035
[30,     3] loss: 1.051
[31,     3] loss: 0.977
[32,     3] loss: 0.972
[33,     3] loss: 1.019
[34,     3] loss: 0.967
[35,     3] loss: 0.942
[36,     3] loss: 0.996
[37,     3] loss: 1.038
[38,     3] loss: 1.039
[39,     3] loss: 0.937
[40,     3] loss: 0.919
[41,     3] loss: 0.896
[42,     3] loss: 0.894
[43,     3] loss: 0.929
[44,     3] loss: 0.892
[45,     3] loss: 0.987
[46,     3] loss: 1.033
[47,     3] loss: 0.917
[48,     3] loss: 0.993
[49,     3] loss: 0.937
[50,     3] loss: 0.956
[51,     3] loss: 1.057
[52,     3] loss: 0.963
[53,     3] loss: 0.964
[54,     3] loss: 0.908
[55,     3] loss: 0.915
[56,     3] loss: 0.873
[57,     3] loss: 0.861
[58,     3] loss: 0.894
[59,     3] loss: 0.889
[60,     3] loss: 0.895
[61,     3] loss: 0.854
[62,     3] loss: 0.884
[63,     3] loss: 0.907
[64,     3] loss: 0.845
[65,     3] loss: 0.860
[66,     3] loss: 0.861
[67,     3] loss: 0.822
[68,     3] loss: 0.830
[69,     3] loss: 0.888
[70,     3] loss: 0.811
[71,     3] loss: 0.874
[72,     3] loss: 0.795
[73,     3] loss: 0.790
[74,     3] loss: 0.856
[75,     3] loss: 0.795
[76,     3] loss: 0.755
[77,     3] loss: 0.791
[78,     3] loss: 0.758
[79,     3] loss: 0.802
[80,     3] loss: 0.776
[81,     3] loss: 0.815
[82,     3] loss: 0.817
Early stopping applied (best metric=0.5045367479324341)
Finished Training
Total time taken: 18.365068674087524
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.390
[3,     3] loss: 1.383
[4,     3] loss: 1.379
[5,     3] loss: 1.384
[6,     3] loss: 1.378
[7,     3] loss: 1.370
[8,     3] loss: 1.367
[9,     3] loss: 1.357
[10,     3] loss: 1.345
[11,     3] loss: 1.332
[12,     3] loss: 1.313
[13,     3] loss: 1.287
[14,     3] loss: 1.243
[15,     3] loss: 1.209
[16,     3] loss: 1.231
[17,     3] loss: 1.151
[18,     3] loss: 1.101
[19,     3] loss: 1.131
[20,     3] loss: 1.091
[21,     3] loss: 1.016
[22,     3] loss: 0.966
[23,     3] loss: 1.025
[24,     3] loss: 0.986
[25,     3] loss: 1.042
[26,     3] loss: 1.022
[27,     3] loss: 1.055
[28,     3] loss: 1.106
[29,     3] loss: 1.101
[30,     3] loss: 1.068
[31,     3] loss: 1.067
[32,     3] loss: 1.141
[33,     3] loss: 0.980
[34,     3] loss: 1.070
[35,     3] loss: 0.999
[36,     3] loss: 1.130
[37,     3] loss: 0.937
[38,     3] loss: 1.028
[39,     3] loss: 0.922
[40,     3] loss: 0.953
[41,     3] loss: 1.006
[42,     3] loss: 0.905
[43,     3] loss: 0.883
[44,     3] loss: 0.841
[45,     3] loss: 0.952
[46,     3] loss: 0.846
[47,     3] loss: 0.804
[48,     3] loss: 0.795
[49,     3] loss: 0.811
[50,     3] loss: 0.836
[51,     3] loss: 0.936
[52,     3] loss: 0.935
[53,     3] loss: 0.925
[54,     3] loss: 0.884
[55,     3] loss: 0.839
[56,     3] loss: 0.948
[57,     3] loss: 0.888
[58,     3] loss: 0.913
[59,     3] loss: 0.968
[60,     3] loss: 0.859
[61,     3] loss: 0.877
[62,     3] loss: 0.925
[63,     3] loss: 0.826
[64,     3] loss: 0.831
[65,     3] loss: 0.841
[66,     3] loss: 0.822
[67,     3] loss: 0.807
[68,     3] loss: 0.789
[69,     3] loss: 0.781
[70,     3] loss: 0.763
[71,     3] loss: 0.770
[72,     3] loss: 0.808
[73,     3] loss: 0.791
Early stopping applied (best metric=0.5269371271133423)
Finished Training
Total time taken: 16.161337852478027
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.389
[3,     3] loss: 1.387
[4,     3] loss: 1.379
[5,     3] loss: 1.386
[6,     3] loss: 1.381
[7,     3] loss: 1.379
[8,     3] loss: 1.380
[9,     3] loss: 1.371
[10,     3] loss: 1.360
[11,     3] loss: 1.341
[12,     3] loss: 1.330
[13,     3] loss: 1.343
[14,     3] loss: 1.280
[15,     3] loss: 1.288
[16,     3] loss: 1.230
[17,     3] loss: 1.197
[18,     3] loss: 1.187
[19,     3] loss: 1.220
[20,     3] loss: 1.127
[21,     3] loss: 1.142
[22,     3] loss: 1.098
[23,     3] loss: 1.095
[24,     3] loss: 1.071
[25,     3] loss: 1.034
[26,     3] loss: 1.063
[27,     3] loss: 1.101
[28,     3] loss: 1.010
[29,     3] loss: 1.065
[30,     3] loss: 1.038
[31,     3] loss: 0.968
[32,     3] loss: 0.955
[33,     3] loss: 0.952
[34,     3] loss: 0.888
[35,     3] loss: 0.896
[36,     3] loss: 0.940
[37,     3] loss: 0.951
[38,     3] loss: 0.931
[39,     3] loss: 0.951
[40,     3] loss: 1.037
[41,     3] loss: 1.141
[42,     3] loss: 0.983
[43,     3] loss: 1.122
[44,     3] loss: 1.022
[45,     3] loss: 0.933
[46,     3] loss: 0.935
[47,     3] loss: 0.916
[48,     3] loss: 0.955
[49,     3] loss: 0.914
[50,     3] loss: 0.919
[51,     3] loss: 0.909
[52,     3] loss: 0.933
[53,     3] loss: 0.856
[54,     3] loss: 0.869
[55,     3] loss: 0.815
[56,     3] loss: 0.832
[57,     3] loss: 0.862
[58,     3] loss: 0.887
[59,     3] loss: 0.838
[60,     3] loss: 0.925
[61,     3] loss: 0.871
[62,     3] loss: 0.823
[63,     3] loss: 0.811
[64,     3] loss: 0.863
[65,     3] loss: 0.819
[66,     3] loss: 0.848
[67,     3] loss: 0.862
[68,     3] loss: 0.920
[69,     3] loss: 0.884
[70,     3] loss: 0.969
[71,     3] loss: 0.961
[72,     3] loss: 0.849
Early stopping applied (best metric=0.513943612575531)
Finished Training
Total time taken: 16.057056665420532
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.379
[3,     3] loss: 1.391
[4,     3] loss: 1.384
[5,     3] loss: 1.387
[6,     3] loss: 1.382
[7,     3] loss: 1.387
[8,     3] loss: 1.384
[9,     3] loss: 1.384
[10,     3] loss: 1.381
[11,     3] loss: 1.368
[12,     3] loss: 1.363
[13,     3] loss: 1.345
[14,     3] loss: 1.337
[15,     3] loss: 1.306
[16,     3] loss: 1.310
[17,     3] loss: 1.276
[18,     3] loss: 1.273
[19,     3] loss: 1.186
[20,     3] loss: 1.159
[21,     3] loss: 1.139
[22,     3] loss: 1.118
[23,     3] loss: 1.040
[24,     3] loss: 1.009
[25,     3] loss: 1.054
[26,     3] loss: 1.020
[27,     3] loss: 0.991
[28,     3] loss: 0.981
[29,     3] loss: 0.976
[30,     3] loss: 0.979
[31,     3] loss: 0.931
[32,     3] loss: 0.923
[33,     3] loss: 0.970
[34,     3] loss: 0.991
[35,     3] loss: 1.046
[36,     3] loss: 0.993
[37,     3] loss: 1.143
[38,     3] loss: 1.046
[39,     3] loss: 0.955
[40,     3] loss: 1.051
[41,     3] loss: 0.979
[42,     3] loss: 0.945
[43,     3] loss: 1.105
[44,     3] loss: 0.944
[45,     3] loss: 0.980
[46,     3] loss: 0.917
[47,     3] loss: 0.958
[48,     3] loss: 0.941
[49,     3] loss: 0.930
[50,     3] loss: 0.882
[51,     3] loss: 0.910
[52,     3] loss: 0.830
[53,     3] loss: 0.847
[54,     3] loss: 0.824
[55,     3] loss: 0.952
[56,     3] loss: 0.791
[57,     3] loss: 0.786
[58,     3] loss: 0.797
[59,     3] loss: 0.793
[60,     3] loss: 0.811
[61,     3] loss: 0.826
[62,     3] loss: 0.827
[63,     3] loss: 0.779
[64,     3] loss: 0.799
[65,     3] loss: 0.773
[66,     3] loss: 0.787
[67,     3] loss: 0.772
[68,     3] loss: 0.772
[69,     3] loss: 0.755
[70,     3] loss: 0.768
[71,     3] loss: 0.756
[72,     3] loss: 0.777
[73,     3] loss: 0.775
[74,     3] loss: 0.798
[75,     3] loss: 0.806
[76,     3] loss: 0.861
[77,     3] loss: 0.790
[78,     3] loss: 0.824
[79,     3] loss: 0.778
[80,     3] loss: 0.778
[81,     3] loss: 0.802
[82,     3] loss: 0.812
[83,     3] loss: 0.799
[84,     3] loss: 0.999
Early stopping applied (best metric=0.5012560486793518)
Finished Training
Total time taken: 18.667075872421265
{'S-palmitoylation-C Validation Accuracy': 0.7186085433247005, 'S-palmitoylation-C Validation Sensitivity': 0.1782178217821782, 'S-palmitoylation-C Validation Specificity': 0.8540709327511391, 'S-palmitoylation-C Validation Precision': 0.23663394814876185, 'S-palmitoylation-C AUC ROC': 0.5457047436487447, 'S-palmitoylation-C AUC PR': 0.22580818349397802, 'S-palmitoylation-C MCC': 0.03644628281745114, 'S-palmitoylation-C F1': 0.1871506471383124, 'Validation Loss (S-palmitoylation-C)': 0.5550269325574239, 'Hydroxylation-K Validation Accuracy': 0.7466903073286052, 'Hydroxylation-K Validation Sensitivity': 0.7837037037037037, 'Hydroxylation-K Validation Specificity': 0.7368421052631579, 'Hydroxylation-K Validation Precision': 0.44526834515482605, 'Hydroxylation-K AUC ROC': 0.8422027290448343, 'Hydroxylation-K AUC PR': 0.6435620741438828, 'Hydroxylation-K MCC': 0.4424329226839584, 'Hydroxylation-K F1': 0.5625292243493143, 'Validation Loss (Hydroxylation-K)': 0.5037650644779206, 'Validation Loss (total)': 1.058791987101237, 'TimeToTrain': 16.415429433186848}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005870353802212805,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8593530236244867,
 'loss_weight_S-palmitoylation-C': 0.001460313355273954,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 716041122,
 'sample_weights': [0.3875465219823181, 0.8144427637293367],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.527937853455787,
 'weight_decay_Hydroxylation-K': 4.873619676027357,
 'weight_decay_S-palmitoylation-C': 6.547492987089983}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.382
[3,     3] loss: 1.388
[4,     3] loss: 1.387
[5,     3] loss: 1.397
[6,     3] loss: 1.376
[7,     3] loss: 1.389
[8,     3] loss: 1.384
[9,     3] loss: 1.376
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024477791283237967,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.0887904527998079,
 'loss_weight_S-palmitoylation-C': 0.0871151952650415,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3615494550,
 'sample_weights': [0.001460313355273954, 0.8593530236244867],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.930243249399833,
 'weight_decay_Hydroxylation-K': 4.220756273650352,
 'weight_decay_S-palmitoylation-C': 3.882511130925461}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.388
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003538395866401836,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4976368990962974,
 'loss_weight_S-palmitoylation-C': 0.045602131163750004,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1086934657,
 'sample_weights': [0.0871151952650415, 0.0887904527998079],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.604434056410871,
 'weight_decay_Hydroxylation-K': 4.382720939073515,
 'weight_decay_S-palmitoylation-C': 9.972900438214323}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.384
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006611787926955421,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7249588966097701,
 'loss_weight_S-palmitoylation-C': 0.822272368779985,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3474864855,
 'sample_weights': [0.045602131163750004, 0.4976368990962974],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5909721763636009,
 'weight_decay_Hydroxylation-K': 6.56932971846425,
 'weight_decay_S-palmitoylation-C': 0.4383495301060736}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.396
[3,     3] loss: 1.389
[4,     3] loss: 1.379
[5,     3] loss: 1.385
[6,     3] loss: 1.386
[7,     3] loss: 1.382
[8,     3] loss: 1.385
[9,     3] loss: 1.396
[10,     3] loss: 1.375
[11,     3] loss: 1.381
[12,     3] loss: 1.393
[13,     3] loss: 1.388
[14,     3] loss: 1.389
[15,     3] loss: 1.386
[16,     3] loss: 1.389
[17,     3] loss: 1.383
[18,     3] loss: 1.382
[19,     3] loss: 1.382
[20,     3] loss: 1.373
[21,     3] loss: 1.372
[22,     3] loss: 1.372
[23,     3] loss: 1.362
[24,     3] loss: 1.343
[25,     3] loss: 1.338
[26,     3] loss: 1.295
[27,     3] loss: 1.299
[28,     3] loss: 1.286
[29,     3] loss: 1.261
[30,     3] loss: 1.254
[31,     3] loss: 1.202
[32,     3] loss: 1.247
[33,     3] loss: 1.156
[34,     3] loss: 1.113
[35,     3] loss: 1.071
[36,     3] loss: 1.082
[37,     3] loss: 1.100
[38,     3] loss: 1.110
[39,     3] loss: 0.984
[40,     3] loss: 0.952
[41,     3] loss: 0.979
[42,     3] loss: 0.896
[43,     3] loss: 0.922
[44,     3] loss: 0.884
[45,     3] loss: 0.898
[46,     3] loss: 0.934
[47,     3] loss: 0.881
[48,     3] loss: 0.865
[49,     3] loss: 0.883
[50,     3] loss: 1.016
[51,     3] loss: 0.975
[52,     3] loss: 0.905
[53,     3] loss: 0.803
[54,     3] loss: 0.842
[55,     3] loss: 0.842
[56,     3] loss: 0.815
[57,     3] loss: 0.941
[58,     3] loss: 0.836
[59,     3] loss: 0.875
[60,     3] loss: 0.817
[61,     3] loss: 0.835
[62,     3] loss: 0.823
[63,     3] loss: 0.838
[64,     3] loss: 0.813
[65,     3] loss: 0.830
[66,     3] loss: 0.839
[67,     3] loss: 0.832
[68,     3] loss: 0.828
[69,     3] loss: 0.808
[70,     3] loss: 0.838
[71,     3] loss: 0.866
[72,     3] loss: 0.778
[73,     3] loss: 0.972
[74,     3] loss: 0.836
[75,     3] loss: 0.882
[76,     3] loss: 0.962
[77,     3] loss: 0.899
[78,     3] loss: 0.813
[79,     3] loss: 0.850
[80,     3] loss: 0.800
[81,     3] loss: 0.866
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010106900374212652,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9894366810308314,
 'loss_weight_S-palmitoylation-C': 0.0683590961156606,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2944667098,
 'sample_weights': [0.822272368779985, 0.7249588966097701],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.199075484646487,
 'weight_decay_Hydroxylation-K': 2.942783160543926,
 'weight_decay_S-palmitoylation-C': 5.28235259738823}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.382
[3,     3] loss: 1.393
[4,     3] loss: 1.391
[5,     3] loss: 1.382
[6,     3] loss: 1.380
[7,     3] loss: 1.383
[8,     3] loss: 1.365
[9,     3] loss: 1.352
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007432990381508755,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4917381864924909,
 'loss_weight_S-palmitoylation-C': 0.2535554323341328,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2863888401,
 'sample_weights': [0.0683590961156606, 0.9894366810308314],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.253740903008807,
 'weight_decay_Hydroxylation-K': 1.675966134329336,
 'weight_decay_S-palmitoylation-C': 9.731023928774835}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.384
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002327341276669755,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.709837995553732,
 'loss_weight_S-palmitoylation-C': 0.7402592224082444,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3571184964,
 'sample_weights': [0.2535554323341328, 0.4917381864924909],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2473604782462773,
 'weight_decay_Hydroxylation-K': 9.897151987243301,
 'weight_decay_S-palmitoylation-C': 0.15587501704681594}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.382
[3,     3] loss: 1.381
[4,     3] loss: 1.390
[5,     3] loss: 1.386
[6,     3] loss: 1.381
[7,     3] loss: 1.384
[8,     3] loss: 1.385
[9,     3] loss: 1.378
[10,     3] loss: 1.379
[11,     3] loss: 1.382
[12,     3] loss: 1.373
[13,     3] loss: 1.374
[14,     3] loss: 1.346
[15,     3] loss: 1.355
[16,     3] loss: 1.328
[17,     3] loss: 1.286
[18,     3] loss: 1.286
[19,     3] loss: 1.222
[20,     3] loss: 1.144
[21,     3] loss: 1.114
[22,     3] loss: 1.081
[23,     3] loss: 1.166
[24,     3] loss: 1.291
[25,     3] loss: 1.092
[26,     3] loss: 1.095
[27,     3] loss: 1.155
[28,     3] loss: 1.106
[29,     3] loss: 1.077
[30,     3] loss: 1.074
[31,     3] loss: 1.083
[32,     3] loss: 1.016
[33,     3] loss: 0.935
[34,     3] loss: 0.945
[35,     3] loss: 0.983
[36,     3] loss: 0.931
[37,     3] loss: 0.993
[38,     3] loss: 1.017
[39,     3] loss: 0.914
[40,     3] loss: 0.929
[41,     3] loss: 0.944
[42,     3] loss: 1.011
[43,     3] loss: 0.890
[44,     3] loss: 0.939
[45,     3] loss: 0.863
[46,     3] loss: 0.856
[47,     3] loss: 0.864
[48,     3] loss: 0.851
[49,     3] loss: 0.907
[50,     3] loss: 0.979
[51,     3] loss: 0.868
[52,     3] loss: 0.872
[53,     3] loss: 0.842
[54,     3] loss: 0.935
[55,     3] loss: 0.860
[56,     3] loss: 0.855
[57,     3] loss: 0.812
[58,     3] loss: 0.803
[59,     3] loss: 0.828
[60,     3] loss: 0.786
[61,     3] loss: 0.814
[62,     3] loss: 0.829
[63,     3] loss: 0.829
[64,     3] loss: 0.762
[65,     3] loss: 0.785
[66,     3] loss: 0.805
[67,     3] loss: 0.823
[68,     3] loss: 0.824
[69,     3] loss: 0.843
Early stopping applied (best metric=0.5141657590866089)
Finished Training
Total time taken: 15.37206768989563
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.389
[3,     3] loss: 1.383
[4,     3] loss: 1.384
[5,     3] loss: 1.388
[6,     3] loss: 1.386
[7,     3] loss: 1.391
[8,     3] loss: 1.380
[9,     3] loss: 1.382
[10,     3] loss: 1.399
[11,     3] loss: 1.385
[12,     3] loss: 1.382
[13,     3] loss: 1.384
[14,     3] loss: 1.382
[15,     3] loss: 1.377
[16,     3] loss: 1.380
[17,     3] loss: 1.372
[18,     3] loss: 1.363
[19,     3] loss: 1.357
[20,     3] loss: 1.352
[21,     3] loss: 1.352
[22,     3] loss: 1.272
[23,     3] loss: 1.248
[24,     3] loss: 1.224
[25,     3] loss: 1.165
[26,     3] loss: 1.083
[27,     3] loss: 1.122
[28,     3] loss: 1.067
[29,     3] loss: 0.970
[30,     3] loss: 1.012
[31,     3] loss: 1.049
[32,     3] loss: 1.021
[33,     3] loss: 0.995
[34,     3] loss: 0.981
[35,     3] loss: 1.012
[36,     3] loss: 0.998
[37,     3] loss: 1.025
[38,     3] loss: 1.084
[39,     3] loss: 1.021
[40,     3] loss: 1.083
[41,     3] loss: 1.090
[42,     3] loss: 1.068
[43,     3] loss: 0.990
[44,     3] loss: 0.984
[45,     3] loss: 0.983
[46,     3] loss: 0.951
[47,     3] loss: 0.945
[48,     3] loss: 0.909
[49,     3] loss: 0.928
[50,     3] loss: 0.913
[51,     3] loss: 0.840
[52,     3] loss: 0.971
[53,     3] loss: 0.998
[54,     3] loss: 0.914
[55,     3] loss: 0.918
[56,     3] loss: 0.895
[57,     3] loss: 0.889
[58,     3] loss: 0.847
[59,     3] loss: 0.919
[60,     3] loss: 0.841
[61,     3] loss: 0.796
[62,     3] loss: 0.863
[63,     3] loss: 0.813
[64,     3] loss: 0.786
[65,     3] loss: 0.821
[66,     3] loss: 0.786
[67,     3] loss: 0.816
[68,     3] loss: 0.782
[69,     3] loss: 0.798
[70,     3] loss: 0.831
[71,     3] loss: 0.824
[72,     3] loss: 0.795
[73,     3] loss: 0.800
[74,     3] loss: 0.777
[75,     3] loss: 0.779
[76,     3] loss: 0.791
[77,     3] loss: 0.788
[78,     3] loss: 0.765
[79,     3] loss: 0.753
[80,     3] loss: 0.793
[81,     3] loss: 0.784
[82,     3] loss: 0.768
[83,     3] loss: 0.932
[84,     3] loss: 0.810
[85,     3] loss: 0.804
[86,     3] loss: 0.835
[87,     3] loss: 0.796
[88,     3] loss: 0.823
[89,     3] loss: 0.805
[90,     3] loss: 0.839
[91,     3] loss: 0.806
[92,     3] loss: 0.785
Early stopping applied (best metric=0.49437928199768066)
Finished Training
Total time taken: 20.56007671356201
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.380
[3,     3] loss: 1.397
[4,     3] loss: 1.394
[5,     3] loss: 1.384
[6,     3] loss: 1.385
[7,     3] loss: 1.389
[8,     3] loss: 1.383
[9,     3] loss: 1.385
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.380
[13,     3] loss: 1.380
[14,     3] loss: 1.380
[15,     3] loss: 1.376
[16,     3] loss: 1.370
[17,     3] loss: 1.344
[18,     3] loss: 1.316
[19,     3] loss: 1.306
[20,     3] loss: 1.306
[21,     3] loss: 1.166
[22,     3] loss: 1.114
[23,     3] loss: 1.120
[24,     3] loss: 1.227
[25,     3] loss: 1.221
[26,     3] loss: 1.214
[27,     3] loss: 1.103
[28,     3] loss: 1.067
[29,     3] loss: 1.070
[30,     3] loss: 1.054
[31,     3] loss: 1.118
[32,     3] loss: 0.987
[33,     3] loss: 0.968
[34,     3] loss: 1.129
[35,     3] loss: 0.980
[36,     3] loss: 1.000
[37,     3] loss: 0.906
[38,     3] loss: 0.946
[39,     3] loss: 0.862
[40,     3] loss: 0.919
[41,     3] loss: 0.898
[42,     3] loss: 0.926
[43,     3] loss: 0.885
[44,     3] loss: 0.860
[45,     3] loss: 0.845
[46,     3] loss: 0.847
[47,     3] loss: 0.813
[48,     3] loss: 0.852
[49,     3] loss: 0.852
[50,     3] loss: 0.785
[51,     3] loss: 0.817
[52,     3] loss: 0.923
[53,     3] loss: 0.806
[54,     3] loss: 0.801
[55,     3] loss: 0.778
[56,     3] loss: 0.785
[57,     3] loss: 0.785
[58,     3] loss: 0.753
[59,     3] loss: 0.783
[60,     3] loss: 0.806
[61,     3] loss: 0.760
[62,     3] loss: 0.771
[63,     3] loss: 0.772
[64,     3] loss: 0.758
[65,     3] loss: 0.753
[66,     3] loss: 0.769
[67,     3] loss: 0.769
[68,     3] loss: 0.796
[69,     3] loss: 0.807
Early stopping applied (best metric=0.5179039239883423)
Finished Training
Total time taken: 15.332047700881958
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.388
[3,     3] loss: 1.387
[4,     3] loss: 1.397
[5,     3] loss: 1.384
[6,     3] loss: 1.386
[7,     3] loss: 1.384
[8,     3] loss: 1.388
[9,     3] loss: 1.389
[10,     3] loss: 1.390
[11,     3] loss: 1.387
[12,     3] loss: 1.385
[13,     3] loss: 1.383
[14,     3] loss: 1.384
[15,     3] loss: 1.385
[16,     3] loss: 1.379
[17,     3] loss: 1.384
[18,     3] loss: 1.379
[19,     3] loss: 1.372
[20,     3] loss: 1.374
[21,     3] loss: 1.372
[22,     3] loss: 1.349
[23,     3] loss: 1.313
[24,     3] loss: 1.248
[25,     3] loss: 1.229
[26,     3] loss: 1.226
[27,     3] loss: 1.085
[28,     3] loss: 1.065
[29,     3] loss: 1.035
[30,     3] loss: 1.001
[31,     3] loss: 1.116
[32,     3] loss: 1.139
[33,     3] loss: 1.110
[34,     3] loss: 1.033
[35,     3] loss: 0.955
[36,     3] loss: 0.969
[37,     3] loss: 1.013
[38,     3] loss: 0.984
[39,     3] loss: 1.004
[40,     3] loss: 0.980
[41,     3] loss: 0.956
[42,     3] loss: 0.951
[43,     3] loss: 0.976
[44,     3] loss: 0.951
[45,     3] loss: 1.121
[46,     3] loss: 1.069
[47,     3] loss: 1.176
[48,     3] loss: 1.028
[49,     3] loss: 1.025
[50,     3] loss: 1.028
[51,     3] loss: 0.979
[52,     3] loss: 0.955
[53,     3] loss: 0.916
[54,     3] loss: 0.955
[55,     3] loss: 0.898
[56,     3] loss: 1.000
[57,     3] loss: 0.893
[58,     3] loss: 0.877
[59,     3] loss: 0.914
[60,     3] loss: 0.865
[61,     3] loss: 0.857
[62,     3] loss: 0.872
[63,     3] loss: 0.861
[64,     3] loss: 0.925
[65,     3] loss: 0.906
[66,     3] loss: 0.853
[67,     3] loss: 0.898
[68,     3] loss: 0.842
[69,     3] loss: 0.807
[70,     3] loss: 0.881
[71,     3] loss: 0.801
[72,     3] loss: 0.803
[73,     3] loss: 0.800
[74,     3] loss: 0.837
[75,     3] loss: 0.835
[76,     3] loss: 0.922
[77,     3] loss: 0.821
[78,     3] loss: 0.830
[79,     3] loss: 0.874
[80,     3] loss: 0.836
[81,     3] loss: 0.816
[82,     3] loss: 0.803
[83,     3] loss: 0.780
[84,     3] loss: 0.789
[85,     3] loss: 0.773
[86,     3] loss: 0.844
[87,     3] loss: 0.828
[88,     3] loss: 0.826
[89,     3] loss: 0.778
[90,     3] loss: 0.819
[91,     3] loss: 0.796
[92,     3] loss: 0.837
[93,     3] loss: 0.786
[94,     3] loss: 0.777
[95,     3] loss: 0.781
[96,     3] loss: 0.813
[97,     3] loss: 0.775
[98,     3] loss: 0.819
[99,     3] loss: 0.772
[100,     3] loss: 0.788
[101,     3] loss: 0.792
[102,     3] loss: 0.803
[103,     3] loss: 0.814
[104,     3] loss: 0.798
[105,     3] loss: 0.757
[106,     3] loss: 0.830
[107,     3] loss: 0.812
[108,     3] loss: 0.833
[109,     3] loss: 0.777
[110,     3] loss: 0.804
[111,     3] loss: 0.813
[112,     3] loss: 0.802
[113,     3] loss: 0.773
[114,     3] loss: 0.803
[115,     3] loss: 0.762
Early stopping applied (best metric=0.5072348713874817)
Finished Training
Total time taken: 25.598102569580078
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.391
[3,     3] loss: 1.392
[4,     3] loss: 1.380
[5,     3] loss: 1.382
[6,     3] loss: 1.390
[7,     3] loss: 1.381
[8,     3] loss: 1.378
[9,     3] loss: 1.378
[10,     3] loss: 1.368
[11,     3] loss: 1.364
[12,     3] loss: 1.345
[13,     3] loss: 1.319
[14,     3] loss: 1.271
[15,     3] loss: 1.236
[16,     3] loss: 1.226
[17,     3] loss: 1.135
[18,     3] loss: 1.225
[19,     3] loss: 1.151
[20,     3] loss: 1.129
[21,     3] loss: 1.086
[22,     3] loss: 1.096
[23,     3] loss: 1.058
[24,     3] loss: 1.088
[25,     3] loss: 1.002
[26,     3] loss: 1.004
[27,     3] loss: 0.942
[28,     3] loss: 0.929
[29,     3] loss: 0.910
[30,     3] loss: 0.909
[31,     3] loss: 0.931
[32,     3] loss: 0.926
[33,     3] loss: 0.957
[34,     3] loss: 1.010
[35,     3] loss: 0.960
[36,     3] loss: 0.957
[37,     3] loss: 0.937
[38,     3] loss: 0.924
[39,     3] loss: 0.852
[40,     3] loss: 0.873
[41,     3] loss: 0.838
[42,     3] loss: 0.909
[43,     3] loss: 0.833
[44,     3] loss: 0.808
[45,     3] loss: 0.815
[46,     3] loss: 0.854
[47,     3] loss: 0.791
[48,     3] loss: 0.863
[49,     3] loss: 0.830
[50,     3] loss: 0.847
[51,     3] loss: 0.845
[52,     3] loss: 0.912
[53,     3] loss: 0.994
[54,     3] loss: 0.944
[55,     3] loss: 0.915
[56,     3] loss: 0.875
[57,     3] loss: 0.922
[58,     3] loss: 0.887
[59,     3] loss: 0.993
[60,     3] loss: 0.900
[61,     3] loss: 0.828
[62,     3] loss: 0.828
[63,     3] loss: 0.843
[64,     3] loss: 0.850
[65,     3] loss: 0.802
Early stopping applied (best metric=0.5205758810043335)
Finished Training
Total time taken: 14.358045101165771
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.393
[3,     3] loss: 1.394
[4,     3] loss: 1.385
[5,     3] loss: 1.389
[6,     3] loss: 1.382
[7,     3] loss: 1.389
[8,     3] loss: 1.385
[9,     3] loss: 1.394
[10,     3] loss: 1.385
[11,     3] loss: 1.386
[12,     3] loss: 1.386
[13,     3] loss: 1.381
[14,     3] loss: 1.386
[15,     3] loss: 1.384
[16,     3] loss: 1.384
[17,     3] loss: 1.381
[18,     3] loss: 1.376
[19,     3] loss: 1.374
[20,     3] loss: 1.372
[21,     3] loss: 1.371
[22,     3] loss: 1.349
[23,     3] loss: 1.331
[24,     3] loss: 1.327
[25,     3] loss: 1.275
[26,     3] loss: 1.247
[27,     3] loss: 1.219
[28,     3] loss: 1.191
[29,     3] loss: 1.100
[30,     3] loss: 1.120
[31,     3] loss: 1.169
[32,     3] loss: 1.097
[33,     3] loss: 1.190
[34,     3] loss: 1.214
[35,     3] loss: 1.063
[36,     3] loss: 1.132
[37,     3] loss: 1.057
[38,     3] loss: 1.049
[39,     3] loss: 1.049
[40,     3] loss: 0.993
[41,     3] loss: 0.983
[42,     3] loss: 0.904
[43,     3] loss: 0.937
[44,     3] loss: 0.882
[45,     3] loss: 0.904
[46,     3] loss: 0.914
[47,     3] loss: 0.855
[48,     3] loss: 0.984
[49,     3] loss: 0.918
[50,     3] loss: 0.892
[51,     3] loss: 0.931
[52,     3] loss: 0.888
[53,     3] loss: 0.843
[54,     3] loss: 0.837
[55,     3] loss: 0.824
[56,     3] loss: 0.802
[57,     3] loss: 0.802
[58,     3] loss: 0.847
[59,     3] loss: 0.773
[60,     3] loss: 0.806
[61,     3] loss: 0.796
[62,     3] loss: 0.784
[63,     3] loss: 0.822
[64,     3] loss: 0.780
[65,     3] loss: 0.797
[66,     3] loss: 0.832
[67,     3] loss: 0.896
[68,     3] loss: 0.847
[69,     3] loss: 0.824
[70,     3] loss: 0.801
[71,     3] loss: 0.793
[72,     3] loss: 0.838
[73,     3] loss: 0.790
[74,     3] loss: 0.775
[75,     3] loss: 0.766
[76,     3] loss: 0.761
[77,     3] loss: 0.844
[78,     3] loss: 0.780
[79,     3] loss: 0.865
[80,     3] loss: 0.816
Early stopping applied (best metric=0.48003464937210083)
Finished Training
Total time taken: 17.818056106567383
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.395
[3,     3] loss: 1.391
[4,     3] loss: 1.392
[5,     3] loss: 1.386
[6,     3] loss: 1.386
[7,     3] loss: 1.383
[8,     3] loss: 1.385
[9,     3] loss: 1.384
[10,     3] loss: 1.384
[11,     3] loss: 1.386
[12,     3] loss: 1.384
[13,     3] loss: 1.384
[14,     3] loss: 1.384
[15,     3] loss: 1.382
[16,     3] loss: 1.384
[17,     3] loss: 1.381
[18,     3] loss: 1.374
[19,     3] loss: 1.372
[20,     3] loss: 1.366
[21,     3] loss: 1.328
[22,     3] loss: 1.334
[23,     3] loss: 1.320
[24,     3] loss: 1.247
[25,     3] loss: 1.221
[26,     3] loss: 1.213
[27,     3] loss: 1.244
[28,     3] loss: 1.126
[29,     3] loss: 1.149
[30,     3] loss: 1.079
[31,     3] loss: 1.004
[32,     3] loss: 1.091
[33,     3] loss: 1.051
[34,     3] loss: 1.116
[35,     3] loss: 1.002
[36,     3] loss: 0.961
[37,     3] loss: 0.962
[38,     3] loss: 1.081
[39,     3] loss: 0.907
[40,     3] loss: 0.971
[41,     3] loss: 0.907
[42,     3] loss: 0.914
[43,     3] loss: 0.941
[44,     3] loss: 0.945
[45,     3] loss: 0.879
[46,     3] loss: 0.876
[47,     3] loss: 0.897
[48,     3] loss: 0.883
[49,     3] loss: 0.867
[50,     3] loss: 0.881
[51,     3] loss: 0.829
[52,     3] loss: 0.831
[53,     3] loss: 0.804
[54,     3] loss: 0.994
[55,     3] loss: 0.811
[56,     3] loss: 0.894
[57,     3] loss: 0.830
[58,     3] loss: 0.896
[59,     3] loss: 0.917
[60,     3] loss: 0.910
[61,     3] loss: 0.855
[62,     3] loss: 0.822
[63,     3] loss: 0.801
[64,     3] loss: 0.802
[65,     3] loss: 0.841
[66,     3] loss: 0.823
[67,     3] loss: 0.770
[68,     3] loss: 0.811
[69,     3] loss: 0.792
[70,     3] loss: 0.769
[71,     3] loss: 0.810
[72,     3] loss: 0.886
[73,     3] loss: 0.929
[74,     3] loss: 0.911
[75,     3] loss: 0.839
[76,     3] loss: 0.887
[77,     3] loss: 0.822
[78,     3] loss: 0.813
[79,     3] loss: 0.777
[80,     3] loss: 0.776
Early stopping applied (best metric=0.5192979574203491)
Finished Training
Total time taken: 17.76104426383972
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.387
[3,     3] loss: 1.391
[4,     3] loss: 1.393
[5,     3] loss: 1.390
[6,     3] loss: 1.383
[7,     3] loss: 1.384
[8,     3] loss: 1.383
[9,     3] loss: 1.382
[10,     3] loss: 1.387
[11,     3] loss: 1.377
[12,     3] loss: 1.375
[13,     3] loss: 1.375
[14,     3] loss: 1.369
[15,     3] loss: 1.364
[16,     3] loss: 1.338
[17,     3] loss: 1.334
[18,     3] loss: 1.306
[19,     3] loss: 1.294
[20,     3] loss: 1.236
[21,     3] loss: 1.202
[22,     3] loss: 1.175
[23,     3] loss: 1.127
[24,     3] loss: 1.072
[25,     3] loss: 0.994
[26,     3] loss: 1.077
[27,     3] loss: 1.025
[28,     3] loss: 0.940
[29,     3] loss: 0.952
[30,     3] loss: 0.941
[31,     3] loss: 1.050
[32,     3] loss: 0.902
[33,     3] loss: 0.912
[34,     3] loss: 0.959
[35,     3] loss: 0.961
[36,     3] loss: 1.167
[37,     3] loss: 0.972
[38,     3] loss: 0.943
[39,     3] loss: 0.981
[40,     3] loss: 1.022
[41,     3] loss: 0.937
[42,     3] loss: 0.913
[43,     3] loss: 0.972
[44,     3] loss: 0.939
[45,     3] loss: 0.919
[46,     3] loss: 0.963
[47,     3] loss: 0.908
[48,     3] loss: 1.016
[49,     3] loss: 0.896
[50,     3] loss: 0.939
[51,     3] loss: 0.855
[52,     3] loss: 0.937
[53,     3] loss: 0.859
[54,     3] loss: 0.859
[55,     3] loss: 0.940
[56,     3] loss: 0.884
[57,     3] loss: 0.859
[58,     3] loss: 0.846
[59,     3] loss: 0.882
[60,     3] loss: 0.855
[61,     3] loss: 0.858
[62,     3] loss: 0.872
[63,     3] loss: 0.990
[64,     3] loss: 0.905
[65,     3] loss: 0.862
[66,     3] loss: 0.900
[67,     3] loss: 0.873
[68,     3] loss: 0.860
[69,     3] loss: 0.834
[70,     3] loss: 0.826
[71,     3] loss: 0.806
[72,     3] loss: 0.809
Early stopping applied (best metric=0.5341731905937195)
Finished Training
Total time taken: 15.954050064086914
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.382
[3,     3] loss: 1.382
[4,     3] loss: 1.385
[5,     3] loss: 1.392
[6,     3] loss: 1.389
[7,     3] loss: 1.382
[8,     3] loss: 1.378
[9,     3] loss: 1.382
[10,     3] loss: 1.374
[11,     3] loss: 1.374
[12,     3] loss: 1.366
[13,     3] loss: 1.344
[14,     3] loss: 1.337
[15,     3] loss: 1.328
[16,     3] loss: 1.271
[17,     3] loss: 1.295
[18,     3] loss: 1.247
[19,     3] loss: 1.289
[20,     3] loss: 1.156
[21,     3] loss: 1.150
[22,     3] loss: 1.135
[23,     3] loss: 1.098
[24,     3] loss: 1.111
[25,     3] loss: 1.074
[26,     3] loss: 1.088
[27,     3] loss: 1.004
[28,     3] loss: 1.021
[29,     3] loss: 1.005
[30,     3] loss: 0.939
[31,     3] loss: 0.945
[32,     3] loss: 0.934
[33,     3] loss: 0.881
[34,     3] loss: 0.881
[35,     3] loss: 0.911
[36,     3] loss: 0.923
[37,     3] loss: 1.033
[38,     3] loss: 0.915
[39,     3] loss: 0.871
[40,     3] loss: 0.939
[41,     3] loss: 0.932
[42,     3] loss: 0.964
[43,     3] loss: 0.900
[44,     3] loss: 0.880
[45,     3] loss: 0.883
[46,     3] loss: 0.874
[47,     3] loss: 0.897
[48,     3] loss: 1.007
[49,     3] loss: 0.920
[50,     3] loss: 0.849
[51,     3] loss: 0.828
[52,     3] loss: 0.808
[53,     3] loss: 0.833
[54,     3] loss: 0.873
[55,     3] loss: 0.815
[56,     3] loss: 0.830
[57,     3] loss: 0.812
[58,     3] loss: 0.785
[59,     3] loss: 0.956
[60,     3] loss: 1.015
[61,     3] loss: 0.863
[62,     3] loss: 0.869
[63,     3] loss: 0.868
[64,     3] loss: 0.834
[65,     3] loss: 0.822
[66,     3] loss: 0.798
[67,     3] loss: 0.793
[68,     3] loss: 0.829
[69,     3] loss: 0.753
[70,     3] loss: 0.771
[71,     3] loss: 0.770
[72,     3] loss: 0.765
Early stopping applied (best metric=0.48772352933883667)
Finished Training
Total time taken: 16.02205204963684
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.390
[3,     3] loss: 1.385
[4,     3] loss: 1.384
[5,     3] loss: 1.381
[6,     3] loss: 1.390
[7,     3] loss: 1.390
[8,     3] loss: 1.393
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.383
[12,     3] loss: 1.385
[13,     3] loss: 1.380
[14,     3] loss: 1.383
[15,     3] loss: 1.381
[16,     3] loss: 1.380
[17,     3] loss: 1.375
[18,     3] loss: 1.376
[19,     3] loss: 1.361
[20,     3] loss: 1.365
[21,     3] loss: 1.341
[22,     3] loss: 1.327
[23,     3] loss: 1.272
[24,     3] loss: 1.288
[25,     3] loss: 1.201
[26,     3] loss: 1.178
[27,     3] loss: 1.153
[28,     3] loss: 1.079
[29,     3] loss: 1.120
[30,     3] loss: 1.046
[31,     3] loss: 1.099
[32,     3] loss: 1.033
[33,     3] loss: 1.105
[34,     3] loss: 1.186
[35,     3] loss: 1.035
[36,     3] loss: 1.049
[37,     3] loss: 1.016
[38,     3] loss: 0.979
[39,     3] loss: 0.981
[40,     3] loss: 1.000
[41,     3] loss: 0.992
[42,     3] loss: 1.002
[43,     3] loss: 1.097
[44,     3] loss: 1.017
[45,     3] loss: 1.094
[46,     3] loss: 0.984
[47,     3] loss: 0.961
[48,     3] loss: 0.936
[49,     3] loss: 0.901
[50,     3] loss: 0.922
[51,     3] loss: 0.938
[52,     3] loss: 0.912
[53,     3] loss: 0.912
[54,     3] loss: 0.868
[55,     3] loss: 0.865
[56,     3] loss: 0.841
[57,     3] loss: 0.819
[58,     3] loss: 0.846
[59,     3] loss: 0.821
[60,     3] loss: 0.842
[61,     3] loss: 0.942
[62,     3] loss: 0.878
[63,     3] loss: 0.868
[64,     3] loss: 0.874
[65,     3] loss: 0.939
[66,     3] loss: 0.860
[67,     3] loss: 0.827
[68,     3] loss: 0.844
[69,     3] loss: 0.870
[70,     3] loss: 0.865
[71,     3] loss: 0.865
[72,     3] loss: 0.854
[73,     3] loss: 0.835
[74,     3] loss: 0.831
[75,     3] loss: 0.842
[76,     3] loss: 0.866
[77,     3] loss: 0.873
[78,     3] loss: 0.824
Early stopping applied (best metric=0.5019038319587708)
Finished Training
Total time taken: 17.334052801132202
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.385
[3,     3] loss: 1.383
[4,     3] loss: 1.390
[5,     3] loss: 1.382
[6,     3] loss: 1.383
[7,     3] loss: 1.390
[8,     3] loss: 1.386
[9,     3] loss: 1.383
[10,     3] loss: 1.383
[11,     3] loss: 1.378
[12,     3] loss: 1.374
[13,     3] loss: 1.367
[14,     3] loss: 1.360
[15,     3] loss: 1.355
[16,     3] loss: 1.369
[17,     3] loss: 1.333
[18,     3] loss: 1.274
[19,     3] loss: 1.240
[20,     3] loss: 1.267
[21,     3] loss: 1.087
[22,     3] loss: 1.116
[23,     3] loss: 1.126
[24,     3] loss: 1.112
[25,     3] loss: 1.103
[26,     3] loss: 1.064
[27,     3] loss: 1.039
[28,     3] loss: 1.046
[29,     3] loss: 0.942
[30,     3] loss: 0.974
[31,     3] loss: 0.969
[32,     3] loss: 1.076
[33,     3] loss: 0.962
[34,     3] loss: 1.020
[35,     3] loss: 0.961
[36,     3] loss: 0.990
[37,     3] loss: 0.974
[38,     3] loss: 0.905
[39,     3] loss: 0.924
[40,     3] loss: 0.886
[41,     3] loss: 0.948
[42,     3] loss: 0.898
[43,     3] loss: 0.940
[44,     3] loss: 0.911
[45,     3] loss: 0.906
[46,     3] loss: 0.826
[47,     3] loss: 0.858
[48,     3] loss: 0.830
[49,     3] loss: 0.881
[50,     3] loss: 0.803
[51,     3] loss: 0.867
[52,     3] loss: 0.827
[53,     3] loss: 0.865
[54,     3] loss: 0.845
[55,     3] loss: 0.870
[56,     3] loss: 0.906
[57,     3] loss: 0.980
[58,     3] loss: 0.857
[59,     3] loss: 0.843
[60,     3] loss: 0.847
[61,     3] loss: 0.900
[62,     3] loss: 0.803
[63,     3] loss: 0.911
[64,     3] loss: 0.924
[65,     3] loss: 0.843
[66,     3] loss: 0.804
[67,     3] loss: 0.819
[68,     3] loss: 0.788
Early stopping applied (best metric=0.5048398971557617)
Finished Training
Total time taken: 15.090627670288086
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.382
[3,     3] loss: 1.390
[4,     3] loss: 1.384
[5,     3] loss: 1.389
[6,     3] loss: 1.378
[7,     3] loss: 1.376
[8,     3] loss: 1.376
[9,     3] loss: 1.368
[10,     3] loss: 1.355
[11,     3] loss: 1.328
[12,     3] loss: 1.322
[13,     3] loss: 1.282
[14,     3] loss: 1.264
[15,     3] loss: 1.271
[16,     3] loss: 1.233
[17,     3] loss: 1.253
[18,     3] loss: 1.181
[19,     3] loss: 1.210
[20,     3] loss: 1.188
[21,     3] loss: 1.139
[22,     3] loss: 1.140
[23,     3] loss: 1.149
[24,     3] loss: 1.078
[25,     3] loss: 1.082
[26,     3] loss: 1.087
[27,     3] loss: 1.048
[28,     3] loss: 0.943
[29,     3] loss: 0.975
[30,     3] loss: 1.012
[31,     3] loss: 0.924
[32,     3] loss: 0.991
[33,     3] loss: 0.946
[34,     3] loss: 1.039
[35,     3] loss: 1.016
[36,     3] loss: 0.935
[37,     3] loss: 0.975
[38,     3] loss: 0.915
[39,     3] loss: 0.972
[40,     3] loss: 0.939
[41,     3] loss: 1.004
[42,     3] loss: 0.926
[43,     3] loss: 0.954
[44,     3] loss: 0.887
[45,     3] loss: 0.882
[46,     3] loss: 0.903
[47,     3] loss: 0.842
[48,     3] loss: 0.925
[49,     3] loss: 0.938
[50,     3] loss: 0.891
[51,     3] loss: 0.859
[52,     3] loss: 0.880
[53,     3] loss: 0.867
[54,     3] loss: 0.889
[55,     3] loss: 0.875
[56,     3] loss: 0.836
[57,     3] loss: 0.834
[58,     3] loss: 0.838
[59,     3] loss: 0.824
[60,     3] loss: 0.825
[61,     3] loss: 0.899
[62,     3] loss: 0.810
[63,     3] loss: 0.800
[64,     3] loss: 0.817
[65,     3] loss: 0.800
[66,     3] loss: 0.768
[67,     3] loss: 0.785
[68,     3] loss: 0.804
[69,     3] loss: 0.766
[70,     3] loss: 0.772
[71,     3] loss: 0.774
[72,     3] loss: 0.804
[73,     3] loss: 0.855
[74,     3] loss: 0.830
[75,     3] loss: 0.764
Early stopping applied (best metric=0.5018656253814697)
Finished Training
Total time taken: 16.705078125
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.383
[3,     3] loss: 1.387
[4,     3] loss: 1.393
[5,     3] loss: 1.383
[6,     3] loss: 1.389
[7,     3] loss: 1.388
[8,     3] loss: 1.386
[9,     3] loss: 1.382
[10,     3] loss: 1.378
[11,     3] loss: 1.377
[12,     3] loss: 1.374
[13,     3] loss: 1.379
[14,     3] loss: 1.366
[15,     3] loss: 1.360
[16,     3] loss: 1.342
[17,     3] loss: 1.300
[18,     3] loss: 1.314
[19,     3] loss: 1.263
[20,     3] loss: 1.196
[21,     3] loss: 1.215
[22,     3] loss: 1.152
[23,     3] loss: 1.174
[24,     3] loss: 1.180
[25,     3] loss: 1.107
[26,     3] loss: 1.084
[27,     3] loss: 1.070
[28,     3] loss: 0.997
[29,     3] loss: 1.145
[30,     3] loss: 1.031
[31,     3] loss: 1.032
[32,     3] loss: 0.937
[33,     3] loss: 0.967
[34,     3] loss: 0.987
[35,     3] loss: 0.950
[36,     3] loss: 1.054
[37,     3] loss: 0.929
[38,     3] loss: 0.947
[39,     3] loss: 1.036
[40,     3] loss: 0.935
[41,     3] loss: 0.960
[42,     3] loss: 0.881
[43,     3] loss: 0.855
[44,     3] loss: 0.826
[45,     3] loss: 0.842
[46,     3] loss: 0.885
[47,     3] loss: 0.845
[48,     3] loss: 0.873
[49,     3] loss: 0.914
[50,     3] loss: 0.914
[51,     3] loss: 0.985
[52,     3] loss: 0.907
[53,     3] loss: 0.884
[54,     3] loss: 0.866
[55,     3] loss: 0.914
[56,     3] loss: 0.835
[57,     3] loss: 0.899
[58,     3] loss: 0.854
[59,     3] loss: 0.848
[60,     3] loss: 0.828
[61,     3] loss: 0.918
[62,     3] loss: 0.853
[63,     3] loss: 0.815
[64,     3] loss: 0.859
[65,     3] loss: 0.846
[66,     3] loss: 0.791
Early stopping applied (best metric=0.5331987738609314)
Finished Training
Total time taken: 14.793045282363892
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.383
[3,     3] loss: 1.380
[4,     3] loss: 1.380
[5,     3] loss: 1.386
[6,     3] loss: 1.373
[7,     3] loss: 1.378
[8,     3] loss: 1.383
[9,     3] loss: 1.371
[10,     3] loss: 1.361
[11,     3] loss: 1.377
[12,     3] loss: 1.352
[13,     3] loss: 1.355
[14,     3] loss: 1.330
[15,     3] loss: 1.333
[16,     3] loss: 1.299
[17,     3] loss: 1.288
[18,     3] loss: 1.265
[19,     3] loss: 1.202
[20,     3] loss: 1.180
[21,     3] loss: 1.137
[22,     3] loss: 1.133
[23,     3] loss: 1.162
[24,     3] loss: 1.051
[25,     3] loss: 1.035
[26,     3] loss: 0.961
[27,     3] loss: 1.028
[28,     3] loss: 0.990
[29,     3] loss: 1.027
[30,     3] loss: 0.991
[31,     3] loss: 0.967
[32,     3] loss: 1.016
[33,     3] loss: 0.994
[34,     3] loss: 1.028
[35,     3] loss: 1.115
[36,     3] loss: 0.941
[37,     3] loss: 0.960
[38,     3] loss: 0.912
[39,     3] loss: 1.067
[40,     3] loss: 0.920
[41,     3] loss: 1.046
[42,     3] loss: 0.912
[43,     3] loss: 0.996
[44,     3] loss: 0.871
[45,     3] loss: 0.887
[46,     3] loss: 1.075
[47,     3] loss: 1.011
[48,     3] loss: 0.902
[49,     3] loss: 0.964
[50,     3] loss: 0.901
[51,     3] loss: 1.014
[52,     3] loss: 0.951
[53,     3] loss: 0.985
[54,     3] loss: 0.944
[55,     3] loss: 0.970
[56,     3] loss: 0.944
[57,     3] loss: 0.950
[58,     3] loss: 0.865
[59,     3] loss: 0.974
[60,     3] loss: 0.864
[61,     3] loss: 0.905
[62,     3] loss: 0.889
[63,     3] loss: 0.876
[64,     3] loss: 0.846
[65,     3] loss: 0.863
[66,     3] loss: 0.814
[67,     3] loss: 0.849
[68,     3] loss: 0.846
[69,     3] loss: 0.797
[70,     3] loss: 0.832
[71,     3] loss: 0.822
Early stopping applied (best metric=0.48756280541419983)
Finished Training
Total time taken: 15.793100357055664
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.384
[3,     3] loss: 1.390
[4,     3] loss: 1.394
[5,     3] loss: 1.382
[6,     3] loss: 1.384
[7,     3] loss: 1.384
[8,     3] loss: 1.382
[9,     3] loss: 1.381
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.383
[15,     3] loss: 1.383
[16,     3] loss: 1.384
[17,     3] loss: 1.379
[18,     3] loss: 1.375
[19,     3] loss: 1.368
[20,     3] loss: 1.356
[21,     3] loss: 1.353
[22,     3] loss: 1.308
[23,     3] loss: 1.275
[24,     3] loss: 1.258
[25,     3] loss: 1.180
[26,     3] loss: 1.144
[27,     3] loss: 1.131
[28,     3] loss: 1.040
[29,     3] loss: 1.275
[30,     3] loss: 1.022
[31,     3] loss: 1.095
[32,     3] loss: 1.022
[33,     3] loss: 1.235
[34,     3] loss: 1.002
[35,     3] loss: 1.006
[36,     3] loss: 1.050
[37,     3] loss: 1.051
[38,     3] loss: 1.028
[39,     3] loss: 1.014
[40,     3] loss: 1.016
[41,     3] loss: 0.988
[42,     3] loss: 0.908
[43,     3] loss: 0.913
[44,     3] loss: 0.956
[45,     3] loss: 0.946
[46,     3] loss: 0.879
[47,     3] loss: 0.940
[48,     3] loss: 0.917
[49,     3] loss: 0.970
[50,     3] loss: 0.941
[51,     3] loss: 0.899
[52,     3] loss: 0.869
[53,     3] loss: 0.942
[54,     3] loss: 0.841
[55,     3] loss: 0.935
[56,     3] loss: 0.955
[57,     3] loss: 0.881
[58,     3] loss: 0.897
[59,     3] loss: 0.843
[60,     3] loss: 0.852
[61,     3] loss: 0.822
[62,     3] loss: 0.886
[63,     3] loss: 0.840
[64,     3] loss: 0.793
[65,     3] loss: 0.854
[66,     3] loss: 0.941
[67,     3] loss: 0.858
[68,     3] loss: 0.866
[69,     3] loss: 0.833
[70,     3] loss: 0.885
[71,     3] loss: 0.942
[72,     3] loss: 0.862
[73,     3] loss: 0.830
[74,     3] loss: 0.870
[75,     3] loss: 0.883
[76,     3] loss: 0.804
[77,     3] loss: 0.806
[78,     3] loss: 0.831
[79,     3] loss: 0.799
[80,     3] loss: 0.798
[81,     3] loss: 0.792
[82,     3] loss: 0.820
[83,     3] loss: 0.861
[84,     3] loss: 0.904
[85,     3] loss: 0.904
[86,     3] loss: 0.888
[87,     3] loss: 0.880
[88,     3] loss: 0.889
[89,     3] loss: 0.825
[90,     3] loss: 0.812
Early stopping applied (best metric=0.4897731840610504)
Finished Training
Total time taken: 20.025516033172607
{'S-palmitoylation-C Validation Accuracy': 0.6958743181450605, 'S-palmitoylation-C Validation Sensitivity': 0.2322112211221122, 'S-palmitoylation-C Validation Specificity': 0.812097763956687, 'S-palmitoylation-C Validation Precision': 0.2546381477279695, 'S-palmitoylation-C AUC ROC': 0.5429351874991009, 'S-palmitoylation-C AUC PR': 0.22753465696868705, 'S-palmitoylation-C MCC': 0.0485677927009791, 'S-palmitoylation-C F1': 0.21885220373855932, 'Validation Loss (S-palmitoylation-C)': 0.5540659387906393, 'Hydroxylation-K Validation Accuracy': 0.6847517730496454, 'Hydroxylation-K Validation Sensitivity': 0.7925925925925926, 'Hydroxylation-K Validation Specificity': 0.6578947368421053, 'Hydroxylation-K Validation Precision': 0.38322210280010793, 'Hydroxylation-K AUC ROC': 0.814093567251462, 'Hydroxylation-K AUC PR': 0.5719011157231374, 'Hydroxylation-K MCC': 0.37533120556371563, 'Hydroxylation-K F1': 0.5068451011588266, 'Validation Loss (Hydroxylation-K)': 0.5063088774681092, 'Validation Loss (total)': 1.0603748083114624, 'TimeToTrain': 17.234464168548584}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00047368980584908257,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4768490204574494,
 'loss_weight_S-palmitoylation-C': 0.7653735639847585,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2922012744,
 'sample_weights': [0.7402592224082444, 0.709837995553732],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.063186511652566,
 'weight_decay_Hydroxylation-K': 2.318094181172315,
 'weight_decay_S-palmitoylation-C': 0.6352981415771034}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.379
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002201065633084341,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7771324489002949,
 'loss_weight_S-palmitoylation-C': 0.9524924024916696,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3932564916,
 'sample_weights': [0.7653735639847585, 0.4768490204574494],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.173765601712861,
 'weight_decay_Hydroxylation-K': 9.618792480429185,
 'weight_decay_S-palmitoylation-C': 0.0351102783161099}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.390
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000744103044031398,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5754344609984976,
 'loss_weight_S-palmitoylation-C': 0.5250624613536583,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3174319857,
 'sample_weights': [0.9524924024916696, 0.7771324489002949],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.719085598191668,
 'weight_decay_Hydroxylation-K': 9.107745343093407,
 'weight_decay_S-palmitoylation-C': 2.27571012836855}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.381
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017151275655844962,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8641402536678386,
 'loss_weight_S-palmitoylation-C': 0.5340310769296294,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2536903304,
 'sample_weights': [0.5250624613536583, 0.5754344609984976],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.917672578434395,
 'weight_decay_Hydroxylation-K': 8.663620858969736,
 'weight_decay_S-palmitoylation-C': 0.16982860978675074}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.404
[2,     3] loss: 1.386
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010009716998232807,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3032824221609758,
 'loss_weight_S-palmitoylation-C': 0.9443880638805753,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1426006377,
 'sample_weights': [0.5340310769296294, 0.8641402536678386],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7577645893492235,
 'weight_decay_Hydroxylation-K': 2.560335480400073,
 'weight_decay_S-palmitoylation-C': 0.21560639276347213}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.391
[3,     3] loss: 1.380
[4,     3] loss: 1.381
[5,     3] loss: 1.374
[6,     3] loss: 1.383
[7,     3] loss: 1.377
[8,     3] loss: 1.380
[9,     3] loss: 1.372
[10,     3] loss: 1.356
[11,     3] loss: 1.360
[12,     3] loss: 1.337
[13,     3] loss: 1.329
[14,     3] loss: 1.316
[15,     3] loss: 1.271
[16,     3] loss: 1.261
[17,     3] loss: 1.292
[18,     3] loss: 1.235
[19,     3] loss: 1.240
[20,     3] loss: 1.153
[21,     3] loss: 1.052
[22,     3] loss: 1.121
[23,     3] loss: 1.130
[24,     3] loss: 1.122
[25,     3] loss: 1.113
[26,     3] loss: 1.163
[27,     3] loss: 1.235
[28,     3] loss: 1.061
[29,     3] loss: 1.064
[30,     3] loss: 0.997
[31,     3] loss: 1.051
[32,     3] loss: 0.942
[33,     3] loss: 0.943
[34,     3] loss: 0.910
[35,     3] loss: 0.964
[36,     3] loss: 0.928
[37,     3] loss: 0.958
[38,     3] loss: 0.969
[39,     3] loss: 0.839
[40,     3] loss: 1.054
[41,     3] loss: 1.030
[42,     3] loss: 0.895
[43,     3] loss: 0.936
[44,     3] loss: 0.920
[45,     3] loss: 0.847
[46,     3] loss: 0.833
[47,     3] loss: 0.798
[48,     3] loss: 0.818
[49,     3] loss: 0.859
[50,     3] loss: 0.977
[51,     3] loss: 0.799
[52,     3] loss: 0.852
[53,     3] loss: 0.865
[54,     3] loss: 0.817
[55,     3] loss: 0.799
[56,     3] loss: 0.815
[57,     3] loss: 0.777
[58,     3] loss: 0.909
[59,     3] loss: 0.926
[60,     3] loss: 0.762
[61,     3] loss: 0.831
[62,     3] loss: 0.759
[63,     3] loss: 0.858
[64,     3] loss: 0.817
[65,     3] loss: 0.817
[66,     3] loss: 0.772
[67,     3] loss: 0.767
[68,     3] loss: 0.775
[69,     3] loss: 0.810
[70,     3] loss: 0.795
[71,     3] loss: 0.782
[72,     3] loss: 0.731
[73,     3] loss: 0.774
[74,     3] loss: 0.737
Early stopping applied (best metric=0.5140409469604492)
Finished Training
Total time taken: 16.45799160003662
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.393
[3,     3] loss: 1.383
[4,     3] loss: 1.383
[5,     3] loss: 1.390
[6,     3] loss: 1.381
[7,     3] loss: 1.384
[8,     3] loss: 1.389
[9,     3] loss: 1.379
[10,     3] loss: 1.385
[11,     3] loss: 1.375
[12,     3] loss: 1.379
[13,     3] loss: 1.375
[14,     3] loss: 1.365
[15,     3] loss: 1.361
[16,     3] loss: 1.352
[17,     3] loss: 1.314
[18,     3] loss: 1.281
[19,     3] loss: 1.280
[20,     3] loss: 1.258
[21,     3] loss: 1.251
[22,     3] loss: 1.255
[23,     3] loss: 1.199
[24,     3] loss: 1.172
[25,     3] loss: 1.094
[26,     3] loss: 1.104
[27,     3] loss: 1.186
[28,     3] loss: 0.990
[29,     3] loss: 1.058
[30,     3] loss: 1.151
[31,     3] loss: 1.132
[32,     3] loss: 1.277
[33,     3] loss: 1.102
[34,     3] loss: 1.285
[35,     3] loss: 1.072
[36,     3] loss: 1.080
[37,     3] loss: 1.071
[38,     3] loss: 0.973
[39,     3] loss: 1.057
[40,     3] loss: 0.960
[41,     3] loss: 1.084
[42,     3] loss: 0.895
[43,     3] loss: 1.014
[44,     3] loss: 0.953
[45,     3] loss: 0.876
[46,     3] loss: 0.882
[47,     3] loss: 0.902
[48,     3] loss: 0.915
[49,     3] loss: 0.867
[50,     3] loss: 0.906
[51,     3] loss: 0.852
[52,     3] loss: 0.861
[53,     3] loss: 0.803
[54,     3] loss: 0.848
[55,     3] loss: 0.807
[56,     3] loss: 0.851
[57,     3] loss: 0.858
[58,     3] loss: 0.883
[59,     3] loss: 0.922
[60,     3] loss: 0.872
[61,     3] loss: 0.850
[62,     3] loss: 0.842
[63,     3] loss: 0.861
[64,     3] loss: 0.826
[65,     3] loss: 0.933
[66,     3] loss: 0.828
[67,     3] loss: 0.852
[68,     3] loss: 0.815
[69,     3] loss: 0.742
[70,     3] loss: 0.773
[71,     3] loss: 0.743
[72,     3] loss: 0.746
[73,     3] loss: 0.786
[74,     3] loss: 0.735
Early stopping applied (best metric=0.5135195255279541)
Finished Training
Total time taken: 16.372801542282104
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.383
[3,     3] loss: 1.383
[4,     3] loss: 1.402
[5,     3] loss: 1.375
[6,     3] loss: 1.373
[7,     3] loss: 1.371
[8,     3] loss: 1.381
[9,     3] loss: 1.360
[10,     3] loss: 1.367
[11,     3] loss: 1.338
[12,     3] loss: 1.349
[13,     3] loss: 1.291
[14,     3] loss: 1.287
[15,     3] loss: 1.280
[16,     3] loss: 1.255
[17,     3] loss: 1.237
[18,     3] loss: 1.198
[19,     3] loss: 1.205
[20,     3] loss: 1.138
[21,     3] loss: 1.067
[22,     3] loss: 1.039
[23,     3] loss: 1.060
[24,     3] loss: 1.042
[25,     3] loss: 1.029
[26,     3] loss: 0.994
[27,     3] loss: 1.009
[28,     3] loss: 1.057
[29,     3] loss: 1.023
[30,     3] loss: 0.962
[31,     3] loss: 1.138
[32,     3] loss: 0.952
[33,     3] loss: 0.939
[34,     3] loss: 0.865
[35,     3] loss: 0.929
[36,     3] loss: 0.906
[37,     3] loss: 0.844
[38,     3] loss: 0.881
[39,     3] loss: 0.852
[40,     3] loss: 0.831
[41,     3] loss: 0.818
[42,     3] loss: 0.908
[43,     3] loss: 0.917
[44,     3] loss: 0.836
[45,     3] loss: 0.851
[46,     3] loss: 0.808
[47,     3] loss: 0.825
[48,     3] loss: 0.817
[49,     3] loss: 0.812
[50,     3] loss: 0.861
[51,     3] loss: 0.785
[52,     3] loss: 0.763
[53,     3] loss: 0.776
[54,     3] loss: 0.870
[55,     3] loss: 0.774
[56,     3] loss: 0.752
[57,     3] loss: 0.748
[58,     3] loss: 0.782
[59,     3] loss: 0.788
[60,     3] loss: 0.783
[61,     3] loss: 0.776
[62,     3] loss: 0.780
[63,     3] loss: 0.730
[64,     3] loss: 0.780
[65,     3] loss: 0.827
[66,     3] loss: 0.736
[67,     3] loss: 0.754
[68,     3] loss: 0.800
[69,     3] loss: 1.018
[70,     3] loss: 0.865
[71,     3] loss: 0.805
[72,     3] loss: 0.770
[73,     3] loss: 0.808
[74,     3] loss: 0.813
Early stopping applied (best metric=0.5058001279830933)
Finished Training
Total time taken: 16.518062591552734
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.384
[3,     3] loss: 1.383
[4,     3] loss: 1.392
[5,     3] loss: 1.382
[6,     3] loss: 1.390
[7,     3] loss: 1.395
[8,     3] loss: 1.389
[9,     3] loss: 1.390
[10,     3] loss: 1.370
[11,     3] loss: 1.377
[12,     3] loss: 1.378
[13,     3] loss: 1.378
[14,     3] loss: 1.386
[15,     3] loss: 1.378
[16,     3] loss: 1.361
[17,     3] loss: 1.351
[18,     3] loss: 1.346
[19,     3] loss: 1.307
[20,     3] loss: 1.312
[21,     3] loss: 1.297
[22,     3] loss: 1.269
[23,     3] loss: 1.251
[24,     3] loss: 1.236
[25,     3] loss: 1.206
[26,     3] loss: 1.157
[27,     3] loss: 1.127
[28,     3] loss: 1.038
[29,     3] loss: 1.049
[30,     3] loss: 1.000
[31,     3] loss: 0.983
[32,     3] loss: 1.004
[33,     3] loss: 0.932
[34,     3] loss: 0.952
[35,     3] loss: 0.893
[36,     3] loss: 0.985
[37,     3] loss: 0.936
[38,     3] loss: 0.845
[39,     3] loss: 0.841
[40,     3] loss: 0.823
[41,     3] loss: 0.836
[42,     3] loss: 0.836
[43,     3] loss: 0.823
[44,     3] loss: 0.887
[45,     3] loss: 0.835
[46,     3] loss: 0.896
[47,     3] loss: 0.836
[48,     3] loss: 0.774
[49,     3] loss: 0.775
[50,     3] loss: 0.766
[51,     3] loss: 0.812
[52,     3] loss: 0.738
[53,     3] loss: 0.763
[54,     3] loss: 0.748
[55,     3] loss: 0.761
[56,     3] loss: 0.766
[57,     3] loss: 0.791
[58,     3] loss: 0.762
[59,     3] loss: 0.766
[60,     3] loss: 0.755
[61,     3] loss: 0.789
[62,     3] loss: 0.834
[63,     3] loss: 0.753
[64,     3] loss: 0.808
[65,     3] loss: 0.783
[66,     3] loss: 0.801
[67,     3] loss: 0.749
[68,     3] loss: 0.787
[69,     3] loss: 0.805
[70,     3] loss: 0.781
[71,     3] loss: 0.795
[72,     3] loss: 0.743
[73,     3] loss: 0.784
[74,     3] loss: 0.753
[75,     3] loss: 0.744
[76,     3] loss: 0.737
[77,     3] loss: 0.767
[78,     3] loss: 0.759
[79,     3] loss: 0.727
Early stopping applied (best metric=0.4640045464038849)
Finished Training
Total time taken: 17.565053462982178
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.389
[3,     3] loss: 1.386
[4,     3] loss: 1.384
[5,     3] loss: 1.380
[6,     3] loss: 1.387
[7,     3] loss: 1.384
[8,     3] loss: 1.381
[9,     3] loss: 1.380
[10,     3] loss: 1.368
[11,     3] loss: 1.341
[12,     3] loss: 1.353
[13,     3] loss: 1.345
[14,     3] loss: 1.348
[15,     3] loss: 1.322
[16,     3] loss: 1.292
[17,     3] loss: 1.242
[18,     3] loss: 1.300
[19,     3] loss: 1.236
[20,     3] loss: 1.230
[21,     3] loss: 1.132
[22,     3] loss: 1.075
[23,     3] loss: 1.122
[24,     3] loss: 1.212
[25,     3] loss: 1.167
[26,     3] loss: 1.195
[27,     3] loss: 1.034
[28,     3] loss: 1.118
[29,     3] loss: 0.993
[30,     3] loss: 1.000
[31,     3] loss: 1.089
[32,     3] loss: 0.944
[33,     3] loss: 1.100
[34,     3] loss: 0.907
[35,     3] loss: 1.082
[36,     3] loss: 0.932
[37,     3] loss: 0.925
[38,     3] loss: 0.935
[39,     3] loss: 1.061
[40,     3] loss: 1.040
[41,     3] loss: 0.992
[42,     3] loss: 0.951
[43,     3] loss: 0.884
[44,     3] loss: 0.974
[45,     3] loss: 0.949
[46,     3] loss: 0.846
[47,     3] loss: 0.900
[48,     3] loss: 0.860
[49,     3] loss: 0.866
[50,     3] loss: 0.815
[51,     3] loss: 0.821
[52,     3] loss: 0.882
[53,     3] loss: 0.826
[54,     3] loss: 0.826
[55,     3] loss: 0.862
[56,     3] loss: 0.880
[57,     3] loss: 0.765
[58,     3] loss: 0.777
[59,     3] loss: 0.772
[60,     3] loss: 0.869
[61,     3] loss: 0.765
[62,     3] loss: 0.897
[63,     3] loss: 0.782
[64,     3] loss: 0.801
[65,     3] loss: 0.786
[66,     3] loss: 0.792
[67,     3] loss: 0.844
[68,     3] loss: 0.794
[69,     3] loss: 0.795
[70,     3] loss: 0.775
[71,     3] loss: 0.765
Early stopping applied (best metric=0.4773096740245819)
Finished Training
Total time taken: 15.784051179885864
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.387
[3,     3] loss: 1.390
[4,     3] loss: 1.377
[5,     3] loss: 1.397
[6,     3] loss: 1.373
[7,     3] loss: 1.384
[8,     3] loss: 1.373
[9,     3] loss: 1.374
[10,     3] loss: 1.374
[11,     3] loss: 1.355
[12,     3] loss: 1.355
[13,     3] loss: 1.334
[14,     3] loss: 1.287
[15,     3] loss: 1.252
[16,     3] loss: 1.269
[17,     3] loss: 1.233
[18,     3] loss: 1.175
[19,     3] loss: 1.133
[20,     3] loss: 1.104
[21,     3] loss: 1.135
[22,     3] loss: 1.101
[23,     3] loss: 1.001
[24,     3] loss: 1.003
[25,     3] loss: 0.944
[26,     3] loss: 0.990
[27,     3] loss: 1.031
[28,     3] loss: 1.145
[29,     3] loss: 0.979
[30,     3] loss: 0.916
[31,     3] loss: 1.027
[32,     3] loss: 0.989
[33,     3] loss: 0.941
[34,     3] loss: 0.959
[35,     3] loss: 1.046
[36,     3] loss: 0.965
[37,     3] loss: 0.970
[38,     3] loss: 0.997
[39,     3] loss: 0.885
[40,     3] loss: 0.937
[41,     3] loss: 0.895
[42,     3] loss: 0.893
[43,     3] loss: 0.874
[44,     3] loss: 0.805
[45,     3] loss: 0.889
[46,     3] loss: 0.996
[47,     3] loss: 0.860
[48,     3] loss: 0.837
[49,     3] loss: 0.848
[50,     3] loss: 0.999
[51,     3] loss: 0.815
[52,     3] loss: 0.911
[53,     3] loss: 0.835
[54,     3] loss: 0.815
[55,     3] loss: 0.798
[56,     3] loss: 0.784
[57,     3] loss: 0.800
[58,     3] loss: 0.795
[59,     3] loss: 0.834
[60,     3] loss: 0.751
[61,     3] loss: 0.740
[62,     3] loss: 0.752
[63,     3] loss: 0.734
[64,     3] loss: 0.790
[65,     3] loss: 0.770
[66,     3] loss: 0.748
[67,     3] loss: 0.839
[68,     3] loss: 0.789
[69,     3] loss: 0.793
[70,     3] loss: 0.774
[71,     3] loss: 0.745
[72,     3] loss: 0.771
[73,     3] loss: 0.762
[74,     3] loss: 0.753
[75,     3] loss: 0.818
[76,     3] loss: 0.795
[77,     3] loss: 0.806
[78,     3] loss: 0.750
[79,     3] loss: 0.757
[80,     3] loss: 0.771
[81,     3] loss: 0.786
[82,     3] loss: 0.766
[83,     3] loss: 0.743
[84,     3] loss: 0.919
[85,     3] loss: 0.804
[86,     3] loss: 0.781
[87,     3] loss: 0.766
[88,     3] loss: 0.752
[89,     3] loss: 0.737
[90,     3] loss: 0.739
[91,     3] loss: 0.750
[92,     3] loss: 0.724
[93,     3] loss: 0.754
[94,     3] loss: 0.776
[95,     3] loss: 0.751
[96,     3] loss: 0.766
[97,     3] loss: 0.720
[98,     3] loss: 0.763
[99,     3] loss: 0.721
[100,     3] loss: 0.734
[101,     3] loss: 0.756
[102,     3] loss: 0.727
[103,     3] loss: 0.710
[104,     3] loss: 0.749
[105,     3] loss: 0.713
[106,     3] loss: 0.721
[107,     3] loss: 0.721
[108,     3] loss: 0.709
[109,     3] loss: 0.720
[110,     3] loss: 0.718
[111,     3] loss: 0.720
[112,     3] loss: 0.706
[113,     3] loss: 0.720
[114,     3] loss: 0.707
[115,     3] loss: 0.713
Early stopping applied (best metric=0.501729428768158)
Finished Training
Total time taken: 25.595112323760986
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.402
[2,     3] loss: 1.400
[3,     3] loss: 1.391
[4,     3] loss: 1.384
[5,     3] loss: 1.384
[6,     3] loss: 1.380
[7,     3] loss: 1.390
[8,     3] loss: 1.382
[9,     3] loss: 1.386
[10,     3] loss: 1.385
[11,     3] loss: 1.378
[12,     3] loss: 1.377
[13,     3] loss: 1.371
[14,     3] loss: 1.360
[15,     3] loss: 1.364
[16,     3] loss: 1.335
[17,     3] loss: 1.336
[18,     3] loss: 1.302
[19,     3] loss: 1.268
[20,     3] loss: 1.245
[21,     3] loss: 1.202
[22,     3] loss: 1.232
[23,     3] loss: 1.284
[24,     3] loss: 1.230
[25,     3] loss: 1.152
[26,     3] loss: 1.153
[27,     3] loss: 1.183
[28,     3] loss: 1.119
[29,     3] loss: 1.181
[30,     3] loss: 1.091
[31,     3] loss: 1.053
[32,     3] loss: 1.036
[33,     3] loss: 0.998
[34,     3] loss: 1.073
[35,     3] loss: 1.061
[36,     3] loss: 1.089
[37,     3] loss: 0.951
[38,     3] loss: 1.044
[39,     3] loss: 0.972
[40,     3] loss: 1.048
[41,     3] loss: 1.015
[42,     3] loss: 1.073
[43,     3] loss: 0.963
[44,     3] loss: 0.942
[45,     3] loss: 1.118
[46,     3] loss: 0.897
[47,     3] loss: 0.889
[48,     3] loss: 0.931
[49,     3] loss: 0.890
[50,     3] loss: 0.909
[51,     3] loss: 0.902
[52,     3] loss: 0.937
[53,     3] loss: 0.914
[54,     3] loss: 0.830
[55,     3] loss: 0.827
[56,     3] loss: 0.898
[57,     3] loss: 0.785
[58,     3] loss: 0.847
[59,     3] loss: 0.799
[60,     3] loss: 0.816
[61,     3] loss: 0.825
[62,     3] loss: 0.833
[63,     3] loss: 0.794
[64,     3] loss: 0.818
[65,     3] loss: 0.796
[66,     3] loss: 0.963
[67,     3] loss: 0.772
[68,     3] loss: 0.822
[69,     3] loss: 0.846
[70,     3] loss: 0.784
[71,     3] loss: 0.812
[72,     3] loss: 0.762
[73,     3] loss: 0.830
[74,     3] loss: 0.857
[75,     3] loss: 0.796
[76,     3] loss: 0.757
[77,     3] loss: 0.796
[78,     3] loss: 0.775
[79,     3] loss: 0.792
[80,     3] loss: 0.750
[81,     3] loss: 0.754
[82,     3] loss: 0.764
[83,     3] loss: 0.829
[84,     3] loss: 0.835
[85,     3] loss: 0.748
[86,     3] loss: 0.841
[87,     3] loss: 0.810
[88,     3] loss: 0.768
[89,     3] loss: 0.783
[90,     3] loss: 0.778
[91,     3] loss: 0.760
[92,     3] loss: 0.790
[93,     3] loss: 0.754
[94,     3] loss: 0.757
[95,     3] loss: 0.807
[96,     3] loss: 0.759
[97,     3] loss: 0.751
[98,     3] loss: 0.742
[99,     3] loss: 0.749
[100,     3] loss: 0.726
Early stopping applied (best metric=0.48331719636917114)
Finished Training
Total time taken: 22.15978217124939
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.382
[3,     3] loss: 1.381
[4,     3] loss: 1.383
[5,     3] loss: 1.371
[6,     3] loss: 1.371
[7,     3] loss: 1.366
[8,     3] loss: 1.348
[9,     3] loss: 1.325
[10,     3] loss: 1.341
[11,     3] loss: 1.306
[12,     3] loss: 1.319
[13,     3] loss: 1.293
[14,     3] loss: 1.285
[15,     3] loss: 1.229
[16,     3] loss: 1.168
[17,     3] loss: 1.267
[18,     3] loss: 1.184
[19,     3] loss: 1.116
[20,     3] loss: 1.081
[21,     3] loss: 1.152
[22,     3] loss: 1.085
[23,     3] loss: 1.071
[24,     3] loss: 1.006
[25,     3] loss: 1.038
[26,     3] loss: 1.114
[27,     3] loss: 1.056
[28,     3] loss: 1.006
[29,     3] loss: 0.919
[30,     3] loss: 0.994
[31,     3] loss: 0.990
[32,     3] loss: 0.906
[33,     3] loss: 0.888
[34,     3] loss: 1.001
[35,     3] loss: 1.026
[36,     3] loss: 0.947
[37,     3] loss: 0.960
[38,     3] loss: 0.910
[39,     3] loss: 1.003
[40,     3] loss: 0.853
[41,     3] loss: 0.877
[42,     3] loss: 0.933
[43,     3] loss: 0.813
[44,     3] loss: 0.908
[45,     3] loss: 0.874
[46,     3] loss: 0.869
[47,     3] loss: 0.859
[48,     3] loss: 0.942
[49,     3] loss: 0.814
[50,     3] loss: 0.827
[51,     3] loss: 0.838
[52,     3] loss: 0.798
[53,     3] loss: 0.762
[54,     3] loss: 0.822
[55,     3] loss: 0.824
[56,     3] loss: 0.835
[57,     3] loss: 0.864
[58,     3] loss: 0.767
[59,     3] loss: 0.816
[60,     3] loss: 0.870
[61,     3] loss: 0.810
[62,     3] loss: 0.824
[63,     3] loss: 0.785
[64,     3] loss: 0.777
[65,     3] loss: 0.824
[66,     3] loss: 0.841
[67,     3] loss: 0.801
[68,     3] loss: 0.796
[69,     3] loss: 0.940
[70,     3] loss: 0.854
[71,     3] loss: 0.806
[72,     3] loss: 0.933
[73,     3] loss: 0.939
[74,     3] loss: 0.840
[75,     3] loss: 0.804
[76,     3] loss: 0.860
Early stopping applied (best metric=0.5358240604400635)
Finished Training
Total time taken: 16.800864458084106
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.381
[3,     3] loss: 1.390
[4,     3] loss: 1.394
[5,     3] loss: 1.380
[6,     3] loss: 1.378
[7,     3] loss: 1.376
[8,     3] loss: 1.369
[9,     3] loss: 1.375
[10,     3] loss: 1.352
[11,     3] loss: 1.337
[12,     3] loss: 1.310
[13,     3] loss: 1.310
[14,     3] loss: 1.299
[15,     3] loss: 1.315
[16,     3] loss: 1.252
[17,     3] loss: 1.249
[18,     3] loss: 1.149
[19,     3] loss: 1.215
[20,     3] loss: 1.094
[21,     3] loss: 1.111
[22,     3] loss: 1.199
[23,     3] loss: 1.067
[24,     3] loss: 1.000
[25,     3] loss: 1.046
[26,     3] loss: 1.066
[27,     3] loss: 0.957
[28,     3] loss: 0.956
[29,     3] loss: 0.975
[30,     3] loss: 0.942
[31,     3] loss: 0.888
[32,     3] loss: 0.876
[33,     3] loss: 1.006
[34,     3] loss: 0.858
[35,     3] loss: 1.081
[36,     3] loss: 0.885
[37,     3] loss: 0.854
[38,     3] loss: 0.938
[39,     3] loss: 0.888
[40,     3] loss: 0.994
[41,     3] loss: 0.875
[42,     3] loss: 1.029
[43,     3] loss: 0.819
[44,     3] loss: 0.871
[45,     3] loss: 0.807
[46,     3] loss: 0.847
[47,     3] loss: 0.834
[48,     3] loss: 0.786
[49,     3] loss: 0.803
[50,     3] loss: 0.779
[51,     3] loss: 0.783
[52,     3] loss: 0.771
[53,     3] loss: 0.813
[54,     3] loss: 0.791
[55,     3] loss: 0.733
[56,     3] loss: 0.737
[57,     3] loss: 0.756
[58,     3] loss: 0.727
[59,     3] loss: 0.741
[60,     3] loss: 0.716
[61,     3] loss: 0.732
[62,     3] loss: 0.727
[63,     3] loss: 0.728
[64,     3] loss: 0.730
[65,     3] loss: 0.720
[66,     3] loss: 0.741
[67,     3] loss: 0.744
[68,     3] loss: 0.719
[69,     3] loss: 0.824
[70,     3] loss: 0.740
[71,     3] loss: 0.767
[72,     3] loss: 0.712
Early stopping applied (best metric=0.4870827794075012)
Finished Training
Total time taken: 15.972940683364868
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.391
[3,     3] loss: 1.396
[4,     3] loss: 1.388
[5,     3] loss: 1.384
[6,     3] loss: 1.383
[7,     3] loss: 1.382
[8,     3] loss: 1.381
[9,     3] loss: 1.374
[10,     3] loss: 1.379
[11,     3] loss: 1.358
[12,     3] loss: 1.347
[13,     3] loss: 1.346
[14,     3] loss: 1.337
[15,     3] loss: 1.295
[16,     3] loss: 1.245
[17,     3] loss: 1.223
[18,     3] loss: 1.181
[19,     3] loss: 1.163
[20,     3] loss: 1.210
[21,     3] loss: 1.186
[22,     3] loss: 1.112
[23,     3] loss: 1.173
[24,     3] loss: 1.052
[25,     3] loss: 1.081
[26,     3] loss: 1.080
[27,     3] loss: 1.005
[28,     3] loss: 0.949
[29,     3] loss: 0.953
[30,     3] loss: 0.970
[31,     3] loss: 0.913
[32,     3] loss: 0.998
[33,     3] loss: 1.002
[34,     3] loss: 1.033
[35,     3] loss: 0.903
[36,     3] loss: 0.903
[37,     3] loss: 0.891
[38,     3] loss: 0.874
[39,     3] loss: 0.824
[40,     3] loss: 0.836
[41,     3] loss: 0.839
[42,     3] loss: 0.853
[43,     3] loss: 0.830
[44,     3] loss: 0.768
[45,     3] loss: 0.966
[46,     3] loss: 0.857
[47,     3] loss: 0.787
[48,     3] loss: 0.764
[49,     3] loss: 0.858
[50,     3] loss: 0.874
[51,     3] loss: 0.857
[52,     3] loss: 0.877
[53,     3] loss: 0.784
[54,     3] loss: 0.908
[55,     3] loss: 0.847
[56,     3] loss: 0.858
[57,     3] loss: 0.816
[58,     3] loss: 0.899
[59,     3] loss: 0.816
[60,     3] loss: 0.826
[61,     3] loss: 0.883
[62,     3] loss: 0.970
[63,     3] loss: 0.823
[64,     3] loss: 0.919
[65,     3] loss: 0.805
[66,     3] loss: 0.900
[67,     3] loss: 0.860
[68,     3] loss: 0.763
[69,     3] loss: 0.802
[70,     3] loss: 0.785
[71,     3] loss: 0.981
[72,     3] loss: 0.779
[73,     3] loss: 0.866
[74,     3] loss: 0.815
[75,     3] loss: 0.806
[76,     3] loss: 0.766
[77,     3] loss: 0.744
[78,     3] loss: 0.762
[79,     3] loss: 0.767
Early stopping applied (best metric=0.49472859501838684)
Finished Training
Total time taken: 17.552067518234253
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.379
[2,     3] loss: 1.402
[3,     3] loss: 1.384
[4,     3] loss: 1.385
[5,     3] loss: 1.387
[6,     3] loss: 1.387
[7,     3] loss: 1.386
[8,     3] loss: 1.389
[9,     3] loss: 1.392
[10,     3] loss: 1.378
[11,     3] loss: 1.391
[12,     3] loss: 1.379
[13,     3] loss: 1.378
[14,     3] loss: 1.375
[15,     3] loss: 1.371
[16,     3] loss: 1.373
[17,     3] loss: 1.360
[18,     3] loss: 1.349
[19,     3] loss: 1.357
[20,     3] loss: 1.317
[21,     3] loss: 1.249
[22,     3] loss: 1.260
[23,     3] loss: 1.208
[24,     3] loss: 1.187
[25,     3] loss: 1.202
[26,     3] loss: 1.147
[27,     3] loss: 1.116
[28,     3] loss: 1.089
[29,     3] loss: 0.993
[30,     3] loss: 1.235
[31,     3] loss: 1.002
[32,     3] loss: 1.088
[33,     3] loss: 0.967
[34,     3] loss: 1.011
[35,     3] loss: 0.983
[36,     3] loss: 0.994
[37,     3] loss: 0.992
[38,     3] loss: 0.981
[39,     3] loss: 0.994
[40,     3] loss: 0.897
[41,     3] loss: 0.875
[42,     3] loss: 0.947
[43,     3] loss: 0.956
[44,     3] loss: 0.922
[45,     3] loss: 0.948
[46,     3] loss: 0.855
[47,     3] loss: 0.887
[48,     3] loss: 0.830
[49,     3] loss: 0.814
[50,     3] loss: 0.828
[51,     3] loss: 0.861
[52,     3] loss: 0.776
[53,     3] loss: 0.832
[54,     3] loss: 0.780
[55,     3] loss: 0.886
[56,     3] loss: 0.741
[57,     3] loss: 0.787
[58,     3] loss: 0.751
[59,     3] loss: 0.738
[60,     3] loss: 0.790
[61,     3] loss: 0.796
[62,     3] loss: 0.777
[63,     3] loss: 0.776
[64,     3] loss: 0.756
[65,     3] loss: 0.766
[66,     3] loss: 0.767
[67,     3] loss: 0.828
[68,     3] loss: 0.740
[69,     3] loss: 0.826
[70,     3] loss: 0.773
[71,     3] loss: 0.818
[72,     3] loss: 0.764
[73,     3] loss: 0.802
[74,     3] loss: 0.774
[75,     3] loss: 0.751
[76,     3] loss: 0.781
[77,     3] loss: 0.789
[78,     3] loss: 0.735
[79,     3] loss: 0.740
Early stopping applied (best metric=0.4934743046760559)
Finished Training
Total time taken: 17.582881927490234
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.399
[2,     3] loss: 1.384
[3,     3] loss: 1.386
[4,     3] loss: 1.385
[5,     3] loss: 1.384
[6,     3] loss: 1.383
[7,     3] loss: 1.381
[8,     3] loss: 1.387
[9,     3] loss: 1.371
[10,     3] loss: 1.393
[11,     3] loss: 1.382
[12,     3] loss: 1.373
[13,     3] loss: 1.371
[14,     3] loss: 1.368
[15,     3] loss: 1.380
[16,     3] loss: 1.351
[17,     3] loss: 1.342
[18,     3] loss: 1.314
[19,     3] loss: 1.286
[20,     3] loss: 1.273
[21,     3] loss: 1.232
[22,     3] loss: 1.250
[23,     3] loss: 1.243
[24,     3] loss: 1.191
[25,     3] loss: 1.159
[26,     3] loss: 1.169
[27,     3] loss: 1.097
[28,     3] loss: 1.072
[29,     3] loss: 1.095
[30,     3] loss: 1.157
[31,     3] loss: 1.045
[32,     3] loss: 1.193
[33,     3] loss: 1.055
[34,     3] loss: 1.005
[35,     3] loss: 0.979
[36,     3] loss: 1.090
[37,     3] loss: 0.947
[38,     3] loss: 0.976
[39,     3] loss: 0.963
[40,     3] loss: 1.011
[41,     3] loss: 0.894
[42,     3] loss: 0.934
[43,     3] loss: 0.952
[44,     3] loss: 0.845
[45,     3] loss: 0.824
[46,     3] loss: 0.895
[47,     3] loss: 0.879
[48,     3] loss: 0.910
[49,     3] loss: 0.958
[50,     3] loss: 0.842
[51,     3] loss: 0.815
[52,     3] loss: 0.854
[53,     3] loss: 0.896
[54,     3] loss: 0.885
[55,     3] loss: 0.814
[56,     3] loss: 0.849
[57,     3] loss: 0.901
[58,     3] loss: 0.832
[59,     3] loss: 0.854
[60,     3] loss: 0.778
[61,     3] loss: 0.824
[62,     3] loss: 1.018
[63,     3] loss: 0.825
[64,     3] loss: 0.907
[65,     3] loss: 0.816
[66,     3] loss: 0.859
[67,     3] loss: 0.794
[68,     3] loss: 0.801
[69,     3] loss: 0.930
[70,     3] loss: 0.848
[71,     3] loss: 0.802
[72,     3] loss: 0.787
[73,     3] loss: 0.818
[74,     3] loss: 0.795
[75,     3] loss: 0.852
[76,     3] loss: 0.818
[77,     3] loss: 0.779
[78,     3] loss: 0.846
[79,     3] loss: 0.783
[80,     3] loss: 0.733
[81,     3] loss: 0.755
[82,     3] loss: 0.835
[83,     3] loss: 0.821
[84,     3] loss: 0.735
[85,     3] loss: 0.753
[86,     3] loss: 0.754
[87,     3] loss: 0.746
[88,     3] loss: 0.735
[89,     3] loss: 0.743
[90,     3] loss: 0.752
[91,     3] loss: 0.832
[92,     3] loss: 0.758
[93,     3] loss: 0.750
[94,     3] loss: 0.769
[95,     3] loss: 0.831
[96,     3] loss: 0.780
[97,     3] loss: 0.767
[98,     3] loss: 0.759
[99,     3] loss: 0.746
[100,     3] loss: 0.756
[101,     3] loss: 0.730
[102,     3] loss: 0.763
[103,     3] loss: 0.781
[104,     3] loss: 0.745
[105,     3] loss: 0.728
[106,     3] loss: 0.729
[107,     3] loss: 0.725
[108,     3] loss: 0.720
[109,     3] loss: 0.715
[110,     3] loss: 0.710
[111,     3] loss: 0.712
[112,     3] loss: 0.722
[113,     3] loss: 0.711
Early stopping applied (best metric=0.5267400741577148)
Finished Training
Total time taken: 25.093078136444092
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.385
[3,     3] loss: 1.380
[4,     3] loss: 1.372
[5,     3] loss: 1.381
[6,     3] loss: 1.383
[7,     3] loss: 1.374
[8,     3] loss: 1.356
[9,     3] loss: 1.339
[10,     3] loss: 1.355
[11,     3] loss: 1.288
[12,     3] loss: 1.296
[13,     3] loss: 1.271
[14,     3] loss: 1.224
[15,     3] loss: 1.232
[16,     3] loss: 1.186
[17,     3] loss: 1.231
[18,     3] loss: 1.102
[19,     3] loss: 1.148
[20,     3] loss: 1.125
[21,     3] loss: 1.155
[22,     3] loss: 1.015
[23,     3] loss: 1.031
[24,     3] loss: 1.091
[25,     3] loss: 1.102
[26,     3] loss: 1.031
[27,     3] loss: 1.006
[28,     3] loss: 1.136
[29,     3] loss: 1.035
[30,     3] loss: 1.045
[31,     3] loss: 1.028
[32,     3] loss: 0.920
[33,     3] loss: 0.989
[34,     3] loss: 1.008
[35,     3] loss: 0.875
[36,     3] loss: 0.973
[37,     3] loss: 0.925
[38,     3] loss: 0.857
[39,     3] loss: 0.864
[40,     3] loss: 0.860
[41,     3] loss: 0.836
[42,     3] loss: 0.889
[43,     3] loss: 0.851
[44,     3] loss: 0.881
[45,     3] loss: 0.813
[46,     3] loss: 0.807
[47,     3] loss: 0.804
[48,     3] loss: 0.850
[49,     3] loss: 0.804
[50,     3] loss: 0.851
[51,     3] loss: 0.799
[52,     3] loss: 0.817
[53,     3] loss: 0.903
[54,     3] loss: 0.758
[55,     3] loss: 0.782
[56,     3] loss: 0.795
[57,     3] loss: 0.790
[58,     3] loss: 0.771
[59,     3] loss: 0.768
[60,     3] loss: 0.747
[61,     3] loss: 0.832
[62,     3] loss: 0.769
[63,     3] loss: 0.839
[64,     3] loss: 0.885
[65,     3] loss: 0.881
[66,     3] loss: 0.823
[67,     3] loss: 0.772
[68,     3] loss: 0.855
[69,     3] loss: 0.814
[70,     3] loss: 0.801
[71,     3] loss: 0.794
[72,     3] loss: 0.789
[73,     3] loss: 0.752
[74,     3] loss: 0.995
[75,     3] loss: 0.854
[76,     3] loss: 0.777
[77,     3] loss: 0.780
[78,     3] loss: 0.782
[79,     3] loss: 0.846
[80,     3] loss: 0.747
[81,     3] loss: 0.778
[82,     3] loss: 0.756
[83,     3] loss: 0.756
Early stopping applied (best metric=0.521904706954956)
Finished Training
Total time taken: 18.48505735397339
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.380
[3,     3] loss: 1.403
[4,     3] loss: 1.380
[5,     3] loss: 1.375
[6,     3] loss: 1.374
[7,     3] loss: 1.384
[8,     3] loss: 1.375
[9,     3] loss: 1.356
[10,     3] loss: 1.351
[11,     3] loss: 1.330
[12,     3] loss: 1.314
[13,     3] loss: 1.297
[14,     3] loss: 1.298
[15,     3] loss: 1.271
[16,     3] loss: 1.207
[17,     3] loss: 1.275
[18,     3] loss: 1.202
[19,     3] loss: 1.140
[20,     3] loss: 1.186
[21,     3] loss: 1.102
[22,     3] loss: 1.138
[23,     3] loss: 1.131
[24,     3] loss: 1.106
[25,     3] loss: 1.025
[26,     3] loss: 1.087
[27,     3] loss: 1.053
[28,     3] loss: 1.027
[29,     3] loss: 0.951
[30,     3] loss: 0.963
[31,     3] loss: 0.946
[32,     3] loss: 0.949
[33,     3] loss: 0.919
[34,     3] loss: 0.909
[35,     3] loss: 0.949
[36,     3] loss: 0.843
[37,     3] loss: 0.857
[38,     3] loss: 0.879
[39,     3] loss: 0.900
[40,     3] loss: 0.857
[41,     3] loss: 1.082
[42,     3] loss: 0.849
[43,     3] loss: 0.849
[44,     3] loss: 0.961
[45,     3] loss: 0.947
[46,     3] loss: 0.929
[47,     3] loss: 0.964
[48,     3] loss: 0.799
[49,     3] loss: 0.844
[50,     3] loss: 0.896
[51,     3] loss: 0.814
[52,     3] loss: 0.799
[53,     3] loss: 0.781
[54,     3] loss: 0.867
[55,     3] loss: 0.827
[56,     3] loss: 0.832
[57,     3] loss: 0.785
[58,     3] loss: 0.803
[59,     3] loss: 0.821
[60,     3] loss: 0.790
[61,     3] loss: 0.762
[62,     3] loss: 0.764
[63,     3] loss: 0.824
[64,     3] loss: 0.753
[65,     3] loss: 0.741
[66,     3] loss: 0.758
[67,     3] loss: 0.753
[68,     3] loss: 0.732
[69,     3] loss: 0.801
[70,     3] loss: 0.859
[71,     3] loss: 0.886
[72,     3] loss: 0.811
[73,     3] loss: 0.926
[74,     3] loss: 0.819
[75,     3] loss: 0.773
[76,     3] loss: 0.789
[77,     3] loss: 0.879
[78,     3] loss: 0.780
[79,     3] loss: 0.796
Early stopping applied (best metric=0.48826321959495544)
Finished Training
Total time taken: 17.549052953720093
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.388
[3,     3] loss: 1.387
[4,     3] loss: 1.385
[5,     3] loss: 1.381
[6,     3] loss: 1.382
[7,     3] loss: 1.391
[8,     3] loss: 1.384
[9,     3] loss: 1.368
[10,     3] loss: 1.372
[11,     3] loss: 1.361
[12,     3] loss: 1.363
[13,     3] loss: 1.344
[14,     3] loss: 1.319
[15,     3] loss: 1.301
[16,     3] loss: 1.263
[17,     3] loss: 1.230
[18,     3] loss: 1.216
[19,     3] loss: 1.220
[20,     3] loss: 1.160
[21,     3] loss: 1.162
[22,     3] loss: 1.127
[23,     3] loss: 1.084
[24,     3] loss: 1.149
[25,     3] loss: 1.030
[26,     3] loss: 1.053
[27,     3] loss: 0.972
[28,     3] loss: 0.982
[29,     3] loss: 0.981
[30,     3] loss: 0.915
[31,     3] loss: 0.987
[32,     3] loss: 0.975
[33,     3] loss: 1.004
[34,     3] loss: 0.900
[35,     3] loss: 0.902
[36,     3] loss: 0.978
[37,     3] loss: 1.024
[38,     3] loss: 0.979
[39,     3] loss: 1.018
[40,     3] loss: 0.988
[41,     3] loss: 0.886
[42,     3] loss: 0.864
[43,     3] loss: 0.847
[44,     3] loss: 0.859
[45,     3] loss: 0.901
[46,     3] loss: 0.864
[47,     3] loss: 0.840
[48,     3] loss: 0.859
[49,     3] loss: 0.836
[50,     3] loss: 0.932
[51,     3] loss: 0.787
[52,     3] loss: 0.891
[53,     3] loss: 0.837
[54,     3] loss: 0.840
[55,     3] loss: 0.797
[56,     3] loss: 0.791
[57,     3] loss: 0.775
[58,     3] loss: 0.780
[59,     3] loss: 0.805
[60,     3] loss: 0.778
[61,     3] loss: 0.813
[62,     3] loss: 0.773
[63,     3] loss: 0.766
[64,     3] loss: 0.782
[65,     3] loss: 0.895
[66,     3] loss: 0.808
[67,     3] loss: 0.772
[68,     3] loss: 0.851
[69,     3] loss: 0.754
[70,     3] loss: 0.781
[71,     3] loss: 0.755
[72,     3] loss: 0.755
[73,     3] loss: 0.781
[74,     3] loss: 0.804
[75,     3] loss: 0.953
[76,     3] loss: 0.790
[77,     3] loss: 0.768
[78,     3] loss: 0.766
[79,     3] loss: 0.805
[80,     3] loss: 0.794
[81,     3] loss: 0.768
[82,     3] loss: 0.766
[83,     3] loss: 0.754
[84,     3] loss: 0.790
[85,     3] loss: 0.755
[86,     3] loss: 0.780
[87,     3] loss: 0.742
[88,     3] loss: 0.761
[89,     3] loss: 0.733
Early stopping applied (best metric=0.5045514702796936)
Finished Training
Total time taken: 19.700071096420288
{'S-palmitoylation-C Validation Accuracy': 0.7049029597282872, 'S-palmitoylation-C Validation Sensitivity': 0.21465346534653465, 'S-palmitoylation-C Validation Specificity': 0.8277968365363054, 'S-palmitoylation-C Validation Precision': 0.23811770383400796, 'S-palmitoylation-C AUC ROC': 0.5450859649439974, 'S-palmitoylation-C AUC PR': 0.22589675295704514, 'S-palmitoylation-C MCC': 0.0439317881014159, 'S-palmitoylation-C F1': 0.21863340698751152, 'Validation Loss (S-palmitoylation-C)': 0.5544988512992859, 'Hydroxylation-K Validation Accuracy': 0.7409869976359338, 'Hydroxylation-K Validation Sensitivity': 0.8103703703703704, 'Hydroxylation-K Validation Specificity': 0.7228070175438597, 'Hydroxylation-K Validation Precision': 0.43186585551170287, 'Hydroxylation-K AUC ROC': 0.8672124756335282, 'Hydroxylation-K AUC PR': 0.6792814449052853, 'Hydroxylation-K MCC': 0.4453031168402784, 'Hydroxylation-K F1': 0.5594104320420403, 'Validation Loss (Hydroxylation-K)': 0.5008193771044414, 'Validation Loss (total)': 1.0553182204564413, 'TimeToTrain': 18.61259126663208}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003903191093599127,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.408615637825266,
 'loss_weight_S-palmitoylation-C': 0.9758481062182315,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2181102022,
 'sample_weights': [0.9443880638805753, 0.3032824221609758],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.418396350135145,
 'weight_decay_Hydroxylation-K': 3.133529408941087,
 'weight_decay_S-palmitoylation-C': 1.2803450957531666}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.390
[3,     3] loss: 1.386
[4,     3] loss: 1.384
[5,     3] loss: 1.387
[6,     3] loss: 1.385
[7,     3] loss: 1.379
[8,     3] loss: 1.377
[9,     3] loss: 1.376
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00684119576974696,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.18659013723436305,
 'loss_weight_S-palmitoylation-C': 0.20512683557722955,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 744379823,
 'sample_weights': [0.9758481062182315, 0.408615637825266],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.853497237426613,
 'weight_decay_Hydroxylation-K': 5.971410116375909,
 'weight_decay_S-palmitoylation-C': 4.010583785693064}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.405
[2,     3] loss: 1.384
[3,     3] loss: 1.400
[4,     3] loss: 1.392
[5,     3] loss: 1.388
[6,     3] loss: 1.386
[7,     3] loss: 1.385
[8,     3] loss: 1.384
[9,     3] loss: 1.383
[10,     3] loss: 1.382
[11,     3] loss: 1.391
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.385
[15,     3] loss: 1.385
[16,     3] loss: 1.384
[17,     3] loss: 1.362
[18,     3] loss: 1.331
[19,     3] loss: 1.309
[20,     3] loss: 1.185
[21,     3] loss: 1.362
[22,     3] loss: 1.343
[23,     3] loss: 1.301
[24,     3] loss: 1.295
[25,     3] loss: 1.220
[26,     3] loss: 1.195
[27,     3] loss: 1.230
[28,     3] loss: 1.143
[29,     3] loss: 1.144
[30,     3] loss: 1.070
[31,     3] loss: 1.135
[32,     3] loss: 1.244
[33,     3] loss: 1.160
[34,     3] loss: 1.248
[35,     3] loss: 1.062
[36,     3] loss: 1.013
[37,     3] loss: 1.071
[38,     3] loss: 1.345
[39,     3] loss: 1.327
[40,     3] loss: 1.252
[41,     3] loss: 1.342
[42,     3] loss: 1.340
[43,     3] loss: 1.275
[44,     3] loss: 1.262
[45,     3] loss: 1.161
[46,     3] loss: 1.203
[47,     3] loss: 1.072
[48,     3] loss: 1.210
[49,     3] loss: 1.104
[50,     3] loss: 1.097
[51,     3] loss: 1.026
[52,     3] loss: 1.094
[53,     3] loss: 1.209
[54,     3] loss: 1.247
[55,     3] loss: 1.230
[56,     3] loss: 1.133
[57,     3] loss: 1.116
[58,     3] loss: 1.106
[59,     3] loss: 1.082
[60,     3] loss: 1.083
[61,     3] loss: 1.343
[62,     3] loss: 1.310
[63,     3] loss: 1.273
[64,     3] loss: 1.284
[65,     3] loss: 1.234
[66,     3] loss: 1.115
[67,     3] loss: 0.979
[68,     3] loss: 1.020
[69,     3] loss: 1.290
[70,     3] loss: 1.176
[71,     3] loss: 1.150
[72,     3] loss: 1.196
[73,     3] loss: 1.048
[74,     3] loss: 1.082
[75,     3] loss: 1.041
[76,     3] loss: 1.086
[77,     3] loss: 1.106
[78,     3] loss: 0.987
[79,     3] loss: 1.082
[80,     3] loss: 1.212
[81,     3] loss: 1.144
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003009601825693589,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7905569924760705,
 'loss_weight_S-palmitoylation-C': 0.012150329672286686,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1076804832,
 'sample_weights': [0.20512683557722955, 0.18659013723436305],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.730603367554611,
 'weight_decay_Hydroxylation-K': 8.980708971866463,
 'weight_decay_S-palmitoylation-C': 1.8881500913316038}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.399
[2,     3] loss: 1.392
[3,     3] loss: 1.386
[4,     3] loss: 1.386
[5,     3] loss: 1.389
[6,     3] loss: 1.388
[7,     3] loss: 1.388
[8,     3] loss: 1.388
[9,     3] loss: 1.388
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.387
[13,     3] loss: 1.386
[14,     3] loss: 1.388
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.387
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.385
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.385
[26,     3] loss: 1.385
[27,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002484948747081152,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2173401925392407,
 'loss_weight_S-palmitoylation-C': 0.2210371060468806,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4273786323,
 'sample_weights': [0.012150329672286686, 0.7905569924760705],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8072216439586581,
 'weight_decay_Hydroxylation-K': 1.4133444420902057,
 'weight_decay_S-palmitoylation-C': 5.018893710461145}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.385
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009420160103115874,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.27453363551006227,
 'loss_weight_S-palmitoylation-C': 0.050127199691194724,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 45008120,
 'sample_weights': [0.2210371060468806, 0.2173401925392407],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.656424130460703,
 'weight_decay_Hydroxylation-K': 7.335817171481684,
 'weight_decay_S-palmitoylation-C': 5.42210559724464}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.390
[3,     3] loss: 1.389
[4,     3] loss: 1.387
[5,     3] loss: 1.388
[6,     3] loss: 1.385
[7,     3] loss: 1.385
[8,     3] loss: 1.384
[9,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012134716961003619,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8415459926953213,
 'loss_weight_S-palmitoylation-C': 0.969070668447201,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3241876324,
 'sample_weights': [0.050127199691194724, 0.27453363551006227],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8074544416237035,
 'weight_decay_Hydroxylation-K': 9.621124851117692,
 'weight_decay_S-palmitoylation-C': 1.9646464827005639}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.381
[3,     3] loss: 1.378
[4,     3] loss: 1.407
[5,     3] loss: 1.382
[6,     3] loss: 1.382
[7,     3] loss: 1.385
[8,     3] loss: 1.383
[9,     3] loss: 1.376
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024287039994346565,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8104261442238935,
 'loss_weight_S-palmitoylation-C': 0.6227817890394398,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3456456056,
 'sample_weights': [0.969070668447201, 0.8415459926953213],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.220884654439342,
 'weight_decay_Hydroxylation-K': 5.753308854413725,
 'weight_decay_S-palmitoylation-C': 0.9853740841605477}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.379
[3,     3] loss: 1.373
[4,     3] loss: 1.391
[5,     3] loss: 1.388
[6,     3] loss: 1.383
[7,     3] loss: 1.395
[8,     3] loss: 1.385
[9,     3] loss: 1.383
[10,     3] loss: 1.390
[11,     3] loss: 1.383
[12,     3] loss: 1.382
[13,     3] loss: 1.374
[14,     3] loss: 1.381
[15,     3] loss: 1.357
[16,     3] loss: 1.348
[17,     3] loss: 1.343
[18,     3] loss: 1.293
[19,     3] loss: 1.314
[20,     3] loss: 1.246
[21,     3] loss: 1.148
[22,     3] loss: 1.152
[23,     3] loss: 1.245
[24,     3] loss: 1.262
[25,     3] loss: 1.340
[26,     3] loss: 1.146
[27,     3] loss: 1.292
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002872488131198874,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5921885629553688,
 'loss_weight_S-palmitoylation-C': 0.01048031266123799,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3512300275,
 'sample_weights': [0.6227817890394398, 0.8104261442238935],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.240358471348564,
 'weight_decay_Hydroxylation-K': 1.5866325782375692,
 'weight_decay_S-palmitoylation-C': 0.4642595707044686}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.390
[3,     3] loss: 1.383
[4,     3] loss: 1.376
[5,     3] loss: 1.397
[6,     3] loss: 1.394
[7,     3] loss: 1.382
[8,     3] loss: 1.369
[9,     3] loss: 1.363
[10,     3] loss: 1.334
[11,     3] loss: 1.275
[12,     3] loss: 1.305
[13,     3] loss: 1.172
[14,     3] loss: 1.149
[15,     3] loss: 1.135
[16,     3] loss: 1.165
[17,     3] loss: 1.109
[18,     3] loss: 1.084
[19,     3] loss: 1.065
[20,     3] loss: 1.112
[21,     3] loss: 1.020
[22,     3] loss: 1.008
[23,     3] loss: 0.983
[24,     3] loss: 1.089
[25,     3] loss: 1.008
[26,     3] loss: 0.945
[27,     3] loss: 0.976
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003454713859769214,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7665518390802314,
 'loss_weight_S-palmitoylation-C': 0.5862932048516881,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2417789471,
 'sample_weights': [0.01048031266123799, 0.5921885629553688],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.808341249781898,
 'weight_decay_Hydroxylation-K': 9.875058239299863,
 'weight_decay_S-palmitoylation-C': 0.6453556004900262}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.392
[3,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007982029936701893,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.290641136105236,
 'loss_weight_S-palmitoylation-C': 0.3810125541869887,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1941947233,
 'sample_weights': [0.5862932048516881, 0.7665518390802314],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.839161833844184,
 'weight_decay_Hydroxylation-K': 2.242057877674155,
 'weight_decay_S-palmitoylation-C': 0.20169651811523093}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.395
[3,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012357864292555864,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.030131496530850843,
 'loss_weight_S-palmitoylation-C': 0.5356255364254807,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 365288866,
 'sample_weights': [0.3810125541869887, 0.290641136105236],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.731120011500288,
 'weight_decay_Hydroxylation-K': 3.41141740159318,
 'weight_decay_S-palmitoylation-C': 0.7546528406432969}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.392
[3,     3] loss: 1.394
[4,     3] loss: 1.381
[5,     3] loss: 1.387
[6,     3] loss: 1.390
[7,     3] loss: 1.386
[8,     3] loss: 1.385
[9,     3] loss: 1.377
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024077336388149254,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6928330500915855,
 'loss_weight_S-palmitoylation-C': 0.7086064036570943,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2648049114,
 'sample_weights': [0.5356255364254807, 0.030131496530850843],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.5894983463961396,
 'weight_decay_Hydroxylation-K': 9.524004697751598,
 'weight_decay_S-palmitoylation-C': 0.39228807393800325}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.402
[2,     3] loss: 1.394
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00025143301674045756,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6237435229460838,
 'loss_weight_S-palmitoylation-C': 0.10924371055087856,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 434819812,
 'sample_weights': [0.7086064036570943, 0.6928330500915855],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.2014064173346224,
 'weight_decay_Hydroxylation-K': 1.7714312743337344,
 'weight_decay_S-palmitoylation-C': 9.262460936924564}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.384
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 6.46015342250796e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2578818341030478,
 'loss_weight_S-palmitoylation-C': 0.9930586616710586,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2891322693,
 'sample_weights': [0.10924371055087856, 0.6237435229460838],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.0950174520212155,
 'weight_decay_Hydroxylation-K': 4.087415960522575,
 'weight_decay_S-palmitoylation-C': 2.9806538792943282}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.388
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003748673373684862,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1765697494750309,
 'loss_weight_S-palmitoylation-C': 0.4999244942159413,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3593996066,
 'sample_weights': [0.9930586616710586, 0.2578818341030478],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.0338318069797836,
 'weight_decay_Hydroxylation-K': 3.149720160595616,
 'weight_decay_S-palmitoylation-C': 7.768468279951077}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.389
[3,     3] loss: 1.395
[4,     3] loss: 1.388
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.392
[8,     3] loss: 1.385
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003392845998566205,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.995032329417419,
 'loss_weight_S-palmitoylation-C': 0.2260169899413459,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3373579615,
 'sample_weights': [0.4999244942159413, 0.1765697494750309],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.784862272624283,
 'weight_decay_Hydroxylation-K': 3.218762142159381,
 'weight_decay_S-palmitoylation-C': 7.467482269176118}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.399
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00036145503443428973,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.07726726109531262,
 'loss_weight_S-palmitoylation-C': 0.9213848530779873,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3163671526,
 'sample_weights': [0.2260169899413459, 0.995032329417419],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6342869610371387,
 'weight_decay_Hydroxylation-K': 0.34494431100559986,
 'weight_decay_S-palmitoylation-C': 0.5059398071190857}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.385
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0034022448469739164,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.32618997468086375,
 'loss_weight_S-palmitoylation-C': 0.11913386542092005,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2348897961,
 'sample_weights': [0.9213848530779873, 0.07726726109531262],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.9581912551085487,
 'weight_decay_Hydroxylation-K': 3.548963215795216,
 'weight_decay_S-palmitoylation-C': 8.832609098291321}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.392
[3,     3] loss: 1.387
[4,     3] loss: 1.395
[5,     3] loss: 1.388
[6,     3] loss: 1.393
[7,     3] loss: 1.392
[8,     3] loss: 1.385
[9,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002685281238474307,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6577205915403297,
 'loss_weight_S-palmitoylation-C': 0.4248252672786816,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1840981805,
 'sample_weights': [0.11913386542092005, 0.32618997468086375],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.998395744793725,
 'weight_decay_Hydroxylation-K': 2.5114769890744646,
 'weight_decay_S-palmitoylation-C': 1.0843422864371814}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.382
[3,     3] loss: 1.386
[4,     3] loss: 1.390
[5,     3] loss: 1.379
[6,     3] loss: 1.388
[7,     3] loss: 1.380
[8,     3] loss: 1.389
[9,     3] loss: 1.392
[10,     3] loss: 1.378
[11,     3] loss: 1.390
[12,     3] loss: 1.372
[13,     3] loss: 1.363
[14,     3] loss: 1.330
[15,     3] loss: 1.310
[16,     3] loss: 1.273
[17,     3] loss: 1.197
[18,     3] loss: 1.246
[19,     3] loss: 1.097
[20,     3] loss: 1.143
[21,     3] loss: 1.062
[22,     3] loss: 1.112
[23,     3] loss: 1.063
[24,     3] loss: 1.076
[25,     3] loss: 0.991
[26,     3] loss: 1.066
[27,     3] loss: 0.927
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012713711566369203,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21962499801376692,
 'loss_weight_S-palmitoylation-C': 0.9132036726722608,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3862959532,
 'sample_weights': [0.4248252672786816, 0.6577205915403297],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.399821091624507,
 'weight_decay_Hydroxylation-K': 3.8404586641627523,
 'weight_decay_S-palmitoylation-C': 0.38444491025207866}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.391
[3,     3] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00021970355889831296,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9627032876676052,
 'loss_weight_S-palmitoylation-C': 0.43714214395694095,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 618474178,
 'sample_weights': [0.9132036726722608, 0.21962499801376692],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.01848916614813,
 'weight_decay_Hydroxylation-K': 9.545784383908693,
 'weight_decay_S-palmitoylation-C': 2.2715527896689376}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.385
[3,     3] loss: 1.388
[4,     3] loss: 1.389
[5,     3] loss: 1.384
[6,     3] loss: 1.383
[7,     3] loss: 1.385
[8,     3] loss: 1.382
[9,     3] loss: 1.383
[10,     3] loss: 1.385
[11,     3] loss: 1.384
[12,     3] loss: 1.376
[13,     3] loss: 1.379
[14,     3] loss: 1.380
[15,     3] loss: 1.374
[16,     3] loss: 1.373
[17,     3] loss: 1.369
[18,     3] loss: 1.372
[19,     3] loss: 1.370
[20,     3] loss: 1.362
[21,     3] loss: 1.366
[22,     3] loss: 1.352
[23,     3] loss: 1.348
[24,     3] loss: 1.339
[25,     3] loss: 1.325
[26,     3] loss: 1.325
[27,     3] loss: 1.314
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003436944173383871,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7652733596665858,
 'loss_weight_S-palmitoylation-C': 0.15583158638538075,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2999930109,
 'sample_weights': [0.43714214395694095, 0.9627032876676052],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.792275963551647,
 'weight_decay_Hydroxylation-K': 0.20771535440720756,
 'weight_decay_S-palmitoylation-C': 7.028588205568871}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.388
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005019519019358735,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6055752915650817,
 'loss_weight_S-palmitoylation-C': 0.647315361375146,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 135526563,
 'sample_weights': [0.15583158638538075, 0.7652733596665858],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.873420570648165,
 'weight_decay_Hydroxylation-K': 0.7865628923889529,
 'weight_decay_S-palmitoylation-C': 1.6177428895386128}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.380
[3,     3] loss: 1.381
[4,     3] loss: 1.385
[5,     3] loss: 1.392
[6,     3] loss: 1.389
[7,     3] loss: 1.384
[8,     3] loss: 1.371
[9,     3] loss: 1.359
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027880439070111693,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9086963502250668,
 'loss_weight_S-palmitoylation-C': 0.2019788062527093,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1419329812,
 'sample_weights': [0.647315361375146, 0.6055752915650817],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.986378492953632,
 'weight_decay_Hydroxylation-K': 2.2489987997956846,
 'weight_decay_S-palmitoylation-C': 5.096589258293509}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.385
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024994415040331553,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8940380517603257,
 'loss_weight_S-palmitoylation-C': 0.42915533397065725,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 810280384,
 'sample_weights': [0.2019788062527093, 0.9086963502250668],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.642457552358819,
 'weight_decay_Hydroxylation-K': 6.478090029859737,
 'weight_decay_S-palmitoylation-C': 3.825830431461595}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.384
[3,     3] loss: 1.390
[4,     3] loss: 1.387
[5,     3] loss: 1.383
[6,     3] loss: 1.385
[7,     3] loss: 1.384
[8,     3] loss: 1.380
[9,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009035327670147576,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8979890206479237,
 'loss_weight_S-palmitoylation-C': 0.7351847723362239,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2820191550,
 'sample_weights': [0.42915533397065725, 0.8940380517603257],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.822997644007147,
 'weight_decay_Hydroxylation-K': 0.02992523512969214,
 'weight_decay_S-palmitoylation-C': 3.7513049376564873}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.388
[3,     3] loss: 1.391
[4,     3] loss: 1.387
[5,     3] loss: 1.387
[6,     3] loss: 1.388
[7,     3] loss: 1.386
[8,     3] loss: 1.381
[9,     3] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002673922605057501,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5928284583404181,
 'loss_weight_S-palmitoylation-C': 0.14708272967849695,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3219436487,
 'sample_weights': [0.7351847723362239, 0.8979890206479237],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.154318772524869,
 'weight_decay_Hydroxylation-K': 1.338184913292977,
 'weight_decay_S-palmitoylation-C': 8.713075383394118}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.392
[3,     3] loss: 1.390
[4,     3] loss: 1.385
[5,     3] loss: 1.380
[6,     3] loss: 1.388
[7,     3] loss: 1.395
[8,     3] loss: 1.391
[9,     3] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009660273476903294,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7384949010761033,
 'loss_weight_S-palmitoylation-C': 0.44491359248422296,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1684531480,
 'sample_weights': [0.14708272967849695, 0.5928284583404181],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.724189454779867,
 'weight_decay_Hydroxylation-K': 4.828359832898238,
 'weight_decay_S-palmitoylation-C': 2.1301879753720776}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.409
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018204566420862382,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7025755246758025,
 'loss_weight_S-palmitoylation-C': 0.5023142906491536,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1928932043,
 'sample_weights': [0.44491359248422296, 0.7384949010761033],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.071404980640087,
 'weight_decay_Hydroxylation-K': 2.379907001376921,
 'weight_decay_S-palmitoylation-C': 0.1702174304803915}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.384
[3,     3] loss: 1.396
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022278458718716708,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.37035960150361397,
 'loss_weight_S-palmitoylation-C': 0.9014733958812338,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4830192,
 'sample_weights': [0.5023142906491536, 0.7025755246758025],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.959243548178005,
 'weight_decay_Hydroxylation-K': 9.292361041658417,
 'weight_decay_S-palmitoylation-C': 7.132075275786951}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.382
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006447905804148424,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.15882777887221355,
 'loss_weight_S-palmitoylation-C': 0.7158265918368432,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2246071267,
 'sample_weights': [0.9014733958812338, 0.37035960150361397],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.973576053285175,
 'weight_decay_Hydroxylation-K': 0.1962614657798909,
 'weight_decay_S-palmitoylation-C': 7.822270623745049}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.377
[2,     3] loss: 1.399
[3,     3] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002511326346804185,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.39800795185163457,
 'loss_weight_S-palmitoylation-C': 0.776719154748527,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 301476726,
 'sample_weights': [0.7158265918368432, 0.15882777887221355],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.18807198121423063,
 'weight_decay_Hydroxylation-K': 0.3416488629288841,
 'weight_decay_S-palmitoylation-C': 1.4104151518996892}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.387
[3,     3] loss: 1.393
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004162796844124498,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.37574223547045793,
 'loss_weight_S-palmitoylation-C': 0.4021004497764241,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 708939179,
 'sample_weights': [0.776719154748527, 0.39800795185163457],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.293698660266779,
 'weight_decay_Hydroxylation-K': 3.5160486960305852,
 'weight_decay_S-palmitoylation-C': 1.619668372094116}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.389
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028026296952290007,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8815889230353213,
 'loss_weight_S-palmitoylation-C': 0.01962878401949287,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 372279026,
 'sample_weights': [0.4021004497764241, 0.37574223547045793],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.028638370446663,
 'weight_decay_Hydroxylation-K': 2.496412716436069,
 'weight_decay_S-palmitoylation-C': 3.835582412498568}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.396
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009654297385235782,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6096287210388294,
 'loss_weight_S-palmitoylation-C': 0.9997804130810479,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1917015419,
 'sample_weights': [0.01962878401949287, 0.8815889230353213],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.421116511687043,
 'weight_decay_Hydroxylation-K': 2.121958466644273,
 'weight_decay_S-palmitoylation-C': 0.40975641323005263}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.386
[3,     3] loss: 1.398
[4,     3] loss: 1.384
[5,     3] loss: 1.390
[6,     3] loss: 1.391
[7,     3] loss: 1.386
[8,     3] loss: 1.383
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023905900649313335,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4519873678645657,
 'loss_weight_S-palmitoylation-C': 0.4324910012400982,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1098115528,
 'sample_weights': [0.9997804130810479, 0.6096287210388294],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.2539024263666745,
 'weight_decay_Hydroxylation-K': 1.1412214674517667,
 'weight_decay_S-palmitoylation-C': 1.1554359132543488}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.389
[3,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018819702568889474,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2521092680144802,
 'loss_weight_S-palmitoylation-C': 0.8935262937311442,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 111116615,
 'sample_weights': [0.4324910012400982, 0.4519873678645657],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.137614829558833,
 'weight_decay_Hydroxylation-K': 1.5155980319031783,
 'weight_decay_S-palmitoylation-C': 0.7912975574543557}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.389
[3,     3] loss: 1.389
[4,     3] loss: 1.383
[5,     3] loss: 1.382
[6,     3] loss: 1.385
[7,     3] loss: 1.377
[8,     3] loss: 1.372
[9,     3] loss: 1.363
[10,     3] loss: 1.365
[11,     3] loss: 1.340
[12,     3] loss: 1.314
[13,     3] loss: 1.289
[14,     3] loss: 1.243
[15,     3] loss: 1.197
[16,     3] loss: 1.253
[17,     3] loss: 1.208
[18,     3] loss: 1.143
[19,     3] loss: 1.161
[20,     3] loss: 1.064
[21,     3] loss: 1.018
[22,     3] loss: 1.090
[23,     3] loss: 1.049
[24,     3] loss: 0.923
[25,     3] loss: 1.017
[26,     3] loss: 1.031
[27,     3] loss: 1.059
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022569146819467834,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3608912700697357,
 'loss_weight_S-palmitoylation-C': 0.7602241266027967,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 995275472,
 'sample_weights': [0.8935262937311442, 0.2521092680144802],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8720206450304806,
 'weight_decay_Hydroxylation-K': 8.444429785229728,
 'weight_decay_S-palmitoylation-C': 0.20162066315203764}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.392
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011686624319813296,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.057887411863099925,
 'loss_weight_S-palmitoylation-C': 0.647547668785311,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3837533077,
 'sample_weights': [0.7602241266027967, 0.3608912700697357],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.1791360734586265,
 'weight_decay_Hydroxylation-K': 7.643039398502156,
 'weight_decay_S-palmitoylation-C': 3.8322617604744096}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.387
[3,     3] loss: 1.380
[4,     3] loss: 1.380
[5,     3] loss: 1.382
[6,     3] loss: 1.394
[7,     3] loss: 1.389
[8,     3] loss: 1.376
[9,     3] loss: 1.376
[10,     3] loss: 1.375
[11,     3] loss: 1.351
[12,     3] loss: 1.319
[13,     3] loss: 1.324
[14,     3] loss: 1.287
[15,     3] loss: 1.272
[16,     3] loss: 1.210
[17,     3] loss: 1.218
[18,     3] loss: 1.275
[19,     3] loss: 1.277
[20,     3] loss: 1.204
[21,     3] loss: 1.188
[22,     3] loss: 1.144
[23,     3] loss: 1.061
[24,     3] loss: 1.089
[25,     3] loss: 0.989
[26,     3] loss: 1.051
[27,     3] loss: 1.020
[28,     3] loss: 1.051
[29,     3] loss: 1.062
[30,     3] loss: 1.189
[31,     3] loss: 1.166
[32,     3] loss: 1.027
[33,     3] loss: 0.984
[34,     3] loss: 1.005
[35,     3] loss: 1.037
[36,     3] loss: 1.014
[37,     3] loss: 1.031
[38,     3] loss: 0.914
[39,     3] loss: 0.947
[40,     3] loss: 0.920
[41,     3] loss: 0.883
[42,     3] loss: 0.886
[43,     3] loss: 0.859
[44,     3] loss: 0.874
[45,     3] loss: 0.884
[46,     3] loss: 0.942
[47,     3] loss: 0.926
[48,     3] loss: 0.861
[49,     3] loss: 0.846
[50,     3] loss: 0.903
[51,     3] loss: 0.897
[52,     3] loss: 0.882
[53,     3] loss: 0.854
[54,     3] loss: 0.840
[55,     3] loss: 0.885
[56,     3] loss: 0.810
[57,     3] loss: 0.936
[58,     3] loss: 0.883
[59,     3] loss: 0.815
[60,     3] loss: 0.830
[61,     3] loss: 0.817
[62,     3] loss: 0.833
[63,     3] loss: 0.808
[64,     3] loss: 0.797
[65,     3] loss: 0.814
[66,     3] loss: 0.800
[67,     3] loss: 0.850
[68,     3] loss: 0.833
[69,     3] loss: 0.829
[70,     3] loss: 0.927
[71,     3] loss: 0.957
[72,     3] loss: 0.831
[73,     3] loss: 0.831
[74,     3] loss: 0.832
[75,     3] loss: 0.797
[76,     3] loss: 0.796
[77,     3] loss: 0.793
[78,     3] loss: 0.785
[79,     3] loss: 0.762
Early stopping applied (best metric=0.503309965133667)
Finished Training
Total time taken: 17.554051876068115
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.381
[3,     3] loss: 1.390
[4,     3] loss: 1.389
[5,     3] loss: 1.388
[6,     3] loss: 1.381
[7,     3] loss: 1.381
[8,     3] loss: 1.380
[9,     3] loss: 1.373
[10,     3] loss: 1.361
[11,     3] loss: 1.358
[12,     3] loss: 1.338
[13,     3] loss: 1.322
[14,     3] loss: 1.292
[15,     3] loss: 1.251
[16,     3] loss: 1.196
[17,     3] loss: 1.274
[18,     3] loss: 1.168
[19,     3] loss: 1.134
[20,     3] loss: 1.067
[21,     3] loss: 1.121
[22,     3] loss: 1.029
[23,     3] loss: 1.008
[24,     3] loss: 0.988
[25,     3] loss: 1.003
[26,     3] loss: 0.982
[27,     3] loss: 0.983
[28,     3] loss: 0.975
[29,     3] loss: 0.964
[30,     3] loss: 0.907
[31,     3] loss: 0.958
[32,     3] loss: 1.042
[33,     3] loss: 1.265
[34,     3] loss: 1.128
[35,     3] loss: 1.136
[36,     3] loss: 1.036
[37,     3] loss: 1.025
[38,     3] loss: 1.027
[39,     3] loss: 0.981
[40,     3] loss: 0.932
[41,     3] loss: 0.936
[42,     3] loss: 0.906
[43,     3] loss: 0.897
[44,     3] loss: 0.950
[45,     3] loss: 0.858
[46,     3] loss: 0.848
[47,     3] loss: 0.837
[48,     3] loss: 0.855
[49,     3] loss: 0.934
[50,     3] loss: 0.864
[51,     3] loss: 0.855
[52,     3] loss: 0.882
[53,     3] loss: 0.878
[54,     3] loss: 0.855
[55,     3] loss: 0.888
[56,     3] loss: 0.842
[57,     3] loss: 0.846
[58,     3] loss: 0.852
[59,     3] loss: 0.874
[60,     3] loss: 0.878
[61,     3] loss: 0.822
[62,     3] loss: 0.904
[63,     3] loss: 0.794
[64,     3] loss: 0.857
[65,     3] loss: 0.869
[66,     3] loss: 0.854
[67,     3] loss: 0.805
Early stopping applied (best metric=0.5260016322135925)
Finished Training
Total time taken: 14.900044679641724
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.392
[3,     3] loss: 1.394
[4,     3] loss: 1.382
[5,     3] loss: 1.379
[6,     3] loss: 1.374
[7,     3] loss: 1.366
[8,     3] loss: 1.362
[9,     3] loss: 1.350
[10,     3] loss: 1.331
[11,     3] loss: 1.304
[12,     3] loss: 1.298
[13,     3] loss: 1.224
[14,     3] loss: 1.213
[15,     3] loss: 1.169
[16,     3] loss: 1.110
[17,     3] loss: 1.082
[18,     3] loss: 1.154
[19,     3] loss: 1.039
[20,     3] loss: 1.088
[21,     3] loss: 0.986
[22,     3] loss: 1.032
[23,     3] loss: 0.943
[24,     3] loss: 0.911
[25,     3] loss: 0.982
[26,     3] loss: 0.953
[27,     3] loss: 0.942
[28,     3] loss: 0.968
[29,     3] loss: 0.850
[30,     3] loss: 0.945
[31,     3] loss: 0.902
[32,     3] loss: 0.866
[33,     3] loss: 0.888
[34,     3] loss: 0.935
[35,     3] loss: 0.824
[36,     3] loss: 0.893
[37,     3] loss: 0.848
[38,     3] loss: 0.862
[39,     3] loss: 0.879
[40,     3] loss: 0.866
[41,     3] loss: 0.874
[42,     3] loss: 0.848
[43,     3] loss: 0.925
[44,     3] loss: 0.933
[45,     3] loss: 0.905
[46,     3] loss: 0.822
[47,     3] loss: 0.872
[48,     3] loss: 0.816
[49,     3] loss: 0.837
[50,     3] loss: 0.838
[51,     3] loss: 0.787
[52,     3] loss: 0.791
[53,     3] loss: 0.796
[54,     3] loss: 0.811
[55,     3] loss: 0.787
[56,     3] loss: 0.819
[57,     3] loss: 0.835
[58,     3] loss: 0.855
[59,     3] loss: 0.816
[60,     3] loss: 0.817
[61,     3] loss: 0.865
[62,     3] loss: 0.771
[63,     3] loss: 0.819
[64,     3] loss: 0.891
[65,     3] loss: 0.976
[66,     3] loss: 0.940
[67,     3] loss: 0.930
[68,     3] loss: 0.826
[69,     3] loss: 0.819
[70,     3] loss: 0.870
[71,     3] loss: 0.795
[72,     3] loss: 0.832
[73,     3] loss: 0.819
[74,     3] loss: 0.801
[75,     3] loss: 0.796
[76,     3] loss: 0.787
[77,     3] loss: 0.782
[78,     3] loss: 0.778
[79,     3] loss: 0.825
[80,     3] loss: 0.777
[81,     3] loss: 0.785
[82,     3] loss: 0.785
[83,     3] loss: 0.791
[84,     3] loss: 0.781
[85,     3] loss: 0.779
[86,     3] loss: 0.752
[87,     3] loss: 0.807
Early stopping applied (best metric=0.5365906357765198)
Finished Training
Total time taken: 19.328070878982544
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.394
[3,     3] loss: 1.386
[4,     3] loss: 1.382
[5,     3] loss: 1.383
[6,     3] loss: 1.377
[7,     3] loss: 1.375
[8,     3] loss: 1.366
[9,     3] loss: 1.351
[10,     3] loss: 1.330
[11,     3] loss: 1.336
[12,     3] loss: 1.342
[13,     3] loss: 1.275
[14,     3] loss: 1.232
[15,     3] loss: 1.214
[16,     3] loss: 1.208
[17,     3] loss: 1.097
[18,     3] loss: 1.116
[19,     3] loss: 1.051
[20,     3] loss: 1.054
[21,     3] loss: 0.994
[22,     3] loss: 1.114
[23,     3] loss: 0.991
[24,     3] loss: 1.006
[25,     3] loss: 1.001
[26,     3] loss: 0.995
[27,     3] loss: 1.114
[28,     3] loss: 0.993
[29,     3] loss: 0.973
[30,     3] loss: 1.031
[31,     3] loss: 0.925
[32,     3] loss: 1.005
[33,     3] loss: 0.892
[34,     3] loss: 0.914
[35,     3] loss: 1.032
[36,     3] loss: 0.979
[37,     3] loss: 0.868
[38,     3] loss: 0.851
[39,     3] loss: 0.948
[40,     3] loss: 0.924
[41,     3] loss: 0.872
[42,     3] loss: 0.856
[43,     3] loss: 0.890
[44,     3] loss: 0.829
[45,     3] loss: 0.856
[46,     3] loss: 0.902
[47,     3] loss: 0.923
[48,     3] loss: 0.890
[49,     3] loss: 0.873
[50,     3] loss: 0.842
[51,     3] loss: 0.844
[52,     3] loss: 0.841
[53,     3] loss: 0.868
[54,     3] loss: 0.916
[55,     3] loss: 0.909
[56,     3] loss: 0.849
[57,     3] loss: 0.899
[58,     3] loss: 0.876
[59,     3] loss: 0.936
[60,     3] loss: 0.861
[61,     3] loss: 0.858
[62,     3] loss: 0.833
[63,     3] loss: 0.808
[64,     3] loss: 0.784
[65,     3] loss: 0.776
[66,     3] loss: 0.753
[67,     3] loss: 0.806
[68,     3] loss: 0.865
[69,     3] loss: 0.805
[70,     3] loss: 0.796
Early stopping applied (best metric=0.507262647151947)
Finished Training
Total time taken: 15.51004672050476
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.380
[3,     3] loss: 1.382
[4,     3] loss: 1.366
[5,     3] loss: 1.387
[6,     3] loss: 1.397
[7,     3] loss: 1.369
[8,     3] loss: 1.354
[9,     3] loss: 1.363
[10,     3] loss: 1.345
[11,     3] loss: 1.357
[12,     3] loss: 1.329
[13,     3] loss: 1.271
[14,     3] loss: 1.290
[15,     3] loss: 1.271
[16,     3] loss: 1.284
[17,     3] loss: 1.187
[18,     3] loss: 1.119
[19,     3] loss: 1.105
[20,     3] loss: 1.110
[21,     3] loss: 1.098
[22,     3] loss: 1.142
[23,     3] loss: 1.069
[24,     3] loss: 1.028
[25,     3] loss: 1.048
[26,     3] loss: 1.044
[27,     3] loss: 1.003
[28,     3] loss: 0.977
[29,     3] loss: 1.114
[30,     3] loss: 1.027
[31,     3] loss: 1.145
[32,     3] loss: 0.990
[33,     3] loss: 0.936
[34,     3] loss: 0.966
[35,     3] loss: 0.956
[36,     3] loss: 0.933
[37,     3] loss: 0.924
[38,     3] loss: 0.918
[39,     3] loss: 0.932
[40,     3] loss: 0.993
[41,     3] loss: 0.910
[42,     3] loss: 0.842
[43,     3] loss: 0.905
[44,     3] loss: 1.096
[45,     3] loss: 1.170
[46,     3] loss: 0.940
[47,     3] loss: 0.895
[48,     3] loss: 1.065
[49,     3] loss: 0.928
[50,     3] loss: 0.920
[51,     3] loss: 0.883
[52,     3] loss: 0.868
[53,     3] loss: 0.894
[54,     3] loss: 0.959
[55,     3] loss: 0.883
[56,     3] loss: 0.864
[57,     3] loss: 0.906
[58,     3] loss: 0.875
[59,     3] loss: 0.952
[60,     3] loss: 0.882
[61,     3] loss: 0.850
[62,     3] loss: 0.909
[63,     3] loss: 0.865
[64,     3] loss: 0.813
[65,     3] loss: 0.814
[66,     3] loss: 0.847
[67,     3] loss: 0.880
[68,     3] loss: 0.784
[69,     3] loss: 0.818
Early stopping applied (best metric=0.5059068202972412)
Finished Training
Total time taken: 15.392047882080078
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.380
[2,     3] loss: 1.389
[3,     3] loss: 1.385
[4,     3] loss: 1.388
[5,     3] loss: 1.383
[6,     3] loss: 1.382
[7,     3] loss: 1.380
[8,     3] loss: 1.380
[9,     3] loss: 1.376
[10,     3] loss: 1.378
[11,     3] loss: 1.360
[12,     3] loss: 1.350
[13,     3] loss: 1.332
[14,     3] loss: 1.317
[15,     3] loss: 1.309
[16,     3] loss: 1.275
[17,     3] loss: 1.207
[18,     3] loss: 1.198
[19,     3] loss: 1.223
[20,     3] loss: 1.161
[21,     3] loss: 1.072
[22,     3] loss: 1.037
[23,     3] loss: 1.113
[24,     3] loss: 1.183
[25,     3] loss: 1.058
[26,     3] loss: 1.077
[27,     3] loss: 1.002
[28,     3] loss: 0.947
[29,     3] loss: 0.998
[30,     3] loss: 1.000
[31,     3] loss: 0.933
[32,     3] loss: 0.901
[33,     3] loss: 0.904
[34,     3] loss: 0.942
[35,     3] loss: 1.045
[36,     3] loss: 0.903
[37,     3] loss: 0.919
[38,     3] loss: 0.969
[39,     3] loss: 0.899
[40,     3] loss: 0.885
[41,     3] loss: 0.907
[42,     3] loss: 0.883
[43,     3] loss: 0.915
[44,     3] loss: 0.889
[45,     3] loss: 0.842
[46,     3] loss: 0.832
[47,     3] loss: 0.836
[48,     3] loss: 0.849
[49,     3] loss: 0.929
[50,     3] loss: 0.863
[51,     3] loss: 0.916
[52,     3] loss: 0.875
[53,     3] loss: 0.864
[54,     3] loss: 0.828
[55,     3] loss: 0.826
[56,     3] loss: 0.862
[57,     3] loss: 0.823
[58,     3] loss: 0.901
[59,     3] loss: 0.885
[60,     3] loss: 0.891
[61,     3] loss: 0.880
[62,     3] loss: 0.804
[63,     3] loss: 0.914
[64,     3] loss: 0.814
[65,     3] loss: 0.848
[66,     3] loss: 0.822
[67,     3] loss: 0.814
[68,     3] loss: 0.858
[69,     3] loss: 0.854
[70,     3] loss: 0.825
[71,     3] loss: 0.776
Early stopping applied (best metric=0.5238329768180847)
Finished Training
Total time taken: 15.780057430267334
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.392
[3,     3] loss: 1.391
[4,     3] loss: 1.383
[5,     3] loss: 1.390
[6,     3] loss: 1.383
[7,     3] loss: 1.377
[8,     3] loss: 1.376
[9,     3] loss: 1.365
[10,     3] loss: 1.370
[11,     3] loss: 1.349
[12,     3] loss: 1.360
[13,     3] loss: 1.354
[14,     3] loss: 1.306
[15,     3] loss: 1.327
[16,     3] loss: 1.283
[17,     3] loss: 1.280
[18,     3] loss: 1.251
[19,     3] loss: 1.191
[20,     3] loss: 1.128
[21,     3] loss: 1.097
[22,     3] loss: 1.085
[23,     3] loss: 1.254
[24,     3] loss: 1.219
[25,     3] loss: 1.090
[26,     3] loss: 1.060
[27,     3] loss: 1.034
[28,     3] loss: 1.138
[29,     3] loss: 1.057
[30,     3] loss: 1.079
[31,     3] loss: 1.091
[32,     3] loss: 1.020
[33,     3] loss: 0.950
[34,     3] loss: 0.931
[35,     3] loss: 1.235
[36,     3] loss: 1.076
[37,     3] loss: 1.001
[38,     3] loss: 0.949
[39,     3] loss: 1.056
[40,     3] loss: 1.040
[41,     3] loss: 0.924
[42,     3] loss: 0.909
[43,     3] loss: 0.939
[44,     3] loss: 0.923
[45,     3] loss: 0.947
[46,     3] loss: 0.894
[47,     3] loss: 0.962
[48,     3] loss: 0.995
[49,     3] loss: 0.889
[50,     3] loss: 0.873
[51,     3] loss: 0.954
[52,     3] loss: 0.852
[53,     3] loss: 0.903
[54,     3] loss: 0.849
[55,     3] loss: 0.862
[56,     3] loss: 0.804
[57,     3] loss: 0.905
[58,     3] loss: 0.873
[59,     3] loss: 0.860
[60,     3] loss: 0.848
[61,     3] loss: 0.808
[62,     3] loss: 0.776
[63,     3] loss: 0.780
[64,     3] loss: 0.795
[65,     3] loss: 0.813
[66,     3] loss: 0.823
[67,     3] loss: 0.875
[68,     3] loss: 0.823
[69,     3] loss: 0.852
[70,     3] loss: 0.812
[71,     3] loss: 0.820
[72,     3] loss: 0.772
[73,     3] loss: 0.798
[74,     3] loss: 0.779
[75,     3] loss: 0.798
[76,     3] loss: 0.795
[77,     3] loss: 0.759
[78,     3] loss: 0.799
Early stopping applied (best metric=0.5157366394996643)
Finished Training
Total time taken: 17.406071424484253
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.383
[3,     3] loss: 1.384
[4,     3] loss: 1.375
[5,     3] loss: 1.374
[6,     3] loss: 1.361
[7,     3] loss: 1.352
[8,     3] loss: 1.338
[9,     3] loss: 1.320
[10,     3] loss: 1.281
[11,     3] loss: 1.277
[12,     3] loss: 1.219
[13,     3] loss: 1.204
[14,     3] loss: 1.211
[15,     3] loss: 1.143
[16,     3] loss: 1.072
[17,     3] loss: 1.089
[18,     3] loss: 1.062
[19,     3] loss: 1.111
[20,     3] loss: 1.136
[21,     3] loss: 1.068
[22,     3] loss: 1.073
[23,     3] loss: 1.051
[24,     3] loss: 1.098
[25,     3] loss: 1.026
[26,     3] loss: 1.035
[27,     3] loss: 1.042
[28,     3] loss: 0.949
[29,     3] loss: 0.954
[30,     3] loss: 0.956
[31,     3] loss: 0.896
[32,     3] loss: 0.952
[33,     3] loss: 0.925
[34,     3] loss: 0.899
[35,     3] loss: 0.942
[36,     3] loss: 0.950
[37,     3] loss: 0.992
[38,     3] loss: 0.977
[39,     3] loss: 0.916
[40,     3] loss: 0.890
[41,     3] loss: 0.882
[42,     3] loss: 0.855
[43,     3] loss: 0.875
[44,     3] loss: 0.942
[45,     3] loss: 0.896
[46,     3] loss: 0.878
[47,     3] loss: 0.858
[48,     3] loss: 0.875
[49,     3] loss: 0.850
[50,     3] loss: 0.875
[51,     3] loss: 0.856
[52,     3] loss: 0.895
[53,     3] loss: 0.894
[54,     3] loss: 0.843
[55,     3] loss: 0.853
[56,     3] loss: 0.924
[57,     3] loss: 0.916
[58,     3] loss: 0.891
[59,     3] loss: 0.824
[60,     3] loss: 0.875
[61,     3] loss: 0.832
[62,     3] loss: 0.835
[63,     3] loss: 0.828
[64,     3] loss: 0.824
[65,     3] loss: 0.830
[66,     3] loss: 0.922
[67,     3] loss: 0.830
[68,     3] loss: 0.821
[69,     3] loss: 0.826
[70,     3] loss: 0.831
[71,     3] loss: 0.815
[72,     3] loss: 0.824
[73,     3] loss: 0.794
[74,     3] loss: 0.824
[75,     3] loss: 0.794
[76,     3] loss: 0.782
[77,     3] loss: 0.822
[78,     3] loss: 0.867
[79,     3] loss: 0.889
[80,     3] loss: 0.796
[81,     3] loss: 0.823
[82,     3] loss: 0.842
[83,     3] loss: 0.868
[84,     3] loss: 0.933
Early stopping applied (best metric=0.5149097442626953)
Finished Training
Total time taken: 18.6430721282959
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.385
[3,     3] loss: 1.385
[4,     3] loss: 1.376
[5,     3] loss: 1.387
[6,     3] loss: 1.376
[7,     3] loss: 1.368
[8,     3] loss: 1.373
[9,     3] loss: 1.356
[10,     3] loss: 1.327
[11,     3] loss: 1.322
[12,     3] loss: 1.317
[13,     3] loss: 1.324
[14,     3] loss: 1.256
[15,     3] loss: 1.253
[16,     3] loss: 1.273
[17,     3] loss: 1.135
[18,     3] loss: 1.180
[19,     3] loss: 1.123
[20,     3] loss: 1.104
[21,     3] loss: 1.063
[22,     3] loss: 1.169
[23,     3] loss: 1.016
[24,     3] loss: 0.991
[25,     3] loss: 1.083
[26,     3] loss: 0.975
[27,     3] loss: 0.968
[28,     3] loss: 0.982
[29,     3] loss: 0.930
[30,     3] loss: 0.921
[31,     3] loss: 0.912
[32,     3] loss: 0.921
[33,     3] loss: 0.941
[34,     3] loss: 0.877
[35,     3] loss: 0.940
[36,     3] loss: 0.889
[37,     3] loss: 0.909
[38,     3] loss: 0.905
[39,     3] loss: 0.895
[40,     3] loss: 1.011
[41,     3] loss: 0.946
[42,     3] loss: 0.955
[43,     3] loss: 0.867
[44,     3] loss: 0.921
[45,     3] loss: 0.824
[46,     3] loss: 0.856
[47,     3] loss: 0.932
[48,     3] loss: 0.869
[49,     3] loss: 0.913
[50,     3] loss: 0.833
[51,     3] loss: 0.832
[52,     3] loss: 0.813
[53,     3] loss: 0.885
[54,     3] loss: 0.868
[55,     3] loss: 0.883
[56,     3] loss: 0.800
[57,     3] loss: 0.833
[58,     3] loss: 0.783
[59,     3] loss: 0.779
[60,     3] loss: 0.846
[61,     3] loss: 0.779
[62,     3] loss: 0.791
[63,     3] loss: 0.790
[64,     3] loss: 0.775
[65,     3] loss: 0.777
[66,     3] loss: 0.857
[67,     3] loss: 0.834
[68,     3] loss: 0.908
[69,     3] loss: 0.792
[70,     3] loss: 0.804
[71,     3] loss: 0.810
[72,     3] loss: 0.808
[73,     3] loss: 0.795
[74,     3] loss: 0.786
[75,     3] loss: 0.825
[76,     3] loss: 0.802
[77,     3] loss: 0.771
[78,     3] loss: 0.812
[79,     3] loss: 0.805
[80,     3] loss: 0.851
[81,     3] loss: 0.902
[82,     3] loss: 0.964
[83,     3] loss: 0.814
[84,     3] loss: 0.908
[85,     3] loss: 0.777
[86,     3] loss: 0.817
[87,     3] loss: 0.803
[88,     3] loss: 0.788
[89,     3] loss: 0.761
[90,     3] loss: 0.783
[91,     3] loss: 0.802
[92,     3] loss: 0.770
[93,     3] loss: 0.807
[94,     3] loss: 0.776
[95,     3] loss: 0.765
[96,     3] loss: 0.759
[97,     3] loss: 0.754
[98,     3] loss: 0.744
[99,     3] loss: 0.754
[100,     3] loss: 0.767
[101,     3] loss: 0.851
[102,     3] loss: 0.843
[103,     3] loss: 0.799
[104,     3] loss: 0.765
[105,     3] loss: 0.772
[106,     3] loss: 0.780
[107,     3] loss: 0.757
[108,     3] loss: 0.746
[109,     3] loss: 0.784
[110,     3] loss: 0.734
[111,     3] loss: 0.753
[112,     3] loss: 0.761
[113,     3] loss: 0.743
Early stopping applied (best metric=0.5214266180992126)
Finished Training
Total time taken: 25.0381076335907
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.405
[3,     3] loss: 1.389
[4,     3] loss: 1.388
[5,     3] loss: 1.385
[6,     3] loss: 1.383
[7,     3] loss: 1.387
[8,     3] loss: 1.380
[9,     3] loss: 1.378
[10,     3] loss: 1.371
[11,     3] loss: 1.366
[12,     3] loss: 1.363
[13,     3] loss: 1.347
[14,     3] loss: 1.332
[15,     3] loss: 1.320
[16,     3] loss: 1.290
[17,     3] loss: 1.255
[18,     3] loss: 1.256
[19,     3] loss: 1.170
[20,     3] loss: 1.154
[21,     3] loss: 1.169
[22,     3] loss: 1.036
[23,     3] loss: 1.080
[24,     3] loss: 1.151
[25,     3] loss: 1.154
[26,     3] loss: 1.129
[27,     3] loss: 1.078
[28,     3] loss: 1.013
[29,     3] loss: 1.014
[30,     3] loss: 1.086
[31,     3] loss: 1.073
[32,     3] loss: 1.061
[33,     3] loss: 0.946
[34,     3] loss: 0.989
[35,     3] loss: 1.014
[36,     3] loss: 1.007
[37,     3] loss: 1.042
[38,     3] loss: 1.039
[39,     3] loss: 0.991
[40,     3] loss: 0.903
[41,     3] loss: 0.987
[42,     3] loss: 0.906
[43,     3] loss: 0.895
[44,     3] loss: 1.046
[45,     3] loss: 0.932
[46,     3] loss: 0.878
[47,     3] loss: 0.927
[48,     3] loss: 0.932
[49,     3] loss: 0.877
[50,     3] loss: 0.871
[51,     3] loss: 0.866
[52,     3] loss: 0.856
[53,     3] loss: 0.858
[54,     3] loss: 0.861
[55,     3] loss: 0.954
[56,     3] loss: 0.873
[57,     3] loss: 0.863
[58,     3] loss: 0.880
[59,     3] loss: 0.849
[60,     3] loss: 0.834
[61,     3] loss: 0.829
[62,     3] loss: 0.799
[63,     3] loss: 0.815
[64,     3] loss: 0.813
[65,     3] loss: 0.819
[66,     3] loss: 0.798
[67,     3] loss: 0.796
[68,     3] loss: 0.908
[69,     3] loss: 0.815
[70,     3] loss: 0.809
[71,     3] loss: 0.808
[72,     3] loss: 0.817
[73,     3] loss: 0.840
[74,     3] loss: 0.805
Early stopping applied (best metric=0.49541163444519043)
Finished Training
Total time taken: 16.444455862045288
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.372
[3,     3] loss: 1.385
[4,     3] loss: 1.381
[5,     3] loss: 1.379
[6,     3] loss: 1.365
[7,     3] loss: 1.360
[8,     3] loss: 1.322
[9,     3] loss: 1.325
[10,     3] loss: 1.287
[11,     3] loss: 1.233
[12,     3] loss: 1.209
[13,     3] loss: 1.155
[14,     3] loss: 1.195
[15,     3] loss: 1.193
[16,     3] loss: 1.229
[17,     3] loss: 1.093
[18,     3] loss: 1.058
[19,     3] loss: 1.093
[20,     3] loss: 1.003
[21,     3] loss: 1.003
[22,     3] loss: 0.987
[23,     3] loss: 0.969
[24,     3] loss: 1.067
[25,     3] loss: 0.941
[26,     3] loss: 0.911
[27,     3] loss: 0.986
[28,     3] loss: 0.927
[29,     3] loss: 0.897
[30,     3] loss: 0.979
[31,     3] loss: 0.873
[32,     3] loss: 0.944
[33,     3] loss: 0.907
[34,     3] loss: 0.888
[35,     3] loss: 0.937
[36,     3] loss: 0.898
[37,     3] loss: 0.901
[38,     3] loss: 0.923
[39,     3] loss: 1.017
[40,     3] loss: 0.959
[41,     3] loss: 0.901
[42,     3] loss: 0.870
[43,     3] loss: 0.925
[44,     3] loss: 0.898
[45,     3] loss: 0.953
[46,     3] loss: 0.910
[47,     3] loss: 0.935
[48,     3] loss: 0.855
[49,     3] loss: 0.930
[50,     3] loss: 0.834
[51,     3] loss: 0.842
[52,     3] loss: 0.844
[53,     3] loss: 0.839
[54,     3] loss: 0.825
[55,     3] loss: 0.848
[56,     3] loss: 0.837
[57,     3] loss: 0.805
[58,     3] loss: 0.815
[59,     3] loss: 0.867
[60,     3] loss: 0.924
[61,     3] loss: 0.813
[62,     3] loss: 0.851
[63,     3] loss: 0.847
[64,     3] loss: 0.819
[65,     3] loss: 0.846
[66,     3] loss: 0.849
Early stopping applied (best metric=0.5356220006942749)
Finished Training
Total time taken: 14.635061740875244
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.387
[3,     3] loss: 1.378
[4,     3] loss: 1.375
[5,     3] loss: 1.378
[6,     3] loss: 1.375
[7,     3] loss: 1.370
[8,     3] loss: 1.385
[9,     3] loss: 1.366
[10,     3] loss: 1.336
[11,     3] loss: 1.341
[12,     3] loss: 1.321
[13,     3] loss: 1.260
[14,     3] loss: 1.234
[15,     3] loss: 1.217
[16,     3] loss: 1.179
[17,     3] loss: 1.198
[18,     3] loss: 1.188
[19,     3] loss: 1.159
[20,     3] loss: 1.088
[21,     3] loss: 1.171
[22,     3] loss: 1.056
[23,     3] loss: 1.049
[24,     3] loss: 0.999
[25,     3] loss: 1.029
[26,     3] loss: 1.044
[27,     3] loss: 1.139
[28,     3] loss: 1.013
[29,     3] loss: 1.070
[30,     3] loss: 0.991
[31,     3] loss: 0.945
[32,     3] loss: 0.981
[33,     3] loss: 1.056
[34,     3] loss: 1.152
[35,     3] loss: 0.993
[36,     3] loss: 1.054
[37,     3] loss: 0.969
[38,     3] loss: 1.070
[39,     3] loss: 1.006
[40,     3] loss: 0.902
[41,     3] loss: 0.934
[42,     3] loss: 0.906
[43,     3] loss: 0.910
[44,     3] loss: 0.980
[45,     3] loss: 0.967
[46,     3] loss: 0.920
[47,     3] loss: 0.923
[48,     3] loss: 0.895
[49,     3] loss: 0.925
[50,     3] loss: 0.923
[51,     3] loss: 0.922
[52,     3] loss: 0.935
[53,     3] loss: 0.892
[54,     3] loss: 0.846
[55,     3] loss: 0.898
[56,     3] loss: 0.877
[57,     3] loss: 0.982
[58,     3] loss: 0.971
[59,     3] loss: 0.867
[60,     3] loss: 0.901
[61,     3] loss: 0.843
[62,     3] loss: 0.826
[63,     3] loss: 0.971
[64,     3] loss: 0.878
[65,     3] loss: 0.902
[66,     3] loss: 0.908
[67,     3] loss: 0.818
[68,     3] loss: 0.913
[69,     3] loss: 0.795
[70,     3] loss: 0.811
[71,     3] loss: 0.861
[72,     3] loss: 0.843
[73,     3] loss: 0.814
[74,     3] loss: 0.804
[75,     3] loss: 0.799
[76,     3] loss: 0.814
[77,     3] loss: 0.812
[78,     3] loss: 0.815
[79,     3] loss: 0.783
[80,     3] loss: 0.909
[81,     3] loss: 0.824
[82,     3] loss: 0.875
[83,     3] loss: 0.902
[84,     3] loss: 0.811
[85,     3] loss: 0.937
[86,     3] loss: 0.927
[87,     3] loss: 0.840
[88,     3] loss: 0.889
[89,     3] loss: 0.821
[90,     3] loss: 0.804
[91,     3] loss: 0.801
[92,     3] loss: 0.791
[93,     3] loss: 0.816
[94,     3] loss: 0.807
[95,     3] loss: 0.769
Early stopping applied (best metric=0.5295572280883789)
Finished Training
Total time taken: 21.07506513595581
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.381
[3,     3] loss: 1.382
[4,     3] loss: 1.380
[5,     3] loss: 1.373
[6,     3] loss: 1.384
[7,     3] loss: 1.369
[8,     3] loss: 1.347
[9,     3] loss: 1.349
[10,     3] loss: 1.342
[11,     3] loss: 1.285
[12,     3] loss: 1.230
[13,     3] loss: 1.232
[14,     3] loss: 1.210
[15,     3] loss: 1.129
[16,     3] loss: 1.247
[17,     3] loss: 1.074
[18,     3] loss: 1.147
[19,     3] loss: 1.081
[20,     3] loss: 1.141
[21,     3] loss: 1.125
[22,     3] loss: 1.031
[23,     3] loss: 1.058
[24,     3] loss: 0.976
[25,     3] loss: 0.974
[26,     3] loss: 1.126
[27,     3] loss: 0.932
[28,     3] loss: 0.943
[29,     3] loss: 0.964
[30,     3] loss: 1.046
[31,     3] loss: 0.938
[32,     3] loss: 0.931
[33,     3] loss: 0.933
[34,     3] loss: 0.937
[35,     3] loss: 0.955
[36,     3] loss: 0.879
[37,     3] loss: 0.921
[38,     3] loss: 0.856
[39,     3] loss: 0.916
[40,     3] loss: 0.870
[41,     3] loss: 0.886
[42,     3] loss: 0.861
[43,     3] loss: 0.869
[44,     3] loss: 0.871
[45,     3] loss: 0.827
[46,     3] loss: 0.842
[47,     3] loss: 0.872
[48,     3] loss: 0.808
[49,     3] loss: 0.787
[50,     3] loss: 0.935
[51,     3] loss: 0.882
[52,     3] loss: 0.820
[53,     3] loss: 0.944
[54,     3] loss: 0.835
[55,     3] loss: 0.810
[56,     3] loss: 0.862
[57,     3] loss: 0.920
[58,     3] loss: 0.894
[59,     3] loss: 0.872
[60,     3] loss: 0.863
[61,     3] loss: 0.885
[62,     3] loss: 1.021
[63,     3] loss: 0.883
[64,     3] loss: 0.901
[65,     3] loss: 0.947
[66,     3] loss: 0.854
[67,     3] loss: 0.928
[68,     3] loss: 0.862
[69,     3] loss: 0.865
[70,     3] loss: 0.852
[71,     3] loss: 0.840
[72,     3] loss: 0.797
[73,     3] loss: 0.778
[74,     3] loss: 0.808
[75,     3] loss: 0.795
[76,     3] loss: 0.788
[77,     3] loss: 0.764
[78,     3] loss: 0.768
[79,     3] loss: 0.778
Early stopping applied (best metric=0.5431433916091919)
Finished Training
Total time taken: 17.531070947647095
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.382
[3,     3] loss: 1.390
[4,     3] loss: 1.381
[5,     3] loss: 1.383
[6,     3] loss: 1.389
[7,     3] loss: 1.381
[8,     3] loss: 1.370
[9,     3] loss: 1.367
[10,     3] loss: 1.376
[11,     3] loss: 1.356
[12,     3] loss: 1.364
[13,     3] loss: 1.334
[14,     3] loss: 1.307
[15,     3] loss: 1.265
[16,     3] loss: 1.250
[17,     3] loss: 1.240
[18,     3] loss: 1.209
[19,     3] loss: 1.156
[20,     3] loss: 1.216
[21,     3] loss: 1.124
[22,     3] loss: 1.126
[23,     3] loss: 1.166
[24,     3] loss: 1.125
[25,     3] loss: 1.097
[26,     3] loss: 1.075
[27,     3] loss: 1.026
[28,     3] loss: 0.977
[29,     3] loss: 0.973
[30,     3] loss: 0.916
[31,     3] loss: 0.958
[32,     3] loss: 0.944
[33,     3] loss: 0.944
[34,     3] loss: 1.002
[35,     3] loss: 1.006
[36,     3] loss: 0.914
[37,     3] loss: 0.985
[38,     3] loss: 0.882
[39,     3] loss: 0.892
[40,     3] loss: 0.956
[41,     3] loss: 0.933
[42,     3] loss: 0.868
[43,     3] loss: 0.898
[44,     3] loss: 0.921
[45,     3] loss: 0.961
[46,     3] loss: 0.952
[47,     3] loss: 0.864
[48,     3] loss: 0.873
[49,     3] loss: 0.834
[50,     3] loss: 0.806
[51,     3] loss: 0.805
[52,     3] loss: 0.899
[53,     3] loss: 0.811
[54,     3] loss: 0.846
[55,     3] loss: 0.828
[56,     3] loss: 0.841
[57,     3] loss: 0.850
[58,     3] loss: 0.840
[59,     3] loss: 0.798
[60,     3] loss: 0.803
[61,     3] loss: 0.811
[62,     3] loss: 0.793
[63,     3] loss: 0.851
[64,     3] loss: 0.816
[65,     3] loss: 0.833
[66,     3] loss: 0.843
[67,     3] loss: 0.770
[68,     3] loss: 0.786
[69,     3] loss: 0.812
[70,     3] loss: 0.788
[71,     3] loss: 0.782
Early stopping applied (best metric=0.5123780965805054)
Finished Training
Total time taken: 15.723050117492676
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.389
[3,     3] loss: 1.388
[4,     3] loss: 1.393
[5,     3] loss: 1.379
[6,     3] loss: 1.383
[7,     3] loss: 1.380
[8,     3] loss: 1.384
[9,     3] loss: 1.373
[10,     3] loss: 1.361
[11,     3] loss: 1.362
[12,     3] loss: 1.335
[13,     3] loss: 1.325
[14,     3] loss: 1.304
[15,     3] loss: 1.261
[16,     3] loss: 1.221
[17,     3] loss: 1.183
[18,     3] loss: 1.222
[19,     3] loss: 1.228
[20,     3] loss: 1.166
[21,     3] loss: 1.044
[22,     3] loss: 1.099
[23,     3] loss: 1.123
[24,     3] loss: 1.053
[25,     3] loss: 0.973
[26,     3] loss: 1.034
[27,     3] loss: 1.085
[28,     3] loss: 0.929
[29,     3] loss: 0.969
[30,     3] loss: 1.037
[31,     3] loss: 1.031
[32,     3] loss: 0.969
[33,     3] loss: 0.995
[34,     3] loss: 0.912
[35,     3] loss: 0.939
[36,     3] loss: 0.917
[37,     3] loss: 0.922
[38,     3] loss: 0.931
[39,     3] loss: 0.931
[40,     3] loss: 0.912
[41,     3] loss: 0.901
[42,     3] loss: 0.872
[43,     3] loss: 0.982
[44,     3] loss: 0.867
[45,     3] loss: 0.841
[46,     3] loss: 0.808
[47,     3] loss: 0.830
[48,     3] loss: 0.855
[49,     3] loss: 0.799
[50,     3] loss: 0.804
[51,     3] loss: 0.903
[52,     3] loss: 0.863
[53,     3] loss: 0.835
[54,     3] loss: 0.802
[55,     3] loss: 0.815
[56,     3] loss: 0.861
[57,     3] loss: 0.835
[58,     3] loss: 0.859
[59,     3] loss: 0.835
[60,     3] loss: 0.817
[61,     3] loss: 0.799
[62,     3] loss: 0.817
[63,     3] loss: 0.818
[64,     3] loss: 0.887
[65,     3] loss: 0.850
[66,     3] loss: 0.828
[67,     3] loss: 0.829
[68,     3] loss: 0.816
[69,     3] loss: 0.826
[70,     3] loss: 0.815
[71,     3] loss: 0.868
[72,     3] loss: 0.830
[73,     3] loss: 0.843
[74,     3] loss: 0.841
[75,     3] loss: 0.858
[76,     3] loss: 0.927
[77,     3] loss: 0.866
[78,     3] loss: 0.831
[79,     3] loss: 0.862
[80,     3] loss: 0.894
[81,     3] loss: 0.856
[82,     3] loss: 0.866
[83,     3] loss: 0.918
[84,     3] loss: 0.882
[85,     3] loss: 0.794
Early stopping applied (best metric=0.5284339189529419)
Finished Training
Total time taken: 18.89068627357483
{'S-palmitoylation-C Validation Accuracy': 0.6776460592617798, 'S-palmitoylation-C Validation Sensitivity': 0.2524092409240924, 'S-palmitoylation-C Validation Specificity': 0.7842385189529374, 'S-palmitoylation-C Validation Precision': 0.23231459649429687, 'S-palmitoylation-C AUC ROC': 0.5451423264104238, 'S-palmitoylation-C AUC PR': 0.22590073594279422, 'S-palmitoylation-C MCC': 0.03714634566572247, 'S-palmitoylation-C F1': 0.22019837966574757, 'Validation Loss (S-palmitoylation-C)': 0.5539691050847372, 'Hydroxylation-K Validation Accuracy': 0.7069444444444445, 'Hydroxylation-K Validation Sensitivity': 0.7637037037037037, 'Hydroxylation-K Validation Specificity': 0.6929824561403509, 'Hydroxylation-K Validation Precision': 0.4127583736265928, 'Hydroxylation-K AUC ROC': 0.8051072124756335, 'Hydroxylation-K AUC PR': 0.5479407375437357, 'Hydroxylation-K MCC': 0.3940087246824002, 'Hydroxylation-K F1': 0.5195902738418812, 'Validation Loss (Hydroxylation-K)': 0.5199682633082072, 'Validation Loss (total)': 1.0739373604456584, 'TimeToTrain': 17.59006404876709}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001448670627843527,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3506072038473014,
 'loss_weight_S-palmitoylation-C': 0.427191975835758,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3569601566,
 'sample_weights': [0.647547668785311, 0.057887411863099925],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6115499712299775,
 'weight_decay_Hydroxylation-K': 9.35289790010271,
 'weight_decay_S-palmitoylation-C': 0.04857018349129394}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.385
[3,     3] loss: 1.383
[4,     3] loss: 1.383
[5,     3] loss: 1.383
[6,     3] loss: 1.383
[7,     3] loss: 1.374
[8,     3] loss: 1.370
[9,     3] loss: 1.377
[10,     3] loss: 1.355
[11,     3] loss: 1.338
[12,     3] loss: 1.303
[13,     3] loss: 1.311
[14,     3] loss: 1.247
[15,     3] loss: 1.196
[16,     3] loss: 1.210
[17,     3] loss: 1.175
[18,     3] loss: 1.102
[19,     3] loss: 1.058
[20,     3] loss: 1.100
[21,     3] loss: 1.055
[22,     3] loss: 0.996
[23,     3] loss: 1.009
[24,     3] loss: 1.085
[25,     3] loss: 1.022
[26,     3] loss: 0.995
[27,     3] loss: 0.958
[28,     3] loss: 0.899
[29,     3] loss: 0.914
[30,     3] loss: 0.903
[31,     3] loss: 0.949
[32,     3] loss: 0.948
[33,     3] loss: 0.922
[34,     3] loss: 0.991
[35,     3] loss: 1.149
[36,     3] loss: 0.912
[37,     3] loss: 0.897
[38,     3] loss: 0.966
[39,     3] loss: 0.880
[40,     3] loss: 0.846
[41,     3] loss: 0.894
[42,     3] loss: 0.850
[43,     3] loss: 0.859
[44,     3] loss: 0.892
[45,     3] loss: 0.831
[46,     3] loss: 0.808
[47,     3] loss: 0.805
[48,     3] loss: 0.805
[49,     3] loss: 0.808
[50,     3] loss: 0.796
[51,     3] loss: 0.848
[52,     3] loss: 0.949
[53,     3] loss: 0.890
[54,     3] loss: 0.845
[55,     3] loss: 0.848
[56,     3] loss: 0.848
[57,     3] loss: 0.869
[58,     3] loss: 0.821
[59,     3] loss: 0.867
[60,     3] loss: 0.815
[61,     3] loss: 0.783
[62,     3] loss: 0.770
[63,     3] loss: 0.773
[64,     3] loss: 0.784
[65,     3] loss: 0.854
[66,     3] loss: 0.757
[67,     3] loss: 0.774
[68,     3] loss: 0.817
[69,     3] loss: 0.786
[70,     3] loss: 0.758
Early stopping applied (best metric=0.5506672859191895)
Finished Training
Total time taken: 15.565250158309937
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.375
[3,     3] loss: 1.384
[4,     3] loss: 1.384
[5,     3] loss: 1.371
[6,     3] loss: 1.376
[7,     3] loss: 1.374
[8,     3] loss: 1.345
[9,     3] loss: 1.354
[10,     3] loss: 1.347
[11,     3] loss: 1.320
[12,     3] loss: 1.268
[13,     3] loss: 1.246
[14,     3] loss: 1.266
[15,     3] loss: 1.202
[16,     3] loss: 1.230
[17,     3] loss: 1.148
[18,     3] loss: 1.076
[19,     3] loss: 1.101
[20,     3] loss: 1.136
[21,     3] loss: 0.998
[22,     3] loss: 0.981
[23,     3] loss: 1.027
[24,     3] loss: 0.915
[25,     3] loss: 0.953
[26,     3] loss: 1.033
[27,     3] loss: 0.958
[28,     3] loss: 0.912
[29,     3] loss: 0.937
[30,     3] loss: 0.991
[31,     3] loss: 0.918
[32,     3] loss: 0.907
[33,     3] loss: 0.877
[34,     3] loss: 0.973
[35,     3] loss: 0.989
[36,     3] loss: 0.930
[37,     3] loss: 0.979
[38,     3] loss: 0.944
[39,     3] loss: 0.960
[40,     3] loss: 0.902
[41,     3] loss: 0.954
[42,     3] loss: 0.869
[43,     3] loss: 0.944
[44,     3] loss: 0.904
[45,     3] loss: 0.864
[46,     3] loss: 0.825
[47,     3] loss: 0.879
[48,     3] loss: 0.802
[49,     3] loss: 0.839
[50,     3] loss: 0.824
[51,     3] loss: 0.810
[52,     3] loss: 0.767
[53,     3] loss: 0.825
[54,     3] loss: 0.794
[55,     3] loss: 0.790
[56,     3] loss: 0.810
[57,     3] loss: 0.809
[58,     3] loss: 0.792
[59,     3] loss: 0.818
[60,     3] loss: 0.820
[61,     3] loss: 0.798
[62,     3] loss: 0.789
[63,     3] loss: 0.792
[64,     3] loss: 0.798
[65,     3] loss: 0.804
[66,     3] loss: 0.873
[67,     3] loss: 0.797
[68,     3] loss: 0.773
[69,     3] loss: 0.797
[70,     3] loss: 0.819
[71,     3] loss: 0.866
[72,     3] loss: 0.878
[73,     3] loss: 0.866
[74,     3] loss: 0.864
[75,     3] loss: 0.821
[76,     3] loss: 0.888
[77,     3] loss: 0.788
[78,     3] loss: 0.850
[79,     3] loss: 0.808
[80,     3] loss: 0.848
[81,     3] loss: 0.842
[82,     3] loss: 0.846
[83,     3] loss: 0.828
[84,     3] loss: 0.787
[85,     3] loss: 0.861
Early stopping applied (best metric=0.529456377029419)
Finished Training
Total time taken: 18.88086986541748
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.386
[3,     3] loss: 1.387
[4,     3] loss: 1.389
[5,     3] loss: 1.384
[6,     3] loss: 1.382
[7,     3] loss: 1.387
[8,     3] loss: 1.388
[9,     3] loss: 1.383
[10,     3] loss: 1.378
[11,     3] loss: 1.369
[12,     3] loss: 1.394
[13,     3] loss: 1.380
[14,     3] loss: 1.379
[15,     3] loss: 1.382
[16,     3] loss: 1.381
[17,     3] loss: 1.379
[18,     3] loss: 1.370
[19,     3] loss: 1.362
[20,     3] loss: 1.345
[21,     3] loss: 1.320
[22,     3] loss: 1.312
[23,     3] loss: 1.304
[24,     3] loss: 1.321
[25,     3] loss: 1.301
[26,     3] loss: 1.286
[27,     3] loss: 1.246
[28,     3] loss: 1.211
[29,     3] loss: 1.179
[30,     3] loss: 1.185
[31,     3] loss: 1.120
[32,     3] loss: 1.087
[33,     3] loss: 1.050
[34,     3] loss: 1.070
[35,     3] loss: 0.973
[36,     3] loss: 0.974
[37,     3] loss: 0.956
[38,     3] loss: 1.064
[39,     3] loss: 1.017
[40,     3] loss: 0.888
[41,     3] loss: 0.944
[42,     3] loss: 0.969
[43,     3] loss: 1.048
[44,     3] loss: 1.071
[45,     3] loss: 0.935
[46,     3] loss: 0.922
[47,     3] loss: 0.982
[48,     3] loss: 0.883
[49,     3] loss: 0.946
[50,     3] loss: 0.926
[51,     3] loss: 0.923
[52,     3] loss: 0.941
[53,     3] loss: 1.055
[54,     3] loss: 0.976
[55,     3] loss: 0.922
[56,     3] loss: 0.928
[57,     3] loss: 0.897
[58,     3] loss: 0.910
[59,     3] loss: 0.935
[60,     3] loss: 0.953
[61,     3] loss: 0.894
[62,     3] loss: 0.845
[63,     3] loss: 0.870
[64,     3] loss: 0.836
[65,     3] loss: 0.874
[66,     3] loss: 0.815
[67,     3] loss: 0.814
[68,     3] loss: 0.830
[69,     3] loss: 0.875
[70,     3] loss: 0.849
[71,     3] loss: 0.803
[72,     3] loss: 0.886
[73,     3] loss: 0.841
[74,     3] loss: 0.821
[75,     3] loss: 0.835
[76,     3] loss: 0.806
[77,     3] loss: 0.830
[78,     3] loss: 0.801
[79,     3] loss: 0.776
Early stopping applied (best metric=0.4983906149864197)
Finished Training
Total time taken: 17.615158081054688
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.386
[3,     3] loss: 1.390
[4,     3] loss: 1.385
[5,     3] loss: 1.385
[6,     3] loss: 1.390
[7,     3] loss: 1.386
[8,     3] loss: 1.385
[9,     3] loss: 1.378
[10,     3] loss: 1.388
[11,     3] loss: 1.371
[12,     3] loss: 1.364
[13,     3] loss: 1.366
[14,     3] loss: 1.340
[15,     3] loss: 1.340
[16,     3] loss: 1.331
[17,     3] loss: 1.267
[18,     3] loss: 1.291
[19,     3] loss: 1.215
[20,     3] loss: 1.194
[21,     3] loss: 1.148
[22,     3] loss: 1.093
[23,     3] loss: 1.060
[24,     3] loss: 1.124
[25,     3] loss: 1.078
[26,     3] loss: 1.105
[27,     3] loss: 1.039
[28,     3] loss: 1.112
[29,     3] loss: 0.960
[30,     3] loss: 1.001
[31,     3] loss: 0.989
[32,     3] loss: 0.961
[33,     3] loss: 0.964
[34,     3] loss: 1.044
[35,     3] loss: 0.975
[36,     3] loss: 0.908
[37,     3] loss: 1.022
[38,     3] loss: 0.968
[39,     3] loss: 1.013
[40,     3] loss: 0.934
[41,     3] loss: 0.944
[42,     3] loss: 0.946
[43,     3] loss: 0.936
[44,     3] loss: 0.933
[45,     3] loss: 0.885
[46,     3] loss: 0.972
[47,     3] loss: 0.899
[48,     3] loss: 0.925
[49,     3] loss: 0.829
[50,     3] loss: 0.844
[51,     3] loss: 0.827
[52,     3] loss: 0.853
[53,     3] loss: 0.811
[54,     3] loss: 0.819
[55,     3] loss: 0.850
[56,     3] loss: 0.881
[57,     3] loss: 0.784
[58,     3] loss: 0.821
[59,     3] loss: 0.889
[60,     3] loss: 0.797
[61,     3] loss: 0.858
[62,     3] loss: 0.958
[63,     3] loss: 0.905
[64,     3] loss: 0.931
[65,     3] loss: 1.030
[66,     3] loss: 0.960
[67,     3] loss: 1.008
[68,     3] loss: 0.857
[69,     3] loss: 0.883
[70,     3] loss: 0.885
[71,     3] loss: 0.891
[72,     3] loss: 0.823
Early stopping applied (best metric=0.4704364538192749)
Finished Training
Total time taken: 16.05305027961731
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.389
[3,     3] loss: 1.386
[4,     3] loss: 1.389
[5,     3] loss: 1.380
[6,     3] loss: 1.403
[7,     3] loss: 1.389
[8,     3] loss: 1.385
[9,     3] loss: 1.387
[10,     3] loss: 1.384
[11,     3] loss: 1.383
[12,     3] loss: 1.385
[13,     3] loss: 1.385
[14,     3] loss: 1.382
[15,     3] loss: 1.384
[16,     3] loss: 1.383
[17,     3] loss: 1.383
[18,     3] loss: 1.380
[19,     3] loss: 1.371
[20,     3] loss: 1.373
[21,     3] loss: 1.363
[22,     3] loss: 1.330
[23,     3] loss: 1.312
[24,     3] loss: 1.285
[25,     3] loss: 1.244
[26,     3] loss: 1.259
[27,     3] loss: 1.142
[28,     3] loss: 1.158
[29,     3] loss: 1.154
[30,     3] loss: 1.080
[31,     3] loss: 1.047
[32,     3] loss: 1.038
[33,     3] loss: 1.022
[34,     3] loss: 1.019
[35,     3] loss: 1.103
[36,     3] loss: 1.207
[37,     3] loss: 1.042
[38,     3] loss: 1.065
[39,     3] loss: 1.084
[40,     3] loss: 0.992
[41,     3] loss: 1.021
[42,     3] loss: 0.980
[43,     3] loss: 1.014
[44,     3] loss: 0.901
[45,     3] loss: 0.945
[46,     3] loss: 0.914
[47,     3] loss: 0.862
[48,     3] loss: 0.905
[49,     3] loss: 0.952
[50,     3] loss: 0.972
[51,     3] loss: 0.868
[52,     3] loss: 0.892
[53,     3] loss: 0.859
[54,     3] loss: 0.934
[55,     3] loss: 0.918
[56,     3] loss: 0.855
[57,     3] loss: 0.889
[58,     3] loss: 0.974
[59,     3] loss: 0.903
[60,     3] loss: 0.803
[61,     3] loss: 0.861
[62,     3] loss: 0.852
[63,     3] loss: 0.848
[64,     3] loss: 0.803
[65,     3] loss: 0.959
[66,     3] loss: 0.979
[67,     3] loss: 0.831
[68,     3] loss: 0.828
[69,     3] loss: 0.871
[70,     3] loss: 0.866
[71,     3] loss: 0.877
[72,     3] loss: 0.818
[73,     3] loss: 0.837
[74,     3] loss: 0.839
[75,     3] loss: 0.865
[76,     3] loss: 0.790
[77,     3] loss: 0.801
[78,     3] loss: 0.790
[79,     3] loss: 0.853
Early stopping applied (best metric=0.5092027187347412)
Finished Training
Total time taken: 17.63305640220642
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.381
[3,     3] loss: 1.390
[4,     3] loss: 1.392
[5,     3] loss: 1.387
[6,     3] loss: 1.386
[7,     3] loss: 1.384
[8,     3] loss: 1.386
[9,     3] loss: 1.382
[10,     3] loss: 1.385
[11,     3] loss: 1.385
[12,     3] loss: 1.377
[13,     3] loss: 1.377
[14,     3] loss: 1.381
[15,     3] loss: 1.367
[16,     3] loss: 1.363
[17,     3] loss: 1.362
[18,     3] loss: 1.324
[19,     3] loss: 1.366
[20,     3] loss: 1.325
[21,     3] loss: 1.309
[22,     3] loss: 1.288
[23,     3] loss: 1.341
[24,     3] loss: 1.256
[25,     3] loss: 1.210
[26,     3] loss: 1.257
[27,     3] loss: 1.204
[28,     3] loss: 1.170
[29,     3] loss: 1.133
[30,     3] loss: 1.138
[31,     3] loss: 1.052
[32,     3] loss: 1.047
[33,     3] loss: 1.063
[34,     3] loss: 0.993
[35,     3] loss: 1.038
[36,     3] loss: 0.938
[37,     3] loss: 0.973
[38,     3] loss: 0.956
[39,     3] loss: 0.968
[40,     3] loss: 0.917
[41,     3] loss: 0.962
[42,     3] loss: 0.991
[43,     3] loss: 1.010
[44,     3] loss: 1.052
[45,     3] loss: 0.943
[46,     3] loss: 0.959
[47,     3] loss: 0.965
[48,     3] loss: 0.937
[49,     3] loss: 0.939
[50,     3] loss: 1.004
[51,     3] loss: 0.937
[52,     3] loss: 0.887
[53,     3] loss: 0.894
[54,     3] loss: 0.856
[55,     3] loss: 0.943
[56,     3] loss: 0.852
[57,     3] loss: 0.860
[58,     3] loss: 0.879
[59,     3] loss: 0.872
[60,     3] loss: 0.893
[61,     3] loss: 0.838
[62,     3] loss: 0.892
[63,     3] loss: 0.836
[64,     3] loss: 0.879
[65,     3] loss: 0.787
[66,     3] loss: 0.945
[67,     3] loss: 0.870
[68,     3] loss: 1.009
[69,     3] loss: 0.913
[70,     3] loss: 0.919
[71,     3] loss: 0.877
[72,     3] loss: 0.886
[73,     3] loss: 0.879
[74,     3] loss: 0.930
[75,     3] loss: 0.921
[76,     3] loss: 0.833
[77,     3] loss: 0.849
[78,     3] loss: 0.825
[79,     3] loss: 0.849
[80,     3] loss: 0.798
[81,     3] loss: 0.801
[82,     3] loss: 0.863
Early stopping applied (best metric=0.5038760304450989)
Finished Training
Total time taken: 18.264057159423828
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.384
[3,     3] loss: 1.384
[4,     3] loss: 1.381
[5,     3] loss: 1.379
[6,     3] loss: 1.376
[7,     3] loss: 1.369
[8,     3] loss: 1.365
[9,     3] loss: 1.326
[10,     3] loss: 1.313
[11,     3] loss: 1.281
[12,     3] loss: 1.277
[13,     3] loss: 1.224
[14,     3] loss: 1.267
[15,     3] loss: 1.148
[16,     3] loss: 1.150
[17,     3] loss: 1.161
[18,     3] loss: 1.125
[19,     3] loss: 1.116
[20,     3] loss: 1.055
[21,     3] loss: 0.994
[22,     3] loss: 1.019
[23,     3] loss: 1.063
[24,     3] loss: 0.929
[25,     3] loss: 0.919
[26,     3] loss: 0.987
[27,     3] loss: 0.862
[28,     3] loss: 0.903
[29,     3] loss: 0.915
[30,     3] loss: 0.858
[31,     3] loss: 1.003
[32,     3] loss: 0.912
[33,     3] loss: 0.942
[34,     3] loss: 0.908
[35,     3] loss: 0.921
[36,     3] loss: 0.932
[37,     3] loss: 0.896
[38,     3] loss: 1.000
[39,     3] loss: 0.967
[40,     3] loss: 0.986
[41,     3] loss: 0.883
[42,     3] loss: 0.857
[43,     3] loss: 0.900
[44,     3] loss: 0.869
[45,     3] loss: 0.928
[46,     3] loss: 0.888
[47,     3] loss: 0.876
[48,     3] loss: 0.946
[49,     3] loss: 0.968
[50,     3] loss: 0.803
[51,     3] loss: 0.851
[52,     3] loss: 0.822
[53,     3] loss: 0.834
[54,     3] loss: 0.806
[55,     3] loss: 0.785
[56,     3] loss: 0.844
[57,     3] loss: 0.793
[58,     3] loss: 0.789
[59,     3] loss: 0.801
[60,     3] loss: 0.833
[61,     3] loss: 0.759
[62,     3] loss: 0.800
[63,     3] loss: 0.764
[64,     3] loss: 0.776
[65,     3] loss: 0.774
[66,     3] loss: 0.756
[67,     3] loss: 0.813
[68,     3] loss: 0.795
[69,     3] loss: 0.772
[70,     3] loss: 0.796
Early stopping applied (best metric=0.5294961929321289)
Finished Training
Total time taken: 15.561120986938477
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.386
[3,     3] loss: 1.382
[4,     3] loss: 1.386
[5,     3] loss: 1.384
[6,     3] loss: 1.381
[7,     3] loss: 1.374
[8,     3] loss: 1.374
[9,     3] loss: 1.363
[10,     3] loss: 1.350
[11,     3] loss: 1.339
[12,     3] loss: 1.318
[13,     3] loss: 1.289
[14,     3] loss: 1.258
[15,     3] loss: 1.247
[16,     3] loss: 1.217
[17,     3] loss: 1.208
[18,     3] loss: 1.119
[19,     3] loss: 1.178
[20,     3] loss: 1.077
[21,     3] loss: 1.122
[22,     3] loss: 1.067
[23,     3] loss: 1.172
[24,     3] loss: 1.127
[25,     3] loss: 1.066
[26,     3] loss: 0.994
[27,     3] loss: 0.995
[28,     3] loss: 1.048
[29,     3] loss: 0.931
[30,     3] loss: 0.872
[31,     3] loss: 0.888
[32,     3] loss: 0.939
[33,     3] loss: 0.877
[34,     3] loss: 0.916
[35,     3] loss: 0.852
[36,     3] loss: 0.999
[37,     3] loss: 0.845
[38,     3] loss: 0.950
[39,     3] loss: 0.930
[40,     3] loss: 0.928
[41,     3] loss: 0.959
[42,     3] loss: 0.877
[43,     3] loss: 0.899
[44,     3] loss: 0.899
[45,     3] loss: 0.964
[46,     3] loss: 0.879
[47,     3] loss: 0.942
[48,     3] loss: 0.834
[49,     3] loss: 0.882
[50,     3] loss: 0.822
[51,     3] loss: 0.822
[52,     3] loss: 0.808
[53,     3] loss: 0.824
[54,     3] loss: 0.852
[55,     3] loss: 0.790
[56,     3] loss: 0.910
[57,     3] loss: 0.824
[58,     3] loss: 0.797
[59,     3] loss: 0.871
[60,     3] loss: 0.783
[61,     3] loss: 0.822
[62,     3] loss: 0.781
[63,     3] loss: 0.794
[64,     3] loss: 0.783
[65,     3] loss: 0.807
[66,     3] loss: 0.789
Early stopping applied (best metric=0.4657764434814453)
Finished Training
Total time taken: 14.71605658531189
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.404
[3,     3] loss: 1.381
[4,     3] loss: 1.381
[5,     3] loss: 1.386
[6,     3] loss: 1.380
[7,     3] loss: 1.382
[8,     3] loss: 1.378
[9,     3] loss: 1.374
[10,     3] loss: 1.362
[11,     3] loss: 1.359
[12,     3] loss: 1.342
[13,     3] loss: 1.322
[14,     3] loss: 1.294
[15,     3] loss: 1.291
[16,     3] loss: 1.277
[17,     3] loss: 1.250
[18,     3] loss: 1.232
[19,     3] loss: 1.203
[20,     3] loss: 1.186
[21,     3] loss: 1.144
[22,     3] loss: 1.061
[23,     3] loss: 1.067
[24,     3] loss: 1.076
[25,     3] loss: 1.024
[26,     3] loss: 1.012
[27,     3] loss: 1.005
[28,     3] loss: 1.084
[29,     3] loss: 1.043
[30,     3] loss: 1.013
[31,     3] loss: 0.929
[32,     3] loss: 1.000
[33,     3] loss: 0.921
[34,     3] loss: 0.965
[35,     3] loss: 0.866
[36,     3] loss: 0.877
[37,     3] loss: 0.944
[38,     3] loss: 0.981
[39,     3] loss: 0.847
[40,     3] loss: 0.928
[41,     3] loss: 0.994
[42,     3] loss: 0.878
[43,     3] loss: 0.865
[44,     3] loss: 0.907
[45,     3] loss: 0.893
[46,     3] loss: 0.853
[47,     3] loss: 0.871
[48,     3] loss: 0.953
[49,     3] loss: 0.811
[50,     3] loss: 0.838
[51,     3] loss: 0.865
[52,     3] loss: 0.869
[53,     3] loss: 0.855
[54,     3] loss: 0.813
[55,     3] loss: 0.868
[56,     3] loss: 0.824
[57,     3] loss: 0.830
[58,     3] loss: 0.873
[59,     3] loss: 0.887
[60,     3] loss: 0.790
[61,     3] loss: 0.908
[62,     3] loss: 0.894
[63,     3] loss: 0.917
[64,     3] loss: 0.888
[65,     3] loss: 0.821
[66,     3] loss: 0.840
[67,     3] loss: 0.836
[68,     3] loss: 0.887
[69,     3] loss: 0.818
[70,     3] loss: 0.815
[71,     3] loss: 0.793
[72,     3] loss: 0.800
[73,     3] loss: 0.814
[74,     3] loss: 0.834
[75,     3] loss: 0.828
[76,     3] loss: 0.815
[77,     3] loss: 0.790
[78,     3] loss: 0.789
[79,     3] loss: 0.787
[80,     3] loss: 0.793
[81,     3] loss: 0.742
[82,     3] loss: 0.803
[83,     3] loss: 0.810
Early stopping applied (best metric=0.5013455152511597)
Finished Training
Total time taken: 18.389057159423828
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.391
[3,     3] loss: 1.387
[4,     3] loss: 1.386
[5,     3] loss: 1.389
[6,     3] loss: 1.390
[7,     3] loss: 1.387
[8,     3] loss: 1.384
[9,     3] loss: 1.387
[10,     3] loss: 1.384
[11,     3] loss: 1.387
[12,     3] loss: 1.382
[13,     3] loss: 1.388
[14,     3] loss: 1.384
[15,     3] loss: 1.385
[16,     3] loss: 1.380
[17,     3] loss: 1.375
[18,     3] loss: 1.382
[19,     3] loss: 1.374
[20,     3] loss: 1.365
[21,     3] loss: 1.343
[22,     3] loss: 1.329
[23,     3] loss: 1.308
[24,     3] loss: 1.298
[25,     3] loss: 1.259
[26,     3] loss: 1.189
[27,     3] loss: 1.170
[28,     3] loss: 1.132
[29,     3] loss: 1.133
[30,     3] loss: 1.054
[31,     3] loss: 1.151
[32,     3] loss: 1.056
[33,     3] loss: 0.984
[34,     3] loss: 1.063
[35,     3] loss: 0.976
[36,     3] loss: 1.056
[37,     3] loss: 0.980
[38,     3] loss: 0.964
[39,     3] loss: 0.913
[40,     3] loss: 0.926
[41,     3] loss: 1.133
[42,     3] loss: 1.061
[43,     3] loss: 0.983
[44,     3] loss: 0.971
[45,     3] loss: 0.885
[46,     3] loss: 0.984
[47,     3] loss: 1.055
[48,     3] loss: 1.037
[49,     3] loss: 0.927
[50,     3] loss: 0.936
[51,     3] loss: 1.049
[52,     3] loss: 0.923
[53,     3] loss: 0.887
[54,     3] loss: 0.877
[55,     3] loss: 0.913
[56,     3] loss: 0.901
[57,     3] loss: 0.861
[58,     3] loss: 0.913
[59,     3] loss: 0.947
[60,     3] loss: 0.915
[61,     3] loss: 0.837
[62,     3] loss: 0.859
[63,     3] loss: 0.811
[64,     3] loss: 0.837
[65,     3] loss: 0.836
[66,     3] loss: 0.928
[67,     3] loss: 0.852
[68,     3] loss: 0.827
[69,     3] loss: 0.856
[70,     3] loss: 0.839
[71,     3] loss: 0.812
[72,     3] loss: 0.843
[73,     3] loss: 0.822
[74,     3] loss: 0.838
[75,     3] loss: 0.791
[76,     3] loss: 0.781
[77,     3] loss: 0.838
[78,     3] loss: 0.816
[79,     3] loss: 0.845
Early stopping applied (best metric=0.4722941517829895)
Finished Training
Total time taken: 17.75005531311035
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.387
[3,     3] loss: 1.389
[4,     3] loss: 1.388
[5,     3] loss: 1.390
[6,     3] loss: 1.396
[7,     3] loss: 1.381
[8,     3] loss: 1.381
[9,     3] loss: 1.373
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.379
[13,     3] loss: 1.369
[14,     3] loss: 1.379
[15,     3] loss: 1.358
[16,     3] loss: 1.347
[17,     3] loss: 1.317
[18,     3] loss: 1.298
[19,     3] loss: 1.280
[20,     3] loss: 1.191
[21,     3] loss: 1.133
[22,     3] loss: 1.099
[23,     3] loss: 1.121
[24,     3] loss: 1.023
[25,     3] loss: 1.165
[26,     3] loss: 1.163
[27,     3] loss: 1.034
[28,     3] loss: 1.040
[29,     3] loss: 1.106
[30,     3] loss: 1.072
[31,     3] loss: 1.146
[32,     3] loss: 1.008
[33,     3] loss: 0.996
[34,     3] loss: 0.965
[35,     3] loss: 0.983
[36,     3] loss: 0.884
[37,     3] loss: 0.970
[38,     3] loss: 0.938
[39,     3] loss: 0.892
[40,     3] loss: 0.872
[41,     3] loss: 0.968
[42,     3] loss: 0.981
[43,     3] loss: 1.117
[44,     3] loss: 0.925
[45,     3] loss: 0.951
[46,     3] loss: 0.919
[47,     3] loss: 0.905
[48,     3] loss: 0.960
[49,     3] loss: 0.985
[50,     3] loss: 0.917
[51,     3] loss: 0.908
[52,     3] loss: 0.834
[53,     3] loss: 0.895
[54,     3] loss: 0.901
[55,     3] loss: 0.851
[56,     3] loss: 0.846
[57,     3] loss: 0.860
[58,     3] loss: 0.840
[59,     3] loss: 0.849
[60,     3] loss: 0.793
[61,     3] loss: 0.874
[62,     3] loss: 0.832
[63,     3] loss: 0.884
[64,     3] loss: 0.806
[65,     3] loss: 0.894
[66,     3] loss: 0.789
[67,     3] loss: 0.799
[68,     3] loss: 0.830
[69,     3] loss: 0.798
[70,     3] loss: 0.839
[71,     3] loss: 0.846
[72,     3] loss: 0.846
[73,     3] loss: 0.828
Early stopping applied (best metric=0.503269612789154)
Finished Training
Total time taken: 16.207048654556274
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.389
[4,     3] loss: 1.374
[5,     3] loss: 1.380
[6,     3] loss: 1.372
[7,     3] loss: 1.363
[8,     3] loss: 1.366
[9,     3] loss: 1.344
[10,     3] loss: 1.328
[11,     3] loss: 1.301
[12,     3] loss: 1.296
[13,     3] loss: 1.289
[14,     3] loss: 1.237
[15,     3] loss: 1.202
[16,     3] loss: 1.199
[17,     3] loss: 1.194
[18,     3] loss: 1.146
[19,     3] loss: 1.040
[20,     3] loss: 1.116
[21,     3] loss: 1.091
[22,     3] loss: 1.079
[23,     3] loss: 1.040
[24,     3] loss: 1.016
[25,     3] loss: 0.990
[26,     3] loss: 1.069
[27,     3] loss: 1.014
[28,     3] loss: 1.001
[29,     3] loss: 0.992
[30,     3] loss: 0.905
[31,     3] loss: 0.910
[32,     3] loss: 0.870
[33,     3] loss: 0.882
[34,     3] loss: 0.877
[35,     3] loss: 0.918
[36,     3] loss: 0.884
[37,     3] loss: 0.904
[38,     3] loss: 0.867
[39,     3] loss: 0.870
[40,     3] loss: 0.879
[41,     3] loss: 0.831
[42,     3] loss: 0.946
[43,     3] loss: 0.884
[44,     3] loss: 0.888
[45,     3] loss: 0.869
[46,     3] loss: 0.831
[47,     3] loss: 0.885
[48,     3] loss: 0.917
[49,     3] loss: 0.890
[50,     3] loss: 0.891
[51,     3] loss: 0.822
[52,     3] loss: 0.839
[53,     3] loss: 0.843
[54,     3] loss: 0.909
[55,     3] loss: 0.871
[56,     3] loss: 0.933
[57,     3] loss: 0.914
[58,     3] loss: 0.832
[59,     3] loss: 0.810
[60,     3] loss: 0.799
[61,     3] loss: 0.805
[62,     3] loss: 0.793
[63,     3] loss: 0.804
[64,     3] loss: 0.802
[65,     3] loss: 0.872
[66,     3] loss: 0.895
[67,     3] loss: 0.810
Early stopping applied (best metric=0.5196235179901123)
Finished Training
Total time taken: 14.895655632019043
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.381
[3,     3] loss: 1.390
[4,     3] loss: 1.387
[5,     3] loss: 1.383
[6,     3] loss: 1.381
[7,     3] loss: 1.382
[8,     3] loss: 1.374
[9,     3] loss: 1.370
[10,     3] loss: 1.365
[11,     3] loss: 1.353
[12,     3] loss: 1.345
[13,     3] loss: 1.349
[14,     3] loss: 1.355
[15,     3] loss: 1.283
[16,     3] loss: 1.260
[17,     3] loss: 1.268
[18,     3] loss: 1.233
[19,     3] loss: 1.238
[20,     3] loss: 1.256
[21,     3] loss: 1.246
[22,     3] loss: 1.053
[23,     3] loss: 1.074
[24,     3] loss: 1.044
[25,     3] loss: 1.011
[26,     3] loss: 0.971
[27,     3] loss: 1.049
[28,     3] loss: 1.016
[29,     3] loss: 1.032
[30,     3] loss: 0.970
[31,     3] loss: 1.050
[32,     3] loss: 1.060
[33,     3] loss: 1.087
[34,     3] loss: 0.952
[35,     3] loss: 0.959
[36,     3] loss: 0.997
[37,     3] loss: 1.023
[38,     3] loss: 1.014
[39,     3] loss: 0.962
[40,     3] loss: 0.927
[41,     3] loss: 0.954
[42,     3] loss: 0.959
[43,     3] loss: 0.954
[44,     3] loss: 0.905
[45,     3] loss: 0.930
[46,     3] loss: 0.889
[47,     3] loss: 0.864
[48,     3] loss: 0.858
[49,     3] loss: 0.854
[50,     3] loss: 0.817
[51,     3] loss: 0.826
[52,     3] loss: 0.867
[53,     3] loss: 0.897
[54,     3] loss: 0.909
[55,     3] loss: 0.811
[56,     3] loss: 0.938
[57,     3] loss: 0.876
[58,     3] loss: 0.870
[59,     3] loss: 0.811
[60,     3] loss: 0.858
[61,     3] loss: 0.899
[62,     3] loss: 0.861
[63,     3] loss: 0.793
[64,     3] loss: 0.826
[65,     3] loss: 0.829
[66,     3] loss: 0.876
[67,     3] loss: 0.809
[68,     3] loss: 0.889
[69,     3] loss: 0.806
Early stopping applied (best metric=0.4966760575771332)
Finished Training
Total time taken: 15.37104868888855
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.402
[2,     3] loss: 1.387
[3,     3] loss: 1.392
[4,     3] loss: 1.393
[5,     3] loss: 1.392
[6,     3] loss: 1.382
[7,     3] loss: 1.388
[8,     3] loss: 1.387
[9,     3] loss: 1.390
[10,     3] loss: 1.383
[11,     3] loss: 1.388
[12,     3] loss: 1.383
[13,     3] loss: 1.383
[14,     3] loss: 1.377
[15,     3] loss: 1.377
[16,     3] loss: 1.367
[17,     3] loss: 1.367
[18,     3] loss: 1.349
[19,     3] loss: 1.337
[20,     3] loss: 1.314
[21,     3] loss: 1.264
[22,     3] loss: 1.293
[23,     3] loss: 1.274
[24,     3] loss: 1.229
[25,     3] loss: 1.155
[26,     3] loss: 1.199
[27,     3] loss: 1.086
[28,     3] loss: 1.131
[29,     3] loss: 1.075
[30,     3] loss: 1.137
[31,     3] loss: 1.103
[32,     3] loss: 1.137
[33,     3] loss: 1.072
[34,     3] loss: 1.107
[35,     3] loss: 1.033
[36,     3] loss: 1.076
[37,     3] loss: 1.061
[38,     3] loss: 0.987
[39,     3] loss: 1.008
[40,     3] loss: 0.964
[41,     3] loss: 0.947
[42,     3] loss: 0.899
[43,     3] loss: 0.892
[44,     3] loss: 0.896
[45,     3] loss: 0.882
[46,     3] loss: 0.895
[47,     3] loss: 0.861
[48,     3] loss: 0.870
[49,     3] loss: 0.951
[50,     3] loss: 0.893
[51,     3] loss: 0.877
[52,     3] loss: 0.907
[53,     3] loss: 0.858
[54,     3] loss: 0.891
[55,     3] loss: 0.870
[56,     3] loss: 0.889
[57,     3] loss: 0.926
[58,     3] loss: 0.872
[59,     3] loss: 1.021
[60,     3] loss: 0.905
[61,     3] loss: 0.994
[62,     3] loss: 0.904
[63,     3] loss: 0.861
[64,     3] loss: 0.904
[65,     3] loss: 0.865
[66,     3] loss: 0.868
[67,     3] loss: 0.871
[68,     3] loss: 0.941
[69,     3] loss: 1.042
[70,     3] loss: 0.928
[71,     3] loss: 0.932
[72,     3] loss: 0.898
[73,     3] loss: 1.007
[74,     3] loss: 0.895
[75,     3] loss: 0.883
[76,     3] loss: 0.894
Early stopping applied (best metric=0.48770684003829956)
Finished Training
Total time taken: 16.919435501098633
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.384
[3,     3] loss: 1.391
[4,     3] loss: 1.385
[5,     3] loss: 1.386
[6,     3] loss: 1.383
[7,     3] loss: 1.384
[8,     3] loss: 1.384
[9,     3] loss: 1.382
[10,     3] loss: 1.381
[11,     3] loss: 1.371
[12,     3] loss: 1.380
[13,     3] loss: 1.357
[14,     3] loss: 1.355
[15,     3] loss: 1.350
[16,     3] loss: 1.328
[17,     3] loss: 1.350
[18,     3] loss: 1.328
[19,     3] loss: 1.255
[20,     3] loss: 1.286
[21,     3] loss: 1.219
[22,     3] loss: 1.230
[23,     3] loss: 1.162
[24,     3] loss: 1.210
[25,     3] loss: 1.178
[26,     3] loss: 1.192
[27,     3] loss: 1.128
[28,     3] loss: 1.180
[29,     3] loss: 1.120
[30,     3] loss: 1.125
[31,     3] loss: 1.133
[32,     3] loss: 1.063
[33,     3] loss: 1.068
[34,     3] loss: 1.066
[35,     3] loss: 1.034
[36,     3] loss: 0.937
[37,     3] loss: 1.062
[38,     3] loss: 0.986
[39,     3] loss: 0.946
[40,     3] loss: 0.934
[41,     3] loss: 0.947
[42,     3] loss: 0.922
[43,     3] loss: 1.022
[44,     3] loss: 0.866
[45,     3] loss: 0.976
[46,     3] loss: 0.973
[47,     3] loss: 0.932
[48,     3] loss: 0.890
[49,     3] loss: 0.886
[50,     3] loss: 0.971
[51,     3] loss: 0.894
[52,     3] loss: 0.821
[53,     3] loss: 0.861
[54,     3] loss: 0.868
[55,     3] loss: 0.800
[56,     3] loss: 0.887
[57,     3] loss: 0.875
[58,     3] loss: 0.940
[59,     3] loss: 0.846
[60,     3] loss: 0.816
[61,     3] loss: 0.869
[62,     3] loss: 0.874
[63,     3] loss: 0.852
[64,     3] loss: 0.842
[65,     3] loss: 0.839
[66,     3] loss: 0.800
[67,     3] loss: 0.771
[68,     3] loss: 0.808
[69,     3] loss: 0.782
[70,     3] loss: 0.777
[71,     3] loss: 0.783
[72,     3] loss: 0.791
[73,     3] loss: 0.822
[74,     3] loss: 0.764
[75,     3] loss: 0.753
[76,     3] loss: 0.765
[77,     3] loss: 0.796
[78,     3] loss: 0.777
[79,     3] loss: 0.772
[80,     3] loss: 0.808
[81,     3] loss: 0.791
[82,     3] loss: 0.784
[83,     3] loss: 0.773
[84,     3] loss: 0.815
[85,     3] loss: 0.858
[86,     3] loss: 0.848
[87,     3] loss: 0.791
[88,     3] loss: 0.836
[89,     3] loss: 0.824
[90,     3] loss: 0.874
[91,     3] loss: 0.858
[92,     3] loss: 0.832
[93,     3] loss: 0.859
[94,     3] loss: 0.831
[95,     3] loss: 0.825
[96,     3] loss: 0.795
Early stopping applied (best metric=0.49458879232406616)
Finished Training
Total time taken: 21.315070152282715
{'S-palmitoylation-C Validation Accuracy': 0.6939430066940984, 'S-palmitoylation-C Validation Sensitivity': 0.22508250825082507, 'S-palmitoylation-C Validation Specificity': 0.811469227401572, 'S-palmitoylation-C Validation Precision': 0.23216731303846466, 'S-palmitoylation-C AUC ROC': 0.5427666153157659, 'S-palmitoylation-C AUC PR': 0.2238625329455906, 'S-palmitoylation-C MCC': 0.037138576687399644, 'S-palmitoylation-C F1': 0.20957171794187468, 'Validation Loss (S-palmitoylation-C)': 0.5550771156946818, 'Hydroxylation-K Validation Accuracy': 0.7184988179669031, 'Hydroxylation-K Validation Sensitivity': 0.8096296296296296, 'Hydroxylation-K Validation Specificity': 0.6964912280701754, 'Hydroxylation-K Validation Precision': 0.41892612144572927, 'Hydroxylation-K AUC ROC': 0.827738791423002, 'Hydroxylation-K AUC PR': 0.5825322246486179, 'Hydroxylation-K MCC': 0.4251632318615749, 'Hydroxylation-K F1': 0.5418097878882193, 'Validation Loss (Hydroxylation-K)': 0.5021871070067088, 'Validation Loss (total)': 1.05726424853007, 'TimeToTrain': 17.00906604131063}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 1.764655967237904e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.25970268148191294,
 'loss_weight_S-palmitoylation-C': 0.6767736519691636,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1016910148,
 'sample_weights': [0.427191975835758, 0.3506072038473014],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7565010899290125,
 'weight_decay_Hydroxylation-K': 1.3842785919964056,
 'weight_decay_S-palmitoylation-C': 0.06200200399530753}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.391
[3,     3] loss: 1.395
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000524200636502986,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.49016105572198954,
 'loss_weight_S-palmitoylation-C': 0.24157179136281842,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3039453499,
 'sample_weights': [0.6767736519691636, 0.25970268148191294],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.761069929157289,
 'weight_decay_Hydroxylation-K': 5.857640285680451,
 'weight_decay_S-palmitoylation-C': 2.7860803790939324}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.383
[3,     3] loss: 1.381
[4,     3] loss: 1.378
[5,     3] loss: 1.378
[6,     3] loss: 1.383
[7,     3] loss: 1.387
[8,     3] loss: 1.374
[9,     3] loss: 1.374
[10,     3] loss: 1.363
[11,     3] loss: 1.352
[12,     3] loss: 1.350
[13,     3] loss: 1.312
[14,     3] loss: 1.296
[15,     3] loss: 1.317
[16,     3] loss: 1.257
[17,     3] loss: 1.238
[18,     3] loss: 1.243
[19,     3] loss: 1.222
[20,     3] loss: 1.157
[21,     3] loss: 1.166
[22,     3] loss: 1.105
[23,     3] loss: 1.037
[24,     3] loss: 1.149
[25,     3] loss: 1.027
[26,     3] loss: 1.003
[27,     3] loss: 0.976
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008059595353851009,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6279853548087233,
 'loss_weight_S-palmitoylation-C': 0.8912915827925596,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 537763577,
 'sample_weights': [0.24157179136281842, 0.49016105572198954],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.529717679305117,
 'weight_decay_Hydroxylation-K': 4.307599255998135,
 'weight_decay_S-palmitoylation-C': 8.756321073145397}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.411
[2,     3] loss: 1.392
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032130860994335486,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3423280289497176,
 'loss_weight_S-palmitoylation-C': 0.8196033197008189,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1735605519,
 'sample_weights': [0.8912915827925596, 0.6279853548087233],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.4578370457553715,
 'weight_decay_Hydroxylation-K': 1.2647491861460483,
 'weight_decay_S-palmitoylation-C': 2.14273598976764}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.385
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000580378263608532,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.015640327857666614,
 'loss_weight_S-palmitoylation-C': 0.014405228930331637,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 497632079,
 'sample_weights': [0.8196033197008189, 0.3423280289497176],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.9772171862304555,
 'weight_decay_Hydroxylation-K': 0.37745316376141513,
 'weight_decay_S-palmitoylation-C': 8.06617536395088}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.383
[3,     3] loss: 1.391
[4,     3] loss: 1.380
[5,     3] loss: 1.378
[6,     3] loss: 1.379
[7,     3] loss: 1.389
[8,     3] loss: 1.389
[9,     3] loss: 1.375
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013129388050108473,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.44617764188642617,
 'loss_weight_S-palmitoylation-C': 0.9188686224274163,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 889150729,
 'sample_weights': [0.014405228930331637, 0.015640327857666614],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3029564488827297,
 'weight_decay_Hydroxylation-K': 2.682198789964289,
 'weight_decay_S-palmitoylation-C': 0.610087811526109}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.383
[3,     3] loss: 1.377
[4,     3] loss: 1.396
[5,     3] loss: 1.394
[6,     3] loss: 1.382
[7,     3] loss: 1.382
[8,     3] loss: 1.379
[9,     3] loss: 1.380
[10,     3] loss: 1.370
[11,     3] loss: 1.367
[12,     3] loss: 1.366
[13,     3] loss: 1.358
[14,     3] loss: 1.344
[15,     3] loss: 1.326
[16,     3] loss: 1.360
[17,     3] loss: 1.298
[18,     3] loss: 1.264
[19,     3] loss: 1.246
[20,     3] loss: 1.169
[21,     3] loss: 1.165
[22,     3] loss: 1.234
[23,     3] loss: 1.107
[24,     3] loss: 1.177
[25,     3] loss: 1.132
[26,     3] loss: 1.086
[27,     3] loss: 1.146
[28,     3] loss: 1.153
[29,     3] loss: 1.106
[30,     3] loss: 1.017
[31,     3] loss: 1.020
[32,     3] loss: 0.971
[33,     3] loss: 0.961
[34,     3] loss: 0.907
[35,     3] loss: 0.939
[36,     3] loss: 0.955
[37,     3] loss: 0.919
[38,     3] loss: 0.912
[39,     3] loss: 0.885
[40,     3] loss: 0.847
[41,     3] loss: 0.864
[42,     3] loss: 0.884
[43,     3] loss: 0.918
[44,     3] loss: 0.818
[45,     3] loss: 0.860
[46,     3] loss: 0.896
[47,     3] loss: 0.789
[48,     3] loss: 0.786
[49,     3] loss: 0.902
[50,     3] loss: 0.850
[51,     3] loss: 0.818
[52,     3] loss: 0.785
[53,     3] loss: 0.819
[54,     3] loss: 0.912
[55,     3] loss: 0.874
[56,     3] loss: 0.888
[57,     3] loss: 0.787
[58,     3] loss: 0.820
[59,     3] loss: 0.759
[60,     3] loss: 0.779
[61,     3] loss: 0.756
[62,     3] loss: 0.803
[63,     3] loss: 0.749
[64,     3] loss: 0.874
[65,     3] loss: 0.758
[66,     3] loss: 0.766
[67,     3] loss: 0.747
[68,     3] loss: 0.749
[69,     3] loss: 0.819
[70,     3] loss: 0.817
[71,     3] loss: 0.891
[72,     3] loss: 0.780
[73,     3] loss: 0.829
[74,     3] loss: 0.747
[75,     3] loss: 0.836
[76,     3] loss: 0.768
[77,     3] loss: 0.857
Early stopping applied (best metric=0.499200701713562)
Finished Training
Total time taken: 17.12606430053711
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.385
[3,     3] loss: 1.388
[4,     3] loss: 1.386
[5,     3] loss: 1.374
[6,     3] loss: 1.377
[7,     3] loss: 1.367
[8,     3] loss: 1.387
[9,     3] loss: 1.353
[10,     3] loss: 1.352
[11,     3] loss: 1.347
[12,     3] loss: 1.347
[13,     3] loss: 1.262
[14,     3] loss: 1.289
[15,     3] loss: 1.235
[16,     3] loss: 1.241
[17,     3] loss: 1.158
[18,     3] loss: 1.148
[19,     3] loss: 1.103
[20,     3] loss: 1.095
[21,     3] loss: 1.033
[22,     3] loss: 1.034
[23,     3] loss: 0.887
[24,     3] loss: 1.012
[25,     3] loss: 1.072
[26,     3] loss: 0.977
[27,     3] loss: 0.967
[28,     3] loss: 0.997
[29,     3] loss: 1.010
[30,     3] loss: 0.906
[31,     3] loss: 0.887
[32,     3] loss: 0.842
[33,     3] loss: 1.003
[34,     3] loss: 0.869
[35,     3] loss: 0.850
[36,     3] loss: 0.840
[37,     3] loss: 0.881
[38,     3] loss: 0.855
[39,     3] loss: 0.827
[40,     3] loss: 0.896
[41,     3] loss: 0.972
[42,     3] loss: 0.895
[43,     3] loss: 0.881
[44,     3] loss: 0.840
[45,     3] loss: 0.863
[46,     3] loss: 0.805
[47,     3] loss: 0.820
[48,     3] loss: 0.887
[49,     3] loss: 0.813
[50,     3] loss: 0.806
[51,     3] loss: 0.806
[52,     3] loss: 0.805
[53,     3] loss: 0.748
[54,     3] loss: 0.802
[55,     3] loss: 0.783
[56,     3] loss: 0.761
[57,     3] loss: 0.785
[58,     3] loss: 0.746
[59,     3] loss: 0.784
[60,     3] loss: 0.746
[61,     3] loss: 0.758
[62,     3] loss: 0.744
[63,     3] loss: 0.768
[64,     3] loss: 0.815
[65,     3] loss: 0.769
[66,     3] loss: 0.834
[67,     3] loss: 0.737
[68,     3] loss: 0.786
[69,     3] loss: 0.808
[70,     3] loss: 0.741
[71,     3] loss: 0.793
[72,     3] loss: 0.762
[73,     3] loss: 0.764
[74,     3] loss: 0.796
[75,     3] loss: 0.877
[76,     3] loss: 0.818
[77,     3] loss: 0.770
[78,     3] loss: 0.797
[79,     3] loss: 0.826
[80,     3] loss: 0.783
[81,     3] loss: 0.838
[82,     3] loss: 0.799
Early stopping applied (best metric=0.5328235030174255)
Finished Training
Total time taken: 18.200058698654175
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.383
[3,     3] loss: 1.380
[4,     3] loss: 1.388
[5,     3] loss: 1.374
[6,     3] loss: 1.393
[7,     3] loss: 1.384
[8,     3] loss: 1.366
[9,     3] loss: 1.355
[10,     3] loss: 1.332
[11,     3] loss: 1.321
[12,     3] loss: 1.314
[13,     3] loss: 1.330
[14,     3] loss: 1.247
[15,     3] loss: 1.248
[16,     3] loss: 1.187
[17,     3] loss: 1.231
[18,     3] loss: 1.151
[19,     3] loss: 1.239
[20,     3] loss: 1.269
[21,     3] loss: 1.149
[22,     3] loss: 1.084
[23,     3] loss: 1.132
[24,     3] loss: 1.038
[25,     3] loss: 1.061
[26,     3] loss: 0.976
[27,     3] loss: 1.143
[28,     3] loss: 0.985
[29,     3] loss: 1.078
[30,     3] loss: 0.967
[31,     3] loss: 0.985
[32,     3] loss: 1.024
[33,     3] loss: 1.053
[34,     3] loss: 1.014
[35,     3] loss: 0.906
[36,     3] loss: 0.962
[37,     3] loss: 0.908
[38,     3] loss: 0.891
[39,     3] loss: 0.893
[40,     3] loss: 0.895
[41,     3] loss: 0.916
[42,     3] loss: 0.835
[43,     3] loss: 0.828
[44,     3] loss: 0.924
[45,     3] loss: 0.849
[46,     3] loss: 0.798
[47,     3] loss: 0.962
[48,     3] loss: 0.937
[49,     3] loss: 0.811
[50,     3] loss: 0.975
[51,     3] loss: 0.898
[52,     3] loss: 0.780
[53,     3] loss: 0.878
[54,     3] loss: 0.889
[55,     3] loss: 0.910
[56,     3] loss: 0.815
[57,     3] loss: 0.832
[58,     3] loss: 0.819
[59,     3] loss: 0.788
[60,     3] loss: 0.841
[61,     3] loss: 0.867
[62,     3] loss: 0.814
[63,     3] loss: 0.779
[64,     3] loss: 0.864
[65,     3] loss: 0.778
[66,     3] loss: 0.863
[67,     3] loss: 0.861
[68,     3] loss: 0.783
[69,     3] loss: 0.842
[70,     3] loss: 0.804
[71,     3] loss: 0.802
[72,     3] loss: 0.774
[73,     3] loss: 0.768
[74,     3] loss: 0.751
[75,     3] loss: 0.761
[76,     3] loss: 0.748
[77,     3] loss: 0.753
[78,     3] loss: 0.735
[79,     3] loss: 0.727
[80,     3] loss: 0.717
[81,     3] loss: 0.738
[82,     3] loss: 0.760
[83,     3] loss: 0.743
[84,     3] loss: 0.739
[85,     3] loss: 0.776
[86,     3] loss: 0.762
[87,     3] loss: 0.772
[88,     3] loss: 1.100
[89,     3] loss: 0.822
[90,     3] loss: 0.842
[91,     3] loss: 0.899
[92,     3] loss: 0.896
[93,     3] loss: 0.836
[94,     3] loss: 0.811
[95,     3] loss: 0.778
[96,     3] loss: 0.767
[97,     3] loss: 0.805
[98,     3] loss: 0.746
Early stopping applied (best metric=0.5195417404174805)
Finished Training
Total time taken: 21.821067571640015
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.391
[3,     3] loss: 1.386
[4,     3] loss: 1.386
[5,     3] loss: 1.385
[6,     3] loss: 1.374
[7,     3] loss: 1.372
[8,     3] loss: 1.367
[9,     3] loss: 1.355
[10,     3] loss: 1.351
[11,     3] loss: 1.335
[12,     3] loss: 1.334
[13,     3] loss: 1.300
[14,     3] loss: 1.271
[15,     3] loss: 1.260
[16,     3] loss: 1.204
[17,     3] loss: 1.278
[18,     3] loss: 1.213
[19,     3] loss: 1.154
[20,     3] loss: 1.114
[21,     3] loss: 1.106
[22,     3] loss: 1.163
[23,     3] loss: 1.050
[24,     3] loss: 1.165
[25,     3] loss: 1.049
[26,     3] loss: 1.026
[27,     3] loss: 0.990
[28,     3] loss: 0.980
[29,     3] loss: 1.030
[30,     3] loss: 0.951
[31,     3] loss: 0.964
[32,     3] loss: 0.889
[33,     3] loss: 1.106
[34,     3] loss: 0.864
[35,     3] loss: 0.896
[36,     3] loss: 0.858
[37,     3] loss: 0.889
[38,     3] loss: 1.039
[39,     3] loss: 1.145
[40,     3] loss: 0.973
[41,     3] loss: 0.880
[42,     3] loss: 1.022
[43,     3] loss: 0.900
[44,     3] loss: 0.949
[45,     3] loss: 0.844
[46,     3] loss: 0.924
[47,     3] loss: 0.851
[48,     3] loss: 0.843
[49,     3] loss: 0.836
[50,     3] loss: 0.817
[51,     3] loss: 0.822
[52,     3] loss: 0.789
[53,     3] loss: 0.744
[54,     3] loss: 0.750
[55,     3] loss: 0.760
[56,     3] loss: 0.806
[57,     3] loss: 0.772
[58,     3] loss: 0.734
[59,     3] loss: 0.860
[60,     3] loss: 0.751
[61,     3] loss: 0.736
[62,     3] loss: 0.738
[63,     3] loss: 0.792
[64,     3] loss: 0.739
[65,     3] loss: 0.798
[66,     3] loss: 0.829
[67,     3] loss: 0.774
[68,     3] loss: 0.741
[69,     3] loss: 0.739
[70,     3] loss: 0.772
[71,     3] loss: 0.786
[72,     3] loss: 0.777
[73,     3] loss: 0.816
Early stopping applied (best metric=0.5047251582145691)
Finished Training
Total time taken: 16.287049531936646
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.384
[3,     3] loss: 1.393
[4,     3] loss: 1.368
[5,     3] loss: 1.381
[6,     3] loss: 1.356
[7,     3] loss: 1.345
[8,     3] loss: 1.318
[9,     3] loss: 1.328
[10,     3] loss: 1.297
[11,     3] loss: 1.295
[12,     3] loss: 1.312
[13,     3] loss: 1.263
[14,     3] loss: 1.211
[15,     3] loss: 1.209
[16,     3] loss: 1.200
[17,     3] loss: 1.192
[18,     3] loss: 1.084
[19,     3] loss: 1.106
[20,     3] loss: 1.031
[21,     3] loss: 1.012
[22,     3] loss: 1.100
[23,     3] loss: 0.966
[24,     3] loss: 1.038
[25,     3] loss: 0.964
[26,     3] loss: 1.002
[27,     3] loss: 1.244
[28,     3] loss: 1.152
[29,     3] loss: 1.012
[30,     3] loss: 1.031
[31,     3] loss: 0.919
[32,     3] loss: 0.998
[33,     3] loss: 0.973
[34,     3] loss: 0.925
[35,     3] loss: 0.932
[36,     3] loss: 1.046
[37,     3] loss: 0.899
[38,     3] loss: 0.876
[39,     3] loss: 0.895
[40,     3] loss: 0.909
[41,     3] loss: 0.842
[42,     3] loss: 0.807
[43,     3] loss: 0.999
[44,     3] loss: 1.002
[45,     3] loss: 0.869
[46,     3] loss: 0.917
[47,     3] loss: 0.857
[48,     3] loss: 0.832
[49,     3] loss: 0.877
[50,     3] loss: 0.857
[51,     3] loss: 0.886
[52,     3] loss: 0.871
[53,     3] loss: 0.912
[54,     3] loss: 0.853
[55,     3] loss: 0.823
[56,     3] loss: 0.836
[57,     3] loss: 0.947
[58,     3] loss: 1.061
[59,     3] loss: 0.853
[60,     3] loss: 0.952
[61,     3] loss: 0.817
[62,     3] loss: 0.823
[63,     3] loss: 0.805
[64,     3] loss: 0.790
[65,     3] loss: 0.824
[66,     3] loss: 0.794
[67,     3] loss: 0.767
[68,     3] loss: 0.750
[69,     3] loss: 0.744
[70,     3] loss: 0.767
[71,     3] loss: 0.821
[72,     3] loss: 0.790
Early stopping applied (best metric=0.5039467215538025)
Finished Training
Total time taken: 16.06305241584778
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.380
[4,     3] loss: 1.392
[5,     3] loss: 1.390
[6,     3] loss: 1.382
[7,     3] loss: 1.381
[8,     3] loss: 1.380
[9,     3] loss: 1.378
[10,     3] loss: 1.370
[11,     3] loss: 1.372
[12,     3] loss: 1.358
[13,     3] loss: 1.348
[14,     3] loss: 1.306
[15,     3] loss: 1.317
[16,     3] loss: 1.268
[17,     3] loss: 1.197
[18,     3] loss: 1.264
[19,     3] loss: 1.165
[20,     3] loss: 1.196
[21,     3] loss: 1.127
[22,     3] loss: 1.124
[23,     3] loss: 1.144
[24,     3] loss: 1.133
[25,     3] loss: 1.252
[26,     3] loss: 1.059
[27,     3] loss: 1.037
[28,     3] loss: 1.011
[29,     3] loss: 0.946
[30,     3] loss: 0.929
[31,     3] loss: 0.941
[32,     3] loss: 1.007
[33,     3] loss: 0.995
[34,     3] loss: 1.071
[35,     3] loss: 0.918
[36,     3] loss: 0.979
[37,     3] loss: 0.939
[38,     3] loss: 0.883
[39,     3] loss: 0.997
[40,     3] loss: 0.945
[41,     3] loss: 0.872
[42,     3] loss: 0.884
[43,     3] loss: 0.903
[44,     3] loss: 0.874
[45,     3] loss: 0.859
[46,     3] loss: 1.031
[47,     3] loss: 0.924
[48,     3] loss: 0.915
[49,     3] loss: 0.894
[50,     3] loss: 0.816
[51,     3] loss: 0.835
[52,     3] loss: 0.845
[53,     3] loss: 0.828
[54,     3] loss: 0.860
[55,     3] loss: 0.787
[56,     3] loss: 0.807
[57,     3] loss: 0.889
[58,     3] loss: 0.858
[59,     3] loss: 0.786
[60,     3] loss: 0.761
[61,     3] loss: 0.779
[62,     3] loss: 0.756
[63,     3] loss: 0.734
[64,     3] loss: 0.756
[65,     3] loss: 0.751
[66,     3] loss: 0.743
[67,     3] loss: 0.774
[68,     3] loss: 0.721
[69,     3] loss: 0.731
[70,     3] loss: 0.710
[71,     3] loss: 0.712
[72,     3] loss: 0.721
[73,     3] loss: 0.739
Early stopping applied (best metric=0.5198951959609985)
Finished Training
Total time taken: 16.29605221748352
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.384
[3,     3] loss: 1.390
[4,     3] loss: 1.392
[5,     3] loss: 1.375
[6,     3] loss: 1.373
[7,     3] loss: 1.357
[8,     3] loss: 1.344
[9,     3] loss: 1.326
[10,     3] loss: 1.300
[11,     3] loss: 1.289
[12,     3] loss: 1.262
[13,     3] loss: 1.238
[14,     3] loss: 1.204
[15,     3] loss: 1.092
[16,     3] loss: 1.147
[17,     3] loss: 1.136
[18,     3] loss: 1.108
[19,     3] loss: 1.066
[20,     3] loss: 1.082
[21,     3] loss: 1.020
[22,     3] loss: 1.028
[23,     3] loss: 1.043
[24,     3] loss: 0.915
[25,     3] loss: 0.924
[26,     3] loss: 0.918
[27,     3] loss: 0.899
[28,     3] loss: 0.897
[29,     3] loss: 0.831
[30,     3] loss: 0.916
[31,     3] loss: 0.915
[32,     3] loss: 0.916
[33,     3] loss: 0.929
[34,     3] loss: 0.883
[35,     3] loss: 0.889
[36,     3] loss: 1.006
[37,     3] loss: 0.939
[38,     3] loss: 0.930
[39,     3] loss: 0.796
[40,     3] loss: 0.905
[41,     3] loss: 0.834
[42,     3] loss: 0.794
[43,     3] loss: 0.783
[44,     3] loss: 0.830
[45,     3] loss: 0.813
[46,     3] loss: 0.906
[47,     3] loss: 0.798
[48,     3] loss: 0.854
[49,     3] loss: 0.787
[50,     3] loss: 0.755
[51,     3] loss: 0.792
[52,     3] loss: 0.789
[53,     3] loss: 0.812
[54,     3] loss: 0.766
[55,     3] loss: 0.767
[56,     3] loss: 0.768
[57,     3] loss: 0.730
[58,     3] loss: 0.794
[59,     3] loss: 0.776
[60,     3] loss: 0.792
[61,     3] loss: 0.802
[62,     3] loss: 0.824
[63,     3] loss: 0.907
[64,     3] loss: 0.882
[65,     3] loss: 0.779
[66,     3] loss: 1.001
[67,     3] loss: 0.811
[68,     3] loss: 0.769
[69,     3] loss: 0.843
[70,     3] loss: 0.861
[71,     3] loss: 0.802
[72,     3] loss: 0.814
Early stopping applied (best metric=0.5383564829826355)
Finished Training
Total time taken: 16.00304889678955
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.403
[2,     3] loss: 1.390
[3,     3] loss: 1.385
[4,     3] loss: 1.380
[5,     3] loss: 1.388
[6,     3] loss: 1.396
[7,     3] loss: 1.385
[8,     3] loss: 1.379
[9,     3] loss: 1.379
[10,     3] loss: 1.395
[11,     3] loss: 1.385
[12,     3] loss: 1.378
[13,     3] loss: 1.373
[14,     3] loss: 1.373
[15,     3] loss: 1.381
[16,     3] loss: 1.367
[17,     3] loss: 1.348
[18,     3] loss: 1.346
[19,     3] loss: 1.333
[20,     3] loss: 1.289
[21,     3] loss: 1.357
[22,     3] loss: 1.276
[23,     3] loss: 1.275
[24,     3] loss: 1.207
[25,     3] loss: 1.261
[26,     3] loss: 1.132
[27,     3] loss: 1.216
[28,     3] loss: 1.148
[29,     3] loss: 1.168
[30,     3] loss: 1.105
[31,     3] loss: 1.099
[32,     3] loss: 1.149
[33,     3] loss: 1.101
[34,     3] loss: 1.244
[35,     3] loss: 1.060
[36,     3] loss: 1.128
[37,     3] loss: 1.071
[38,     3] loss: 1.057
[39,     3] loss: 1.011
[40,     3] loss: 1.031
[41,     3] loss: 0.922
[42,     3] loss: 1.037
[43,     3] loss: 0.887
[44,     3] loss: 0.885
[45,     3] loss: 0.839
[46,     3] loss: 0.975
[47,     3] loss: 1.030
[48,     3] loss: 0.820
[49,     3] loss: 0.937
[50,     3] loss: 0.900
[51,     3] loss: 0.847
[52,     3] loss: 0.830
[53,     3] loss: 0.880
[54,     3] loss: 0.862
[55,     3] loss: 0.801
[56,     3] loss: 0.884
[57,     3] loss: 0.806
[58,     3] loss: 0.901
[59,     3] loss: 0.834
[60,     3] loss: 0.876
[61,     3] loss: 0.845
[62,     3] loss: 0.899
[63,     3] loss: 0.808
[64,     3] loss: 0.783
[65,     3] loss: 0.827
[66,     3] loss: 0.936
[67,     3] loss: 0.918
[68,     3] loss: 0.875
[69,     3] loss: 0.845
[70,     3] loss: 0.946
[71,     3] loss: 0.785
[72,     3] loss: 0.877
[73,     3] loss: 0.921
[74,     3] loss: 0.815
[75,     3] loss: 0.829
[76,     3] loss: 0.810
[77,     3] loss: 0.789
[78,     3] loss: 0.819
[79,     3] loss: 0.836
Early stopping applied (best metric=0.5133291482925415)
Finished Training
Total time taken: 17.60605549812317
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.389
[3,     3] loss: 1.377
[4,     3] loss: 1.380
[5,     3] loss: 1.365
[6,     3] loss: 1.358
[7,     3] loss: 1.338
[8,     3] loss: 1.359
[9,     3] loss: 1.319
[10,     3] loss: 1.298
[11,     3] loss: 1.279
[12,     3] loss: 1.238
[13,     3] loss: 1.164
[14,     3] loss: 1.152
[15,     3] loss: 1.107
[16,     3] loss: 1.091
[17,     3] loss: 1.084
[18,     3] loss: 1.070
[19,     3] loss: 1.048
[20,     3] loss: 0.989
[21,     3] loss: 1.105
[22,     3] loss: 1.052
[23,     3] loss: 0.937
[24,     3] loss: 0.930
[25,     3] loss: 0.980
[26,     3] loss: 1.030
[27,     3] loss: 0.861
[28,     3] loss: 1.029
[29,     3] loss: 0.909
[30,     3] loss: 0.850
[31,     3] loss: 1.015
[32,     3] loss: 0.980
[33,     3] loss: 0.893
[34,     3] loss: 0.894
[35,     3] loss: 1.026
[36,     3] loss: 0.943
[37,     3] loss: 0.830
[38,     3] loss: 1.000
[39,     3] loss: 0.940
[40,     3] loss: 0.922
[41,     3] loss: 1.044
[42,     3] loss: 0.861
[43,     3] loss: 0.867
[44,     3] loss: 0.889
[45,     3] loss: 0.912
[46,     3] loss: 0.816
[47,     3] loss: 0.848
[48,     3] loss: 0.857
[49,     3] loss: 0.819
[50,     3] loss: 0.877
[51,     3] loss: 0.780
[52,     3] loss: 0.807
[53,     3] loss: 0.804
[54,     3] loss: 0.871
[55,     3] loss: 0.795
[56,     3] loss: 0.776
[57,     3] loss: 0.778
[58,     3] loss: 0.788
[59,     3] loss: 0.766
[60,     3] loss: 0.770
[61,     3] loss: 0.806
[62,     3] loss: 0.789
[63,     3] loss: 0.778
[64,     3] loss: 0.757
[65,     3] loss: 0.738
[66,     3] loss: 0.755
[67,     3] loss: 0.759
Early stopping applied (best metric=0.5116410255432129)
Finished Training
Total time taken: 14.981048822402954
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.386
[3,     3] loss: 1.380
[4,     3] loss: 1.382
[5,     3] loss: 1.384
[6,     3] loss: 1.384
[7,     3] loss: 1.376
[8,     3] loss: 1.352
[9,     3] loss: 1.356
[10,     3] loss: 1.348
[11,     3] loss: 1.330
[12,     3] loss: 1.300
[13,     3] loss: 1.259
[14,     3] loss: 1.209
[15,     3] loss: 1.234
[16,     3] loss: 1.168
[17,     3] loss: 1.147
[18,     3] loss: 1.108
[19,     3] loss: 1.078
[20,     3] loss: 1.159
[21,     3] loss: 1.071
[22,     3] loss: 1.030
[23,     3] loss: 0.971
[24,     3] loss: 1.040
[25,     3] loss: 1.043
[26,     3] loss: 0.986
[27,     3] loss: 1.015
[28,     3] loss: 0.956
[29,     3] loss: 0.995
[30,     3] loss: 0.981
[31,     3] loss: 0.937
[32,     3] loss: 0.855
[33,     3] loss: 0.912
[34,     3] loss: 0.874
[35,     3] loss: 0.924
[36,     3] loss: 0.837
[37,     3] loss: 0.912
[38,     3] loss: 0.910
[39,     3] loss: 0.834
[40,     3] loss: 0.932
[41,     3] loss: 0.834
[42,     3] loss: 0.877
[43,     3] loss: 0.812
[44,     3] loss: 0.858
[45,     3] loss: 0.818
[46,     3] loss: 0.772
[47,     3] loss: 0.843
[48,     3] loss: 0.848
[49,     3] loss: 0.864
[50,     3] loss: 0.910
[51,     3] loss: 0.804
[52,     3] loss: 1.061
[53,     3] loss: 0.887
[54,     3] loss: 0.812
[55,     3] loss: 0.787
[56,     3] loss: 0.828
[57,     3] loss: 0.786
[58,     3] loss: 0.820
[59,     3] loss: 0.782
[60,     3] loss: 0.782
[61,     3] loss: 0.814
[62,     3] loss: 0.767
[63,     3] loss: 0.788
[64,     3] loss: 0.772
[65,     3] loss: 0.808
[66,     3] loss: 0.747
[67,     3] loss: 0.763
[68,     3] loss: 0.759
[69,     3] loss: 0.771
[70,     3] loss: 0.742
[71,     3] loss: 0.747
[72,     3] loss: 0.728
[73,     3] loss: 0.754
[74,     3] loss: 0.807
[75,     3] loss: 0.751
[76,     3] loss: 0.757
[77,     3] loss: 0.884
[78,     3] loss: 0.775
[79,     3] loss: 0.890
[80,     3] loss: 0.783
[81,     3] loss: 0.789
[82,     3] loss: 0.784
[83,     3] loss: 0.751
[84,     3] loss: 0.815
[85,     3] loss: 0.786
[86,     3] loss: 0.785
[87,     3] loss: 0.759
[88,     3] loss: 0.725
[89,     3] loss: 0.746
[90,     3] loss: 0.733
[91,     3] loss: 0.722
Early stopping applied (best metric=0.5047147870063782)
Finished Training
Total time taken: 20.330073356628418
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.388
[3,     3] loss: 1.392
[4,     3] loss: 1.394
[5,     3] loss: 1.379
[6,     3] loss: 1.382
[7,     3] loss: 1.372
[8,     3] loss: 1.371
[9,     3] loss: 1.356
[10,     3] loss: 1.345
[11,     3] loss: 1.334
[12,     3] loss: 1.285
[13,     3] loss: 1.311
[14,     3] loss: 1.253
[15,     3] loss: 1.249
[16,     3] loss: 1.256
[17,     3] loss: 1.162
[18,     3] loss: 1.186
[19,     3] loss: 1.068
[20,     3] loss: 1.077
[21,     3] loss: 1.066
[22,     3] loss: 1.022
[23,     3] loss: 1.051
[24,     3] loss: 0.970
[25,     3] loss: 0.995
[26,     3] loss: 1.161
[27,     3] loss: 0.928
[28,     3] loss: 0.911
[29,     3] loss: 0.893
[30,     3] loss: 0.928
[31,     3] loss: 0.941
[32,     3] loss: 0.939
[33,     3] loss: 0.901
[34,     3] loss: 0.903
[35,     3] loss: 0.869
[36,     3] loss: 0.990
[37,     3] loss: 0.798
[38,     3] loss: 0.859
[39,     3] loss: 0.827
[40,     3] loss: 0.836
[41,     3] loss: 0.914
[42,     3] loss: 0.942
[43,     3] loss: 0.869
[44,     3] loss: 0.903
[45,     3] loss: 0.871
[46,     3] loss: 0.797
[47,     3] loss: 0.824
[48,     3] loss: 0.850
[49,     3] loss: 0.790
[50,     3] loss: 0.827
[51,     3] loss: 0.788
[52,     3] loss: 0.781
[53,     3] loss: 0.928
[54,     3] loss: 0.885
[55,     3] loss: 0.892
[56,     3] loss: 0.894
[57,     3] loss: 0.866
[58,     3] loss: 0.789
[59,     3] loss: 0.816
[60,     3] loss: 0.857
[61,     3] loss: 0.924
[62,     3] loss: 0.913
[63,     3] loss: 0.811
[64,     3] loss: 0.919
[65,     3] loss: 1.006
[66,     3] loss: 0.805
[67,     3] loss: 0.896
[68,     3] loss: 0.864
[69,     3] loss: 0.911
[70,     3] loss: 0.835
Early stopping applied (best metric=0.5262304544448853)
Finished Training
Total time taken: 15.607048511505127
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.382
[3,     3] loss: 1.386
[4,     3] loss: 1.379
[5,     3] loss: 1.383
[6,     3] loss: 1.377
[7,     3] loss: 1.354
[8,     3] loss: 1.335
[9,     3] loss: 1.349
[10,     3] loss: 1.315
[11,     3] loss: 1.281
[12,     3] loss: 1.267
[13,     3] loss: 1.293
[14,     3] loss: 1.238
[15,     3] loss: 1.209
[16,     3] loss: 1.173
[17,     3] loss: 1.120
[18,     3] loss: 1.122
[19,     3] loss: 1.002
[20,     3] loss: 1.181
[21,     3] loss: 1.093
[22,     3] loss: 0.956
[23,     3] loss: 1.029
[24,     3] loss: 1.046
[25,     3] loss: 1.004
[26,     3] loss: 1.118
[27,     3] loss: 1.069
[28,     3] loss: 1.050
[29,     3] loss: 1.004
[30,     3] loss: 0.923
[31,     3] loss: 0.940
[32,     3] loss: 0.947
[33,     3] loss: 0.969
[34,     3] loss: 0.890
[35,     3] loss: 0.955
[36,     3] loss: 0.857
[37,     3] loss: 0.886
[38,     3] loss: 0.819
[39,     3] loss: 0.824
[40,     3] loss: 0.821
[41,     3] loss: 0.887
[42,     3] loss: 0.803
[43,     3] loss: 0.809
[44,     3] loss: 0.799
[45,     3] loss: 0.836
[46,     3] loss: 0.853
[47,     3] loss: 0.792
[48,     3] loss: 0.825
[49,     3] loss: 0.835
[50,     3] loss: 0.800
[51,     3] loss: 0.881
[52,     3] loss: 0.851
[53,     3] loss: 0.830
[54,     3] loss: 0.789
[55,     3] loss: 0.792
[56,     3] loss: 0.785
[57,     3] loss: 0.791
[58,     3] loss: 0.871
[59,     3] loss: 0.763
[60,     3] loss: 0.738
[61,     3] loss: 0.786
[62,     3] loss: 0.789
Early stopping applied (best metric=0.5275207757949829)
Finished Training
Total time taken: 13.805043697357178
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.407
[2,     3] loss: 1.382
[3,     3] loss: 1.385
[4,     3] loss: 1.388
[5,     3] loss: 1.405
[6,     3] loss: 1.379
[7,     3] loss: 1.388
[8,     3] loss: 1.375
[9,     3] loss: 1.378
[10,     3] loss: 1.380
[11,     3] loss: 1.350
[12,     3] loss: 1.349
[13,     3] loss: 1.329
[14,     3] loss: 1.288
[15,     3] loss: 1.303
[16,     3] loss: 1.313
[17,     3] loss: 1.246
[18,     3] loss: 1.162
[19,     3] loss: 1.180
[20,     3] loss: 1.113
[21,     3] loss: 1.227
[22,     3] loss: 1.171
[23,     3] loss: 1.109
[24,     3] loss: 1.048
[25,     3] loss: 1.012
[26,     3] loss: 1.145
[27,     3] loss: 0.973
[28,     3] loss: 0.989
[29,     3] loss: 1.029
[30,     3] loss: 1.076
[31,     3] loss: 1.018
[32,     3] loss: 1.004
[33,     3] loss: 1.028
[34,     3] loss: 1.043
[35,     3] loss: 1.013
[36,     3] loss: 0.936
[37,     3] loss: 1.021
[38,     3] loss: 0.874
[39,     3] loss: 0.951
[40,     3] loss: 0.923
[41,     3] loss: 0.946
[42,     3] loss: 1.013
[43,     3] loss: 0.945
[44,     3] loss: 0.914
[45,     3] loss: 0.867
[46,     3] loss: 0.929
[47,     3] loss: 0.881
[48,     3] loss: 0.921
[49,     3] loss: 0.885
[50,     3] loss: 0.796
[51,     3] loss: 0.852
[52,     3] loss: 0.923
[53,     3] loss: 0.824
[54,     3] loss: 0.798
[55,     3] loss: 0.811
[56,     3] loss: 0.846
[57,     3] loss: 0.790
[58,     3] loss: 0.792
[59,     3] loss: 0.787
[60,     3] loss: 0.809
[61,     3] loss: 0.812
[62,     3] loss: 0.770
[63,     3] loss: 0.763
[64,     3] loss: 0.903
[65,     3] loss: 0.813
[66,     3] loss: 0.974
[67,     3] loss: 0.823
[68,     3] loss: 0.853
[69,     3] loss: 0.867
[70,     3] loss: 0.806
[71,     3] loss: 0.869
[72,     3] loss: 0.893
[73,     3] loss: 0.807
[74,     3] loss: 0.774
[75,     3] loss: 0.786
[76,     3] loss: 0.820
[77,     3] loss: 0.767
[78,     3] loss: 0.744
[79,     3] loss: 0.784
[80,     3] loss: 0.878
[81,     3] loss: 0.742
[82,     3] loss: 0.769
[83,     3] loss: 0.769
[84,     3] loss: 0.790
[85,     3] loss: 0.784
[86,     3] loss: 0.774
[87,     3] loss: 0.761
[88,     3] loss: 0.752
[89,     3] loss: 0.753
[90,     3] loss: 0.747
[91,     3] loss: 0.749
[92,     3] loss: 0.773
[93,     3] loss: 0.719
[94,     3] loss: 0.804
[95,     3] loss: 0.783
[96,     3] loss: 0.754
[97,     3] loss: 0.771
[98,     3] loss: 0.743
[99,     3] loss: 0.742
[100,     3] loss: 0.731
[101,     3] loss: 0.777
[102,     3] loss: 0.748
[103,     3] loss: 0.761
[104,     3] loss: 0.719
[105,     3] loss: 0.766
[106,     3] loss: 0.736
[107,     3] loss: 0.755
[108,     3] loss: 0.722
[109,     3] loss: 0.824
[110,     3] loss: 0.785
[111,     3] loss: 0.728
[112,     3] loss: 0.812
[113,     3] loss: 0.759
[114,     3] loss: 0.770
[115,     3] loss: 0.746
[116,     3] loss: 0.732
[117,     3] loss: 0.745
[118,     3] loss: 0.749
[119,     3] loss: 0.738
[120,     3] loss: 0.764
[121,     3] loss: 0.715
[122,     3] loss: 0.825
[123,     3] loss: 0.790
[124,     3] loss: 0.722
[125,     3] loss: 0.771
Early stopping applied (best metric=0.4924948215484619)
Finished Training
Total time taken: 27.777099132537842
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.387
[3,     3] loss: 1.386
[4,     3] loss: 1.386
[5,     3] loss: 1.383
[6,     3] loss: 1.380
[7,     3] loss: 1.372
[8,     3] loss: 1.376
[9,     3] loss: 1.378
[10,     3] loss: 1.356
[11,     3] loss: 1.344
[12,     3] loss: 1.322
[13,     3] loss: 1.293
[14,     3] loss: 1.234
[15,     3] loss: 1.270
[16,     3] loss: 1.212
[17,     3] loss: 1.132
[18,     3] loss: 1.172
[19,     3] loss: 1.076
[20,     3] loss: 1.031
[21,     3] loss: 1.077
[22,     3] loss: 1.007
[23,     3] loss: 1.015
[24,     3] loss: 1.088
[25,     3] loss: 0.985
[26,     3] loss: 0.998
[27,     3] loss: 0.992
[28,     3] loss: 1.016
[29,     3] loss: 0.988
[30,     3] loss: 1.016
[31,     3] loss: 0.895
[32,     3] loss: 0.932
[33,     3] loss: 0.939
[34,     3] loss: 0.892
[35,     3] loss: 0.939
[36,     3] loss: 0.920
[37,     3] loss: 0.982
[38,     3] loss: 0.965
[39,     3] loss: 0.914
[40,     3] loss: 0.885
[41,     3] loss: 0.848
[42,     3] loss: 0.884
[43,     3] loss: 0.853
[44,     3] loss: 0.873
[45,     3] loss: 0.856
[46,     3] loss: 0.872
[47,     3] loss: 0.811
[48,     3] loss: 1.009
[49,     3] loss: 0.908
[50,     3] loss: 0.958
[51,     3] loss: 0.863
[52,     3] loss: 1.078
[53,     3] loss: 0.929
[54,     3] loss: 0.949
[55,     3] loss: 0.941
[56,     3] loss: 0.935
[57,     3] loss: 0.851
[58,     3] loss: 0.880
[59,     3] loss: 0.815
[60,     3] loss: 0.862
[61,     3] loss: 0.806
[62,     3] loss: 0.809
[63,     3] loss: 0.765
[64,     3] loss: 0.786
[65,     3] loss: 0.792
[66,     3] loss: 0.754
[67,     3] loss: 0.781
[68,     3] loss: 0.811
[69,     3] loss: 0.748
Early stopping applied (best metric=0.5134636759757996)
Finished Training
Total time taken: 15.511059522628784
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.394
[3,     3] loss: 1.398
[4,     3] loss: 1.387
[5,     3] loss: 1.389
[6,     3] loss: 1.384
[7,     3] loss: 1.384
[8,     3] loss: 1.379
[9,     3] loss: 1.386
[10,     3] loss: 1.380
[11,     3] loss: 1.379
[12,     3] loss: 1.369
[13,     3] loss: 1.354
[14,     3] loss: 1.312
[15,     3] loss: 1.306
[16,     3] loss: 1.289
[17,     3] loss: 1.262
[18,     3] loss: 1.247
[19,     3] loss: 1.251
[20,     3] loss: 1.180
[21,     3] loss: 1.108
[22,     3] loss: 1.088
[23,     3] loss: 1.100
[24,     3] loss: 1.077
[25,     3] loss: 1.150
[26,     3] loss: 1.067
[27,     3] loss: 0.964
[28,     3] loss: 1.060
[29,     3] loss: 1.090
[30,     3] loss: 1.271
[31,     3] loss: 1.019
[32,     3] loss: 0.953
[33,     3] loss: 1.041
[34,     3] loss: 0.948
[35,     3] loss: 0.981
[36,     3] loss: 0.921
[37,     3] loss: 0.966
[38,     3] loss: 0.897
[39,     3] loss: 0.865
[40,     3] loss: 0.829
[41,     3] loss: 0.846
[42,     3] loss: 0.894
[43,     3] loss: 0.803
[44,     3] loss: 0.823
[45,     3] loss: 0.822
[46,     3] loss: 0.813
[47,     3] loss: 0.799
[48,     3] loss: 0.823
[49,     3] loss: 0.867
[50,     3] loss: 0.885
[51,     3] loss: 0.880
[52,     3] loss: 0.944
[53,     3] loss: 0.908
[54,     3] loss: 0.797
[55,     3] loss: 0.789
[56,     3] loss: 0.790
[57,     3] loss: 0.792
[58,     3] loss: 0.767
[59,     3] loss: 0.762
[60,     3] loss: 0.762
[61,     3] loss: 0.763
[62,     3] loss: 0.769
[63,     3] loss: 0.753
[64,     3] loss: 0.757
[65,     3] loss: 0.739
[66,     3] loss: 0.745
[67,     3] loss: 0.771
[68,     3] loss: 0.790
[69,     3] loss: 0.723
[70,     3] loss: 0.757
[71,     3] loss: 0.779
[72,     3] loss: 0.856
[73,     3] loss: 0.836
[74,     3] loss: 0.777
Early stopping applied (best metric=0.4897821843624115)
Finished Training
Total time taken: 16.455050468444824
{'S-palmitoylation-C Validation Accuracy': 0.7085482502294729, 'S-palmitoylation-C Validation Sensitivity': 0.20541254125412542, 'S-palmitoylation-C Validation Specificity': 0.8346656941525122, 'S-palmitoylation-C Validation Precision': 0.24642762765298024, 'S-palmitoylation-C AUC ROC': 0.5429271769602562, 'S-palmitoylation-C AUC PR': 0.22692489522946666, 'S-palmitoylation-C MCC': 0.04443902818331132, 'S-palmitoylation-C F1': 0.20242163650472444, 'Validation Loss (S-palmitoylation-C)': 0.5546561002731323, 'Hydroxylation-K Validation Accuracy': 0.7336879432624114, 'Hydroxylation-K Validation Sensitivity': 0.7696296296296297, 'Hydroxylation-K Validation Specificity': 0.724561403508772, 'Hydroxylation-K Validation Precision': 0.43705194129342734, 'Hydroxylation-K AUC ROC': 0.8114619883040936, 'Hydroxylation-K AUC PR': 0.5847701080274333, 'Hydroxylation-K MCC': 0.42461299646879425, 'Hydroxylation-K F1': 0.5473969868546773, 'Validation Loss (Hydroxylation-K)': 0.5131777584552765, 'Validation Loss (total)': 1.0678338607152302, 'TimeToTrain': 17.591258176167806}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005967114099564868,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.15727455030440163,
 'loss_weight_S-palmitoylation-C': 0.4724821215876892,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 369882257,
 'sample_weights': [0.9188686224274163, 0.44617764188642617],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.030039342880452,
 'weight_decay_Hydroxylation-K': 7.1175210819093575,
 'weight_decay_S-palmitoylation-C': 4.9883441741141805}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.388
[3,     3] loss: 1.390
[4,     3] loss: 1.387
[5,     3] loss: 1.389
[6,     3] loss: 1.390
[7,     3] loss: 1.385
[8,     3] loss: 1.386
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009466150576322732,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2628020492317059,
 'loss_weight_S-palmitoylation-C': 0.8998552427917006,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 52359038,
 'sample_weights': [0.4724821215876892, 0.15727455030440163],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.678568737632027,
 'weight_decay_Hydroxylation-K': 2.2056578093531347,
 'weight_decay_S-palmitoylation-C': 0.9837213765632725}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.378
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033001905630758075,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4209466030545961,
 'loss_weight_S-palmitoylation-C': 0.4891426077185219,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 224989138,
 'sample_weights': [0.8998552427917006, 0.2628020492317059],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.700004212342375,
 'weight_decay_Hydroxylation-K': 0.1198622057184866,
 'weight_decay_S-palmitoylation-C': 0.12255226147271063}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.386
[3,     3] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022273537319246763,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7513061330807983,
 'loss_weight_S-palmitoylation-C': 0.9645397234960207,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 176112229,
 'sample_weights': [0.4891426077185219, 0.4209466030545961],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.898107401224119,
 'weight_decay_Hydroxylation-K': 4.408347171133355,
 'weight_decay_S-palmitoylation-C': 1.2497012645863352}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.390
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0065051640263571915,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4652172671444097,
 'loss_weight_S-palmitoylation-C': 0.08127985721245573,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2289965702,
 'sample_weights': [0.9645397234960207, 0.7513061330807983],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.796164958032351,
 'weight_decay_Hydroxylation-K': 8.718221467670974,
 'weight_decay_S-palmitoylation-C': 3.741613852544144}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.392
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017229974226412026,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21772079641655046,
 'loss_weight_S-palmitoylation-C': 0.048416291704129304,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1012567053,
 'sample_weights': [0.08127985721245573, 0.4652172671444097],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.132540614591651,
 'weight_decay_Hydroxylation-K': 6.621772131250245,
 'weight_decay_S-palmitoylation-C': 0.6944568146231895}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.394
[3,     3] loss: 1.388
[4,     3] loss: 1.387
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.393
[8,     3] loss: 1.389
[9,     3] loss: 1.387
[10,     3] loss: 1.378
[11,     3] loss: 1.378
[12,     3] loss: 1.376
[13,     3] loss: 1.365
[14,     3] loss: 1.362
[15,     3] loss: 1.343
[16,     3] loss: 1.315
[17,     3] loss: 1.303
[18,     3] loss: 1.243
[19,     3] loss: 1.241
[20,     3] loss: 1.119
[21,     3] loss: 1.152
[22,     3] loss: 1.045
[23,     3] loss: 1.079
[24,     3] loss: 1.087
[25,     3] loss: 1.069
[26,     3] loss: 1.222
[27,     3] loss: 1.119
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006169655423478416,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8377085970439327,
 'loss_weight_S-palmitoylation-C': 0.32403954149068914,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3818827909,
 'sample_weights': [0.048416291704129304, 0.21772079641655046],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.587810946458655,
 'weight_decay_Hydroxylation-K': 0.1554505852063056,
 'weight_decay_S-palmitoylation-C': 1.4699598896767168}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.382
[3,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033405063567909523,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.590726795017924,
 'loss_weight_S-palmitoylation-C': 0.8847966339494012,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1121362564,
 'sample_weights': [0.32403954149068914, 0.8377085970439327],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.603466212694203,
 'weight_decay_Hydroxylation-K': 1.6402500964583908,
 'weight_decay_S-palmitoylation-C': 0.06964187408139522}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.402
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007434358047207087,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4266029978534328,
 'loss_weight_S-palmitoylation-C': 0.625207599416508,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1876759857,
 'sample_weights': [0.8847966339494012, 0.590726795017924],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.6194993769190345,
 'weight_decay_Hydroxylation-K': 3.979911144508752,
 'weight_decay_S-palmitoylation-C': 0.972306242490119}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.386
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003244372300307967,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5362004729214718,
 'loss_weight_S-palmitoylation-C': 0.9123985825641369,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 499707106,
 'sample_weights': [0.625207599416508, 0.4266029978534328],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.048561034565495,
 'weight_decay_Hydroxylation-K': 1.7714225149862295,
 'weight_decay_S-palmitoylation-C': 1.6576156027688191}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.381
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004114007457822245,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5058084638012246,
 'loss_weight_S-palmitoylation-C': 0.2558643987933658,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3493324996,
 'sample_weights': [0.9123985825641369, 0.5362004729214718],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.189488007180497,
 'weight_decay_Hydroxylation-K': 9.90685617853952,
 'weight_decay_S-palmitoylation-C': 0.42594317915794805}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.398
[3,     3] loss: 1.390
[4,     3] loss: 1.385
[5,     3] loss: 1.388
[6,     3] loss: 1.386
[7,     3] loss: 1.389
[8,     3] loss: 1.384
[9,     3] loss: 1.385
[10,     3] loss: 1.392
[11,     3] loss: 1.383
[12,     3] loss: 1.387
[13,     3] loss: 1.388
[14,     3] loss: 1.385
[15,     3] loss: 1.388
[16,     3] loss: 1.388
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.385
[25,     3] loss: 1.386
[26,     3] loss: 1.387
[27,     3] loss: 1.387
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.385
[31,     3] loss: 1.387
[32,     3] loss: 1.384
[33,     3] loss: 1.383
[34,     3] loss: 1.383
[35,     3] loss: 1.379
[36,     3] loss: 1.382
[37,     3] loss: 1.371
[38,     3] loss: 1.364
[39,     3] loss: 1.361
[40,     3] loss: 1.374
[41,     3] loss: 1.338
[42,     3] loss: 1.336
[43,     3] loss: 1.358
[44,     3] loss: 1.292
[45,     3] loss: 1.304
[46,     3] loss: 1.293
[47,     3] loss: 1.286
[48,     3] loss: 1.236
[49,     3] loss: 1.228
[50,     3] loss: 1.136
[51,     3] loss: 1.198
[52,     3] loss: 1.205
[53,     3] loss: 1.194
[54,     3] loss: 1.165
[55,     3] loss: 1.143
[56,     3] loss: 1.180
[57,     3] loss: 1.270
[58,     3] loss: 1.201
[59,     3] loss: 1.169
[60,     3] loss: 1.198
[61,     3] loss: 1.071
[62,     3] loss: 1.018
[63,     3] loss: 1.035
[64,     3] loss: 0.985
[65,     3] loss: 1.080
[66,     3] loss: 1.068
[67,     3] loss: 0.979
[68,     3] loss: 1.026
[69,     3] loss: 1.004
[70,     3] loss: 1.040
[71,     3] loss: 1.065
[72,     3] loss: 0.940
[73,     3] loss: 0.961
[74,     3] loss: 0.950
[75,     3] loss: 0.978
[76,     3] loss: 0.915
[77,     3] loss: 0.988
[78,     3] loss: 0.855
[79,     3] loss: 0.947
[80,     3] loss: 0.956
[81,     3] loss: 0.993
[82,     3] loss: 1.016
[83,     3] loss: 0.968
[84,     3] loss: 0.936
[85,     3] loss: 0.996
[86,     3] loss: 0.882
[87,     3] loss: 0.970
[88,     3] loss: 0.993
[89,     3] loss: 1.024
[90,     3] loss: 1.061
[91,     3] loss: 0.963
[92,     3] loss: 0.955
[93,     3] loss: 1.030
[94,     3] loss: 1.002
[95,     3] loss: 0.956
[96,     3] loss: 1.048
[97,     3] loss: 0.902
[98,     3] loss: 1.016
[99,     3] loss: 0.990
[100,     3] loss: 0.883
[101,     3] loss: 0.878
[102,     3] loss: 0.963
[103,     3] loss: 0.885
[104,     3] loss: 0.832
[105,     3] loss: 0.839
[106,     3] loss: 0.861
[107,     3] loss: 0.824
Early stopping applied (best metric=0.4745463728904724)
Finished Training
Total time taken: 23.90507411956787
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.386
[3,     3] loss: 1.381
[4,     3] loss: 1.386
[5,     3] loss: 1.382
[6,     3] loss: 1.381
[7,     3] loss: 1.388
[8,     3] loss: 1.387
[9,     3] loss: 1.385
[10,     3] loss: 1.390
[11,     3] loss: 1.383
[12,     3] loss: 1.383
[13,     3] loss: 1.386
[14,     3] loss: 1.394
[15,     3] loss: 1.389
[16,     3] loss: 1.385
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.387
[25,     3] loss: 1.387
[26,     3] loss: 1.386
[27,     3] loss: 1.386
[28,     3] loss: 1.387
[29,     3] loss: 1.386
[30,     3] loss: 1.387
[31,     3] loss: 1.386
[32,     3] loss: 1.387
[33,     3] loss: 1.387
[34,     3] loss: 1.387
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.386
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.387
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.387
[50,     3] loss: 1.387
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.386
[54,     3] loss: 1.386
[55,     3] loss: 1.386
[56,     3] loss: 1.387
[57,     3] loss: 1.386
[58,     3] loss: 1.387
[59,     3] loss: 1.387
[60,     3] loss: 1.386
[61,     3] loss: 1.386
[62,     3] loss: 1.386
[63,     3] loss: 1.386
[64,     3] loss: 1.386
[65,     3] loss: 1.386
[66,     3] loss: 1.386
[67,     3] loss: 1.386
[68,     3] loss: 1.386
[69,     3] loss: 1.387
[70,     3] loss: 1.387
[71,     3] loss: 1.387
[72,     3] loss: 1.386
[73,     3] loss: 1.386
[74,     3] loss: 1.386
Early stopping applied (best metric=0.5621839761734009)
Finished Training
Total time taken: 16.575051069259644
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.383
[3,     3] loss: 1.396
[4,     3] loss: 1.384
[5,     3] loss: 1.391
[6,     3] loss: 1.384
[7,     3] loss: 1.386
[8,     3] loss: 1.383
[9,     3] loss: 1.387
[10,     3] loss: 1.386
[11,     3] loss: 1.385
[12,     3] loss: 1.390
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.385
[16,     3] loss: 1.385
[17,     3] loss: 1.386
[18,     3] loss: 1.387
[19,     3] loss: 1.386
[20,     3] loss: 1.385
[21,     3] loss: 1.384
[22,     3] loss: 1.384
[23,     3] loss: 1.384
[24,     3] loss: 1.382
[25,     3] loss: 1.377
[26,     3] loss: 1.365
[27,     3] loss: 1.342
[28,     3] loss: 1.308
[29,     3] loss: 1.284
[30,     3] loss: 1.268
[31,     3] loss: 1.225
[32,     3] loss: 1.256
[33,     3] loss: 1.218
[34,     3] loss: 1.282
[35,     3] loss: 1.254
[36,     3] loss: 1.181
[37,     3] loss: 1.230
[38,     3] loss: 1.183
[39,     3] loss: 1.182
[40,     3] loss: 1.088
[41,     3] loss: 1.062
[42,     3] loss: 1.063
[43,     3] loss: 1.089
[44,     3] loss: 1.040
[45,     3] loss: 1.060
[46,     3] loss: 0.998
[47,     3] loss: 0.971
[48,     3] loss: 0.961
[49,     3] loss: 0.986
[50,     3] loss: 0.964
[51,     3] loss: 0.932
[52,     3] loss: 1.057
[53,     3] loss: 1.028
[54,     3] loss: 0.961
[55,     3] loss: 0.996
[56,     3] loss: 1.002
[57,     3] loss: 0.933
[58,     3] loss: 0.874
[59,     3] loss: 0.862
[60,     3] loss: 0.938
[61,     3] loss: 0.850
[62,     3] loss: 0.929
[63,     3] loss: 0.924
[64,     3] loss: 0.852
[65,     3] loss: 0.845
[66,     3] loss: 0.832
[67,     3] loss: 0.841
[68,     3] loss: 0.830
[69,     3] loss: 0.911
[70,     3] loss: 0.782
[71,     3] loss: 0.860
[72,     3] loss: 0.894
[73,     3] loss: 0.830
[74,     3] loss: 0.823
[75,     3] loss: 0.857
[76,     3] loss: 0.819
[77,     3] loss: 0.884
[78,     3] loss: 0.810
[79,     3] loss: 0.884
[80,     3] loss: 0.849
[81,     3] loss: 0.840
[82,     3] loss: 0.824
[83,     3] loss: 0.913
[84,     3] loss: 0.851
[85,     3] loss: 0.808
[86,     3] loss: 0.920
[87,     3] loss: 0.881
[88,     3] loss: 0.882
[89,     3] loss: 0.946
[90,     3] loss: 0.885
[91,     3] loss: 0.855
[92,     3] loss: 0.881
Early stopping applied (best metric=0.49018430709838867)
Finished Training
Total time taken: 20.534066677093506
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.393
[3,     3] loss: 1.383
[4,     3] loss: 1.394
[5,     3] loss: 1.394
[6,     3] loss: 1.386
[7,     3] loss: 1.385
[8,     3] loss: 1.387
[9,     3] loss: 1.386
[10,     3] loss: 1.384
[11,     3] loss: 1.385
[12,     3] loss: 1.386
[13,     3] loss: 1.385
[14,     3] loss: 1.387
[15,     3] loss: 1.385
[16,     3] loss: 1.383
[17,     3] loss: 1.387
[18,     3] loss: 1.381
[19,     3] loss: 1.377
[20,     3] loss: 1.361
[21,     3] loss: 1.364
[22,     3] loss: 1.331
[23,     3] loss: 1.265
[24,     3] loss: 1.228
[25,     3] loss: 1.281
[26,     3] loss: 1.143
[27,     3] loss: 1.170
[28,     3] loss: 1.116
[29,     3] loss: 1.254
[30,     3] loss: 1.226
[31,     3] loss: 1.191
[32,     3] loss: 1.148
[33,     3] loss: 1.109
[34,     3] loss: 1.065
[35,     3] loss: 1.082
[36,     3] loss: 1.104
[37,     3] loss: 1.108
[38,     3] loss: 1.114
[39,     3] loss: 0.970
[40,     3] loss: 0.969
[41,     3] loss: 1.018
[42,     3] loss: 0.960
[43,     3] loss: 1.000
[44,     3] loss: 0.989
[45,     3] loss: 1.061
[46,     3] loss: 0.996
[47,     3] loss: 1.032
[48,     3] loss: 1.117
[49,     3] loss: 1.108
[50,     3] loss: 1.123
[51,     3] loss: 1.115
[52,     3] loss: 1.047
[53,     3] loss: 1.004
[54,     3] loss: 0.948
[55,     3] loss: 0.968
[56,     3] loss: 0.923
[57,     3] loss: 0.917
[58,     3] loss: 0.933
[59,     3] loss: 0.900
[60,     3] loss: 0.901
[61,     3] loss: 0.921
[62,     3] loss: 0.983
[63,     3] loss: 1.015
[64,     3] loss: 0.939
[65,     3] loss: 1.145
[66,     3] loss: 1.196
[67,     3] loss: 1.008
[68,     3] loss: 1.098
[69,     3] loss: 1.090
[70,     3] loss: 1.024
[71,     3] loss: 0.970
[72,     3] loss: 1.030
[73,     3] loss: 0.939
[74,     3] loss: 0.929
Early stopping applied (best metric=0.51656574010849)
Finished Training
Total time taken: 16.505051851272583
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.390
[3,     3] loss: 1.388
[4,     3] loss: 1.385
[5,     3] loss: 1.386
[6,     3] loss: 1.387
[7,     3] loss: 1.387
[8,     3] loss: 1.388
[9,     3] loss: 1.387
[10,     3] loss: 1.387
[11,     3] loss: 1.384
[12,     3] loss: 1.385
[13,     3] loss: 1.387
[14,     3] loss: 1.385
[15,     3] loss: 1.383
[16,     3] loss: 1.390
[17,     3] loss: 1.384
[18,     3] loss: 1.389
[19,     3] loss: 1.384
[20,     3] loss: 1.386
[21,     3] loss: 1.384
[22,     3] loss: 1.380
[23,     3] loss: 1.375
[24,     3] loss: 1.360
[25,     3] loss: 1.350
[26,     3] loss: 1.310
[27,     3] loss: 1.268
[28,     3] loss: 1.155
[29,     3] loss: 1.319
[30,     3] loss: 1.135
[31,     3] loss: 1.243
[32,     3] loss: 1.206
[33,     3] loss: 1.254
[34,     3] loss: 1.217
[35,     3] loss: 1.195
[36,     3] loss: 1.217
[37,     3] loss: 1.119
[38,     3] loss: 1.136
[39,     3] loss: 1.149
[40,     3] loss: 1.065
[41,     3] loss: 1.050
[42,     3] loss: 0.989
[43,     3] loss: 1.078
[44,     3] loss: 0.959
[45,     3] loss: 1.012
[46,     3] loss: 0.925
[47,     3] loss: 0.977
[48,     3] loss: 1.042
[49,     3] loss: 0.894
[50,     3] loss: 1.079
[51,     3] loss: 0.910
[52,     3] loss: 0.981
[53,     3] loss: 0.963
[54,     3] loss: 1.027
[55,     3] loss: 1.046
[56,     3] loss: 0.948
[57,     3] loss: 1.102
[58,     3] loss: 1.000
[59,     3] loss: 0.968
[60,     3] loss: 0.911
[61,     3] loss: 1.050
[62,     3] loss: 0.905
[63,     3] loss: 0.905
[64,     3] loss: 0.962
[65,     3] loss: 0.842
[66,     3] loss: 0.905
[67,     3] loss: 0.984
[68,     3] loss: 0.900
[69,     3] loss: 0.929
[70,     3] loss: 1.010
[71,     3] loss: 0.929
[72,     3] loss: 0.861
[73,     3] loss: 0.845
[74,     3] loss: 0.817
[75,     3] loss: 0.830
[76,     3] loss: 0.828
[77,     3] loss: 0.846
Early stopping applied (best metric=0.4865361750125885)
Finished Training
Total time taken: 17.170053243637085
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.391
[3,     3] loss: 1.389
[4,     3] loss: 1.388
[5,     3] loss: 1.389
[6,     3] loss: 1.387
[7,     3] loss: 1.385
[8,     3] loss: 1.386
[9,     3] loss: 1.388
[10,     3] loss: 1.387
[11,     3] loss: 1.385
[12,     3] loss: 1.386
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.387
[16,     3] loss: 1.388
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.386
[20,     3] loss: 1.385
[21,     3] loss: 1.385
[22,     3] loss: 1.386
[23,     3] loss: 1.388
[24,     3] loss: 1.385
[25,     3] loss: 1.384
[26,     3] loss: 1.385
[27,     3] loss: 1.380
[28,     3] loss: 1.384
[29,     3] loss: 1.385
[30,     3] loss: 1.386
[31,     3] loss: 1.380
[32,     3] loss: 1.366
[33,     3] loss: 1.401
[34,     3] loss: 1.359
[35,     3] loss: 1.336
[36,     3] loss: 1.277
[37,     3] loss: 1.241
[38,     3] loss: 1.259
[39,     3] loss: 1.229
[40,     3] loss: 1.157
[41,     3] loss: 1.178
[42,     3] loss: 1.132
[43,     3] loss: 1.154
[44,     3] loss: 1.151
[45,     3] loss: 1.175
[46,     3] loss: 1.126
[47,     3] loss: 1.043
[48,     3] loss: 1.159
[49,     3] loss: 1.020
[50,     3] loss: 1.026
[51,     3] loss: 0.987
[52,     3] loss: 1.025
[53,     3] loss: 0.985
[54,     3] loss: 0.950
[55,     3] loss: 1.011
[56,     3] loss: 0.911
[57,     3] loss: 0.949
[58,     3] loss: 0.941
[59,     3] loss: 0.950
[60,     3] loss: 0.960
[61,     3] loss: 0.885
[62,     3] loss: 0.868
[63,     3] loss: 0.878
[64,     3] loss: 0.849
[65,     3] loss: 0.927
[66,     3] loss: 0.847
[67,     3] loss: 0.893
[68,     3] loss: 0.866
[69,     3] loss: 0.913
[70,     3] loss: 0.911
[71,     3] loss: 0.916
[72,     3] loss: 0.918
[73,     3] loss: 0.835
[74,     3] loss: 0.865
[75,     3] loss: 0.851
[76,     3] loss: 0.918
[77,     3] loss: 0.830
[78,     3] loss: 0.843
[79,     3] loss: 0.829
[80,     3] loss: 0.817
[81,     3] loss: 0.833
[82,     3] loss: 0.838
[83,     3] loss: 0.826
[84,     3] loss: 0.887
[85,     3] loss: 1.111
[86,     3] loss: 1.041
[87,     3] loss: 0.987
Early stopping applied (best metric=0.5296261310577393)
Finished Training
Total time taken: 19.255078315734863
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.391
[3,     3] loss: 1.383
[4,     3] loss: 1.391
[5,     3] loss: 1.385
[6,     3] loss: 1.387
[7,     3] loss: 1.385
[8,     3] loss: 1.391
[9,     3] loss: 1.388
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.386
[13,     3] loss: 1.388
[14,     3] loss: 1.388
[15,     3] loss: 1.388
[16,     3] loss: 1.386
[17,     3] loss: 1.387
[18,     3] loss: 1.387
[19,     3] loss: 1.387
[20,     3] loss: 1.386
[21,     3] loss: 1.386
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.386
[26,     3] loss: 1.387
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.387
[31,     3] loss: 1.387
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.386
[35,     3] loss: 1.387
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.387
[39,     3] loss: 1.386
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.386
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.386
[52,     3] loss: 1.386
[53,     3] loss: 1.384
[54,     3] loss: 1.384
[55,     3] loss: 1.381
[56,     3] loss: 1.370
[57,     3] loss: 1.377
[58,     3] loss: 1.371
[59,     3] loss: 1.364
[60,     3] loss: 1.349
[61,     3] loss: 1.384
[62,     3] loss: 1.391
[63,     3] loss: 1.387
[64,     3] loss: 1.385
[65,     3] loss: 1.379
[66,     3] loss: 1.377
[67,     3] loss: 1.347
[68,     3] loss: 1.331
[69,     3] loss: 1.334
[70,     3] loss: 1.243
[71,     3] loss: 1.490
[72,     3] loss: 1.382
[73,     3] loss: 1.361
[74,     3] loss: 1.318
[75,     3] loss: 1.329
[76,     3] loss: 1.290
[77,     3] loss: 1.281
[78,     3] loss: 1.281
[79,     3] loss: 1.281
[80,     3] loss: 1.326
[81,     3] loss: 1.151
[82,     3] loss: 1.248
[83,     3] loss: 1.229
[84,     3] loss: 1.214
[85,     3] loss: 1.141
[86,     3] loss: 1.159
[87,     3] loss: 1.238
[88,     3] loss: 1.201
[89,     3] loss: 1.186
[90,     3] loss: 1.133
[91,     3] loss: 1.096
[92,     3] loss: 1.099
[93,     3] loss: 1.087
[94,     3] loss: 1.107
[95,     3] loss: 1.062
[96,     3] loss: 1.061
[97,     3] loss: 1.059
[98,     3] loss: 1.239
[99,     3] loss: 1.048
[100,     3] loss: 1.389
[101,     3] loss: 1.305
[102,     3] loss: 1.270
[103,     3] loss: 1.243
[104,     3] loss: 1.272
[105,     3] loss: 1.249
[106,     3] loss: 1.225
[107,     3] loss: 1.183
[108,     3] loss: 1.166
[109,     3] loss: 1.152
[110,     3] loss: 1.148
[111,     3] loss: 1.015
[112,     3] loss: 1.081
[113,     3] loss: 1.057
[114,     3] loss: 1.110
[115,     3] loss: 1.030
[116,     3] loss: 1.006
[117,     3] loss: 1.068
[118,     3] loss: 1.080
[119,     3] loss: 1.212
[120,     3] loss: 1.089
[121,     3] loss: 1.117
[122,     3] loss: 1.169
[123,     3] loss: 1.127
[124,     3] loss: 1.140
[125,     3] loss: 1.147
[126,     3] loss: 1.088
[127,     3] loss: 1.038
[128,     3] loss: 1.050
[129,     3] loss: 0.976
[130,     3] loss: 0.996
[131,     3] loss: 0.976
[132,     3] loss: 0.963
[133,     3] loss: 1.066
[134,     3] loss: 1.080
[135,     3] loss: 1.019
[136,     3] loss: 1.002
[137,     3] loss: 1.102
[138,     3] loss: 0.991
[139,     3] loss: 0.981
[140,     3] loss: 0.936
[141,     3] loss: 0.882
[142,     3] loss: 0.878
[143,     3] loss: 0.925
[144,     3] loss: 1.375
Early stopping applied (best metric=0.5223071575164795)
Finished Training
Total time taken: 31.996108531951904
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.383
[4,     3] loss: 1.380
[5,     3] loss: 1.388
[6,     3] loss: 1.384
[7,     3] loss: 1.391
[8,     3] loss: 1.394
[9,     3] loss: 1.386
[10,     3] loss: 1.385
[11,     3] loss: 1.385
[12,     3] loss: 1.385
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.385
[20,     3] loss: 1.387
[21,     3] loss: 1.387
[22,     3] loss: 1.387
[23,     3] loss: 1.386
[24,     3] loss: 1.385
[25,     3] loss: 1.384
[26,     3] loss: 1.384
[27,     3] loss: 1.376
[28,     3] loss: 1.371
[29,     3] loss: 1.356
[30,     3] loss: 1.357
[31,     3] loss: 1.303
[32,     3] loss: 1.274
[33,     3] loss: 1.261
[34,     3] loss: 1.223
[35,     3] loss: 1.248
[36,     3] loss: 1.206
[37,     3] loss: 1.174
[38,     3] loss: 1.170
[39,     3] loss: 1.068
[40,     3] loss: 1.132
[41,     3] loss: 1.189
[42,     3] loss: 1.103
[43,     3] loss: 1.133
[44,     3] loss: 1.129
[45,     3] loss: 1.093
[46,     3] loss: 1.059
[47,     3] loss: 0.996
[48,     3] loss: 0.949
[49,     3] loss: 0.983
[50,     3] loss: 0.987
[51,     3] loss: 0.950
[52,     3] loss: 0.911
[53,     3] loss: 0.884
[54,     3] loss: 0.991
[55,     3] loss: 0.895
[56,     3] loss: 1.019
[57,     3] loss: 0.950
[58,     3] loss: 0.984
[59,     3] loss: 0.964
[60,     3] loss: 0.872
[61,     3] loss: 0.903
[62,     3] loss: 0.888
[63,     3] loss: 0.844
[64,     3] loss: 0.913
[65,     3] loss: 0.943
[66,     3] loss: 0.915
[67,     3] loss: 0.846
[68,     3] loss: 0.843
[69,     3] loss: 0.802
[70,     3] loss: 0.824
[71,     3] loss: 0.826
[72,     3] loss: 0.833
[73,     3] loss: 0.831
[74,     3] loss: 0.791
[75,     3] loss: 0.765
[76,     3] loss: 0.774
[77,     3] loss: 0.806
[78,     3] loss: 0.778
[79,     3] loss: 0.782
[80,     3] loss: 0.763
[81,     3] loss: 0.789
[82,     3] loss: 0.785
[83,     3] loss: 0.848
[84,     3] loss: 0.955
[85,     3] loss: 0.962
[86,     3] loss: 0.929
[87,     3] loss: 0.875
[88,     3] loss: 0.947
[89,     3] loss: 0.966
[90,     3] loss: 0.905
[91,     3] loss: 0.994
Early stopping applied (best metric=0.5120891332626343)
Finished Training
Total time taken: 20.212063550949097
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.384
[3,     3] loss: 1.390
[4,     3] loss: 1.392
[5,     3] loss: 1.387
[6,     3] loss: 1.384
[7,     3] loss: 1.388
[8,     3] loss: 1.381
[9,     3] loss: 1.391
[10,     3] loss: 1.385
[11,     3] loss: 1.390
[12,     3] loss: 1.387
[13,     3] loss: 1.387
[14,     3] loss: 1.386
[15,     3] loss: 1.386
[16,     3] loss: 1.386
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.385
[21,     3] loss: 1.385
[22,     3] loss: 1.385
[23,     3] loss: 1.380
[24,     3] loss: 1.380
[25,     3] loss: 1.356
[26,     3] loss: 1.341
[27,     3] loss: 1.289
[28,     3] loss: 1.237
[29,     3] loss: 1.269
[30,     3] loss: 1.148
[31,     3] loss: 1.158
[32,     3] loss: 1.168
[33,     3] loss: 1.110
[34,     3] loss: 1.085
[35,     3] loss: 1.241
[36,     3] loss: 1.080
[37,     3] loss: 1.040
[38,     3] loss: 0.996
[39,     3] loss: 1.198
[40,     3] loss: 1.009
[41,     3] loss: 1.035
[42,     3] loss: 0.992
[43,     3] loss: 1.081
[44,     3] loss: 0.934
[45,     3] loss: 0.956
[46,     3] loss: 1.044
[47,     3] loss: 0.979
[48,     3] loss: 0.889
[49,     3] loss: 0.924
[50,     3] loss: 0.868
[51,     3] loss: 0.874
[52,     3] loss: 0.882
[53,     3] loss: 0.834
[54,     3] loss: 0.947
[55,     3] loss: 1.182
[56,     3] loss: 1.111
[57,     3] loss: 1.154
[58,     3] loss: 1.077
[59,     3] loss: 1.075
[60,     3] loss: 0.995
[61,     3] loss: 0.915
[62,     3] loss: 0.896
[63,     3] loss: 0.994
[64,     3] loss: 0.949
[65,     3] loss: 0.922
[66,     3] loss: 0.933
[67,     3] loss: 0.918
[68,     3] loss: 0.878
[69,     3] loss: 0.902
[70,     3] loss: 0.936
[71,     3] loss: 0.963
[72,     3] loss: 0.923
[73,     3] loss: 0.971
[74,     3] loss: 0.946
[75,     3] loss: 0.923
[76,     3] loss: 0.937
[77,     3] loss: 0.883
[78,     3] loss: 0.876
[79,     3] loss: 0.832
[80,     3] loss: 0.842
Early stopping applied (best metric=0.518310010433197)
Finished Training
Total time taken: 17.74805474281311
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.386
[3,     3] loss: 1.386
[4,     3] loss: 1.384
[5,     3] loss: 1.388
[6,     3] loss: 1.385
[7,     3] loss: 1.383
[8,     3] loss: 1.382
[9,     3] loss: 1.386
[10,     3] loss: 1.386
[11,     3] loss: 1.381
[12,     3] loss: 1.381
[13,     3] loss: 1.393
[14,     3] loss: 1.384
[15,     3] loss: 1.382
[16,     3] loss: 1.383
[17,     3] loss: 1.380
[18,     3] loss: 1.374
[19,     3] loss: 1.366
[20,     3] loss: 1.351
[21,     3] loss: 1.321
[22,     3] loss: 1.310
[23,     3] loss: 1.247
[24,     3] loss: 1.245
[25,     3] loss: 1.161
[26,     3] loss: 1.092
[27,     3] loss: 1.252
[28,     3] loss: 1.217
[29,     3] loss: 1.237
[30,     3] loss: 1.220
[31,     3] loss: 1.225
[32,     3] loss: 1.183
[33,     3] loss: 1.155
[34,     3] loss: 1.113
[35,     3] loss: 1.033
[36,     3] loss: 1.053
[37,     3] loss: 1.059
[38,     3] loss: 0.975
[39,     3] loss: 1.017
[40,     3] loss: 1.011
[41,     3] loss: 1.047
[42,     3] loss: 0.957
[43,     3] loss: 0.977
[44,     3] loss: 1.025
[45,     3] loss: 0.933
[46,     3] loss: 0.908
[47,     3] loss: 0.940
[48,     3] loss: 0.846
[49,     3] loss: 0.920
[50,     3] loss: 0.850
[51,     3] loss: 0.824
[52,     3] loss: 0.901
[53,     3] loss: 0.798
[54,     3] loss: 0.795
[55,     3] loss: 0.904
[56,     3] loss: 0.900
[57,     3] loss: 0.862
[58,     3] loss: 0.927
[59,     3] loss: 1.136
[60,     3] loss: 1.037
[61,     3] loss: 0.976
[62,     3] loss: 1.118
[63,     3] loss: 1.010
[64,     3] loss: 0.979
[65,     3] loss: 0.880
[66,     3] loss: 0.849
[67,     3] loss: 0.936
[68,     3] loss: 0.854
[69,     3] loss: 0.775
[70,     3] loss: 0.806
Early stopping applied (best metric=0.5043717622756958)
Finished Training
Total time taken: 15.547043800354004
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.384
[3,     3] loss: 1.394
[4,     3] loss: 1.386
[5,     3] loss: 1.395
[6,     3] loss: 1.389
[7,     3] loss: 1.389
[8,     3] loss: 1.385
[9,     3] loss: 1.391
[10,     3] loss: 1.386
[11,     3] loss: 1.388
[12,     3] loss: 1.386
[13,     3] loss: 1.386
[14,     3] loss: 1.388
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.387
[20,     3] loss: 1.388
[21,     3] loss: 1.387
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.387
[25,     3] loss: 1.388
[26,     3] loss: 1.387
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.386
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.388
[35,     3] loss: 1.386
[36,     3] loss: 1.385
[37,     3] loss: 1.386
[38,     3] loss: 1.385
[39,     3] loss: 1.382
[40,     3] loss: 1.382
[41,     3] loss: 1.381
[42,     3] loss: 1.376
[43,     3] loss: 1.372
[44,     3] loss: 1.380
[45,     3] loss: 1.384
[46,     3] loss: 1.369
[47,     3] loss: 1.361
[48,     3] loss: 1.351
[49,     3] loss: 1.342
[50,     3] loss: 1.336
[51,     3] loss: 1.334
[52,     3] loss: 1.357
[53,     3] loss: 1.334
[54,     3] loss: 1.318
[55,     3] loss: 1.289
[56,     3] loss: 1.309
[57,     3] loss: 1.242
[58,     3] loss: 1.171
[59,     3] loss: 1.162
[60,     3] loss: 1.245
[61,     3] loss: 1.302
[62,     3] loss: 1.321
[63,     3] loss: 1.295
[64,     3] loss: 1.266
[65,     3] loss: 1.184
[66,     3] loss: 1.104
[67,     3] loss: 1.020
[68,     3] loss: 1.092
[69,     3] loss: 1.196
[70,     3] loss: 1.104
[71,     3] loss: 1.035
[72,     3] loss: 1.099
[73,     3] loss: 0.983
[74,     3] loss: 1.020
[75,     3] loss: 0.896
[76,     3] loss: 1.017
[77,     3] loss: 1.083
[78,     3] loss: 0.928
[79,     3] loss: 1.009
[80,     3] loss: 0.963
[81,     3] loss: 1.043
[82,     3] loss: 0.961
[83,     3] loss: 0.933
[84,     3] loss: 0.949
[85,     3] loss: 0.864
[86,     3] loss: 0.948
[87,     3] loss: 0.931
[88,     3] loss: 0.905
[89,     3] loss: 0.949
[90,     3] loss: 0.838
[91,     3] loss: 0.917
[92,     3] loss: 0.878
[93,     3] loss: 0.966
[94,     3] loss: 0.909
[95,     3] loss: 0.853
[96,     3] loss: 0.875
[97,     3] loss: 0.864
[98,     3] loss: 0.882
[99,     3] loss: 0.874
[100,     3] loss: 0.850
[101,     3] loss: 0.845
[102,     3] loss: 0.805
[103,     3] loss: 0.844
[104,     3] loss: 0.905
[105,     3] loss: 1.246
[106,     3] loss: 1.064
[107,     3] loss: 1.182
[108,     3] loss: 1.088
[109,     3] loss: 1.044
[110,     3] loss: 0.970
Early stopping applied (best metric=0.4161609411239624)
Finished Training
Total time taken: 24.3830783367157
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.388
[3,     3] loss: 1.391
[4,     3] loss: 1.390
[5,     3] loss: 1.381
[6,     3] loss: 1.391
[7,     3] loss: 1.386
[8,     3] loss: 1.389
[9,     3] loss: 1.386
[10,     3] loss: 1.388
[11,     3] loss: 1.386
[12,     3] loss: 1.386
[13,     3] loss: 1.388
[14,     3] loss: 1.385
[15,     3] loss: 1.387
[16,     3] loss: 1.387
[17,     3] loss: 1.386
[18,     3] loss: 1.386
[19,     3] loss: 1.388
[20,     3] loss: 1.386
[21,     3] loss: 1.384
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.385
[25,     3] loss: 1.389
[26,     3] loss: 1.386
[27,     3] loss: 1.387
[28,     3] loss: 1.386
[29,     3] loss: 1.387
[30,     3] loss: 1.387
[31,     3] loss: 1.387
[32,     3] loss: 1.387
[33,     3] loss: 1.386
[34,     3] loss: 1.387
[35,     3] loss: 1.386
[36,     3] loss: 1.386
[37,     3] loss: 1.386
[38,     3] loss: 1.387
[39,     3] loss: 1.387
[40,     3] loss: 1.386
[41,     3] loss: 1.386
[42,     3] loss: 1.387
[43,     3] loss: 1.386
[44,     3] loss: 1.386
[45,     3] loss: 1.386
[46,     3] loss: 1.386
[47,     3] loss: 1.387
[48,     3] loss: 1.386
[49,     3] loss: 1.386
[50,     3] loss: 1.386
[51,     3] loss: 1.387
[52,     3] loss: 1.387
[53,     3] loss: 1.386
[54,     3] loss: 1.387
[55,     3] loss: 1.386
[56,     3] loss: 1.387
[57,     3] loss: 1.386
[58,     3] loss: 1.386
[59,     3] loss: 1.386
[60,     3] loss: 1.387
[61,     3] loss: 1.386
[62,     3] loss: 1.386
[63,     3] loss: 1.387
[64,     3] loss: 1.386
[65,     3] loss: 1.386
[66,     3] loss: 1.386
[67,     3] loss: 1.385
[68,     3] loss: 1.382
[69,     3] loss: 1.377
[70,     3] loss: 1.379
[71,     3] loss: 1.369
[72,     3] loss: 1.363
[73,     3] loss: 1.347
[74,     3] loss: 1.365
[75,     3] loss: 1.313
[76,     3] loss: 1.352
[77,     3] loss: 1.328
[78,     3] loss: 1.335
[79,     3] loss: 1.309
[80,     3] loss: 1.323
[81,     3] loss: 1.287
[82,     3] loss: 1.217
[83,     3] loss: 1.105
[84,     3] loss: 1.070
[85,     3] loss: 1.216
[86,     3] loss: 1.074
[87,     3] loss: 1.021
[88,     3] loss: 0.984
[89,     3] loss: 1.012
[90,     3] loss: 1.095
[91,     3] loss: 1.104
[92,     3] loss: 1.114
[93,     3] loss: 0.956
[94,     3] loss: 1.044
[95,     3] loss: 0.974
[96,     3] loss: 0.874
[97,     3] loss: 0.791
[98,     3] loss: 0.768
[99,     3] loss: 0.899
[100,     3] loss: 0.930
[101,     3] loss: 0.891
[102,     3] loss: 0.845
[103,     3] loss: 0.878
[104,     3] loss: 0.857
[105,     3] loss: 0.862
[106,     3] loss: 0.907
[107,     3] loss: 0.862
[108,     3] loss: 0.844
[109,     3] loss: 1.013
[110,     3] loss: 0.875
[111,     3] loss: 1.035
[112,     3] loss: 0.974
[113,     3] loss: 0.853
[114,     3] loss: 0.918
[115,     3] loss: 0.894
[116,     3] loss: 1.197
[117,     3] loss: 1.063
[118,     3] loss: 1.025
[119,     3] loss: 1.013
[120,     3] loss: 0.975
[121,     3] loss: 0.911
[122,     3] loss: 0.876
[123,     3] loss: 0.883
[124,     3] loss: 0.869
[125,     3] loss: 0.854
[126,     3] loss: 0.834
[127,     3] loss: 0.770
[128,     3] loss: 0.811
[129,     3] loss: 0.827
[130,     3] loss: 0.816
Early stopping applied (best metric=0.5071316957473755)
Finished Training
Total time taken: 28.95910382270813
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.406
[3,     3] loss: 1.383
[4,     3] loss: 1.384
[5,     3] loss: 1.382
[6,     3] loss: 1.384
[7,     3] loss: 1.385
[8,     3] loss: 1.390
[9,     3] loss: 1.384
[10,     3] loss: 1.384
[11,     3] loss: 1.384
[12,     3] loss: 1.385
[13,     3] loss: 1.382
[14,     3] loss: 1.383
[15,     3] loss: 1.385
[16,     3] loss: 1.379
[17,     3] loss: 1.375
[18,     3] loss: 1.368
[19,     3] loss: 1.347
[20,     3] loss: 1.353
[21,     3] loss: 1.327
[22,     3] loss: 1.304
[23,     3] loss: 1.216
[24,     3] loss: 1.198
[25,     3] loss: 1.180
[26,     3] loss: 1.089
[27,     3] loss: 1.063
[28,     3] loss: 1.135
[29,     3] loss: 1.039
[30,     3] loss: 1.085
[31,     3] loss: 1.036
[32,     3] loss: 1.085
[33,     3] loss: 1.096
[34,     3] loss: 1.008
[35,     3] loss: 1.078
[36,     3] loss: 1.106
[37,     3] loss: 0.976
[38,     3] loss: 0.976
[39,     3] loss: 0.945
[40,     3] loss: 0.949
[41,     3] loss: 0.931
[42,     3] loss: 0.881
[43,     3] loss: 0.941
[44,     3] loss: 0.893
[45,     3] loss: 0.907
[46,     3] loss: 1.116
[47,     3] loss: 1.025
[48,     3] loss: 0.991
[49,     3] loss: 0.893
[50,     3] loss: 0.948
[51,     3] loss: 0.891
[52,     3] loss: 0.877
[53,     3] loss: 0.897
[54,     3] loss: 0.983
[55,     3] loss: 0.858
[56,     3] loss: 0.878
[57,     3] loss: 0.875
[58,     3] loss: 0.895
[59,     3] loss: 0.884
[60,     3] loss: 0.841
[61,     3] loss: 0.822
[62,     3] loss: 0.801
[63,     3] loss: 0.830
[64,     3] loss: 0.818
[65,     3] loss: 0.839
[66,     3] loss: 0.944
[67,     3] loss: 1.000
[68,     3] loss: 1.008
[69,     3] loss: 0.973
[70,     3] loss: 0.979
[71,     3] loss: 0.975
[72,     3] loss: 0.895
[73,     3] loss: 0.870
[74,     3] loss: 0.839
Early stopping applied (best metric=0.5413650870323181)
Finished Training
Total time taken: 16.482219219207764
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.378
[4,     3] loss: 1.388
[5,     3] loss: 1.379
[6,     3] loss: 1.388
[7,     3] loss: 1.381
[8,     3] loss: 1.379
[9,     3] loss: 1.381
[10,     3] loss: 1.383
[11,     3] loss: 1.384
[12,     3] loss: 1.380
[13,     3] loss: 1.382
[14,     3] loss: 1.378
[15,     3] loss: 1.374
[16,     3] loss: 1.369
[17,     3] loss: 1.355
[18,     3] loss: 1.349
[19,     3] loss: 1.315
[20,     3] loss: 1.292
[21,     3] loss: 1.223
[22,     3] loss: 1.193
[23,     3] loss: 1.154
[24,     3] loss: 1.284
[25,     3] loss: 1.220
[26,     3] loss: 1.166
[27,     3] loss: 1.209
[28,     3] loss: 1.217
[29,     3] loss: 1.173
[30,     3] loss: 1.090
[31,     3] loss: 1.026
[32,     3] loss: 1.081
[33,     3] loss: 1.180
[34,     3] loss: 1.219
[35,     3] loss: 1.057
[36,     3] loss: 1.112
[37,     3] loss: 1.189
[38,     3] loss: 1.046
[39,     3] loss: 1.175
[40,     3] loss: 1.139
[41,     3] loss: 1.057
[42,     3] loss: 0.971
[43,     3] loss: 0.962
[44,     3] loss: 0.958
[45,     3] loss: 1.009
[46,     3] loss: 0.969
[47,     3] loss: 1.074
[48,     3] loss: 1.002
[49,     3] loss: 1.071
[50,     3] loss: 1.106
[51,     3] loss: 0.965
[52,     3] loss: 0.909
[53,     3] loss: 0.926
[54,     3] loss: 0.969
[55,     3] loss: 0.936
[56,     3] loss: 0.916
[57,     3] loss: 0.876
[58,     3] loss: 0.952
[59,     3] loss: 0.933
[60,     3] loss: 0.909
[61,     3] loss: 0.949
[62,     3] loss: 0.975
[63,     3] loss: 0.922
[64,     3] loss: 0.902
[65,     3] loss: 0.964
[66,     3] loss: 0.892
[67,     3] loss: 0.890
[68,     3] loss: 0.963
[69,     3] loss: 0.911
[70,     3] loss: 0.881
[71,     3] loss: 0.877
[72,     3] loss: 1.008
[73,     3] loss: 0.961
[74,     3] loss: 0.924
[75,     3] loss: 0.848
[76,     3] loss: 0.864
Early stopping applied (best metric=0.5251405835151672)
Finished Training
Total time taken: 16.93768310546875
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.386
[3,     3] loss: 1.389
[4,     3] loss: 1.386
[5,     3] loss: 1.389
[6,     3] loss: 1.381
[7,     3] loss: 1.393
[8,     3] loss: 1.388
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.386
[12,     3] loss: 1.382
[13,     3] loss: 1.383
[14,     3] loss: 1.383
[15,     3] loss: 1.370
[16,     3] loss: 1.367
[17,     3] loss: 1.352
[18,     3] loss: 1.315
[19,     3] loss: 1.294
[20,     3] loss: 1.223
[21,     3] loss: 1.198
[22,     3] loss: 1.229
[23,     3] loss: 1.232
[24,     3] loss: 1.324
[25,     3] loss: 1.247
[26,     3] loss: 1.240
[27,     3] loss: 1.186
[28,     3] loss: 1.197
[29,     3] loss: 1.085
[30,     3] loss: 1.086
[31,     3] loss: 1.056
[32,     3] loss: 1.102
[33,     3] loss: 1.246
[34,     3] loss: 1.201
[35,     3] loss: 1.082
[36,     3] loss: 1.118
[37,     3] loss: 1.063
[38,     3] loss: 1.138
[39,     3] loss: 1.124
[40,     3] loss: 1.058
[41,     3] loss: 1.049
[42,     3] loss: 0.964
[43,     3] loss: 0.937
[44,     3] loss: 0.907
[45,     3] loss: 0.935
[46,     3] loss: 0.850
[47,     3] loss: 0.850
[48,     3] loss: 0.809
[49,     3] loss: 0.841
[50,     3] loss: 0.863
[51,     3] loss: 0.993
[52,     3] loss: 0.934
[53,     3] loss: 0.914
[54,     3] loss: 0.903
[55,     3] loss: 0.920
[56,     3] loss: 0.959
[57,     3] loss: 0.997
[58,     3] loss: 0.912
[59,     3] loss: 0.993
[60,     3] loss: 0.969
[61,     3] loss: 0.867
[62,     3] loss: 1.000
[63,     3] loss: 1.012
[64,     3] loss: 0.896
[65,     3] loss: 0.878
[66,     3] loss: 0.908
[67,     3] loss: 0.828
[68,     3] loss: 0.825
[69,     3] loss: 0.799
[70,     3] loss: 0.783
[71,     3] loss: 0.799
[72,     3] loss: 0.836
[73,     3] loss: 0.799
[74,     3] loss: 0.810
[75,     3] loss: 0.780
[76,     3] loss: 0.765
[77,     3] loss: 0.775
[78,     3] loss: 0.771
[79,     3] loss: 0.765
[80,     3] loss: 0.752
[81,     3] loss: 0.764
[82,     3] loss: 0.823
[83,     3] loss: 1.251
[84,     3] loss: 1.083
[85,     3] loss: 1.406
[86,     3] loss: 1.149
[87,     3] loss: 1.180
[88,     3] loss: 1.149
[89,     3] loss: 1.196
[90,     3] loss: 1.100
[91,     3] loss: 1.111
[92,     3] loss: 1.048
[93,     3] loss: 1.011
[94,     3] loss: 0.968
[95,     3] loss: 0.971
[96,     3] loss: 0.908
[97,     3] loss: 0.938
[98,     3] loss: 0.993
[99,     3] loss: 0.889
[100,     3] loss: 0.872
[101,     3] loss: 0.912
[102,     3] loss: 0.947
[103,     3] loss: 0.865
[104,     3] loss: 0.912
[105,     3] loss: 0.871
[106,     3] loss: 0.873
[107,     3] loss: 0.876
[108,     3] loss: 0.822
[109,     3] loss: 0.998
[110,     3] loss: 0.967
[111,     3] loss: 1.012
[112,     3] loss: 0.967
[113,     3] loss: 0.921
[114,     3] loss: 0.998
[115,     3] loss: 0.866
[116,     3] loss: 0.863
[117,     3] loss: 1.029
[118,     3] loss: 0.899
[119,     3] loss: 0.850
[120,     3] loss: 0.823
[121,     3] loss: 0.862
[122,     3] loss: 0.817
[123,     3] loss: 0.896
[124,     3] loss: 0.783
[125,     3] loss: 0.802
[126,     3] loss: 0.833
Early stopping applied (best metric=0.5224846005439758)
Finished Training
Total time taken: 27.94508934020996
{'S-palmitoylation-C Validation Accuracy': 0.7072480891258184, 'S-palmitoylation-C Validation Sensitivity': 0.2066006600660066, 'S-palmitoylation-C Validation Specificity': 0.8327396232986136, 'S-palmitoylation-C Validation Precision': nan, 'S-palmitoylation-C AUC ROC': 0.5626322311395106, 'S-palmitoylation-C AUC PR': 0.23817196285534206, 'S-palmitoylation-C MCC': 0.045899496783271924, 'S-palmitoylation-C F1': 0.20044060748683828, 'Validation Loss (S-palmitoylation-C)': 0.5660585045814515, 'Hydroxylation-K Validation Accuracy': 0.7178782505910165, 'Hydroxylation-K Validation Sensitivity': 0.7118518518518518, 'Hydroxylation-K Validation Specificity': 0.7210526315789474, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.8115204678362573, 'Hydroxylation-K AUC PR': 0.5488074731609804, 'Hydroxylation-K MCC': 0.3658414834963207, 'Hydroxylation-K F1': 0.4822731865835314, 'Validation Loss (Hydroxylation-K)': 0.508600244919459, 'Validation Loss (total)': 1.0746587276458741, 'TimeToTrain': 20.943654648462932}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018312416572190808,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1890932107654822,
 'loss_weight_S-palmitoylation-C': 0.9015291692299406,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 571740675,
 'sample_weights': [0.2558643987933658, 0.5058084638012246],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7475270944046652,
 'weight_decay_Hydroxylation-K': 2.4389344752920805,
 'weight_decay_S-palmitoylation-C': 0.7312832921160477}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.379
[2,     3] loss: 1.389
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 8.699826722074924e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7883024881477675,
 'loss_weight_S-palmitoylation-C': 0.1700650612180536,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1837742774,
 'sample_weights': [0.9015291692299406, 0.1890932107654822],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.745126199279238,
 'weight_decay_Hydroxylation-K': 2.4698093998631037,
 'weight_decay_S-palmitoylation-C': 7.522275177018668}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.390
[3,     3] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003185468412454773,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.054708177556583276,
 'loss_weight_S-palmitoylation-C': 0.5750343909710449,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2703983733,
 'sample_weights': [0.1700650612180536, 0.7883024881477675],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.717967921732791,
 'weight_decay_Hydroxylation-K': 1.4878599549877312,
 'weight_decay_S-palmitoylation-C': 1.3869723078843956}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.377
[2,     3] loss: 1.387
[3,     3] loss: 1.384
[4,     3] loss: 1.386
[5,     3] loss: 1.385
[6,     3] loss: 1.380
[7,     3] loss: 1.385
[8,     3] loss: 1.376
[9,     3] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008120139313363317,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2951813986977929,
 'loss_weight_S-palmitoylation-C': 0.31745527062805157,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 709432596,
 'sample_weights': [0.5750343909710449, 0.054708177556583276],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.3689444475778876,
 'weight_decay_Hydroxylation-K': 6.033937842371113,
 'weight_decay_S-palmitoylation-C': 1.7396146729414794}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.376
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002444707578011778,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4387997672890222,
 'loss_weight_S-palmitoylation-C': 0.16223040641526915,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3320563403,
 'sample_weights': [0.31745527062805157, 0.2951813986977929],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.363265845055493,
 'weight_decay_Hydroxylation-K': 2.5725652866578983,
 'weight_decay_S-palmitoylation-C': 4.965192082619456}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.383
[3,     3] loss: 1.389
[4,     3] loss: 1.374
[5,     3] loss: 1.381
[6,     3] loss: 1.392
[7,     3] loss: 1.373
[8,     3] loss: 1.378
[9,     3] loss: 1.368
[10,     3] loss: 1.339
[11,     3] loss: 1.301
[12,     3] loss: 1.268
[13,     3] loss: 1.245
[14,     3] loss: 1.270
[15,     3] loss: 1.298
[16,     3] loss: 1.172
[17,     3] loss: 1.214
[18,     3] loss: 1.176
[19,     3] loss: 1.167
[20,     3] loss: 1.204
[21,     3] loss: 1.252
[22,     3] loss: 1.122
[23,     3] loss: 1.131
[24,     3] loss: 1.113
[25,     3] loss: 1.033
[26,     3] loss: 1.055
[27,     3] loss: 1.025
[28,     3] loss: 1.015
[29,     3] loss: 0.997
[30,     3] loss: 0.991
[31,     3] loss: 1.019
[32,     3] loss: 1.155
[33,     3] loss: 1.131
[34,     3] loss: 0.981
[35,     3] loss: 0.979
[36,     3] loss: 0.982
[37,     3] loss: 0.947
[38,     3] loss: 0.986
[39,     3] loss: 1.018
[40,     3] loss: 0.854
[41,     3] loss: 0.983
[42,     3] loss: 0.900
[43,     3] loss: 0.922
[44,     3] loss: 0.851
[45,     3] loss: 0.857
[46,     3] loss: 0.785
[47,     3] loss: 0.915
[48,     3] loss: 1.390
[49,     3] loss: 1.001
[50,     3] loss: 1.195
[51,     3] loss: 1.014
[52,     3] loss: 1.118
[53,     3] loss: 1.005
[54,     3] loss: 1.128
[55,     3] loss: 0.938
[56,     3] loss: 0.929
[57,     3] loss: 0.906
[58,     3] loss: 0.818
[59,     3] loss: 0.855
[60,     3] loss: 1.028
[61,     3] loss: 0.849
[62,     3] loss: 0.847
[63,     3] loss: 0.832
[64,     3] loss: 0.818
[65,     3] loss: 0.834
[66,     3] loss: 0.917
[67,     3] loss: 0.867
[68,     3] loss: 0.842
[69,     3] loss: 0.899
[70,     3] loss: 0.872
[71,     3] loss: 0.835
[72,     3] loss: 0.830
[73,     3] loss: 0.874
[74,     3] loss: 0.817
[75,     3] loss: 0.868
[76,     3] loss: 0.914
Early stopping applied (best metric=0.535857617855072)
Finished Training
Total time taken: 16.906051635742188
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.388
[3,     3] loss: 1.391
[4,     3] loss: 1.375
[5,     3] loss: 1.378
[6,     3] loss: 1.373
[7,     3] loss: 1.362
[8,     3] loss: 1.363
[9,     3] loss: 1.328
[10,     3] loss: 1.273
[11,     3] loss: 1.282
[12,     3] loss: 1.306
[13,     3] loss: 1.250
[14,     3] loss: 1.195
[15,     3] loss: 1.254
[16,     3] loss: 1.244
[17,     3] loss: 1.309
[18,     3] loss: 1.209
[19,     3] loss: 1.223
[20,     3] loss: 1.169
[21,     3] loss: 1.149
[22,     3] loss: 1.165
[23,     3] loss: 1.149
[24,     3] loss: 1.109
[25,     3] loss: 1.134
[26,     3] loss: 1.040
[27,     3] loss: 1.017
[28,     3] loss: 0.937
[29,     3] loss: 1.118
[30,     3] loss: 1.074
[31,     3] loss: 1.001
[32,     3] loss: 1.043
[33,     3] loss: 1.037
[34,     3] loss: 0.873
[35,     3] loss: 0.968
[36,     3] loss: 0.904
[37,     3] loss: 1.011
[38,     3] loss: 0.869
[39,     3] loss: 0.913
[40,     3] loss: 0.871
[41,     3] loss: 0.874
[42,     3] loss: 0.898
[43,     3] loss: 0.838
[44,     3] loss: 0.874
[45,     3] loss: 0.956
[46,     3] loss: 1.182
[47,     3] loss: 1.084
[48,     3] loss: 1.038
[49,     3] loss: 0.993
[50,     3] loss: 0.923
[51,     3] loss: 0.891
[52,     3] loss: 0.857
[53,     3] loss: 0.782
[54,     3] loss: 0.898
[55,     3] loss: 0.879
[56,     3] loss: 0.861
[57,     3] loss: 0.855
[58,     3] loss: 0.803
[59,     3] loss: 0.795
[60,     3] loss: 0.777
[61,     3] loss: 0.759
[62,     3] loss: 0.800
[63,     3] loss: 0.810
[64,     3] loss: 0.857
Early stopping applied (best metric=0.5324059128761292)
Finished Training
Total time taken: 14.246045589447021
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.386
[3,     3] loss: 1.376
[4,     3] loss: 1.391
[5,     3] loss: 1.394
[6,     3] loss: 1.386
[7,     3] loss: 1.386
[8,     3] loss: 1.380
[9,     3] loss: 1.378
[10,     3] loss: 1.374
[11,     3] loss: 1.372
[12,     3] loss: 1.361
[13,     3] loss: 1.301
[14,     3] loss: 1.329
[15,     3] loss: 1.213
[16,     3] loss: 1.205
[17,     3] loss: 1.162
[18,     3] loss: 1.113
[19,     3] loss: 1.003
[20,     3] loss: 1.041
[21,     3] loss: 1.075
[22,     3] loss: 1.035
[23,     3] loss: 0.992
[24,     3] loss: 1.315
[25,     3] loss: 1.084
[26,     3] loss: 1.230
[27,     3] loss: 1.231
[28,     3] loss: 1.221
[29,     3] loss: 1.099
[30,     3] loss: 1.072
[31,     3] loss: 0.969
[32,     3] loss: 0.997
[33,     3] loss: 0.991
[34,     3] loss: 0.987
[35,     3] loss: 0.918
[36,     3] loss: 1.067
[37,     3] loss: 0.874
[38,     3] loss: 0.875
[39,     3] loss: 0.910
[40,     3] loss: 0.908
[41,     3] loss: 0.888
[42,     3] loss: 0.917
[43,     3] loss: 1.062
[44,     3] loss: 1.017
[45,     3] loss: 0.973
[46,     3] loss: 0.922
[47,     3] loss: 0.914
[48,     3] loss: 0.836
[49,     3] loss: 0.885
[50,     3] loss: 0.822
[51,     3] loss: 0.838
[52,     3] loss: 0.862
[53,     3] loss: 0.985
[54,     3] loss: 0.792
[55,     3] loss: 0.934
[56,     3] loss: 0.925
[57,     3] loss: 0.933
[58,     3] loss: 0.943
[59,     3] loss: 0.973
[60,     3] loss: 0.867
[61,     3] loss: 0.845
[62,     3] loss: 0.841
[63,     3] loss: 0.831
[64,     3] loss: 0.826
[65,     3] loss: 0.806
[66,     3] loss: 0.847
[67,     3] loss: 0.830
Early stopping applied (best metric=0.5359359979629517)
Finished Training
Total time taken: 14.85204529762268
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.383
[3,     3] loss: 1.373
[4,     3] loss: 1.378
[5,     3] loss: 1.369
[6,     3] loss: 1.362
[7,     3] loss: 1.375
[8,     3] loss: 1.339
[9,     3] loss: 1.290
[10,     3] loss: 1.269
[11,     3] loss: 1.328
[12,     3] loss: 1.197
[13,     3] loss: 1.125
[14,     3] loss: 1.099
[15,     3] loss: 1.097
[16,     3] loss: 1.068
[17,     3] loss: 1.033
[18,     3] loss: 0.974
[19,     3] loss: 1.008
[20,     3] loss: 0.963
[21,     3] loss: 1.031
[22,     3] loss: 1.005
[23,     3] loss: 1.158
[24,     3] loss: 1.001
[25,     3] loss: 1.050
[26,     3] loss: 0.954
[27,     3] loss: 0.931
[28,     3] loss: 0.989
[29,     3] loss: 0.935
[30,     3] loss: 0.852
[31,     3] loss: 0.980
[32,     3] loss: 0.962
[33,     3] loss: 0.882
[34,     3] loss: 0.910
[35,     3] loss: 0.895
[36,     3] loss: 0.876
[37,     3] loss: 0.819
[38,     3] loss: 0.772
[39,     3] loss: 0.809
[40,     3] loss: 0.876
[41,     3] loss: 1.207
[42,     3] loss: 0.952
[43,     3] loss: 1.012
[44,     3] loss: 1.032
[45,     3] loss: 1.045
[46,     3] loss: 1.019
[47,     3] loss: 0.954
[48,     3] loss: 0.876
[49,     3] loss: 0.838
[50,     3] loss: 0.793
[51,     3] loss: 0.877
[52,     3] loss: 0.792
[53,     3] loss: 0.779
[54,     3] loss: 0.881
[55,     3] loss: 0.785
[56,     3] loss: 0.815
[57,     3] loss: 0.774
[58,     3] loss: 0.798
[59,     3] loss: 0.911
[60,     3] loss: 0.920
[61,     3] loss: 0.806
[62,     3] loss: 0.818
[63,     3] loss: 0.801
[64,     3] loss: 0.772
[65,     3] loss: 0.760
Early stopping applied (best metric=0.5175268650054932)
Finished Training
Total time taken: 14.452057838439941
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.385
[3,     3] loss: 1.380
[4,     3] loss: 1.397
[5,     3] loss: 1.389
[6,     3] loss: 1.380
[7,     3] loss: 1.379
[8,     3] loss: 1.356
[9,     3] loss: 1.347
[10,     3] loss: 1.322
[11,     3] loss: 1.286
[12,     3] loss: 1.290
[13,     3] loss: 1.275
[14,     3] loss: 1.258
[15,     3] loss: 1.257
[16,     3] loss: 1.167
[17,     3] loss: 1.099
[18,     3] loss: 1.072
[19,     3] loss: 1.035
[20,     3] loss: 1.111
[21,     3] loss: 1.042
[22,     3] loss: 1.051
[23,     3] loss: 1.000
[24,     3] loss: 0.977
[25,     3] loss: 1.039
[26,     3] loss: 1.322
[27,     3] loss: 1.014
[28,     3] loss: 1.182
[29,     3] loss: 1.117
[30,     3] loss: 1.121
[31,     3] loss: 1.091
[32,     3] loss: 1.009
[33,     3] loss: 1.030
[34,     3] loss: 0.924
[35,     3] loss: 0.865
[36,     3] loss: 0.873
[37,     3] loss: 0.969
[38,     3] loss: 0.957
[39,     3] loss: 1.143
[40,     3] loss: 0.990
[41,     3] loss: 0.997
[42,     3] loss: 0.956
[43,     3] loss: 0.909
[44,     3] loss: 0.863
[45,     3] loss: 0.862
[46,     3] loss: 0.835
[47,     3] loss: 0.799
[48,     3] loss: 0.815
[49,     3] loss: 0.825
[50,     3] loss: 0.823
[51,     3] loss: 0.789
[52,     3] loss: 0.860
[53,     3] loss: 0.969
[54,     3] loss: 0.893
[55,     3] loss: 0.845
[56,     3] loss: 0.863
[57,     3] loss: 0.918
[58,     3] loss: 0.880
[59,     3] loss: 0.809
[60,     3] loss: 0.854
[61,     3] loss: 0.829
[62,     3] loss: 0.805
[63,     3] loss: 0.788
[64,     3] loss: 0.874
[65,     3] loss: 0.805
[66,     3] loss: 0.850
[67,     3] loss: 0.909
[68,     3] loss: 0.998
Early stopping applied (best metric=0.5171868205070496)
Finished Training
Total time taken: 15.158048868179321
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.380
[3,     3] loss: 1.387
[4,     3] loss: 1.392
[5,     3] loss: 1.388
[6,     3] loss: 1.383
[7,     3] loss: 1.386
[8,     3] loss: 1.385
[9,     3] loss: 1.376
[10,     3] loss: 1.373
[11,     3] loss: 1.362
[12,     3] loss: 1.321
[13,     3] loss: 1.292
[14,     3] loss: 1.300
[15,     3] loss: 1.232
[16,     3] loss: 1.198
[17,     3] loss: 1.212
[18,     3] loss: 1.160
[19,     3] loss: 1.173
[20,     3] loss: 1.201
[21,     3] loss: 1.146
[22,     3] loss: 1.154
[23,     3] loss: 1.185
[24,     3] loss: 1.077
[25,     3] loss: 1.057
[26,     3] loss: 0.972
[27,     3] loss: 1.073
[28,     3] loss: 1.028
[29,     3] loss: 1.013
[30,     3] loss: 1.019
[31,     3] loss: 1.142
[32,     3] loss: 1.176
[33,     3] loss: 1.086
[34,     3] loss: 1.199
[35,     3] loss: 1.117
[36,     3] loss: 1.244
[37,     3] loss: 1.045
[38,     3] loss: 1.080
[39,     3] loss: 0.997
[40,     3] loss: 0.925
[41,     3] loss: 0.895
[42,     3] loss: 0.950
[43,     3] loss: 1.069
[44,     3] loss: 0.983
[45,     3] loss: 1.024
[46,     3] loss: 0.963
[47,     3] loss: 0.923
[48,     3] loss: 0.950
[49,     3] loss: 0.871
[50,     3] loss: 0.842
[51,     3] loss: 0.834
[52,     3] loss: 0.828
[53,     3] loss: 0.784
[54,     3] loss: 0.867
[55,     3] loss: 0.771
[56,     3] loss: 0.847
[57,     3] loss: 0.767
[58,     3] loss: 0.768
[59,     3] loss: 0.759
[60,     3] loss: 0.780
[61,     3] loss: 0.760
[62,     3] loss: 0.983
[63,     3] loss: 0.821
[64,     3] loss: 0.807
[65,     3] loss: 0.780
[66,     3] loss: 0.776
[67,     3] loss: 0.813
[68,     3] loss: 0.770
[69,     3] loss: 1.109
[70,     3] loss: 1.059
[71,     3] loss: 1.023
[72,     3] loss: 1.002
[73,     3] loss: 0.928
[74,     3] loss: 0.916
[75,     3] loss: 0.833
[76,     3] loss: 0.816
[77,     3] loss: 0.897
[78,     3] loss: 0.832
[79,     3] loss: 0.862
[80,     3] loss: 0.816
[81,     3] loss: 0.761
[82,     3] loss: 0.766
[83,     3] loss: 0.751
[84,     3] loss: 0.783
[85,     3] loss: 0.784
[86,     3] loss: 0.805
[87,     3] loss: 0.823
[88,     3] loss: 0.838
[89,     3] loss: 0.908
Early stopping applied (best metric=0.5342804789543152)
Finished Training
Total time taken: 19.809650182724
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.386
[3,     3] loss: 1.400
[4,     3] loss: 1.397
[5,     3] loss: 1.384
[6,     3] loss: 1.387
[7,     3] loss: 1.394
[8,     3] loss: 1.385
[9,     3] loss: 1.379
[10,     3] loss: 1.381
[11,     3] loss: 1.368
[12,     3] loss: 1.371
[13,     3] loss: 1.369
[14,     3] loss: 1.324
[15,     3] loss: 1.329
[16,     3] loss: 1.305
[17,     3] loss: 1.264
[18,     3] loss: 1.177
[19,     3] loss: 1.262
[20,     3] loss: 1.253
[21,     3] loss: 1.250
[22,     3] loss: 1.329
[23,     3] loss: 1.309
[24,     3] loss: 1.208
[25,     3] loss: 1.195
[26,     3] loss: 1.162
[27,     3] loss: 1.131
[28,     3] loss: 1.057
[29,     3] loss: 0.997
[30,     3] loss: 1.090
[31,     3] loss: 1.072
[32,     3] loss: 1.147
[33,     3] loss: 0.976
[34,     3] loss: 1.135
[35,     3] loss: 1.052
[36,     3] loss: 1.074
[37,     3] loss: 1.054
[38,     3] loss: 1.052
[39,     3] loss: 0.896
[40,     3] loss: 1.002
[41,     3] loss: 0.898
[42,     3] loss: 1.030
[43,     3] loss: 0.995
[44,     3] loss: 0.970
[45,     3] loss: 0.935
[46,     3] loss: 0.919
[47,     3] loss: 0.936
[48,     3] loss: 1.061
[49,     3] loss: 0.988
[50,     3] loss: 1.056
[51,     3] loss: 0.902
[52,     3] loss: 0.898
[53,     3] loss: 0.882
[54,     3] loss: 0.827
[55,     3] loss: 0.866
[56,     3] loss: 0.841
[57,     3] loss: 0.842
[58,     3] loss: 0.825
[59,     3] loss: 0.828
[60,     3] loss: 0.923
[61,     3] loss: 0.860
[62,     3] loss: 0.881
[63,     3] loss: 0.925
[64,     3] loss: 0.908
[65,     3] loss: 0.999
[66,     3] loss: 1.057
[67,     3] loss: 1.025
[68,     3] loss: 0.976
[69,     3] loss: 0.997
[70,     3] loss: 0.953
[71,     3] loss: 0.908
[72,     3] loss: 0.858
[73,     3] loss: 0.866
[74,     3] loss: 0.849
[75,     3] loss: 0.775
[76,     3] loss: 0.778
[77,     3] loss: 0.793
[78,     3] loss: 0.840
Early stopping applied (best metric=0.5313647985458374)
Finished Training
Total time taken: 17.432054042816162
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.382
[3,     3] loss: 1.377
[4,     3] loss: 1.375
[5,     3] loss: 1.389
[6,     3] loss: 1.385
[7,     3] loss: 1.388
[8,     3] loss: 1.368
[9,     3] loss: 1.377
[10,     3] loss: 1.358
[11,     3] loss: 1.360
[12,     3] loss: 1.329
[13,     3] loss: 1.299
[14,     3] loss: 1.242
[15,     3] loss: 1.268
[16,     3] loss: 1.201
[17,     3] loss: 1.097
[18,     3] loss: 1.183
[19,     3] loss: 1.248
[20,     3] loss: 1.109
[21,     3] loss: 1.089
[22,     3] loss: 1.060
[23,     3] loss: 0.976
[24,     3] loss: 0.959
[25,     3] loss: 0.928
[26,     3] loss: 0.970
[27,     3] loss: 1.084
[28,     3] loss: 1.017
[29,     3] loss: 1.021
[30,     3] loss: 1.046
[31,     3] loss: 1.070
[32,     3] loss: 1.042
[33,     3] loss: 1.047
[34,     3] loss: 1.010
[35,     3] loss: 0.989
[36,     3] loss: 0.978
[37,     3] loss: 0.943
[38,     3] loss: 0.971
[39,     3] loss: 0.984
[40,     3] loss: 0.941
[41,     3] loss: 0.977
[42,     3] loss: 1.032
[43,     3] loss: 0.991
[44,     3] loss: 0.947
[45,     3] loss: 1.009
[46,     3] loss: 0.940
[47,     3] loss: 0.907
[48,     3] loss: 0.907
[49,     3] loss: 0.918
[50,     3] loss: 0.899
[51,     3] loss: 0.853
[52,     3] loss: 0.982
[53,     3] loss: 0.896
[54,     3] loss: 0.868
[55,     3] loss: 0.840
[56,     3] loss: 0.901
[57,     3] loss: 0.863
[58,     3] loss: 0.819
[59,     3] loss: 0.814
[60,     3] loss: 0.805
[61,     3] loss: 0.864
[62,     3] loss: 0.866
[63,     3] loss: 0.889
[64,     3] loss: 0.894
[65,     3] loss: 0.877
[66,     3] loss: 0.831
[67,     3] loss: 0.873
Early stopping applied (best metric=0.5281855463981628)
Finished Training
Total time taken: 14.84306263923645
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.388
[3,     3] loss: 1.389
[4,     3] loss: 1.378
[5,     3] loss: 1.392
[6,     3] loss: 1.370
[7,     3] loss: 1.365
[8,     3] loss: 1.346
[9,     3] loss: 1.336
[10,     3] loss: 1.286
[11,     3] loss: 1.282
[12,     3] loss: 1.186
[13,     3] loss: 1.207
[14,     3] loss: 1.163
[15,     3] loss: 1.125
[16,     3] loss: 1.039
[17,     3] loss: 1.059
[18,     3] loss: 1.048
[19,     3] loss: 1.090
[20,     3] loss: 1.017
[21,     3] loss: 0.950
[22,     3] loss: 0.984
[23,     3] loss: 0.978
[24,     3] loss: 0.968
[25,     3] loss: 0.947
[26,     3] loss: 1.086
[27,     3] loss: 0.940
[28,     3] loss: 1.096
[29,     3] loss: 1.272
[30,     3] loss: 1.065
[31,     3] loss: 1.029
[32,     3] loss: 0.984
[33,     3] loss: 0.925
[34,     3] loss: 0.969
[35,     3] loss: 0.980
[36,     3] loss: 0.954
[37,     3] loss: 0.978
[38,     3] loss: 0.958
[39,     3] loss: 1.016
[40,     3] loss: 0.963
[41,     3] loss: 0.966
[42,     3] loss: 0.948
[43,     3] loss: 0.894
[44,     3] loss: 0.913
[45,     3] loss: 0.834
[46,     3] loss: 0.856
[47,     3] loss: 0.787
[48,     3] loss: 0.910
[49,     3] loss: 0.860
[50,     3] loss: 0.812
[51,     3] loss: 0.830
[52,     3] loss: 0.812
[53,     3] loss: 0.773
[54,     3] loss: 0.805
[55,     3] loss: 0.768
[56,     3] loss: 0.859
[57,     3] loss: 1.071
[58,     3] loss: 1.077
[59,     3] loss: 0.973
[60,     3] loss: 0.965
[61,     3] loss: 0.890
[62,     3] loss: 0.848
[63,     3] loss: 0.845
[64,     3] loss: 0.840
[65,     3] loss: 0.896
[66,     3] loss: 0.875
[67,     3] loss: 0.971
[68,     3] loss: 0.880
[69,     3] loss: 0.893
[70,     3] loss: 0.813
[71,     3] loss: 0.774
[72,     3] loss: 0.853
[73,     3] loss: 1.000
[74,     3] loss: 0.951
[75,     3] loss: 1.018
[76,     3] loss: 0.883
[77,     3] loss: 0.877
[78,     3] loss: 0.880
[79,     3] loss: 0.801
[80,     3] loss: 0.779
[81,     3] loss: 0.757
[82,     3] loss: 0.760
[83,     3] loss: 0.761
[84,     3] loss: 0.898
[85,     3] loss: 0.846
Early stopping applied (best metric=0.5212156772613525)
Finished Training
Total time taken: 18.932058572769165
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.384
[3,     3] loss: 1.382
[4,     3] loss: 1.400
[5,     3] loss: 1.387
[6,     3] loss: 1.382
[7,     3] loss: 1.379
[8,     3] loss: 1.391
[9,     3] loss: 1.388
[10,     3] loss: 1.383
[11,     3] loss: 1.380
[12,     3] loss: 1.381
[13,     3] loss: 1.366
[14,     3] loss: 1.357
[15,     3] loss: 1.340
[16,     3] loss: 1.301
[17,     3] loss: 1.301
[18,     3] loss: 1.252
[19,     3] loss: 1.245
[20,     3] loss: 1.263
[21,     3] loss: 1.227
[22,     3] loss: 1.131
[23,     3] loss: 1.178
[24,     3] loss: 1.075
[25,     3] loss: 1.086
[26,     3] loss: 1.076
[27,     3] loss: 1.082
[28,     3] loss: 1.159
[29,     3] loss: 1.162
[30,     3] loss: 1.125
[31,     3] loss: 1.031
[32,     3] loss: 1.085
[33,     3] loss: 1.060
[34,     3] loss: 0.983
[35,     3] loss: 1.059
[36,     3] loss: 1.034
[37,     3] loss: 0.967
[38,     3] loss: 1.104
[39,     3] loss: 0.973
[40,     3] loss: 0.960
[41,     3] loss: 0.980
[42,     3] loss: 0.947
[43,     3] loss: 0.941
[44,     3] loss: 0.898
[45,     3] loss: 1.013
[46,     3] loss: 1.038
[47,     3] loss: 0.945
[48,     3] loss: 0.926
[49,     3] loss: 0.839
[50,     3] loss: 0.857
[51,     3] loss: 0.822
[52,     3] loss: 0.821
[53,     3] loss: 0.921
[54,     3] loss: 0.824
[55,     3] loss: 0.861
[56,     3] loss: 0.838
[57,     3] loss: 0.912
[58,     3] loss: 0.805
[59,     3] loss: 0.855
[60,     3] loss: 1.353
[61,     3] loss: 0.967
[62,     3] loss: 1.014
[63,     3] loss: 1.045
[64,     3] loss: 1.071
[65,     3] loss: 0.933
[66,     3] loss: 0.957
[67,     3] loss: 0.933
[68,     3] loss: 0.880
[69,     3] loss: 0.818
[70,     3] loss: 0.801
[71,     3] loss: 0.896
[72,     3] loss: 0.823
[73,     3] loss: 0.816
[74,     3] loss: 0.792
[75,     3] loss: 0.752
[76,     3] loss: 0.742
[77,     3] loss: 0.740
[78,     3] loss: 0.804
[79,     3] loss: 0.834
Early stopping applied (best metric=0.5091959834098816)
Finished Training
Total time taken: 17.67907452583313
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.389
[3,     3] loss: 1.382
[4,     3] loss: 1.385
[5,     3] loss: 1.388
[6,     3] loss: 1.386
[7,     3] loss: 1.387
[8,     3] loss: 1.384
[9,     3] loss: 1.383
[10,     3] loss: 1.383
[11,     3] loss: 1.379
[12,     3] loss: 1.371
[13,     3] loss: 1.362
[14,     3] loss: 1.300
[15,     3] loss: 1.283
[16,     3] loss: 1.287
[17,     3] loss: 1.222
[18,     3] loss: 1.164
[19,     3] loss: 1.286
[20,     3] loss: 1.197
[21,     3] loss: 1.159
[22,     3] loss: 1.157
[23,     3] loss: 1.069
[24,     3] loss: 1.125
[25,     3] loss: 1.060
[26,     3] loss: 1.042
[27,     3] loss: 1.174
[28,     3] loss: 1.119
[29,     3] loss: 1.241
[30,     3] loss: 1.155
[31,     3] loss: 1.146
[32,     3] loss: 1.111
[33,     3] loss: 1.065
[34,     3] loss: 1.025
[35,     3] loss: 1.028
[36,     3] loss: 1.048
[37,     3] loss: 1.075
[38,     3] loss: 1.032
[39,     3] loss: 1.034
[40,     3] loss: 1.008
[41,     3] loss: 0.989
[42,     3] loss: 1.097
[43,     3] loss: 0.906
[44,     3] loss: 0.945
[45,     3] loss: 0.925
[46,     3] loss: 0.915
[47,     3] loss: 0.892
[48,     3] loss: 0.850
[49,     3] loss: 0.952
[50,     3] loss: 0.836
[51,     3] loss: 1.026
[52,     3] loss: 1.011
[53,     3] loss: 1.004
[54,     3] loss: 0.954
[55,     3] loss: 1.007
[56,     3] loss: 0.976
[57,     3] loss: 0.941
[58,     3] loss: 0.893
[59,     3] loss: 0.998
[60,     3] loss: 0.917
[61,     3] loss: 0.881
[62,     3] loss: 0.817
[63,     3] loss: 0.790
[64,     3] loss: 0.799
[65,     3] loss: 1.010
[66,     3] loss: 0.977
[67,     3] loss: 0.978
[68,     3] loss: 0.976
[69,     3] loss: 0.906
[70,     3] loss: 0.910
[71,     3] loss: 0.856
[72,     3] loss: 0.800
[73,     3] loss: 0.810
[74,     3] loss: 0.835
[75,     3] loss: 0.742
[76,     3] loss: 0.849
[77,     3] loss: 0.833
[78,     3] loss: 0.995
[79,     3] loss: 0.966
[80,     3] loss: 0.889
[81,     3] loss: 0.921
[82,     3] loss: 0.878
[83,     3] loss: 0.829
[84,     3] loss: 0.822
[85,     3] loss: 0.844
Early stopping applied (best metric=0.5350538492202759)
Finished Training
Total time taken: 19.018059492111206
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.399
[2,     3] loss: 1.384
[3,     3] loss: 1.390
[4,     3] loss: 1.387
[5,     3] loss: 1.385
[6,     3] loss: 1.387
[7,     3] loss: 1.387
[8,     3] loss: 1.387
[9,     3] loss: 1.390
[10,     3] loss: 1.386
[11,     3] loss: 1.379
[12,     3] loss: 1.370
[13,     3] loss: 1.367
[14,     3] loss: 1.303
[15,     3] loss: 1.305
[16,     3] loss: 1.280
[17,     3] loss: 1.244
[18,     3] loss: 1.219
[19,     3] loss: 1.225
[20,     3] loss: 1.103
[21,     3] loss: 1.151
[22,     3] loss: 1.126
[23,     3] loss: 1.113
[24,     3] loss: 1.079
[25,     3] loss: 1.019
[26,     3] loss: 0.948
[27,     3] loss: 0.927
[28,     3] loss: 1.035
[29,     3] loss: 0.912
[30,     3] loss: 0.999
[31,     3] loss: 0.969
[32,     3] loss: 0.944
[33,     3] loss: 0.917
[34,     3] loss: 1.040
[35,     3] loss: 0.897
[36,     3] loss: 0.941
[37,     3] loss: 1.025
[38,     3] loss: 1.130
[39,     3] loss: 1.056
[40,     3] loss: 0.921
[41,     3] loss: 0.927
[42,     3] loss: 0.886
[43,     3] loss: 0.881
[44,     3] loss: 0.797
[45,     3] loss: 0.789
[46,     3] loss: 0.797
[47,     3] loss: 0.809
[48,     3] loss: 0.820
[49,     3] loss: 0.805
[50,     3] loss: 0.811
[51,     3] loss: 0.829
[52,     3] loss: 0.954
[53,     3] loss: 0.852
[54,     3] loss: 0.844
[55,     3] loss: 0.953
[56,     3] loss: 0.839
[57,     3] loss: 0.910
[58,     3] loss: 0.951
[59,     3] loss: 0.917
[60,     3] loss: 0.886
[61,     3] loss: 0.818
[62,     3] loss: 0.849
[63,     3] loss: 0.799
[64,     3] loss: 0.788
[65,     3] loss: 0.804
[66,     3] loss: 0.878
[67,     3] loss: 0.954
[68,     3] loss: 0.920
[69,     3] loss: 0.951
[70,     3] loss: 0.901
[71,     3] loss: 0.803
[72,     3] loss: 0.843
Early stopping applied (best metric=0.5329692363739014)
Finished Training
Total time taken: 16.079050540924072
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.381
[3,     3] loss: 1.372
[4,     3] loss: 1.408
[5,     3] loss: 1.383
[6,     3] loss: 1.386
[7,     3] loss: 1.382
[8,     3] loss: 1.388
[9,     3] loss: 1.383
[10,     3] loss: 1.384
[11,     3] loss: 1.366
[12,     3] loss: 1.368
[13,     3] loss: 1.345
[14,     3] loss: 1.339
[15,     3] loss: 1.294
[16,     3] loss: 1.270
[17,     3] loss: 1.261
[18,     3] loss: 1.166
[19,     3] loss: 1.213
[20,     3] loss: 1.137
[21,     3] loss: 1.028
[22,     3] loss: 1.022
[23,     3] loss: 1.061
[24,     3] loss: 1.122
[25,     3] loss: 1.222
[26,     3] loss: 1.279
[27,     3] loss: 1.358
[28,     3] loss: 1.179
[29,     3] loss: 1.277
[30,     3] loss: 1.190
[31,     3] loss: 1.180
[32,     3] loss: 1.158
[33,     3] loss: 1.045
[34,     3] loss: 0.990
[35,     3] loss: 0.974
[36,     3] loss: 1.074
[37,     3] loss: 1.112
[38,     3] loss: 0.994
[39,     3] loss: 1.037
[40,     3] loss: 1.019
[41,     3] loss: 0.990
[42,     3] loss: 0.951
[43,     3] loss: 0.995
[44,     3] loss: 0.918
[45,     3] loss: 0.951
[46,     3] loss: 0.929
[47,     3] loss: 0.947
[48,     3] loss: 0.930
[49,     3] loss: 0.886
[50,     3] loss: 0.819
[51,     3] loss: 0.798
[52,     3] loss: 0.811
[53,     3] loss: 0.809
[54,     3] loss: 0.819
[55,     3] loss: 1.342
[56,     3] loss: 0.955
[57,     3] loss: 0.960
[58,     3] loss: 0.998
[59,     3] loss: 1.000
[60,     3] loss: 0.932
[61,     3] loss: 0.899
[62,     3] loss: 0.832
[63,     3] loss: 0.820
[64,     3] loss: 0.830
[65,     3] loss: 1.026
[66,     3] loss: 0.916
[67,     3] loss: 0.946
[68,     3] loss: 0.959
[69,     3] loss: 0.908
[70,     3] loss: 0.847
[71,     3] loss: 0.854
[72,     3] loss: 0.922
[73,     3] loss: 0.935
Early stopping applied (best metric=0.5304552316665649)
Finished Training
Total time taken: 16.296058654785156
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.403
[3,     3] loss: 1.398
[4,     3] loss: 1.394
[5,     3] loss: 1.371
[6,     3] loss: 1.384
[7,     3] loss: 1.406
[8,     3] loss: 1.388
[9,     3] loss: 1.385
[10,     3] loss: 1.387
[11,     3] loss: 1.381
[12,     3] loss: 1.401
[13,     3] loss: 1.392
[14,     3] loss: 1.381
[15,     3] loss: 1.389
[16,     3] loss: 1.380
[17,     3] loss: 1.376
[18,     3] loss: 1.372
[19,     3] loss: 1.363
[20,     3] loss: 1.321
[21,     3] loss: 1.287
[22,     3] loss: 1.273
[23,     3] loss: 1.275
[24,     3] loss: 1.181
[25,     3] loss: 1.182
[26,     3] loss: 1.165
[27,     3] loss: 1.109
[28,     3] loss: 1.248
[29,     3] loss: 1.390
[30,     3] loss: 1.150
[31,     3] loss: 1.244
[32,     3] loss: 1.185
[33,     3] loss: 1.101
[34,     3] loss: 1.087
[35,     3] loss: 1.133
[36,     3] loss: 1.137
[37,     3] loss: 1.060
[38,     3] loss: 1.007
[39,     3] loss: 1.076
[40,     3] loss: 1.042
[41,     3] loss: 1.017
[42,     3] loss: 1.119
[43,     3] loss: 0.989
[44,     3] loss: 1.018
[45,     3] loss: 1.060
[46,     3] loss: 1.007
[47,     3] loss: 1.034
[48,     3] loss: 1.000
[49,     3] loss: 1.066
[50,     3] loss: 0.988
[51,     3] loss: 0.987
[52,     3] loss: 0.926
[53,     3] loss: 0.881
[54,     3] loss: 0.881
[55,     3] loss: 0.776
[56,     3] loss: 0.898
[57,     3] loss: 0.868
[58,     3] loss: 0.934
[59,     3] loss: 0.844
[60,     3] loss: 0.937
[61,     3] loss: 0.943
[62,     3] loss: 0.924
[63,     3] loss: 0.908
[64,     3] loss: 0.863
[65,     3] loss: 0.872
[66,     3] loss: 0.815
[67,     3] loss: 0.850
[68,     3] loss: 0.818
[69,     3] loss: 0.897
[70,     3] loss: 0.991
[71,     3] loss: 0.915
[72,     3] loss: 0.888
[73,     3] loss: 0.834
[74,     3] loss: 0.808
[75,     3] loss: 1.009
[76,     3] loss: 0.795
[77,     3] loss: 0.834
[78,     3] loss: 0.834
[79,     3] loss: 0.897
[80,     3] loss: 0.820
[81,     3] loss: 0.908
[82,     3] loss: 0.911
[83,     3] loss: 0.921
[84,     3] loss: 0.877
[85,     3] loss: 0.908
[86,     3] loss: 0.810
[87,     3] loss: 0.913
[88,     3] loss: 0.978
[89,     3] loss: 1.098
[90,     3] loss: 0.962
[91,     3] loss: 0.954
[92,     3] loss: 0.946
[93,     3] loss: 0.897
[94,     3] loss: 0.908
[95,     3] loss: 0.834
[96,     3] loss: 0.809
[97,     3] loss: 0.801
[98,     3] loss: 0.795
[99,     3] loss: 0.799
[100,     3] loss: 0.791
[101,     3] loss: 0.871
[102,     3] loss: 0.870
[103,     3] loss: 0.963
[104,     3] loss: 0.837
[105,     3] loss: 0.938
[106,     3] loss: 0.939
[107,     3] loss: 0.872
Early stopping applied (best metric=0.511269748210907)
Finished Training
Total time taken: 23.829951763153076
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.384
[3,     3] loss: 1.389
[4,     3] loss: 1.375
[5,     3] loss: 1.376
[6,     3] loss: 1.364
[7,     3] loss: 1.348
[8,     3] loss: 1.334
[9,     3] loss: 1.275
[10,     3] loss: 1.266
[11,     3] loss: 1.177
[12,     3] loss: 1.196
[13,     3] loss: 1.214
[14,     3] loss: 1.136
[15,     3] loss: 1.145
[16,     3] loss: 1.276
[17,     3] loss: 1.113
[18,     3] loss: 1.049
[19,     3] loss: 1.194
[20,     3] loss: 1.206
[21,     3] loss: 1.117
[22,     3] loss: 1.096
[23,     3] loss: 1.015
[24,     3] loss: 0.983
[25,     3] loss: 0.989
[26,     3] loss: 0.955
[27,     3] loss: 1.059
[28,     3] loss: 0.989
[29,     3] loss: 0.987
[30,     3] loss: 1.043
[31,     3] loss: 0.972
[32,     3] loss: 0.908
[33,     3] loss: 0.948
[34,     3] loss: 0.916
[35,     3] loss: 1.016
[36,     3] loss: 1.017
[37,     3] loss: 1.217
[38,     3] loss: 1.003
[39,     3] loss: 1.008
[40,     3] loss: 0.962
[41,     3] loss: 0.935
[42,     3] loss: 0.838
[43,     3] loss: 0.866
[44,     3] loss: 0.797
[45,     3] loss: 0.882
[46,     3] loss: 0.841
[47,     3] loss: 0.832
[48,     3] loss: 0.829
[49,     3] loss: 0.842
[50,     3] loss: 0.971
[51,     3] loss: 0.793
[52,     3] loss: 0.865
[53,     3] loss: 0.883
[54,     3] loss: 0.822
[55,     3] loss: 0.804
[56,     3] loss: 0.839
[57,     3] loss: 0.773
[58,     3] loss: 0.754
[59,     3] loss: 0.760
[60,     3] loss: 0.747
[61,     3] loss: 0.747
[62,     3] loss: 0.787
[63,     3] loss: 0.765
[64,     3] loss: 0.763
[65,     3] loss: 0.755
[66,     3] loss: 0.771
[67,     3] loss: 0.799
[68,     3] loss: 0.767
[69,     3] loss: 0.805
[70,     3] loss: 0.803
[71,     3] loss: 0.786
[72,     3] loss: 0.771
[73,     3] loss: 0.780
[74,     3] loss: 0.729
[75,     3] loss: 0.833
Early stopping applied (best metric=0.5149306058883667)
Finished Training
Total time taken: 16.870049953460693
{'S-palmitoylation-C Validation Accuracy': 0.6978035186550471, 'S-palmitoylation-C Validation Sensitivity': 0.23023102310231025, 'S-palmitoylation-C Validation Specificity': 0.8150052198711583, 'S-palmitoylation-C Validation Precision': 0.2525148232843304, 'S-palmitoylation-C AUC ROC': 0.5441324858608955, 'S-palmitoylation-C AUC PR': 0.22831164649144306, 'S-palmitoylation-C MCC': 0.049920263489365256, 'S-palmitoylation-C F1': 0.21371064670989948, 'Validation Loss (S-palmitoylation-C)': 0.5539123336474101, 'Hydroxylation-K Validation Accuracy': 0.732210401891253, 'Hydroxylation-K Validation Sensitivity': 0.762962962962963, 'Hydroxylation-K Validation Specificity': 0.724561403508772, 'Hydroxylation-K Validation Precision': 0.42984006734006736, 'Hydroxylation-K AUC ROC': 0.8142884990253411, 'Hydroxylation-K AUC PR': 0.619510050423419, 'Hydroxylation-K MCC': 0.4161999983059212, 'Hydroxylation-K F1': 0.5398463322726144, 'Validation Loss (Hydroxylation-K)': 0.5258556246757508, 'Validation Loss (total)': 1.0797679662704467, 'TimeToTrain': 17.093554639816283}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017046788029075946,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.38131266747943504,
 'loss_weight_S-palmitoylation-C': 0.7723278879835983,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1460541828,
 'sample_weights': [0.16223040641526915, 0.4387997672890222],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.637035908870966,
 'weight_decay_Hydroxylation-K': 1.8595273714254748,
 'weight_decay_S-palmitoylation-C': 1.2148054387661267}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.391
[3,     3] loss: 1.401
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007903490065939694,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.16083542835721398,
 'loss_weight_S-palmitoylation-C': 0.3581972854064275,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4840758,
 'sample_weights': [0.7723278879835983, 0.38131266747943504],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.803291895407109,
 'weight_decay_Hydroxylation-K': 5.0269950936721,
 'weight_decay_S-palmitoylation-C': 6.562965872912864}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.410
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018374947186396645,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.41454324881595306,
 'loss_weight_S-palmitoylation-C': 0.6163247757243915,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3420676032,
 'sample_weights': [0.3581972854064275, 0.16083542835721398],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.778252205578474,
 'weight_decay_Hydroxylation-K': 0.6451485380388061,
 'weight_decay_S-palmitoylation-C': 4.596402065584992}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.384
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003819724037570001,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8762481180505034,
 'loss_weight_S-palmitoylation-C': 0.3990518272737569,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3081988888,
 'sample_weights': [0.6163247757243915, 0.41454324881595306],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.063575793531523,
 'weight_decay_Hydroxylation-K': 2.6742585503298937,
 'weight_decay_S-palmitoylation-C': 2.6192033222203337}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.380
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0044018007222283734,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5277592294093539,
 'loss_weight_S-palmitoylation-C': 0.2202774404265061,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3623049654,
 'sample_weights': [0.3990518272737569, 0.8762481180505034],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.433137493119498,
 'weight_decay_Hydroxylation-K': 1.8253873798440767,
 'weight_decay_S-palmitoylation-C': 0.22178940035483624}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.408
[2,     3] loss: 1.395
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027386028865200836,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.436466186946042,
 'loss_weight_S-palmitoylation-C': 0.05312052888619359,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 858976707,
 'sample_weights': [0.2202774404265061, 0.5277592294093539],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1443868592041238,
 'weight_decay_Hydroxylation-K': 5.298237447537237,
 'weight_decay_S-palmitoylation-C': 5.845167796368506}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.392
[3,     3] loss: 1.388
[4,     3] loss: 1.386
[5,     3] loss: 1.383
[6,     3] loss: 1.384
[7,     3] loss: 1.380
[8,     3] loss: 1.392
[9,     3] loss: 1.382
[10,     3] loss: 1.375
[11,     3] loss: 1.375
[12,     3] loss: 1.377
[13,     3] loss: 1.363
[14,     3] loss: 1.360
[15,     3] loss: 1.334
[16,     3] loss: 1.298
[17,     3] loss: 1.299
[18,     3] loss: 1.294
[19,     3] loss: 1.266
[20,     3] loss: 1.276
[21,     3] loss: 1.259
[22,     3] loss: 1.197
[23,     3] loss: 1.212
[24,     3] loss: 1.197
[25,     3] loss: 1.212
[26,     3] loss: 1.194
[27,     3] loss: 1.092
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015016487369931462,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9652890046667922,
 'loss_weight_S-palmitoylation-C': 0.14009856493173295,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 739636958,
 'sample_weights': [0.05312052888619359, 0.436466186946042],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.722414880279432,
 'weight_decay_Hydroxylation-K': 2.572664781057106,
 'weight_decay_S-palmitoylation-C': 5.240696710734107}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.389
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002151578874905424,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5219449073511672,
 'loss_weight_S-palmitoylation-C': 0.19370713901406109,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3284908111,
 'sample_weights': [0.14009856493173295, 0.9652890046667922],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9386108245945599,
 'weight_decay_Hydroxylation-K': 3.707367289809328,
 'weight_decay_S-palmitoylation-C': 9.85391822979333}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.392
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0039444769115515805,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.32722541782502806,
 'loss_weight_S-palmitoylation-C': 0.20729084096222836,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3077229757,
 'sample_weights': [0.19370713901406109, 0.5219449073511672],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.6982366797728967,
 'weight_decay_Hydroxylation-K': 5.024658657444693,
 'weight_decay_S-palmitoylation-C': 4.976841444650487}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.393
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006323944158492345,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.987262130811829,
 'loss_weight_S-palmitoylation-C': 0.1314930114187312,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1821252597,
 'sample_weights': [0.20729084096222836, 0.32722541782502806],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.791214371103742,
 'weight_decay_Hydroxylation-K': 1.095444630620623,
 'weight_decay_S-palmitoylation-C': 4.77768135513692}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.394
[3,     3] loss: 1.392
[4,     3] loss: 1.381
[5,     3] loss: 1.389
[6,     3] loss: 1.389
[7,     3] loss: 1.390
[8,     3] loss: 1.388
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009180635008686884,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5532645133125904,
 'loss_weight_S-palmitoylation-C': 0.5695430299621324,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3344848876,
 'sample_weights': [0.1314930114187312, 0.987262130811829],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.779196531758725,
 'weight_decay_Hydroxylation-K': 1.332960997524455,
 'weight_decay_S-palmitoylation-C': 7.180788682736753}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.389
[3,     3] loss: 1.397
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001274978803027165,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7462102693031055,
 'loss_weight_S-palmitoylation-C': 0.42665029644154373,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1566502372,
 'sample_weights': [0.5695430299621324, 0.5532645133125904],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.586921765937018,
 'weight_decay_Hydroxylation-K': 4.0955887333005085,
 'weight_decay_S-palmitoylation-C': 6.586919570030668}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.389
[3,     3] loss: 1.380
[4,     3] loss: 1.379
[5,     3] loss: 1.395
[6,     3] loss: 1.376
[7,     3] loss: 1.387
[8,     3] loss: 1.384
[9,     3] loss: 1.384
[10,     3] loss: 1.379
[11,     3] loss: 1.371
[12,     3] loss: 1.358
[13,     3] loss: 1.340
[14,     3] loss: 1.333
[15,     3] loss: 1.321
[16,     3] loss: 1.301
[17,     3] loss: 1.298
[18,     3] loss: 1.232
[19,     3] loss: 1.231
[20,     3] loss: 1.185
[21,     3] loss: 1.105
[22,     3] loss: 1.089
[23,     3] loss: 1.103
[24,     3] loss: 0.998
[25,     3] loss: 1.096
[26,     3] loss: 0.944
[27,     3] loss: 1.096
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008022731890028481,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9224097057369569,
 'loss_weight_S-palmitoylation-C': 0.5415431636660869,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2908257968,
 'sample_weights': [0.42665029644154373, 0.7462102693031055],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1562107796239514,
 'weight_decay_Hydroxylation-K': 3.03888115926099,
 'weight_decay_S-palmitoylation-C': 5.512434523836931}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.386
[3,     3] loss: 1.382
[4,     3] loss: 1.390
[5,     3] loss: 1.383
[6,     3] loss: 1.384
[7,     3] loss: 1.384
[8,     3] loss: 1.367
[9,     3] loss: 1.365
[10,     3] loss: 1.352
[11,     3] loss: 1.334
[12,     3] loss: 1.332
[13,     3] loss: 1.325
[14,     3] loss: 1.288
[15,     3] loss: 1.240
[16,     3] loss: 1.264
[17,     3] loss: 1.309
[18,     3] loss: 1.206
[19,     3] loss: 1.229
[20,     3] loss: 1.203
[21,     3] loss: 1.228
[22,     3] loss: 1.113
[23,     3] loss: 1.053
[24,     3] loss: 1.075
[25,     3] loss: 1.043
[26,     3] loss: 1.168
[27,     3] loss: 0.971
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009062229392860312,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.16416315580277732,
 'loss_weight_S-palmitoylation-C': 0.1152120792663503,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1217614536,
 'sample_weights': [0.5415431636660869, 0.9224097057369569],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.263983276628701,
 'weight_decay_Hydroxylation-K': 9.022284478923062,
 'weight_decay_S-palmitoylation-C': 2.8577573379455132}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005459375289187725,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7818912916107819,
 'loss_weight_S-palmitoylation-C': 0.7763677978767876,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1398656096,
 'sample_weights': [0.1152120792663503, 0.16416315580277732],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.56609776092716,
 'weight_decay_Hydroxylation-K': 2.1885622883966365,
 'weight_decay_S-palmitoylation-C': 3.714548127062791}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.391
[3,     3] loss: 1.376
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004813040051968862,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.0931634446003573,
 'loss_weight_S-palmitoylation-C': 0.28054790436988636,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 80308237,
 'sample_weights': [0.7763677978767876, 0.7818912916107819],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.1357664837989785,
 'weight_decay_Hydroxylation-K': 2.177847045176474,
 'weight_decay_S-palmitoylation-C': 0.40237063025732794}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.401
[2,     3] loss: 1.388
[3,     3] loss: 1.385
[4,     3] loss: 1.394
[5,     3] loss: 1.384
[6,     3] loss: 1.401
[7,     3] loss: 1.378
[8,     3] loss: 1.382
[9,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016894756317058206,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7528736018479806,
 'loss_weight_S-palmitoylation-C': 0.575739195947933,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2848195068,
 'sample_weights': [0.28054790436988636, 0.0931634446003573],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.24254377305519093,
 'weight_decay_Hydroxylation-K': 6.020839670515244,
 'weight_decay_S-palmitoylation-C': 3.598141364935372}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.399
[2,     3] loss: 1.386
[3,     3] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013924186487003106,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7616821764570871,
 'loss_weight_S-palmitoylation-C': 0.4824951195978608,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 94404857,
 'sample_weights': [0.575739195947933, 0.7528736018479806],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.935864659894733,
 'weight_decay_Hydroxylation-K': 4.857503956971987,
 'weight_decay_S-palmitoylation-C': 8.349645565135534}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.387
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025721419192243256,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.46347646298781703,
 'loss_weight_S-palmitoylation-C': 0.9892467081171175,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2536345211,
 'sample_weights': [0.4824951195978608, 0.7616821764570871],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.170323883123263,
 'weight_decay_Hydroxylation-K': 4.0411093398401405,
 'weight_decay_S-palmitoylation-C': 0.917697447314348}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.392
[3,     3] loss: 1.383
[4,     3] loss: 1.378
[5,     3] loss: 1.368
[6,     3] loss: 1.388
[7,     3] loss: 1.375
[8,     3] loss: 1.357
[9,     3] loss: 1.348
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007654975850122342,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9809066411233637,
 'loss_weight_S-palmitoylation-C': 0.43111616522168417,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2256646657,
 'sample_weights': [0.9892467081171175, 0.46347646298781703],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.449321583392782,
 'weight_decay_Hydroxylation-K': 4.000157294385133,
 'weight_decay_S-palmitoylation-C': 3.079755510055077}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.396
[3,     3] loss: 1.387
[4,     3] loss: 1.381
[5,     3] loss: 1.388
[6,     3] loss: 1.385
[7,     3] loss: 1.380
[8,     3] loss: 1.366
[9,     3] loss: 1.381
[10,     3] loss: 1.366
[11,     3] loss: 1.361
[12,     3] loss: 1.349
[13,     3] loss: 1.323
[14,     3] loss: 1.314
[15,     3] loss: 1.297
[16,     3] loss: 1.283
[17,     3] loss: 1.215
[18,     3] loss: 1.181
[19,     3] loss: 1.193
[20,     3] loss: 1.167
[21,     3] loss: 1.100
[22,     3] loss: 1.103
[23,     3] loss: 1.120
[24,     3] loss: 1.164
[25,     3] loss: 1.026
[26,     3] loss: 1.139
[27,     3] loss: 1.030
[28,     3] loss: 1.035
[29,     3] loss: 1.113
[30,     3] loss: 1.108
[31,     3] loss: 1.046
[32,     3] loss: 1.222
[33,     3] loss: 1.041
[34,     3] loss: 1.065
[35,     3] loss: 1.006
[36,     3] loss: 1.065
[37,     3] loss: 0.935
[38,     3] loss: 1.065
[39,     3] loss: 0.964
[40,     3] loss: 0.906
[41,     3] loss: 0.942
[42,     3] loss: 0.905
[43,     3] loss: 0.957
[44,     3] loss: 0.905
[45,     3] loss: 0.925
[46,     3] loss: 0.900
[47,     3] loss: 0.922
[48,     3] loss: 0.982
[49,     3] loss: 0.942
[50,     3] loss: 0.848
[51,     3] loss: 0.864
[52,     3] loss: 0.983
[53,     3] loss: 0.847
[54,     3] loss: 0.965
[55,     3] loss: 0.846
[56,     3] loss: 0.854
[57,     3] loss: 0.860
[58,     3] loss: 0.921
[59,     3] loss: 0.857
[60,     3] loss: 0.913
[61,     3] loss: 0.937
[62,     3] loss: 0.821
[63,     3] loss: 0.907
[64,     3] loss: 0.916
[65,     3] loss: 0.909
[66,     3] loss: 0.895
[67,     3] loss: 0.819
[68,     3] loss: 0.857
[69,     3] loss: 0.907
[70,     3] loss: 0.858
[71,     3] loss: 0.852
[72,     3] loss: 0.919
[73,     3] loss: 0.822
[74,     3] loss: 0.786
[75,     3] loss: 0.902
[76,     3] loss: 0.856
[77,     3] loss: 0.814
[78,     3] loss: 0.796
[79,     3] loss: 0.795
[80,     3] loss: 0.833
[81,     3] loss: 0.814
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005364702413091574,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.823889740034396,
 'loss_weight_S-palmitoylation-C': 0.584912577525441,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2595727647,
 'sample_weights': [0.43111616522168417, 0.9809066411233637],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.437712673635859,
 'weight_decay_Hydroxylation-K': 2.202821556435802,
 'weight_decay_S-palmitoylation-C': 6.59777502025273}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.383
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005143895906485715,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22398974810728262,
 'loss_weight_S-palmitoylation-C': 0.41131642275102975,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1499989251,
 'sample_weights': [0.584912577525441, 0.823889740034396],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.496139007745151,
 'weight_decay_Hydroxylation-K': 9.531927139134933,
 'weight_decay_S-palmitoylation-C': 5.921457800946591}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.383
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002849486041031242,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24706981769915956,
 'loss_weight_S-palmitoylation-C': 0.2705300932008706,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4124738157,
 'sample_weights': [0.41131642275102975, 0.22398974810728262],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.063302505261081,
 'weight_decay_Hydroxylation-K': 0.912836687045664,
 'weight_decay_S-palmitoylation-C': 0.08371066817630435}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.373
[3,     3] loss: 1.391
[4,     3] loss: 1.392
[5,     3] loss: 1.388
[6,     3] loss: 1.387
[7,     3] loss: 1.383
[8,     3] loss: 1.387
[9,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010425232938393563,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8865527359685555,
 'loss_weight_S-palmitoylation-C': 0.3483414045984558,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1054507306,
 'sample_weights': [0.2705300932008706, 0.24706981769915956],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7862752653241385,
 'weight_decay_Hydroxylation-K': 5.410585741319953,
 'weight_decay_S-palmitoylation-C': 6.969690600807115}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.379
[2,     3] loss: 1.386
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011549367281212513,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2501880289322188,
 'loss_weight_S-palmitoylation-C': 0.34466684371258094,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4279814193,
 'sample_weights': [0.3483414045984558, 0.8865527359685555],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.0314821967788035,
 'weight_decay_Hydroxylation-K': 0.5775989276231249,
 'weight_decay_S-palmitoylation-C': 4.066984447730577}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.412
[3,     3] loss: 1.389
[4,     3] loss: 1.392
[5,     3] loss: 1.381
[6,     3] loss: 1.386
[7,     3] loss: 1.390
[8,     3] loss: 1.386
[9,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007238113915337057,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9975799163318645,
 'loss_weight_S-palmitoylation-C': 0.8868899740883467,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2505444361,
 'sample_weights': [0.34466684371258094, 0.2501880289322188],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.085796870473524,
 'weight_decay_Hydroxylation-K': 9.324843249312538,
 'weight_decay_S-palmitoylation-C': 9.207144851031039}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.392
[4,     3] loss: 1.388
[5,     3] loss: 1.384
[6,     3] loss: 1.386
[7,     3] loss: 1.386
[8,     3] loss: 1.380
[9,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002285070845682634,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5967689021202491,
 'loss_weight_S-palmitoylation-C': 0.3016896891681036,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 641669577,
 'sample_weights': [0.8868899740883467, 0.9975799163318645],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9761542486012456,
 'weight_decay_Hydroxylation-K': 3.4327069283000347,
 'weight_decay_S-palmitoylation-C': 5.382110509844005}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.393
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020382861880234773,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6000612316741467,
 'loss_weight_S-palmitoylation-C': 0.25542761959029453,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1867147198,
 'sample_weights': [0.3016896891681036, 0.5967689021202491],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7401236307664627,
 'weight_decay_Hydroxylation-K': 1.2631740125801687,
 'weight_decay_S-palmitoylation-C': 1.1359723768339562}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.388
[3,     3] loss: 1.389
[4,     3] loss: 1.388
[5,     3] loss: 1.381
[6,     3] loss: 1.380
[7,     3] loss: 1.388
[8,     3] loss: 1.378
[9,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015239144111687196,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9123438588420076,
 'loss_weight_S-palmitoylation-C': 0.6175463478109956,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 812735606,
 'sample_weights': [0.25542761959029453, 0.6000612316741467],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9875425938637985,
 'weight_decay_Hydroxylation-K': 4.321687962149788,
 'weight_decay_S-palmitoylation-C': 5.1368498734176}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.381
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00037355288178015473,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9611403967332438,
 'loss_weight_S-palmitoylation-C': 0.5429596010502923,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2492398783,
 'sample_weights': [0.6175463478109956, 0.9123438588420076],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2107310381253655,
 'weight_decay_Hydroxylation-K': 1.4104984458469354,
 'weight_decay_S-palmitoylation-C': 3.761694368386233}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.386
[3,     3] loss: 1.387
[4,     3] loss: 1.380
[5,     3] loss: 1.384
[6,     3] loss: 1.392
[7,     3] loss: 1.392
[8,     3] loss: 1.376
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015313769754772288,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8099414989991554,
 'loss_weight_S-palmitoylation-C': 0.3604170411383182,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2626888705,
 'sample_weights': [0.5429596010502923, 0.9611403967332438],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.9968103130310624,
 'weight_decay_Hydroxylation-K': 2.653992006886986,
 'weight_decay_S-palmitoylation-C': 5.279842944533966}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.385
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 9.199623887460326e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7974486664705679,
 'loss_weight_S-palmitoylation-C': 0.297557780590077,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 595939065,
 'sample_weights': [0.3604170411383182, 0.8099414989991554],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.795469176235264,
 'weight_decay_Hydroxylation-K': 5.742186969739077,
 'weight_decay_S-palmitoylation-C': 4.426755596996609}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.386
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005304737384176363,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.23777578618702747,
 'loss_weight_S-palmitoylation-C': 0.11588161483783878,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1568962323,
 'sample_weights': [0.297557780590077, 0.7974486664705679],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.977466032672103,
 'weight_decay_Hydroxylation-K': 2.2366561606685726,
 'weight_decay_S-palmitoylation-C': 1.1322346144302202}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.374
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00020472184603784866,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.10612682892186298,
 'loss_weight_S-palmitoylation-C': 0.46893853999220536,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 295084826,
 'sample_weights': [0.11588161483783878, 0.23777578618702747],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.751360725557742,
 'weight_decay_Hydroxylation-K': 1.8362278998864328,
 'weight_decay_S-palmitoylation-C': 4.945197466615807}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.393
[3,     3] loss: 1.384
[4,     3] loss: 1.391
[5,     3] loss: 1.392
[6,     3] loss: 1.379
[7,     3] loss: 1.385
[8,     3] loss: 1.383
[9,     3] loss: 1.380
[10,     3] loss: 1.378
[11,     3] loss: 1.377
[12,     3] loss: 1.372
[13,     3] loss: 1.372
[14,     3] loss: 1.371
[15,     3] loss: 1.376
[16,     3] loss: 1.363
[17,     3] loss: 1.355
[18,     3] loss: 1.346
[19,     3] loss: 1.344
[20,     3] loss: 1.327
[21,     3] loss: 1.323
[22,     3] loss: 1.315
[23,     3] loss: 1.305
[24,     3] loss: 1.275
[25,     3] loss: 1.254
[26,     3] loss: 1.279
[27,     3] loss: 1.253
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027021028026905152,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4276731172014597,
 'loss_weight_S-palmitoylation-C': 0.1920983579783738,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4046696571,
 'sample_weights': [0.46893853999220536, 0.10612682892186298],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.1185736648378,
 'weight_decay_Hydroxylation-K': 4.1619836439013245,
 'weight_decay_S-palmitoylation-C': 2.532624764066253}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.384
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000576719350261898,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.11864379134534205,
 'loss_weight_S-palmitoylation-C': 0.35963079730059183,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1006506994,
 'sample_weights': [0.1920983579783738, 0.4276731172014597],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.581923069942576,
 'weight_decay_Hydroxylation-K': 4.178497716907359,
 'weight_decay_S-palmitoylation-C': 2.0633396687477275}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.388
[3,     3] loss: 1.385
[4,     3] loss: 1.379
[5,     3] loss: 1.381
[6,     3] loss: 1.380
[7,     3] loss: 1.366
[8,     3] loss: 1.367
[9,     3] loss: 1.363
[10,     3] loss: 1.345
[11,     3] loss: 1.339
[12,     3] loss: 1.367
[13,     3] loss: 1.346
[14,     3] loss: 1.314
[15,     3] loss: 1.283
[16,     3] loss: 1.252
[17,     3] loss: 1.250
[18,     3] loss: 1.213
[19,     3] loss: 1.245
[20,     3] loss: 1.185
[21,     3] loss: 1.182
[22,     3] loss: 1.144
[23,     3] loss: 1.093
[24,     3] loss: 1.105
[25,     3] loss: 1.005
[26,     3] loss: 0.960
[27,     3] loss: 0.957
[28,     3] loss: 0.987
[29,     3] loss: 1.040
[30,     3] loss: 0.964
[31,     3] loss: 1.048
[32,     3] loss: 1.056
[33,     3] loss: 0.963
[34,     3] loss: 1.023
[35,     3] loss: 0.919
[36,     3] loss: 0.899
[37,     3] loss: 0.903
[38,     3] loss: 0.892
[39,     3] loss: 0.918
[40,     3] loss: 0.925
[41,     3] loss: 1.011
[42,     3] loss: 0.936
[43,     3] loss: 0.942
[44,     3] loss: 0.887
[45,     3] loss: 0.887
[46,     3] loss: 0.865
[47,     3] loss: 0.856
[48,     3] loss: 0.845
[49,     3] loss: 0.874
[50,     3] loss: 0.954
[51,     3] loss: 0.914
[52,     3] loss: 0.827
[53,     3] loss: 0.874
[54,     3] loss: 0.818
[55,     3] loss: 0.911
[56,     3] loss: 0.963
[57,     3] loss: 0.853
[58,     3] loss: 0.825
[59,     3] loss: 0.809
[60,     3] loss: 0.829
[61,     3] loss: 0.783
[62,     3] loss: 0.825
[63,     3] loss: 0.801
[64,     3] loss: 0.785
[65,     3] loss: 0.776
[66,     3] loss: 0.775
[67,     3] loss: 0.798
[68,     3] loss: 0.794
[69,     3] loss: 0.779
[70,     3] loss: 0.841
[71,     3] loss: 0.828
[72,     3] loss: 0.865
[73,     3] loss: 0.903
[74,     3] loss: 0.858
[75,     3] loss: 0.863
Early stopping applied (best metric=0.5132371187210083)
Finished Training
Total time taken: 16.617058753967285
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.383
[3,     3] loss: 1.377
[4,     3] loss: 1.376
[5,     3] loss: 1.379
[6,     3] loss: 1.391
[7,     3] loss: 1.376
[8,     3] loss: 1.384
[9,     3] loss: 1.376
[10,     3] loss: 1.394
[11,     3] loss: 1.380
[12,     3] loss: 1.369
[13,     3] loss: 1.358
[14,     3] loss: 1.354
[15,     3] loss: 1.336
[16,     3] loss: 1.344
[17,     3] loss: 1.297
[18,     3] loss: 1.310
[19,     3] loss: 1.287
[20,     3] loss: 1.299
[21,     3] loss: 1.261
[22,     3] loss: 1.214
[23,     3] loss: 1.188
[24,     3] loss: 1.182
[25,     3] loss: 1.175
[26,     3] loss: 1.179
[27,     3] loss: 1.058
[28,     3] loss: 1.067
[29,     3] loss: 1.023
[30,     3] loss: 1.127
[31,     3] loss: 1.122
[32,     3] loss: 0.979
[33,     3] loss: 1.019
[34,     3] loss: 1.100
[35,     3] loss: 0.927
[36,     3] loss: 0.988
[37,     3] loss: 0.983
[38,     3] loss: 0.977
[39,     3] loss: 1.005
[40,     3] loss: 0.959
[41,     3] loss: 1.022
[42,     3] loss: 0.939
[43,     3] loss: 0.987
[44,     3] loss: 0.895
[45,     3] loss: 0.958
[46,     3] loss: 0.965
[47,     3] loss: 0.864
[48,     3] loss: 0.840
[49,     3] loss: 0.891
[50,     3] loss: 0.954
[51,     3] loss: 0.868
[52,     3] loss: 0.857
[53,     3] loss: 0.807
[54,     3] loss: 0.831
[55,     3] loss: 0.846
[56,     3] loss: 0.811
[57,     3] loss: 0.829
[58,     3] loss: 0.813
[59,     3] loss: 0.763
[60,     3] loss: 0.755
[61,     3] loss: 0.805
[62,     3] loss: 0.832
[63,     3] loss: 0.786
[64,     3] loss: 0.799
[65,     3] loss: 0.780
[66,     3] loss: 0.791
[67,     3] loss: 0.815
[68,     3] loss: 0.881
[69,     3] loss: 0.891
[70,     3] loss: 0.781
[71,     3] loss: 0.803
[72,     3] loss: 0.956
[73,     3] loss: 0.894
[74,     3] loss: 0.809
[75,     3] loss: 0.918
[76,     3] loss: 0.819
[77,     3] loss: 0.857
Early stopping applied (best metric=0.48220282793045044)
Finished Training
Total time taken: 17.02605652809143
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.383
[3,     3] loss: 1.385
[4,     3] loss: 1.384
[5,     3] loss: 1.370
[6,     3] loss: 1.385
[7,     3] loss: 1.373
[8,     3] loss: 1.368
[9,     3] loss: 1.365
[10,     3] loss: 1.345
[11,     3] loss: 1.338
[12,     3] loss: 1.298
[13,     3] loss: 1.282
[14,     3] loss: 1.283
[15,     3] loss: 1.285
[16,     3] loss: 1.227
[17,     3] loss: 1.222
[18,     3] loss: 1.131
[19,     3] loss: 1.126
[20,     3] loss: 1.105
[21,     3] loss: 1.079
[22,     3] loss: 1.009
[23,     3] loss: 1.070
[24,     3] loss: 0.987
[25,     3] loss: 0.929
[26,     3] loss: 0.943
[27,     3] loss: 0.957
[28,     3] loss: 1.120
[29,     3] loss: 0.971
[30,     3] loss: 0.993
[31,     3] loss: 0.941
[32,     3] loss: 0.939
[33,     3] loss: 0.930
[34,     3] loss: 0.960
[35,     3] loss: 1.059
[36,     3] loss: 0.983
[37,     3] loss: 0.948
[38,     3] loss: 0.947
[39,     3] loss: 0.935
[40,     3] loss: 0.927
[41,     3] loss: 0.973
[42,     3] loss: 1.032
[43,     3] loss: 0.912
[44,     3] loss: 0.955
[45,     3] loss: 0.926
[46,     3] loss: 0.990
[47,     3] loss: 0.905
[48,     3] loss: 0.885
[49,     3] loss: 0.893
[50,     3] loss: 0.833
[51,     3] loss: 0.795
[52,     3] loss: 0.828
[53,     3] loss: 0.805
[54,     3] loss: 0.829
[55,     3] loss: 0.779
[56,     3] loss: 0.777
[57,     3] loss: 0.781
[58,     3] loss: 0.779
[59,     3] loss: 0.816
[60,     3] loss: 0.822
[61,     3] loss: 0.884
[62,     3] loss: 0.773
[63,     3] loss: 0.943
[64,     3] loss: 0.765
[65,     3] loss: 0.859
[66,     3] loss: 0.802
[67,     3] loss: 0.835
[68,     3] loss: 0.805
[69,     3] loss: 0.809
[70,     3] loss: 0.872
[71,     3] loss: 0.828
Early stopping applied (best metric=0.5472168922424316)
Finished Training
Total time taken: 15.814857482910156
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.384
[3,     3] loss: 1.384
[4,     3] loss: 1.384
[5,     3] loss: 1.388
[6,     3] loss: 1.371
[7,     3] loss: 1.370
[8,     3] loss: 1.366
[9,     3] loss: 1.341
[10,     3] loss: 1.340
[11,     3] loss: 1.312
[12,     3] loss: 1.295
[13,     3] loss: 1.255
[14,     3] loss: 1.264
[15,     3] loss: 1.242
[16,     3] loss: 1.259
[17,     3] loss: 1.156
[18,     3] loss: 1.166
[19,     3] loss: 1.105
[20,     3] loss: 1.118
[21,     3] loss: 1.142
[22,     3] loss: 1.062
[23,     3] loss: 1.113
[24,     3] loss: 1.014
[25,     3] loss: 1.030
[26,     3] loss: 1.047
[27,     3] loss: 1.025
[28,     3] loss: 0.983
[29,     3] loss: 1.044
[30,     3] loss: 0.927
[31,     3] loss: 0.932
[32,     3] loss: 0.970
[33,     3] loss: 0.927
[34,     3] loss: 1.008
[35,     3] loss: 0.912
[36,     3] loss: 0.877
[37,     3] loss: 0.984
[38,     3] loss: 0.845
[39,     3] loss: 0.924
[40,     3] loss: 0.989
[41,     3] loss: 1.089
[42,     3] loss: 0.857
[43,     3] loss: 0.858
[44,     3] loss: 0.897
[45,     3] loss: 1.027
[46,     3] loss: 0.880
[47,     3] loss: 0.871
[48,     3] loss: 0.879
[49,     3] loss: 0.873
[50,     3] loss: 0.848
[51,     3] loss: 0.906
[52,     3] loss: 0.955
[53,     3] loss: 0.852
[54,     3] loss: 0.838
[55,     3] loss: 0.863
[56,     3] loss: 0.835
[57,     3] loss: 0.865
[58,     3] loss: 0.792
[59,     3] loss: 0.789
[60,     3] loss: 0.822
[61,     3] loss: 0.776
[62,     3] loss: 0.774
[63,     3] loss: 0.825
[64,     3] loss: 0.760
[65,     3] loss: 0.824
[66,     3] loss: 0.861
[67,     3] loss: 0.887
[68,     3] loss: 0.810
[69,     3] loss: 0.958
[70,     3] loss: 0.904
[71,     3] loss: 0.817
[72,     3] loss: 0.844
[73,     3] loss: 0.803
[74,     3] loss: 0.797
[75,     3] loss: 0.769
[76,     3] loss: 0.778
[77,     3] loss: 0.795
[78,     3] loss: 0.752
[79,     3] loss: 0.789
[80,     3] loss: 0.754
[81,     3] loss: 0.745
[82,     3] loss: 0.737
[83,     3] loss: 0.770
[84,     3] loss: 0.733
[85,     3] loss: 0.733
[86,     3] loss: 0.727
[87,     3] loss: 0.745
[88,     3] loss: 0.724
Early stopping applied (best metric=0.5040832757949829)
Finished Training
Total time taken: 19.658743381500244
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.389
[3,     3] loss: 1.388
[4,     3] loss: 1.386
[5,     3] loss: 1.376
[6,     3] loss: 1.381
[7,     3] loss: 1.382
[8,     3] loss: 1.375
[9,     3] loss: 1.370
[10,     3] loss: 1.363
[11,     3] loss: 1.363
[12,     3] loss: 1.342
[13,     3] loss: 1.322
[14,     3] loss: 1.297
[15,     3] loss: 1.317
[16,     3] loss: 1.279
[17,     3] loss: 1.279
[18,     3] loss: 1.231
[19,     3] loss: 1.284
[20,     3] loss: 1.252
[21,     3] loss: 1.267
[22,     3] loss: 1.181
[23,     3] loss: 1.122
[24,     3] loss: 1.138
[25,     3] loss: 1.098
[26,     3] loss: 1.079
[27,     3] loss: 1.066
[28,     3] loss: 1.074
[29,     3] loss: 0.963
[30,     3] loss: 0.994
[31,     3] loss: 1.146
[32,     3] loss: 1.016
[33,     3] loss: 1.026
[34,     3] loss: 1.086
[35,     3] loss: 0.935
[36,     3] loss: 0.950
[37,     3] loss: 0.967
[38,     3] loss: 0.897
[39,     3] loss: 0.898
[40,     3] loss: 0.946
[41,     3] loss: 1.006
[42,     3] loss: 1.083
[43,     3] loss: 1.022
[44,     3] loss: 0.991
[45,     3] loss: 1.044
[46,     3] loss: 1.028
[47,     3] loss: 0.910
[48,     3] loss: 0.963
[49,     3] loss: 1.000
[50,     3] loss: 0.938
[51,     3] loss: 0.885
[52,     3] loss: 0.863
[53,     3] loss: 0.915
[54,     3] loss: 0.851
[55,     3] loss: 0.866
[56,     3] loss: 0.848
[57,     3] loss: 0.844
[58,     3] loss: 0.860
[59,     3] loss: 0.847
[60,     3] loss: 0.825
[61,     3] loss: 0.842
[62,     3] loss: 0.824
[63,     3] loss: 0.787
[64,     3] loss: 0.824
[65,     3] loss: 0.796
[66,     3] loss: 0.806
[67,     3] loss: 0.842
[68,     3] loss: 0.764
[69,     3] loss: 0.843
[70,     3] loss: 0.805
[71,     3] loss: 0.782
[72,     3] loss: 0.846
[73,     3] loss: 0.808
[74,     3] loss: 0.895
[75,     3] loss: 0.866
[76,     3] loss: 0.798
Early stopping applied (best metric=0.518011212348938)
Finished Training
Total time taken: 16.891053676605225
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.380
[3,     3] loss: 1.390
[4,     3] loss: 1.388
[5,     3] loss: 1.389
[6,     3] loss: 1.380
[7,     3] loss: 1.381
[8,     3] loss: 1.371
[9,     3] loss: 1.366
[10,     3] loss: 1.356
[11,     3] loss: 1.360
[12,     3] loss: 1.329
[13,     3] loss: 1.309
[14,     3] loss: 1.319
[15,     3] loss: 1.260
[16,     3] loss: 1.291
[17,     3] loss: 1.284
[18,     3] loss: 1.243
[19,     3] loss: 1.150
[20,     3] loss: 1.223
[21,     3] loss: 1.156
[22,     3] loss: 1.135
[23,     3] loss: 1.239
[24,     3] loss: 1.172
[25,     3] loss: 1.081
[26,     3] loss: 1.097
[27,     3] loss: 1.027
[28,     3] loss: 1.010
[29,     3] loss: 1.052
[30,     3] loss: 0.982
[31,     3] loss: 0.962
[32,     3] loss: 1.039
[33,     3] loss: 0.971
[34,     3] loss: 0.954
[35,     3] loss: 1.000
[36,     3] loss: 1.024
[37,     3] loss: 1.020
[38,     3] loss: 1.034
[39,     3] loss: 1.047
[40,     3] loss: 0.966
[41,     3] loss: 0.919
[42,     3] loss: 0.921
[43,     3] loss: 0.902
[44,     3] loss: 0.985
[45,     3] loss: 0.897
[46,     3] loss: 0.875
[47,     3] loss: 0.887
[48,     3] loss: 0.853
[49,     3] loss: 0.823
[50,     3] loss: 0.897
[51,     3] loss: 0.868
[52,     3] loss: 0.811
[53,     3] loss: 0.835
[54,     3] loss: 0.842
[55,     3] loss: 0.821
[56,     3] loss: 0.803
[57,     3] loss: 0.837
[58,     3] loss: 0.771
[59,     3] loss: 0.768
[60,     3] loss: 0.775
[61,     3] loss: 0.789
[62,     3] loss: 0.802
[63,     3] loss: 0.755
[64,     3] loss: 0.793
[65,     3] loss: 0.899
[66,     3] loss: 0.787
[67,     3] loss: 0.829
[68,     3] loss: 0.791
[69,     3] loss: 0.838
[70,     3] loss: 0.838
[71,     3] loss: 0.797
[72,     3] loss: 0.782
[73,     3] loss: 0.774
[74,     3] loss: 0.773
[75,     3] loss: 0.824
[76,     3] loss: 0.830
[77,     3] loss: 0.840
[78,     3] loss: 0.782
[79,     3] loss: 0.768
[80,     3] loss: 0.764
[81,     3] loss: 0.760
[82,     3] loss: 0.765
[83,     3] loss: 0.757
[84,     3] loss: 0.767
Early stopping applied (best metric=0.5137296915054321)
Finished Training
Total time taken: 19.72106432914734
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.391
[4,     3] loss: 1.388
[5,     3] loss: 1.380
[6,     3] loss: 1.381
[7,     3] loss: 1.382
[8,     3] loss: 1.386
[9,     3] loss: 1.381
[10,     3] loss: 1.374
[11,     3] loss: 1.364
[12,     3] loss: 1.355
[13,     3] loss: 1.337
[14,     3] loss: 1.320
[15,     3] loss: 1.341
[16,     3] loss: 1.283
[17,     3] loss: 1.272
[18,     3] loss: 1.279
[19,     3] loss: 1.277
[20,     3] loss: 1.242
[21,     3] loss: 1.248
[22,     3] loss: 1.187
[23,     3] loss: 1.168
[24,     3] loss: 1.121
[25,     3] loss: 1.084
[26,     3] loss: 1.142
[27,     3] loss: 1.034
[28,     3] loss: 1.055
[29,     3] loss: 1.117
[30,     3] loss: 1.009
[31,     3] loss: 0.988
[32,     3] loss: 1.010
[33,     3] loss: 0.952
[34,     3] loss: 0.967
[35,     3] loss: 1.058
[36,     3] loss: 0.979
[37,     3] loss: 0.904
[38,     3] loss: 1.022
[39,     3] loss: 0.877
[40,     3] loss: 0.929
[41,     3] loss: 0.851
[42,     3] loss: 0.932
[43,     3] loss: 0.947
[44,     3] loss: 0.882
[45,     3] loss: 0.822
[46,     3] loss: 0.807
[47,     3] loss: 0.863
[48,     3] loss: 0.843
[49,     3] loss: 0.800
[50,     3] loss: 0.801
[51,     3] loss: 0.833
[52,     3] loss: 0.805
[53,     3] loss: 0.970
[54,     3] loss: 1.112
[55,     3] loss: 0.989
[56,     3] loss: 0.890
[57,     3] loss: 1.049
[58,     3] loss: 0.838
[59,     3] loss: 0.836
[60,     3] loss: 0.902
[61,     3] loss: 0.820
[62,     3] loss: 0.826
[63,     3] loss: 0.849
[64,     3] loss: 0.816
[65,     3] loss: 0.779
[66,     3] loss: 0.786
[67,     3] loss: 0.759
[68,     3] loss: 0.803
[69,     3] loss: 0.771
[70,     3] loss: 0.753
[71,     3] loss: 0.746
[72,     3] loss: 0.763
[73,     3] loss: 0.772
[74,     3] loss: 0.745
[75,     3] loss: 0.779
[76,     3] loss: 0.738
[77,     3] loss: 0.740
Early stopping applied (best metric=0.5351438522338867)
Finished Training
Total time taken: 17.076054334640503
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.388
[3,     3] loss: 1.385
[4,     3] loss: 1.388
[5,     3] loss: 1.382
[6,     3] loss: 1.382
[7,     3] loss: 1.381
[8,     3] loss: 1.374
[9,     3] loss: 1.370
[10,     3] loss: 1.369
[11,     3] loss: 1.362
[12,     3] loss: 1.346
[13,     3] loss: 1.330
[14,     3] loss: 1.340
[15,     3] loss: 1.332
[16,     3] loss: 1.292
[17,     3] loss: 1.285
[18,     3] loss: 1.313
[19,     3] loss: 1.241
[20,     3] loss: 1.224
[21,     3] loss: 1.143
[22,     3] loss: 1.134
[23,     3] loss: 1.106
[24,     3] loss: 1.073
[25,     3] loss: 1.060
[26,     3] loss: 1.006
[27,     3] loss: 1.056
[28,     3] loss: 1.073
[29,     3] loss: 1.023
[30,     3] loss: 0.962
[31,     3] loss: 1.018
[32,     3] loss: 0.966
[33,     3] loss: 1.071
[34,     3] loss: 0.976
[35,     3] loss: 0.992
[36,     3] loss: 0.962
[37,     3] loss: 0.929
[38,     3] loss: 0.939
[39,     3] loss: 0.989
[40,     3] loss: 0.897
[41,     3] loss: 0.919
[42,     3] loss: 1.023
[43,     3] loss: 0.877
[44,     3] loss: 0.871
[45,     3] loss: 0.945
[46,     3] loss: 0.840
[47,     3] loss: 0.901
[48,     3] loss: 0.873
[49,     3] loss: 0.960
[50,     3] loss: 0.904
[51,     3] loss: 0.873
[52,     3] loss: 0.817
[53,     3] loss: 0.867
[54,     3] loss: 0.878
[55,     3] loss: 0.859
[56,     3] loss: 0.804
[57,     3] loss: 0.786
[58,     3] loss: 0.774
[59,     3] loss: 0.808
[60,     3] loss: 0.850
[61,     3] loss: 0.758
[62,     3] loss: 0.774
[63,     3] loss: 0.820
[64,     3] loss: 0.794
[65,     3] loss: 0.781
[66,     3] loss: 0.782
[67,     3] loss: 0.825
[68,     3] loss: 0.822
[69,     3] loss: 0.788
[70,     3] loss: 0.822
[71,     3] loss: 0.770
[72,     3] loss: 0.758
[73,     3] loss: 0.747
Early stopping applied (best metric=0.5306655168533325)
Finished Training
Total time taken: 16.15605330467224
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.390
[3,     3] loss: 1.382
[4,     3] loss: 1.381
[5,     3] loss: 1.390
[6,     3] loss: 1.387
[7,     3] loss: 1.381
[8,     3] loss: 1.379
[9,     3] loss: 1.381
[10,     3] loss: 1.370
[11,     3] loss: 1.373
[12,     3] loss: 1.357
[13,     3] loss: 1.344
[14,     3] loss: 1.343
[15,     3] loss: 1.328
[16,     3] loss: 1.325
[17,     3] loss: 1.263
[18,     3] loss: 1.293
[19,     3] loss: 1.251
[20,     3] loss: 1.206
[21,     3] loss: 1.147
[22,     3] loss: 1.140
[23,     3] loss: 1.141
[24,     3] loss: 1.039
[25,     3] loss: 1.112
[26,     3] loss: 1.076
[27,     3] loss: 1.096
[28,     3] loss: 1.030
[29,     3] loss: 1.060
[30,     3] loss: 1.022
[31,     3] loss: 1.014
[32,     3] loss: 0.941
[33,     3] loss: 0.951
[34,     3] loss: 0.960
[35,     3] loss: 0.953
[36,     3] loss: 0.957
[37,     3] loss: 0.919
[38,     3] loss: 1.032
[39,     3] loss: 0.975
[40,     3] loss: 1.046
[41,     3] loss: 0.884
[42,     3] loss: 0.986
[43,     3] loss: 1.091
[44,     3] loss: 0.991
[45,     3] loss: 0.873
[46,     3] loss: 0.960
[47,     3] loss: 0.967
[48,     3] loss: 0.914
[49,     3] loss: 0.905
[50,     3] loss: 0.832
[51,     3] loss: 0.950
[52,     3] loss: 0.933
[53,     3] loss: 0.848
[54,     3] loss: 0.887
[55,     3] loss: 0.867
[56,     3] loss: 0.862
[57,     3] loss: 0.974
[58,     3] loss: 0.874
[59,     3] loss: 0.910
[60,     3] loss: 0.865
[61,     3] loss: 0.848
[62,     3] loss: 0.812
[63,     3] loss: 0.834
[64,     3] loss: 0.822
[65,     3] loss: 0.822
[66,     3] loss: 0.820
[67,     3] loss: 0.828
[68,     3] loss: 0.794
[69,     3] loss: 0.859
[70,     3] loss: 0.799
[71,     3] loss: 0.842
[72,     3] loss: 0.813
[73,     3] loss: 0.833
[74,     3] loss: 0.804
Early stopping applied (best metric=0.4850154519081116)
Finished Training
Total time taken: 16.528053760528564
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.380
[2,     3] loss: 1.390
[3,     3] loss: 1.386
[4,     3] loss: 1.383
[5,     3] loss: 1.382
[6,     3] loss: 1.384
[7,     3] loss: 1.385
[8,     3] loss: 1.379
[9,     3] loss: 1.386
[10,     3] loss: 1.375
[11,     3] loss: 1.372
[12,     3] loss: 1.355
[13,     3] loss: 1.353
[14,     3] loss: 1.329
[15,     3] loss: 1.321
[16,     3] loss: 1.302
[17,     3] loss: 1.300
[18,     3] loss: 1.259
[19,     3] loss: 1.252
[20,     3] loss: 1.238
[21,     3] loss: 1.235
[22,     3] loss: 1.212
[23,     3] loss: 1.123
[24,     3] loss: 1.194
[25,     3] loss: 1.108
[26,     3] loss: 1.229
[27,     3] loss: 1.059
[28,     3] loss: 1.072
[29,     3] loss: 1.061
[30,     3] loss: 1.126
[31,     3] loss: 1.067
[32,     3] loss: 1.049
[33,     3] loss: 1.134
[34,     3] loss: 1.098
[35,     3] loss: 1.081
[36,     3] loss: 0.982
[37,     3] loss: 1.043
[38,     3] loss: 1.048
[39,     3] loss: 0.985
[40,     3] loss: 0.964
[41,     3] loss: 0.903
[42,     3] loss: 0.896
[43,     3] loss: 0.873
[44,     3] loss: 0.897
[45,     3] loss: 0.985
[46,     3] loss: 0.943
[47,     3] loss: 0.891
[48,     3] loss: 0.938
[49,     3] loss: 0.867
[50,     3] loss: 0.842
[51,     3] loss: 0.838
[52,     3] loss: 0.856
[53,     3] loss: 0.808
[54,     3] loss: 0.827
[55,     3] loss: 0.821
[56,     3] loss: 0.796
[57,     3] loss: 0.799
[58,     3] loss: 0.880
[59,     3] loss: 0.855
[60,     3] loss: 0.829
[61,     3] loss: 0.978
[62,     3] loss: 0.873
[63,     3] loss: 0.797
[64,     3] loss: 0.854
[65,     3] loss: 0.845
[66,     3] loss: 0.841
[67,     3] loss: 0.810
[68,     3] loss: 0.828
[69,     3] loss: 0.780
[70,     3] loss: 0.776
[71,     3] loss: 0.787
[72,     3] loss: 0.760
[73,     3] loss: 0.811
[74,     3] loss: 0.770
[75,     3] loss: 0.785
[76,     3] loss: 0.769
[77,     3] loss: 0.760
[78,     3] loss: 0.748
[79,     3] loss: 0.788
[80,     3] loss: 0.752
[81,     3] loss: 0.748
[82,     3] loss: 0.762
[83,     3] loss: 0.741
[84,     3] loss: 0.746
[85,     3] loss: 0.747
[86,     3] loss: 0.759
[87,     3] loss: 0.744
[88,     3] loss: 0.750
[89,     3] loss: 0.746
[90,     3] loss: 0.773
[91,     3] loss: 0.772
[92,     3] loss: 0.753
Early stopping applied (best metric=0.5125876069068909)
Finished Training
Total time taken: 20.392067432403564
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.384
[3,     3] loss: 1.386
[4,     3] loss: 1.395
[5,     3] loss: 1.393
[6,     3] loss: 1.387
[7,     3] loss: 1.378
[8,     3] loss: 1.381
[9,     3] loss: 1.384
[10,     3] loss: 1.380
[11,     3] loss: 1.384
[12,     3] loss: 1.373
[13,     3] loss: 1.369
[14,     3] loss: 1.360
[15,     3] loss: 1.355
[16,     3] loss: 1.338
[17,     3] loss: 1.333
[18,     3] loss: 1.305
[19,     3] loss: 1.270
[20,     3] loss: 1.289
[21,     3] loss: 1.228
[22,     3] loss: 1.236
[23,     3] loss: 1.172
[24,     3] loss: 1.132
[25,     3] loss: 1.134
[26,     3] loss: 1.055
[27,     3] loss: 1.025
[28,     3] loss: 1.117
[29,     3] loss: 1.123
[30,     3] loss: 1.131
[31,     3] loss: 1.075
[32,     3] loss: 1.001
[33,     3] loss: 1.054
[34,     3] loss: 1.048
[35,     3] loss: 1.031
[36,     3] loss: 0.943
[37,     3] loss: 1.088
[38,     3] loss: 0.899
[39,     3] loss: 1.024
[40,     3] loss: 0.950
[41,     3] loss: 0.903
[42,     3] loss: 0.875
[43,     3] loss: 0.912
[44,     3] loss: 0.959
[45,     3] loss: 0.893
[46,     3] loss: 0.917
[47,     3] loss: 0.862
[48,     3] loss: 0.875
[49,     3] loss: 0.811
[50,     3] loss: 1.050
[51,     3] loss: 0.823
[52,     3] loss: 0.854
[53,     3] loss: 0.882
[54,     3] loss: 0.845
[55,     3] loss: 0.865
[56,     3] loss: 0.897
[57,     3] loss: 0.816
[58,     3] loss: 0.920
[59,     3] loss: 0.847
[60,     3] loss: 0.824
[61,     3] loss: 0.843
[62,     3] loss: 0.804
[63,     3] loss: 0.900
[64,     3] loss: 0.824
[65,     3] loss: 0.836
[66,     3] loss: 0.862
[67,     3] loss: 0.806
[68,     3] loss: 0.942
[69,     3] loss: 1.027
[70,     3] loss: 0.903
[71,     3] loss: 0.833
[72,     3] loss: 0.896
[73,     3] loss: 0.840
[74,     3] loss: 0.830
[75,     3] loss: 0.867
[76,     3] loss: 0.823
[77,     3] loss: 0.821
[78,     3] loss: 0.805
Early stopping applied (best metric=0.5247993469238281)
Finished Training
Total time taken: 17.295664310455322
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.385
[3,     3] loss: 1.385
[4,     3] loss: 1.380
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.379
[8,     3] loss: 1.381
[9,     3] loss: 1.375
[10,     3] loss: 1.376
[11,     3] loss: 1.369
[12,     3] loss: 1.355
[13,     3] loss: 1.355
[14,     3] loss: 1.343
[15,     3] loss: 1.328
[16,     3] loss: 1.305
[17,     3] loss: 1.281
[18,     3] loss: 1.292
[19,     3] loss: 1.271
[20,     3] loss: 1.264
[21,     3] loss: 1.216
[22,     3] loss: 1.228
[23,     3] loss: 1.223
[24,     3] loss: 1.220
[25,     3] loss: 1.144
[26,     3] loss: 1.138
[27,     3] loss: 1.095
[28,     3] loss: 1.027
[29,     3] loss: 1.026
[30,     3] loss: 1.020
[31,     3] loss: 1.091
[32,     3] loss: 0.951
[33,     3] loss: 0.950
[34,     3] loss: 1.004
[35,     3] loss: 1.002
[36,     3] loss: 0.990
[37,     3] loss: 0.935
[38,     3] loss: 0.920
[39,     3] loss: 0.895
[40,     3] loss: 0.849
[41,     3] loss: 0.851
[42,     3] loss: 0.835
[43,     3] loss: 0.848
[44,     3] loss: 0.820
[45,     3] loss: 0.836
[46,     3] loss: 0.815
[47,     3] loss: 0.845
[48,     3] loss: 0.831
[49,     3] loss: 0.873
[50,     3] loss: 0.921
[51,     3] loss: 0.779
[52,     3] loss: 0.879
[53,     3] loss: 0.824
[54,     3] loss: 0.813
[55,     3] loss: 0.806
[56,     3] loss: 0.938
[57,     3] loss: 0.813
[58,     3] loss: 0.807
[59,     3] loss: 0.846
[60,     3] loss: 0.846
[61,     3] loss: 0.822
[62,     3] loss: 0.847
[63,     3] loss: 0.790
[64,     3] loss: 0.788
[65,     3] loss: 0.789
[66,     3] loss: 0.785
[67,     3] loss: 0.802
[68,     3] loss: 0.768
[69,     3] loss: 0.759
[70,     3] loss: 0.778
[71,     3] loss: 0.790
[72,     3] loss: 0.803
[73,     3] loss: 0.786
[74,     3] loss: 0.767
[75,     3] loss: 0.755
[76,     3] loss: 0.755
[77,     3] loss: 0.749
[78,     3] loss: 0.779
[79,     3] loss: 0.747
[80,     3] loss: 0.818
[81,     3] loss: 0.786
[82,     3] loss: 0.728
Early stopping applied (best metric=0.4800151586532593)
Finished Training
Total time taken: 18.31514310836792
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.383
[3,     3] loss: 1.383
[4,     3] loss: 1.385
[5,     3] loss: 1.390
[6,     3] loss: 1.376
[7,     3] loss: 1.376
[8,     3] loss: 1.376
[9,     3] loss: 1.363
[10,     3] loss: 1.359
[11,     3] loss: 1.351
[12,     3] loss: 1.334
[13,     3] loss: 1.317
[14,     3] loss: 1.327
[15,     3] loss: 1.260
[16,     3] loss: 1.267
[17,     3] loss: 1.188
[18,     3] loss: 1.270
[19,     3] loss: 1.194
[20,     3] loss: 1.122
[21,     3] loss: 1.159
[22,     3] loss: 1.106
[23,     3] loss: 1.023
[24,     3] loss: 1.045
[25,     3] loss: 1.097
[26,     3] loss: 1.083
[27,     3] loss: 0.969
[28,     3] loss: 1.033
[29,     3] loss: 1.000
[30,     3] loss: 0.965
[31,     3] loss: 1.083
[32,     3] loss: 1.141
[33,     3] loss: 0.956
[34,     3] loss: 1.054
[35,     3] loss: 0.949
[36,     3] loss: 1.024
[37,     3] loss: 1.074
[38,     3] loss: 0.937
[39,     3] loss: 0.947
[40,     3] loss: 0.875
[41,     3] loss: 0.928
[42,     3] loss: 0.891
[43,     3] loss: 0.905
[44,     3] loss: 0.836
[45,     3] loss: 0.811
[46,     3] loss: 0.831
[47,     3] loss: 0.868
[48,     3] loss: 0.956
[49,     3] loss: 0.851
[50,     3] loss: 1.065
[51,     3] loss: 0.931
[52,     3] loss: 0.969
[53,     3] loss: 0.983
[54,     3] loss: 1.000
[55,     3] loss: 0.978
[56,     3] loss: 0.874
[57,     3] loss: 0.873
[58,     3] loss: 0.855
[59,     3] loss: 0.883
[60,     3] loss: 0.864
[61,     3] loss: 0.878
[62,     3] loss: 0.837
[63,     3] loss: 0.897
[64,     3] loss: 0.868
[65,     3] loss: 0.918
[66,     3] loss: 0.911
[67,     3] loss: 0.900
[68,     3] loss: 0.860
[69,     3] loss: 0.816
[70,     3] loss: 0.814
[71,     3] loss: 0.934
[72,     3] loss: 0.799
[73,     3] loss: 0.848
[74,     3] loss: 0.798
[75,     3] loss: 0.776
[76,     3] loss: 0.826
[77,     3] loss: 0.792
Early stopping applied (best metric=0.5407208204269409)
Finished Training
Total time taken: 17.06405258178711
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.390
[3,     3] loss: 1.380
[4,     3] loss: 1.395
[5,     3] loss: 1.370
[6,     3] loss: 1.391
[7,     3] loss: 1.367
[8,     3] loss: 1.378
[9,     3] loss: 1.372
[10,     3] loss: 1.370
[11,     3] loss: 1.374
[12,     3] loss: 1.340
[13,     3] loss: 1.349
[14,     3] loss: 1.342
[15,     3] loss: 1.300
[16,     3] loss: 1.291
[17,     3] loss: 1.282
[18,     3] loss: 1.282
[19,     3] loss: 1.261
[20,     3] loss: 1.230
[21,     3] loss: 1.181
[22,     3] loss: 1.162
[23,     3] loss: 1.152
[24,     3] loss: 1.150
[25,     3] loss: 1.097
[26,     3] loss: 1.115
[27,     3] loss: 1.088
[28,     3] loss: 1.100
[29,     3] loss: 0.957
[30,     3] loss: 0.982
[31,     3] loss: 0.989
[32,     3] loss: 0.979
[33,     3] loss: 1.038
[34,     3] loss: 0.995
[35,     3] loss: 1.009
[36,     3] loss: 0.994
[37,     3] loss: 0.950
[38,     3] loss: 0.971
[39,     3] loss: 1.018
[40,     3] loss: 0.927
[41,     3] loss: 0.915
[42,     3] loss: 0.991
[43,     3] loss: 0.945
[44,     3] loss: 0.855
[45,     3] loss: 0.987
[46,     3] loss: 0.916
[47,     3] loss: 0.870
[48,     3] loss: 0.891
[49,     3] loss: 0.829
[50,     3] loss: 0.869
[51,     3] loss: 1.006
[52,     3] loss: 1.130
[53,     3] loss: 1.047
[54,     3] loss: 1.010
[55,     3] loss: 0.881
[56,     3] loss: 0.943
[57,     3] loss: 0.862
[58,     3] loss: 0.857
[59,     3] loss: 0.870
[60,     3] loss: 0.829
[61,     3] loss: 0.811
[62,     3] loss: 0.817
[63,     3] loss: 0.877
[64,     3] loss: 0.908
[65,     3] loss: 0.878
[66,     3] loss: 0.790
[67,     3] loss: 0.805
[68,     3] loss: 0.814
[69,     3] loss: 0.831
[70,     3] loss: 0.839
[71,     3] loss: 0.840
[72,     3] loss: 0.887
[73,     3] loss: 0.836
[74,     3] loss: 0.790
Early stopping applied (best metric=0.4624718129634857)
Finished Training
Total time taken: 16.505054235458374
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.389
[3,     3] loss: 1.384
[4,     3] loss: 1.384
[5,     3] loss: 1.383
[6,     3] loss: 1.384
[7,     3] loss: 1.386
[8,     3] loss: 1.383
[9,     3] loss: 1.388
[10,     3] loss: 1.379
[11,     3] loss: 1.374
[12,     3] loss: 1.368
[13,     3] loss: 1.363
[14,     3] loss: 1.365
[15,     3] loss: 1.347
[16,     3] loss: 1.334
[17,     3] loss: 1.305
[18,     3] loss: 1.278
[19,     3] loss: 1.238
[20,     3] loss: 1.186
[21,     3] loss: 1.192
[22,     3] loss: 1.204
[23,     3] loss: 1.195
[24,     3] loss: 1.063
[25,     3] loss: 1.146
[26,     3] loss: 1.125
[27,     3] loss: 1.010
[28,     3] loss: 1.015
[29,     3] loss: 1.019
[30,     3] loss: 1.121
[31,     3] loss: 0.942
[32,     3] loss: 0.983
[33,     3] loss: 0.891
[34,     3] loss: 1.016
[35,     3] loss: 1.039
[36,     3] loss: 0.909
[37,     3] loss: 1.061
[38,     3] loss: 1.003
[39,     3] loss: 0.957
[40,     3] loss: 1.058
[41,     3] loss: 1.016
[42,     3] loss: 0.920
[43,     3] loss: 1.056
[44,     3] loss: 0.946
[45,     3] loss: 0.919
[46,     3] loss: 0.927
[47,     3] loss: 0.955
[48,     3] loss: 0.936
[49,     3] loss: 0.995
[50,     3] loss: 0.910
[51,     3] loss: 0.939
[52,     3] loss: 0.878
[53,     3] loss: 0.909
[54,     3] loss: 0.878
[55,     3] loss: 0.890
[56,     3] loss: 0.940
[57,     3] loss: 0.994
[58,     3] loss: 0.867
[59,     3] loss: 0.912
[60,     3] loss: 0.898
[61,     3] loss: 0.868
[62,     3] loss: 0.951
[63,     3] loss: 0.885
[64,     3] loss: 0.843
[65,     3] loss: 0.899
[66,     3] loss: 0.839
[67,     3] loss: 0.813
[68,     3] loss: 0.795
[69,     3] loss: 0.807
[70,     3] loss: 0.811
[71,     3] loss: 0.770
[72,     3] loss: 0.787
[73,     3] loss: 0.759
[74,     3] loss: 0.758
[75,     3] loss: 0.797
[76,     3] loss: 0.845
[77,     3] loss: 0.864
[78,     3] loss: 0.768
[79,     3] loss: 0.850
[80,     3] loss: 0.809
[81,     3] loss: 0.775
[82,     3] loss: 0.780
[83,     3] loss: 0.819
[84,     3] loss: 0.774
[85,     3] loss: 0.778
[86,     3] loss: 0.810
[87,     3] loss: 0.773
[88,     3] loss: 0.768
[89,     3] loss: 0.751
[90,     3] loss: 0.772
[91,     3] loss: 0.758
[92,     3] loss: 0.761
[93,     3] loss: 0.806
[94,     3] loss: 0.762
[95,     3] loss: 0.768
[96,     3] loss: 0.775
[97,     3] loss: 0.769
[98,     3] loss: 0.776
[99,     3] loss: 0.764
[100,     3] loss: 0.776
[101,     3] loss: 0.828
[102,     3] loss: 0.798
[103,     3] loss: 0.744
[104,     3] loss: 0.776
[105,     3] loss: 0.775
[106,     3] loss: 0.736
[107,     3] loss: 0.761
[108,     3] loss: 0.733
Early stopping applied (best metric=0.5255908966064453)
Finished Training
Total time taken: 24.01807403564453
{'S-palmitoylation-C Validation Accuracy': 0.7062751658821528, 'S-palmitoylation-C Validation Sensitivity': 0.20580858085808582, 'S-palmitoylation-C Validation Specificity': 0.831726565817606, 'S-palmitoylation-C Validation Precision': 0.24136410051308865, 'S-palmitoylation-C AUC ROC': 0.5402226247906873, 'S-palmitoylation-C AUC PR': 0.22497814533130145, 'S-palmitoylation-C MCC': 0.04131451860147254, 'S-palmitoylation-C F1': 0.20233900526023432, 'Validation Loss (S-palmitoylation-C)': 0.5544717113176981, 'Hydroxylation-K Validation Accuracy': 0.7424645390070922, 'Hydroxylation-K Validation Sensitivity': 0.7362962962962963, 'Hydroxylation-K Validation Specificity': 0.743859649122807, 'Hydroxylation-K Validation Precision': 0.4385202074613839, 'Hydroxylation-K AUC ROC': 0.8263547758284601, 'Hydroxylation-K AUC PR': 0.6007179065842585, 'Hydroxylation-K MCC': 0.4159636008599415, 'Hydroxylation-K F1': 0.5356868280966264, 'Validation Loss (Hydroxylation-K)': 0.5116994321346283, 'Validation Loss (total)': 1.066171145439148, 'TimeToTrain': 17.938603417078653}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00035344319856742704,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21067609597434817,
 'loss_weight_S-palmitoylation-C': 0.42594473947352784,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2177307066,
 'sample_weights': [0.35963079730059183, 0.11864379134534205],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.144459783422718,
 'weight_decay_Hydroxylation-K': 5.936890431958371,
 'weight_decay_S-palmitoylation-C': 2.5241221733710466}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.391
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00020725433710172287,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6045747359590604,
 'loss_weight_S-palmitoylation-C': 0.37515506712728564,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 732524604,
 'sample_weights': [0.42594473947352784, 0.21067609597434817],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.4568356353495515,
 'weight_decay_Hydroxylation-K': 6.0461550023363175,
 'weight_decay_S-palmitoylation-C': 5.827466636194296}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.392
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032478776505721497,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.19136966036577913,
 'loss_weight_S-palmitoylation-C': 0.378192456935549,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3109047215,
 'sample_weights': [0.37515506712728564, 0.6045747359590604],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.321481357981142,
 'weight_decay_Hydroxylation-K': 7.647284247400914,
 'weight_decay_S-palmitoylation-C': 5.770781229354193}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.387
[3,     3] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00042501858678491535,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.16898119181910332,
 'loss_weight_S-palmitoylation-C': 0.28666253735598834,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4163728432,
 'sample_weights': [0.378192456935549, 0.19136966036577913],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.548150167241872,
 'weight_decay_Hydroxylation-K': 2.427118912514309,
 'weight_decay_S-palmitoylation-C': 4.393142589706279}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.390
[3,     3] loss: 1.383
[4,     3] loss: 1.382
[5,     3] loss: 1.392
[6,     3] loss: 1.384
[7,     3] loss: 1.380
[8,     3] loss: 1.381
[9,     3] loss: 1.379
[10,     3] loss: 1.373
[11,     3] loss: 1.378
[12,     3] loss: 1.364
[13,     3] loss: 1.355
[14,     3] loss: 1.342
[15,     3] loss: 1.323
[16,     3] loss: 1.291
[17,     3] loss: 1.295
[18,     3] loss: 1.253
[19,     3] loss: 1.254
[20,     3] loss: 1.217
[21,     3] loss: 1.167
[22,     3] loss: 1.163
[23,     3] loss: 1.129
[24,     3] loss: 1.127
[25,     3] loss: 1.100
[26,     3] loss: 1.092
[27,     3] loss: 1.022
[28,     3] loss: 1.031
[29,     3] loss: 1.040
[30,     3] loss: 1.057
[31,     3] loss: 0.994
[32,     3] loss: 0.980
[33,     3] loss: 0.959
[34,     3] loss: 0.945
[35,     3] loss: 0.904
[36,     3] loss: 0.911
[37,     3] loss: 0.961
[38,     3] loss: 0.960
[39,     3] loss: 0.920
[40,     3] loss: 0.902
[41,     3] loss: 0.945
[42,     3] loss: 0.857
[43,     3] loss: 0.929
[44,     3] loss: 0.886
[45,     3] loss: 0.918
[46,     3] loss: 0.969
[47,     3] loss: 0.904
[48,     3] loss: 0.889
[49,     3] loss: 0.843
[50,     3] loss: 0.894
[51,     3] loss: 0.890
[52,     3] loss: 0.899
[53,     3] loss: 0.835
[54,     3] loss: 0.826
[55,     3] loss: 0.864
[56,     3] loss: 0.796
[57,     3] loss: 0.890
[58,     3] loss: 0.823
[59,     3] loss: 0.831
[60,     3] loss: 0.824
[61,     3] loss: 0.854
[62,     3] loss: 0.812
[63,     3] loss: 0.868
[64,     3] loss: 0.807
[65,     3] loss: 0.919
[66,     3] loss: 0.847
[67,     3] loss: 0.796
[68,     3] loss: 0.946
[69,     3] loss: 0.828
[70,     3] loss: 0.782
[71,     3] loss: 0.812
[72,     3] loss: 0.885
[73,     3] loss: 0.844
[74,     3] loss: 0.785
[75,     3] loss: 0.787
[76,     3] loss: 0.824
[77,     3] loss: 0.780
[78,     3] loss: 0.776
[79,     3] loss: 0.826
[80,     3] loss: 0.756
[81,     3] loss: 0.761
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00013339453769771874,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.12601554328158104,
 'loss_weight_S-palmitoylation-C': 0.6105881678113626,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3527872236,
 'sample_weights': [0.28666253735598834, 0.16898119181910332],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.751534350575218,
 'weight_decay_Hydroxylation-K': 2.618726474660701,
 'weight_decay_S-palmitoylation-C': 5.954613669578691}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.384
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020352270749232786,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.028962687779788984,
 'loss_weight_S-palmitoylation-C': 0.44141150587648736,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2589508808,
 'sample_weights': [0.6105881678113626, 0.12601554328158104],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.625110698723846,
 'weight_decay_Hydroxylation-K': 3.330664795714573,
 'weight_decay_S-palmitoylation-C': 3.907893049673478}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.389
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003313107851507202,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5182700254501985,
 'loss_weight_S-palmitoylation-C': 0.8327323056753072,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4157424340,
 'sample_weights': [0.44141150587648736, 0.028962687779788984],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.385072630570385,
 'weight_decay_Hydroxylation-K': 9.87375922601165,
 'weight_decay_S-palmitoylation-C': 1.3897958793217593}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.403
[2,     3] loss: 1.388
[3,     3] loss: 1.378
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003282672805372174,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5951392872568515,
 'loss_weight_S-palmitoylation-C': 0.12381943497645889,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 332176126,
 'sample_weights': [0.8327323056753072, 0.5182700254501985],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.375147552565147,
 'weight_decay_Hydroxylation-K': 0.9678939114150233,
 'weight_decay_S-palmitoylation-C': 2.4230831648515743}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.377
[3,     3] loss: 1.404
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002438584092253272,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8651631085055886,
 'loss_weight_S-palmitoylation-C': 0.09319645383433922,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3405822298,
 'sample_weights': [0.12381943497645889, 0.5951392872568515],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.89459405696783,
 'weight_decay_Hydroxylation-K': 6.425326458393753,
 'weight_decay_S-palmitoylation-C': 2.993709247097404}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.392
[3,     3] loss: 1.397
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019732679280442655,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8057595429103342,
 'loss_weight_S-palmitoylation-C': 0.8233426819094399,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2654350323,
 'sample_weights': [0.09319645383433922, 0.8651631085055886],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.9751124429475775,
 'weight_decay_Hydroxylation-K': 3.8950681425617817,
 'weight_decay_S-palmitoylation-C': 5.841022860130452}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.393
[4,     3] loss: 1.383
[5,     3] loss: 1.379
[6,     3] loss: 1.381
[7,     3] loss: 1.385
[8,     3] loss: 1.371
[9,     3] loss: 1.377
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0029860491427665353,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6403631694040113,
 'loss_weight_S-palmitoylation-C': 0.11972699655620428,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2854081297,
 'sample_weights': [0.8233426819094399, 0.8057595429103342],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.341274101306661,
 'weight_decay_Hydroxylation-K': 3.7327563947730824,
 'weight_decay_S-palmitoylation-C': 8.965452362350321}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.390
[3,     3] loss: 1.370
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00960841922210015,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7947103521415071,
 'loss_weight_S-palmitoylation-C': 0.7030761850962761,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3181846388,
 'sample_weights': [0.11972699655620428, 0.6403631694040113],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.80351991653088,
 'weight_decay_Hydroxylation-K': 7.806555980882596,
 'weight_decay_S-palmitoylation-C': 0.037111602716619174}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012265018793647837,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22883589850033184,
 'loss_weight_S-palmitoylation-C': 0.39349828601673187,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2363691281,
 'sample_weights': [0.7030761850962761, 0.7947103521415071],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.96547966188205,
 'weight_decay_Hydroxylation-K': 0.3313698612973517,
 'weight_decay_S-palmitoylation-C': 4.445842702549474}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.394
[3,     3] loss: 1.383
[4,     3] loss: 1.390
[5,     3] loss: 1.384
[6,     3] loss: 1.393
[7,     3] loss: 1.383
[8,     3] loss: 1.388
[9,     3] loss: 1.381
[10,     3] loss: 1.382
[11,     3] loss: 1.376
[12,     3] loss: 1.371
[13,     3] loss: 1.362
[14,     3] loss: 1.354
[15,     3] loss: 1.367
[16,     3] loss: 1.329
[17,     3] loss: 1.297
[18,     3] loss: 1.286
[19,     3] loss: 1.192
[20,     3] loss: 1.259
[21,     3] loss: 1.150
[22,     3] loss: 1.163
[23,     3] loss: 1.049
[24,     3] loss: 1.099
[25,     3] loss: 0.975
[26,     3] loss: 1.157
[27,     3] loss: 1.132
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013328358928137213,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.28219134032401016,
 'loss_weight_S-palmitoylation-C': 0.2483677862459558,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2742556332,
 'sample_weights': [0.39349828601673187, 0.22883589850033184],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.162955191782418,
 'weight_decay_Hydroxylation-K': 3.6228565064059146,
 'weight_decay_S-palmitoylation-C': 5.389004798768398}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.384
[3,     3] loss: 1.397
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013763971657565998,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22276911976379357,
 'loss_weight_S-palmitoylation-C': 0.06540441913206257,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2116644689,
 'sample_weights': [0.2483677862459558, 0.28219134032401016],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.7805971302728825,
 'weight_decay_Hydroxylation-K': 5.883094991969836,
 'weight_decay_S-palmitoylation-C': 1.941122712488809}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.390
[3,     3] loss: 1.390
[4,     3] loss: 1.387
[5,     3] loss: 1.381
[6,     3] loss: 1.384
[7,     3] loss: 1.389
[8,     3] loss: 1.382
[9,     3] loss: 1.373
[10,     3] loss: 1.368
[11,     3] loss: 1.364
[12,     3] loss: 1.332
[13,     3] loss: 1.294
[14,     3] loss: 1.239
[15,     3] loss: 1.274
[16,     3] loss: 1.177
[17,     3] loss: 1.184
[18,     3] loss: 1.109
[19,     3] loss: 1.096
[20,     3] loss: 1.070
[21,     3] loss: 1.093
[22,     3] loss: 1.108
[23,     3] loss: 1.007
[24,     3] loss: 0.950
[25,     3] loss: 1.045
[26,     3] loss: 1.060
[27,     3] loss: 0.895
[28,     3] loss: 0.938
[29,     3] loss: 0.845
[30,     3] loss: 0.910
[31,     3] loss: 0.914
[32,     3] loss: 0.920
[33,     3] loss: 0.915
[34,     3] loss: 0.964
[35,     3] loss: 1.072
[36,     3] loss: 0.877
[37,     3] loss: 0.955
[38,     3] loss: 0.890
[39,     3] loss: 0.922
[40,     3] loss: 0.865
[41,     3] loss: 0.899
[42,     3] loss: 0.888
[43,     3] loss: 0.842
[44,     3] loss: 0.906
[45,     3] loss: 0.875
[46,     3] loss: 0.850
[47,     3] loss: 0.881
[48,     3] loss: 0.912
[49,     3] loss: 0.894
[50,     3] loss: 0.835
[51,     3] loss: 0.790
[52,     3] loss: 0.807
[53,     3] loss: 0.851
[54,     3] loss: 0.794
[55,     3] loss: 0.797
[56,     3] loss: 0.846
[57,     3] loss: 0.823
[58,     3] loss: 0.902
[59,     3] loss: 0.794
[60,     3] loss: 0.944
[61,     3] loss: 0.832
[62,     3] loss: 0.813
[63,     3] loss: 0.793
[64,     3] loss: 0.795
[65,     3] loss: 0.816
[66,     3] loss: 0.922
[67,     3] loss: 0.777
[68,     3] loss: 0.784
Early stopping applied (best metric=0.5322566032409668)
Finished Training
Total time taken: 15.189046621322632
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.385
[3,     3] loss: 1.386
[4,     3] loss: 1.382
[5,     3] loss: 1.363
[6,     3] loss: 1.371
[7,     3] loss: 1.362
[8,     3] loss: 1.349
[9,     3] loss: 1.335
[10,     3] loss: 1.288
[11,     3] loss: 1.273
[12,     3] loss: 1.218
[13,     3] loss: 1.241
[14,     3] loss: 1.236
[15,     3] loss: 1.134
[16,     3] loss: 1.118
[17,     3] loss: 1.087
[18,     3] loss: 1.089
[19,     3] loss: 1.022
[20,     3] loss: 1.043
[21,     3] loss: 1.029
[22,     3] loss: 1.072
[23,     3] loss: 0.985
[24,     3] loss: 0.987
[25,     3] loss: 0.977
[26,     3] loss: 1.004
[27,     3] loss: 0.932
[28,     3] loss: 0.910
[29,     3] loss: 0.860
[30,     3] loss: 1.007
[31,     3] loss: 0.907
[32,     3] loss: 0.883
[33,     3] loss: 0.928
[34,     3] loss: 0.901
[35,     3] loss: 0.919
[36,     3] loss: 0.936
[37,     3] loss: 0.930
[38,     3] loss: 0.936
[39,     3] loss: 0.937
[40,     3] loss: 0.914
[41,     3] loss: 1.082
[42,     3] loss: 0.925
[43,     3] loss: 0.920
[44,     3] loss: 0.926
[45,     3] loss: 0.893
[46,     3] loss: 0.947
[47,     3] loss: 0.877
[48,     3] loss: 0.907
[49,     3] loss: 0.957
[50,     3] loss: 0.837
[51,     3] loss: 0.931
[52,     3] loss: 0.912
[53,     3] loss: 0.911
[54,     3] loss: 0.855
[55,     3] loss: 0.914
[56,     3] loss: 0.903
[57,     3] loss: 0.895
[58,     3] loss: 0.954
[59,     3] loss: 0.897
[60,     3] loss: 0.872
[61,     3] loss: 0.812
[62,     3] loss: 0.843
[63,     3] loss: 0.812
[64,     3] loss: 0.801
[65,     3] loss: 0.795
[66,     3] loss: 0.819
[67,     3] loss: 0.778
[68,     3] loss: 0.781
[69,     3] loss: 0.784
[70,     3] loss: 0.793
[71,     3] loss: 0.802
[72,     3] loss: 0.893
[73,     3] loss: 0.795
[74,     3] loss: 0.865
[75,     3] loss: 0.877
[76,     3] loss: 0.802
[77,     3] loss: 0.832
[78,     3] loss: 0.820
[79,     3] loss: 0.805
[80,     3] loss: 0.815
[81,     3] loss: 0.809
[82,     3] loss: 0.847
Early stopping applied (best metric=0.5393621921539307)
Finished Training
Total time taken: 18.224058628082275
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.390
[3,     3] loss: 1.388
[4,     3] loss: 1.384
[5,     3] loss: 1.391
[6,     3] loss: 1.385
[7,     3] loss: 1.386
[8,     3] loss: 1.384
[9,     3] loss: 1.386
[10,     3] loss: 1.380
[11,     3] loss: 1.377
[12,     3] loss: 1.381
[13,     3] loss: 1.373
[14,     3] loss: 1.364
[15,     3] loss: 1.353
[16,     3] loss: 1.337
[17,     3] loss: 1.314
[18,     3] loss: 1.282
[19,     3] loss: 1.257
[20,     3] loss: 1.164
[21,     3] loss: 1.200
[22,     3] loss: 1.231
[23,     3] loss: 1.216
[24,     3] loss: 1.163
[25,     3] loss: 1.090
[26,     3] loss: 1.025
[27,     3] loss: 1.096
[28,     3] loss: 1.098
[29,     3] loss: 1.124
[30,     3] loss: 1.016
[31,     3] loss: 1.060
[32,     3] loss: 1.026
[33,     3] loss: 1.095
[34,     3] loss: 1.141
[35,     3] loss: 1.037
[36,     3] loss: 0.990
[37,     3] loss: 0.974
[38,     3] loss: 1.074
[39,     3] loss: 1.037
[40,     3] loss: 1.008
[41,     3] loss: 0.962
[42,     3] loss: 0.991
[43,     3] loss: 0.959
[44,     3] loss: 1.052
[45,     3] loss: 0.906
[46,     3] loss: 1.057
[47,     3] loss: 0.961
[48,     3] loss: 0.981
[49,     3] loss: 0.944
[50,     3] loss: 0.910
[51,     3] loss: 0.896
[52,     3] loss: 0.936
[53,     3] loss: 0.847
[54,     3] loss: 0.846
[55,     3] loss: 0.840
[56,     3] loss: 0.809
[57,     3] loss: 0.801
[58,     3] loss: 0.857
[59,     3] loss: 0.823
[60,     3] loss: 0.811
[61,     3] loss: 0.804
[62,     3] loss: 0.850
[63,     3] loss: 0.979
[64,     3] loss: 0.987
[65,     3] loss: 0.871
[66,     3] loss: 0.823
[67,     3] loss: 0.848
[68,     3] loss: 0.794
[69,     3] loss: 0.783
[70,     3] loss: 0.831
[71,     3] loss: 0.834
[72,     3] loss: 0.777
[73,     3] loss: 0.876
Early stopping applied (best metric=0.507257342338562)
Finished Training
Total time taken: 16.247706651687622
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.384
[3,     3] loss: 1.387
[4,     3] loss: 1.382
[5,     3] loss: 1.393
[6,     3] loss: 1.387
[7,     3] loss: 1.384
[8,     3] loss: 1.380
[9,     3] loss: 1.380
[10,     3] loss: 1.374
[11,     3] loss: 1.379
[12,     3] loss: 1.353
[13,     3] loss: 1.342
[14,     3] loss: 1.338
[15,     3] loss: 1.278
[16,     3] loss: 1.301
[17,     3] loss: 1.176
[18,     3] loss: 1.239
[19,     3] loss: 1.256
[20,     3] loss: 1.122
[21,     3] loss: 1.170
[22,     3] loss: 1.115
[23,     3] loss: 1.095
[24,     3] loss: 1.063
[25,     3] loss: 1.124
[26,     3] loss: 1.062
[27,     3] loss: 0.985
[28,     3] loss: 0.947
[29,     3] loss: 1.007
[30,     3] loss: 0.904
[31,     3] loss: 0.969
[32,     3] loss: 0.911
[33,     3] loss: 0.918
[34,     3] loss: 0.962
[35,     3] loss: 0.907
[36,     3] loss: 0.925
[37,     3] loss: 0.909
[38,     3] loss: 0.934
[39,     3] loss: 0.956
[40,     3] loss: 0.877
[41,     3] loss: 0.908
[42,     3] loss: 0.885
[43,     3] loss: 0.847
[44,     3] loss: 0.851
[45,     3] loss: 0.880
[46,     3] loss: 0.972
[47,     3] loss: 0.916
[48,     3] loss: 0.973
[49,     3] loss: 0.978
[50,     3] loss: 0.896
[51,     3] loss: 0.949
[52,     3] loss: 0.934
[53,     3] loss: 0.984
[54,     3] loss: 0.899
[55,     3] loss: 0.864
[56,     3] loss: 0.830
[57,     3] loss: 0.857
[58,     3] loss: 0.844
[59,     3] loss: 0.800
[60,     3] loss: 0.831
[61,     3] loss: 0.797
[62,     3] loss: 0.846
[63,     3] loss: 0.830
[64,     3] loss: 0.815
Early stopping applied (best metric=0.5320953726768494)
Finished Training
Total time taken: 14.270043849945068
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.387
[3,     3] loss: 1.388
[4,     3] loss: 1.377
[5,     3] loss: 1.378
[6,     3] loss: 1.377
[7,     3] loss: 1.375
[8,     3] loss: 1.351
[9,     3] loss: 1.353
[10,     3] loss: 1.339
[11,     3] loss: 1.317
[12,     3] loss: 1.276
[13,     3] loss: 1.219
[14,     3] loss: 1.216
[15,     3] loss: 1.232
[16,     3] loss: 1.183
[17,     3] loss: 1.151
[18,     3] loss: 1.129
[19,     3] loss: 1.114
[20,     3] loss: 1.128
[21,     3] loss: 1.065
[22,     3] loss: 0.978
[23,     3] loss: 1.146
[24,     3] loss: 0.985
[25,     3] loss: 1.065
[26,     3] loss: 0.961
[27,     3] loss: 1.025
[28,     3] loss: 0.997
[29,     3] loss: 1.077
[30,     3] loss: 0.935
[31,     3] loss: 0.875
[32,     3] loss: 0.957
[33,     3] loss: 1.047
[34,     3] loss: 1.070
[35,     3] loss: 1.012
[36,     3] loss: 0.902
[37,     3] loss: 0.934
[38,     3] loss: 0.916
[39,     3] loss: 1.010
[40,     3] loss: 0.967
[41,     3] loss: 1.004
[42,     3] loss: 0.886
[43,     3] loss: 0.953
[44,     3] loss: 0.878
[45,     3] loss: 0.998
[46,     3] loss: 0.910
[47,     3] loss: 0.871
[48,     3] loss: 0.920
[49,     3] loss: 0.833
[50,     3] loss: 0.841
[51,     3] loss: 0.862
[52,     3] loss: 0.834
[53,     3] loss: 0.822
[54,     3] loss: 0.907
[55,     3] loss: 0.911
[56,     3] loss: 0.906
[57,     3] loss: 0.901
[58,     3] loss: 0.882
[59,     3] loss: 0.843
[60,     3] loss: 0.827
[61,     3] loss: 0.816
[62,     3] loss: 0.860
[63,     3] loss: 0.800
[64,     3] loss: 0.850
[65,     3] loss: 0.792
Early stopping applied (best metric=0.4790918827056885)
Finished Training
Total time taken: 14.4476637840271
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.380
[2,     3] loss: 1.385
[3,     3] loss: 1.390
[4,     3] loss: 1.389
[5,     3] loss: 1.385
[6,     3] loss: 1.386
[7,     3] loss: 1.386
[8,     3] loss: 1.391
[9,     3] loss: 1.386
[10,     3] loss: 1.378
[11,     3] loss: 1.382
[12,     3] loss: 1.375
[13,     3] loss: 1.385
[14,     3] loss: 1.362
[15,     3] loss: 1.365
[16,     3] loss: 1.351
[17,     3] loss: 1.368
[18,     3] loss: 1.288
[19,     3] loss: 1.303
[20,     3] loss: 1.261
[21,     3] loss: 1.218
[22,     3] loss: 1.204
[23,     3] loss: 1.184
[24,     3] loss: 1.168
[25,     3] loss: 1.201
[26,     3] loss: 1.111
[27,     3] loss: 1.132
[28,     3] loss: 1.041
[29,     3] loss: 1.043
[30,     3] loss: 0.991
[31,     3] loss: 1.166
[32,     3] loss: 1.028
[33,     3] loss: 1.129
[34,     3] loss: 1.106
[35,     3] loss: 1.080
[36,     3] loss: 0.954
[37,     3] loss: 1.062
[38,     3] loss: 1.116
[39,     3] loss: 0.901
[40,     3] loss: 0.927
[41,     3] loss: 0.970
[42,     3] loss: 0.909
[43,     3] loss: 0.935
[44,     3] loss: 0.935
[45,     3] loss: 0.942
[46,     3] loss: 0.890
[47,     3] loss: 0.930
[48,     3] loss: 0.981
[49,     3] loss: 0.939
[50,     3] loss: 1.009
[51,     3] loss: 0.943
[52,     3] loss: 0.923
[53,     3] loss: 0.897
[54,     3] loss: 0.826
[55,     3] loss: 0.842
[56,     3] loss: 0.853
[57,     3] loss: 0.886
[58,     3] loss: 0.876
[59,     3] loss: 0.941
[60,     3] loss: 0.926
[61,     3] loss: 0.817
[62,     3] loss: 0.861
[63,     3] loss: 0.785
[64,     3] loss: 0.776
[65,     3] loss: 0.813
[66,     3] loss: 0.867
[67,     3] loss: 0.973
[68,     3] loss: 0.912
[69,     3] loss: 0.905
[70,     3] loss: 0.873
[71,     3] loss: 0.897
[72,     3] loss: 0.835
[73,     3] loss: 0.803
[74,     3] loss: 0.857
[75,     3] loss: 0.811
[76,     3] loss: 0.775
[77,     3] loss: 0.799
[78,     3] loss: 0.778
[79,     3] loss: 0.792
[80,     3] loss: 0.766
Early stopping applied (best metric=0.5361329317092896)
Finished Training
Total time taken: 17.837080478668213
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.382
[3,     3] loss: 1.385
[4,     3] loss: 1.396
[5,     3] loss: 1.381
[6,     3] loss: 1.385
[7,     3] loss: 1.385
[8,     3] loss: 1.384
[9,     3] loss: 1.379
[10,     3] loss: 1.375
[11,     3] loss: 1.376
[12,     3] loss: 1.355
[13,     3] loss: 1.369
[14,     3] loss: 1.334
[15,     3] loss: 1.312
[16,     3] loss: 1.255
[17,     3] loss: 1.281
[18,     3] loss: 1.205
[19,     3] loss: 1.279
[20,     3] loss: 1.251
[21,     3] loss: 1.143
[22,     3] loss: 1.088
[23,     3] loss: 1.149
[24,     3] loss: 1.235
[25,     3] loss: 1.081
[26,     3] loss: 1.123
[27,     3] loss: 1.012
[28,     3] loss: 1.127
[29,     3] loss: 1.058
[30,     3] loss: 0.993
[31,     3] loss: 1.094
[32,     3] loss: 1.058
[33,     3] loss: 1.010
[34,     3] loss: 0.966
[35,     3] loss: 0.972
[36,     3] loss: 0.935
[37,     3] loss: 0.886
[38,     3] loss: 0.918
[39,     3] loss: 0.993
[40,     3] loss: 0.911
[41,     3] loss: 0.894
[42,     3] loss: 0.880
[43,     3] loss: 0.928
[44,     3] loss: 0.900
[45,     3] loss: 0.884
[46,     3] loss: 0.837
[47,     3] loss: 0.888
[48,     3] loss: 0.816
[49,     3] loss: 0.875
[50,     3] loss: 0.815
[51,     3] loss: 0.827
[52,     3] loss: 0.873
[53,     3] loss: 0.981
[54,     3] loss: 0.879
[55,     3] loss: 0.860
[56,     3] loss: 0.955
[57,     3] loss: 0.912
[58,     3] loss: 0.953
[59,     3] loss: 0.907
[60,     3] loss: 0.872
[61,     3] loss: 0.902
[62,     3] loss: 0.901
[63,     3] loss: 0.869
[64,     3] loss: 0.832
[65,     3] loss: 0.812
[66,     3] loss: 0.785
[67,     3] loss: 0.801
[68,     3] loss: 0.839
[69,     3] loss: 0.805
[70,     3] loss: 0.758
[71,     3] loss: 0.770
[72,     3] loss: 0.818
[73,     3] loss: 0.811
[74,     3] loss: 0.774
[75,     3] loss: 0.778
[76,     3] loss: 0.859
[77,     3] loss: 0.941
[78,     3] loss: 1.134
[79,     3] loss: 0.970
Early stopping applied (best metric=0.5226370692253113)
Finished Training
Total time taken: 17.555068969726562
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.386
[3,     3] loss: 1.387
[4,     3] loss: 1.387
[5,     3] loss: 1.384
[6,     3] loss: 1.385
[7,     3] loss: 1.388
[8,     3] loss: 1.387
[9,     3] loss: 1.388
[10,     3] loss: 1.377
[11,     3] loss: 1.370
[12,     3] loss: 1.364
[13,     3] loss: 1.348
[14,     3] loss: 1.343
[15,     3] loss: 1.348
[16,     3] loss: 1.328
[17,     3] loss: 1.257
[18,     3] loss: 1.278
[19,     3] loss: 1.205
[20,     3] loss: 1.270
[21,     3] loss: 1.169
[22,     3] loss: 1.088
[23,     3] loss: 1.175
[24,     3] loss: 1.172
[25,     3] loss: 1.109
[26,     3] loss: 1.073
[27,     3] loss: 1.182
[28,     3] loss: 1.065
[29,     3] loss: 1.041
[30,     3] loss: 1.009
[31,     3] loss: 0.988
[32,     3] loss: 0.980
[33,     3] loss: 0.990
[34,     3] loss: 0.976
[35,     3] loss: 1.000
[36,     3] loss: 0.984
[37,     3] loss: 0.960
[38,     3] loss: 0.980
[39,     3] loss: 0.958
[40,     3] loss: 0.945
[41,     3] loss: 0.989
[42,     3] loss: 0.950
[43,     3] loss: 0.966
[44,     3] loss: 0.965
[45,     3] loss: 1.026
[46,     3] loss: 0.892
[47,     3] loss: 0.961
[48,     3] loss: 0.912
[49,     3] loss: 0.900
[50,     3] loss: 0.922
[51,     3] loss: 0.846
[52,     3] loss: 0.898
[53,     3] loss: 0.877
[54,     3] loss: 0.858
[55,     3] loss: 0.809
[56,     3] loss: 0.793
[57,     3] loss: 0.802
[58,     3] loss: 0.810
[59,     3] loss: 0.791
[60,     3] loss: 0.791
[61,     3] loss: 0.803
[62,     3] loss: 0.840
[63,     3] loss: 0.767
[64,     3] loss: 0.816
[65,     3] loss: 0.829
[66,     3] loss: 0.786
[67,     3] loss: 0.890
[68,     3] loss: 0.856
[69,     3] loss: 0.923
[70,     3] loss: 0.898
[71,     3] loss: 0.943
[72,     3] loss: 0.903
[73,     3] loss: 0.967
[74,     3] loss: 0.872
[75,     3] loss: 0.868
[76,     3] loss: 0.870
[77,     3] loss: 0.808
[78,     3] loss: 0.848
[79,     3] loss: 0.802
[80,     3] loss: 0.810
[81,     3] loss: 0.797
[82,     3] loss: 0.799
[83,     3] loss: 0.842
Early stopping applied (best metric=0.49307140707969666)
Finished Training
Total time taken: 18.478062629699707
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.359
[3,     3] loss: 1.424
[4,     3] loss: 1.406
[5,     3] loss: 1.388
[6,     3] loss: 1.393
[7,     3] loss: 1.385
[8,     3] loss: 1.385
[9,     3] loss: 1.387
[10,     3] loss: 1.384
[11,     3] loss: 1.383
[12,     3] loss: 1.381
[13,     3] loss: 1.380
[14,     3] loss: 1.364
[15,     3] loss: 1.358
[16,     3] loss: 1.347
[17,     3] loss: 1.342
[18,     3] loss: 1.321
[19,     3] loss: 1.299
[20,     3] loss: 1.225
[21,     3] loss: 1.232
[22,     3] loss: 1.124
[23,     3] loss: 1.229
[24,     3] loss: 1.215
[25,     3] loss: 1.228
[26,     3] loss: 1.138
[27,     3] loss: 1.264
[28,     3] loss: 1.101
[29,     3] loss: 1.064
[30,     3] loss: 1.079
[31,     3] loss: 1.118
[32,     3] loss: 1.132
[33,     3] loss: 1.074
[34,     3] loss: 1.097
[35,     3] loss: 1.005
[36,     3] loss: 1.006
[37,     3] loss: 1.132
[38,     3] loss: 0.995
[39,     3] loss: 1.064
[40,     3] loss: 1.020
[41,     3] loss: 0.982
[42,     3] loss: 1.031
[43,     3] loss: 0.935
[44,     3] loss: 0.984
[45,     3] loss: 0.918
[46,     3] loss: 0.885
[47,     3] loss: 0.850
[48,     3] loss: 0.851
[49,     3] loss: 0.808
[50,     3] loss: 0.860
[51,     3] loss: 0.903
[52,     3] loss: 0.852
[53,     3] loss: 0.846
[54,     3] loss: 0.941
[55,     3] loss: 0.938
[56,     3] loss: 0.947
[57,     3] loss: 0.853
[58,     3] loss: 0.941
[59,     3] loss: 0.842
[60,     3] loss: 0.874
[61,     3] loss: 0.828
[62,     3] loss: 0.817
[63,     3] loss: 0.857
[64,     3] loss: 0.895
[65,     3] loss: 0.779
[66,     3] loss: 0.790
[67,     3] loss: 0.770
[68,     3] loss: 0.778
[69,     3] loss: 0.802
[70,     3] loss: 0.757
[71,     3] loss: 0.821
[72,     3] loss: 0.783
[73,     3] loss: 0.762
[74,     3] loss: 0.767
[75,     3] loss: 0.777
[76,     3] loss: 0.773
[77,     3] loss: 0.808
[78,     3] loss: 0.769
[79,     3] loss: 0.862
[80,     3] loss: 0.804
Early stopping applied (best metric=0.5097044706344604)
Finished Training
Total time taken: 17.807449102401733
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.382
[3,     3] loss: 1.387
[4,     3] loss: 1.386
[5,     3] loss: 1.384
[6,     3] loss: 1.402
[7,     3] loss: 1.378
[8,     3] loss: 1.387
[9,     3] loss: 1.383
[10,     3] loss: 1.386
[11,     3] loss: 1.387
[12,     3] loss: 1.386
[13,     3] loss: 1.381
[14,     3] loss: 1.379
[15,     3] loss: 1.375
[16,     3] loss: 1.368
[17,     3] loss: 1.345
[18,     3] loss: 1.344
[19,     3] loss: 1.311
[20,     3] loss: 1.292
[21,     3] loss: 1.212
[22,     3] loss: 1.185
[23,     3] loss: 1.264
[24,     3] loss: 1.266
[25,     3] loss: 1.150
[26,     3] loss: 1.096
[27,     3] loss: 1.211
[28,     3] loss: 1.246
[29,     3] loss: 1.103
[30,     3] loss: 1.161
[31,     3] loss: 1.161
[32,     3] loss: 1.199
[33,     3] loss: 1.005
[34,     3] loss: 1.104
[35,     3] loss: 1.160
[36,     3] loss: 1.009
[37,     3] loss: 1.022
[38,     3] loss: 1.036
[39,     3] loss: 0.986
[40,     3] loss: 0.946
[41,     3] loss: 0.925
[42,     3] loss: 0.881
[43,     3] loss: 1.044
[44,     3] loss: 1.032
[45,     3] loss: 0.977
[46,     3] loss: 1.038
[47,     3] loss: 1.068
[48,     3] loss: 1.018
[49,     3] loss: 1.015
[50,     3] loss: 0.994
[51,     3] loss: 1.036
[52,     3] loss: 1.019
[53,     3] loss: 0.910
[54,     3] loss: 1.084
[55,     3] loss: 1.043
[56,     3] loss: 0.904
[57,     3] loss: 0.936
[58,     3] loss: 0.943
[59,     3] loss: 0.950
[60,     3] loss: 1.067
[61,     3] loss: 0.895
[62,     3] loss: 0.894
[63,     3] loss: 0.848
[64,     3] loss: 0.880
[65,     3] loss: 0.866
[66,     3] loss: 0.862
[67,     3] loss: 0.882
[68,     3] loss: 0.860
[69,     3] loss: 0.821
[70,     3] loss: 0.868
[71,     3] loss: 0.899
[72,     3] loss: 0.863
[73,     3] loss: 0.868
[74,     3] loss: 0.814
[75,     3] loss: 0.868
Early stopping applied (best metric=0.4951908588409424)
Finished Training
Total time taken: 16.70004653930664
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.401
[3,     3] loss: 1.390
[4,     3] loss: 1.383
[5,     3] loss: 1.383
[6,     3] loss: 1.385
[7,     3] loss: 1.384
[8,     3] loss: 1.383
[9,     3] loss: 1.379
[10,     3] loss: 1.390
[11,     3] loss: 1.377
[12,     3] loss: 1.376
[13,     3] loss: 1.374
[14,     3] loss: 1.352
[15,     3] loss: 1.344
[16,     3] loss: 1.330
[17,     3] loss: 1.306
[18,     3] loss: 1.293
[19,     3] loss: 1.224
[20,     3] loss: 1.182
[21,     3] loss: 1.120
[22,     3] loss: 1.123
[23,     3] loss: 1.170
[24,     3] loss: 1.128
[25,     3] loss: 1.085
[26,     3] loss: 1.210
[27,     3] loss: 1.137
[28,     3] loss: 1.036
[29,     3] loss: 1.125
[30,     3] loss: 1.030
[31,     3] loss: 1.074
[32,     3] loss: 1.076
[33,     3] loss: 0.983
[34,     3] loss: 0.938
[35,     3] loss: 0.894
[36,     3] loss: 0.991
[37,     3] loss: 0.992
[38,     3] loss: 0.905
[39,     3] loss: 0.915
[40,     3] loss: 1.173
[41,     3] loss: 1.077
[42,     3] loss: 0.983
[43,     3] loss: 1.119
[44,     3] loss: 0.918
[45,     3] loss: 1.032
[46,     3] loss: 0.998
[47,     3] loss: 1.014
[48,     3] loss: 0.922
[49,     3] loss: 0.943
[50,     3] loss: 0.879
[51,     3] loss: 0.929
[52,     3] loss: 0.886
[53,     3] loss: 0.988
[54,     3] loss: 0.850
[55,     3] loss: 0.843
[56,     3] loss: 0.912
[57,     3] loss: 0.831
[58,     3] loss: 0.851
[59,     3] loss: 0.814
[60,     3] loss: 0.768
[61,     3] loss: 0.856
[62,     3] loss: 0.777
[63,     3] loss: 0.780
[64,     3] loss: 0.768
[65,     3] loss: 0.818
[66,     3] loss: 0.784
[67,     3] loss: 0.789
[68,     3] loss: 0.777
[69,     3] loss: 0.867
[70,     3] loss: 0.792
[71,     3] loss: 0.793
[72,     3] loss: 0.773
[73,     3] loss: 0.798
[74,     3] loss: 0.799
[75,     3] loss: 0.773
Early stopping applied (best metric=0.5286041498184204)
Finished Training
Total time taken: 16.647045373916626
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.388
[3,     3] loss: 1.386
[4,     3] loss: 1.388
[5,     3] loss: 1.386
[6,     3] loss: 1.389
[7,     3] loss: 1.385
[8,     3] loss: 1.384
[9,     3] loss: 1.381
[10,     3] loss: 1.378
[11,     3] loss: 1.383
[12,     3] loss: 1.374
[13,     3] loss: 1.377
[14,     3] loss: 1.376
[15,     3] loss: 1.373
[16,     3] loss: 1.351
[17,     3] loss: 1.332
[18,     3] loss: 1.282
[19,     3] loss: 1.273
[20,     3] loss: 1.214
[21,     3] loss: 1.221
[22,     3] loss: 1.174
[23,     3] loss: 1.157
[24,     3] loss: 1.112
[25,     3] loss: 1.039
[26,     3] loss: 1.036
[27,     3] loss: 0.961
[28,     3] loss: 0.971
[29,     3] loss: 0.924
[30,     3] loss: 0.918
[31,     3] loss: 1.001
[32,     3] loss: 0.937
[33,     3] loss: 0.997
[34,     3] loss: 1.175
[35,     3] loss: 1.052
[36,     3] loss: 1.025
[37,     3] loss: 1.088
[38,     3] loss: 0.978
[39,     3] loss: 1.001
[40,     3] loss: 1.006
[41,     3] loss: 0.912
[42,     3] loss: 0.940
[43,     3] loss: 0.886
[44,     3] loss: 0.848
[45,     3] loss: 0.810
[46,     3] loss: 0.819
[47,     3] loss: 0.804
[48,     3] loss: 0.804
[49,     3] loss: 0.828
[50,     3] loss: 0.809
[51,     3] loss: 0.837
[52,     3] loss: 0.839
[53,     3] loss: 0.791
[54,     3] loss: 0.766
[55,     3] loss: 0.929
[56,     3] loss: 0.821
[57,     3] loss: 0.894
[58,     3] loss: 0.889
[59,     3] loss: 0.936
[60,     3] loss: 0.894
[61,     3] loss: 0.901
[62,     3] loss: 0.873
[63,     3] loss: 0.931
[64,     3] loss: 1.063
[65,     3] loss: 0.886
[66,     3] loss: 0.906
[67,     3] loss: 0.931
[68,     3] loss: 0.860
[69,     3] loss: 0.844
[70,     3] loss: 0.840
[71,     3] loss: 0.786
[72,     3] loss: 0.836
[73,     3] loss: 0.770
[74,     3] loss: 0.779
[75,     3] loss: 0.774
[76,     3] loss: 0.787
[77,     3] loss: 0.763
[78,     3] loss: 0.782
[79,     3] loss: 0.776
[80,     3] loss: 0.821
[81,     3] loss: 0.818
[82,     3] loss: 0.874
[83,     3] loss: 0.835
[84,     3] loss: 0.812
[85,     3] loss: 0.833
[86,     3] loss: 0.780
[87,     3] loss: 0.784
[88,     3] loss: 0.792
[89,     3] loss: 0.778
[90,     3] loss: 0.765
[91,     3] loss: 0.788
[92,     3] loss: 0.778
[93,     3] loss: 0.747
[94,     3] loss: 0.769
Early stopping applied (best metric=0.5054678916931152)
Finished Training
Total time taken: 20.839068174362183
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.389
[3,     3] loss: 1.393
[4,     3] loss: 1.377
[5,     3] loss: 1.388
[6,     3] loss: 1.378
[7,     3] loss: 1.376
[8,     3] loss: 1.365
[9,     3] loss: 1.361
[10,     3] loss: 1.363
[11,     3] loss: 1.299
[12,     3] loss: 1.303
[13,     3] loss: 1.287
[14,     3] loss: 1.262
[15,     3] loss: 1.245
[16,     3] loss: 1.155
[17,     3] loss: 1.206
[18,     3] loss: 1.243
[19,     3] loss: 1.228
[20,     3] loss: 1.199
[21,     3] loss: 1.167
[22,     3] loss: 1.214
[23,     3] loss: 1.129
[24,     3] loss: 1.161
[25,     3] loss: 1.074
[26,     3] loss: 1.120
[27,     3] loss: 1.058
[28,     3] loss: 1.006
[29,     3] loss: 0.961
[30,     3] loss: 0.985
[31,     3] loss: 1.133
[32,     3] loss: 1.008
[33,     3] loss: 0.964
[34,     3] loss: 0.911
[35,     3] loss: 1.051
[36,     3] loss: 0.935
[37,     3] loss: 0.900
[38,     3] loss: 0.999
[39,     3] loss: 0.901
[40,     3] loss: 0.941
[41,     3] loss: 1.004
[42,     3] loss: 0.918
[43,     3] loss: 0.957
[44,     3] loss: 0.922
[45,     3] loss: 0.886
[46,     3] loss: 0.904
[47,     3] loss: 0.883
[48,     3] loss: 0.841
[49,     3] loss: 0.862
[50,     3] loss: 0.902
[51,     3] loss: 0.843
[52,     3] loss: 0.810
[53,     3] loss: 0.837
[54,     3] loss: 0.811
[55,     3] loss: 0.812
[56,     3] loss: 0.810
[57,     3] loss: 0.824
[58,     3] loss: 0.869
[59,     3] loss: 0.784
[60,     3] loss: 0.788
[61,     3] loss: 0.800
[62,     3] loss: 0.755
[63,     3] loss: 0.779
[64,     3] loss: 0.792
[65,     3] loss: 0.795
[66,     3] loss: 0.773
[67,     3] loss: 0.935
[68,     3] loss: 0.845
[69,     3] loss: 0.832
[70,     3] loss: 0.871
[71,     3] loss: 0.810
[72,     3] loss: 0.815
[73,     3] loss: 0.802
[74,     3] loss: 0.768
[75,     3] loss: 0.828
[76,     3] loss: 0.796
[77,     3] loss: 0.782
[78,     3] loss: 0.789
[79,     3] loss: 0.790
[80,     3] loss: 0.767
[81,     3] loss: 0.795
Early stopping applied (best metric=0.5345910787582397)
Finished Training
Total time taken: 18.195049285888672
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.380
[2,     3] loss: 1.392
[3,     3] loss: 1.387
[4,     3] loss: 1.381
[5,     3] loss: 1.374
[6,     3] loss: 1.391
[7,     3] loss: 1.381
[8,     3] loss: 1.376
[9,     3] loss: 1.379
[10,     3] loss: 1.373
[11,     3] loss: 1.344
[12,     3] loss: 1.334
[13,     3] loss: 1.329
[14,     3] loss: 1.288
[15,     3] loss: 1.267
[16,     3] loss: 1.304
[17,     3] loss: 1.242
[18,     3] loss: 1.213
[19,     3] loss: 1.257
[20,     3] loss: 1.273
[21,     3] loss: 1.269
[22,     3] loss: 1.182
[23,     3] loss: 1.123
[24,     3] loss: 1.143
[25,     3] loss: 1.237
[26,     3] loss: 1.136
[27,     3] loss: 1.111
[28,     3] loss: 1.143
[29,     3] loss: 1.096
[30,     3] loss: 1.120
[31,     3] loss: 1.050
[32,     3] loss: 1.048
[33,     3] loss: 1.017
[34,     3] loss: 1.144
[35,     3] loss: 1.005
[36,     3] loss: 0.985
[37,     3] loss: 1.049
[38,     3] loss: 1.064
[39,     3] loss: 0.994
[40,     3] loss: 0.963
[41,     3] loss: 0.923
[42,     3] loss: 0.958
[43,     3] loss: 0.989
[44,     3] loss: 1.018
[45,     3] loss: 1.013
[46,     3] loss: 1.093
[47,     3] loss: 0.941
[48,     3] loss: 1.023
[49,     3] loss: 0.947
[50,     3] loss: 1.054
[51,     3] loss: 0.931
[52,     3] loss: 0.886
[53,     3] loss: 0.906
[54,     3] loss: 0.845
[55,     3] loss: 0.867
[56,     3] loss: 0.884
[57,     3] loss: 0.833
[58,     3] loss: 0.794
[59,     3] loss: 0.828
[60,     3] loss: 0.865
[61,     3] loss: 0.819
[62,     3] loss: 0.800
[63,     3] loss: 0.810
[64,     3] loss: 0.781
[65,     3] loss: 0.811
[66,     3] loss: 0.848
[67,     3] loss: 0.844
[68,     3] loss: 0.906
[69,     3] loss: 0.897
[70,     3] loss: 0.810
[71,     3] loss: 0.845
[72,     3] loss: 0.923
[73,     3] loss: 0.950
[74,     3] loss: 0.846
[75,     3] loss: 0.942
[76,     3] loss: 0.814
[77,     3] loss: 0.813
[78,     3] loss: 0.799
[79,     3] loss: 0.870
Early stopping applied (best metric=0.5176648497581482)
Finished Training
Total time taken: 17.52705669403076
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.383
[3,     3] loss: 1.384
[4,     3] loss: 1.388
[5,     3] loss: 1.372
[6,     3] loss: 1.372
[7,     3] loss: 1.374
[8,     3] loss: 1.369
[9,     3] loss: 1.345
[10,     3] loss: 1.328
[11,     3] loss: 1.270
[12,     3] loss: 1.275
[13,     3] loss: 1.191
[14,     3] loss: 1.158
[15,     3] loss: 1.237
[16,     3] loss: 1.113
[17,     3] loss: 1.110
[18,     3] loss: 1.096
[19,     3] loss: 1.044
[20,     3] loss: 1.086
[21,     3] loss: 1.001
[22,     3] loss: 1.038
[23,     3] loss: 1.024
[24,     3] loss: 1.011
[25,     3] loss: 0.971
[26,     3] loss: 0.908
[27,     3] loss: 0.905
[28,     3] loss: 0.959
[29,     3] loss: 1.010
[30,     3] loss: 0.925
[31,     3] loss: 0.888
[32,     3] loss: 0.888
[33,     3] loss: 0.883
[34,     3] loss: 0.873
[35,     3] loss: 0.840
[36,     3] loss: 0.873
[37,     3] loss: 0.987
[38,     3] loss: 0.852
[39,     3] loss: 0.817
[40,     3] loss: 0.854
[41,     3] loss: 0.852
[42,     3] loss: 0.870
[43,     3] loss: 0.870
[44,     3] loss: 0.809
[45,     3] loss: 0.879
[46,     3] loss: 0.854
[47,     3] loss: 0.809
[48,     3] loss: 0.875
[49,     3] loss: 0.870
[50,     3] loss: 0.811
[51,     3] loss: 0.792
[52,     3] loss: 0.797
[53,     3] loss: 0.779
[54,     3] loss: 0.805
[55,     3] loss: 0.806
[56,     3] loss: 0.940
[57,     3] loss: 0.858
[58,     3] loss: 0.920
[59,     3] loss: 0.854
[60,     3] loss: 0.896
[61,     3] loss: 0.934
[62,     3] loss: 0.891
[63,     3] loss: 0.846
[64,     3] loss: 0.861
[65,     3] loss: 0.799
[66,     3] loss: 0.798
[67,     3] loss: 0.811
[68,     3] loss: 0.825
[69,     3] loss: 0.870
[70,     3] loss: 0.785
[71,     3] loss: 0.810
[72,     3] loss: 0.795
[73,     3] loss: 0.839
[74,     3] loss: 0.883
[75,     3] loss: 0.917
[76,     3] loss: 0.832
[77,     3] loss: 1.002
[78,     3] loss: 0.842
[79,     3] loss: 0.866
[80,     3] loss: 0.829
[81,     3] loss: 0.788
[82,     3] loss: 0.806
[83,     3] loss: 0.755
[84,     3] loss: 0.784
[85,     3] loss: 0.779
[86,     3] loss: 0.758
[87,     3] loss: 0.782
[88,     3] loss: 0.754
[89,     3] loss: 0.754
[90,     3] loss: 0.760
[91,     3] loss: 0.738
[92,     3] loss: 0.761
[93,     3] loss: 0.787
[94,     3] loss: 0.772
[95,     3] loss: 0.760
Early stopping applied (best metric=0.5173583626747131)
Finished Training
Total time taken: 21.14505696296692
{'S-palmitoylation-C Validation Accuracy': 0.6858304084723299, 'S-palmitoylation-C Validation Sensitivity': 0.22851485148514852, 'S-palmitoylation-C Validation Specificity': 0.8004717843581284, 'S-palmitoylation-C Validation Precision': 0.2343848219767049, 'S-palmitoylation-C AUC ROC': 0.5362816393964781, 'S-palmitoylation-C AUC PR': 0.2219901664809459, 'S-palmitoylation-C MCC': 0.032791029289403986, 'S-palmitoylation-C F1': 0.1992220704309228, 'Validation Loss (S-palmitoylation-C)': 0.5545668363571167, 'Hydroxylation-K Validation Accuracy': 0.7467198581560284, 'Hydroxylation-K Validation Sensitivity': 0.7807407407407407, 'Hydroxylation-K Validation Specificity': 0.7368421052631579, 'Hydroxylation-K Validation Precision': 0.48224627603144227, 'Hydroxylation-K AUC ROC': 0.8318323586744639, 'Hydroxylation-K AUC PR': 0.6217300907427566, 'Hydroxylation-K MCC': 0.46466539759406517, 'Hydroxylation-K F1': 0.5699455636817462, 'Validation Loss (Hydroxylation-K)': 0.516699097553889, 'Validation Loss (total)': 1.0712659200032553, 'TimeToTrain': 17.407300249735513}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002212587781484815,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5746799439437282,
 'loss_weight_S-palmitoylation-C': 0.5564479120770347,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2337508041,
 'sample_weights': [0.06540441913206257, 0.22276911976379357],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.599556664942196,
 'weight_decay_Hydroxylation-K': 8.282791118661017,
 'weight_decay_S-palmitoylation-C': 3.2510445451399175}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.384
[3,     3] loss: 1.380
[4,     3] loss: 1.377
[5,     3] loss: 1.376
[6,     3] loss: 1.365
[7,     3] loss: 1.363
[8,     3] loss: 1.330
[9,     3] loss: 1.295
[10,     3] loss: 1.250
[11,     3] loss: 1.262
[12,     3] loss: 1.230
[13,     3] loss: 1.225
[14,     3] loss: 1.290
[15,     3] loss: 1.216
[16,     3] loss: 1.158
[17,     3] loss: 1.203
[18,     3] loss: 1.121
[19,     3] loss: 1.060
[20,     3] loss: 1.091
[21,     3] loss: 1.112
[22,     3] loss: 0.998
[23,     3] loss: 0.936
[24,     3] loss: 0.917
[25,     3] loss: 1.086
[26,     3] loss: 0.965
[27,     3] loss: 0.992
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00026124357267854665,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.12745256907917474,
 'loss_weight_S-palmitoylation-C': 0.2515600587950101,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1913793207,
 'sample_weights': [0.5564479120770347, 0.5746799439437282],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.673526794876164,
 'weight_decay_Hydroxylation-K': 3.398603253118977,
 'weight_decay_S-palmitoylation-C': 1.80970516206431}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.385
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002966487708080096,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8378492670648113,
 'loss_weight_S-palmitoylation-C': 0.19748262095927155,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2663986975,
 'sample_weights': [0.2515600587950101, 0.12745256907917474],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7027431062740308,
 'weight_decay_Hydroxylation-K': 2.185130098651055,
 'weight_decay_S-palmitoylation-C': 1.8054006910935216}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.390
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003748504263637055,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9247785365041944,
 'loss_weight_S-palmitoylation-C': 0.6144847523953813,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 553964586,
 'sample_weights': [0.19748262095927155, 0.8378492670648113],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6817676765600622,
 'weight_decay_Hydroxylation-K': 1.5314323591760979,
 'weight_decay_S-palmitoylation-C': 6.327594070038983}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.390
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009289071175591176,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6603494236053667,
 'loss_weight_S-palmitoylation-C': 0.8341618257926962,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3301077363,
 'sample_weights': [0.6144847523953813, 0.9247785365041944],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6868930759132983,
 'weight_decay_Hydroxylation-K': 3.2315128598352456,
 'weight_decay_S-palmitoylation-C': 1.9775694604252818}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.395
[3,     3] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005696328926200466,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4068471959658414,
 'loss_weight_S-palmitoylation-C': 0.2737976079347588,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 10606038,
 'sample_weights': [0.8341618257926962, 0.6603494236053667],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.12491278430356,
 'weight_decay_Hydroxylation-K': 1.279182735766355,
 'weight_decay_S-palmitoylation-C': 4.280577388579755}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.384
[3,     3] loss: 1.381
[4,     3] loss: 1.387
[5,     3] loss: 1.378
[6,     3] loss: 1.387
[7,     3] loss: 1.377
[8,     3] loss: 1.377
[9,     3] loss: 1.372
[10,     3] loss: 1.367
[11,     3] loss: 1.336
[12,     3] loss: 1.337
[13,     3] loss: 1.319
[14,     3] loss: 1.292
[15,     3] loss: 1.285
[16,     3] loss: 1.247
[17,     3] loss: 1.203
[18,     3] loss: 1.256
[19,     3] loss: 1.221
[20,     3] loss: 1.176
[21,     3] loss: 1.133
[22,     3] loss: 1.175
[23,     3] loss: 1.153
[24,     3] loss: 1.201
[25,     3] loss: 1.035
[26,     3] loss: 1.062
[27,     3] loss: 1.067
[28,     3] loss: 0.992
[29,     3] loss: 1.071
[30,     3] loss: 1.005
[31,     3] loss: 0.974
[32,     3] loss: 0.951
[33,     3] loss: 0.930
[34,     3] loss: 0.934
[35,     3] loss: 1.047
[36,     3] loss: 0.918
[37,     3] loss: 0.895
[38,     3] loss: 0.972
[39,     3] loss: 0.861
[40,     3] loss: 0.866
[41,     3] loss: 1.049
[42,     3] loss: 0.832
[43,     3] loss: 0.976
[44,     3] loss: 0.894
[45,     3] loss: 0.811
[46,     3] loss: 0.860
[47,     3] loss: 0.839
[48,     3] loss: 0.819
[49,     3] loss: 0.880
[50,     3] loss: 0.864
[51,     3] loss: 0.857
[52,     3] loss: 0.933
[53,     3] loss: 0.792
[54,     3] loss: 0.794
[55,     3] loss: 0.821
[56,     3] loss: 0.795
[57,     3] loss: 0.793
[58,     3] loss: 0.819
[59,     3] loss: 0.792
[60,     3] loss: 0.819
[61,     3] loss: 0.761
[62,     3] loss: 0.826
[63,     3] loss: 0.766
[64,     3] loss: 0.900
[65,     3] loss: 0.779
[66,     3] loss: 0.904
[67,     3] loss: 0.826
[68,     3] loss: 0.819
[69,     3] loss: 1.052
[70,     3] loss: 0.829
[71,     3] loss: 0.805
[72,     3] loss: 0.815
[73,     3] loss: 0.818
[74,     3] loss: 0.842
[75,     3] loss: 0.813
[76,     3] loss: 0.814
[77,     3] loss: 0.845
[78,     3] loss: 0.854
[79,     3] loss: 0.777
[80,     3] loss: 0.916
[81,     3] loss: 0.816
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020765013043853088,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.28030333215574804,
 'loss_weight_S-palmitoylation-C': 0.18072087100406328,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3885866205,
 'sample_weights': [0.2737976079347588, 0.4068471959658414],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.088813935676846,
 'weight_decay_Hydroxylation-K': 1.5228649716382483,
 'weight_decay_S-palmitoylation-C': 0.45056701232332075}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.389
[3,     3] loss: 1.387
[4,     3] loss: 1.391
[5,     3] loss: 1.377
[6,     3] loss: 1.389
[7,     3] loss: 1.387
[8,     3] loss: 1.379
[9,     3] loss: 1.369
[10,     3] loss: 1.363
[11,     3] loss: 1.344
[12,     3] loss: 1.304
[13,     3] loss: 1.271
[14,     3] loss: 1.245
[15,     3] loss: 1.218
[16,     3] loss: 1.232
[17,     3] loss: 1.361
[18,     3] loss: 1.238
[19,     3] loss: 1.133
[20,     3] loss: 1.241
[21,     3] loss: 1.103
[22,     3] loss: 1.139
[23,     3] loss: 1.146
[24,     3] loss: 1.050
[25,     3] loss: 1.118
[26,     3] loss: 1.017
[27,     3] loss: 1.014
[28,     3] loss: 0.976
[29,     3] loss: 0.962
[30,     3] loss: 1.029
[31,     3] loss: 1.103
[32,     3] loss: 1.153
[33,     3] loss: 1.049
[34,     3] loss: 1.101
[35,     3] loss: 1.068
[36,     3] loss: 1.039
[37,     3] loss: 1.058
[38,     3] loss: 0.934
[39,     3] loss: 0.952
[40,     3] loss: 0.888
[41,     3] loss: 0.898
[42,     3] loss: 0.967
[43,     3] loss: 0.968
[44,     3] loss: 0.952
[45,     3] loss: 1.045
[46,     3] loss: 1.146
[47,     3] loss: 1.157
[48,     3] loss: 1.050
[49,     3] loss: 1.050
[50,     3] loss: 0.969
[51,     3] loss: 1.038
[52,     3] loss: 0.971
[53,     3] loss: 0.882
[54,     3] loss: 0.825
[55,     3] loss: 0.810
[56,     3] loss: 0.924
[57,     3] loss: 0.781
[58,     3] loss: 0.835
[59,     3] loss: 0.792
[60,     3] loss: 0.774
[61,     3] loss: 0.782
[62,     3] loss: 0.807
[63,     3] loss: 0.786
[64,     3] loss: 0.783
[65,     3] loss: 0.746
[66,     3] loss: 0.770
[67,     3] loss: 0.823
[68,     3] loss: 0.785
[69,     3] loss: 0.764
[70,     3] loss: 0.771
[71,     3] loss: 0.780
[72,     3] loss: 0.762
[73,     3] loss: 1.298
[74,     3] loss: 1.313
[75,     3] loss: 1.176
[76,     3] loss: 1.226
[77,     3] loss: 1.238
[78,     3] loss: 1.193
[79,     3] loss: 1.088
[80,     3] loss: 1.039
Early stopping applied (best metric=0.5104782581329346)
Finished Training
Total time taken: 17.807060718536377
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.403
[2,     3] loss: 1.393
[3,     3] loss: 1.390
[4,     3] loss: 1.390
[5,     3] loss: 1.380
[6,     3] loss: 1.377
[7,     3] loss: 1.383
[8,     3] loss: 1.394
[9,     3] loss: 1.384
[10,     3] loss: 1.378
[11,     3] loss: 1.377
[12,     3] loss: 1.355
[13,     3] loss: 1.335
[14,     3] loss: 1.291
[15,     3] loss: 1.233
[16,     3] loss: 1.175
[17,     3] loss: 1.138
[18,     3] loss: 1.067
[19,     3] loss: 1.140
[20,     3] loss: 1.124
[21,     3] loss: 1.158
[22,     3] loss: 1.057
[23,     3] loss: 1.007
[24,     3] loss: 1.102
[25,     3] loss: 1.049
[26,     3] loss: 1.069
[27,     3] loss: 0.956
[28,     3] loss: 0.994
[29,     3] loss: 0.984
[30,     3] loss: 0.873
[31,     3] loss: 0.877
[32,     3] loss: 0.857
[33,     3] loss: 0.830
[34,     3] loss: 0.843
[35,     3] loss: 0.873
[36,     3] loss: 0.809
[37,     3] loss: 0.918
[38,     3] loss: 0.972
[39,     3] loss: 0.943
[40,     3] loss: 0.832
[41,     3] loss: 0.830
[42,     3] loss: 0.810
[43,     3] loss: 0.818
[44,     3] loss: 0.804
[45,     3] loss: 0.784
[46,     3] loss: 0.835
[47,     3] loss: 0.846
[48,     3] loss: 0.770
[49,     3] loss: 0.800
[50,     3] loss: 0.813
[51,     3] loss: 0.875
[52,     3] loss: 0.838
[53,     3] loss: 0.833
[54,     3] loss: 0.837
[55,     3] loss: 0.745
[56,     3] loss: 0.770
[57,     3] loss: 0.732
[58,     3] loss: 0.764
[59,     3] loss: 0.846
[60,     3] loss: 0.796
[61,     3] loss: 0.779
[62,     3] loss: 0.771
[63,     3] loss: 0.797
[64,     3] loss: 0.771
[65,     3] loss: 0.882
[66,     3] loss: 0.773
[67,     3] loss: 0.769
[68,     3] loss: 0.818
[69,     3] loss: 0.804
[70,     3] loss: 0.768
[71,     3] loss: 0.770
[72,     3] loss: 0.745
[73,     3] loss: 0.756
[74,     3] loss: 0.741
[75,     3] loss: 0.727
[76,     3] loss: 0.738
[77,     3] loss: 0.749
Early stopping applied (best metric=0.5328710079193115)
Finished Training
Total time taken: 17.149056673049927
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.399
[2,     3] loss: 1.389
[3,     3] loss: 1.394
[4,     3] loss: 1.383
[5,     3] loss: 1.394
[6,     3] loss: 1.385
[7,     3] loss: 1.370
[8,     3] loss: 1.375
[9,     3] loss: 1.362
[10,     3] loss: 1.349
[11,     3] loss: 1.342
[12,     3] loss: 1.299
[13,     3] loss: 1.268
[14,     3] loss: 1.203
[15,     3] loss: 1.139
[16,     3] loss: 1.170
[17,     3] loss: 1.125
[18,     3] loss: 1.148
[19,     3] loss: 1.048
[20,     3] loss: 1.100
[21,     3] loss: 1.089
[22,     3] loss: 1.026
[23,     3] loss: 1.057
[24,     3] loss: 0.981
[25,     3] loss: 0.920
[26,     3] loss: 0.931
[27,     3] loss: 1.170
[28,     3] loss: 0.992
[29,     3] loss: 1.094
[30,     3] loss: 0.960
[31,     3] loss: 0.936
[32,     3] loss: 1.045
[33,     3] loss: 0.901
[34,     3] loss: 0.942
[35,     3] loss: 0.929
[36,     3] loss: 0.867
[37,     3] loss: 0.887
[38,     3] loss: 1.068
[39,     3] loss: 0.853
[40,     3] loss: 0.929
[41,     3] loss: 0.942
[42,     3] loss: 0.888
[43,     3] loss: 0.868
[44,     3] loss: 0.855
[45,     3] loss: 0.908
[46,     3] loss: 0.861
[47,     3] loss: 0.858
[48,     3] loss: 0.879
[49,     3] loss: 1.037
[50,     3] loss: 0.870
[51,     3] loss: 0.844
[52,     3] loss: 0.788
[53,     3] loss: 0.908
[54,     3] loss: 0.806
[55,     3] loss: 0.844
[56,     3] loss: 0.794
[57,     3] loss: 0.800
[58,     3] loss: 0.776
[59,     3] loss: 0.824
[60,     3] loss: 0.788
[61,     3] loss: 0.837
[62,     3] loss: 0.981
[63,     3] loss: 0.922
Early stopping applied (best metric=0.537047803401947)
Finished Training
Total time taken: 13.972038269042969
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.379
[3,     3] loss: 1.381
[4,     3] loss: 1.387
[5,     3] loss: 1.381
[6,     3] loss: 1.386
[7,     3] loss: 1.378
[8,     3] loss: 1.380
[9,     3] loss: 1.374
[10,     3] loss: 1.352
[11,     3] loss: 1.306
[12,     3] loss: 1.316
[13,     3] loss: 1.296
[14,     3] loss: 1.179
[15,     3] loss: 1.209
[16,     3] loss: 1.212
[17,     3] loss: 1.210
[18,     3] loss: 1.264
[19,     3] loss: 1.204
[20,     3] loss: 1.120
[21,     3] loss: 1.162
[22,     3] loss: 1.086
[23,     3] loss: 1.067
[24,     3] loss: 1.095
[25,     3] loss: 1.043
[26,     3] loss: 1.026
[27,     3] loss: 1.050
[28,     3] loss: 0.935
[29,     3] loss: 0.953
[30,     3] loss: 1.039
[31,     3] loss: 1.135
[32,     3] loss: 1.213
[33,     3] loss: 1.054
[34,     3] loss: 1.034
[35,     3] loss: 1.009
[36,     3] loss: 0.968
[37,     3] loss: 0.892
[38,     3] loss: 0.933
[39,     3] loss: 1.020
[40,     3] loss: 0.874
[41,     3] loss: 0.982
[42,     3] loss: 0.918
[43,     3] loss: 0.927
[44,     3] loss: 0.880
[45,     3] loss: 0.857
[46,     3] loss: 0.884
[47,     3] loss: 1.087
[48,     3] loss: 1.025
[49,     3] loss: 0.978
[50,     3] loss: 1.021
[51,     3] loss: 1.007
[52,     3] loss: 0.842
[53,     3] loss: 0.867
[54,     3] loss: 0.885
[55,     3] loss: 0.855
[56,     3] loss: 0.835
[57,     3] loss: 0.767
[58,     3] loss: 0.812
[59,     3] loss: 0.807
[60,     3] loss: 0.760
[61,     3] loss: 0.756
[62,     3] loss: 0.788
[63,     3] loss: 0.851
[64,     3] loss: 0.875
[65,     3] loss: 0.919
[66,     3] loss: 0.893
Early stopping applied (best metric=0.4887988865375519)
Finished Training
Total time taken: 14.693049669265747
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.388
[3,     3] loss: 1.378
[4,     3] loss: 1.385
[5,     3] loss: 1.380
[6,     3] loss: 1.363
[7,     3] loss: 1.371
[8,     3] loss: 1.337
[9,     3] loss: 1.305
[10,     3] loss: 1.246
[11,     3] loss: 1.218
[12,     3] loss: 1.148
[13,     3] loss: 1.187
[14,     3] loss: 1.254
[15,     3] loss: 1.236
[16,     3] loss: 1.109
[17,     3] loss: 1.070
[18,     3] loss: 1.140
[19,     3] loss: 1.079
[20,     3] loss: 1.084
[21,     3] loss: 1.010
[22,     3] loss: 1.165
[23,     3] loss: 0.984
[24,     3] loss: 1.123
[25,     3] loss: 1.044
[26,     3] loss: 1.008
[27,     3] loss: 0.971
[28,     3] loss: 0.996
[29,     3] loss: 0.884
[30,     3] loss: 0.905
[31,     3] loss: 0.877
[32,     3] loss: 0.875
[33,     3] loss: 0.984
[34,     3] loss: 0.924
[35,     3] loss: 0.919
[36,     3] loss: 0.899
[37,     3] loss: 0.839
[38,     3] loss: 0.831
[39,     3] loss: 0.781
[40,     3] loss: 0.817
[41,     3] loss: 0.933
[42,     3] loss: 0.899
[43,     3] loss: 0.884
[44,     3] loss: 0.944
[45,     3] loss: 0.883
[46,     3] loss: 0.865
[47,     3] loss: 0.849
[48,     3] loss: 0.813
[49,     3] loss: 0.913
[50,     3] loss: 0.891
[51,     3] loss: 0.899
[52,     3] loss: 0.914
[53,     3] loss: 0.902
[54,     3] loss: 0.870
[55,     3] loss: 0.782
[56,     3] loss: 0.755
[57,     3] loss: 0.767
[58,     3] loss: 0.747
[59,     3] loss: 0.769
[60,     3] loss: 0.760
[61,     3] loss: 0.897
[62,     3] loss: 0.923
[63,     3] loss: 0.997
[64,     3] loss: 0.922
[65,     3] loss: 0.864
[66,     3] loss: 0.789
[67,     3] loss: 0.762
[68,     3] loss: 0.841
[69,     3] loss: 0.924
Early stopping applied (best metric=0.5162309408187866)
Finished Training
Total time taken: 15.381041765213013
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.378
[3,     3] loss: 1.396
[4,     3] loss: 1.383
[5,     3] loss: 1.388
[6,     3] loss: 1.385
[7,     3] loss: 1.384
[8,     3] loss: 1.383
[9,     3] loss: 1.377
[10,     3] loss: 1.373
[11,     3] loss: 1.347
[12,     3] loss: 1.379
[13,     3] loss: 1.317
[14,     3] loss: 1.279
[15,     3] loss: 1.170
[16,     3] loss: 1.112
[17,     3] loss: 1.161
[18,     3] loss: 1.088
[19,     3] loss: 1.012
[20,     3] loss: 1.204
[21,     3] loss: 1.088
[22,     3] loss: 1.164
[23,     3] loss: 1.103
[24,     3] loss: 1.077
[25,     3] loss: 1.052
[26,     3] loss: 1.011
[27,     3] loss: 0.934
[28,     3] loss: 1.000
[29,     3] loss: 0.965
[30,     3] loss: 0.897
[31,     3] loss: 0.918
[32,     3] loss: 0.907
[33,     3] loss: 0.919
[34,     3] loss: 0.967
[35,     3] loss: 1.004
[36,     3] loss: 0.954
[37,     3] loss: 1.084
[38,     3] loss: 0.988
[39,     3] loss: 0.991
[40,     3] loss: 0.879
[41,     3] loss: 0.858
[42,     3] loss: 0.801
[43,     3] loss: 0.807
[44,     3] loss: 0.828
[45,     3] loss: 0.769
[46,     3] loss: 0.823
[47,     3] loss: 0.790
[48,     3] loss: 0.818
[49,     3] loss: 0.789
[50,     3] loss: 0.769
[51,     3] loss: 0.853
[52,     3] loss: 0.890
[53,     3] loss: 0.930
[54,     3] loss: 0.852
[55,     3] loss: 0.870
[56,     3] loss: 0.776
[57,     3] loss: 0.739
[58,     3] loss: 0.825
[59,     3] loss: 0.769
[60,     3] loss: 0.766
[61,     3] loss: 0.785
[62,     3] loss: 0.776
[63,     3] loss: 0.835
[64,     3] loss: 0.913
[65,     3] loss: 0.845
[66,     3] loss: 0.863
[67,     3] loss: 0.920
[68,     3] loss: 0.821
[69,     3] loss: 0.799
[70,     3] loss: 0.788
[71,     3] loss: 0.891
[72,     3] loss: 0.748
[73,     3] loss: 0.777
[74,     3] loss: 0.854
[75,     3] loss: 0.801
[76,     3] loss: 0.781
[77,     3] loss: 0.767
[78,     3] loss: 0.750
[79,     3] loss: 0.733
[80,     3] loss: 0.786
[81,     3] loss: 0.805
Early stopping applied (best metric=0.5243359804153442)
Finished Training
Total time taken: 17.962061405181885
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.398
[3,     3] loss: 1.388
[4,     3] loss: 1.389
[5,     3] loss: 1.383
[6,     3] loss: 1.380
[7,     3] loss: 1.378
[8,     3] loss: 1.376
[9,     3] loss: 1.375
[10,     3] loss: 1.355
[11,     3] loss: 1.317
[12,     3] loss: 1.256
[13,     3] loss: 1.253
[14,     3] loss: 1.213
[15,     3] loss: 1.179
[16,     3] loss: 1.185
[17,     3] loss: 1.196
[18,     3] loss: 1.115
[19,     3] loss: 1.165
[20,     3] loss: 1.140
[21,     3] loss: 1.040
[22,     3] loss: 1.031
[23,     3] loss: 1.139
[24,     3] loss: 0.993
[25,     3] loss: 0.991
[26,     3] loss: 1.033
[27,     3] loss: 1.031
[28,     3] loss: 1.018
[29,     3] loss: 1.000
[30,     3] loss: 1.121
[31,     3] loss: 1.009
[32,     3] loss: 0.941
[33,     3] loss: 0.942
[34,     3] loss: 1.012
[35,     3] loss: 0.974
[36,     3] loss: 0.908
[37,     3] loss: 0.962
[38,     3] loss: 0.880
[39,     3] loss: 0.925
[40,     3] loss: 0.857
[41,     3] loss: 0.961
[42,     3] loss: 0.912
[43,     3] loss: 1.008
[44,     3] loss: 1.030
[45,     3] loss: 0.884
[46,     3] loss: 0.943
[47,     3] loss: 0.892
[48,     3] loss: 0.834
[49,     3] loss: 0.800
[50,     3] loss: 0.785
[51,     3] loss: 0.756
[52,     3] loss: 0.751
[53,     3] loss: 0.738
[54,     3] loss: 0.820
[55,     3] loss: 0.750
[56,     3] loss: 0.764
[57,     3] loss: 0.753
[58,     3] loss: 0.763
[59,     3] loss: 0.945
[60,     3] loss: 1.302
[61,     3] loss: 1.179
[62,     3] loss: 1.066
[63,     3] loss: 1.207
[64,     3] loss: 1.150
[65,     3] loss: 1.067
[66,     3] loss: 0.914
[67,     3] loss: 0.954
[68,     3] loss: 0.929
[69,     3] loss: 0.872
[70,     3] loss: 0.809
[71,     3] loss: 0.785
[72,     3] loss: 0.864
[73,     3] loss: 0.851
[74,     3] loss: 0.786
[75,     3] loss: 0.817
[76,     3] loss: 0.791
[77,     3] loss: 0.855
[78,     3] loss: 0.813
[79,     3] loss: 0.807
[80,     3] loss: 0.773
[81,     3] loss: 0.750
[82,     3] loss: 0.797
[83,     3] loss: 0.771
[84,     3] loss: 0.768
[85,     3] loss: 0.799
[86,     3] loss: 0.888
[87,     3] loss: 0.860
[88,     3] loss: 0.910
[89,     3] loss: 0.943
[90,     3] loss: 0.829
[91,     3] loss: 0.797
[92,     3] loss: 0.833
[93,     3] loss: 0.905
[94,     3] loss: 0.851
[95,     3] loss: 0.881
[96,     3] loss: 0.809
[97,     3] loss: 0.804
[98,     3] loss: 0.753
[99,     3] loss: 0.770
Early stopping applied (best metric=0.5278606414794922)
Finished Training
Total time taken: 22.0790593624115
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.383
[3,     3] loss: 1.391
[4,     3] loss: 1.396
[5,     3] loss: 1.384
[6,     3] loss: 1.384
[7,     3] loss: 1.379
[8,     3] loss: 1.379
[9,     3] loss: 1.368
[10,     3] loss: 1.362
[11,     3] loss: 1.362
[12,     3] loss: 1.311
[13,     3] loss: 1.284
[14,     3] loss: 1.258
[15,     3] loss: 1.186
[16,     3] loss: 1.264
[17,     3] loss: 1.178
[18,     3] loss: 1.133
[19,     3] loss: 1.143
[20,     3] loss: 1.126
[21,     3] loss: 1.097
[22,     3] loss: 1.069
[23,     3] loss: 1.247
[24,     3] loss: 1.129
[25,     3] loss: 1.127
[26,     3] loss: 1.267
[27,     3] loss: 1.119
[28,     3] loss: 1.131
[29,     3] loss: 1.078
[30,     3] loss: 1.084
[31,     3] loss: 1.038
[32,     3] loss: 0.995
[33,     3] loss: 0.902
[34,     3] loss: 0.966
[35,     3] loss: 1.006
[36,     3] loss: 0.897
[37,     3] loss: 0.940
[38,     3] loss: 0.909
[39,     3] loss: 0.913
[40,     3] loss: 0.895
[41,     3] loss: 0.963
[42,     3] loss: 0.931
[43,     3] loss: 0.943
[44,     3] loss: 0.865
[45,     3] loss: 0.845
[46,     3] loss: 0.907
[47,     3] loss: 0.804
[48,     3] loss: 0.781
[49,     3] loss: 0.807
[50,     3] loss: 0.792
[51,     3] loss: 0.776
[52,     3] loss: 0.767
[53,     3] loss: 0.838
[54,     3] loss: 0.780
[55,     3] loss: 0.801
[56,     3] loss: 0.910
[57,     3] loss: 0.872
[58,     3] loss: 0.830
[59,     3] loss: 0.804
[60,     3] loss: 0.857
[61,     3] loss: 0.914
[62,     3] loss: 0.802
[63,     3] loss: 0.840
[64,     3] loss: 0.882
[65,     3] loss: 0.965
[66,     3] loss: 0.940
[67,     3] loss: 1.049
[68,     3] loss: 0.846
[69,     3] loss: 0.912
[70,     3] loss: 0.812
[71,     3] loss: 0.767
[72,     3] loss: 0.740
[73,     3] loss: 0.746
[74,     3] loss: 0.719
[75,     3] loss: 0.736
[76,     3] loss: 0.732
[77,     3] loss: 0.764
[78,     3] loss: 0.745
[79,     3] loss: 0.795
[80,     3] loss: 0.751
[81,     3] loss: 0.785
Early stopping applied (best metric=0.5120421648025513)
Finished Training
Total time taken: 18.04106831550598
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.392
[3,     3] loss: 1.391
[4,     3] loss: 1.386
[5,     3] loss: 1.384
[6,     3] loss: 1.383
[7,     3] loss: 1.391
[8,     3] loss: 1.381
[9,     3] loss: 1.381
[10,     3] loss: 1.391
[11,     3] loss: 1.382
[12,     3] loss: 1.387
[13,     3] loss: 1.360
[14,     3] loss: 1.367
[15,     3] loss: 1.331
[16,     3] loss: 1.318
[17,     3] loss: 1.305
[18,     3] loss: 1.265
[19,     3] loss: 1.204
[20,     3] loss: 1.173
[21,     3] loss: 1.189
[22,     3] loss: 1.252
[23,     3] loss: 1.242
[24,     3] loss: 1.179
[25,     3] loss: 1.108
[26,     3] loss: 1.118
[27,     3] loss: 1.071
[28,     3] loss: 0.982
[29,     3] loss: 1.003
[30,     3] loss: 0.943
[31,     3] loss: 1.071
[32,     3] loss: 1.001
[33,     3] loss: 1.099
[34,     3] loss: 0.965
[35,     3] loss: 0.984
[36,     3] loss: 0.995
[37,     3] loss: 0.975
[38,     3] loss: 0.907
[39,     3] loss: 1.021
[40,     3] loss: 0.881
[41,     3] loss: 0.920
[42,     3] loss: 0.851
[43,     3] loss: 0.888
[44,     3] loss: 0.984
[45,     3] loss: 0.922
[46,     3] loss: 0.896
[47,     3] loss: 0.950
[48,     3] loss: 0.885
[49,     3] loss: 0.866
[50,     3] loss: 0.877
[51,     3] loss: 0.873
[52,     3] loss: 0.826
[53,     3] loss: 0.863
[54,     3] loss: 0.859
[55,     3] loss: 0.836
[56,     3] loss: 0.872
[57,     3] loss: 0.776
[58,     3] loss: 0.770
[59,     3] loss: 0.780
[60,     3] loss: 0.748
[61,     3] loss: 0.752
[62,     3] loss: 0.725
[63,     3] loss: 0.783
[64,     3] loss: 0.756
[65,     3] loss: 0.793
[66,     3] loss: 0.768
[67,     3] loss: 0.782
[68,     3] loss: 0.788
[69,     3] loss: 0.967
[70,     3] loss: 1.172
[71,     3] loss: 1.160
[72,     3] loss: 1.115
[73,     3] loss: 1.096
Early stopping applied (best metric=0.4877944886684418)
Finished Training
Total time taken: 16.250077486038208
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.369
[3,     3] loss: 1.386
[4,     3] loss: 1.403
[5,     3] loss: 1.380
[6,     3] loss: 1.376
[7,     3] loss: 1.362
[8,     3] loss: 1.368
[9,     3] loss: 1.349
[10,     3] loss: 1.322
[11,     3] loss: 1.280
[12,     3] loss: 1.292
[13,     3] loss: 1.237
[14,     3] loss: 1.143
[15,     3] loss: 1.225
[16,     3] loss: 1.067
[17,     3] loss: 1.142
[18,     3] loss: 0.982
[19,     3] loss: 0.962
[20,     3] loss: 1.095
[21,     3] loss: 1.081
[22,     3] loss: 0.968
[23,     3] loss: 0.952
[24,     3] loss: 1.039
[25,     3] loss: 0.902
[26,     3] loss: 0.928
[27,     3] loss: 0.992
[28,     3] loss: 0.966
[29,     3] loss: 0.942
[30,     3] loss: 1.034
[31,     3] loss: 0.921
[32,     3] loss: 0.933
[33,     3] loss: 0.870
[34,     3] loss: 0.822
[35,     3] loss: 0.958
[36,     3] loss: 0.834
[37,     3] loss: 0.897
[38,     3] loss: 0.793
[39,     3] loss: 0.852
[40,     3] loss: 0.831
[41,     3] loss: 0.798
[42,     3] loss: 0.855
[43,     3] loss: 0.757
[44,     3] loss: 0.788
[45,     3] loss: 0.788
[46,     3] loss: 0.907
[47,     3] loss: 0.775
[48,     3] loss: 0.816
[49,     3] loss: 0.774
[50,     3] loss: 0.916
[51,     3] loss: 0.819
[52,     3] loss: 0.905
[53,     3] loss: 0.807
[54,     3] loss: 0.860
[55,     3] loss: 0.886
[56,     3] loss: 0.854
[57,     3] loss: 0.819
[58,     3] loss: 0.783
[59,     3] loss: 0.795
[60,     3] loss: 0.810
[61,     3] loss: 0.838
[62,     3] loss: 0.772
[63,     3] loss: 0.806
[64,     3] loss: 0.772
[65,     3] loss: 0.793
[66,     3] loss: 0.745
[67,     3] loss: 0.764
[68,     3] loss: 0.789
[69,     3] loss: 1.093
[70,     3] loss: 0.887
Early stopping applied (best metric=0.5008363127708435)
Finished Training
Total time taken: 15.563041925430298
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.390
[3,     3] loss: 1.387
[4,     3] loss: 1.384
[5,     3] loss: 1.381
[6,     3] loss: 1.379
[7,     3] loss: 1.383
[8,     3] loss: 1.369
[9,     3] loss: 1.363
[10,     3] loss: 1.317
[11,     3] loss: 1.298
[12,     3] loss: 1.260
[13,     3] loss: 1.224
[14,     3] loss: 1.205
[15,     3] loss: 1.150
[16,     3] loss: 1.275
[17,     3] loss: 1.215
[18,     3] loss: 1.101
[19,     3] loss: 1.201
[20,     3] loss: 1.122
[21,     3] loss: 1.058
[22,     3] loss: 1.202
[23,     3] loss: 1.156
[24,     3] loss: 1.034
[25,     3] loss: 1.037
[26,     3] loss: 1.000
[27,     3] loss: 0.979
[28,     3] loss: 0.902
[29,     3] loss: 0.972
[30,     3] loss: 0.979
[31,     3] loss: 1.037
[32,     3] loss: 0.972
[33,     3] loss: 0.982
[34,     3] loss: 1.024
[35,     3] loss: 0.924
[36,     3] loss: 0.982
[37,     3] loss: 1.081
[38,     3] loss: 0.956
[39,     3] loss: 1.006
[40,     3] loss: 0.892
[41,     3] loss: 0.845
[42,     3] loss: 0.995
[43,     3] loss: 0.838
[44,     3] loss: 0.876
[45,     3] loss: 0.822
[46,     3] loss: 0.790
[47,     3] loss: 0.807
[48,     3] loss: 0.772
[49,     3] loss: 0.904
[50,     3] loss: 0.879
[51,     3] loss: 0.835
[52,     3] loss: 0.860
[53,     3] loss: 0.838
[54,     3] loss: 0.782
[55,     3] loss: 0.831
[56,     3] loss: 0.837
[57,     3] loss: 0.896
[58,     3] loss: 0.834
[59,     3] loss: 0.796
[60,     3] loss: 0.862
[61,     3] loss: 0.824
[62,     3] loss: 0.848
[63,     3] loss: 0.962
[64,     3] loss: 0.862
[65,     3] loss: 0.852
[66,     3] loss: 0.812
[67,     3] loss: 0.865
[68,     3] loss: 0.896
Early stopping applied (best metric=0.5339506268501282)
Finished Training
Total time taken: 15.147040605545044
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.400
[3,     3] loss: 1.386
[4,     3] loss: 1.383
[5,     3] loss: 1.390
[6,     3] loss: 1.395
[7,     3] loss: 1.380
[8,     3] loss: 1.375
[9,     3] loss: 1.384
[10,     3] loss: 1.367
[11,     3] loss: 1.342
[12,     3] loss: 1.318
[13,     3] loss: 1.284
[14,     3] loss: 1.192
[15,     3] loss: 1.235
[16,     3] loss: 1.237
[17,     3] loss: 1.307
[18,     3] loss: 1.153
[19,     3] loss: 1.082
[20,     3] loss: 1.190
[21,     3] loss: 1.127
[22,     3] loss: 1.082
[23,     3] loss: 1.081
[24,     3] loss: 1.015
[25,     3] loss: 0.961
[26,     3] loss: 1.003
[27,     3] loss: 1.069
[28,     3] loss: 0.943
[29,     3] loss: 0.968
[30,     3] loss: 0.937
[31,     3] loss: 0.862
[32,     3] loss: 0.955
[33,     3] loss: 0.894
[34,     3] loss: 1.015
[35,     3] loss: 0.972
[36,     3] loss: 0.974
[37,     3] loss: 1.007
[38,     3] loss: 0.920
[39,     3] loss: 0.878
[40,     3] loss: 0.887
[41,     3] loss: 0.853
[42,     3] loss: 0.906
[43,     3] loss: 0.869
[44,     3] loss: 0.974
[45,     3] loss: 0.982
[46,     3] loss: 1.072
[47,     3] loss: 0.945
[48,     3] loss: 0.917
[49,     3] loss: 0.946
[50,     3] loss: 0.914
[51,     3] loss: 0.895
[52,     3] loss: 0.796
[53,     3] loss: 0.790
[54,     3] loss: 0.820
[55,     3] loss: 0.885
[56,     3] loss: 0.782
[57,     3] loss: 0.810
[58,     3] loss: 0.817
[59,     3] loss: 0.775
[60,     3] loss: 0.783
[61,     3] loss: 0.798
[62,     3] loss: 0.810
[63,     3] loss: 0.846
[64,     3] loss: 0.776
[65,     3] loss: 0.825
Early stopping applied (best metric=0.5343457460403442)
Finished Training
Total time taken: 14.447047710418701
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.388
[3,     3] loss: 1.383
[4,     3] loss: 1.380
[5,     3] loss: 1.383
[6,     3] loss: 1.392
[7,     3] loss: 1.379
[8,     3] loss: 1.388
[9,     3] loss: 1.358
[10,     3] loss: 1.342
[11,     3] loss: 1.318
[12,     3] loss: 1.321
[13,     3] loss: 1.288
[14,     3] loss: 1.287
[15,     3] loss: 1.234
[16,     3] loss: 1.183
[17,     3] loss: 1.194
[18,     3] loss: 1.131
[19,     3] loss: 1.121
[20,     3] loss: 1.054
[21,     3] loss: 1.070
[22,     3] loss: 1.178
[23,     3] loss: 0.997
[24,     3] loss: 1.057
[25,     3] loss: 1.019
[26,     3] loss: 1.018
[27,     3] loss: 0.998
[28,     3] loss: 1.153
[29,     3] loss: 1.046
[30,     3] loss: 1.255
[31,     3] loss: 1.110
[32,     3] loss: 1.112
[33,     3] loss: 1.204
[34,     3] loss: 1.120
[35,     3] loss: 1.061
[36,     3] loss: 1.066
[37,     3] loss: 1.030
[38,     3] loss: 1.111
[39,     3] loss: 0.960
[40,     3] loss: 0.913
[41,     3] loss: 0.980
[42,     3] loss: 0.889
[43,     3] loss: 0.912
[44,     3] loss: 0.870
[45,     3] loss: 0.883
[46,     3] loss: 0.854
[47,     3] loss: 0.925
[48,     3] loss: 0.959
[49,     3] loss: 0.955
[50,     3] loss: 0.919
[51,     3] loss: 0.915
[52,     3] loss: 0.893
[53,     3] loss: 0.860
[54,     3] loss: 0.792
[55,     3] loss: 0.808
[56,     3] loss: 0.783
[57,     3] loss: 0.774
[58,     3] loss: 0.769
[59,     3] loss: 0.758
[60,     3] loss: 0.797
[61,     3] loss: 0.827
[62,     3] loss: 0.791
[63,     3] loss: 0.758
[64,     3] loss: 0.770
[65,     3] loss: 0.847
[66,     3] loss: 0.775
[67,     3] loss: 0.785
[68,     3] loss: 0.773
[69,     3] loss: 0.779
[70,     3] loss: 0.949
[71,     3] loss: 1.004
Early stopping applied (best metric=0.5330034494400024)
Finished Training
Total time taken: 15.755042791366577
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.397
[3,     3] loss: 1.388
[4,     3] loss: 1.385
[5,     3] loss: 1.388
[6,     3] loss: 1.396
[7,     3] loss: 1.384
[8,     3] loss: 1.395
[9,     3] loss: 1.382
[10,     3] loss: 1.387
[11,     3] loss: 1.389
[12,     3] loss: 1.375
[13,     3] loss: 1.374
[14,     3] loss: 1.373
[15,     3] loss: 1.318
[16,     3] loss: 1.284
[17,     3] loss: 1.256
[18,     3] loss: 1.169
[19,     3] loss: 1.262
[20,     3] loss: 1.195
[21,     3] loss: 1.109
[22,     3] loss: 1.068
[23,     3] loss: 1.064
[24,     3] loss: 1.106
[25,     3] loss: 1.075
[26,     3] loss: 1.194
[27,     3] loss: 0.973
[28,     3] loss: 1.131
[29,     3] loss: 1.080
[30,     3] loss: 0.989
[31,     3] loss: 1.001
[32,     3] loss: 0.938
[33,     3] loss: 1.109
[34,     3] loss: 1.098
[35,     3] loss: 1.109
[36,     3] loss: 1.111
[37,     3] loss: 1.046
[38,     3] loss: 0.954
[39,     3] loss: 0.996
[40,     3] loss: 1.004
[41,     3] loss: 0.892
[42,     3] loss: 0.887
[43,     3] loss: 0.895
[44,     3] loss: 1.029
[45,     3] loss: 1.146
[46,     3] loss: 1.155
[47,     3] loss: 1.024
[48,     3] loss: 1.123
[49,     3] loss: 1.032
[50,     3] loss: 0.941
[51,     3] loss: 0.909
[52,     3] loss: 0.851
[53,     3] loss: 0.836
[54,     3] loss: 0.768
[55,     3] loss: 0.809
[56,     3] loss: 0.879
[57,     3] loss: 0.771
[58,     3] loss: 0.871
[59,     3] loss: 0.984
[60,     3] loss: 1.094
[61,     3] loss: 0.970
[62,     3] loss: 0.986
[63,     3] loss: 1.102
[64,     3] loss: 0.978
[65,     3] loss: 0.944
[66,     3] loss: 0.967
[67,     3] loss: 0.867
[68,     3] loss: 0.909
[69,     3] loss: 0.855
[70,     3] loss: 0.811
Early stopping applied (best metric=0.5020872950553894)
Finished Training
Total time taken: 15.577045202255249
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.385
[3,     3] loss: 1.391
[4,     3] loss: 1.389
[5,     3] loss: 1.389
[6,     3] loss: 1.372
[7,     3] loss: 1.382
[8,     3] loss: 1.356
[9,     3] loss: 1.352
[10,     3] loss: 1.315
[11,     3] loss: 1.303
[12,     3] loss: 1.263
[13,     3] loss: 1.180
[14,     3] loss: 1.206
[15,     3] loss: 1.121
[16,     3] loss: 1.176
[17,     3] loss: 1.227
[18,     3] loss: 1.046
[19,     3] loss: 1.026
[20,     3] loss: 1.052
[21,     3] loss: 1.012
[22,     3] loss: 0.948
[23,     3] loss: 0.933
[24,     3] loss: 1.040
[25,     3] loss: 0.966
[26,     3] loss: 0.960
[27,     3] loss: 0.894
[28,     3] loss: 0.922
[29,     3] loss: 0.951
[30,     3] loss: 0.875
[31,     3] loss: 0.916
[32,     3] loss: 0.950
[33,     3] loss: 0.947
[34,     3] loss: 0.969
[35,     3] loss: 0.890
[36,     3] loss: 0.848
[37,     3] loss: 0.915
[38,     3] loss: 0.949
[39,     3] loss: 0.908
[40,     3] loss: 0.951
[41,     3] loss: 0.940
[42,     3] loss: 0.929
[43,     3] loss: 0.905
[44,     3] loss: 0.879
[45,     3] loss: 0.829
[46,     3] loss: 0.862
[47,     3] loss: 0.815
[48,     3] loss: 0.818
[49,     3] loss: 0.807
[50,     3] loss: 0.800
[51,     3] loss: 0.867
[52,     3] loss: 0.863
[53,     3] loss: 1.128
[54,     3] loss: 1.066
[55,     3] loss: 1.011
[56,     3] loss: 0.962
[57,     3] loss: 0.907
[58,     3] loss: 0.918
[59,     3] loss: 0.903
[60,     3] loss: 0.804
[61,     3] loss: 0.927
[62,     3] loss: 0.808
[63,     3] loss: 0.780
[64,     3] loss: 0.773
[65,     3] loss: 0.777
[66,     3] loss: 0.933
[67,     3] loss: 0.810
[68,     3] loss: 0.828
[69,     3] loss: 0.822
[70,     3] loss: 0.806
[71,     3] loss: 0.930
Early stopping applied (best metric=0.5155931115150452)
Finished Training
Total time taken: 15.856045484542847
{'S-palmitoylation-C Validation Accuracy': 0.6852113566524047, 'S-palmitoylation-C Validation Sensitivity': 0.2337953795379538, 'S-palmitoylation-C Validation Specificity': 0.7983652398471247, 'S-palmitoylation-C Validation Precision': 0.24983781158162705, 'S-palmitoylation-C AUC ROC': 0.5417182172930085, 'S-palmitoylation-C AUC PR': 0.22564272062813945, 'S-palmitoylation-C MCC': 0.03623149949343235, 'S-palmitoylation-C F1': 0.20947721768563438, 'Validation Loss (S-palmitoylation-C)': 0.5549679358800252, 'Hydroxylation-K Validation Accuracy': 0.7169917257683215, 'Hydroxylation-K Validation Sensitivity': 0.8066666666666666, 'Hydroxylation-K Validation Specificity': 0.6947368421052632, 'Hydroxylation-K Validation Precision': 0.4132426945882323, 'Hydroxylation-K AUC ROC': 0.822962962962963, 'Hydroxylation-K AUC PR': 0.5723422625659337, 'Hydroxylation-K MCC': 0.41920814889149954, 'Hydroxylation-K F1': 0.5379096928284915, 'Validation Loss (Hydroxylation-K)': 0.5171517809232076, 'Validation Loss (total)': 1.072119696935018, 'TimeToTrain': 16.378651825586953}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0026176099828192512,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6888445149061562,
 'loss_weight_S-palmitoylation-C': 0.01752676188248123,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 412424737,
 'sample_weights': [0.18072087100406328, 0.28030333215574804],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.716738267057522,
 'weight_decay_Hydroxylation-K': 5.388830388760834,
 'weight_decay_S-palmitoylation-C': 3.0916928292350514}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.384
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016787253128067129,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9584900674043646,
 'loss_weight_S-palmitoylation-C': 0.31993869892185944,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1664695530,
 'sample_weights': [0.01752676188248123, 0.6888445149061562],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.0110383245709733,
 'weight_decay_Hydroxylation-K': 4.386799947424501,
 'weight_decay_S-palmitoylation-C': 4.35348977601661}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.383
[3,     3] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00016388844376864027,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6544846766520886,
 'loss_weight_S-palmitoylation-C': 0.3581929484574767,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1754044771,
 'sample_weights': [0.31993869892185944, 0.9584900674043646],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6568140628624297,
 'weight_decay_Hydroxylation-K': 3.5661111919265704,
 'weight_decay_S-palmitoylation-C': 7.471102417845966}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.383
[3,     3] loss: 1.399
[4,     3] loss: 1.392
[5,     3] loss: 1.393
[6,     3] loss: 1.388
[7,     3] loss: 1.383
[8,     3] loss: 1.381
[9,     3] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004408861498451273,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7935171436638053,
 'loss_weight_S-palmitoylation-C': 0.197566527204154,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1585703803,
 'sample_weights': [0.3581929484574767, 0.6544846766520886],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.807670838337083,
 'weight_decay_Hydroxylation-K': 3.7574964773244948,
 'weight_decay_S-palmitoylation-C': 2.4129488037068767}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.390
[4,     3] loss: 1.389
[5,     3] loss: 1.382
[6,     3] loss: 1.379
[7,     3] loss: 1.386
[8,     3] loss: 1.379
[9,     3] loss: 1.366
[10,     3] loss: 1.356
[11,     3] loss: 1.303
[12,     3] loss: 1.262
[13,     3] loss: 1.297
[14,     3] loss: 1.159
[15,     3] loss: 1.097
[16,     3] loss: 1.244
[17,     3] loss: 1.147
[18,     3] loss: 1.185
[19,     3] loss: 1.188
[20,     3] loss: 1.108
[21,     3] loss: 1.102
[22,     3] loss: 1.135
[23,     3] loss: 1.085
[24,     3] loss: 1.061
[25,     3] loss: 0.997
[26,     3] loss: 0.937
[27,     3] loss: 0.966
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002261459189887647,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.20292076468498751,
 'loss_weight_S-palmitoylation-C': 0.5924175174534596,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1133496032,
 'sample_weights': [0.197566527204154, 0.7935171436638053],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6031189009283509,
 'weight_decay_Hydroxylation-K': 8.853117225658233,
 'weight_decay_S-palmitoylation-C': 1.4962641704120783}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.382
[3,     3] loss: 1.376
[4,     3] loss: 1.406
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.386
[8,     3] loss: 1.389
[9,     3] loss: 1.382
[10,     3] loss: 1.386
[11,     3] loss: 1.377
[12,     3] loss: 1.382
[13,     3] loss: 1.382
[14,     3] loss: 1.391
[15,     3] loss: 1.395
[16,     3] loss: 1.388
[17,     3] loss: 1.386
[18,     3] loss: 1.383
[19,     3] loss: 1.389
[20,     3] loss: 1.385
[21,     3] loss: 1.385
[22,     3] loss: 1.386
[23,     3] loss: 1.386
[24,     3] loss: 1.386
[25,     3] loss: 1.385
[26,     3] loss: 1.387
[27,     3] loss: 1.384
[28,     3] loss: 1.384
[29,     3] loss: 1.380
[30,     3] loss: 1.383
[31,     3] loss: 1.377
[32,     3] loss: 1.378
[33,     3] loss: 1.370
[34,     3] loss: 1.363
[35,     3] loss: 1.343
[36,     3] loss: 1.331
[37,     3] loss: 1.277
[38,     3] loss: 1.271
[39,     3] loss: 1.215
[40,     3] loss: 1.237
[41,     3] loss: 1.185
[42,     3] loss: 1.318
[43,     3] loss: 1.135
[44,     3] loss: 1.129
[45,     3] loss: 1.120
[46,     3] loss: 1.110
[47,     3] loss: 1.066
[48,     3] loss: 1.005
[49,     3] loss: 1.013
[50,     3] loss: 0.960
[51,     3] loss: 0.968
[52,     3] loss: 0.882
[53,     3] loss: 1.088
[54,     3] loss: 0.923
[55,     3] loss: 0.937
[56,     3] loss: 0.918
[57,     3] loss: 0.919
[58,     3] loss: 0.902
[59,     3] loss: 0.908
[60,     3] loss: 0.869
[61,     3] loss: 0.863
[62,     3] loss: 0.821
[63,     3] loss: 0.950
[64,     3] loss: 0.940
[65,     3] loss: 0.972
[66,     3] loss: 0.906
[67,     3] loss: 1.033
[68,     3] loss: 0.882
[69,     3] loss: 0.938
[70,     3] loss: 0.919
[71,     3] loss: 0.943
[72,     3] loss: 0.869
[73,     3] loss: 0.914
[74,     3] loss: 0.860
[75,     3] loss: 0.844
[76,     3] loss: 0.894
[77,     3] loss: 0.893
[78,     3] loss: 0.786
[79,     3] loss: 0.859
[80,     3] loss: 0.900
[81,     3] loss: 0.835
[82,     3] loss: 0.888
[83,     3] loss: 0.864
[84,     3] loss: 0.848
[85,     3] loss: 0.814
[86,     3] loss: 0.860
[87,     3] loss: 0.836
[88,     3] loss: 0.869
[89,     3] loss: 0.811
Early stopping applied (best metric=0.49044081568717957)
Finished Training
Total time taken: 19.7940571308136
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.386
[3,     3] loss: 1.382
[4,     3] loss: 1.398
[5,     3] loss: 1.398
[6,     3] loss: 1.382
[7,     3] loss: 1.393
[8,     3] loss: 1.387
[9,     3] loss: 1.385
[10,     3] loss: 1.390
[11,     3] loss: 1.384
[12,     3] loss: 1.384
[13,     3] loss: 1.385
[14,     3] loss: 1.387
[15,     3] loss: 1.390
[16,     3] loss: 1.386
[17,     3] loss: 1.384
[18,     3] loss: 1.382
[19,     3] loss: 1.382
[20,     3] loss: 1.385
[21,     3] loss: 1.382
[22,     3] loss: 1.380
[23,     3] loss: 1.378
[24,     3] loss: 1.373
[25,     3] loss: 1.370
[26,     3] loss: 1.361
[27,     3] loss: 1.328
[28,     3] loss: 1.300
[29,     3] loss: 1.309
[30,     3] loss: 1.355
[31,     3] loss: 1.207
[32,     3] loss: 1.215
[33,     3] loss: 1.166
[34,     3] loss: 1.068
[35,     3] loss: 1.105
[36,     3] loss: 1.094
[37,     3] loss: 1.120
[38,     3] loss: 1.099
[39,     3] loss: 1.044
[40,     3] loss: 1.133
[41,     3] loss: 1.031
[42,     3] loss: 1.056
[43,     3] loss: 1.062
[44,     3] loss: 1.004
[45,     3] loss: 1.075
[46,     3] loss: 1.219
[47,     3] loss: 1.114
[48,     3] loss: 1.027
[49,     3] loss: 0.996
[50,     3] loss: 1.050
[51,     3] loss: 1.045
[52,     3] loss: 0.972
[53,     3] loss: 0.976
[54,     3] loss: 0.938
[55,     3] loss: 0.981
[56,     3] loss: 0.932
[57,     3] loss: 0.887
[58,     3] loss: 0.955
[59,     3] loss: 0.930
[60,     3] loss: 0.870
[61,     3] loss: 0.878
[62,     3] loss: 0.967
[63,     3] loss: 0.880
[64,     3] loss: 0.846
[65,     3] loss: 0.842
[66,     3] loss: 0.852
[67,     3] loss: 0.842
[68,     3] loss: 0.872
[69,     3] loss: 0.902
[70,     3] loss: 0.911
[71,     3] loss: 0.817
[72,     3] loss: 0.832
[73,     3] loss: 0.863
[74,     3] loss: 0.851
[75,     3] loss: 0.810
[76,     3] loss: 0.804
[77,     3] loss: 0.900
[78,     3] loss: 0.827
[79,     3] loss: 0.862
[80,     3] loss: 0.854
[81,     3] loss: 0.814
Early stopping applied (best metric=0.4778563976287842)
Finished Training
Total time taken: 18.025047779083252
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.393
[3,     3] loss: 1.387
[4,     3] loss: 1.384
[5,     3] loss: 1.387
[6,     3] loss: 1.387
[7,     3] loss: 1.386
[8,     3] loss: 1.381
[9,     3] loss: 1.380
[10,     3] loss: 1.382
[11,     3] loss: 1.378
[12,     3] loss: 1.393
[13,     3] loss: 1.379
[14,     3] loss: 1.379
[15,     3] loss: 1.369
[16,     3] loss: 1.365
[17,     3] loss: 1.350
[18,     3] loss: 1.346
[19,     3] loss: 1.331
[20,     3] loss: 1.294
[21,     3] loss: 1.275
[22,     3] loss: 1.259
[23,     3] loss: 1.204
[24,     3] loss: 1.245
[25,     3] loss: 1.328
[26,     3] loss: 1.176
[27,     3] loss: 1.166
[28,     3] loss: 1.220
[29,     3] loss: 1.184
[30,     3] loss: 1.160
[31,     3] loss: 1.178
[32,     3] loss: 1.143
[33,     3] loss: 1.144
[34,     3] loss: 1.120
[35,     3] loss: 1.044
[36,     3] loss: 1.130
[37,     3] loss: 0.982
[38,     3] loss: 0.992
[39,     3] loss: 1.045
[40,     3] loss: 0.986
[41,     3] loss: 1.101
[42,     3] loss: 0.962
[43,     3] loss: 1.010
[44,     3] loss: 0.951
[45,     3] loss: 0.941
[46,     3] loss: 0.892
[47,     3] loss: 0.933
[48,     3] loss: 0.869
[49,     3] loss: 1.111
[50,     3] loss: 0.867
[51,     3] loss: 0.883
[52,     3] loss: 0.855
[53,     3] loss: 0.890
[54,     3] loss: 0.931
[55,     3] loss: 1.002
[56,     3] loss: 0.882
[57,     3] loss: 0.865
[58,     3] loss: 0.888
[59,     3] loss: 0.876
[60,     3] loss: 0.884
[61,     3] loss: 0.894
[62,     3] loss: 0.936
[63,     3] loss: 0.874
[64,     3] loss: 0.888
[65,     3] loss: 0.947
[66,     3] loss: 0.874
[67,     3] loss: 0.877
[68,     3] loss: 0.824
[69,     3] loss: 0.925
[70,     3] loss: 0.862
[71,     3] loss: 0.803
[72,     3] loss: 0.815
[73,     3] loss: 0.793
[74,     3] loss: 0.801
[75,     3] loss: 0.826
[76,     3] loss: 0.827
[77,     3] loss: 0.768
[78,     3] loss: 0.791
[79,     3] loss: 0.795
[80,     3] loss: 0.778
[81,     3] loss: 0.759
[82,     3] loss: 0.806
[83,     3] loss: 0.750
[84,     3] loss: 0.757
[85,     3] loss: 0.903
[86,     3] loss: 0.811
[87,     3] loss: 0.762
[88,     3] loss: 0.770
[89,     3] loss: 0.796
Early stopping applied (best metric=0.5262455940246582)
Finished Training
Total time taken: 19.766050815582275
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.390
[3,     3] loss: 1.389
[4,     3] loss: 1.386
[5,     3] loss: 1.392
[6,     3] loss: 1.385
[7,     3] loss: 1.381
[8,     3] loss: 1.381
[9,     3] loss: 1.380
[10,     3] loss: 1.379
[11,     3] loss: 1.378
[12,     3] loss: 1.374
[13,     3] loss: 1.373
[14,     3] loss: 1.369
[15,     3] loss: 1.353
[16,     3] loss: 1.349
[17,     3] loss: 1.317
[18,     3] loss: 1.302
[19,     3] loss: 1.254
[20,     3] loss: 1.239
[21,     3] loss: 1.222
[22,     3] loss: 1.145
[23,     3] loss: 1.093
[24,     3] loss: 1.116
[25,     3] loss: 1.116
[26,     3] loss: 1.170
[27,     3] loss: 1.157
[28,     3] loss: 1.076
[29,     3] loss: 1.056
[30,     3] loss: 1.028
[31,     3] loss: 1.037
[32,     3] loss: 1.086
[33,     3] loss: 1.016
[34,     3] loss: 1.005
[35,     3] loss: 0.935
[36,     3] loss: 0.964
[37,     3] loss: 0.887
[38,     3] loss: 0.939
[39,     3] loss: 1.006
[40,     3] loss: 1.001
[41,     3] loss: 0.962
[42,     3] loss: 0.959
[43,     3] loss: 0.905
[44,     3] loss: 1.060
[45,     3] loss: 0.959
[46,     3] loss: 0.893
[47,     3] loss: 0.913
[48,     3] loss: 0.919
[49,     3] loss: 0.903
[50,     3] loss: 0.872
[51,     3] loss: 0.849
[52,     3] loss: 0.867
[53,     3] loss: 0.858
[54,     3] loss: 0.816
[55,     3] loss: 0.783
[56,     3] loss: 0.792
[57,     3] loss: 0.825
[58,     3] loss: 0.901
[59,     3] loss: 0.892
[60,     3] loss: 0.833
[61,     3] loss: 0.816
[62,     3] loss: 0.813
[63,     3] loss: 0.790
[64,     3] loss: 0.893
[65,     3] loss: 0.789
[66,     3] loss: 0.810
[67,     3] loss: 0.828
[68,     3] loss: 0.777
[69,     3] loss: 0.833
[70,     3] loss: 0.886
[71,     3] loss: 0.776
[72,     3] loss: 0.834
[73,     3] loss: 0.843
[74,     3] loss: 0.763
[75,     3] loss: 0.798
[76,     3] loss: 0.819
[77,     3] loss: 0.764
[78,     3] loss: 0.785
[79,     3] loss: 0.825
[80,     3] loss: 0.777
[81,     3] loss: 0.797
[82,     3] loss: 0.763
[83,     3] loss: 0.775
[84,     3] loss: 0.756
[85,     3] loss: 0.768
[86,     3] loss: 0.751
[87,     3] loss: 0.773
Early stopping applied (best metric=0.5235701203346252)
Finished Training
Total time taken: 19.306053400039673
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.386
[3,     3] loss: 1.384
[4,     3] loss: 1.385
[5,     3] loss: 1.381
[6,     3] loss: 1.384
[7,     3] loss: 1.374
[8,     3] loss: 1.384
[9,     3] loss: 1.380
[10,     3] loss: 1.368
[11,     3] loss: 1.361
[12,     3] loss: 1.366
[13,     3] loss: 1.345
[14,     3] loss: 1.331
[15,     3] loss: 1.300
[16,     3] loss: 1.246
[17,     3] loss: 1.239
[18,     3] loss: 1.257
[19,     3] loss: 1.249
[20,     3] loss: 1.154
[21,     3] loss: 1.250
[22,     3] loss: 1.177
[23,     3] loss: 1.227
[24,     3] loss: 1.144
[25,     3] loss: 1.110
[26,     3] loss: 1.096
[27,     3] loss: 1.074
[28,     3] loss: 1.068
[29,     3] loss: 1.108
[30,     3] loss: 0.970
[31,     3] loss: 1.041
[32,     3] loss: 1.009
[33,     3] loss: 1.004
[34,     3] loss: 0.967
[35,     3] loss: 0.880
[36,     3] loss: 0.922
[37,     3] loss: 0.895
[38,     3] loss: 0.946
[39,     3] loss: 0.872
[40,     3] loss: 0.831
[41,     3] loss: 0.889
[42,     3] loss: 0.909
[43,     3] loss: 0.901
[44,     3] loss: 0.888
[45,     3] loss: 0.890
[46,     3] loss: 0.903
[47,     3] loss: 0.859
[48,     3] loss: 0.860
[49,     3] loss: 0.797
[50,     3] loss: 0.835
[51,     3] loss: 0.811
[52,     3] loss: 0.784
[53,     3] loss: 0.788
[54,     3] loss: 0.800
[55,     3] loss: 0.838
[56,     3] loss: 0.810
[57,     3] loss: 0.803
[58,     3] loss: 0.850
[59,     3] loss: 0.807
[60,     3] loss: 0.840
[61,     3] loss: 0.830
[62,     3] loss: 0.892
[63,     3] loss: 0.809
[64,     3] loss: 0.808
[65,     3] loss: 0.807
[66,     3] loss: 0.801
[67,     3] loss: 0.769
[68,     3] loss: 0.758
[69,     3] loss: 0.783
[70,     3] loss: 0.835
[71,     3] loss: 0.753
[72,     3] loss: 0.778
[73,     3] loss: 0.817
[74,     3] loss: 0.762
[75,     3] loss: 0.764
[76,     3] loss: 0.763
[77,     3] loss: 0.747
[78,     3] loss: 0.753
[79,     3] loss: 0.743
Early stopping applied (best metric=0.4799663722515106)
Finished Training
Total time taken: 17.539050817489624
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.380
[3,     3] loss: 1.385
[4,     3] loss: 1.381
[5,     3] loss: 1.388
[6,     3] loss: 1.389
[7,     3] loss: 1.383
[8,     3] loss: 1.379
[9,     3] loss: 1.384
[10,     3] loss: 1.371
[11,     3] loss: 1.376
[12,     3] loss: 1.370
[13,     3] loss: 1.358
[14,     3] loss: 1.340
[15,     3] loss: 1.315
[16,     3] loss: 1.306
[17,     3] loss: 1.250
[18,     3] loss: 1.243
[19,     3] loss: 1.251
[20,     3] loss: 1.137
[21,     3] loss: 1.148
[22,     3] loss: 1.068
[23,     3] loss: 1.171
[24,     3] loss: 1.063
[25,     3] loss: 1.084
[26,     3] loss: 1.127
[27,     3] loss: 1.081
[28,     3] loss: 1.036
[29,     3] loss: 0.990
[30,     3] loss: 0.953
[31,     3] loss: 0.935
[32,     3] loss: 0.968
[33,     3] loss: 1.004
[34,     3] loss: 0.923
[35,     3] loss: 0.912
[36,     3] loss: 0.871
[37,     3] loss: 0.912
[38,     3] loss: 0.900
[39,     3] loss: 0.850
[40,     3] loss: 0.920
[41,     3] loss: 0.981
[42,     3] loss: 0.876
[43,     3] loss: 0.902
[44,     3] loss: 0.884
[45,     3] loss: 0.876
[46,     3] loss: 0.839
[47,     3] loss: 0.853
[48,     3] loss: 0.828
[49,     3] loss: 0.826
[50,     3] loss: 0.845
[51,     3] loss: 0.794
[52,     3] loss: 0.823
[53,     3] loss: 0.827
[54,     3] loss: 0.795
[55,     3] loss: 0.814
[56,     3] loss: 0.896
[57,     3] loss: 0.818
[58,     3] loss: 0.789
[59,     3] loss: 0.778
[60,     3] loss: 0.829
[61,     3] loss: 0.824
[62,     3] loss: 0.903
[63,     3] loss: 0.847
[64,     3] loss: 0.817
[65,     3] loss: 0.806
[66,     3] loss: 0.835
[67,     3] loss: 0.830
[68,     3] loss: 0.920
[69,     3] loss: 0.866
[70,     3] loss: 0.799
[71,     3] loss: 0.836
[72,     3] loss: 0.802
[73,     3] loss: 0.893
[74,     3] loss: 0.777
[75,     3] loss: 0.838
[76,     3] loss: 0.827
[77,     3] loss: 0.813
[78,     3] loss: 0.762
[79,     3] loss: 0.814
[80,     3] loss: 0.804
[81,     3] loss: 0.839
[82,     3] loss: 0.771
[83,     3] loss: 0.779
[84,     3] loss: 0.766
[85,     3] loss: 0.820
[86,     3] loss: 0.774
[87,     3] loss: 0.791
[88,     3] loss: 0.746
[89,     3] loss: 0.751
[90,     3] loss: 0.761
[91,     3] loss: 0.776
[92,     3] loss: 0.763
[93,     3] loss: 0.786
[94,     3] loss: 0.760
[95,     3] loss: 0.744
[96,     3] loss: 0.745
[97,     3] loss: 0.770
[98,     3] loss: 0.751
[99,     3] loss: 0.746
[100,     3] loss: 0.733
[101,     3] loss: 0.777
[102,     3] loss: 0.776
[103,     3] loss: 0.789
[104,     3] loss: 0.767
[105,     3] loss: 0.809
[106,     3] loss: 0.765
[107,     3] loss: 0.859
[108,     3] loss: 0.853
[109,     3] loss: 0.799
Early stopping applied (best metric=0.5304017663002014)
Finished Training
Total time taken: 24.24908447265625
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.394
[3,     3] loss: 1.386
[4,     3] loss: 1.387
[5,     3] loss: 1.389
[6,     3] loss: 1.388
[7,     3] loss: 1.387
[8,     3] loss: 1.385
[9,     3] loss: 1.382
[10,     3] loss: 1.380
[11,     3] loss: 1.380
[12,     3] loss: 1.378
[13,     3] loss: 1.391
[14,     3] loss: 1.370
[15,     3] loss: 1.378
[16,     3] loss: 1.367
[17,     3] loss: 1.350
[18,     3] loss: 1.346
[19,     3] loss: 1.281
[20,     3] loss: 1.326
[21,     3] loss: 1.283
[22,     3] loss: 1.283
[23,     3] loss: 1.265
[24,     3] loss: 1.223
[25,     3] loss: 1.145
[26,     3] loss: 1.065
[27,     3] loss: 1.052
[28,     3] loss: 0.984
[29,     3] loss: 1.167
[30,     3] loss: 1.001
[31,     3] loss: 1.069
[32,     3] loss: 1.038
[33,     3] loss: 0.976
[34,     3] loss: 0.967
[35,     3] loss: 1.061
[36,     3] loss: 1.038
[37,     3] loss: 1.026
[38,     3] loss: 0.942
[39,     3] loss: 0.962
[40,     3] loss: 0.868
[41,     3] loss: 0.976
[42,     3] loss: 0.867
[43,     3] loss: 0.931
[44,     3] loss: 1.006
[45,     3] loss: 0.917
[46,     3] loss: 0.919
[47,     3] loss: 0.884
[48,     3] loss: 0.872
[49,     3] loss: 0.891
[50,     3] loss: 0.856
[51,     3] loss: 0.901
[52,     3] loss: 0.865
[53,     3] loss: 0.873
[54,     3] loss: 0.834
[55,     3] loss: 0.938
[56,     3] loss: 0.879
[57,     3] loss: 0.819
[58,     3] loss: 0.845
[59,     3] loss: 0.840
[60,     3] loss: 0.826
[61,     3] loss: 0.809
[62,     3] loss: 0.826
[63,     3] loss: 0.797
[64,     3] loss: 0.836
[65,     3] loss: 0.789
[66,     3] loss: 0.787
[67,     3] loss: 0.786
[68,     3] loss: 0.780
[69,     3] loss: 0.865
[70,     3] loss: 0.819
[71,     3] loss: 0.800
[72,     3] loss: 0.814
[73,     3] loss: 0.781
[74,     3] loss: 0.782
[75,     3] loss: 0.793
[76,     3] loss: 0.761
[77,     3] loss: 0.769
[78,     3] loss: 0.778
[79,     3] loss: 0.840
[80,     3] loss: 0.761
Early stopping applied (best metric=0.5297150611877441)
Finished Training
Total time taken: 17.797061443328857
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.390
[3,     3] loss: 1.385
[4,     3] loss: 1.399
[5,     3] loss: 1.385
[6,     3] loss: 1.386
[7,     3] loss: 1.384
[8,     3] loss: 1.383
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.386
[12,     3] loss: 1.380
[13,     3] loss: 1.379
[14,     3] loss: 1.382
[15,     3] loss: 1.382
[16,     3] loss: 1.387
[17,     3] loss: 1.376
[18,     3] loss: 1.377
[19,     3] loss: 1.369
[20,     3] loss: 1.356
[21,     3] loss: 1.330
[22,     3] loss: 1.316
[23,     3] loss: 1.332
[24,     3] loss: 1.227
[25,     3] loss: 1.206
[26,     3] loss: 1.198
[27,     3] loss: 1.080
[28,     3] loss: 1.042
[29,     3] loss: 1.046
[30,     3] loss: 1.048
[31,     3] loss: 1.008
[32,     3] loss: 1.022
[33,     3] loss: 1.013
[34,     3] loss: 1.032
[35,     3] loss: 0.961
[36,     3] loss: 0.967
[37,     3] loss: 0.950
[38,     3] loss: 0.999
[39,     3] loss: 0.945
[40,     3] loss: 0.964
[41,     3] loss: 0.958
[42,     3] loss: 0.908
[43,     3] loss: 0.917
[44,     3] loss: 0.939
[45,     3] loss: 0.921
[46,     3] loss: 0.838
[47,     3] loss: 0.951
[48,     3] loss: 0.829
[49,     3] loss: 0.859
[50,     3] loss: 0.820
[51,     3] loss: 0.828
[52,     3] loss: 0.784
[53,     3] loss: 0.769
[54,     3] loss: 0.788
[55,     3] loss: 0.794
[56,     3] loss: 0.778
[57,     3] loss: 0.766
[58,     3] loss: 0.822
[59,     3] loss: 0.818
[60,     3] loss: 0.789
[61,     3] loss: 0.790
[62,     3] loss: 0.811
[63,     3] loss: 0.808
[64,     3] loss: 0.795
[65,     3] loss: 0.782
[66,     3] loss: 0.757
[67,     3] loss: 0.798
[68,     3] loss: 0.802
[69,     3] loss: 0.815
[70,     3] loss: 0.850
[71,     3] loss: 0.784
[72,     3] loss: 0.812
[73,     3] loss: 0.799
[74,     3] loss: 0.789
[75,     3] loss: 0.784
[76,     3] loss: 0.838
[77,     3] loss: 0.776
[78,     3] loss: 0.758
[79,     3] loss: 0.761
[80,     3] loss: 0.750
[81,     3] loss: 0.735
Early stopping applied (best metric=0.5048491358757019)
Finished Training
Total time taken: 18.012059450149536
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.410
[2,     3] loss: 1.395
[3,     3] loss: 1.389
[4,     3] loss: 1.385
[5,     3] loss: 1.387
[6,     3] loss: 1.379
[7,     3] loss: 1.384
[8,     3] loss: 1.387
[9,     3] loss: 1.388
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.388
[13,     3] loss: 1.386
[14,     3] loss: 1.385
[15,     3] loss: 1.387
[16,     3] loss: 1.388
[17,     3] loss: 1.386
[18,     3] loss: 1.385
[19,     3] loss: 1.385
[20,     3] loss: 1.385
[21,     3] loss: 1.384
[22,     3] loss: 1.390
[23,     3] loss: 1.386
[24,     3] loss: 1.388
[25,     3] loss: 1.386
[26,     3] loss: 1.385
[27,     3] loss: 1.386
[28,     3] loss: 1.386
[29,     3] loss: 1.386
[30,     3] loss: 1.387
[31,     3] loss: 1.386
[32,     3] loss: 1.386
[33,     3] loss: 1.386
[34,     3] loss: 1.385
[35,     3] loss: 1.383
[36,     3] loss: 1.381
[37,     3] loss: 1.378
[38,     3] loss: 1.374
[39,     3] loss: 1.376
[40,     3] loss: 1.358
[41,     3] loss: 1.338
[42,     3] loss: 1.284
[43,     3] loss: 1.252
[44,     3] loss: 1.132
[45,     3] loss: 1.320
[46,     3] loss: 1.213
[47,     3] loss: 1.130
[48,     3] loss: 1.186
[49,     3] loss: 1.095
[50,     3] loss: 1.039
[51,     3] loss: 1.035
[52,     3] loss: 1.086
[53,     3] loss: 1.068
[54,     3] loss: 1.012
[55,     3] loss: 1.002
[56,     3] loss: 1.090
[57,     3] loss: 0.949
[58,     3] loss: 1.058
[59,     3] loss: 0.949
[60,     3] loss: 0.960
[61,     3] loss: 0.944
[62,     3] loss: 0.942
[63,     3] loss: 0.993
[64,     3] loss: 1.003
[65,     3] loss: 0.863
[66,     3] loss: 0.920
[67,     3] loss: 0.923
[68,     3] loss: 0.871
[69,     3] loss: 0.899
[70,     3] loss: 0.902
[71,     3] loss: 0.856
[72,     3] loss: 0.976
[73,     3] loss: 0.854
[74,     3] loss: 0.886
[75,     3] loss: 0.869
[76,     3] loss: 0.857
[77,     3] loss: 0.905
[78,     3] loss: 0.880
[79,     3] loss: 0.855
[80,     3] loss: 0.867
[81,     3] loss: 0.866
[82,     3] loss: 0.892
[83,     3] loss: 0.924
[84,     3] loss: 0.854
[85,     3] loss: 0.912
[86,     3] loss: 0.921
[87,     3] loss: 0.906
[88,     3] loss: 0.949
[89,     3] loss: 0.810
[90,     3] loss: 0.910
[91,     3] loss: 0.843
[92,     3] loss: 0.957
Early stopping applied (best metric=0.5240474343299866)
Finished Training
Total time taken: 20.429067134857178
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.387
[3,     3] loss: 1.385
[4,     3] loss: 1.388
[5,     3] loss: 1.387
[6,     3] loss: 1.390
[7,     3] loss: 1.386
[8,     3] loss: 1.384
[9,     3] loss: 1.390
[10,     3] loss: 1.384
[11,     3] loss: 1.383
[12,     3] loss: 1.385
[13,     3] loss: 1.386
[14,     3] loss: 1.385
[15,     3] loss: 1.385
[16,     3] loss: 1.385
[17,     3] loss: 1.386
[18,     3] loss: 1.383
[19,     3] loss: 1.385
[20,     3] loss: 1.386
[21,     3] loss: 1.380
[22,     3] loss: 1.380
[23,     3] loss: 1.377
[24,     3] loss: 1.367
[25,     3] loss: 1.365
[26,     3] loss: 1.350
[27,     3] loss: 1.323
[28,     3] loss: 1.325
[29,     3] loss: 1.248
[30,     3] loss: 1.227
[31,     3] loss: 1.235
[32,     3] loss: 1.268
[33,     3] loss: 1.245
[34,     3] loss: 1.303
[35,     3] loss: 1.240
[36,     3] loss: 1.199
[37,     3] loss: 1.272
[38,     3] loss: 1.173
[39,     3] loss: 1.156
[40,     3] loss: 1.203
[41,     3] loss: 1.159
[42,     3] loss: 1.085
[43,     3] loss: 1.055
[44,     3] loss: 1.154
[45,     3] loss: 1.062
[46,     3] loss: 1.175
[47,     3] loss: 1.158
[48,     3] loss: 1.098
[49,     3] loss: 1.075
[50,     3] loss: 1.086
[51,     3] loss: 1.058
[52,     3] loss: 1.046
[53,     3] loss: 1.012
[54,     3] loss: 0.939
[55,     3] loss: 0.929
[56,     3] loss: 0.969
[57,     3] loss: 0.980
[58,     3] loss: 0.921
[59,     3] loss: 0.887
[60,     3] loss: 0.949
[61,     3] loss: 0.950
[62,     3] loss: 1.001
[63,     3] loss: 0.916
[64,     3] loss: 1.014
[65,     3] loss: 0.953
[66,     3] loss: 0.996
[67,     3] loss: 0.960
[68,     3] loss: 0.907
[69,     3] loss: 1.042
[70,     3] loss: 0.969
[71,     3] loss: 0.940
[72,     3] loss: 0.927
[73,     3] loss: 0.987
[74,     3] loss: 1.037
[75,     3] loss: 0.905
[76,     3] loss: 0.864
[77,     3] loss: 0.918
[78,     3] loss: 0.888
[79,     3] loss: 0.903
[80,     3] loss: 0.834
[81,     3] loss: 0.839
[82,     3] loss: 0.872
[83,     3] loss: 0.839
[84,     3] loss: 0.835
[85,     3] loss: 0.824
[86,     3] loss: 0.820
[87,     3] loss: 0.820
[88,     3] loss: 0.811
[89,     3] loss: 0.794
[90,     3] loss: 0.823
[91,     3] loss: 0.806
[92,     3] loss: 0.791
[93,     3] loss: 0.783
[94,     3] loss: 0.878
[95,     3] loss: 0.825
[96,     3] loss: 0.780
[97,     3] loss: 0.795
[98,     3] loss: 0.783
[99,     3] loss: 0.774
[100,     3] loss: 0.792
[101,     3] loss: 0.830
[102,     3] loss: 0.769
[103,     3] loss: 0.754
[104,     3] loss: 0.780
[105,     3] loss: 0.785
[106,     3] loss: 0.769
[107,     3] loss: 0.754
[108,     3] loss: 0.757
[109,     3] loss: 0.742
Early stopping applied (best metric=0.49442461133003235)
Finished Training
Total time taken: 24.262067794799805
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.386
[3,     3] loss: 1.398
[4,     3] loss: 1.385
[5,     3] loss: 1.385
[6,     3] loss: 1.387
[7,     3] loss: 1.384
[8,     3] loss: 1.383
[9,     3] loss: 1.391
[10,     3] loss: 1.386
[11,     3] loss: 1.387
[12,     3] loss: 1.384
[13,     3] loss: 1.386
[14,     3] loss: 1.387
[15,     3] loss: 1.385
[16,     3] loss: 1.385
[17,     3] loss: 1.385
[18,     3] loss: 1.385
[19,     3] loss: 1.385
[20,     3] loss: 1.388
[21,     3] loss: 1.387
[22,     3] loss: 1.384
[23,     3] loss: 1.381
[24,     3] loss: 1.382
[25,     3] loss: 1.384
[26,     3] loss: 1.377
[27,     3] loss: 1.375
[28,     3] loss: 1.371
[29,     3] loss: 1.346
[30,     3] loss: 1.323
[31,     3] loss: 1.293
[32,     3] loss: 1.189
[33,     3] loss: 1.189
[34,     3] loss: 1.239
[35,     3] loss: 1.152
[36,     3] loss: 1.218
[37,     3] loss: 1.091
[38,     3] loss: 1.118
[39,     3] loss: 1.167
[40,     3] loss: 1.041
[41,     3] loss: 1.116
[42,     3] loss: 1.256
[43,     3] loss: 1.061
[44,     3] loss: 1.151
[45,     3] loss: 1.089
[46,     3] loss: 1.084
[47,     3] loss: 1.111
[48,     3] loss: 1.093
[49,     3] loss: 1.052
[50,     3] loss: 0.952
[51,     3] loss: 0.957
[52,     3] loss: 1.008
[53,     3] loss: 0.955
[54,     3] loss: 0.898
[55,     3] loss: 0.904
[56,     3] loss: 0.922
[57,     3] loss: 0.889
[58,     3] loss: 0.913
[59,     3] loss: 0.893
[60,     3] loss: 0.856
[61,     3] loss: 0.829
[62,     3] loss: 0.852
[63,     3] loss: 0.966
[64,     3] loss: 0.795
[65,     3] loss: 0.835
[66,     3] loss: 0.855
[67,     3] loss: 0.803
[68,     3] loss: 0.834
[69,     3] loss: 0.802
[70,     3] loss: 0.799
[71,     3] loss: 0.905
[72,     3] loss: 0.814
[73,     3] loss: 0.780
[74,     3] loss: 0.853
[75,     3] loss: 0.806
[76,     3] loss: 0.807
[77,     3] loss: 0.768
[78,     3] loss: 0.834
[79,     3] loss: 0.788
[80,     3] loss: 0.788
[81,     3] loss: 0.775
[82,     3] loss: 0.784
[83,     3] loss: 0.872
[84,     3] loss: 0.948
[85,     3] loss: 0.928
[86,     3] loss: 0.854
[87,     3] loss: 0.864
[88,     3] loss: 0.900
[89,     3] loss: 0.843
[90,     3] loss: 0.866
[91,     3] loss: 0.847
Early stopping applied (best metric=0.5267038345336914)
Finished Training
Total time taken: 20.241056442260742
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.386
[3,     3] loss: 1.383
[4,     3] loss: 1.380
[5,     3] loss: 1.375
[6,     3] loss: 1.379
[7,     3] loss: 1.377
[8,     3] loss: 1.391
[9,     3] loss: 1.374
[10,     3] loss: 1.377
[11,     3] loss: 1.360
[12,     3] loss: 1.365
[13,     3] loss: 1.341
[14,     3] loss: 1.312
[15,     3] loss: 1.306
[16,     3] loss: 1.264
[17,     3] loss: 1.242
[18,     3] loss: 1.236
[19,     3] loss: 1.190
[20,     3] loss: 1.192
[21,     3] loss: 1.142
[22,     3] loss: 1.182
[23,     3] loss: 1.105
[24,     3] loss: 1.145
[25,     3] loss: 1.081
[26,     3] loss: 1.117
[27,     3] loss: 1.109
[28,     3] loss: 1.064
[29,     3] loss: 1.086
[30,     3] loss: 0.973
[31,     3] loss: 1.125
[32,     3] loss: 0.979
[33,     3] loss: 0.984
[34,     3] loss: 1.033
[35,     3] loss: 0.938
[36,     3] loss: 0.949
[37,     3] loss: 0.964
[38,     3] loss: 0.934
[39,     3] loss: 1.073
[40,     3] loss: 0.963
[41,     3] loss: 0.954
[42,     3] loss: 0.913
[43,     3] loss: 0.908
[44,     3] loss: 0.913
[45,     3] loss: 0.896
[46,     3] loss: 0.883
[47,     3] loss: 0.884
[48,     3] loss: 1.038
[49,     3] loss: 0.854
[50,     3] loss: 0.851
[51,     3] loss: 0.973
[52,     3] loss: 0.890
[53,     3] loss: 0.874
[54,     3] loss: 0.936
[55,     3] loss: 0.851
[56,     3] loss: 0.946
[57,     3] loss: 0.820
[58,     3] loss: 0.876
[59,     3] loss: 0.905
[60,     3] loss: 0.824
[61,     3] loss: 0.844
[62,     3] loss: 0.793
[63,     3] loss: 0.791
[64,     3] loss: 0.785
[65,     3] loss: 0.823
[66,     3] loss: 0.772
[67,     3] loss: 0.819
[68,     3] loss: 0.883
[69,     3] loss: 0.783
[70,     3] loss: 0.793
[71,     3] loss: 0.803
[72,     3] loss: 0.773
[73,     3] loss: 0.782
[74,     3] loss: 0.756
[75,     3] loss: 0.794
[76,     3] loss: 0.845
[77,     3] loss: 0.788
[78,     3] loss: 0.771
[79,     3] loss: 0.754
[80,     3] loss: 0.754
[81,     3] loss: 0.760
[82,     3] loss: 0.765
[83,     3] loss: 0.771
[84,     3] loss: 0.756
[85,     3] loss: 0.747
[86,     3] loss: 0.739
[87,     3] loss: 0.738
[88,     3] loss: 0.751
[89,     3] loss: 0.751
[90,     3] loss: 0.755
[91,     3] loss: 0.746
[92,     3] loss: 0.750
[93,     3] loss: 0.747
[94,     3] loss: 0.758
[95,     3] loss: 0.750
Early stopping applied (best metric=0.5176271796226501)
Finished Training
Total time taken: 21.14505696296692
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.392
[3,     3] loss: 1.394
[4,     3] loss: 1.384
[5,     3] loss: 1.383
[6,     3] loss: 1.388
[7,     3] loss: 1.388
[8,     3] loss: 1.387
[9,     3] loss: 1.381
[10,     3] loss: 1.388
[11,     3] loss: 1.387
[12,     3] loss: 1.387
[13,     3] loss: 1.387
[14,     3] loss: 1.382
[15,     3] loss: 1.384
[16,     3] loss: 1.384
[17,     3] loss: 1.386
[18,     3] loss: 1.383
[19,     3] loss: 1.376
[20,     3] loss: 1.380
[21,     3] loss: 1.374
[22,     3] loss: 1.367
[23,     3] loss: 1.357
[24,     3] loss: 1.354
[25,     3] loss: 1.359
[26,     3] loss: 1.351
[27,     3] loss: 1.294
[28,     3] loss: 1.267
[29,     3] loss: 1.222
[30,     3] loss: 1.201
[31,     3] loss: 1.222
[32,     3] loss: 1.179
[33,     3] loss: 1.203
[34,     3] loss: 1.183
[35,     3] loss: 1.168
[36,     3] loss: 1.123
[37,     3] loss: 1.075
[38,     3] loss: 1.049
[39,     3] loss: 1.109
[40,     3] loss: 0.984
[41,     3] loss: 1.063
[42,     3] loss: 0.950
[43,     3] loss: 0.998
[44,     3] loss: 0.974
[45,     3] loss: 0.943
[46,     3] loss: 0.917
[47,     3] loss: 0.898
[48,     3] loss: 0.885
[49,     3] loss: 0.893
[50,     3] loss: 0.861
[51,     3] loss: 0.946
[52,     3] loss: 0.972
[53,     3] loss: 0.937
[54,     3] loss: 0.964
[55,     3] loss: 0.914
[56,     3] loss: 0.909
[57,     3] loss: 0.947
[58,     3] loss: 0.889
[59,     3] loss: 0.936
[60,     3] loss: 0.888
[61,     3] loss: 0.987
[62,     3] loss: 0.824
[63,     3] loss: 0.834
[64,     3] loss: 0.846
[65,     3] loss: 0.830
[66,     3] loss: 0.849
[67,     3] loss: 0.819
[68,     3] loss: 0.797
[69,     3] loss: 0.784
[70,     3] loss: 0.787
[71,     3] loss: 0.793
[72,     3] loss: 0.807
[73,     3] loss: 0.822
[74,     3] loss: 0.762
[75,     3] loss: 0.806
[76,     3] loss: 0.819
[77,     3] loss: 0.775
[78,     3] loss: 0.816
[79,     3] loss: 0.794
[80,     3] loss: 0.768
[81,     3] loss: 0.793
[82,     3] loss: 0.758
[83,     3] loss: 0.754
[84,     3] loss: 0.779
[85,     3] loss: 0.769
[86,     3] loss: 0.747
[87,     3] loss: 0.741
[88,     3] loss: 0.735
Early stopping applied (best metric=0.5377195477485657)
Finished Training
Total time taken: 19.469053745269775
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.395
[3,     3] loss: 1.392
[4,     3] loss: 1.383
[5,     3] loss: 1.379
[6,     3] loss: 1.381
[7,     3] loss: 1.389
[8,     3] loss: 1.386
[9,     3] loss: 1.391
[10,     3] loss: 1.393
[11,     3] loss: 1.383
[12,     3] loss: 1.384
[13,     3] loss: 1.385
[14,     3] loss: 1.386
[15,     3] loss: 1.388
[16,     3] loss: 1.389
[17,     3] loss: 1.383
[18,     3] loss: 1.385
[19,     3] loss: 1.384
[20,     3] loss: 1.381
[21,     3] loss: 1.381
[22,     3] loss: 1.381
[23,     3] loss: 1.377
[24,     3] loss: 1.364
[25,     3] loss: 1.349
[26,     3] loss: 1.339
[27,     3] loss: 1.315
[28,     3] loss: 1.288
[29,     3] loss: 1.281
[30,     3] loss: 1.211
[31,     3] loss: 1.144
[32,     3] loss: 1.143
[33,     3] loss: 1.178
[34,     3] loss: 1.064
[35,     3] loss: 1.191
[36,     3] loss: 1.192
[37,     3] loss: 1.191
[38,     3] loss: 1.115
[39,     3] loss: 1.178
[40,     3] loss: 1.097
[41,     3] loss: 1.073
[42,     3] loss: 1.029
[43,     3] loss: 1.039
[44,     3] loss: 0.993
[45,     3] loss: 1.041
[46,     3] loss: 0.940
[47,     3] loss: 0.966
[48,     3] loss: 0.956
[49,     3] loss: 1.000
[50,     3] loss: 1.045
[51,     3] loss: 0.924
[52,     3] loss: 0.918
[53,     3] loss: 0.923
[54,     3] loss: 0.848
[55,     3] loss: 0.922
[56,     3] loss: 0.862
[57,     3] loss: 0.879
[58,     3] loss: 0.862
[59,     3] loss: 0.964
[60,     3] loss: 0.859
[61,     3] loss: 0.822
[62,     3] loss: 0.790
[63,     3] loss: 0.830
[64,     3] loss: 0.806
[65,     3] loss: 0.782
[66,     3] loss: 0.817
[67,     3] loss: 0.772
[68,     3] loss: 0.741
[69,     3] loss: 0.768
[70,     3] loss: 0.747
[71,     3] loss: 0.786
[72,     3] loss: 0.825
[73,     3] loss: 0.868
[74,     3] loss: 0.887
[75,     3] loss: 0.985
[76,     3] loss: 0.954
[77,     3] loss: 0.879
[78,     3] loss: 0.887
[79,     3] loss: 0.865
[80,     3] loss: 0.882
[81,     3] loss: 0.793
[82,     3] loss: 0.876
[83,     3] loss: 0.809
[84,     3] loss: 0.777
[85,     3] loss: 0.807
[86,     3] loss: 0.810
[87,     3] loss: 0.772
[88,     3] loss: 0.751
Early stopping applied (best metric=0.5099426507949829)
Finished Training
Total time taken: 19.664053916931152
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.383
[3,     3] loss: 1.391
[4,     3] loss: 1.373
[5,     3] loss: 1.382
[6,     3] loss: 1.375
[7,     3] loss: 1.380
[8,     3] loss: 1.354
[9,     3] loss: 1.361
[10,     3] loss: 1.360
[11,     3] loss: 1.325
[12,     3] loss: 1.372
[13,     3] loss: 1.292
[14,     3] loss: 1.272
[15,     3] loss: 1.261
[16,     3] loss: 1.303
[17,     3] loss: 1.231
[18,     3] loss: 1.153
[19,     3] loss: 1.182
[20,     3] loss: 1.122
[21,     3] loss: 1.080
[22,     3] loss: 1.124
[23,     3] loss: 1.064
[24,     3] loss: 1.079
[25,     3] loss: 1.088
[26,     3] loss: 1.017
[27,     3] loss: 1.062
[28,     3] loss: 1.036
[29,     3] loss: 0.981
[30,     3] loss: 0.964
[31,     3] loss: 1.004
[32,     3] loss: 0.970
[33,     3] loss: 1.011
[34,     3] loss: 1.017
[35,     3] loss: 0.879
[36,     3] loss: 0.938
[37,     3] loss: 0.983
[38,     3] loss: 0.957
[39,     3] loss: 0.903
[40,     3] loss: 0.926
[41,     3] loss: 0.917
[42,     3] loss: 1.001
[43,     3] loss: 1.023
[44,     3] loss: 0.861
[45,     3] loss: 0.871
[46,     3] loss: 0.877
[47,     3] loss: 0.837
[48,     3] loss: 0.886
[49,     3] loss: 0.822
[50,     3] loss: 0.833
[51,     3] loss: 0.885
[52,     3] loss: 0.844
[53,     3] loss: 0.814
[54,     3] loss: 0.815
[55,     3] loss: 0.801
[56,     3] loss: 0.789
[57,     3] loss: 0.793
[58,     3] loss: 0.769
[59,     3] loss: 0.762
[60,     3] loss: 0.770
[61,     3] loss: 0.864
[62,     3] loss: 0.810
[63,     3] loss: 0.801
[64,     3] loss: 0.863
[65,     3] loss: 0.857
[66,     3] loss: 0.818
[67,     3] loss: 0.838
[68,     3] loss: 0.829
[69,     3] loss: 0.837
[70,     3] loss: 0.821
[71,     3] loss: 0.881
[72,     3] loss: 0.811
[73,     3] loss: 0.843
[74,     3] loss: 0.927
[75,     3] loss: 0.808
[76,     3] loss: 0.849
Early stopping applied (best metric=0.5016589164733887)
Finished Training
Total time taken: 16.91704511642456
{'S-palmitoylation-C Validation Accuracy': 0.7141861954962392, 'S-palmitoylation-C Validation Sensitivity': 0.18574257425742574, 'S-palmitoylation-C Validation Specificity': 0.8466498612278156, 'S-palmitoylation-C Validation Precision': 0.23632536894042028, 'S-palmitoylation-C AUC ROC': 0.5392749639582842, 'S-palmitoylation-C AUC PR': 0.22370096782258975, 'S-palmitoylation-C MCC': 0.03595818617255399, 'S-palmitoylation-C F1': 0.1916096341136546, 'Validation Loss (S-palmitoylation-C)': 0.5550620118776958, 'Hydroxylation-K Validation Accuracy': 0.7476654846335697, 'Hydroxylation-K Validation Sensitivity': 0.7918518518518518, 'Hydroxylation-K Validation Specificity': 0.7368421052631579, 'Hydroxylation-K Validation Precision': 0.45470878441068424, 'Hydroxylation-K AUC ROC': 0.8103118908382066, 'Hydroxylation-K AUC PR': 0.5460801198724461, 'Hydroxylation-K MCC': 0.45319408257833166, 'Hydroxylation-K F1': 0.5681110270351973, 'Validation Loss (Hydroxylation-K)': 0.5116779625415802, 'Validation Loss (total)': 1.0667399883270263, 'TimeToTrain': 19.774391094843548}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006328618571355686,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.35813283066149915,
 'loss_weight_S-palmitoylation-C': 0.021702842458278804,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 507894988,
 'sample_weights': [0.5924175174534596, 0.20292076468498751],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.758962956853857,
 'weight_decay_Hydroxylation-K': 8.019520703503972,
 'weight_decay_S-palmitoylation-C': 0.6816734827885949}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.402
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0048845145078143535,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8423801762285792,
 'loss_weight_S-palmitoylation-C': 0.07795285607051802,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1651388233,
 'sample_weights': [0.021702842458278804, 0.35813283066149915],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.022382181580177,
 'weight_decay_Hydroxylation-K': 6.882422577879094,
 'weight_decay_S-palmitoylation-C': 7.5187748843596225}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.386
[3,     3] loss: 1.382
[4,     3] loss: 1.391
[5,     3] loss: 1.385
[6,     3] loss: 1.387
[7,     3] loss: 1.384
[8,     3] loss: 1.385
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00047806271359641874,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.49956939350755547,
 'loss_weight_S-palmitoylation-C': 0.19894499157511966,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3087186971,
 'sample_weights': [0.07795285607051802, 0.8423801762285792],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.519499679824402,
 'weight_decay_Hydroxylation-K': 2.2500787380161693,
 'weight_decay_S-palmitoylation-C': 1.2939229481952046}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.380
[3,     3] loss: 1.386
[4,     3] loss: 1.387
[5,     3] loss: 1.391
[6,     3] loss: 1.387
[7,     3] loss: 1.386
[8,     3] loss: 1.384
[9,     3] loss: 1.375
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002004708886690857,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5114160974283911,
 'loss_weight_S-palmitoylation-C': 0.3270781941539055,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2199881502,
 'sample_weights': [0.19894499157511966, 0.49956939350755547],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6106367846195173,
 'weight_decay_Hydroxylation-K': 3.8398143881857036,
 'weight_decay_S-palmitoylation-C': 8.106653584809877}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.379
[3,     3] loss: 1.395
[4,     3] loss: 1.384
[5,     3] loss: 1.384
[6,     3] loss: 1.387
[7,     3] loss: 1.382
[8,     3] loss: 1.389
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030005966160479985,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7033909498695577,
 'loss_weight_S-palmitoylation-C': 0.5924036550660853,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1737742694,
 'sample_weights': [0.3270781941539055, 0.5114160974283911],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.742557814124792,
 'weight_decay_Hydroxylation-K': 3.2929414443113285,
 'weight_decay_S-palmitoylation-C': 6.25629038507497}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.384
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008873936790179701,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4950548808263191,
 'loss_weight_S-palmitoylation-C': 0.3399006143552758,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 580251591,
 'sample_weights': [0.5924036550660853, 0.7033909498695577],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.43024913931043,
 'weight_decay_Hydroxylation-K': 0.8513579278917393,
 'weight_decay_S-palmitoylation-C': 3.2434418367763413}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.381
[3,     3] loss: 1.384
[4,     3] loss: 1.383
[5,     3] loss: 1.367
[6,     3] loss: 1.378
[7,     3] loss: 1.365
[8,     3] loss: 1.361
[9,     3] loss: 1.336
[10,     3] loss: 1.332
[11,     3] loss: 1.268
[12,     3] loss: 1.255
[13,     3] loss: 1.254
[14,     3] loss: 1.289
[15,     3] loss: 1.227
[16,     3] loss: 1.234
[17,     3] loss: 1.210
[18,     3] loss: 1.200
[19,     3] loss: 1.219
[20,     3] loss: 1.099
[21,     3] loss: 1.085
[22,     3] loss: 1.194
[23,     3] loss: 1.089
[24,     3] loss: 1.062
[25,     3] loss: 1.089
[26,     3] loss: 1.003
[27,     3] loss: 1.042
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003433129387275587,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6302004730943274,
 'loss_weight_S-palmitoylation-C': 0.7708277370214784,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3984658050,
 'sample_weights': [0.3399006143552758, 0.4950548808263191],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.2194743121563676,
 'weight_decay_Hydroxylation-K': 2.5645955664030153,
 'weight_decay_S-palmitoylation-C': 3.555984066358002}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.396
[3,     3] loss: 1.386
[4,     3] loss: 1.385
[5,     3] loss: 1.381
[6,     3] loss: 1.388
[7,     3] loss: 1.379
[8,     3] loss: 1.396
[9,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004538430895201356,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9088949277532045,
 'loss_weight_S-palmitoylation-C': 0.6569899183046973,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3234744278,
 'sample_weights': [0.7708277370214784, 0.6302004730943274],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7157602673440953,
 'weight_decay_Hydroxylation-K': 9.880302417272855,
 'weight_decay_S-palmitoylation-C': 3.195849551214621}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.395
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020282260814160594,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22945143810105212,
 'loss_weight_S-palmitoylation-C': 0.4567298286876755,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3397293432,
 'sample_weights': [0.6569899183046973, 0.9088949277532045],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.027423795000896,
 'weight_decay_Hydroxylation-K': 6.755635934000987,
 'weight_decay_S-palmitoylation-C': 0.19695473889879503}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.390
[3,     3] loss: 1.381
[4,     3] loss: 1.387
[5,     3] loss: 1.383
[6,     3] loss: 1.385
[7,     3] loss: 1.386
[8,     3] loss: 1.386
[9,     3] loss: 1.387
[10,     3] loss: 1.381
[11,     3] loss: 1.383
[12,     3] loss: 1.379
[13,     3] loss: 1.375
[14,     3] loss: 1.374
[15,     3] loss: 1.357
[16,     3] loss: 1.344
[17,     3] loss: 1.281
[18,     3] loss: 1.329
[19,     3] loss: 1.198
[20,     3] loss: 1.156
[21,     3] loss: 1.124
[22,     3] loss: 1.052
[23,     3] loss: 1.014
[24,     3] loss: 0.982
[25,     3] loss: 1.029
[26,     3] loss: 1.076
[27,     3] loss: 1.205
[28,     3] loss: 1.055
[29,     3] loss: 1.026
[30,     3] loss: 1.021
[31,     3] loss: 0.983
[32,     3] loss: 0.993
[33,     3] loss: 1.051
[34,     3] loss: 1.018
[35,     3] loss: 0.995
[36,     3] loss: 1.032
[37,     3] loss: 0.958
[38,     3] loss: 0.928
[39,     3] loss: 0.993
[40,     3] loss: 0.946
[41,     3] loss: 0.883
[42,     3] loss: 0.950
[43,     3] loss: 0.904
[44,     3] loss: 0.892
[45,     3] loss: 0.906
[46,     3] loss: 0.931
[47,     3] loss: 0.865
[48,     3] loss: 0.930
[49,     3] loss: 0.893
[50,     3] loss: 0.928
[51,     3] loss: 0.922
[52,     3] loss: 0.862
[53,     3] loss: 0.871
[54,     3] loss: 0.933
[55,     3] loss: 0.835
[56,     3] loss: 0.810
[57,     3] loss: 0.826
[58,     3] loss: 0.847
[59,     3] loss: 0.947
[60,     3] loss: 1.130
[61,     3] loss: 1.033
[62,     3] loss: 0.991
[63,     3] loss: 0.895
[64,     3] loss: 0.893
[65,     3] loss: 0.868
[66,     3] loss: 0.849
[67,     3] loss: 0.793
[68,     3] loss: 0.810
[69,     3] loss: 0.866
[70,     3] loss: 0.796
[71,     3] loss: 0.812
[72,     3] loss: 0.899
Early stopping applied (best metric=0.510809063911438)
Finished Training
Total time taken: 16.00104284286499
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.384
[3,     3] loss: 1.390
[4,     3] loss: 1.386
[5,     3] loss: 1.378
[6,     3] loss: 1.385
[7,     3] loss: 1.389
[8,     3] loss: 1.388
[9,     3] loss: 1.381
[10,     3] loss: 1.372
[11,     3] loss: 1.355
[12,     3] loss: 1.347
[13,     3] loss: 1.324
[14,     3] loss: 1.305
[15,     3] loss: 1.284
[16,     3] loss: 1.267
[17,     3] loss: 1.254
[18,     3] loss: 1.174
[19,     3] loss: 1.123
[20,     3] loss: 1.189
[21,     3] loss: 1.103
[22,     3] loss: 1.081
[23,     3] loss: 1.069
[24,     3] loss: 1.036
[25,     3] loss: 1.048
[26,     3] loss: 1.049
[27,     3] loss: 1.024
[28,     3] loss: 0.962
[29,     3] loss: 0.971
[30,     3] loss: 0.967
[31,     3] loss: 1.069
[32,     3] loss: 0.954
[33,     3] loss: 1.067
[34,     3] loss: 1.090
[35,     3] loss: 1.006
[36,     3] loss: 0.914
[37,     3] loss: 1.014
[38,     3] loss: 0.887
[39,     3] loss: 0.983
[40,     3] loss: 0.946
[41,     3] loss: 0.870
[42,     3] loss: 0.901
[43,     3] loss: 0.867
[44,     3] loss: 0.875
[45,     3] loss: 0.811
[46,     3] loss: 0.917
[47,     3] loss: 0.853
[48,     3] loss: 0.937
[49,     3] loss: 0.833
[50,     3] loss: 0.800
[51,     3] loss: 0.808
[52,     3] loss: 0.844
[53,     3] loss: 0.811
[54,     3] loss: 0.777
[55,     3] loss: 0.774
[56,     3] loss: 0.795
[57,     3] loss: 0.763
[58,     3] loss: 0.757
[59,     3] loss: 0.762
[60,     3] loss: 0.912
[61,     3] loss: 0.802
[62,     3] loss: 0.832
[63,     3] loss: 0.997
[64,     3] loss: 0.885
Early stopping applied (best metric=0.5302164554595947)
Finished Training
Total time taken: 14.208038568496704
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.386
[3,     3] loss: 1.389
[4,     3] loss: 1.388
[5,     3] loss: 1.382
[6,     3] loss: 1.383
[7,     3] loss: 1.375
[8,     3] loss: 1.370
[9,     3] loss: 1.362
[10,     3] loss: 1.353
[11,     3] loss: 1.337
[12,     3] loss: 1.336
[13,     3] loss: 1.234
[14,     3] loss: 1.288
[15,     3] loss: 1.251
[16,     3] loss: 1.279
[17,     3] loss: 1.284
[18,     3] loss: 1.318
[19,     3] loss: 1.261
[20,     3] loss: 1.220
[21,     3] loss: 1.257
[22,     3] loss: 1.174
[23,     3] loss: 1.189
[24,     3] loss: 1.148
[25,     3] loss: 1.132
[26,     3] loss: 1.036
[27,     3] loss: 1.103
[28,     3] loss: 1.010
[29,     3] loss: 1.005
[30,     3] loss: 1.043
[31,     3] loss: 1.005
[32,     3] loss: 1.104
[33,     3] loss: 1.098
[34,     3] loss: 1.098
[35,     3] loss: 0.989
[36,     3] loss: 0.993
[37,     3] loss: 0.941
[38,     3] loss: 1.012
[39,     3] loss: 0.954
[40,     3] loss: 0.908
[41,     3] loss: 1.051
[42,     3] loss: 0.897
[43,     3] loss: 0.943
[44,     3] loss: 1.002
[45,     3] loss: 1.045
[46,     3] loss: 0.994
[47,     3] loss: 0.904
[48,     3] loss: 0.918
[49,     3] loss: 0.995
[50,     3] loss: 0.990
[51,     3] loss: 0.875
[52,     3] loss: 0.970
[53,     3] loss: 0.893
[54,     3] loss: 0.891
[55,     3] loss: 0.879
[56,     3] loss: 0.878
[57,     3] loss: 0.997
[58,     3] loss: 1.032
[59,     3] loss: 0.973
[60,     3] loss: 0.923
[61,     3] loss: 0.936
[62,     3] loss: 0.905
[63,     3] loss: 0.874
[64,     3] loss: 0.859
[65,     3] loss: 0.815
[66,     3] loss: 0.806
[67,     3] loss: 0.822
[68,     3] loss: 0.782
[69,     3] loss: 0.831
[70,     3] loss: 0.785
[71,     3] loss: 0.807
[72,     3] loss: 0.795
[73,     3] loss: 0.762
[74,     3] loss: 0.754
[75,     3] loss: 0.760
[76,     3] loss: 0.775
[77,     3] loss: 0.763
Early stopping applied (best metric=0.5229527950286865)
Finished Training
Total time taken: 17.10199522972107
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.382
[3,     3] loss: 1.383
[4,     3] loss: 1.375
[5,     3] loss: 1.380
[6,     3] loss: 1.357
[7,     3] loss: 1.352
[8,     3] loss: 1.315
[9,     3] loss: 1.328
[10,     3] loss: 1.258
[11,     3] loss: 1.303
[12,     3] loss: 1.234
[13,     3] loss: 1.200
[14,     3] loss: 1.188
[15,     3] loss: 1.159
[16,     3] loss: 1.041
[17,     3] loss: 1.046
[18,     3] loss: 0.988
[19,     3] loss: 1.067
[20,     3] loss: 0.957
[21,     3] loss: 1.037
[22,     3] loss: 1.069
[23,     3] loss: 1.160
[24,     3] loss: 1.185
[25,     3] loss: 1.043
[26,     3] loss: 1.195
[27,     3] loss: 1.097
[28,     3] loss: 1.158
[29,     3] loss: 1.036
[30,     3] loss: 1.102
[31,     3] loss: 0.979
[32,     3] loss: 0.934
[33,     3] loss: 0.921
[34,     3] loss: 0.923
[35,     3] loss: 0.906
[36,     3] loss: 0.989
[37,     3] loss: 0.915
[38,     3] loss: 0.905
[39,     3] loss: 0.854
[40,     3] loss: 1.052
[41,     3] loss: 0.916
[42,     3] loss: 1.143
[43,     3] loss: 1.045
[44,     3] loss: 0.985
[45,     3] loss: 1.029
[46,     3] loss: 0.999
[47,     3] loss: 0.925
[48,     3] loss: 0.923
[49,     3] loss: 0.907
[50,     3] loss: 0.849
[51,     3] loss: 0.814
[52,     3] loss: 0.829
[53,     3] loss: 0.781
[54,     3] loss: 0.801
[55,     3] loss: 0.802
[56,     3] loss: 0.826
[57,     3] loss: 0.768
[58,     3] loss: 0.859
[59,     3] loss: 0.848
[60,     3] loss: 0.848
[61,     3] loss: 0.880
[62,     3] loss: 0.791
[63,     3] loss: 0.809
Early stopping applied (best metric=0.5030593872070312)
Finished Training
Total time taken: 14.095062971115112
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.392
[3,     3] loss: 1.386
[4,     3] loss: 1.386
[5,     3] loss: 1.388
[6,     3] loss: 1.388
[7,     3] loss: 1.390
[8,     3] loss: 1.384
[9,     3] loss: 1.383
[10,     3] loss: 1.381
[11,     3] loss: 1.383
[12,     3] loss: 1.384
[13,     3] loss: 1.382
[14,     3] loss: 1.374
[15,     3] loss: 1.375
[16,     3] loss: 1.361
[17,     3] loss: 1.331
[18,     3] loss: 1.316
[19,     3] loss: 1.270
[20,     3] loss: 1.232
[21,     3] loss: 1.217
[22,     3] loss: 1.138
[23,     3] loss: 1.201
[24,     3] loss: 1.052
[25,     3] loss: 1.125
[26,     3] loss: 1.097
[27,     3] loss: 1.055
[28,     3] loss: 1.172
[29,     3] loss: 1.124
[30,     3] loss: 1.005
[31,     3] loss: 1.013
[32,     3] loss: 1.016
[33,     3] loss: 1.042
[34,     3] loss: 1.006
[35,     3] loss: 1.024
[36,     3] loss: 0.944
[37,     3] loss: 1.049
[38,     3] loss: 0.942
[39,     3] loss: 0.905
[40,     3] loss: 0.967
[41,     3] loss: 0.880
[42,     3] loss: 1.055
[43,     3] loss: 0.903
[44,     3] loss: 0.938
[45,     3] loss: 0.963
[46,     3] loss: 1.072
[47,     3] loss: 0.911
[48,     3] loss: 0.949
[49,     3] loss: 0.883
[50,     3] loss: 0.922
[51,     3] loss: 0.887
[52,     3] loss: 0.866
[53,     3] loss: 0.967
[54,     3] loss: 0.913
[55,     3] loss: 1.002
[56,     3] loss: 1.055
[57,     3] loss: 0.878
[58,     3] loss: 0.862
[59,     3] loss: 0.872
[60,     3] loss: 0.869
[61,     3] loss: 0.868
[62,     3] loss: 0.850
[63,     3] loss: 0.828
[64,     3] loss: 0.875
[65,     3] loss: 0.835
[66,     3] loss: 0.934
[67,     3] loss: 0.835
[68,     3] loss: 0.855
[69,     3] loss: 0.830
[70,     3] loss: 0.900
[71,     3] loss: 0.886
[72,     3] loss: 0.817
[73,     3] loss: 0.827
[74,     3] loss: 0.836
[75,     3] loss: 0.861
[76,     3] loss: 0.892
[77,     3] loss: 0.820
[78,     3] loss: 0.901
[79,     3] loss: 0.886
[80,     3] loss: 0.867
[81,     3] loss: 0.826
[82,     3] loss: 0.843
[83,     3] loss: 0.840
[84,     3] loss: 0.865
[85,     3] loss: 0.824
[86,     3] loss: 0.833
[87,     3] loss: 0.891
[88,     3] loss: 0.836
[89,     3] loss: 0.823
[90,     3] loss: 0.788
[91,     3] loss: 0.899
[92,     3] loss: 0.773
[93,     3] loss: 0.785
[94,     3] loss: 0.804
Early stopping applied (best metric=0.5115184783935547)
Finished Training
Total time taken: 20.932060956954956
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.377
[3,     3] loss: 1.370
[4,     3] loss: 1.374
[5,     3] loss: 1.350
[6,     3] loss: 1.361
[7,     3] loss: 1.345
[8,     3] loss: 1.310
[9,     3] loss: 1.298
[10,     3] loss: 1.265
[11,     3] loss: 1.219
[12,     3] loss: 1.203
[13,     3] loss: 1.133
[14,     3] loss: 1.063
[15,     3] loss: 1.060
[16,     3] loss: 1.090
[17,     3] loss: 1.052
[18,     3] loss: 0.991
[19,     3] loss: 1.035
[20,     3] loss: 1.078
[21,     3] loss: 1.089
[22,     3] loss: 0.951
[23,     3] loss: 0.991
[24,     3] loss: 0.918
[25,     3] loss: 1.046
[26,     3] loss: 1.030
[27,     3] loss: 1.051
[28,     3] loss: 1.039
[29,     3] loss: 0.998
[30,     3] loss: 0.904
[31,     3] loss: 0.956
[32,     3] loss: 0.947
[33,     3] loss: 1.021
[34,     3] loss: 0.912
[35,     3] loss: 0.970
[36,     3] loss: 0.923
[37,     3] loss: 0.904
[38,     3] loss: 0.854
[39,     3] loss: 0.897
[40,     3] loss: 0.875
[41,     3] loss: 0.923
[42,     3] loss: 0.872
[43,     3] loss: 0.829
[44,     3] loss: 0.868
[45,     3] loss: 0.864
[46,     3] loss: 0.888
[47,     3] loss: 0.872
[48,     3] loss: 0.854
[49,     3] loss: 0.838
[50,     3] loss: 0.829
[51,     3] loss: 0.859
[52,     3] loss: 0.898
[53,     3] loss: 0.809
[54,     3] loss: 0.795
[55,     3] loss: 0.811
[56,     3] loss: 0.805
[57,     3] loss: 0.862
[58,     3] loss: 0.791
[59,     3] loss: 0.939
[60,     3] loss: 0.871
[61,     3] loss: 0.900
[62,     3] loss: 0.827
[63,     3] loss: 0.941
[64,     3] loss: 1.011
[65,     3] loss: 0.988
[66,     3] loss: 0.942
[67,     3] loss: 0.900
[68,     3] loss: 0.850
Early stopping applied (best metric=0.5480665564537048)
Finished Training
Total time taken: 15.094040870666504
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.381
[4,     3] loss: 1.395
[5,     3] loss: 1.388
[6,     3] loss: 1.383
[7,     3] loss: 1.382
[8,     3] loss: 1.380
[9,     3] loss: 1.388
[10,     3] loss: 1.379
[11,     3] loss: 1.380
[12,     3] loss: 1.380
[13,     3] loss: 1.377
[14,     3] loss: 1.369
[15,     3] loss: 1.369
[16,     3] loss: 1.353
[17,     3] loss: 1.348
[18,     3] loss: 1.313
[19,     3] loss: 1.210
[20,     3] loss: 1.215
[21,     3] loss: 1.254
[22,     3] loss: 1.125
[23,     3] loss: 1.161
[24,     3] loss: 1.099
[25,     3] loss: 1.160
[26,     3] loss: 1.165
[27,     3] loss: 1.291
[28,     3] loss: 1.214
[29,     3] loss: 1.129
[30,     3] loss: 1.127
[31,     3] loss: 1.076
[32,     3] loss: 1.105
[33,     3] loss: 1.004
[34,     3] loss: 0.962
[35,     3] loss: 1.031
[36,     3] loss: 0.987
[37,     3] loss: 1.262
[38,     3] loss: 1.018
[39,     3] loss: 1.058
[40,     3] loss: 1.080
[41,     3] loss: 1.045
[42,     3] loss: 1.056
[43,     3] loss: 1.011
[44,     3] loss: 0.974
[45,     3] loss: 0.933
[46,     3] loss: 0.937
[47,     3] loss: 0.927
[48,     3] loss: 0.924
[49,     3] loss: 0.915
[50,     3] loss: 0.921
[51,     3] loss: 1.050
[52,     3] loss: 0.891
[53,     3] loss: 0.951
[54,     3] loss: 0.889
[55,     3] loss: 0.869
[56,     3] loss: 0.882
[57,     3] loss: 0.902
[58,     3] loss: 0.828
[59,     3] loss: 0.905
[60,     3] loss: 0.845
[61,     3] loss: 0.889
[62,     3] loss: 0.835
[63,     3] loss: 0.816
[64,     3] loss: 0.837
[65,     3] loss: 0.925
[66,     3] loss: 0.853
[67,     3] loss: 0.849
[68,     3] loss: 0.877
[69,     3] loss: 0.852
[70,     3] loss: 0.812
[71,     3] loss: 0.826
[72,     3] loss: 0.803
[73,     3] loss: 0.762
[74,     3] loss: 0.762
[75,     3] loss: 0.753
[76,     3] loss: 0.790
[77,     3] loss: 0.775
[78,     3] loss: 0.795
[79,     3] loss: 0.761
[80,     3] loss: 0.781
[81,     3] loss: 0.836
[82,     3] loss: 0.994
[83,     3] loss: 1.252
[84,     3] loss: 1.250
Early stopping applied (best metric=0.5068588256835938)
Finished Training
Total time taken: 18.682049036026
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.387
[3,     3] loss: 1.388
[4,     3] loss: 1.377
[5,     3] loss: 1.379
[6,     3] loss: 1.374
[7,     3] loss: 1.363
[8,     3] loss: 1.357
[9,     3] loss: 1.328
[10,     3] loss: 1.318
[11,     3] loss: 1.287
[12,     3] loss: 1.310
[13,     3] loss: 1.265
[14,     3] loss: 1.218
[15,     3] loss: 1.200
[16,     3] loss: 1.238
[17,     3] loss: 1.178
[18,     3] loss: 1.205
[19,     3] loss: 1.199
[20,     3] loss: 1.057
[21,     3] loss: 1.186
[22,     3] loss: 1.013
[23,     3] loss: 1.073
[24,     3] loss: 1.081
[25,     3] loss: 1.211
[26,     3] loss: 1.129
[27,     3] loss: 1.151
[28,     3] loss: 1.099
[29,     3] loss: 1.050
[30,     3] loss: 1.074
[31,     3] loss: 1.007
[32,     3] loss: 0.964
[33,     3] loss: 0.947
[34,     3] loss: 0.923
[35,     3] loss: 0.947
[36,     3] loss: 0.869
[37,     3] loss: 0.899
[38,     3] loss: 0.885
[39,     3] loss: 1.000
[40,     3] loss: 0.867
[41,     3] loss: 1.037
[42,     3] loss: 0.914
[43,     3] loss: 0.878
[44,     3] loss: 0.857
[45,     3] loss: 0.867
[46,     3] loss: 0.969
[47,     3] loss: 0.877
[48,     3] loss: 0.893
[49,     3] loss: 0.871
[50,     3] loss: 0.946
[51,     3] loss: 0.883
[52,     3] loss: 0.894
[53,     3] loss: 0.979
[54,     3] loss: 0.899
[55,     3] loss: 0.862
[56,     3] loss: 0.847
[57,     3] loss: 0.833
[58,     3] loss: 0.851
[59,     3] loss: 0.831
[60,     3] loss: 0.915
[61,     3] loss: 0.909
[62,     3] loss: 0.773
[63,     3] loss: 0.844
[64,     3] loss: 0.810
[65,     3] loss: 0.779
[66,     3] loss: 0.822
Early stopping applied (best metric=0.5237980484962463)
Finished Training
Total time taken: 14.65576696395874
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.390
[3,     3] loss: 1.384
[4,     3] loss: 1.386
[5,     3] loss: 1.391
[6,     3] loss: 1.387
[7,     3] loss: 1.386
[8,     3] loss: 1.385
[9,     3] loss: 1.383
[10,     3] loss: 1.380
[11,     3] loss: 1.370
[12,     3] loss: 1.376
[13,     3] loss: 1.355
[14,     3] loss: 1.340
[15,     3] loss: 1.329
[16,     3] loss: 1.295
[17,     3] loss: 1.274
[18,     3] loss: 1.189
[19,     3] loss: 1.126
[20,     3] loss: 1.185
[21,     3] loss: 1.329
[22,     3] loss: 1.200
[23,     3] loss: 1.104
[24,     3] loss: 1.155
[25,     3] loss: 1.108
[26,     3] loss: 1.184
[27,     3] loss: 1.102
[28,     3] loss: 1.194
[29,     3] loss: 1.070
[30,     3] loss: 1.024
[31,     3] loss: 1.062
[32,     3] loss: 1.076
[33,     3] loss: 1.083
[34,     3] loss: 0.967
[35,     3] loss: 0.953
[36,     3] loss: 0.925
[37,     3] loss: 0.948
[38,     3] loss: 0.920
[39,     3] loss: 0.860
[40,     3] loss: 1.005
[41,     3] loss: 0.920
[42,     3] loss: 0.882
[43,     3] loss: 0.932
[44,     3] loss: 0.895
[45,     3] loss: 0.890
[46,     3] loss: 0.832
[47,     3] loss: 0.838
[48,     3] loss: 0.921
[49,     3] loss: 0.865
[50,     3] loss: 0.913
[51,     3] loss: 0.893
[52,     3] loss: 0.920
[53,     3] loss: 0.932
[54,     3] loss: 0.909
[55,     3] loss: 0.857
[56,     3] loss: 0.839
[57,     3] loss: 0.826
[58,     3] loss: 0.852
[59,     3] loss: 0.829
[60,     3] loss: 0.805
[61,     3] loss: 0.839
[62,     3] loss: 0.839
[63,     3] loss: 0.888
[64,     3] loss: 0.906
[65,     3] loss: 0.885
[66,     3] loss: 0.847
[67,     3] loss: 0.871
[68,     3] loss: 0.801
[69,     3] loss: 0.914
Early stopping applied (best metric=0.4860527515411377)
Finished Training
Total time taken: 15.358104944229126
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.390
[3,     3] loss: 1.380
[4,     3] loss: 1.393
[5,     3] loss: 1.375
[6,     3] loss: 1.369
[7,     3] loss: 1.361
[8,     3] loss: 1.336
[9,     3] loss: 1.337
[10,     3] loss: 1.291
[11,     3] loss: 1.267
[12,     3] loss: 1.244
[13,     3] loss: 1.215
[14,     3] loss: 1.116
[15,     3] loss: 1.109
[16,     3] loss: 1.160
[17,     3] loss: 1.183
[18,     3] loss: 1.178
[19,     3] loss: 1.095
[20,     3] loss: 1.140
[21,     3] loss: 1.233
[22,     3] loss: 1.068
[23,     3] loss: 1.074
[24,     3] loss: 1.132
[25,     3] loss: 1.046
[26,     3] loss: 0.962
[27,     3] loss: 0.943
[28,     3] loss: 0.934
[29,     3] loss: 0.902
[30,     3] loss: 1.017
[31,     3] loss: 0.939
[32,     3] loss: 0.984
[33,     3] loss: 0.937
[34,     3] loss: 0.929
[35,     3] loss: 0.886
[36,     3] loss: 1.072
[37,     3] loss: 0.949
[38,     3] loss: 1.150
[39,     3] loss: 0.860
[40,     3] loss: 0.989
[41,     3] loss: 1.029
[42,     3] loss: 0.987
[43,     3] loss: 0.955
[44,     3] loss: 0.942
[45,     3] loss: 0.874
[46,     3] loss: 0.875
[47,     3] loss: 0.988
[48,     3] loss: 0.867
[49,     3] loss: 0.931
[50,     3] loss: 0.927
[51,     3] loss: 0.847
[52,     3] loss: 0.845
[53,     3] loss: 0.812
[54,     3] loss: 0.918
[55,     3] loss: 0.834
[56,     3] loss: 0.817
[57,     3] loss: 0.819
[58,     3] loss: 0.785
[59,     3] loss: 0.816
[60,     3] loss: 0.766
[61,     3] loss: 0.754
[62,     3] loss: 0.821
[63,     3] loss: 0.773
[64,     3] loss: 0.825
[65,     3] loss: 0.926
[66,     3] loss: 0.844
[67,     3] loss: 0.816
[68,     3] loss: 0.861
[69,     3] loss: 0.819
[70,     3] loss: 0.817
[71,     3] loss: 0.915
[72,     3] loss: 0.848
[73,     3] loss: 0.806
[74,     3] loss: 0.796
[75,     3] loss: 0.812
[76,     3] loss: 0.805
[77,     3] loss: 0.798
[78,     3] loss: 0.780
[79,     3] loss: 0.769
[80,     3] loss: 0.770
[81,     3] loss: 0.768
[82,     3] loss: 0.762
[83,     3] loss: 0.749
[84,     3] loss: 0.753
[85,     3] loss: 0.748
[86,     3] loss: 0.748
[87,     3] loss: 0.766
[88,     3] loss: 0.762
[89,     3] loss: 0.760
[90,     3] loss: 0.766
[91,     3] loss: 0.757
[92,     3] loss: 0.737
[93,     3] loss: 0.838
[94,     3] loss: 1.093
[95,     3] loss: 1.098
[96,     3] loss: 1.189
[97,     3] loss: 1.111
[98,     3] loss: 1.067
[99,     3] loss: 0.973
[100,     3] loss: 0.922
[101,     3] loss: 0.972
[102,     3] loss: 1.010
[103,     3] loss: 0.885
[104,     3] loss: 0.856
[105,     3] loss: 0.849
[106,     3] loss: 0.800
[107,     3] loss: 0.809
[108,     3] loss: 0.782
[109,     3] loss: 0.780
[110,     3] loss: 0.803
[111,     3] loss: 0.756
[112,     3] loss: 0.775
[113,     3] loss: 0.766
[114,     3] loss: 0.780
[115,     3] loss: 0.808
[116,     3] loss: 0.852
[117,     3] loss: 0.841
[118,     3] loss: 0.811
[119,     3] loss: 0.783
[120,     3] loss: 0.829
[121,     3] loss: 0.826
[122,     3] loss: 0.786
Early stopping applied (best metric=0.5265894532203674)
Finished Training
Total time taken: 27.145073652267456
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.388
[3,     3] loss: 1.394
[4,     3] loss: 1.380
[5,     3] loss: 1.377
[6,     3] loss: 1.380
[7,     3] loss: 1.383
[8,     3] loss: 1.392
[9,     3] loss: 1.383
[10,     3] loss: 1.377
[11,     3] loss: 1.374
[12,     3] loss: 1.359
[13,     3] loss: 1.350
[14,     3] loss: 1.336
[15,     3] loss: 1.295
[16,     3] loss: 1.293
[17,     3] loss: 1.205
[18,     3] loss: 1.247
[19,     3] loss: 1.357
[20,     3] loss: 1.271
[21,     3] loss: 1.127
[22,     3] loss: 1.163
[23,     3] loss: 1.199
[24,     3] loss: 1.113
[25,     3] loss: 1.177
[26,     3] loss: 1.099
[27,     3] loss: 1.110
[28,     3] loss: 1.057
[29,     3] loss: 1.057
[30,     3] loss: 1.049
[31,     3] loss: 1.111
[32,     3] loss: 1.013
[33,     3] loss: 1.022
[34,     3] loss: 0.990
[35,     3] loss: 1.171
[36,     3] loss: 1.136
[37,     3] loss: 1.153
[38,     3] loss: 1.076
[39,     3] loss: 1.147
[40,     3] loss: 1.153
[41,     3] loss: 1.139
[42,     3] loss: 1.037
[43,     3] loss: 0.981
[44,     3] loss: 1.015
[45,     3] loss: 0.998
[46,     3] loss: 0.922
[47,     3] loss: 0.878
[48,     3] loss: 0.967
[49,     3] loss: 0.913
[50,     3] loss: 0.896
[51,     3] loss: 0.959
[52,     3] loss: 0.917
[53,     3] loss: 1.030
[54,     3] loss: 1.030
[55,     3] loss: 0.912
[56,     3] loss: 0.998
[57,     3] loss: 0.925
[58,     3] loss: 0.880
[59,     3] loss: 0.929
[60,     3] loss: 0.883
[61,     3] loss: 0.892
[62,     3] loss: 1.024
[63,     3] loss: 0.856
[64,     3] loss: 0.893
[65,     3] loss: 0.928
[66,     3] loss: 0.884
[67,     3] loss: 0.809
[68,     3] loss: 0.883
[69,     3] loss: 0.857
[70,     3] loss: 0.887
[71,     3] loss: 0.835
[72,     3] loss: 0.880
[73,     3] loss: 0.830
[74,     3] loss: 0.852
Early stopping applied (best metric=0.5259053707122803)
Finished Training
Total time taken: 16.444044828414917
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.388
[3,     3] loss: 1.382
[4,     3] loss: 1.385
[5,     3] loss: 1.380
[6,     3] loss: 1.387
[7,     3] loss: 1.389
[8,     3] loss: 1.376
[9,     3] loss: 1.372
[10,     3] loss: 1.351
[11,     3] loss: 1.343
[12,     3] loss: 1.322
[13,     3] loss: 1.269
[14,     3] loss: 1.258
[15,     3] loss: 1.275
[16,     3] loss: 1.185
[17,     3] loss: 1.190
[18,     3] loss: 1.157
[19,     3] loss: 1.105
[20,     3] loss: 1.064
[21,     3] loss: 1.017
[22,     3] loss: 1.040
[23,     3] loss: 1.065
[24,     3] loss: 0.978
[25,     3] loss: 0.974
[26,     3] loss: 0.922
[27,     3] loss: 0.972
[28,     3] loss: 0.943
[29,     3] loss: 0.906
[30,     3] loss: 0.954
[31,     3] loss: 0.878
[32,     3] loss: 0.964
[33,     3] loss: 0.955
[34,     3] loss: 0.928
[35,     3] loss: 0.928
[36,     3] loss: 1.001
[37,     3] loss: 0.967
[38,     3] loss: 0.998
[39,     3] loss: 0.942
[40,     3] loss: 0.893
[41,     3] loss: 0.913
[42,     3] loss: 0.936
[43,     3] loss: 0.854
[44,     3] loss: 0.860
[45,     3] loss: 0.864
[46,     3] loss: 0.848
[47,     3] loss: 0.855
[48,     3] loss: 0.843
[49,     3] loss: 0.881
[50,     3] loss: 0.853
[51,     3] loss: 0.927
[52,     3] loss: 0.891
[53,     3] loss: 0.896
[54,     3] loss: 0.850
[55,     3] loss: 0.876
[56,     3] loss: 0.850
[57,     3] loss: 0.889
[58,     3] loss: 0.779
[59,     3] loss: 0.805
[60,     3] loss: 0.793
[61,     3] loss: 0.841
[62,     3] loss: 0.800
[63,     3] loss: 0.806
[64,     3] loss: 0.787
[65,     3] loss: 0.792
[66,     3] loss: 0.815
[67,     3] loss: 0.781
[68,     3] loss: 0.780
[69,     3] loss: 0.769
[70,     3] loss: 0.962
[71,     3] loss: 0.884
[72,     3] loss: 0.964
[73,     3] loss: 0.885
[74,     3] loss: 0.970
[75,     3] loss: 0.919
[76,     3] loss: 0.882
[77,     3] loss: 0.841
[78,     3] loss: 0.811
[79,     3] loss: 0.877
[80,     3] loss: 0.909
[81,     3] loss: 0.900
[82,     3] loss: 0.838
[83,     3] loss: 0.838
[84,     3] loss: 0.793
[85,     3] loss: 0.775
[86,     3] loss: 0.782
[87,     3] loss: 0.784
[88,     3] loss: 0.759
[89,     3] loss: 0.852
[90,     3] loss: 0.833
[91,     3] loss: 0.797
[92,     3] loss: 0.843
[93,     3] loss: 0.809
[94,     3] loss: 0.889
Early stopping applied (best metric=0.5181636214256287)
Finished Training
Total time taken: 20.806057453155518
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.391
[3,     3] loss: 1.388
[4,     3] loss: 1.383
[5,     3] loss: 1.386
[6,     3] loss: 1.366
[7,     3] loss: 1.346
[8,     3] loss: 1.342
[9,     3] loss: 1.286
[10,     3] loss: 1.265
[11,     3] loss: 1.285
[12,     3] loss: 1.248
[13,     3] loss: 1.180
[14,     3] loss: 1.103
[15,     3] loss: 1.106
[16,     3] loss: 1.127
[17,     3] loss: 1.141
[18,     3] loss: 1.138
[19,     3] loss: 1.115
[20,     3] loss: 1.072
[21,     3] loss: 1.043
[22,     3] loss: 1.131
[23,     3] loss: 0.992
[24,     3] loss: 1.044
[25,     3] loss: 1.095
[26,     3] loss: 1.148
[27,     3] loss: 1.073
[28,     3] loss: 1.010
[29,     3] loss: 1.134
[30,     3] loss: 1.033
[31,     3] loss: 1.108
[32,     3] loss: 1.140
[33,     3] loss: 1.044
[34,     3] loss: 0.975
[35,     3] loss: 0.951
[36,     3] loss: 0.972
[37,     3] loss: 0.964
[38,     3] loss: 0.888
[39,     3] loss: 0.908
[40,     3] loss: 0.888
[41,     3] loss: 0.885
[42,     3] loss: 0.848
[43,     3] loss: 0.840
[44,     3] loss: 0.814
[45,     3] loss: 0.831
[46,     3] loss: 0.825
[47,     3] loss: 0.812
[48,     3] loss: 0.818
[49,     3] loss: 0.816
[50,     3] loss: 0.860
[51,     3] loss: 0.849
[52,     3] loss: 0.798
[53,     3] loss: 0.848
[54,     3] loss: 0.991
[55,     3] loss: 0.898
[56,     3] loss: 0.905
[57,     3] loss: 0.869
[58,     3] loss: 0.854
[59,     3] loss: 0.885
[60,     3] loss: 0.833
[61,     3] loss: 0.816
[62,     3] loss: 0.786
[63,     3] loss: 0.883
[64,     3] loss: 0.773
[65,     3] loss: 0.905
[66,     3] loss: 0.789
[67,     3] loss: 0.778
[68,     3] loss: 0.770
[69,     3] loss: 0.780
[70,     3] loss: 0.760
[71,     3] loss: 0.830
[72,     3] loss: 0.778
[73,     3] loss: 0.797
[74,     3] loss: 0.796
[75,     3] loss: 0.815
[76,     3] loss: 0.873
[77,     3] loss: 0.876
[78,     3] loss: 0.788
[79,     3] loss: 0.798
[80,     3] loss: 0.852
[81,     3] loss: 0.828
[82,     3] loss: 0.928
[83,     3] loss: 0.888
[84,     3] loss: 0.893
[85,     3] loss: 0.821
[86,     3] loss: 0.896
[87,     3] loss: 0.787
[88,     3] loss: 0.812
[89,     3] loss: 0.814
[90,     3] loss: 0.791
[91,     3] loss: 0.756
[92,     3] loss: 0.794
[93,     3] loss: 0.831
[94,     3] loss: 0.791
[95,     3] loss: 0.780
[96,     3] loss: 0.772
[97,     3] loss: 0.817
[98,     3] loss: 0.871
[99,     3] loss: 0.840
Early stopping applied (best metric=0.5263584852218628)
Finished Training
Total time taken: 21.927061796188354
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.391
[3,     3] loss: 1.385
[4,     3] loss: 1.383
[5,     3] loss: 1.381
[6,     3] loss: 1.385
[7,     3] loss: 1.382
[8,     3] loss: 1.388
[9,     3] loss: 1.376
[10,     3] loss: 1.380
[11,     3] loss: 1.369
[12,     3] loss: 1.350
[13,     3] loss: 1.339
[14,     3] loss: 1.327
[15,     3] loss: 1.273
[16,     3] loss: 1.271
[17,     3] loss: 1.244
[18,     3] loss: 1.231
[19,     3] loss: 1.185
[20,     3] loss: 1.249
[21,     3] loss: 1.185
[22,     3] loss: 1.197
[23,     3] loss: 1.138
[24,     3] loss: 1.223
[25,     3] loss: 1.135
[26,     3] loss: 1.120
[27,     3] loss: 1.030
[28,     3] loss: 1.100
[29,     3] loss: 0.983
[30,     3] loss: 0.963
[31,     3] loss: 1.031
[32,     3] loss: 0.970
[33,     3] loss: 1.026
[34,     3] loss: 1.006
[35,     3] loss: 1.145
[36,     3] loss: 1.196
[37,     3] loss: 1.048
[38,     3] loss: 1.087
[39,     3] loss: 1.004
[40,     3] loss: 1.025
[41,     3] loss: 0.969
[42,     3] loss: 0.972
[43,     3] loss: 0.997
[44,     3] loss: 0.976
[45,     3] loss: 1.000
[46,     3] loss: 0.991
[47,     3] loss: 0.933
[48,     3] loss: 0.902
[49,     3] loss: 0.890
[50,     3] loss: 0.849
[51,     3] loss: 0.925
[52,     3] loss: 0.796
[53,     3] loss: 0.883
[54,     3] loss: 0.894
[55,     3] loss: 0.851
[56,     3] loss: 0.863
[57,     3] loss: 1.094
[58,     3] loss: 0.858
[59,     3] loss: 0.913
[60,     3] loss: 0.931
[61,     3] loss: 0.927
[62,     3] loss: 0.951
[63,     3] loss: 0.882
[64,     3] loss: 0.851
[65,     3] loss: 0.896
[66,     3] loss: 0.873
[67,     3] loss: 0.842
[68,     3] loss: 0.819
[69,     3] loss: 0.785
[70,     3] loss: 0.939
[71,     3] loss: 0.796
[72,     3] loss: 0.780
[73,     3] loss: 0.775
[74,     3] loss: 0.788
[75,     3] loss: 0.790
[76,     3] loss: 0.813
[77,     3] loss: 0.896
[78,     3] loss: 0.819
[79,     3] loss: 0.873
[80,     3] loss: 0.836
[81,     3] loss: 0.775
Early stopping applied (best metric=0.4991530776023865)
Finished Training
Total time taken: 18.039842128753662
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.386
[4,     3] loss: 1.389
[5,     3] loss: 1.390
[6,     3] loss: 1.380
[7,     3] loss: 1.387
[8,     3] loss: 1.379
[9,     3] loss: 1.370
[10,     3] loss: 1.369
[11,     3] loss: 1.354
[12,     3] loss: 1.351
[13,     3] loss: 1.334
[14,     3] loss: 1.285
[15,     3] loss: 1.258
[16,     3] loss: 1.248
[17,     3] loss: 1.161
[18,     3] loss: 1.212
[19,     3] loss: 1.176
[20,     3] loss: 1.126
[21,     3] loss: 1.093
[22,     3] loss: 1.230
[23,     3] loss: 1.134
[24,     3] loss: 1.129
[25,     3] loss: 1.164
[26,     3] loss: 1.116
[27,     3] loss: 1.137
[28,     3] loss: 1.149
[29,     3] loss: 1.082
[30,     3] loss: 1.038
[31,     3] loss: 1.054
[32,     3] loss: 1.039
[33,     3] loss: 0.993
[34,     3] loss: 0.986
[35,     3] loss: 1.066
[36,     3] loss: 1.161
[37,     3] loss: 0.944
[38,     3] loss: 1.039
[39,     3] loss: 1.265
[40,     3] loss: 1.051
[41,     3] loss: 1.064
[42,     3] loss: 1.053
[43,     3] loss: 0.955
[44,     3] loss: 1.032
[45,     3] loss: 0.999
[46,     3] loss: 0.991
[47,     3] loss: 1.170
[48,     3] loss: 1.049
[49,     3] loss: 1.031
[50,     3] loss: 0.955
[51,     3] loss: 1.012
[52,     3] loss: 0.980
[53,     3] loss: 0.931
[54,     3] loss: 0.876
[55,     3] loss: 0.957
[56,     3] loss: 0.862
[57,     3] loss: 0.865
[58,     3] loss: 0.933
[59,     3] loss: 0.827
[60,     3] loss: 0.834
[61,     3] loss: 0.790
[62,     3] loss: 0.932
[63,     3] loss: 0.793
[64,     3] loss: 0.793
[65,     3] loss: 0.771
Early stopping applied (best metric=0.4950040280818939)
Finished Training
Total time taken: 14.430039405822754
{'S-palmitoylation-C Validation Accuracy': 0.7043461859182383, 'S-palmitoylation-C Validation Sensitivity': 0.20884488448844885, 'S-palmitoylation-C Validation Specificity': 0.8285552333007246, 'S-palmitoylation-C Validation Precision': 0.23961202069127527, 'S-palmitoylation-C AUC ROC': 0.5484839932883316, 'S-palmitoylation-C AUC PR': 0.22878969354999731, 'S-palmitoylation-C MCC': 0.04052224760127111, 'S-palmitoylation-C F1': 0.20568699574898675, 'Validation Loss (S-palmitoylation-C)': 0.555226997534434, 'Hydroxylation-K Validation Accuracy': 0.6960992907801419, 'Hydroxylation-K Validation Sensitivity': 0.7851851851851852, 'Hydroxylation-K Validation Specificity': 0.6736842105263158, 'Hydroxylation-K Validation Precision': 0.3840172921906668, 'Hydroxylation-K AUC ROC': 0.8100389863547759, 'Hydroxylation-K AUC PR': 0.5228814815126018, 'Hydroxylation-K MCC': 0.3763732611846094, 'Hydroxylation-K F1': 0.5136557764156513, 'Validation Loss (Hydroxylation-K)': 0.5156337598959605, 'Validation Loss (total)': 1.07086075146993, 'TimeToTrain': 17.661352109909057}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028981639525239456,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9550220280994031,
 'loss_weight_S-palmitoylation-C': 0.029465316364894946,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4114252444,
 'sample_weights': [0.4567298286876755, 0.22945143810105212],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.7609526326423195,
 'weight_decay_Hydroxylation-K': 2.9352046453921643,
 'weight_decay_S-palmitoylation-C': 6.296261364185315}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.392
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037861393992661184,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24726894364735247,
 'loss_weight_S-palmitoylation-C': 0.9727378053632997,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2284809398,
 'sample_weights': [0.029465316364894946, 0.9550220280994031],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.5480537000067094,
 'weight_decay_Hydroxylation-K': 0.26758911720239453,
 'weight_decay_S-palmitoylation-C': 0.02167157018464072}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.390
[3,     3] loss: 1.383
[4,     3] loss: 1.391
[5,     3] loss: 1.381
[6,     3] loss: 1.385
[7,     3] loss: 1.394
[8,     3] loss: 1.378
[9,     3] loss: 1.369
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0021230723857508364,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.40970988057119345,
 'loss_weight_S-palmitoylation-C': 0.9996947020255517,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2136596513,
 'sample_weights': [0.9727378053632997, 0.24726894364735247],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.768173116839858,
 'weight_decay_Hydroxylation-K': 1.7385176341691901,
 'weight_decay_S-palmitoylation-C': 0.6055813486354065}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.384
[3,     3] loss: 1.392
[4,     3] loss: 1.386
[5,     3] loss: 1.388
[6,     3] loss: 1.390
[7,     3] loss: 1.384
[8,     3] loss: 1.381
[9,     3] loss: 1.365
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013195491581053562,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1842139690157791,
 'loss_weight_S-palmitoylation-C': 0.3208698438258102,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2089028469,
 'sample_weights': [0.9996947020255517, 0.40970988057119345],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.498859583076902,
 'weight_decay_Hydroxylation-K': 1.4526970896376734,
 'weight_decay_S-palmitoylation-C': 5.769330940940126}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.387
[3,     3] loss: 1.378
[4,     3] loss: 1.368
[5,     3] loss: 1.382
[6,     3] loss: 1.367
[7,     3] loss: 1.361
[8,     3] loss: 1.319
[9,     3] loss: 1.311
[10,     3] loss: 1.289
[11,     3] loss: 1.248
[12,     3] loss: 1.209
[13,     3] loss: 1.165
[14,     3] loss: 1.111
[15,     3] loss: 1.174
[16,     3] loss: 1.081
[17,     3] loss: 1.050
[18,     3] loss: 1.080
[19,     3] loss: 1.069
[20,     3] loss: 1.035
[21,     3] loss: 1.049
[22,     3] loss: 1.095
[23,     3] loss: 1.076
[24,     3] loss: 0.973
[25,     3] loss: 0.996
[26,     3] loss: 1.023
[27,     3] loss: 1.176
[28,     3] loss: 1.109
[29,     3] loss: 1.142
[30,     3] loss: 1.160
[31,     3] loss: 1.043
[32,     3] loss: 1.158
[33,     3] loss: 1.033
[34,     3] loss: 1.044
[35,     3] loss: 0.991
[36,     3] loss: 1.019
[37,     3] loss: 0.933
[38,     3] loss: 1.006
[39,     3] loss: 0.911
[40,     3] loss: 0.916
[41,     3] loss: 0.864
[42,     3] loss: 0.817
[43,     3] loss: 0.896
[44,     3] loss: 0.884
[45,     3] loss: 0.806
[46,     3] loss: 0.846
[47,     3] loss: 0.937
[48,     3] loss: 0.838
[49,     3] loss: 0.912
[50,     3] loss: 0.899
[51,     3] loss: 0.875
[52,     3] loss: 0.851
[53,     3] loss: 0.804
[54,     3] loss: 0.871
[55,     3] loss: 0.884
[56,     3] loss: 0.838
[57,     3] loss: 0.811
[58,     3] loss: 0.826
[59,     3] loss: 0.809
[60,     3] loss: 0.892
[61,     3] loss: 0.866
[62,     3] loss: 0.814
[63,     3] loss: 0.819
[64,     3] loss: 0.796
[65,     3] loss: 0.813
[66,     3] loss: 0.795
[67,     3] loss: 0.792
[68,     3] loss: 0.807
[69,     3] loss: 0.802
Early stopping applied (best metric=0.5093334317207336)
Finished Training
Total time taken: 15.301041603088379
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.387
[4,     3] loss: 1.388
[5,     3] loss: 1.390
[6,     3] loss: 1.385
[7,     3] loss: 1.381
[8,     3] loss: 1.383
[9,     3] loss: 1.388
[10,     3] loss: 1.370
[11,     3] loss: 1.366
[12,     3] loss: 1.341
[13,     3] loss: 1.336
[14,     3] loss: 1.277
[15,     3] loss: 1.288
[16,     3] loss: 1.205
[17,     3] loss: 1.210
[18,     3] loss: 1.212
[19,     3] loss: 1.135
[20,     3] loss: 1.275
[21,     3] loss: 1.037
[22,     3] loss: 1.152
[23,     3] loss: 1.067
[24,     3] loss: 1.090
[25,     3] loss: 1.056
[26,     3] loss: 1.206
[27,     3] loss: 1.181
[28,     3] loss: 1.067
[29,     3] loss: 1.070
[30,     3] loss: 1.131
[31,     3] loss: 1.015
[32,     3] loss: 1.083
[33,     3] loss: 0.999
[34,     3] loss: 0.982
[35,     3] loss: 0.947
[36,     3] loss: 0.941
[37,     3] loss: 0.954
[38,     3] loss: 0.990
[39,     3] loss: 0.902
[40,     3] loss: 0.895
[41,     3] loss: 0.883
[42,     3] loss: 0.900
[43,     3] loss: 1.003
[44,     3] loss: 1.069
[45,     3] loss: 1.009
[46,     3] loss: 1.009
[47,     3] loss: 0.998
[48,     3] loss: 0.979
[49,     3] loss: 0.907
[50,     3] loss: 0.897
[51,     3] loss: 0.847
[52,     3] loss: 0.877
[53,     3] loss: 0.834
[54,     3] loss: 0.913
[55,     3] loss: 0.883
[56,     3] loss: 0.872
[57,     3] loss: 0.840
[58,     3] loss: 0.816
[59,     3] loss: 0.875
[60,     3] loss: 0.799
[61,     3] loss: 0.865
[62,     3] loss: 0.824
[63,     3] loss: 0.811
[64,     3] loss: 0.796
[65,     3] loss: 0.798
[66,     3] loss: 0.799
[67,     3] loss: 0.857
[68,     3] loss: 0.803
[69,     3] loss: 0.801
[70,     3] loss: 0.778
[71,     3] loss: 0.809
[72,     3] loss: 0.852
[73,     3] loss: 0.958
[74,     3] loss: 0.912
[75,     3] loss: 1.010
[76,     3] loss: 0.929
[77,     3] loss: 0.883
[78,     3] loss: 0.829
[79,     3] loss: 0.807
[80,     3] loss: 0.752
[81,     3] loss: 0.817
[82,     3] loss: 0.799
[83,     3] loss: 0.776
[84,     3] loss: 0.779
[85,     3] loss: 0.797
[86,     3] loss: 0.795
[87,     3] loss: 0.825
[88,     3] loss: 0.845
Early stopping applied (best metric=0.5152239799499512)
Finished Training
Total time taken: 19.518053770065308
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.387
[3,     3] loss: 1.385
[4,     3] loss: 1.385
[5,     3] loss: 1.376
[6,     3] loss: 1.380
[7,     3] loss: 1.375
[8,     3] loss: 1.384
[9,     3] loss: 1.375
[10,     3] loss: 1.395
[11,     3] loss: 1.382
[12,     3] loss: 1.365
[13,     3] loss: 1.331
[14,     3] loss: 1.312
[15,     3] loss: 1.274
[16,     3] loss: 1.246
[17,     3] loss: 1.257
[18,     3] loss: 1.212
[19,     3] loss: 1.183
[20,     3] loss: 1.087
[21,     3] loss: 1.136
[22,     3] loss: 1.119
[23,     3] loss: 1.108
[24,     3] loss: 1.059
[25,     3] loss: 1.188
[26,     3] loss: 1.021
[27,     3] loss: 1.007
[28,     3] loss: 0.977
[29,     3] loss: 0.961
[30,     3] loss: 0.977
[31,     3] loss: 1.038
[32,     3] loss: 0.934
[33,     3] loss: 0.986
[34,     3] loss: 0.969
[35,     3] loss: 0.968
[36,     3] loss: 1.037
[37,     3] loss: 1.065
[38,     3] loss: 0.960
[39,     3] loss: 0.907
[40,     3] loss: 0.939
[41,     3] loss: 0.881
[42,     3] loss: 0.814
[43,     3] loss: 0.820
[44,     3] loss: 0.773
[45,     3] loss: 0.863
[46,     3] loss: 0.960
[47,     3] loss: 0.870
[48,     3] loss: 0.825
[49,     3] loss: 0.912
[50,     3] loss: 0.947
[51,     3] loss: 0.895
[52,     3] loss: 0.844
[53,     3] loss: 0.913
[54,     3] loss: 0.923
[55,     3] loss: 0.852
[56,     3] loss: 0.814
[57,     3] loss: 0.791
[58,     3] loss: 0.776
[59,     3] loss: 0.759
[60,     3] loss: 0.788
[61,     3] loss: 0.745
[62,     3] loss: 0.832
[63,     3] loss: 0.810
[64,     3] loss: 0.762
[65,     3] loss: 0.805
[66,     3] loss: 0.764
[67,     3] loss: 0.786
[68,     3] loss: 0.793
[69,     3] loss: 0.749
[70,     3] loss: 0.777
[71,     3] loss: 0.813
[72,     3] loss: 0.749
[73,     3] loss: 0.784
[74,     3] loss: 0.769
[75,     3] loss: 0.838
[76,     3] loss: 0.966
[77,     3] loss: 0.921
[78,     3] loss: 0.955
[79,     3] loss: 0.946
[80,     3] loss: 0.856
Early stopping applied (best metric=0.5209164619445801)
Finished Training
Total time taken: 17.9060480594635
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.388
[3,     3] loss: 1.385
[4,     3] loss: 1.388
[5,     3] loss: 1.387
[6,     3] loss: 1.384
[7,     3] loss: 1.381
[8,     3] loss: 1.380
[9,     3] loss: 1.375
[10,     3] loss: 1.360
[11,     3] loss: 1.348
[12,     3] loss: 1.320
[13,     3] loss: 1.262
[14,     3] loss: 1.197
[15,     3] loss: 1.173
[16,     3] loss: 1.212
[17,     3] loss: 1.120
[18,     3] loss: 1.097
[19,     3] loss: 1.138
[20,     3] loss: 1.225
[21,     3] loss: 1.031
[22,     3] loss: 0.977
[23,     3] loss: 0.977
[24,     3] loss: 1.035
[25,     3] loss: 0.941
[26,     3] loss: 0.909
[27,     3] loss: 1.017
[28,     3] loss: 0.951
[29,     3] loss: 0.984
[30,     3] loss: 0.952
[31,     3] loss: 0.931
[32,     3] loss: 0.919
[33,     3] loss: 0.924
[34,     3] loss: 1.024
[35,     3] loss: 0.916
[36,     3] loss: 0.930
[37,     3] loss: 0.903
[38,     3] loss: 0.967
[39,     3] loss: 0.927
[40,     3] loss: 0.846
[41,     3] loss: 0.937
[42,     3] loss: 0.967
[43,     3] loss: 0.850
[44,     3] loss: 0.930
[45,     3] loss: 0.874
[46,     3] loss: 0.853
[47,     3] loss: 0.994
[48,     3] loss: 0.793
[49,     3] loss: 0.807
[50,     3] loss: 0.814
[51,     3] loss: 0.833
[52,     3] loss: 0.823
[53,     3] loss: 0.840
[54,     3] loss: 0.820
[55,     3] loss: 0.878
[56,     3] loss: 0.816
[57,     3] loss: 0.773
[58,     3] loss: 0.785
[59,     3] loss: 0.794
[60,     3] loss: 0.827
[61,     3] loss: 0.819
[62,     3] loss: 0.762
[63,     3] loss: 0.816
[64,     3] loss: 0.798
[65,     3] loss: 0.739
[66,     3] loss: 0.772
[67,     3] loss: 0.809
[68,     3] loss: 0.782
[69,     3] loss: 1.003
[70,     3] loss: 0.841
Early stopping applied (best metric=0.5232955813407898)
Finished Training
Total time taken: 15.559340953826904
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.388
[3,     3] loss: 1.384
[4,     3] loss: 1.379
[5,     3] loss: 1.377
[6,     3] loss: 1.376
[7,     3] loss: 1.359
[8,     3] loss: 1.342
[9,     3] loss: 1.291
[10,     3] loss: 1.286
[11,     3] loss: 1.250
[12,     3] loss: 1.132
[13,     3] loss: 1.102
[14,     3] loss: 1.137
[15,     3] loss: 1.157
[16,     3] loss: 1.148
[17,     3] loss: 1.119
[18,     3] loss: 1.026
[19,     3] loss: 1.014
[20,     3] loss: 1.025
[21,     3] loss: 0.998
[22,     3] loss: 1.032
[23,     3] loss: 0.912
[24,     3] loss: 1.034
[25,     3] loss: 0.946
[26,     3] loss: 1.000
[27,     3] loss: 0.975
[28,     3] loss: 0.937
[29,     3] loss: 1.045
[30,     3] loss: 0.978
[31,     3] loss: 0.928
[32,     3] loss: 0.915
[33,     3] loss: 0.934
[34,     3] loss: 0.931
[35,     3] loss: 0.820
[36,     3] loss: 0.938
[37,     3] loss: 0.947
[38,     3] loss: 0.886
[39,     3] loss: 0.855
[40,     3] loss: 0.899
[41,     3] loss: 1.000
[42,     3] loss: 0.919
[43,     3] loss: 0.898
[44,     3] loss: 0.852
[45,     3] loss: 0.837
[46,     3] loss: 0.845
[47,     3] loss: 0.850
[48,     3] loss: 0.801
[49,     3] loss: 0.780
[50,     3] loss: 1.052
[51,     3] loss: 0.932
[52,     3] loss: 0.975
[53,     3] loss: 0.945
[54,     3] loss: 0.916
[55,     3] loss: 0.883
[56,     3] loss: 1.044
[57,     3] loss: 0.863
[58,     3] loss: 0.842
[59,     3] loss: 0.923
[60,     3] loss: 0.928
[61,     3] loss: 1.025
[62,     3] loss: 0.856
[63,     3] loss: 0.915
[64,     3] loss: 0.866
[65,     3] loss: 0.855
[66,     3] loss: 0.782
[67,     3] loss: 0.751
[68,     3] loss: 0.824
[69,     3] loss: 0.870
[70,     3] loss: 0.798
[71,     3] loss: 0.840
[72,     3] loss: 0.892
[73,     3] loss: 0.854
[74,     3] loss: 0.869
[75,     3] loss: 0.810
[76,     3] loss: 0.794
[77,     3] loss: 0.799
[78,     3] loss: 0.801
[79,     3] loss: 0.798
[80,     3] loss: 0.835
[81,     3] loss: 0.862
[82,     3] loss: 0.844
[83,     3] loss: 0.785
[84,     3] loss: 0.865
[85,     3] loss: 0.769
[86,     3] loss: 0.772
[87,     3] loss: 0.794
[88,     3] loss: 0.841
[89,     3] loss: 0.778
[90,     3] loss: 0.779
[91,     3] loss: 0.758
[92,     3] loss: 0.774
[93,     3] loss: 0.744
[94,     3] loss: 0.746
[95,     3] loss: 0.726
[96,     3] loss: 0.748
[97,     3] loss: 0.766
[98,     3] loss: 0.764
Early stopping applied (best metric=0.5227735638618469)
Finished Training
Total time taken: 21.72598171234131
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.383
[3,     3] loss: 1.383
[4,     3] loss: 1.383
[5,     3] loss: 1.382
[6,     3] loss: 1.380
[7,     3] loss: 1.379
[8,     3] loss: 1.377
[9,     3] loss: 1.356
[10,     3] loss: 1.331
[11,     3] loss: 1.313
[12,     3] loss: 1.283
[13,     3] loss: 1.207
[14,     3] loss: 1.272
[15,     3] loss: 1.204
[16,     3] loss: 1.183
[17,     3] loss: 1.212
[18,     3] loss: 1.151
[19,     3] loss: 1.140
[20,     3] loss: 1.196
[21,     3] loss: 1.114
[22,     3] loss: 1.064
[23,     3] loss: 1.160
[24,     3] loss: 1.064
[25,     3] loss: 1.001
[26,     3] loss: 1.016
[27,     3] loss: 0.969
[28,     3] loss: 0.947
[29,     3] loss: 1.043
[30,     3] loss: 0.924
[31,     3] loss: 0.925
[32,     3] loss: 0.910
[33,     3] loss: 0.932
[34,     3] loss: 0.899
[35,     3] loss: 0.983
[36,     3] loss: 0.893
[37,     3] loss: 0.946
[38,     3] loss: 0.964
[39,     3] loss: 0.876
[40,     3] loss: 1.048
[41,     3] loss: 0.879
[42,     3] loss: 0.887
[43,     3] loss: 0.874
[44,     3] loss: 0.924
[45,     3] loss: 0.921
[46,     3] loss: 0.907
[47,     3] loss: 0.931
[48,     3] loss: 0.845
[49,     3] loss: 0.836
[50,     3] loss: 0.820
[51,     3] loss: 0.837
[52,     3] loss: 0.788
[53,     3] loss: 0.792
[54,     3] loss: 0.837
[55,     3] loss: 0.822
[56,     3] loss: 0.863
[57,     3] loss: 0.828
[58,     3] loss: 0.873
[59,     3] loss: 0.842
[60,     3] loss: 0.873
[61,     3] loss: 0.900
[62,     3] loss: 0.924
[63,     3] loss: 0.909
[64,     3] loss: 0.878
[65,     3] loss: 0.955
[66,     3] loss: 0.883
[67,     3] loss: 0.860
[68,     3] loss: 0.838
[69,     3] loss: 0.794
[70,     3] loss: 0.778
[71,     3] loss: 0.794
[72,     3] loss: 0.761
[73,     3] loss: 0.739
[74,     3] loss: 0.752
[75,     3] loss: 0.740
Early stopping applied (best metric=0.5260632038116455)
Finished Training
Total time taken: 16.77606463432312
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.380
[3,     3] loss: 1.378
[4,     3] loss: 1.377
[5,     3] loss: 1.357
[6,     3] loss: 1.317
[7,     3] loss: 1.346
[8,     3] loss: 1.274
[9,     3] loss: 1.242
[10,     3] loss: 1.248
[11,     3] loss: 1.219
[12,     3] loss: 1.164
[13,     3] loss: 1.097
[14,     3] loss: 1.104
[15,     3] loss: 1.091
[16,     3] loss: 1.137
[17,     3] loss: 1.081
[18,     3] loss: 1.048
[19,     3] loss: 1.040
[20,     3] loss: 0.957
[21,     3] loss: 1.081
[22,     3] loss: 1.027
[23,     3] loss: 1.003
[24,     3] loss: 0.980
[25,     3] loss: 0.873
[26,     3] loss: 1.028
[27,     3] loss: 1.051
[28,     3] loss: 1.099
[29,     3] loss: 1.063
[30,     3] loss: 0.985
[31,     3] loss: 0.965
[32,     3] loss: 0.975
[33,     3] loss: 0.983
[34,     3] loss: 0.861
[35,     3] loss: 0.845
[36,     3] loss: 0.870
[37,     3] loss: 0.850
[38,     3] loss: 0.927
[39,     3] loss: 0.822
[40,     3] loss: 0.814
[41,     3] loss: 0.865
[42,     3] loss: 0.936
[43,     3] loss: 0.867
[44,     3] loss: 0.845
[45,     3] loss: 0.921
[46,     3] loss: 0.852
[47,     3] loss: 0.851
[48,     3] loss: 0.926
[49,     3] loss: 0.860
[50,     3] loss: 0.896
[51,     3] loss: 0.838
[52,     3] loss: 0.814
[53,     3] loss: 0.837
[54,     3] loss: 0.790
[55,     3] loss: 0.837
[56,     3] loss: 0.837
[57,     3] loss: 0.893
[58,     3] loss: 0.819
[59,     3] loss: 0.809
[60,     3] loss: 0.802
[61,     3] loss: 0.779
[62,     3] loss: 0.882
[63,     3] loss: 0.871
[64,     3] loss: 0.923
[65,     3] loss: 0.928
[66,     3] loss: 0.846
[67,     3] loss: 0.815
[68,     3] loss: 0.819
[69,     3] loss: 0.828
[70,     3] loss: 0.836
[71,     3] loss: 0.819
[72,     3] loss: 0.784
[73,     3] loss: 0.837
[74,     3] loss: 0.885
[75,     3] loss: 0.923
[76,     3] loss: 0.887
[77,     3] loss: 0.838
[78,     3] loss: 0.854
[79,     3] loss: 0.784
[80,     3] loss: 0.833
[81,     3] loss: 0.786
Early stopping applied (best metric=0.5476592779159546)
Finished Training
Total time taken: 18.0350501537323
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.403
[3,     3] loss: 1.386
[4,     3] loss: 1.389
[5,     3] loss: 1.392
[6,     3] loss: 1.377
[7,     3] loss: 1.384
[8,     3] loss: 1.378
[9,     3] loss: 1.365
[10,     3] loss: 1.360
[11,     3] loss: 1.342
[12,     3] loss: 1.346
[13,     3] loss: 1.295
[14,     3] loss: 1.275
[15,     3] loss: 1.314
[16,     3] loss: 1.258
[17,     3] loss: 1.202
[18,     3] loss: 1.286
[19,     3] loss: 1.255
[20,     3] loss: 1.119
[21,     3] loss: 1.053
[22,     3] loss: 1.111
[23,     3] loss: 1.130
[24,     3] loss: 1.013
[25,     3] loss: 1.020
[26,     3] loss: 1.046
[27,     3] loss: 0.952
[28,     3] loss: 1.061
[29,     3] loss: 1.037
[30,     3] loss: 1.029
[31,     3] loss: 0.959
[32,     3] loss: 0.875
[33,     3] loss: 0.985
[34,     3] loss: 0.956
[35,     3] loss: 0.988
[36,     3] loss: 0.940
[37,     3] loss: 0.964
[38,     3] loss: 0.904
[39,     3] loss: 1.086
[40,     3] loss: 1.066
[41,     3] loss: 0.938
[42,     3] loss: 1.029
[43,     3] loss: 0.952
[44,     3] loss: 0.972
[45,     3] loss: 0.864
[46,     3] loss: 0.821
[47,     3] loss: 0.845
[48,     3] loss: 0.807
[49,     3] loss: 0.840
[50,     3] loss: 0.807
[51,     3] loss: 0.805
[52,     3] loss: 0.797
[53,     3] loss: 0.916
[54,     3] loss: 0.975
[55,     3] loss: 0.897
[56,     3] loss: 0.897
[57,     3] loss: 0.929
[58,     3] loss: 0.965
[59,     3] loss: 0.893
[60,     3] loss: 0.881
[61,     3] loss: 0.872
[62,     3] loss: 0.869
[63,     3] loss: 0.807
[64,     3] loss: 0.829
[65,     3] loss: 0.763
[66,     3] loss: 0.805
[67,     3] loss: 0.923
[68,     3] loss: 0.780
[69,     3] loss: 0.766
[70,     3] loss: 0.768
[71,     3] loss: 0.762
[72,     3] loss: 0.775
[73,     3] loss: 0.771
[74,     3] loss: 0.758
Early stopping applied (best metric=0.5337342023849487)
Finished Training
Total time taken: 16.57905888557434
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.388
[3,     3] loss: 1.390
[4,     3] loss: 1.389
[5,     3] loss: 1.387
[6,     3] loss: 1.391
[7,     3] loss: 1.381
[8,     3] loss: 1.376
[9,     3] loss: 1.369
[10,     3] loss: 1.362
[11,     3] loss: 1.343
[12,     3] loss: 1.301
[13,     3] loss: 1.288
[14,     3] loss: 1.238
[15,     3] loss: 1.255
[16,     3] loss: 1.254
[17,     3] loss: 1.125
[18,     3] loss: 1.073
[19,     3] loss: 1.114
[20,     3] loss: 1.025
[21,     3] loss: 1.024
[22,     3] loss: 0.972
[23,     3] loss: 1.002
[24,     3] loss: 0.961
[25,     3] loss: 0.932
[26,     3] loss: 1.077
[27,     3] loss: 1.020
[28,     3] loss: 1.067
[29,     3] loss: 0.937
[30,     3] loss: 1.021
[31,     3] loss: 0.932
[32,     3] loss: 1.060
[33,     3] loss: 0.944
[34,     3] loss: 0.952
[35,     3] loss: 0.894
[36,     3] loss: 0.958
[37,     3] loss: 0.913
[38,     3] loss: 0.946
[39,     3] loss: 0.890
[40,     3] loss: 0.955
[41,     3] loss: 0.897
[42,     3] loss: 0.856
[43,     3] loss: 0.855
[44,     3] loss: 0.875
[45,     3] loss: 0.803
[46,     3] loss: 0.812
[47,     3] loss: 0.876
[48,     3] loss: 0.856
[49,     3] loss: 0.824
[50,     3] loss: 0.863
[51,     3] loss: 0.857
[52,     3] loss: 0.844
[53,     3] loss: 0.861
[54,     3] loss: 0.915
[55,     3] loss: 0.899
[56,     3] loss: 0.818
[57,     3] loss: 0.814
[58,     3] loss: 0.792
[59,     3] loss: 0.791
[60,     3] loss: 0.806
[61,     3] loss: 0.861
[62,     3] loss: 0.824
[63,     3] loss: 0.817
[64,     3] loss: 0.805
[65,     3] loss: 0.853
[66,     3] loss: 0.809
[67,     3] loss: 0.783
[68,     3] loss: 0.812
[69,     3] loss: 0.748
[70,     3] loss: 0.753
[71,     3] loss: 0.770
[72,     3] loss: 0.770
[73,     3] loss: 0.762
[74,     3] loss: 0.818
Early stopping applied (best metric=0.5103310942649841)
Finished Training
Total time taken: 16.511045217514038
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.379
[3,     3] loss: 1.392
[4,     3] loss: 1.379
[5,     3] loss: 1.382
[6,     3] loss: 1.377
[7,     3] loss: 1.381
[8,     3] loss: 1.375
[9,     3] loss: 1.362
[10,     3] loss: 1.343
[11,     3] loss: 1.319
[12,     3] loss: 1.311
[13,     3] loss: 1.259
[14,     3] loss: 1.220
[15,     3] loss: 1.269
[16,     3] loss: 1.251
[17,     3] loss: 1.159
[18,     3] loss: 1.197
[19,     3] loss: 1.134
[20,     3] loss: 1.140
[21,     3] loss: 1.063
[22,     3] loss: 1.155
[23,     3] loss: 0.986
[24,     3] loss: 1.008
[25,     3] loss: 1.011
[26,     3] loss: 1.007
[27,     3] loss: 1.051
[28,     3] loss: 1.062
[29,     3] loss: 0.951
[30,     3] loss: 1.139
[31,     3] loss: 0.984
[32,     3] loss: 0.968
[33,     3] loss: 0.939
[34,     3] loss: 0.974
[35,     3] loss: 0.930
[36,     3] loss: 0.877
[37,     3] loss: 0.897
[38,     3] loss: 0.903
[39,     3] loss: 0.902
[40,     3] loss: 1.033
[41,     3] loss: 0.914
[42,     3] loss: 0.907
[43,     3] loss: 0.853
[44,     3] loss: 0.941
[45,     3] loss: 0.801
[46,     3] loss: 0.797
[47,     3] loss: 0.817
[48,     3] loss: 0.899
[49,     3] loss: 0.871
[50,     3] loss: 0.875
[51,     3] loss: 0.876
[52,     3] loss: 0.848
[53,     3] loss: 0.941
[54,     3] loss: 0.930
[55,     3] loss: 0.900
[56,     3] loss: 0.888
[57,     3] loss: 0.821
[58,     3] loss: 0.838
[59,     3] loss: 0.815
[60,     3] loss: 0.769
[61,     3] loss: 0.780
[62,     3] loss: 0.787
[63,     3] loss: 0.778
[64,     3] loss: 0.785
[65,     3] loss: 0.814
[66,     3] loss: 0.799
[67,     3] loss: 0.779
[68,     3] loss: 0.784
[69,     3] loss: 0.826
[70,     3] loss: 0.769
[71,     3] loss: 0.845
[72,     3] loss: 0.855
[73,     3] loss: 0.820
[74,     3] loss: 0.830
[75,     3] loss: 0.816
[76,     3] loss: 0.811
[77,     3] loss: 0.919
[78,     3] loss: 0.927
Early stopping applied (best metric=0.5095632076263428)
Finished Training
Total time taken: 17.352046966552734
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.384
[3,     3] loss: 1.378
[4,     3] loss: 1.379
[5,     3] loss: 1.363
[6,     3] loss: 1.338
[7,     3] loss: 1.318
[8,     3] loss: 1.266
[9,     3] loss: 1.248
[10,     3] loss: 1.223
[11,     3] loss: 1.191
[12,     3] loss: 1.135
[13,     3] loss: 1.177
[14,     3] loss: 1.175
[15,     3] loss: 1.179
[16,     3] loss: 1.178
[17,     3] loss: 1.250
[18,     3] loss: 1.099
[19,     3] loss: 1.123
[20,     3] loss: 1.107
[21,     3] loss: 1.068
[22,     3] loss: 1.015
[23,     3] loss: 1.125
[24,     3] loss: 1.091
[25,     3] loss: 0.943
[26,     3] loss: 1.095
[27,     3] loss: 0.896
[28,     3] loss: 0.997
[29,     3] loss: 0.931
[30,     3] loss: 0.884
[31,     3] loss: 0.944
[32,     3] loss: 0.931
[33,     3] loss: 0.886
[34,     3] loss: 0.974
[35,     3] loss: 0.832
[36,     3] loss: 0.830
[37,     3] loss: 0.917
[38,     3] loss: 0.864
[39,     3] loss: 0.874
[40,     3] loss: 0.831
[41,     3] loss: 0.873
[42,     3] loss: 0.853
[43,     3] loss: 0.806
[44,     3] loss: 0.845
[45,     3] loss: 0.814
[46,     3] loss: 0.818
[47,     3] loss: 0.825
[48,     3] loss: 0.769
[49,     3] loss: 0.803
[50,     3] loss: 0.814
[51,     3] loss: 0.982
[52,     3] loss: 0.790
[53,     3] loss: 0.779
[54,     3] loss: 0.870
[55,     3] loss: 0.780
[56,     3] loss: 0.777
[57,     3] loss: 0.768
[58,     3] loss: 0.761
[59,     3] loss: 0.772
[60,     3] loss: 0.773
[61,     3] loss: 0.948
[62,     3] loss: 0.774
[63,     3] loss: 0.784
[64,     3] loss: 0.795
[65,     3] loss: 0.779
[66,     3] loss: 0.783
[67,     3] loss: 0.750
[68,     3] loss: 0.791
[69,     3] loss: 0.855
[70,     3] loss: 0.764
[71,     3] loss: 0.772
[72,     3] loss: 0.775
[73,     3] loss: 0.779
Early stopping applied (best metric=0.5418544411659241)
Finished Training
Total time taken: 16.351043462753296
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.387
[3,     3] loss: 1.384
[4,     3] loss: 1.387
[5,     3] loss: 1.389
[6,     3] loss: 1.383
[7,     3] loss: 1.376
[8,     3] loss: 1.373
[9,     3] loss: 1.345
[10,     3] loss: 1.334
[11,     3] loss: 1.306
[12,     3] loss: 1.223
[13,     3] loss: 1.239
[14,     3] loss: 1.255
[15,     3] loss: 1.217
[16,     3] loss: 1.101
[17,     3] loss: 1.053
[18,     3] loss: 1.059
[19,     3] loss: 1.153
[20,     3] loss: 0.962
[21,     3] loss: 1.085
[22,     3] loss: 1.048
[23,     3] loss: 0.966
[24,     3] loss: 1.044
[25,     3] loss: 0.910
[26,     3] loss: 0.967
[27,     3] loss: 0.903
[28,     3] loss: 0.842
[29,     3] loss: 0.854
[30,     3] loss: 0.923
[31,     3] loss: 0.844
[32,     3] loss: 1.032
[33,     3] loss: 0.891
[34,     3] loss: 0.864
[35,     3] loss: 0.935
[36,     3] loss: 0.847
[37,     3] loss: 0.854
[38,     3] loss: 0.815
[39,     3] loss: 0.812
[40,     3] loss: 0.860
[41,     3] loss: 0.822
[42,     3] loss: 0.968
[43,     3] loss: 0.963
[44,     3] loss: 0.890
[45,     3] loss: 0.857
[46,     3] loss: 0.846
[47,     3] loss: 0.816
[48,     3] loss: 0.790
[49,     3] loss: 0.793
[50,     3] loss: 0.832
[51,     3] loss: 0.821
[52,     3] loss: 0.805
[53,     3] loss: 0.772
[54,     3] loss: 0.788
[55,     3] loss: 0.814
[56,     3] loss: 0.901
[57,     3] loss: 0.840
[58,     3] loss: 0.970
[59,     3] loss: 1.027
[60,     3] loss: 0.981
[61,     3] loss: 0.886
[62,     3] loss: 0.931
[63,     3] loss: 0.809
[64,     3] loss: 0.842
[65,     3] loss: 0.790
[66,     3] loss: 0.796
[67,     3] loss: 0.895
[68,     3] loss: 1.014
[69,     3] loss: 0.832
[70,     3] loss: 0.921
[71,     3] loss: 0.909
[72,     3] loss: 0.828
[73,     3] loss: 0.874
[74,     3] loss: 0.834
Early stopping applied (best metric=0.5281047224998474)
Finished Training
Total time taken: 16.517048120498657
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.384
[4,     3] loss: 1.376
[5,     3] loss: 1.393
[6,     3] loss: 1.375
[7,     3] loss: 1.382
[8,     3] loss: 1.374
[9,     3] loss: 1.354
[10,     3] loss: 1.329
[11,     3] loss: 1.319
[12,     3] loss: 1.291
[13,     3] loss: 1.252
[14,     3] loss: 1.250
[15,     3] loss: 1.255
[16,     3] loss: 1.133
[17,     3] loss: 1.151
[18,     3] loss: 1.123
[19,     3] loss: 1.111
[20,     3] loss: 1.116
[21,     3] loss: 1.064
[22,     3] loss: 1.052
[23,     3] loss: 1.058
[24,     3] loss: 0.991
[25,     3] loss: 1.010
[26,     3] loss: 1.042
[27,     3] loss: 1.082
[28,     3] loss: 0.936
[29,     3] loss: 0.928
[30,     3] loss: 0.907
[31,     3] loss: 0.853
[32,     3] loss: 0.842
[33,     3] loss: 1.059
[34,     3] loss: 1.003
[35,     3] loss: 0.995
[36,     3] loss: 0.954
[37,     3] loss: 0.888
[38,     3] loss: 0.905
[39,     3] loss: 0.950
[40,     3] loss: 1.019
[41,     3] loss: 0.882
[42,     3] loss: 0.932
[43,     3] loss: 0.942
[44,     3] loss: 0.828
[45,     3] loss: 0.851
[46,     3] loss: 0.861
[47,     3] loss: 0.836
[48,     3] loss: 0.786
[49,     3] loss: 0.843
[50,     3] loss: 0.793
[51,     3] loss: 0.816
[52,     3] loss: 0.861
[53,     3] loss: 0.925
[54,     3] loss: 0.905
[55,     3] loss: 0.913
[56,     3] loss: 0.807
[57,     3] loss: 0.908
[58,     3] loss: 0.855
[59,     3] loss: 0.841
[60,     3] loss: 0.825
[61,     3] loss: 0.786
[62,     3] loss: 0.784
[63,     3] loss: 0.767
[64,     3] loss: 0.779
[65,     3] loss: 0.839
[66,     3] loss: 0.798
[67,     3] loss: 0.820
[68,     3] loss: 0.846
[69,     3] loss: 0.801
[70,     3] loss: 0.842
[71,     3] loss: 0.819
[72,     3] loss: 0.824
[73,     3] loss: 0.784
[74,     3] loss: 0.760
[75,     3] loss: 0.835
[76,     3] loss: 0.764
[77,     3] loss: 0.738
[78,     3] loss: 0.767
[79,     3] loss: 0.755
[80,     3] loss: 0.791
Early stopping applied (best metric=0.5394682884216309)
Finished Training
Total time taken: 17.823070764541626
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.377
[3,     3] loss: 1.384
[4,     3] loss: 1.377
[5,     3] loss: 1.371
[6,     3] loss: 1.380
[7,     3] loss: 1.332
[8,     3] loss: 1.323
[9,     3] loss: 1.336
[10,     3] loss: 1.325
[11,     3] loss: 1.285
[12,     3] loss: 1.201
[13,     3] loss: 1.231
[14,     3] loss: 1.121
[15,     3] loss: 1.206
[16,     3] loss: 1.083
[17,     3] loss: 1.136
[18,     3] loss: 1.112
[19,     3] loss: 1.030
[20,     3] loss: 1.066
[21,     3] loss: 0.965
[22,     3] loss: 0.970
[23,     3] loss: 0.975
[24,     3] loss: 0.976
[25,     3] loss: 0.979
[26,     3] loss: 0.996
[27,     3] loss: 0.956
[28,     3] loss: 0.948
[29,     3] loss: 0.891
[30,     3] loss: 0.948
[31,     3] loss: 0.936
[32,     3] loss: 0.845
[33,     3] loss: 0.912
[34,     3] loss: 0.915
[35,     3] loss: 0.834
[36,     3] loss: 1.004
[37,     3] loss: 1.133
[38,     3] loss: 1.018
[39,     3] loss: 0.941
[40,     3] loss: 0.942
[41,     3] loss: 1.068
[42,     3] loss: 1.009
[43,     3] loss: 0.929
[44,     3] loss: 0.912
[45,     3] loss: 0.912
[46,     3] loss: 0.828
[47,     3] loss: 0.842
[48,     3] loss: 0.821
[49,     3] loss: 0.846
[50,     3] loss: 0.906
[51,     3] loss: 0.846
[52,     3] loss: 0.830
[53,     3] loss: 0.779
[54,     3] loss: 0.788
[55,     3] loss: 0.766
[56,     3] loss: 0.747
[57,     3] loss: 0.751
[58,     3] loss: 0.807
[59,     3] loss: 1.216
[60,     3] loss: 0.979
[61,     3] loss: 0.953
[62,     3] loss: 0.905
[63,     3] loss: 0.943
[64,     3] loss: 0.931
[65,     3] loss: 1.030
[66,     3] loss: 0.865
[67,     3] loss: 0.907
[68,     3] loss: 1.123
[69,     3] loss: 0.886
[70,     3] loss: 0.927
Early stopping applied (best metric=0.49801382422447205)
Finished Training
Total time taken: 15.625042200088501
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.384
[3,     3] loss: 1.388
[4,     3] loss: 1.385
[5,     3] loss: 1.379
[6,     3] loss: 1.383
[7,     3] loss: 1.394
[8,     3] loss: 1.369
[9,     3] loss: 1.366
[10,     3] loss: 1.347
[11,     3] loss: 1.347
[12,     3] loss: 1.319
[13,     3] loss: 1.257
[14,     3] loss: 1.286
[15,     3] loss: 1.219
[16,     3] loss: 1.163
[17,     3] loss: 1.247
[18,     3] loss: 1.166
[19,     3] loss: 1.145
[20,     3] loss: 1.253
[21,     3] loss: 1.149
[22,     3] loss: 1.312
[23,     3] loss: 1.331
[24,     3] loss: 1.202
[25,     3] loss: 1.230
[26,     3] loss: 1.188
[27,     3] loss: 1.143
[28,     3] loss: 1.189
[29,     3] loss: 1.085
[30,     3] loss: 1.031
[31,     3] loss: 0.996
[32,     3] loss: 0.954
[33,     3] loss: 0.952
[34,     3] loss: 0.933
[35,     3] loss: 0.894
[36,     3] loss: 0.890
[37,     3] loss: 0.930
[38,     3] loss: 1.159
[39,     3] loss: 1.172
[40,     3] loss: 1.056
[41,     3] loss: 1.090
[42,     3] loss: 1.048
[43,     3] loss: 1.004
[44,     3] loss: 1.015
[45,     3] loss: 0.969
[46,     3] loss: 0.871
[47,     3] loss: 0.860
[48,     3] loss: 0.841
[49,     3] loss: 0.849
[50,     3] loss: 0.838
[51,     3] loss: 0.877
[52,     3] loss: 0.909
[53,     3] loss: 0.878
[54,     3] loss: 0.897
[55,     3] loss: 0.966
[56,     3] loss: 1.023
[57,     3] loss: 0.931
[58,     3] loss: 1.027
[59,     3] loss: 0.902
[60,     3] loss: 0.909
[61,     3] loss: 0.975
[62,     3] loss: 0.878
[63,     3] loss: 0.864
[64,     3] loss: 0.821
Early stopping applied (best metric=0.50301593542099)
Finished Training
Total time taken: 14.354040145874023
{'S-palmitoylation-C Validation Accuracy': 0.6938351911714358, 'S-palmitoylation-C Validation Sensitivity': 0.23075907590759076, 'S-palmitoylation-C Validation Specificity': 0.8099105927654475, 'S-palmitoylation-C Validation Precision': 0.23778990920297238, 'S-palmitoylation-C AUC ROC': 0.5421675737916382, 'S-palmitoylation-C AUC PR': 0.22484179406799304, 'S-palmitoylation-C MCC': 0.04222541204905515, 'S-palmitoylation-C F1': 0.2221446110319614, 'Validation Loss (S-palmitoylation-C)': 0.5538611054420471, 'Hydroxylation-K Validation Accuracy': 0.7114657210401891, 'Hydroxylation-K Validation Sensitivity': 0.7496296296296296, 'Hydroxylation-K Validation Specificity': 0.7017543859649122, 'Hydroxylation-K Validation Precision': 0.4001330540804225, 'Hydroxylation-K AUC ROC': 0.7978947368421052, 'Hydroxylation-K AUC PR': 0.5830028897001572, 'Hydroxylation-K MCC': 0.379808401898569, 'Hydroxylation-K F1': 0.5140481949357981, 'Validation Loss (Hydroxylation-K)': 0.5219567477703094, 'Validation Loss (total)': 1.07581787109375, 'TimeToTrain': 17.06226511001587}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005380131367908229,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.20398412410831696,
 'loss_weight_S-palmitoylation-C': 0.8021883506460428,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1649164161,
 'sample_weights': [0.3208698438258102, 0.1842139690157791],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.407164281869886,
 'weight_decay_Hydroxylation-K': 6.093352066518419,
 'weight_decay_S-palmitoylation-C': 4.697901445269184}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.397
[3,     3] loss: 1.391
[4,     3] loss: 1.388
[5,     3] loss: 1.388
[6,     3] loss: 1.381
[7,     3] loss: 1.385
[8,     3] loss: 1.384
[9,     3] loss: 1.403
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007450962867372149,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.34321495459167745,
 'loss_weight_S-palmitoylation-C': 0.9432654232302852,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3331532342,
 'sample_weights': [0.8021883506460428, 0.20398412410831696],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9355531971660873,
 'weight_decay_Hydroxylation-K': 0.1914428223012925,
 'weight_decay_S-palmitoylation-C': 0.9602781446977885}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.375
[3,     3] loss: 1.388
[4,     3] loss: 1.381
[5,     3] loss: 1.380
[6,     3] loss: 1.374
[7,     3] loss: 1.355
[8,     3] loss: 1.374
[9,     3] loss: 1.342
[10,     3] loss: 1.333
[11,     3] loss: 1.312
[12,     3] loss: 1.283
[13,     3] loss: 1.265
[14,     3] loss: 1.250
[15,     3] loss: 1.195
[16,     3] loss: 1.192
[17,     3] loss: 1.197
[18,     3] loss: 1.157
[19,     3] loss: 1.108
[20,     3] loss: 1.140
[21,     3] loss: 1.071
[22,     3] loss: 1.015
[23,     3] loss: 1.028
[24,     3] loss: 0.988
[25,     3] loss: 1.082
[26,     3] loss: 0.966
[27,     3] loss: 0.935
[28,     3] loss: 0.989
[29,     3] loss: 1.073
[30,     3] loss: 0.992
[31,     3] loss: 0.961
[32,     3] loss: 0.941
[33,     3] loss: 0.892
[34,     3] loss: 0.883
[35,     3] loss: 0.920
[36,     3] loss: 0.865
[37,     3] loss: 0.814
[38,     3] loss: 0.817
[39,     3] loss: 0.893
[40,     3] loss: 0.852
[41,     3] loss: 0.832
[42,     3] loss: 0.843
[43,     3] loss: 0.860
[44,     3] loss: 0.811
[45,     3] loss: 0.964
[46,     3] loss: 0.817
[47,     3] loss: 0.827
[48,     3] loss: 0.893
[49,     3] loss: 0.789
[50,     3] loss: 0.881
[51,     3] loss: 0.811
[52,     3] loss: 0.889
[53,     3] loss: 0.801
[54,     3] loss: 0.769
[55,     3] loss: 0.763
[56,     3] loss: 0.749
[57,     3] loss: 0.777
[58,     3] loss: 0.764
[59,     3] loss: 0.732
[60,     3] loss: 0.737
[61,     3] loss: 0.742
[62,     3] loss: 0.773
[63,     3] loss: 0.736
[64,     3] loss: 0.758
[65,     3] loss: 0.727
[66,     3] loss: 0.731
[67,     3] loss: 0.794
[68,     3] loss: 0.729
[69,     3] loss: 0.742
[70,     3] loss: 0.756
[71,     3] loss: 0.773
[72,     3] loss: 0.750
[73,     3] loss: 0.890
[74,     3] loss: 0.776
[75,     3] loss: 0.810
[76,     3] loss: 0.795
[77,     3] loss: 0.804
[78,     3] loss: 0.765
[79,     3] loss: 0.747
[80,     3] loss: 0.765
[81,     3] loss: 0.865
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003676626403427436,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.12833775384894622,
 'loss_weight_S-palmitoylation-C': 0.2278847986116861,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3442995631,
 'sample_weights': [0.9432654232302852, 0.34321495459167745],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.902454856504115,
 'weight_decay_Hydroxylation-K': 1.415422068491603,
 'weight_decay_S-palmitoylation-C': 4.639336143993948}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.389
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005028720829684534,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2897373535234925,
 'loss_weight_S-palmitoylation-C': 0.8308855815382775,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3689448238,
 'sample_weights': [0.2278847986116861, 0.12833775384894622],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7970674460417628,
 'weight_decay_Hydroxylation-K': 3.906807608150263,
 'weight_decay_S-palmitoylation-C': 0.31137018298047203}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.381
[3,     3] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012268151080063747,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5127458678264015,
 'loss_weight_S-palmitoylation-C': 0.992788859629311,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2459860530,
 'sample_weights': [0.8308855815382775, 0.2897373535234925],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7062987406115928,
 'weight_decay_Hydroxylation-K': 1.6567320201148754,
 'weight_decay_S-palmitoylation-C': 4.655784386048734}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.384
[3,     3] loss: 1.383
[4,     3] loss: 1.394
[5,     3] loss: 1.385
[6,     3] loss: 1.384
[7,     3] loss: 1.379
[8,     3] loss: 1.390
[9,     3] loss: 1.373
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004212743678955693,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7111895157103617,
 'loss_weight_S-palmitoylation-C': 0.2307846020272527,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1441539545,
 'sample_weights': [0.992788859629311, 0.5127458678264015],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.4327078459214944,
 'weight_decay_Hydroxylation-K': 0.505704689418425,
 'weight_decay_S-palmitoylation-C': 3.172704256512807}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.390
[3,     3] loss: 1.374
[4,     3] loss: 1.387
[5,     3] loss: 1.388
[6,     3] loss: 1.375
[7,     3] loss: 1.374
[8,     3] loss: 1.370
[9,     3] loss: 1.345
[10,     3] loss: 1.332
[11,     3] loss: 1.313
[12,     3] loss: 1.311
[13,     3] loss: 1.290
[14,     3] loss: 1.247
[15,     3] loss: 1.196
[16,     3] loss: 1.259
[17,     3] loss: 1.152
[18,     3] loss: 1.217
[19,     3] loss: 1.115
[20,     3] loss: 1.081
[21,     3] loss: 1.025
[22,     3] loss: 1.225
[23,     3] loss: 1.104
[24,     3] loss: 1.168
[25,     3] loss: 0.990
[26,     3] loss: 0.985
[27,     3] loss: 0.999
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00010111797207553906,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22872681469791853,
 'loss_weight_S-palmitoylation-C': 0.3385120184001416,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3342103700,
 'sample_weights': [0.2307846020272527, 0.7111895157103617],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.459825886263292,
 'weight_decay_Hydroxylation-K': 0.3050915271326563,
 'weight_decay_S-palmitoylation-C': 7.235985589474435}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.403
[3,     3] loss: 1.390
[4,     3] loss: 1.393
[5,     3] loss: 1.391
[6,     3] loss: 1.381
[7,     3] loss: 1.387
[8,     3] loss: 1.386
[9,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003743629139627784,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.28564090608321235,
 'loss_weight_S-palmitoylation-C': 0.37368419312455237,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 89333592,
 'sample_weights': [0.3385120184001416, 0.22872681469791853],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.642686391374163,
 'weight_decay_Hydroxylation-K': 1.2183601487999223,
 'weight_decay_S-palmitoylation-C': 7.81585495737391}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.390
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003220923692181807,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.17314367198907277,
 'loss_weight_S-palmitoylation-C': 0.7491074540592604,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4195391026,
 'sample_weights': [0.37368419312455237, 0.28564090608321235],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.600032573809049,
 'weight_decay_Hydroxylation-K': 9.615035812787765,
 'weight_decay_S-palmitoylation-C': 1.208992497331752}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.391
[3,     3] loss: 1.391
[4,     3] loss: 1.386
[5,     3] loss: 1.388
[6,     3] loss: 1.387
[7,     3] loss: 1.381
[8,     3] loss: 1.381
[9,     3] loss: 1.382
[10,     3] loss: 1.380
[11,     3] loss: 1.376
[12,     3] loss: 1.377
[13,     3] loss: 1.343
[14,     3] loss: 1.331
[15,     3] loss: 1.286
[16,     3] loss: 1.287
[17,     3] loss: 1.175
[18,     3] loss: 1.220
[19,     3] loss: 1.228
[20,     3] loss: 1.203
[21,     3] loss: 1.228
[22,     3] loss: 1.145
[23,     3] loss: 1.108
[24,     3] loss: 1.077
[25,     3] loss: 1.135
[26,     3] loss: 1.067
[27,     3] loss: 1.139
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011476159299815898,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.41169289758315564,
 'loss_weight_S-palmitoylation-C': 0.5420129009623706,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2049143,
 'sample_weights': [0.7491074540592604, 0.17314367198907277],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.646437448491449,
 'weight_decay_Hydroxylation-K': 9.416268855725363,
 'weight_decay_S-palmitoylation-C': 0.4361143534613844}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.383
[3,     3] loss: 1.384
[4,     3] loss: 1.387
[5,     3] loss: 1.382
[6,     3] loss: 1.393
[7,     3] loss: 1.385
[8,     3] loss: 1.391
[9,     3] loss: 1.385
[10,     3] loss: 1.379
[11,     3] loss: 1.376
[12,     3] loss: 1.370
[13,     3] loss: 1.365
[14,     3] loss: 1.361
[15,     3] loss: 1.350
[16,     3] loss: 1.353
[17,     3] loss: 1.315
[18,     3] loss: 1.327
[19,     3] loss: 1.272
[20,     3] loss: 1.203
[21,     3] loss: 1.177
[22,     3] loss: 1.197
[23,     3] loss: 1.099
[24,     3] loss: 1.074
[25,     3] loss: 1.013
[26,     3] loss: 0.928
[27,     3] loss: 1.021
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002555248587955008,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4188705733059117,
 'loss_weight_S-palmitoylation-C': 0.08966787569936882,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3764401491,
 'sample_weights': [0.5420129009623706, 0.41169289758315564],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.346107074416942,
 'weight_decay_Hydroxylation-K': 0.9723687486991119,
 'weight_decay_S-palmitoylation-C': 5.431727813397908}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.385
[3,     3] loss: 1.396
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0052892310889032495,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4245530050708991,
 'loss_weight_S-palmitoylation-C': 0.10815646135506943,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2557687771,
 'sample_weights': [0.08966787569936882, 0.4188705733059117],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.954309954901404,
 'weight_decay_Hydroxylation-K': 5.49727793796534,
 'weight_decay_S-palmitoylation-C': 3.2624401951352593}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.393
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005693211241894572,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22500161907885302,
 'loss_weight_S-palmitoylation-C': 0.3170051359231999,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2524215825,
 'sample_weights': [0.10815646135506943, 0.4245530050708991],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.526845382321294,
 'weight_decay_Hydroxylation-K': 9.926101897866351,
 'weight_decay_S-palmitoylation-C': 1.5822069223968471}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.384
[3,     3] loss: 1.398
[4,     3] loss: 1.382
[5,     3] loss: 1.387
[6,     3] loss: 1.386
[7,     3] loss: 1.383
[8,     3] loss: 1.390
[9,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0002724695667006171,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2232397588638384,
 'loss_weight_S-palmitoylation-C': 0.9938222150192905,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 548493319,
 'sample_weights': [0.3170051359231999, 0.22500161907885302],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.3137668827115414,
 'weight_decay_Hydroxylation-K': 1.6412908409776836,
 'weight_decay_S-palmitoylation-C': 1.975556571572513}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.380
[2,     3] loss: 1.386
[3,     3] loss: 1.393
[4,     3] loss: 1.384
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.381
[8,     3] loss: 1.381
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002217836669766599,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5843761179882342,
 'loss_weight_S-palmitoylation-C': 0.2667840737545334,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1848250638,
 'sample_weights': [0.9938222150192905, 0.2232397588638384],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.307316957626402,
 'weight_decay_Hydroxylation-K': 0.9334972574700562,
 'weight_decay_S-palmitoylation-C': 4.529638140158501}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.391
[3,     3] loss: 1.383
[4,     3] loss: 1.381
[5,     3] loss: 1.379
[6,     3] loss: 1.382
[7,     3] loss: 1.366
[8,     3] loss: 1.387
[9,     3] loss: 1.361
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002249824451862537,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22794975190693342,
 'loss_weight_S-palmitoylation-C': 0.578475929638023,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2005155129,
 'sample_weights': [0.2667840737545334, 0.5843761179882342],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.946228866101395,
 'weight_decay_Hydroxylation-K': 0.1464316117714151,
 'weight_decay_S-palmitoylation-C': 5.450478254312968}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.390
[3,     3] loss: 1.386
[4,     3] loss: 1.386
[5,     3] loss: 1.377
[6,     3] loss: 1.372
[7,     3] loss: 1.399
[8,     3] loss: 1.388
[9,     3] loss: 1.375
[10,     3] loss: 1.376
[11,     3] loss: 1.326
[12,     3] loss: 1.259
[13,     3] loss: 1.257
[14,     3] loss: 1.244
[15,     3] loss: 1.146
[16,     3] loss: 1.213
[17,     3] loss: 1.209
[18,     3] loss: 1.131
[19,     3] loss: 1.171
[20,     3] loss: 1.163
[21,     3] loss: 1.204
[22,     3] loss: 1.133
[23,     3] loss: 1.051
[24,     3] loss: 1.163
[25,     3] loss: 1.153
[26,     3] loss: 1.149
[27,     3] loss: 1.062
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00013779271159474545,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.08928388936403198,
 'loss_weight_S-palmitoylation-C': 0.0007050247506283358,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3753414739,
 'sample_weights': [0.578475929638023, 0.22794975190693342],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1821180932338677,
 'weight_decay_Hydroxylation-K': 1.8430656187469903,
 'weight_decay_S-palmitoylation-C': 3.2415619369348527}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.384
[3,     3] loss: 1.388
[4,     3] loss: 1.382
[5,     3] loss: 1.384
[6,     3] loss: 1.389
[7,     3] loss: 1.387
[8,     3] loss: 1.385
[9,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003819652405615461,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.20092823584802144,
 'loss_weight_S-palmitoylation-C': 0.02553158465918537,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 238871609,
 'sample_weights': [0.0007050247506283358, 0.08928388936403198],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.511133532068422,
 'weight_decay_Hydroxylation-K': 0.40836515433235476,
 'weight_decay_S-palmitoylation-C': 1.2709399384802675}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.411
[3,     3] loss: 1.385
[4,     3] loss: 1.385
[5,     3] loss: 1.386
[6,     3] loss: 1.379
[7,     3] loss: 1.393
[8,     3] loss: 1.392
[9,     3] loss: 1.374
[10,     3] loss: 1.378
[11,     3] loss: 1.347
[12,     3] loss: 1.289
[13,     3] loss: 1.299
[14,     3] loss: 1.308
[15,     3] loss: 1.221
[16,     3] loss: 1.182
[17,     3] loss: 1.216
[18,     3] loss: 1.132
[19,     3] loss: 1.062
[20,     3] loss: 1.106
[21,     3] loss: 1.134
[22,     3] loss: 1.036
[23,     3] loss: 1.124
[24,     3] loss: 1.094
[25,     3] loss: 0.979
[26,     3] loss: 0.942
[27,     3] loss: 1.159
[28,     3] loss: 0.930
[29,     3] loss: 1.038
[30,     3] loss: 1.010
[31,     3] loss: 0.950
[32,     3] loss: 0.930
[33,     3] loss: 0.858
[34,     3] loss: 0.986
[35,     3] loss: 1.300
[36,     3] loss: 1.209
[37,     3] loss: 1.294
[38,     3] loss: 1.199
[39,     3] loss: 1.040
[40,     3] loss: 1.006
[41,     3] loss: 1.570
[42,     3] loss: 1.087
[43,     3] loss: 1.137
[44,     3] loss: 1.112
[45,     3] loss: 1.089
[46,     3] loss: 1.075
[47,     3] loss: 1.069
[48,     3] loss: 0.983
[49,     3] loss: 0.999
[50,     3] loss: 1.053
[51,     3] loss: 1.019
[52,     3] loss: 0.958
[53,     3] loss: 0.980
[54,     3] loss: 1.059
[55,     3] loss: 0.974
[56,     3] loss: 0.988
[57,     3] loss: 1.001
[58,     3] loss: 0.888
[59,     3] loss: 0.966
[60,     3] loss: 0.952
[61,     3] loss: 0.880
[62,     3] loss: 0.907
[63,     3] loss: 0.929
[64,     3] loss: 0.988
[65,     3] loss: 0.884
[66,     3] loss: 0.921
[67,     3] loss: 0.987
[68,     3] loss: 1.128
[69,     3] loss: 1.095
[70,     3] loss: 1.094
[71,     3] loss: 1.019
[72,     3] loss: 1.019
[73,     3] loss: 0.942
[74,     3] loss: 0.856
[75,     3] loss: 0.845
[76,     3] loss: 0.893
[77,     3] loss: 0.882
Early stopping applied (best metric=0.5310606956481934)
Finished Training
Total time taken: 17.194069147109985
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.395
[3,     3] loss: 1.384
[4,     3] loss: 1.382
[5,     3] loss: 1.387
[6,     3] loss: 1.392
[7,     3] loss: 1.383
[8,     3] loss: 1.373
[9,     3] loss: 1.362
[10,     3] loss: 1.362
[11,     3] loss: 1.285
[12,     3] loss: 1.265
[13,     3] loss: 1.237
[14,     3] loss: 1.162
[15,     3] loss: 1.153
[16,     3] loss: 1.079
[17,     3] loss: 1.145
[18,     3] loss: 1.204
[19,     3] loss: 1.158
[20,     3] loss: 1.227
[21,     3] loss: 1.175
[22,     3] loss: 1.007
[23,     3] loss: 1.101
[24,     3] loss: 1.098
[25,     3] loss: 1.138
[26,     3] loss: 0.987
[27,     3] loss: 1.070
[28,     3] loss: 1.059
[29,     3] loss: 1.046
[30,     3] loss: 0.979
[31,     3] loss: 1.129
[32,     3] loss: 1.069
[33,     3] loss: 1.121
[34,     3] loss: 1.039
[35,     3] loss: 1.050
[36,     3] loss: 1.010
[37,     3] loss: 1.007
[38,     3] loss: 0.931
[39,     3] loss: 0.966
[40,     3] loss: 0.894
[41,     3] loss: 0.877
[42,     3] loss: 0.866
[43,     3] loss: 1.178
[44,     3] loss: 1.072
[45,     3] loss: 1.043
[46,     3] loss: 1.007
[47,     3] loss: 0.907
[48,     3] loss: 0.977
[49,     3] loss: 0.933
[50,     3] loss: 1.011
[51,     3] loss: 0.929
[52,     3] loss: 1.247
[53,     3] loss: 1.137
[54,     3] loss: 1.055
[55,     3] loss: 1.059
[56,     3] loss: 1.028
[57,     3] loss: 0.871
[58,     3] loss: 0.926
[59,     3] loss: 0.905
[60,     3] loss: 0.975
[61,     3] loss: 0.906
[62,     3] loss: 0.941
[63,     3] loss: 0.902
[64,     3] loss: 0.892
[65,     3] loss: 1.019
[66,     3] loss: 0.854
[67,     3] loss: 1.124
[68,     3] loss: 1.080
[69,     3] loss: 1.016
[70,     3] loss: 1.049
[71,     3] loss: 0.964
[72,     3] loss: 0.877
[73,     3] loss: 0.916
[74,     3] loss: 1.000
[75,     3] loss: 0.933
[76,     3] loss: 0.883
[77,     3] loss: 0.911
[78,     3] loss: 0.842
[79,     3] loss: 0.832
[80,     3] loss: 0.790
[81,     3] loss: 0.799
Early stopping applied (best metric=0.5481457710266113)
Finished Training
Total time taken: 18.078048706054688
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.392
[3,     3] loss: 1.381
[4,     3] loss: 1.393
[5,     3] loss: 1.382
[6,     3] loss: 1.387
[7,     3] loss: 1.376
[8,     3] loss: 1.389
[9,     3] loss: 1.400
[10,     3] loss: 1.383
[11,     3] loss: 1.375
[12,     3] loss: 1.340
[13,     3] loss: 1.319
[14,     3] loss: 1.251
[15,     3] loss: 1.303
[16,     3] loss: 1.187
[17,     3] loss: 1.280
[18,     3] loss: 1.395
[19,     3] loss: 1.235
[20,     3] loss: 1.197
[21,     3] loss: 1.288
[22,     3] loss: 1.161
[23,     3] loss: 1.193
[24,     3] loss: 1.124
[25,     3] loss: 1.153
[26,     3] loss: 1.130
[27,     3] loss: 1.064
[28,     3] loss: 1.034
[29,     3] loss: 0.913
[30,     3] loss: 1.021
[31,     3] loss: 1.468
[32,     3] loss: 1.253
[33,     3] loss: 1.238
[34,     3] loss: 1.163
[35,     3] loss: 1.160
[36,     3] loss: 1.137
[37,     3] loss: 1.073
[38,     3] loss: 1.030
[39,     3] loss: 1.031
[40,     3] loss: 1.209
[41,     3] loss: 1.105
[42,     3] loss: 1.086
[43,     3] loss: 0.976
[44,     3] loss: 0.846
[45,     3] loss: 0.941
[46,     3] loss: 0.924
[47,     3] loss: 1.041
[48,     3] loss: 0.931
[49,     3] loss: 0.953
[50,     3] loss: 0.911
[51,     3] loss: 1.127
[52,     3] loss: 1.104
[53,     3] loss: 1.038
[54,     3] loss: 0.940
[55,     3] loss: 0.920
[56,     3] loss: 0.887
[57,     3] loss: 1.018
[58,     3] loss: 0.961
[59,     3] loss: 0.958
[60,     3] loss: 0.930
[61,     3] loss: 0.878
[62,     3] loss: 0.837
[63,     3] loss: 0.928
[64,     3] loss: 0.899
[65,     3] loss: 1.008
[66,     3] loss: 0.964
[67,     3] loss: 0.949
[68,     3] loss: 0.968
[69,     3] loss: 0.928
[70,     3] loss: 0.806
[71,     3] loss: 0.885
[72,     3] loss: 0.896
[73,     3] loss: 0.823
[74,     3] loss: 1.115
[75,     3] loss: 0.949
[76,     3] loss: 0.993
[77,     3] loss: 0.960
[78,     3] loss: 0.945
[79,     3] loss: 0.866
Early stopping applied (best metric=0.5268955230712891)
Finished Training
Total time taken: 17.66204595565796
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.391
[3,     3] loss: 1.390
[4,     3] loss: 1.395
[5,     3] loss: 1.390
[6,     3] loss: 1.381
[7,     3] loss: 1.380
[8,     3] loss: 1.376
[9,     3] loss: 1.363
[10,     3] loss: 1.331
[11,     3] loss: 1.280
[12,     3] loss: 1.275
[13,     3] loss: 1.197
[14,     3] loss: 1.430
[15,     3] loss: 1.274
[16,     3] loss: 1.286
[17,     3] loss: 1.264
[18,     3] loss: 1.217
[19,     3] loss: 1.220
[20,     3] loss: 1.239
[21,     3] loss: 1.090
[22,     3] loss: 1.042
[23,     3] loss: 1.092
[24,     3] loss: 1.181
[25,     3] loss: 1.135
[26,     3] loss: 1.217
[27,     3] loss: 1.144
[28,     3] loss: 1.123
[29,     3] loss: 1.053
[30,     3] loss: 1.061
[31,     3] loss: 0.981
[32,     3] loss: 1.015
[33,     3] loss: 0.927
[34,     3] loss: 0.926
[35,     3] loss: 0.990
[36,     3] loss: 0.962
[37,     3] loss: 0.945
[38,     3] loss: 0.968
[39,     3] loss: 1.029
[40,     3] loss: 1.009
[41,     3] loss: 0.907
[42,     3] loss: 0.856
[43,     3] loss: 1.227
[44,     3] loss: 1.032
[45,     3] loss: 1.144
[46,     3] loss: 1.133
[47,     3] loss: 1.042
[48,     3] loss: 1.000
[49,     3] loss: 0.935
[50,     3] loss: 0.924
[51,     3] loss: 0.960
[52,     3] loss: 1.017
[53,     3] loss: 1.045
[54,     3] loss: 0.971
[55,     3] loss: 0.865
[56,     3] loss: 0.812
[57,     3] loss: 1.082
[58,     3] loss: 0.968
[59,     3] loss: 1.028
[60,     3] loss: 0.900
[61,     3] loss: 0.931
[62,     3] loss: 0.997
[63,     3] loss: 0.993
[64,     3] loss: 0.924
[65,     3] loss: 0.887
[66,     3] loss: 0.883
[67,     3] loss: 1.055
[68,     3] loss: 0.928
[69,     3] loss: 0.900
Early stopping applied (best metric=0.4969172179698944)
Finished Training
Total time taken: 15.465040922164917
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.399
[3,     3] loss: 1.385
[4,     3] loss: 1.369
[5,     3] loss: 1.395
[6,     3] loss: 1.385
[7,     3] loss: 1.385
[8,     3] loss: 1.391
[9,     3] loss: 1.378
[10,     3] loss: 1.389
[11,     3] loss: 1.385
[12,     3] loss: 1.377
[13,     3] loss: 1.371
[14,     3] loss: 1.353
[15,     3] loss: 1.359
[16,     3] loss: 1.287
[17,     3] loss: 1.265
[18,     3] loss: 1.173
[19,     3] loss: 1.436
[20,     3] loss: 1.263
[21,     3] loss: 1.240
[22,     3] loss: 1.230
[23,     3] loss: 1.171
[24,     3] loss: 1.233
[25,     3] loss: 1.069
[26,     3] loss: 1.071
[27,     3] loss: 1.153
[28,     3] loss: 1.055
[29,     3] loss: 0.999
[30,     3] loss: 1.083
[31,     3] loss: 1.041
[32,     3] loss: 0.988
[33,     3] loss: 1.117
[34,     3] loss: 0.991
[35,     3] loss: 0.918
[36,     3] loss: 1.069
[37,     3] loss: 1.593
[38,     3] loss: 1.361
[39,     3] loss: 1.337
[40,     3] loss: 1.368
[41,     3] loss: 1.368
[42,     3] loss: 1.359
[43,     3] loss: 1.347
[44,     3] loss: 1.336
[45,     3] loss: 1.281
[46,     3] loss: 1.472
[47,     3] loss: 1.424
[48,     3] loss: 1.392
[49,     3] loss: 1.388
[50,     3] loss: 1.344
[51,     3] loss: 1.259
[52,     3] loss: 1.279
[53,     3] loss: 1.314
[54,     3] loss: 1.277
[55,     3] loss: 1.291
[56,     3] loss: 1.257
[57,     3] loss: 1.249
[58,     3] loss: 1.278
[59,     3] loss: 1.308
[60,     3] loss: 1.276
[61,     3] loss: 1.255
[62,     3] loss: 1.213
[63,     3] loss: 1.181
[64,     3] loss: 1.244
[65,     3] loss: 1.212
[66,     3] loss: 1.358
[67,     3] loss: 1.343
[68,     3] loss: 1.265
[69,     3] loss: 1.185
[70,     3] loss: 1.184
[71,     3] loss: 1.084
[72,     3] loss: 1.130
[73,     3] loss: 1.226
[74,     3] loss: 1.228
[75,     3] loss: 1.210
[76,     3] loss: 1.126
Early stopping applied (best metric=0.4628348648548126)
Finished Training
Total time taken: 16.983049154281616
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.383
[3,     3] loss: 1.399
[4,     3] loss: 1.375
[5,     3] loss: 1.375
[6,     3] loss: 1.372
[7,     3] loss: 1.362
[8,     3] loss: 1.317
[9,     3] loss: 1.292
[10,     3] loss: 1.254
[11,     3] loss: 1.246
[12,     3] loss: 1.250
[13,     3] loss: 1.216
[14,     3] loss: 1.152
[15,     3] loss: 1.185
[16,     3] loss: 1.178
[17,     3] loss: 1.199
[18,     3] loss: 1.051
[19,     3] loss: 1.071
[20,     3] loss: 0.995
[21,     3] loss: 0.986
[22,     3] loss: 0.992
[23,     3] loss: 0.979
[24,     3] loss: 0.956
[25,     3] loss: 0.921
[26,     3] loss: 0.946
[27,     3] loss: 0.934
[28,     3] loss: 0.916
[29,     3] loss: 0.940
[30,     3] loss: 1.065
[31,     3] loss: 0.941
[32,     3] loss: 1.078
[33,     3] loss: 0.960
[34,     3] loss: 0.916
[35,     3] loss: 1.116
[36,     3] loss: 0.988
[37,     3] loss: 1.018
[38,     3] loss: 0.887
[39,     3] loss: 0.839
[40,     3] loss: 0.851
[41,     3] loss: 0.798
[42,     3] loss: 0.824
[43,     3] loss: 0.902
[44,     3] loss: 0.951
[45,     3] loss: 0.899
[46,     3] loss: 1.290
[47,     3] loss: 1.041
[48,     3] loss: 0.972
[49,     3] loss: 1.016
[50,     3] loss: 0.871
[51,     3] loss: 0.832
[52,     3] loss: 0.844
[53,     3] loss: 1.390
[54,     3] loss: 1.119
[55,     3] loss: 1.109
[56,     3] loss: 1.160
[57,     3] loss: 1.128
[58,     3] loss: 1.019
[59,     3] loss: 0.970
[60,     3] loss: 0.909
[61,     3] loss: 0.918
[62,     3] loss: 0.825
[63,     3] loss: 0.835
[64,     3] loss: 0.846
[65,     3] loss: 0.830
[66,     3] loss: 0.907
[67,     3] loss: 0.806
[68,     3] loss: 0.886
[69,     3] loss: 0.782
Early stopping applied (best metric=0.5463460683822632)
Finished Training
Total time taken: 15.42004132270813
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.415
[3,     3] loss: 1.386
[4,     3] loss: 1.380
[5,     3] loss: 1.386
[6,     3] loss: 1.397
[7,     3] loss: 1.384
[8,     3] loss: 1.395
[9,     3] loss: 1.380
[10,     3] loss: 1.392
[11,     3] loss: 1.374
[12,     3] loss: 1.400
[13,     3] loss: 1.378
[14,     3] loss: 1.381
[15,     3] loss: 1.351
[16,     3] loss: 1.324
[17,     3] loss: 1.259
[18,     3] loss: 1.248
[19,     3] loss: 1.271
[20,     3] loss: 1.335
[21,     3] loss: 1.289
[22,     3] loss: 1.270
[23,     3] loss: 1.283
[24,     3] loss: 1.236
[25,     3] loss: 1.220
[26,     3] loss: 1.187
[27,     3] loss: 1.174
[28,     3] loss: 1.087
[29,     3] loss: 1.015
[30,     3] loss: 0.964
[31,     3] loss: 1.183
[32,     3] loss: 1.018
[33,     3] loss: 0.976
[34,     3] loss: 1.131
[35,     3] loss: 1.028
[36,     3] loss: 1.001
[37,     3] loss: 1.374
[38,     3] loss: 1.191
[39,     3] loss: 1.163
[40,     3] loss: 1.100
[41,     3] loss: 1.109
[42,     3] loss: 1.066
[43,     3] loss: 0.951
[44,     3] loss: 1.009
[45,     3] loss: 1.014
[46,     3] loss: 0.899
[47,     3] loss: 0.989
[48,     3] loss: 1.110
[49,     3] loss: 1.084
[50,     3] loss: 1.067
[51,     3] loss: 1.251
[52,     3] loss: 1.216
[53,     3] loss: 1.183
[54,     3] loss: 1.185
[55,     3] loss: 0.992
[56,     3] loss: 1.072
[57,     3] loss: 0.919
[58,     3] loss: 1.041
[59,     3] loss: 1.008
[60,     3] loss: 1.159
[61,     3] loss: 1.118
[62,     3] loss: 0.991
[63,     3] loss: 1.012
[64,     3] loss: 0.955
[65,     3] loss: 0.931
[66,     3] loss: 0.865
[67,     3] loss: 0.912
[68,     3] loss: 0.851
Early stopping applied (best metric=0.5292842388153076)
Finished Training
Total time taken: 15.134247779846191
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.403
[3,     3] loss: 1.392
[4,     3] loss: 1.382
[5,     3] loss: 1.376
[6,     3] loss: 1.376
[7,     3] loss: 1.380
[8,     3] loss: 1.380
[9,     3] loss: 1.326
[10,     3] loss: 1.277
[11,     3] loss: 1.310
[12,     3] loss: 1.268
[13,     3] loss: 1.208
[14,     3] loss: 1.229
[15,     3] loss: 1.138
[16,     3] loss: 1.139
[17,     3] loss: 1.224
[18,     3] loss: 1.175
[19,     3] loss: 1.159
[20,     3] loss: 1.125
[21,     3] loss: 1.040
[22,     3] loss: 1.159
[23,     3] loss: 1.185
[24,     3] loss: 1.117
[25,     3] loss: 1.151
[26,     3] loss: 1.124
[27,     3] loss: 1.047
[28,     3] loss: 1.017
[29,     3] loss: 1.111
[30,     3] loss: 0.979
[31,     3] loss: 1.031
[32,     3] loss: 0.919
[33,     3] loss: 0.980
[34,     3] loss: 0.885
[35,     3] loss: 1.089
[36,     3] loss: 1.292
[37,     3] loss: 1.255
[38,     3] loss: 1.226
[39,     3] loss: 1.214
[40,     3] loss: 1.230
[41,     3] loss: 1.157
[42,     3] loss: 1.168
[43,     3] loss: 0.999
[44,     3] loss: 1.039
[45,     3] loss: 0.910
[46,     3] loss: 0.966
[47,     3] loss: 1.076
[48,     3] loss: 0.939
[49,     3] loss: 0.942
[50,     3] loss: 1.123
[51,     3] loss: 1.382
[52,     3] loss: 1.292
[53,     3] loss: 1.274
[54,     3] loss: 1.205
[55,     3] loss: 1.245
[56,     3] loss: 1.129
[57,     3] loss: 1.064
[58,     3] loss: 1.068
[59,     3] loss: 0.913
[60,     3] loss: 0.936
[61,     3] loss: 0.891
[62,     3] loss: 1.128
[63,     3] loss: 1.048
[64,     3] loss: 1.014
[65,     3] loss: 0.915
[66,     3] loss: 0.973
[67,     3] loss: 0.902
[68,     3] loss: 0.998
[69,     3] loss: 1.010
[70,     3] loss: 1.031
[71,     3] loss: 1.021
[72,     3] loss: 0.936
[73,     3] loss: 0.934
[74,     3] loss: 0.871
[75,     3] loss: 0.878
[76,     3] loss: 0.803
[77,     3] loss: 1.142
[78,     3] loss: 1.006
[79,     3] loss: 0.998
[80,     3] loss: 0.878
[81,     3] loss: 0.905
[82,     3] loss: 1.185
[83,     3] loss: 0.999
[84,     3] loss: 1.046
[85,     3] loss: 0.942
[86,     3] loss: 0.929
[87,     3] loss: 1.007
[88,     3] loss: 1.092
[89,     3] loss: 0.981
[90,     3] loss: 0.939
[91,     3] loss: 0.991
[92,     3] loss: 0.884
[93,     3] loss: 0.836
[94,     3] loss: 1.014
[95,     3] loss: 1.095
[96,     3] loss: 1.138
Early stopping applied (best metric=0.529248058795929)
Finished Training
Total time taken: 21.34965705871582
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.393
[3,     3] loss: 1.382
[4,     3] loss: 1.393
[5,     3] loss: 1.385
[6,     3] loss: 1.375
[7,     3] loss: 1.372
[8,     3] loss: 1.349
[9,     3] loss: 1.343
[10,     3] loss: 1.269
[11,     3] loss: 1.177
[12,     3] loss: 1.153
[13,     3] loss: 1.316
[14,     3] loss: 1.068
[15,     3] loss: 1.200
[16,     3] loss: 1.031
[17,     3] loss: 1.030
[18,     3] loss: 1.132
[19,     3] loss: 1.051
[20,     3] loss: 1.096
[21,     3] loss: 1.000
[22,     3] loss: 1.174
[23,     3] loss: 1.148
[24,     3] loss: 0.993
[25,     3] loss: 1.081
[26,     3] loss: 0.953
[27,     3] loss: 1.057
[28,     3] loss: 1.013
[29,     3] loss: 1.050
[30,     3] loss: 0.942
[31,     3] loss: 0.884
[32,     3] loss: 0.961
[33,     3] loss: 1.142
[34,     3] loss: 1.174
[35,     3] loss: 1.146
[36,     3] loss: 1.093
[37,     3] loss: 1.021
[38,     3] loss: 0.970
[39,     3] loss: 0.894
[40,     3] loss: 1.018
[41,     3] loss: 0.896
[42,     3] loss: 0.854
[43,     3] loss: 0.931
[44,     3] loss: 0.887
[45,     3] loss: 0.873
[46,     3] loss: 1.083
[47,     3] loss: 0.999
[48,     3] loss: 1.034
[49,     3] loss: 0.994
[50,     3] loss: 1.007
[51,     3] loss: 0.972
[52,     3] loss: 0.904
[53,     3] loss: 0.906
[54,     3] loss: 0.892
[55,     3] loss: 0.865
[56,     3] loss: 0.833
[57,     3] loss: 1.069
[58,     3] loss: 0.914
[59,     3] loss: 0.859
[60,     3] loss: 0.833
[61,     3] loss: 1.197
[62,     3] loss: 1.524
[63,     3] loss: 1.223
[64,     3] loss: 1.248
[65,     3] loss: 1.241
[66,     3] loss: 1.156
[67,     3] loss: 1.104
[68,     3] loss: 1.082
[69,     3] loss: 1.180
[70,     3] loss: 1.101
[71,     3] loss: 1.019
[72,     3] loss: 0.911
[73,     3] loss: 0.942
[74,     3] loss: 0.889
[75,     3] loss: 0.854
[76,     3] loss: 0.945
Early stopping applied (best metric=0.5222206115722656)
Finished Training
Total time taken: 16.912405729293823
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.379
[2,     3] loss: 1.398
[3,     3] loss: 1.384
[4,     3] loss: 1.389
[5,     3] loss: 1.383
[6,     3] loss: 1.379
[7,     3] loss: 1.403
[8,     3] loss: 1.389
[9,     3] loss: 1.380
[10,     3] loss: 1.378
[11,     3] loss: 1.379
[12,     3] loss: 1.371
[13,     3] loss: 1.319
[14,     3] loss: 1.308
[15,     3] loss: 1.263
[16,     3] loss: 1.217
[17,     3] loss: 1.179
[18,     3] loss: 1.199
[19,     3] loss: 1.077
[20,     3] loss: 1.252
[21,     3] loss: 1.008
[22,     3] loss: 1.056
[23,     3] loss: 0.986
[24,     3] loss: 1.018
[25,     3] loss: 1.028
[26,     3] loss: 0.988
[27,     3] loss: 0.997
[28,     3] loss: 1.087
[29,     3] loss: 1.043
[30,     3] loss: 1.019
[31,     3] loss: 0.955
[32,     3] loss: 0.895
[33,     3] loss: 0.985
[34,     3] loss: 1.009
[35,     3] loss: 1.236
[36,     3] loss: 1.109
[37,     3] loss: 1.083
[38,     3] loss: 1.028
[39,     3] loss: 0.961
[40,     3] loss: 1.025
[41,     3] loss: 0.924
[42,     3] loss: 1.040
[43,     3] loss: 0.982
[44,     3] loss: 0.927
[45,     3] loss: 1.145
[46,     3] loss: 0.951
[47,     3] loss: 0.916
[48,     3] loss: 0.841
[49,     3] loss: 1.039
[50,     3] loss: 1.263
[51,     3] loss: 1.020
[52,     3] loss: 1.126
[53,     3] loss: 0.999
[54,     3] loss: 0.996
[55,     3] loss: 0.961
[56,     3] loss: 1.099
[57,     3] loss: 0.982
[58,     3] loss: 0.965
[59,     3] loss: 0.878
[60,     3] loss: 0.922
[61,     3] loss: 0.856
[62,     3] loss: 0.852
[63,     3] loss: 1.428
[64,     3] loss: 1.120
[65,     3] loss: 1.141
[66,     3] loss: 1.209
[67,     3] loss: 1.187
[68,     3] loss: 1.159
[69,     3] loss: 1.055
[70,     3] loss: 0.984
[71,     3] loss: 0.972
[72,     3] loss: 0.992
[73,     3] loss: 0.949
[74,     3] loss: 0.981
Early stopping applied (best metric=0.49382486939430237)
Finished Training
Total time taken: 16.45710062980652
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.385
[3,     3] loss: 1.387
[4,     3] loss: 1.378
[5,     3] loss: 1.379
[6,     3] loss: 1.421
[7,     3] loss: 1.380
[8,     3] loss: 1.385
[9,     3] loss: 1.394
[10,     3] loss: 1.389
[11,     3] loss: 1.386
[12,     3] loss: 1.389
[13,     3] loss: 1.380
[14,     3] loss: 1.359
[15,     3] loss: 1.343
[16,     3] loss: 1.285
[17,     3] loss: 1.292
[18,     3] loss: 1.320
[19,     3] loss: 1.204
[20,     3] loss: 1.198
[21,     3] loss: 1.131
[22,     3] loss: 1.193
[23,     3] loss: 1.165
[24,     3] loss: 1.136
[25,     3] loss: 1.042
[26,     3] loss: 1.171
[27,     3] loss: 1.058
[28,     3] loss: 1.086
[29,     3] loss: 0.935
[30,     3] loss: 0.997
[31,     3] loss: 0.972
[32,     3] loss: 0.969
[33,     3] loss: 0.975
[34,     3] loss: 1.046
[35,     3] loss: 1.021
[36,     3] loss: 0.994
[37,     3] loss: 0.897
[38,     3] loss: 0.837
[39,     3] loss: 0.884
[40,     3] loss: 0.798
[41,     3] loss: 0.836
[42,     3] loss: 0.774
[43,     3] loss: 0.951
[44,     3] loss: 1.059
[45,     3] loss: 1.113
[46,     3] loss: 1.018
[47,     3] loss: 1.068
[48,     3] loss: 0.973
[49,     3] loss: 0.903
[50,     3] loss: 0.884
[51,     3] loss: 0.872
[52,     3] loss: 0.788
[53,     3] loss: 1.071
[54,     3] loss: 0.851
[55,     3] loss: 0.843
[56,     3] loss: 0.886
[57,     3] loss: 0.771
[58,     3] loss: 0.784
[59,     3] loss: 1.033
[60,     3] loss: 0.941
[61,     3] loss: 0.883
[62,     3] loss: 0.961
[63,     3] loss: 0.823
[64,     3] loss: 0.796
[65,     3] loss: 0.779
[66,     3] loss: 0.813
[67,     3] loss: 0.767
[68,     3] loss: 1.090
[69,     3] loss: 0.982
[70,     3] loss: 0.989
[71,     3] loss: 0.930
[72,     3] loss: 0.946
[73,     3] loss: 0.976
[74,     3] loss: 0.913
[75,     3] loss: 1.070
Early stopping applied (best metric=0.5391266345977783)
Finished Training
Total time taken: 16.75005865097046
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.383
[3,     3] loss: 1.380
[4,     3] loss: 1.403
[5,     3] loss: 1.395
[6,     3] loss: 1.384
[7,     3] loss: 1.377
[8,     3] loss: 1.384
[9,     3] loss: 1.366
[10,     3] loss: 1.326
[11,     3] loss: 1.284
[12,     3] loss: 1.225
[13,     3] loss: 1.165
[14,     3] loss: 1.194
[15,     3] loss: 1.122
[16,     3] loss: 1.102
[17,     3] loss: 1.045
[18,     3] loss: 1.151
[19,     3] loss: 1.307
[20,     3] loss: 1.166
[21,     3] loss: 1.210
[22,     3] loss: 1.188
[23,     3] loss: 1.023
[24,     3] loss: 1.003
[25,     3] loss: 1.010
[26,     3] loss: 0.870
[27,     3] loss: 0.841
[28,     3] loss: 0.910
[29,     3] loss: 0.953
[30,     3] loss: 0.880
[31,     3] loss: 0.988
[32,     3] loss: 1.080
[33,     3] loss: 1.162
[34,     3] loss: 1.067
[35,     3] loss: 1.025
[36,     3] loss: 0.879
[37,     3] loss: 1.198
[38,     3] loss: 1.015
[39,     3] loss: 1.121
[40,     3] loss: 1.059
[41,     3] loss: 0.923
[42,     3] loss: 1.019
[43,     3] loss: 0.904
[44,     3] loss: 0.868
[45,     3] loss: 0.824
[46,     3] loss: 0.811
[47,     3] loss: 0.819
[48,     3] loss: 0.774
[49,     3] loss: 0.783
[50,     3] loss: 0.910
[51,     3] loss: 1.591
[52,     3] loss: 1.256
[53,     3] loss: 1.355
[54,     3] loss: 1.304
[55,     3] loss: 1.315
[56,     3] loss: 1.268
[57,     3] loss: 1.224
[58,     3] loss: 1.150
[59,     3] loss: 1.128
[60,     3] loss: 1.117
[61,     3] loss: 1.184
[62,     3] loss: 1.165
[63,     3] loss: 1.060
[64,     3] loss: 1.019
[65,     3] loss: 0.952
[66,     3] loss: 1.153
Early stopping applied (best metric=0.5475150942802429)
Finished Training
Total time taken: 14.668049335479736
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.389
[3,     3] loss: 1.393
[4,     3] loss: 1.387
[5,     3] loss: 1.384
[6,     3] loss: 1.379
[7,     3] loss: 1.384
[8,     3] loss: 1.360
[9,     3] loss: 1.323
[10,     3] loss: 1.282
[11,     3] loss: 1.239
[12,     3] loss: 1.163
[13,     3] loss: 1.145
[14,     3] loss: 1.100
[15,     3] loss: 0.986
[16,     3] loss: 0.952
[17,     3] loss: 1.018
[18,     3] loss: 1.157
[19,     3] loss: 1.076
[20,     3] loss: 1.056
[21,     3] loss: 1.060
[22,     3] loss: 0.985
[23,     3] loss: 0.991
[24,     3] loss: 1.008
[25,     3] loss: 1.249
[26,     3] loss: 1.150
[27,     3] loss: 1.169
[28,     3] loss: 1.117
[29,     3] loss: 1.003
[30,     3] loss: 1.019
[31,     3] loss: 0.988
[32,     3] loss: 0.953
[33,     3] loss: 0.871
[34,     3] loss: 0.888
[35,     3] loss: 1.056
[36,     3] loss: 0.965
[37,     3] loss: 0.973
[38,     3] loss: 1.057
[39,     3] loss: 0.942
[40,     3] loss: 0.972
[41,     3] loss: 0.946
[42,     3] loss: 0.998
[43,     3] loss: 0.954
[44,     3] loss: 0.945
[45,     3] loss: 0.921
[46,     3] loss: 0.972
[47,     3] loss: 1.004
[48,     3] loss: 0.894
[49,     3] loss: 0.852
[50,     3] loss: 0.915
[51,     3] loss: 0.895
[52,     3] loss: 0.868
[53,     3] loss: 1.006
[54,     3] loss: 1.028
[55,     3] loss: 1.121
[56,     3] loss: 0.997
[57,     3] loss: 0.906
[58,     3] loss: 1.163
[59,     3] loss: 1.324
[60,     3] loss: 1.234
[61,     3] loss: 1.267
[62,     3] loss: 1.264
[63,     3] loss: 1.208
[64,     3] loss: 1.229
[65,     3] loss: 1.081
[66,     3] loss: 1.041
Early stopping applied (best metric=0.5353595614433289)
Finished Training
Total time taken: 14.763038635253906
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.388
[3,     3] loss: 1.391
[4,     3] loss: 1.380
[5,     3] loss: 1.386
[6,     3] loss: 1.385
[7,     3] loss: 1.380
[8,     3] loss: 1.377
[9,     3] loss: 1.348
[10,     3] loss: 1.329
[11,     3] loss: 1.333
[12,     3] loss: 1.211
[13,     3] loss: 1.247
[14,     3] loss: 1.227
[15,     3] loss: 1.224
[16,     3] loss: 1.190
[17,     3] loss: 1.218
[18,     3] loss: 1.198
[19,     3] loss: 1.270
[20,     3] loss: 1.131
[21,     3] loss: 1.143
[22,     3] loss: 1.101
[23,     3] loss: 0.958
[24,     3] loss: 1.174
[25,     3] loss: 1.106
[26,     3] loss: 1.035
[27,     3] loss: 1.020
[28,     3] loss: 0.942
[29,     3] loss: 0.848
[30,     3] loss: 0.947
[31,     3] loss: 1.235
[32,     3] loss: 1.004
[33,     3] loss: 1.133
[34,     3] loss: 1.047
[35,     3] loss: 1.006
[36,     3] loss: 1.003
[37,     3] loss: 0.894
[38,     3] loss: 0.936
[39,     3] loss: 1.006
[40,     3] loss: 0.939
[41,     3] loss: 0.960
[42,     3] loss: 0.957
[43,     3] loss: 1.014
[44,     3] loss: 0.978
[45,     3] loss: 0.891
[46,     3] loss: 0.865
[47,     3] loss: 0.980
[48,     3] loss: 0.910
[49,     3] loss: 1.162
[50,     3] loss: 1.165
[51,     3] loss: 1.087
[52,     3] loss: 1.016
[53,     3] loss: 0.957
[54,     3] loss: 0.925
[55,     3] loss: 0.865
[56,     3] loss: 0.917
[57,     3] loss: 1.299
[58,     3] loss: 1.119
[59,     3] loss: 1.101
[60,     3] loss: 1.083
[61,     3] loss: 1.028
[62,     3] loss: 0.943
[63,     3] loss: 0.992
Early stopping applied (best metric=0.48109275102615356)
Finished Training
Total time taken: 13.99905014038086
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.403
[3,     3] loss: 1.389
[4,     3] loss: 1.377
[5,     3] loss: 1.393
[6,     3] loss: 1.397
[7,     3] loss: 1.389
[8,     3] loss: 1.355
[9,     3] loss: 1.321
[10,     3] loss: 1.287
[11,     3] loss: 1.136
[12,     3] loss: 1.156
[13,     3] loss: 1.241
[14,     3] loss: 1.227
[15,     3] loss: 1.169
[16,     3] loss: 1.171
[17,     3] loss: 1.193
[18,     3] loss: 1.113
[19,     3] loss: 1.068
[20,     3] loss: 1.039
[21,     3] loss: 0.967
[22,     3] loss: 0.954
[23,     3] loss: 1.210
[24,     3] loss: 1.150
[25,     3] loss: 1.197
[26,     3] loss: 1.125
[27,     3] loss: 1.141
[28,     3] loss: 1.035
[29,     3] loss: 0.997
[30,     3] loss: 0.981
[31,     3] loss: 0.964
[32,     3] loss: 1.009
[33,     3] loss: 0.957
[34,     3] loss: 1.092
[35,     3] loss: 0.986
[36,     3] loss: 1.003
[37,     3] loss: 0.962
[38,     3] loss: 0.945
[39,     3] loss: 0.856
[40,     3] loss: 0.842
[41,     3] loss: 1.262
[42,     3] loss: 1.235
[43,     3] loss: 1.263
[44,     3] loss: 1.287
[45,     3] loss: 1.277
[46,     3] loss: 1.211
[47,     3] loss: 1.141
[48,     3] loss: 1.067
[49,     3] loss: 0.945
[50,     3] loss: 1.089
[51,     3] loss: 1.159
[52,     3] loss: 1.061
[53,     3] loss: 1.069
[54,     3] loss: 1.118
[55,     3] loss: 1.073
[56,     3] loss: 1.040
[57,     3] loss: 0.959
[58,     3] loss: 1.185
[59,     3] loss: 1.046
[60,     3] loss: 1.006
[61,     3] loss: 0.926
[62,     3] loss: 0.957
[63,     3] loss: 1.013
[64,     3] loss: 0.927
[65,     3] loss: 1.041
[66,     3] loss: 0.985
[67,     3] loss: 1.019
[68,     3] loss: 1.004
[69,     3] loss: 1.011
Early stopping applied (best metric=0.530867874622345)
Finished Training
Total time taken: 15.508041143417358
{'S-palmitoylation-C Validation Accuracy': 0.6162610614357339, 'S-palmitoylation-C Validation Sensitivity': 0.36145214521452146, 'S-palmitoylation-C Validation Specificity': 0.6801344927936208, 'S-palmitoylation-C Validation Precision': 0.2250227241933493, 'S-palmitoylation-C AUC ROC': 0.5290864482571178, 'S-palmitoylation-C AUC PR': 0.2185021711182383, 'S-palmitoylation-C MCC': 0.03761361482702745, 'S-palmitoylation-C F1': 0.26513955098156444, 'Validation Loss (S-palmitoylation-C)': 0.5542936563491822, 'Hydroxylation-K Validation Accuracy': 0.6147458628841608, 'Hydroxylation-K Validation Sensitivity': 0.8148148148148148, 'Hydroxylation-K Validation Specificity': 0.5649122807017544, 'Hydroxylation-K Validation Precision': 0.32738350804673283, 'Hydroxylation-K AUC ROC': 0.8089863547758285, 'Hydroxylation-K AUC PR': 0.5863801727824731, 'Hydroxylation-K MCC': 0.3126654899372262, 'Hydroxylation-K F1': 0.4622902175135153, 'Validation Loss (Hydroxylation-K)': 0.5213826557000478, 'Validation Loss (total)': 1.0756763060887655, 'TimeToTrain': 16.4229296207428}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00033661423966999885,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4802048238879609,
 'loss_weight_S-palmitoylation-C': 0.8826071531081485,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1169645412,
 'sample_weights': [0.02553158465918537, 0.20092823584802144],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2101225523353687,
 'weight_decay_Hydroxylation-K': 0.2537878043838439,
 'weight_decay_S-palmitoylation-C': 1.1842841612842507}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.383
[3,     3] loss: 1.384
[4,     3] loss: 1.385
[5,     3] loss: 1.387
[6,     3] loss: 1.384
[7,     3] loss: 1.387
[8,     3] loss: 1.379
[9,     3] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004500114333354714,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6849533761641061,
 'loss_weight_S-palmitoylation-C': 0.3109186194802949,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3987062767,
 'sample_weights': [0.8826071531081485, 0.4802048238879609],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9065977026700796,
 'weight_decay_Hydroxylation-K': 0.0700661241150744,
 'weight_decay_S-palmitoylation-C': 3.693381786185375}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.393
[3,     3] loss: 1.394
[4,     3] loss: 1.395
[5,     3] loss: 1.389
[6,     3] loss: 1.384
[7,     3] loss: 1.383
[8,     3] loss: 1.388
[9,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018429992308691963,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2699908826002452,
 'loss_weight_S-palmitoylation-C': 0.5353678031739899,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 463531583,
 'sample_weights': [0.3109186194802949, 0.6849533761641061],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.844126420370458,
 'weight_decay_Hydroxylation-K': 0.331446041940753,
 'weight_decay_S-palmitoylation-C': 3.728193253550268}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.380
[3,     3] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00855252555284392,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9749655127928445,
 'loss_weight_S-palmitoylation-C': 0.021530293218710528,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 552717297,
 'sample_weights': [0.5353678031739899, 0.2699908826002452],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.245468491415123,
 'weight_decay_Hydroxylation-K': 9.892699249354028,
 'weight_decay_S-palmitoylation-C': 9.355767038257252}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.394
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00085544798388417,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3514343449261583,
 'loss_weight_S-palmitoylation-C': 0.9890571597076063,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3202999773,
 'sample_weights': [0.021530293218710528, 0.9749655127928445],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.417309488270979,
 'weight_decay_Hydroxylation-K': 5.658866059415901,
 'weight_decay_S-palmitoylation-C': 7.88526350746757}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.386
[3,     3] loss: 1.387
[4,     3] loss: 1.383
[5,     3] loss: 1.385
[6,     3] loss: 1.378
[7,     3] loss: 1.365
[8,     3] loss: 1.383
[9,     3] loss: 1.359
[10,     3] loss: 1.366
[11,     3] loss: 1.319
[12,     3] loss: 1.304
[13,     3] loss: 1.316
[14,     3] loss: 1.308
[15,     3] loss: 1.280
[16,     3] loss: 1.204
[17,     3] loss: 1.257
[18,     3] loss: 1.160
[19,     3] loss: 1.164
[20,     3] loss: 1.182
[21,     3] loss: 1.191
[22,     3] loss: 1.148
[23,     3] loss: 1.060
[24,     3] loss: 1.125
[25,     3] loss: 1.012
[26,     3] loss: 0.989
[27,     3] loss: 1.013
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00388616793582366,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6481970573397077,
 'loss_weight_S-palmitoylation-C': 0.16742231170939267,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 382392223,
 'sample_weights': [0.9890571597076063, 0.3514343449261583],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.411611412805102,
 'weight_decay_Hydroxylation-K': 3.406501346683423,
 'weight_decay_S-palmitoylation-C': 4.595051061750382}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.387
[3,     3] loss: 1.366
[4,     3] loss: 1.386
[5,     3] loss: 1.381
[6,     3] loss: 1.393
[7,     3] loss: 1.387
[8,     3] loss: 1.382
[9,     3] loss: 1.371
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0036607621619137052,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.20276659355489848,
 'loss_weight_S-palmitoylation-C': 0.9334808938323651,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 340084317,
 'sample_weights': [0.16742231170939267, 0.6481970573397077],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.42859659593471133,
 'weight_decay_Hydroxylation-K': 1.5926761554134197,
 'weight_decay_S-palmitoylation-C': 0.030165875066654798}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.367
[3,     3] loss: 1.401
[4,     3] loss: 1.396
[5,     3] loss: 1.389
[6,     3] loss: 1.386
[7,     3] loss: 1.385
[8,     3] loss: 1.389
[9,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00041454575761367654,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.13100906546347568,
 'loss_weight_S-palmitoylation-C': 0.010238327832371288,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4166220535,
 'sample_weights': [0.9334808938323651, 0.20276659355489848],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.9050770035733047,
 'weight_decay_Hydroxylation-K': 7.630665507238842,
 'weight_decay_S-palmitoylation-C': 7.3939621789035135}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.390
[3,     3] loss: 1.386
[4,     3] loss: 1.384
[5,     3] loss: 1.384
[6,     3] loss: 1.378
[7,     3] loss: 1.379
[8,     3] loss: 1.375
[9,     3] loss: 1.366
[10,     3] loss: 1.367
[11,     3] loss: 1.360
[12,     3] loss: 1.348
[13,     3] loss: 1.341
[14,     3] loss: 1.335
[15,     3] loss: 1.327
[16,     3] loss: 1.305
[17,     3] loss: 1.299
[18,     3] loss: 1.270
[19,     3] loss: 1.234
[20,     3] loss: 1.256
[21,     3] loss: 1.223
[22,     3] loss: 1.197
[23,     3] loss: 1.142
[24,     3] loss: 1.193
[25,     3] loss: 1.139
[26,     3] loss: 1.129
[27,     3] loss: 1.101
[28,     3] loss: 1.092
[29,     3] loss: 1.148
[30,     3] loss: 1.097
[31,     3] loss: 1.062
[32,     3] loss: 1.133
[33,     3] loss: 1.017
[34,     3] loss: 0.967
[35,     3] loss: 1.060
[36,     3] loss: 0.930
[37,     3] loss: 0.981
[38,     3] loss: 0.976
[39,     3] loss: 0.893
[40,     3] loss: 1.002
[41,     3] loss: 0.879
[42,     3] loss: 0.898
[43,     3] loss: 0.935
[44,     3] loss: 0.935
[45,     3] loss: 0.850
[46,     3] loss: 0.921
[47,     3] loss: 0.864
[48,     3] loss: 0.961
[49,     3] loss: 0.918
[50,     3] loss: 0.863
[51,     3] loss: 0.954
[52,     3] loss: 0.944
[53,     3] loss: 1.011
[54,     3] loss: 0.864
[55,     3] loss: 0.875
[56,     3] loss: 0.902
[57,     3] loss: 0.851
[58,     3] loss: 0.863
[59,     3] loss: 0.866
[60,     3] loss: 0.852
[61,     3] loss: 0.835
[62,     3] loss: 0.850
[63,     3] loss: 0.872
[64,     3] loss: 0.922
[65,     3] loss: 0.835
[66,     3] loss: 0.809
[67,     3] loss: 0.861
[68,     3] loss: 0.899
[69,     3] loss: 0.942
[70,     3] loss: 0.863
[71,     3] loss: 0.838
[72,     3] loss: 0.827
[73,     3] loss: 0.822
[74,     3] loss: 0.794
[75,     3] loss: 0.871
[76,     3] loss: 0.885
[77,     3] loss: 0.787
[78,     3] loss: 0.820
[79,     3] loss: 0.807
[80,     3] loss: 0.801
[81,     3] loss: 0.800
[82,     3] loss: 0.806
[83,     3] loss: 0.782
[84,     3] loss: 0.835
[85,     3] loss: 0.773
[86,     3] loss: 0.796
[87,     3] loss: 0.756
[88,     3] loss: 0.779
[89,     3] loss: 0.783
[90,     3] loss: 0.832
[91,     3] loss: 0.769
[92,     3] loss: 0.789
[93,     3] loss: 0.770
[94,     3] loss: 0.772
[95,     3] loss: 0.764
[96,     3] loss: 0.752
[97,     3] loss: 0.793
[98,     3] loss: 0.773
Early stopping applied (best metric=0.5251746773719788)
Finished Training
Total time taken: 21.9156494140625
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.384
[3,     3] loss: 1.377
[4,     3] loss: 1.371
[5,     3] loss: 1.379
[6,     3] loss: 1.390
[7,     3] loss: 1.388
[8,     3] loss: 1.381
[9,     3] loss: 1.386
[10,     3] loss: 1.383
[11,     3] loss: 1.375
[12,     3] loss: 1.375
[13,     3] loss: 1.364
[14,     3] loss: 1.351
[15,     3] loss: 1.353
[16,     3] loss: 1.333
[17,     3] loss: 1.340
[18,     3] loss: 1.298
[19,     3] loss: 1.311
[20,     3] loss: 1.240
[21,     3] loss: 1.338
[22,     3] loss: 1.250
[23,     3] loss: 1.242
[24,     3] loss: 1.322
[25,     3] loss: 1.258
[26,     3] loss: 1.159
[27,     3] loss: 1.193
[28,     3] loss: 1.169
[29,     3] loss: 1.183
[30,     3] loss: 1.122
[31,     3] loss: 1.120
[32,     3] loss: 1.081
[33,     3] loss: 1.100
[34,     3] loss: 1.021
[35,     3] loss: 1.119
[36,     3] loss: 1.044
[37,     3] loss: 1.016
[38,     3] loss: 0.997
[39,     3] loss: 0.920
[40,     3] loss: 0.916
[41,     3] loss: 0.928
[42,     3] loss: 0.905
[43,     3] loss: 0.890
[44,     3] loss: 0.989
[45,     3] loss: 0.887
[46,     3] loss: 0.874
[47,     3] loss: 0.926
[48,     3] loss: 0.897
[49,     3] loss: 0.870
[50,     3] loss: 0.881
[51,     3] loss: 0.876
[52,     3] loss: 0.859
[53,     3] loss: 0.903
[54,     3] loss: 0.814
[55,     3] loss: 0.806
[56,     3] loss: 0.790
[57,     3] loss: 0.863
[58,     3] loss: 0.879
[59,     3] loss: 0.814
[60,     3] loss: 0.812
[61,     3] loss: 0.775
[62,     3] loss: 0.794
[63,     3] loss: 0.812
[64,     3] loss: 0.849
[65,     3] loss: 0.785
[66,     3] loss: 0.801
[67,     3] loss: 0.875
[68,     3] loss: 0.766
[69,     3] loss: 0.767
[70,     3] loss: 0.778
[71,     3] loss: 0.757
[72,     3] loss: 0.773
[73,     3] loss: 0.793
[74,     3] loss: 0.803
[75,     3] loss: 0.743
[76,     3] loss: 0.769
[77,     3] loss: 0.774
[78,     3] loss: 0.770
[79,     3] loss: 0.743
[80,     3] loss: 0.854
[81,     3] loss: 0.737
[82,     3] loss: 0.752
[83,     3] loss: 0.743
Early stopping applied (best metric=0.5032758712768555)
Finished Training
Total time taken: 18.49318552017212
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.388
[3,     3] loss: 1.384
[4,     3] loss: 1.380
[5,     3] loss: 1.377
[6,     3] loss: 1.381
[7,     3] loss: 1.385
[8,     3] loss: 1.373
[9,     3] loss: 1.387
[10,     3] loss: 1.371
[11,     3] loss: 1.370
[12,     3] loss: 1.371
[13,     3] loss: 1.364
[14,     3] loss: 1.357
[15,     3] loss: 1.331
[16,     3] loss: 1.315
[17,     3] loss: 1.335
[18,     3] loss: 1.332
[19,     3] loss: 1.317
[20,     3] loss: 1.288
[21,     3] loss: 1.268
[22,     3] loss: 1.231
[23,     3] loss: 1.250
[24,     3] loss: 1.241
[25,     3] loss: 1.165
[26,     3] loss: 1.194
[27,     3] loss: 1.148
[28,     3] loss: 1.131
[29,     3] loss: 1.092
[30,     3] loss: 1.170
[31,     3] loss: 1.077
[32,     3] loss: 1.005
[33,     3] loss: 0.998
[34,     3] loss: 1.043
[35,     3] loss: 1.034
[36,     3] loss: 1.006
[37,     3] loss: 0.963
[38,     3] loss: 0.984
[39,     3] loss: 1.074
[40,     3] loss: 0.953
[41,     3] loss: 1.090
[42,     3] loss: 0.923
[43,     3] loss: 0.950
[44,     3] loss: 1.037
[45,     3] loss: 0.944
[46,     3] loss: 0.953
[47,     3] loss: 0.917
[48,     3] loss: 0.940
[49,     3] loss: 0.864
[50,     3] loss: 0.842
[51,     3] loss: 0.850
[52,     3] loss: 0.845
[53,     3] loss: 0.862
[54,     3] loss: 0.853
[55,     3] loss: 0.835
[56,     3] loss: 0.831
[57,     3] loss: 0.871
[58,     3] loss: 0.813
[59,     3] loss: 0.875
[60,     3] loss: 0.961
[61,     3] loss: 0.911
[62,     3] loss: 0.819
[63,     3] loss: 0.803
[64,     3] loss: 0.796
[65,     3] loss: 0.842
[66,     3] loss: 0.818
[67,     3] loss: 0.795
[68,     3] loss: 0.832
[69,     3] loss: 0.792
[70,     3] loss: 0.819
[71,     3] loss: 0.882
[72,     3] loss: 0.822
[73,     3] loss: 0.764
[74,     3] loss: 0.771
[75,     3] loss: 0.800
[76,     3] loss: 0.772
[77,     3] loss: 0.774
[78,     3] loss: 0.757
[79,     3] loss: 0.783
[80,     3] loss: 0.797
[81,     3] loss: 0.766
[82,     3] loss: 0.872
[83,     3] loss: 0.799
[84,     3] loss: 0.766
[85,     3] loss: 0.764
[86,     3] loss: 0.745
[87,     3] loss: 0.751
[88,     3] loss: 0.765
[89,     3] loss: 0.758
[90,     3] loss: 0.758
[91,     3] loss: 0.726
[92,     3] loss: 0.762
[93,     3] loss: 0.740
[94,     3] loss: 0.728
[95,     3] loss: 0.738
[96,     3] loss: 0.744
[97,     3] loss: 0.739
[98,     3] loss: 0.744
[99,     3] loss: 0.745
[100,     3] loss: 0.736
[101,     3] loss: 0.728
[102,     3] loss: 0.730
[103,     3] loss: 0.751
[104,     3] loss: 0.740
[105,     3] loss: 0.740
[106,     3] loss: 0.725
[107,     3] loss: 0.727
[108,     3] loss: 0.723
[109,     3] loss: 0.738
[110,     3] loss: 0.727
[111,     3] loss: 0.731
Early stopping applied (best metric=0.5366084575653076)
Finished Training
Total time taken: 24.69706892967224
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.392
[3,     3] loss: 1.384
[4,     3] loss: 1.382
[5,     3] loss: 1.385
[6,     3] loss: 1.387
[7,     3] loss: 1.390
[8,     3] loss: 1.382
[9,     3] loss: 1.385
[10,     3] loss: 1.381
[11,     3] loss: 1.374
[12,     3] loss: 1.380
[13,     3] loss: 1.375
[14,     3] loss: 1.380
[15,     3] loss: 1.378
[16,     3] loss: 1.357
[17,     3] loss: 1.351
[18,     3] loss: 1.352
[19,     3] loss: 1.346
[20,     3] loss: 1.344
[21,     3] loss: 1.319
[22,     3] loss: 1.309
[23,     3] loss: 1.291
[24,     3] loss: 1.291
[25,     3] loss: 1.273
[26,     3] loss: 1.235
[27,     3] loss: 1.285
[28,     3] loss: 1.214
[29,     3] loss: 1.188
[30,     3] loss: 1.140
[31,     3] loss: 1.152
[32,     3] loss: 1.149
[33,     3] loss: 1.139
[34,     3] loss: 1.048
[35,     3] loss: 1.136
[36,     3] loss: 1.094
[37,     3] loss: 0.986
[38,     3] loss: 0.999
[39,     3] loss: 1.089
[40,     3] loss: 1.009
[41,     3] loss: 0.962
[42,     3] loss: 1.025
[43,     3] loss: 1.010
[44,     3] loss: 0.905
[45,     3] loss: 0.937
[46,     3] loss: 0.907
[47,     3] loss: 0.909
[48,     3] loss: 0.879
[49,     3] loss: 0.891
[50,     3] loss: 0.848
[51,     3] loss: 0.925
[52,     3] loss: 0.912
[53,     3] loss: 0.861
[54,     3] loss: 0.829
[55,     3] loss: 0.918
[56,     3] loss: 0.850
[57,     3] loss: 0.902
[58,     3] loss: 0.854
[59,     3] loss: 0.803
[60,     3] loss: 0.854
[61,     3] loss: 0.827
[62,     3] loss: 0.852
[63,     3] loss: 0.828
[64,     3] loss: 0.817
[65,     3] loss: 0.808
[66,     3] loss: 0.802
[67,     3] loss: 0.868
[68,     3] loss: 0.781
[69,     3] loss: 0.758
[70,     3] loss: 0.775
[71,     3] loss: 0.797
[72,     3] loss: 0.817
[73,     3] loss: 0.805
[74,     3] loss: 0.843
[75,     3] loss: 0.752
[76,     3] loss: 0.811
[77,     3] loss: 0.853
[78,     3] loss: 0.781
[79,     3] loss: 0.761
[80,     3] loss: 0.882
[81,     3] loss: 0.830
[82,     3] loss: 0.798
[83,     3] loss: 0.785
[84,     3] loss: 0.844
[85,     3] loss: 0.860
Early stopping applied (best metric=0.47746628522872925)
Finished Training
Total time taken: 18.89405131340027
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.387
[3,     3] loss: 1.381
[4,     3] loss: 1.387
[5,     3] loss: 1.381
[6,     3] loss: 1.379
[7,     3] loss: 1.383
[8,     3] loss: 1.376
[9,     3] loss: 1.391
[10,     3] loss: 1.367
[11,     3] loss: 1.364
[12,     3] loss: 1.356
[13,     3] loss: 1.362
[14,     3] loss: 1.356
[15,     3] loss: 1.333
[16,     3] loss: 1.328
[17,     3] loss: 1.282
[18,     3] loss: 1.291
[19,     3] loss: 1.288
[20,     3] loss: 1.272
[21,     3] loss: 1.247
[22,     3] loss: 1.232
[23,     3] loss: 1.205
[24,     3] loss: 1.155
[25,     3] loss: 1.200
[26,     3] loss: 1.172
[27,     3] loss: 1.235
[28,     3] loss: 1.112
[29,     3] loss: 1.115
[30,     3] loss: 1.076
[31,     3] loss: 1.012
[32,     3] loss: 1.097
[33,     3] loss: 1.010
[34,     3] loss: 0.993
[35,     3] loss: 1.043
[36,     3] loss: 1.090
[37,     3] loss: 0.961
[38,     3] loss: 1.075
[39,     3] loss: 1.007
[40,     3] loss: 1.042
[41,     3] loss: 0.877
[42,     3] loss: 0.975
[43,     3] loss: 0.905
[44,     3] loss: 0.926
[45,     3] loss: 0.935
[46,     3] loss: 0.879
[47,     3] loss: 0.866
[48,     3] loss: 0.878
[49,     3] loss: 0.897
[50,     3] loss: 1.013
[51,     3] loss: 0.896
[52,     3] loss: 0.926
[53,     3] loss: 0.863
[54,     3] loss: 0.843
[55,     3] loss: 0.898
[56,     3] loss: 0.848
[57,     3] loss: 0.860
[58,     3] loss: 0.834
[59,     3] loss: 0.824
[60,     3] loss: 0.832
[61,     3] loss: 0.880
[62,     3] loss: 0.791
[63,     3] loss: 0.848
[64,     3] loss: 0.813
[65,     3] loss: 0.802
[66,     3] loss: 0.789
[67,     3] loss: 0.796
[68,     3] loss: 0.792
[69,     3] loss: 0.786
[70,     3] loss: 0.784
[71,     3] loss: 0.809
[72,     3] loss: 0.771
[73,     3] loss: 0.753
[74,     3] loss: 0.761
[75,     3] loss: 0.769
[76,     3] loss: 0.771
[77,     3] loss: 0.802
[78,     3] loss: 0.775
[79,     3] loss: 0.774
[80,     3] loss: 0.803
[81,     3] loss: 0.763
[82,     3] loss: 0.744
[83,     3] loss: 0.744
[84,     3] loss: 0.753
[85,     3] loss: 0.749
[86,     3] loss: 0.755
[87,     3] loss: 0.748
[88,     3] loss: 0.746
[89,     3] loss: 0.785
[90,     3] loss: 0.778
[91,     3] loss: 0.738
[92,     3] loss: 0.739
[93,     3] loss: 0.763
[94,     3] loss: 0.750
[95,     3] loss: 0.738
[96,     3] loss: 0.767
[97,     3] loss: 0.771
[98,     3] loss: 0.757
[99,     3] loss: 0.753
[100,     3] loss: 0.755
[101,     3] loss: 0.738
[102,     3] loss: 0.753
[103,     3] loss: 0.740
Early stopping applied (best metric=0.4957512319087982)
Finished Training
Total time taken: 22.900058031082153
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.387
[4,     3] loss: 1.388
[5,     3] loss: 1.380
[6,     3] loss: 1.386
[7,     3] loss: 1.389
[8,     3] loss: 1.380
[9,     3] loss: 1.373
[10,     3] loss: 1.373
[11,     3] loss: 1.370
[12,     3] loss: 1.356
[13,     3] loss: 1.352
[14,     3] loss: 1.344
[15,     3] loss: 1.326
[16,     3] loss: 1.312
[17,     3] loss: 1.303
[18,     3] loss: 1.260
[19,     3] loss: 1.250
[20,     3] loss: 1.225
[21,     3] loss: 1.232
[22,     3] loss: 1.138
[23,     3] loss: 1.207
[24,     3] loss: 1.187
[25,     3] loss: 1.179
[26,     3] loss: 1.167
[27,     3] loss: 1.112
[28,     3] loss: 1.122
[29,     3] loss: 1.039
[30,     3] loss: 1.088
[31,     3] loss: 1.137
[32,     3] loss: 1.119
[33,     3] loss: 0.991
[34,     3] loss: 1.073
[35,     3] loss: 0.996
[36,     3] loss: 0.995
[37,     3] loss: 0.977
[38,     3] loss: 0.956
[39,     3] loss: 0.942
[40,     3] loss: 0.972
[41,     3] loss: 0.997
[42,     3] loss: 0.921
[43,     3] loss: 0.922
[44,     3] loss: 0.995
[45,     3] loss: 0.951
[46,     3] loss: 0.928
[47,     3] loss: 1.037
[48,     3] loss: 0.961
[49,     3] loss: 0.906
[50,     3] loss: 0.894
[51,     3] loss: 0.902
[52,     3] loss: 0.974
[53,     3] loss: 0.848
[54,     3] loss: 0.897
[55,     3] loss: 0.907
[56,     3] loss: 0.874
[57,     3] loss: 1.068
[58,     3] loss: 0.879
[59,     3] loss: 0.866
[60,     3] loss: 0.858
[61,     3] loss: 0.941
[62,     3] loss: 0.862
[63,     3] loss: 0.883
[64,     3] loss: 0.797
[65,     3] loss: 0.834
[66,     3] loss: 0.841
[67,     3] loss: 0.958
[68,     3] loss: 0.926
[69,     3] loss: 0.850
[70,     3] loss: 0.801
[71,     3] loss: 0.812
[72,     3] loss: 0.889
[73,     3] loss: 0.805
[74,     3] loss: 0.921
[75,     3] loss: 0.888
[76,     3] loss: 0.850
[77,     3] loss: 0.818
[78,     3] loss: 0.835
[79,     3] loss: 0.882
[80,     3] loss: 0.795
[81,     3] loss: 0.989
[82,     3] loss: 0.789
[83,     3] loss: 0.833
[84,     3] loss: 0.838
[85,     3] loss: 0.807
[86,     3] loss: 0.787
[87,     3] loss: 0.818
[88,     3] loss: 0.777
[89,     3] loss: 0.774
[90,     3] loss: 0.796
[91,     3] loss: 0.823
[92,     3] loss: 0.850
[93,     3] loss: 0.802
[94,     3] loss: 0.763
[95,     3] loss: 0.801
[96,     3] loss: 0.766
[97,     3] loss: 0.850
[98,     3] loss: 0.826
[99,     3] loss: 0.865
[100,     3] loss: 0.777
[101,     3] loss: 0.790
[102,     3] loss: 0.809
[103,     3] loss: 0.748
[104,     3] loss: 0.786
[105,     3] loss: 0.789
[106,     3] loss: 0.771
[107,     3] loss: 0.813
[108,     3] loss: 0.751
[109,     3] loss: 0.767
[110,     3] loss: 0.793
[111,     3] loss: 0.775
[112,     3] loss: 0.782
[113,     3] loss: 0.739
[114,     3] loss: 0.781
[115,     3] loss: 0.733
[116,     3] loss: 0.739
[117,     3] loss: 0.755
Early stopping applied (best metric=0.5362509489059448)
Finished Training
Total time taken: 26.15497136116028
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.390
[3,     3] loss: 1.389
[4,     3] loss: 1.391
[5,     3] loss: 1.384
[6,     3] loss: 1.384
[7,     3] loss: 1.388
[8,     3] loss: 1.383
[9,     3] loss: 1.383
[10,     3] loss: 1.380
[11,     3] loss: 1.380
[12,     3] loss: 1.374
[13,     3] loss: 1.376
[14,     3] loss: 1.362
[15,     3] loss: 1.362
[16,     3] loss: 1.362
[17,     3] loss: 1.345
[18,     3] loss: 1.324
[19,     3] loss: 1.327
[20,     3] loss: 1.308
[21,     3] loss: 1.289
[22,     3] loss: 1.259
[23,     3] loss: 1.263
[24,     3] loss: 1.247
[25,     3] loss: 1.229
[26,     3] loss: 1.191
[27,     3] loss: 1.198
[28,     3] loss: 1.158
[29,     3] loss: 1.114
[30,     3] loss: 1.162
[31,     3] loss: 1.097
[32,     3] loss: 1.063
[33,     3] loss: 1.114
[34,     3] loss: 1.018
[35,     3] loss: 1.012
[36,     3] loss: 0.954
[37,     3] loss: 1.004
[38,     3] loss: 1.012
[39,     3] loss: 0.896
[40,     3] loss: 0.907
[41,     3] loss: 0.936
[42,     3] loss: 0.921
[43,     3] loss: 0.885
[44,     3] loss: 0.882
[45,     3] loss: 0.852
[46,     3] loss: 0.952
[47,     3] loss: 0.895
[48,     3] loss: 0.942
[49,     3] loss: 0.958
[50,     3] loss: 0.911
[51,     3] loss: 0.885
[52,     3] loss: 0.877
[53,     3] loss: 0.813
[54,     3] loss: 0.819
[55,     3] loss: 0.926
[56,     3] loss: 0.876
[57,     3] loss: 0.845
[58,     3] loss: 0.826
[59,     3] loss: 0.877
[60,     3] loss: 0.867
[61,     3] loss: 0.860
[62,     3] loss: 0.869
[63,     3] loss: 0.818
[64,     3] loss: 0.831
[65,     3] loss: 0.792
[66,     3] loss: 0.915
[67,     3] loss: 0.785
[68,     3] loss: 0.808
[69,     3] loss: 0.865
[70,     3] loss: 0.794
[71,     3] loss: 0.838
[72,     3] loss: 0.805
[73,     3] loss: 0.819
[74,     3] loss: 0.792
[75,     3] loss: 0.771
[76,     3] loss: 0.778
[77,     3] loss: 0.812
[78,     3] loss: 0.754
[79,     3] loss: 0.766
[80,     3] loss: 0.758
[81,     3] loss: 0.792
[82,     3] loss: 0.755
[83,     3] loss: 0.755
[84,     3] loss: 0.751
[85,     3] loss: 0.795
[86,     3] loss: 0.737
[87,     3] loss: 0.768
[88,     3] loss: 0.743
[89,     3] loss: 0.751
[90,     3] loss: 0.737
[91,     3] loss: 0.742
[92,     3] loss: 0.737
[93,     3] loss: 0.738
[94,     3] loss: 0.744
[95,     3] loss: 0.733
Early stopping applied (best metric=0.5441387295722961)
Finished Training
Total time taken: 21.10605502128601
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.386
[3,     3] loss: 1.383
[4,     3] loss: 1.380
[5,     3] loss: 1.383
[6,     3] loss: 1.377
[7,     3] loss: 1.379
[8,     3] loss: 1.376
[9,     3] loss: 1.386
[10,     3] loss: 1.375
[11,     3] loss: 1.367
[12,     3] loss: 1.361
[13,     3] loss: 1.360
[14,     3] loss: 1.344
[15,     3] loss: 1.336
[16,     3] loss: 1.325
[17,     3] loss: 1.340
[18,     3] loss: 1.290
[19,     3] loss: 1.348
[20,     3] loss: 1.288
[21,     3] loss: 1.284
[22,     3] loss: 1.205
[23,     3] loss: 1.239
[24,     3] loss: 1.180
[25,     3] loss: 1.169
[26,     3] loss: 1.127
[27,     3] loss: 1.116
[28,     3] loss: 1.141
[29,     3] loss: 1.067
[30,     3] loss: 1.068
[31,     3] loss: 1.066
[32,     3] loss: 1.049
[33,     3] loss: 1.031
[34,     3] loss: 0.955
[35,     3] loss: 0.965
[36,     3] loss: 0.977
[37,     3] loss: 0.973
[38,     3] loss: 0.940
[39,     3] loss: 0.980
[40,     3] loss: 0.984
[41,     3] loss: 0.932
[42,     3] loss: 0.891
[43,     3] loss: 0.912
[44,     3] loss: 0.919
[45,     3] loss: 0.857
[46,     3] loss: 0.848
[47,     3] loss: 0.871
[48,     3] loss: 1.016
[49,     3] loss: 0.841
[50,     3] loss: 0.921
[51,     3] loss: 0.876
[52,     3] loss: 0.825
[53,     3] loss: 0.840
[54,     3] loss: 0.888
[55,     3] loss: 0.877
[56,     3] loss: 0.805
[57,     3] loss: 0.829
[58,     3] loss: 0.825
[59,     3] loss: 0.808
[60,     3] loss: 0.772
[61,     3] loss: 0.787
[62,     3] loss: 0.795
[63,     3] loss: 0.758
[64,     3] loss: 0.781
[65,     3] loss: 0.803
[66,     3] loss: 0.771
[67,     3] loss: 0.793
[68,     3] loss: 0.750
[69,     3] loss: 0.758
[70,     3] loss: 0.765
[71,     3] loss: 0.756
[72,     3] loss: 0.761
[73,     3] loss: 0.785
[74,     3] loss: 0.744
[75,     3] loss: 0.758
[76,     3] loss: 0.760
[77,     3] loss: 0.784
[78,     3] loss: 0.747
[79,     3] loss: 0.748
[80,     3] loss: 0.765
[81,     3] loss: 0.742
[82,     3] loss: 0.752
[83,     3] loss: 0.783
[84,     3] loss: 0.734
Early stopping applied (best metric=0.5270943641662598)
Finished Training
Total time taken: 18.753053188323975
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.384
[3,     3] loss: 1.390
[4,     3] loss: 1.386
[5,     3] loss: 1.380
[6,     3] loss: 1.384
[7,     3] loss: 1.383
[8,     3] loss: 1.383
[9,     3] loss: 1.377
[10,     3] loss: 1.375
[11,     3] loss: 1.373
[12,     3] loss: 1.365
[13,     3] loss: 1.370
[14,     3] loss: 1.350
[15,     3] loss: 1.334
[16,     3] loss: 1.336
[17,     3] loss: 1.329
[18,     3] loss: 1.299
[19,     3] loss: 1.303
[20,     3] loss: 1.301
[21,     3] loss: 1.250
[22,     3] loss: 1.248
[23,     3] loss: 1.208
[24,     3] loss: 1.174
[25,     3] loss: 1.181
[26,     3] loss: 1.164
[27,     3] loss: 1.162
[28,     3] loss: 1.209
[29,     3] loss: 1.124
[30,     3] loss: 1.112
[31,     3] loss: 1.059
[32,     3] loss: 1.189
[33,     3] loss: 1.002
[34,     3] loss: 1.093
[35,     3] loss: 1.002
[36,     3] loss: 1.000
[37,     3] loss: 0.972
[38,     3] loss: 0.949
[39,     3] loss: 0.965
[40,     3] loss: 0.953
[41,     3] loss: 0.979
[42,     3] loss: 0.960
[43,     3] loss: 0.960
[44,     3] loss: 1.011
[45,     3] loss: 0.947
[46,     3] loss: 0.868
[47,     3] loss: 0.903
[48,     3] loss: 0.897
[49,     3] loss: 0.976
[50,     3] loss: 0.929
[51,     3] loss: 0.836
[52,     3] loss: 0.933
[53,     3] loss: 0.929
[54,     3] loss: 0.913
[55,     3] loss: 0.932
[56,     3] loss: 1.003
[57,     3] loss: 0.798
[58,     3] loss: 0.949
[59,     3] loss: 0.854
[60,     3] loss: 0.978
[61,     3] loss: 0.943
[62,     3] loss: 0.908
[63,     3] loss: 0.872
[64,     3] loss: 0.808
[65,     3] loss: 0.852
[66,     3] loss: 0.877
[67,     3] loss: 0.838
[68,     3] loss: 0.929
[69,     3] loss: 0.814
[70,     3] loss: 0.831
[71,     3] loss: 0.810
[72,     3] loss: 0.848
[73,     3] loss: 0.787
[74,     3] loss: 0.836
[75,     3] loss: 0.872
[76,     3] loss: 0.829
[77,     3] loss: 0.840
[78,     3] loss: 0.823
[79,     3] loss: 0.843
[80,     3] loss: 0.845
[81,     3] loss: 0.815
[82,     3] loss: 0.847
[83,     3] loss: 0.823
[84,     3] loss: 0.875
[85,     3] loss: 0.807
[86,     3] loss: 0.801
[87,     3] loss: 0.812
[88,     3] loss: 0.904
[89,     3] loss: 0.774
[90,     3] loss: 0.825
[91,     3] loss: 0.797
[92,     3] loss: 0.824
[93,     3] loss: 0.803
[94,     3] loss: 0.810
Early stopping applied (best metric=0.5029453635215759)
Finished Training
Total time taken: 20.98505663871765
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.387
[3,     3] loss: 1.389
[4,     3] loss: 1.387
[5,     3] loss: 1.385
[6,     3] loss: 1.386
[7,     3] loss: 1.389
[8,     3] loss: 1.384
[9,     3] loss: 1.382
[10,     3] loss: 1.379
[11,     3] loss: 1.379
[12,     3] loss: 1.387
[13,     3] loss: 1.375
[14,     3] loss: 1.368
[15,     3] loss: 1.364
[16,     3] loss: 1.343
[17,     3] loss: 1.337
[18,     3] loss: 1.332
[19,     3] loss: 1.329
[20,     3] loss: 1.296
[21,     3] loss: 1.292
[22,     3] loss: 1.255
[23,     3] loss: 1.255
[24,     3] loss: 1.208
[25,     3] loss: 1.206
[26,     3] loss: 1.178
[27,     3] loss: 1.123
[28,     3] loss: 1.087
[29,     3] loss: 1.051
[30,     3] loss: 1.060
[31,     3] loss: 0.995
[32,     3] loss: 1.039
[33,     3] loss: 1.039
[34,     3] loss: 1.021
[35,     3] loss: 0.946
[36,     3] loss: 0.980
[37,     3] loss: 0.960
[38,     3] loss: 0.893
[39,     3] loss: 0.934
[40,     3] loss: 0.923
[41,     3] loss: 0.894
[42,     3] loss: 0.916
[43,     3] loss: 0.913
[44,     3] loss: 0.884
[45,     3] loss: 0.899
[46,     3] loss: 0.894
[47,     3] loss: 0.953
[48,     3] loss: 0.890
[49,     3] loss: 0.803
[50,     3] loss: 0.816
[51,     3] loss: 0.821
[52,     3] loss: 1.020
[53,     3] loss: 0.839
[54,     3] loss: 0.803
[55,     3] loss: 0.814
[56,     3] loss: 0.849
[57,     3] loss: 0.802
[58,     3] loss: 0.776
[59,     3] loss: 0.789
[60,     3] loss: 0.795
[61,     3] loss: 0.815
[62,     3] loss: 0.779
[63,     3] loss: 0.809
[64,     3] loss: 0.781
[65,     3] loss: 0.801
[66,     3] loss: 0.754
[67,     3] loss: 0.813
[68,     3] loss: 0.802
[69,     3] loss: 0.761
[70,     3] loss: 0.772
[71,     3] loss: 0.768
[72,     3] loss: 0.748
[73,     3] loss: 0.743
[74,     3] loss: 0.757
[75,     3] loss: 0.761
[76,     3] loss: 0.747
[77,     3] loss: 0.753
[78,     3] loss: 0.751
[79,     3] loss: 0.750
[80,     3] loss: 0.743
[81,     3] loss: 0.838
[82,     3] loss: 0.768
[83,     3] loss: 0.770
[84,     3] loss: 0.803
[85,     3] loss: 0.736
[86,     3] loss: 0.763
[87,     3] loss: 0.789
[88,     3] loss: 0.756
[89,     3] loss: 0.812
[90,     3] loss: 0.751
[91,     3] loss: 0.755
[92,     3] loss: 0.825
Early stopping applied (best metric=0.5126184225082397)
Finished Training
Total time taken: 20.476054668426514
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.391
[3,     3] loss: 1.395
[4,     3] loss: 1.384
[5,     3] loss: 1.393
[6,     3] loss: 1.382
[7,     3] loss: 1.388
[8,     3] loss: 1.385
[9,     3] loss: 1.390
[10,     3] loss: 1.385
[11,     3] loss: 1.386
[12,     3] loss: 1.383
[13,     3] loss: 1.372
[14,     3] loss: 1.365
[15,     3] loss: 1.369
[16,     3] loss: 1.376
[17,     3] loss: 1.359
[18,     3] loss: 1.358
[19,     3] loss: 1.346
[20,     3] loss: 1.335
[21,     3] loss: 1.333
[22,     3] loss: 1.313
[23,     3] loss: 1.318
[24,     3] loss: 1.293
[25,     3] loss: 1.272
[26,     3] loss: 1.265
[27,     3] loss: 1.232
[28,     3] loss: 1.221
[29,     3] loss: 1.140
[30,     3] loss: 1.198
[31,     3] loss: 1.134
[32,     3] loss: 1.183
[33,     3] loss: 1.110
[34,     3] loss: 1.139
[35,     3] loss: 1.052
[36,     3] loss: 1.090
[37,     3] loss: 1.082
[38,     3] loss: 1.016
[39,     3] loss: 1.006
[40,     3] loss: 0.969
[41,     3] loss: 1.072
[42,     3] loss: 0.974
[43,     3] loss: 0.932
[44,     3] loss: 0.957
[45,     3] loss: 1.092
[46,     3] loss: 1.106
[47,     3] loss: 1.023
[48,     3] loss: 1.003
[49,     3] loss: 1.024
[50,     3] loss: 1.056
[51,     3] loss: 1.051
[52,     3] loss: 1.085
[53,     3] loss: 1.012
[54,     3] loss: 0.988
[55,     3] loss: 0.975
[56,     3] loss: 1.028
[57,     3] loss: 0.904
[58,     3] loss: 0.998
[59,     3] loss: 0.961
[60,     3] loss: 0.920
[61,     3] loss: 0.893
[62,     3] loss: 0.990
[63,     3] loss: 0.928
[64,     3] loss: 0.923
[65,     3] loss: 0.882
[66,     3] loss: 0.897
[67,     3] loss: 0.916
[68,     3] loss: 0.900
[69,     3] loss: 0.930
[70,     3] loss: 0.900
[71,     3] loss: 0.841
[72,     3] loss: 0.880
[73,     3] loss: 0.816
[74,     3] loss: 0.820
[75,     3] loss: 0.800
[76,     3] loss: 0.870
[77,     3] loss: 0.854
[78,     3] loss: 0.846
[79,     3] loss: 0.872
[80,     3] loss: 0.792
[81,     3] loss: 0.834
[82,     3] loss: 0.844
[83,     3] loss: 0.835
[84,     3] loss: 0.884
[85,     3] loss: 0.920
[86,     3] loss: 0.850
[87,     3] loss: 0.813
[88,     3] loss: 0.812
[89,     3] loss: 0.858
[90,     3] loss: 0.846
[91,     3] loss: 0.801
[92,     3] loss: 0.820
[93,     3] loss: 0.780
Early stopping applied (best metric=0.5217248797416687)
Finished Training
Total time taken: 20.6860568523407
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.387
[3,     3] loss: 1.386
[4,     3] loss: 1.390
[5,     3] loss: 1.384
[6,     3] loss: 1.387
[7,     3] loss: 1.385
[8,     3] loss: 1.387
[9,     3] loss: 1.387
[10,     3] loss: 1.385
[11,     3] loss: 1.383
[12,     3] loss: 1.376
[13,     3] loss: 1.381
[14,     3] loss: 1.379
[15,     3] loss: 1.374
[16,     3] loss: 1.369
[17,     3] loss: 1.364
[18,     3] loss: 1.360
[19,     3] loss: 1.352
[20,     3] loss: 1.356
[21,     3] loss: 1.340
[22,     3] loss: 1.358
[23,     3] loss: 1.327
[24,     3] loss: 1.306
[25,     3] loss: 1.302
[26,     3] loss: 1.271
[27,     3] loss: 1.242
[28,     3] loss: 1.258
[29,     3] loss: 1.228
[30,     3] loss: 1.242
[31,     3] loss: 1.174
[32,     3] loss: 1.191
[33,     3] loss: 1.130
[34,     3] loss: 1.121
[35,     3] loss: 1.082
[36,     3] loss: 1.091
[37,     3] loss: 1.019
[38,     3] loss: 1.018
[39,     3] loss: 1.005
[40,     3] loss: 0.948
[41,     3] loss: 1.042
[42,     3] loss: 1.062
[43,     3] loss: 0.956
[44,     3] loss: 0.895
[45,     3] loss: 0.873
[46,     3] loss: 0.903
[47,     3] loss: 0.931
[48,     3] loss: 0.874
[49,     3] loss: 0.971
[50,     3] loss: 0.845
[51,     3] loss: 0.884
[52,     3] loss: 0.917
[53,     3] loss: 0.867
[54,     3] loss: 0.822
[55,     3] loss: 0.855
[56,     3] loss: 0.798
[57,     3] loss: 0.886
[58,     3] loss: 0.901
[59,     3] loss: 0.844
[60,     3] loss: 0.871
[61,     3] loss: 0.891
[62,     3] loss: 0.894
[63,     3] loss: 0.868
[64,     3] loss: 0.929
[65,     3] loss: 0.834
[66,     3] loss: 0.878
[67,     3] loss: 0.873
[68,     3] loss: 0.818
[69,     3] loss: 0.918
[70,     3] loss: 0.830
[71,     3] loss: 0.844
[72,     3] loss: 0.815
[73,     3] loss: 0.794
[74,     3] loss: 0.848
[75,     3] loss: 0.802
[76,     3] loss: 0.784
[77,     3] loss: 0.894
[78,     3] loss: 0.815
[79,     3] loss: 0.858
[80,     3] loss: 0.790
[81,     3] loss: 0.798
[82,     3] loss: 0.802
[83,     3] loss: 0.882
[84,     3] loss: 0.883
[85,     3] loss: 0.878
[86,     3] loss: 0.795
[87,     3] loss: 0.768
[88,     3] loss: 0.767
[89,     3] loss: 0.758
[90,     3] loss: 0.764
[91,     3] loss: 0.780
[92,     3] loss: 0.757
[93,     3] loss: 0.770
Early stopping applied (best metric=0.5383468270301819)
Finished Training
Total time taken: 20.76571536064148
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.391
[3,     3] loss: 1.381
[4,     3] loss: 1.389
[5,     3] loss: 1.380
[6,     3] loss: 1.387
[7,     3] loss: 1.382
[8,     3] loss: 1.382
[9,     3] loss: 1.386
[10,     3] loss: 1.377
[11,     3] loss: 1.384
[12,     3] loss: 1.375
[13,     3] loss: 1.378
[14,     3] loss: 1.362
[15,     3] loss: 1.360
[16,     3] loss: 1.356
[17,     3] loss: 1.338
[18,     3] loss: 1.322
[19,     3] loss: 1.327
[20,     3] loss: 1.316
[21,     3] loss: 1.291
[22,     3] loss: 1.300
[23,     3] loss: 1.241
[24,     3] loss: 1.212
[25,     3] loss: 1.196
[26,     3] loss: 1.151
[27,     3] loss: 1.188
[28,     3] loss: 1.133
[29,     3] loss: 1.089
[30,     3] loss: 1.103
[31,     3] loss: 1.083
[32,     3] loss: 1.030
[33,     3] loss: 1.030
[34,     3] loss: 1.045
[35,     3] loss: 0.959
[36,     3] loss: 0.992
[37,     3] loss: 0.968
[38,     3] loss: 0.982
[39,     3] loss: 0.973
[40,     3] loss: 0.953
[41,     3] loss: 0.978
[42,     3] loss: 1.054
[43,     3] loss: 1.029
[44,     3] loss: 0.933
[45,     3] loss: 0.894
[46,     3] loss: 0.876
[47,     3] loss: 0.889
[48,     3] loss: 0.860
[49,     3] loss: 0.994
[50,     3] loss: 0.922
[51,     3] loss: 0.878
[52,     3] loss: 0.993
[53,     3] loss: 0.871
[54,     3] loss: 0.847
[55,     3] loss: 0.851
[56,     3] loss: 0.911
[57,     3] loss: 0.856
[58,     3] loss: 0.953
[59,     3] loss: 0.794
[60,     3] loss: 0.800
[61,     3] loss: 0.839
[62,     3] loss: 0.836
[63,     3] loss: 0.811
[64,     3] loss: 0.945
[65,     3] loss: 0.843
[66,     3] loss: 0.896
[67,     3] loss: 0.845
[68,     3] loss: 0.811
[69,     3] loss: 0.944
[70,     3] loss: 0.875
[71,     3] loss: 0.834
[72,     3] loss: 0.808
[73,     3] loss: 0.825
[74,     3] loss: 0.814
[75,     3] loss: 0.933
[76,     3] loss: 0.902
[77,     3] loss: 0.805
[78,     3] loss: 0.812
[79,     3] loss: 0.807
[80,     3] loss: 0.797
[81,     3] loss: 0.851
[82,     3] loss: 0.788
[83,     3] loss: 0.869
[84,     3] loss: 0.780
[85,     3] loss: 0.795
Early stopping applied (best metric=0.5174869894981384)
Finished Training
Total time taken: 19.055051803588867
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.388
[3,     3] loss: 1.386
[4,     3] loss: 1.385
[5,     3] loss: 1.383
[6,     3] loss: 1.391
[7,     3] loss: 1.380
[8,     3] loss: 1.383
[9,     3] loss: 1.381
[10,     3] loss: 1.378
[11,     3] loss: 1.377
[12,     3] loss: 1.375
[13,     3] loss: 1.375
[14,     3] loss: 1.365
[15,     3] loss: 1.354
[16,     3] loss: 1.331
[17,     3] loss: 1.336
[18,     3] loss: 1.342
[19,     3] loss: 1.335
[20,     3] loss: 1.291
[21,     3] loss: 1.282
[22,     3] loss: 1.264
[23,     3] loss: 1.271
[24,     3] loss: 1.211
[25,     3] loss: 1.245
[26,     3] loss: 1.196
[27,     3] loss: 1.175
[28,     3] loss: 1.222
[29,     3] loss: 1.218
[30,     3] loss: 1.187
[31,     3] loss: 1.086
[32,     3] loss: 1.158
[33,     3] loss: 1.056
[34,     3] loss: 1.152
[35,     3] loss: 1.097
[36,     3] loss: 1.009
[37,     3] loss: 1.082
[38,     3] loss: 1.044
[39,     3] loss: 1.124
[40,     3] loss: 0.927
[41,     3] loss: 1.123
[42,     3] loss: 1.039
[43,     3] loss: 1.056
[44,     3] loss: 0.981
[45,     3] loss: 0.941
[46,     3] loss: 0.925
[47,     3] loss: 0.891
[48,     3] loss: 0.936
[49,     3] loss: 0.928
[50,     3] loss: 0.904
[51,     3] loss: 0.899
[52,     3] loss: 0.843
[53,     3] loss: 0.959
[54,     3] loss: 0.928
[55,     3] loss: 0.931
[56,     3] loss: 0.832
[57,     3] loss: 0.869
[58,     3] loss: 0.835
[59,     3] loss: 0.904
[60,     3] loss: 0.802
[61,     3] loss: 0.895
[62,     3] loss: 0.923
[63,     3] loss: 0.888
[64,     3] loss: 0.823
[65,     3] loss: 0.832
[66,     3] loss: 0.838
[67,     3] loss: 0.790
[68,     3] loss: 0.923
[69,     3] loss: 0.838
[70,     3] loss: 0.802
[71,     3] loss: 0.925
[72,     3] loss: 0.873
[73,     3] loss: 0.816
[74,     3] loss: 0.821
[75,     3] loss: 0.779
[76,     3] loss: 0.814
[77,     3] loss: 0.796
[78,     3] loss: 0.830
[79,     3] loss: 0.817
[80,     3] loss: 0.823
[81,     3] loss: 0.875
[82,     3] loss: 0.778
[83,     3] loss: 0.795
[84,     3] loss: 0.780
[85,     3] loss: 0.814
[86,     3] loss: 0.783
[87,     3] loss: 0.762
[88,     3] loss: 0.838
[89,     3] loss: 0.790
[90,     3] loss: 0.805
[91,     3] loss: 0.786
[92,     3] loss: 0.809
[93,     3] loss: 0.823
[94,     3] loss: 0.811
[95,     3] loss: 0.854
[96,     3] loss: 0.771
[97,     3] loss: 0.771
[98,     3] loss: 0.758
[99,     3] loss: 0.754
[100,     3] loss: 0.834
[101,     3] loss: 0.760
[102,     3] loss: 0.764
Early stopping applied (best metric=0.4841952919960022)
Finished Training
Total time taken: 22.78206181526184
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.385
[3,     3] loss: 1.386
[4,     3] loss: 1.383
[5,     3] loss: 1.386
[6,     3] loss: 1.388
[7,     3] loss: 1.382
[8,     3] loss: 1.377
[9,     3] loss: 1.378
[10,     3] loss: 1.377
[11,     3] loss: 1.379
[12,     3] loss: 1.377
[13,     3] loss: 1.366
[14,     3] loss: 1.360
[15,     3] loss: 1.343
[16,     3] loss: 1.347
[17,     3] loss: 1.350
[18,     3] loss: 1.337
[19,     3] loss: 1.340
[20,     3] loss: 1.306
[21,     3] loss: 1.288
[22,     3] loss: 1.324
[23,     3] loss: 1.288
[24,     3] loss: 1.251
[25,     3] loss: 1.245
[26,     3] loss: 1.233
[27,     3] loss: 1.212
[28,     3] loss: 1.160
[29,     3] loss: 1.157
[30,     3] loss: 1.119
[31,     3] loss: 1.071
[32,     3] loss: 1.077
[33,     3] loss: 1.064
[34,     3] loss: 0.999
[35,     3] loss: 0.977
[36,     3] loss: 0.996
[37,     3] loss: 0.967
[38,     3] loss: 0.955
[39,     3] loss: 0.969
[40,     3] loss: 0.915
[41,     3] loss: 0.937
[42,     3] loss: 0.976
[43,     3] loss: 0.934
[44,     3] loss: 0.916
[45,     3] loss: 0.898
[46,     3] loss: 0.936
[47,     3] loss: 0.874
[48,     3] loss: 0.905
[49,     3] loss: 0.866
[50,     3] loss: 0.967
[51,     3] loss: 1.012
[52,     3] loss: 0.892
[53,     3] loss: 0.932
[54,     3] loss: 0.878
[55,     3] loss: 1.055
[56,     3] loss: 1.005
[57,     3] loss: 0.891
[58,     3] loss: 0.877
[59,     3] loss: 0.906
[60,     3] loss: 0.868
[61,     3] loss: 0.848
[62,     3] loss: 0.909
[63,     3] loss: 0.833
[64,     3] loss: 0.947
[65,     3] loss: 0.852
[66,     3] loss: 0.803
[67,     3] loss: 0.810
[68,     3] loss: 0.806
[69,     3] loss: 0.835
[70,     3] loss: 0.813
[71,     3] loss: 0.806
[72,     3] loss: 0.780
[73,     3] loss: 0.839
[74,     3] loss: 0.778
[75,     3] loss: 0.782
[76,     3] loss: 0.796
[77,     3] loss: 0.775
[78,     3] loss: 0.789
[79,     3] loss: 0.765
[80,     3] loss: 0.818
[81,     3] loss: 0.828
[82,     3] loss: 0.784
[83,     3] loss: 0.814
[84,     3] loss: 0.802
[85,     3] loss: 0.851
[86,     3] loss: 0.763
[87,     3] loss: 0.830
[88,     3] loss: 0.764
[89,     3] loss: 0.768
[90,     3] loss: 0.805
[91,     3] loss: 0.787
[92,     3] loss: 0.744
[93,     3] loss: 0.776
[94,     3] loss: 0.766
[95,     3] loss: 0.755
[96,     3] loss: 0.758
[97,     3] loss: 0.835
[98,     3] loss: 0.786
[99,     3] loss: 0.846
[100,     3] loss: 0.785
Early stopping applied (best metric=0.4918007254600525)
Finished Training
Total time taken: 22.270059823989868
{'S-palmitoylation-C Validation Accuracy': 0.7179987334354146, 'S-palmitoylation-C Validation Sensitivity': 0.19221122112211222, 'S-palmitoylation-C Validation Specificity': 0.8497983265199845, 'S-palmitoylation-C Validation Precision': 0.24749144496601694, 'S-palmitoylation-C AUC ROC': 0.5404909229558955, 'S-palmitoylation-C AUC PR': 0.22542770645237284, 'S-palmitoylation-C MCC': 0.047407098140338534, 'S-palmitoylation-C F1': 0.20746827793256695, 'Validation Loss (S-palmitoylation-C)': 0.5542151888211568, 'Hydroxylation-K Validation Accuracy': 0.7593676122931442, 'Hydroxylation-K Validation Sensitivity': 0.7237037037037037, 'Hydroxylation-K Validation Specificity': 0.7684210526315789, 'Hydroxylation-K Validation Precision': 0.44602426440661735, 'Hydroxylation-K AUC ROC': 0.8198440545808967, 'Hydroxylation-K AUC PR': 0.5973916909947828, 'Hydroxylation-K MCC': 0.4230881736544838, 'Hydroxylation-K F1': 0.5460655257973237, 'Validation Loss (Hydroxylation-K)': 0.5143252710501353, 'Validation Loss (total)': 1.0685404618581136, 'TimeToTrain': 21.328943316141764}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0034562849148562194,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6512785796708075,
 'loss_weight_S-palmitoylation-C': 0.3825758248509605,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2321311009,
 'sample_weights': [0.010238327832371288, 0.13100906546347568],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.806480955322197,
 'weight_decay_Hydroxylation-K': 0.10713176445533945,
 'weight_decay_S-palmitoylation-C': 1.243320887455089}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.391
[3,     3] loss: 1.386
[4,     3] loss: 1.396
[5,     3] loss: 1.380
[6,     3] loss: 1.382
[7,     3] loss: 1.390
[8,     3] loss: 1.384
[9,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004540295658145856,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8339931013017918,
 'loss_weight_S-palmitoylation-C': 0.44259629492467845,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 803785209,
 'sample_weights': [0.3825758248509605, 0.6512785796708075],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.430606352905876,
 'weight_decay_Hydroxylation-K': 1.1746335034185162,
 'weight_decay_S-palmitoylation-C': 3.358332423206835}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.375
[3,     3] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003245343117762714,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2779014529969388,
 'loss_weight_S-palmitoylation-C': 0.7038366215934331,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1994173012,
 'sample_weights': [0.44259629492467845, 0.8339931013017918],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.90877841580775,
 'weight_decay_Hydroxylation-K': 0.9678162875747018,
 'weight_decay_S-palmitoylation-C': 4.731922022203216}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.392
[3,     3] loss: 1.393
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0061817518917052965,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.41385543275203795,
 'loss_weight_S-palmitoylation-C': 0.24198452737635068,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 628381168,
 'sample_weights': [0.7038366215934331, 0.2779014529969388],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.672069771165575,
 'weight_decay_Hydroxylation-K': 2.4765609694248627,
 'weight_decay_S-palmitoylation-C': 1.8820631551753642}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.390
[3,     3] loss: 1.396
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00964636589569268,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7511542535714608,
 'loss_weight_S-palmitoylation-C': 0.4358365256537454,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 309267428,
 'sample_weights': [0.24198452737635068, 0.41385543275203795],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.365917531862088,
 'weight_decay_Hydroxylation-K': 4.854714170393914,
 'weight_decay_S-palmitoylation-C': 6.540869905045137}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.380
[2,     3] loss: 1.396
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0036457312522034206,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6893870093783226,
 'loss_weight_S-palmitoylation-C': 0.1672550089168293,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2195367291,
 'sample_weights': [0.4358365256537454, 0.7511542535714608],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.195374205246509,
 'weight_decay_Hydroxylation-K': 1.6058078115373804,
 'weight_decay_S-palmitoylation-C': 3.2233500879145973}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.386
[3,     3] loss: 1.386
[4,     3] loss: 1.384
[5,     3] loss: 1.378
[6,     3] loss: 1.375
[7,     3] loss: 1.389
[8,     3] loss: 1.382
[9,     3] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008393651224341547,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9348032988843691,
 'loss_weight_S-palmitoylation-C': 0.9728490083501975,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3572015030,
 'sample_weights': [0.1672550089168293, 0.6893870093783226],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.9908549123993966,
 'weight_decay_Hydroxylation-K': 0.10977606856646105,
 'weight_decay_S-palmitoylation-C': 2.834463038861002}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.380
[3,     3] loss: 1.398
[4,     3] loss: 1.384
[5,     3] loss: 1.383
[6,     3] loss: 1.385
[7,     3] loss: 1.392
[8,     3] loss: 1.387
[9,     3] loss: 1.399
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017470388571150764,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.06401512958700979,
 'loss_weight_S-palmitoylation-C': 0.033590571033805486,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 83468738,
 'sample_weights': [0.9728490083501975, 0.9348032988843691],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7413092542356117,
 'weight_decay_Hydroxylation-K': 6.830017369437676,
 'weight_decay_S-palmitoylation-C': 9.59651969533159}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.382
[3,     3] loss: 1.383
[4,     3] loss: 1.391
[5,     3] loss: 1.385
[6,     3] loss: 1.385
[7,     3] loss: 1.386
[8,     3] loss: 1.381
[9,     3] loss: 1.380
[10,     3] loss: 1.376
[11,     3] loss: 1.383
[12,     3] loss: 1.384
[13,     3] loss: 1.368
[14,     3] loss: 1.373
[15,     3] loss: 1.358
[16,     3] loss: 1.354
[17,     3] loss: 1.335
[18,     3] loss: 1.309
[19,     3] loss: 1.291
[20,     3] loss: 1.228
[21,     3] loss: 1.200
[22,     3] loss: 1.233
[23,     3] loss: 1.169
[24,     3] loss: 1.147
[25,     3] loss: 1.120
[26,     3] loss: 1.072
[27,     3] loss: 1.024
[28,     3] loss: 1.049
[29,     3] loss: 1.020
[30,     3] loss: 1.020
[31,     3] loss: 0.995
[32,     3] loss: 0.991
[33,     3] loss: 1.094
[34,     3] loss: 1.028
[35,     3] loss: 1.084
[36,     3] loss: 0.952
[37,     3] loss: 0.920
[38,     3] loss: 0.900
[39,     3] loss: 0.963
[40,     3] loss: 0.934
[41,     3] loss: 0.854
[42,     3] loss: 0.851
[43,     3] loss: 0.910
[44,     3] loss: 0.863
[45,     3] loss: 0.809
[46,     3] loss: 0.910
[47,     3] loss: 0.843
[48,     3] loss: 0.850
[49,     3] loss: 0.871
[50,     3] loss: 0.869
[51,     3] loss: 0.882
[52,     3] loss: 0.876
[53,     3] loss: 0.844
[54,     3] loss: 0.807
[55,     3] loss: 0.901
[56,     3] loss: 0.859
[57,     3] loss: 0.969
[58,     3] loss: 0.880
[59,     3] loss: 0.840
[60,     3] loss: 0.858
[61,     3] loss: 0.846
[62,     3] loss: 0.825
[63,     3] loss: 0.783
[64,     3] loss: 0.833
[65,     3] loss: 0.808
[66,     3] loss: 0.771
[67,     3] loss: 0.797
[68,     3] loss: 0.767
[69,     3] loss: 0.797
[70,     3] loss: 0.768
[71,     3] loss: 0.768
[72,     3] loss: 0.812
[73,     3] loss: 0.745
[74,     3] loss: 0.742
[75,     3] loss: 0.742
[76,     3] loss: 0.734
[77,     3] loss: 0.739
[78,     3] loss: 0.742
Early stopping applied (best metric=0.5291756391525269)
Finished Training
Total time taken: 17.344049215316772
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.385
[3,     3] loss: 1.388
[4,     3] loss: 1.386
[5,     3] loss: 1.385
[6,     3] loss: 1.384
[7,     3] loss: 1.383
[8,     3] loss: 1.380
[9,     3] loss: 1.368
[10,     3] loss: 1.376
[11,     3] loss: 1.369
[12,     3] loss: 1.357
[13,     3] loss: 1.339
[14,     3] loss: 1.329
[15,     3] loss: 1.282
[16,     3] loss: 1.283
[17,     3] loss: 1.248
[18,     3] loss: 1.264
[19,     3] loss: 1.294
[20,     3] loss: 1.178
[21,     3] loss: 1.138
[22,     3] loss: 1.195
[23,     3] loss: 1.095
[24,     3] loss: 1.039
[25,     3] loss: 1.074
[26,     3] loss: 0.999
[27,     3] loss: 1.017
[28,     3] loss: 1.080
[29,     3] loss: 0.970
[30,     3] loss: 1.036
[31,     3] loss: 1.067
[32,     3] loss: 0.959
[33,     3] loss: 0.986
[34,     3] loss: 0.970
[35,     3] loss: 1.003
[36,     3] loss: 1.015
[37,     3] loss: 0.895
[38,     3] loss: 0.935
[39,     3] loss: 1.020
[40,     3] loss: 0.960
[41,     3] loss: 0.878
[42,     3] loss: 0.890
[43,     3] loss: 0.826
[44,     3] loss: 0.806
[45,     3] loss: 0.869
[46,     3] loss: 0.859
[47,     3] loss: 0.810
[48,     3] loss: 0.817
[49,     3] loss: 0.817
[50,     3] loss: 0.821
[51,     3] loss: 0.815
[52,     3] loss: 0.825
[53,     3] loss: 0.831
[54,     3] loss: 0.793
[55,     3] loss: 0.823
[56,     3] loss: 0.774
[57,     3] loss: 0.839
[58,     3] loss: 0.966
[59,     3] loss: 0.986
[60,     3] loss: 0.823
[61,     3] loss: 0.889
[62,     3] loss: 0.915
[63,     3] loss: 0.862
[64,     3] loss: 0.853
[65,     3] loss: 0.830
[66,     3] loss: 0.859
[67,     3] loss: 0.797
[68,     3] loss: 0.804
[69,     3] loss: 0.871
[70,     3] loss: 0.792
[71,     3] loss: 0.813
[72,     3] loss: 0.782
[73,     3] loss: 0.824
[74,     3] loss: 0.796
[75,     3] loss: 0.774
[76,     3] loss: 0.764
Early stopping applied (best metric=0.5345579981803894)
Finished Training
Total time taken: 17.00304651260376
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.391
[3,     3] loss: 1.387
[4,     3] loss: 1.382
[5,     3] loss: 1.381
[6,     3] loss: 1.391
[7,     3] loss: 1.382
[8,     3] loss: 1.383
[9,     3] loss: 1.379
[10,     3] loss: 1.379
[11,     3] loss: 1.380
[12,     3] loss: 1.365
[13,     3] loss: 1.359
[14,     3] loss: 1.353
[15,     3] loss: 1.346
[16,     3] loss: 1.334
[17,     3] loss: 1.311
[18,     3] loss: 1.290
[19,     3] loss: 1.245
[20,     3] loss: 1.219
[21,     3] loss: 1.263
[22,     3] loss: 1.103
[23,     3] loss: 1.113
[24,     3] loss: 1.142
[25,     3] loss: 1.082
[26,     3] loss: 1.060
[27,     3] loss: 1.031
[28,     3] loss: 1.112
[29,     3] loss: 0.998
[30,     3] loss: 1.033
[31,     3] loss: 0.921
[32,     3] loss: 0.997
[33,     3] loss: 0.949
[34,     3] loss: 1.009
[35,     3] loss: 0.959
[36,     3] loss: 0.886
[37,     3] loss: 0.980
[38,     3] loss: 0.948
[39,     3] loss: 0.898
[40,     3] loss: 0.925
[41,     3] loss: 0.883
[42,     3] loss: 0.839
[43,     3] loss: 0.994
[44,     3] loss: 0.831
[45,     3] loss: 0.861
[46,     3] loss: 0.857
[47,     3] loss: 0.821
[48,     3] loss: 0.796
[49,     3] loss: 0.808
[50,     3] loss: 0.806
[51,     3] loss: 0.786
[52,     3] loss: 0.800
[53,     3] loss: 0.780
[54,     3] loss: 0.763
[55,     3] loss: 0.896
[56,     3] loss: 0.784
[57,     3] loss: 0.810
[58,     3] loss: 0.787
[59,     3] loss: 0.833
[60,     3] loss: 0.838
[61,     3] loss: 0.826
[62,     3] loss: 0.762
[63,     3] loss: 0.783
[64,     3] loss: 0.755
[65,     3] loss: 0.874
[66,     3] loss: 0.771
[67,     3] loss: 0.761
[68,     3] loss: 0.744
[69,     3] loss: 0.741
[70,     3] loss: 0.742
[71,     3] loss: 0.778
[72,     3] loss: 0.838
[73,     3] loss: 0.758
[74,     3] loss: 0.846
[75,     3] loss: 0.796
[76,     3] loss: 0.771
[77,     3] loss: 0.865
[78,     3] loss: 0.815
[79,     3] loss: 0.799
[80,     3] loss: 0.806
[81,     3] loss: 0.775
[82,     3] loss: 0.788
[83,     3] loss: 0.773
[84,     3] loss: 0.770
[85,     3] loss: 0.745
Early stopping applied (best metric=0.5268412828445435)
Finished Training
Total time taken: 18.950052976608276
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.384
[3,     3] loss: 1.387
[4,     3] loss: 1.385
[5,     3] loss: 1.390
[6,     3] loss: 1.385
[7,     3] loss: 1.384
[8,     3] loss: 1.377
[9,     3] loss: 1.377
[10,     3] loss: 1.377
[11,     3] loss: 1.363
[12,     3] loss: 1.360
[13,     3] loss: 1.338
[14,     3] loss: 1.337
[15,     3] loss: 1.334
[16,     3] loss: 1.292
[17,     3] loss: 1.265
[18,     3] loss: 1.220
[19,     3] loss: 1.251
[20,     3] loss: 1.185
[21,     3] loss: 1.119
[22,     3] loss: 1.235
[23,     3] loss: 1.111
[24,     3] loss: 1.227
[25,     3] loss: 1.108
[26,     3] loss: 1.043
[27,     3] loss: 1.111
[28,     3] loss: 1.001
[29,     3] loss: 1.023
[30,     3] loss: 1.026
[31,     3] loss: 0.993
[32,     3] loss: 1.026
[33,     3] loss: 1.050
[34,     3] loss: 1.200
[35,     3] loss: 1.010
[36,     3] loss: 1.065
[37,     3] loss: 1.048
[38,     3] loss: 1.240
[39,     3] loss: 0.999
[40,     3] loss: 1.014
[41,     3] loss: 0.988
[42,     3] loss: 1.023
[43,     3] loss: 0.980
[44,     3] loss: 0.954
[45,     3] loss: 1.017
[46,     3] loss: 0.906
[47,     3] loss: 0.918
[48,     3] loss: 0.904
[49,     3] loss: 0.925
[50,     3] loss: 0.851
[51,     3] loss: 0.824
[52,     3] loss: 0.814
[53,     3] loss: 0.829
[54,     3] loss: 0.886
[55,     3] loss: 0.875
[56,     3] loss: 0.895
[57,     3] loss: 0.905
[58,     3] loss: 0.844
[59,     3] loss: 0.855
[60,     3] loss: 0.873
[61,     3] loss: 0.879
[62,     3] loss: 0.906
[63,     3] loss: 0.856
[64,     3] loss: 0.793
[65,     3] loss: 0.818
[66,     3] loss: 0.797
[67,     3] loss: 0.834
[68,     3] loss: 0.810
[69,     3] loss: 0.789
[70,     3] loss: 0.786
[71,     3] loss: 0.807
[72,     3] loss: 0.803
[73,     3] loss: 0.772
[74,     3] loss: 0.767
[75,     3] loss: 0.760
[76,     3] loss: 0.774
[77,     3] loss: 0.750
[78,     3] loss: 0.759
Early stopping applied (best metric=0.5148643851280212)
Finished Training
Total time taken: 17.48687982559204
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.389
[3,     3] loss: 1.385
[4,     3] loss: 1.390
[5,     3] loss: 1.379
[6,     3] loss: 1.382
[7,     3] loss: 1.374
[8,     3] loss: 1.380
[9,     3] loss: 1.356
[10,     3] loss: 1.360
[11,     3] loss: 1.346
[12,     3] loss: 1.299
[13,     3] loss: 1.266
[14,     3] loss: 1.292
[15,     3] loss: 1.250
[16,     3] loss: 1.179
[17,     3] loss: 1.176
[18,     3] loss: 1.141
[19,     3] loss: 1.176
[20,     3] loss: 1.125
[21,     3] loss: 1.151
[22,     3] loss: 1.069
[23,     3] loss: 1.109
[24,     3] loss: 1.002
[25,     3] loss: 0.986
[26,     3] loss: 0.946
[27,     3] loss: 1.014
[28,     3] loss: 0.951
[29,     3] loss: 0.987
[30,     3] loss: 0.867
[31,     3] loss: 0.873
[32,     3] loss: 0.883
[33,     3] loss: 0.891
[34,     3] loss: 0.889
[35,     3] loss: 0.888
[36,     3] loss: 0.890
[37,     3] loss: 0.845
[38,     3] loss: 0.807
[39,     3] loss: 0.822
[40,     3] loss: 0.807
[41,     3] loss: 0.945
[42,     3] loss: 0.814
[43,     3] loss: 0.833
[44,     3] loss: 0.820
[45,     3] loss: 0.848
[46,     3] loss: 0.811
[47,     3] loss: 0.866
[48,     3] loss: 0.876
[49,     3] loss: 0.810
[50,     3] loss: 0.863
[51,     3] loss: 0.851
[52,     3] loss: 0.828
[53,     3] loss: 0.860
[54,     3] loss: 0.859
[55,     3] loss: 0.943
[56,     3] loss: 0.815
[57,     3] loss: 0.831
[58,     3] loss: 0.830
[59,     3] loss: 0.872
[60,     3] loss: 0.833
[61,     3] loss: 0.804
[62,     3] loss: 0.802
[63,     3] loss: 0.823
[64,     3] loss: 0.771
[65,     3] loss: 0.776
[66,     3] loss: 0.787
[67,     3] loss: 0.762
[68,     3] loss: 0.780
[69,     3] loss: 0.765
[70,     3] loss: 0.772
Early stopping applied (best metric=0.5206209421157837)
Finished Training
Total time taken: 15.596044301986694
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.390
[3,     3] loss: 1.377
[4,     3] loss: 1.389
[5,     3] loss: 1.373
[6,     3] loss: 1.376
[7,     3] loss: 1.405
[8,     3] loss: 1.386
[9,     3] loss: 1.374
[10,     3] loss: 1.374
[11,     3] loss: 1.371
[12,     3] loss: 1.366
[13,     3] loss: 1.352
[14,     3] loss: 1.331
[15,     3] loss: 1.315
[16,     3] loss: 1.289
[17,     3] loss: 1.297
[18,     3] loss: 1.262
[19,     3] loss: 1.207
[20,     3] loss: 1.201
[21,     3] loss: 1.180
[22,     3] loss: 1.134
[23,     3] loss: 1.113
[24,     3] loss: 1.065
[25,     3] loss: 1.023
[26,     3] loss: 1.067
[27,     3] loss: 0.924
[28,     3] loss: 0.995
[29,     3] loss: 0.915
[30,     3] loss: 0.893
[31,     3] loss: 1.001
[32,     3] loss: 0.993
[33,     3] loss: 1.086
[34,     3] loss: 0.931
[35,     3] loss: 1.049
[36,     3] loss: 0.920
[37,     3] loss: 0.899
[38,     3] loss: 0.880
[39,     3] loss: 0.912
[40,     3] loss: 0.851
[41,     3] loss: 0.857
[42,     3] loss: 0.832
[43,     3] loss: 0.838
[44,     3] loss: 0.842
[45,     3] loss: 0.803
[46,     3] loss: 0.805
[47,     3] loss: 0.819
[48,     3] loss: 0.792
[49,     3] loss: 0.833
[50,     3] loss: 0.784
[51,     3] loss: 0.817
[52,     3] loss: 0.901
[53,     3] loss: 0.770
[54,     3] loss: 0.790
[55,     3] loss: 0.808
[56,     3] loss: 0.781
[57,     3] loss: 0.833
[58,     3] loss: 0.820
[59,     3] loss: 0.867
[60,     3] loss: 0.875
[61,     3] loss: 0.837
[62,     3] loss: 0.808
[63,     3] loss: 0.849
[64,     3] loss: 0.812
[65,     3] loss: 0.770
[66,     3] loss: 0.838
[67,     3] loss: 0.795
[68,     3] loss: 0.780
[69,     3] loss: 0.844
[70,     3] loss: 0.774
[71,     3] loss: 0.803
[72,     3] loss: 0.751
[73,     3] loss: 0.765
[74,     3] loss: 0.760
[75,     3] loss: 0.764
Early stopping applied (best metric=0.5327030420303345)
Finished Training
Total time taken: 16.756046533584595
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.387
[3,     3] loss: 1.388
[4,     3] loss: 1.387
[5,     3] loss: 1.383
[6,     3] loss: 1.388
[7,     3] loss: 1.381
[8,     3] loss: 1.389
[9,     3] loss: 1.387
[10,     3] loss: 1.387
[11,     3] loss: 1.386
[12,     3] loss: 1.389
[13,     3] loss: 1.374
[14,     3] loss: 1.378
[15,     3] loss: 1.360
[16,     3] loss: 1.375
[17,     3] loss: 1.371
[18,     3] loss: 1.348
[19,     3] loss: 1.342
[20,     3] loss: 1.339
[21,     3] loss: 1.313
[22,     3] loss: 1.278
[23,     3] loss: 1.233
[24,     3] loss: 1.273
[25,     3] loss: 1.214
[26,     3] loss: 1.161
[27,     3] loss: 1.142
[28,     3] loss: 1.109
[29,     3] loss: 1.218
[30,     3] loss: 1.046
[31,     3] loss: 1.065
[32,     3] loss: 1.100
[33,     3] loss: 1.087
[34,     3] loss: 1.050
[35,     3] loss: 0.999
[36,     3] loss: 1.013
[37,     3] loss: 0.953
[38,     3] loss: 1.047
[39,     3] loss: 1.004
[40,     3] loss: 1.024
[41,     3] loss: 0.956
[42,     3] loss: 0.994
[43,     3] loss: 0.934
[44,     3] loss: 0.906
[45,     3] loss: 0.882
[46,     3] loss: 0.942
[47,     3] loss: 0.851
[48,     3] loss: 1.026
[49,     3] loss: 0.846
[50,     3] loss: 0.904
[51,     3] loss: 1.000
[52,     3] loss: 0.899
[53,     3] loss: 0.895
[54,     3] loss: 0.861
[55,     3] loss: 0.921
[56,     3] loss: 0.874
[57,     3] loss: 0.866
[58,     3] loss: 0.872
[59,     3] loss: 0.895
[60,     3] loss: 0.858
[61,     3] loss: 0.965
[62,     3] loss: 0.846
[63,     3] loss: 0.853
[64,     3] loss: 0.848
[65,     3] loss: 0.937
[66,     3] loss: 0.952
[67,     3] loss: 0.918
[68,     3] loss: 0.980
[69,     3] loss: 0.914
[70,     3] loss: 0.851
[71,     3] loss: 0.851
[72,     3] loss: 0.850
[73,     3] loss: 0.862
[74,     3] loss: 0.845
[75,     3] loss: 0.856
[76,     3] loss: 0.811
[77,     3] loss: 0.852
[78,     3] loss: 0.900
[79,     3] loss: 0.788
[80,     3] loss: 0.828
[81,     3] loss: 0.870
[82,     3] loss: 0.878
[83,     3] loss: 0.835
[84,     3] loss: 0.812
[85,     3] loss: 0.855
[86,     3] loss: 0.792
[87,     3] loss: 0.760
[88,     3] loss: 0.782
Early stopping applied (best metric=0.5493440628051758)
Finished Training
Total time taken: 19.585533142089844
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.382
[3,     3] loss: 1.385
[4,     3] loss: 1.397
[5,     3] loss: 1.387
[6,     3] loss: 1.382
[7,     3] loss: 1.379
[8,     3] loss: 1.381
[9,     3] loss: 1.378
[10,     3] loss: 1.386
[11,     3] loss: 1.384
[12,     3] loss: 1.379
[13,     3] loss: 1.380
[14,     3] loss: 1.387
[15,     3] loss: 1.377
[16,     3] loss: 1.391
[17,     3] loss: 1.377
[18,     3] loss: 1.376
[19,     3] loss: 1.369
[20,     3] loss: 1.378
[21,     3] loss: 1.378
[22,     3] loss: 1.363
[23,     3] loss: 1.350
[24,     3] loss: 1.331
[25,     3] loss: 1.299
[26,     3] loss: 1.269
[27,     3] loss: 1.288
[28,     3] loss: 1.228
[29,     3] loss: 1.221
[30,     3] loss: 1.245
[31,     3] loss: 1.177
[32,     3] loss: 1.320
[33,     3] loss: 1.164
[34,     3] loss: 1.196
[35,     3] loss: 1.156
[36,     3] loss: 1.081
[37,     3] loss: 1.113
[38,     3] loss: 1.160
[39,     3] loss: 1.088
[40,     3] loss: 1.037
[41,     3] loss: 1.003
[42,     3] loss: 1.035
[43,     3] loss: 1.006
[44,     3] loss: 1.042
[45,     3] loss: 0.995
[46,     3] loss: 1.056
[47,     3] loss: 1.085
[48,     3] loss: 1.020
[49,     3] loss: 1.074
[50,     3] loss: 1.030
[51,     3] loss: 0.974
[52,     3] loss: 0.959
[53,     3] loss: 0.956
[54,     3] loss: 1.017
[55,     3] loss: 1.022
[56,     3] loss: 0.887
[57,     3] loss: 1.004
[58,     3] loss: 0.866
[59,     3] loss: 0.985
[60,     3] loss: 0.994
[61,     3] loss: 0.906
[62,     3] loss: 0.991
[63,     3] loss: 1.010
[64,     3] loss: 0.836
[65,     3] loss: 0.948
[66,     3] loss: 0.974
[67,     3] loss: 0.882
[68,     3] loss: 0.949
[69,     3] loss: 0.833
[70,     3] loss: 0.867
[71,     3] loss: 0.815
[72,     3] loss: 0.833
[73,     3] loss: 0.805
[74,     3] loss: 0.804
[75,     3] loss: 0.775
[76,     3] loss: 0.766
[77,     3] loss: 0.761
[78,     3] loss: 0.771
[79,     3] loss: 0.989
[80,     3] loss: 0.787
[81,     3] loss: 0.782
[82,     3] loss: 1.004
[83,     3] loss: 0.876
[84,     3] loss: 0.971
[85,     3] loss: 0.883
[86,     3] loss: 0.906
[87,     3] loss: 0.900
[88,     3] loss: 0.843
[89,     3] loss: 0.922
[90,     3] loss: 0.856
[91,     3] loss: 0.801
[92,     3] loss: 0.783
[93,     3] loss: 0.785
Early stopping applied (best metric=0.5102083683013916)
Finished Training
Total time taken: 20.83107852935791
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.380
[3,     3] loss: 1.390
[4,     3] loss: 1.396
[5,     3] loss: 1.383
[6,     3] loss: 1.380
[7,     3] loss: 1.377
[8,     3] loss: 1.375
[9,     3] loss: 1.377
[10,     3] loss: 1.358
[11,     3] loss: 1.344
[12,     3] loss: 1.328
[13,     3] loss: 1.290
[14,     3] loss: 1.261
[15,     3] loss: 1.223
[16,     3] loss: 1.128
[17,     3] loss: 1.249
[18,     3] loss: 1.148
[19,     3] loss: 1.131
[20,     3] loss: 1.169
[21,     3] loss: 1.077
[22,     3] loss: 1.100
[23,     3] loss: 1.091
[24,     3] loss: 1.107
[25,     3] loss: 1.088
[26,     3] loss: 1.109
[27,     3] loss: 1.076
[28,     3] loss: 0.974
[29,     3] loss: 0.995
[30,     3] loss: 0.976
[31,     3] loss: 0.913
[32,     3] loss: 0.900
[33,     3] loss: 0.889
[34,     3] loss: 0.912
[35,     3] loss: 0.832
[36,     3] loss: 0.922
[37,     3] loss: 0.998
[38,     3] loss: 0.918
[39,     3] loss: 0.890
[40,     3] loss: 0.931
[41,     3] loss: 0.860
[42,     3] loss: 0.876
[43,     3] loss: 0.866
[44,     3] loss: 0.886
[45,     3] loss: 0.947
[46,     3] loss: 0.920
[47,     3] loss: 0.865
[48,     3] loss: 0.857
[49,     3] loss: 0.908
[50,     3] loss: 0.879
[51,     3] loss: 0.862
[52,     3] loss: 0.858
[53,     3] loss: 0.842
[54,     3] loss: 0.857
[55,     3] loss: 0.812
[56,     3] loss: 0.817
[57,     3] loss: 0.839
[58,     3] loss: 0.843
[59,     3] loss: 0.863
[60,     3] loss: 0.782
[61,     3] loss: 0.809
[62,     3] loss: 0.824
[63,     3] loss: 0.804
[64,     3] loss: 0.872
[65,     3] loss: 0.843
[66,     3] loss: 0.799
[67,     3] loss: 0.834
[68,     3] loss: 0.785
[69,     3] loss: 0.790
[70,     3] loss: 0.796
[71,     3] loss: 0.787
[72,     3] loss: 0.784
[73,     3] loss: 0.778
[74,     3] loss: 0.824
[75,     3] loss: 0.756
[76,     3] loss: 0.779
[77,     3] loss: 0.751
[78,     3] loss: 0.757
[79,     3] loss: 0.754
[80,     3] loss: 0.836
[81,     3] loss: 0.829
[82,     3] loss: 0.911
[83,     3] loss: 0.815
[84,     3] loss: 0.828
[85,     3] loss: 0.867
[86,     3] loss: 0.823
[87,     3] loss: 0.801
[88,     3] loss: 0.852
[89,     3] loss: 0.817
[90,     3] loss: 0.774
[91,     3] loss: 0.782
[92,     3] loss: 0.847
[93,     3] loss: 0.780
[94,     3] loss: 0.798
[95,     3] loss: 0.748
Early stopping applied (best metric=0.5243138074874878)
Finished Training
Total time taken: 21.091071844100952
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.391
[3,     3] loss: 1.375
[4,     3] loss: 1.379
[5,     3] loss: 1.383
[6,     3] loss: 1.385
[7,     3] loss: 1.382
[8,     3] loss: 1.381
[9,     3] loss: 1.374
[10,     3] loss: 1.369
[11,     3] loss: 1.366
[12,     3] loss: 1.345
[13,     3] loss: 1.341
[14,     3] loss: 1.341
[15,     3] loss: 1.297
[16,     3] loss: 1.297
[17,     3] loss: 1.250
[18,     3] loss: 1.292
[19,     3] loss: 1.207
[20,     3] loss: 1.217
[21,     3] loss: 1.110
[22,     3] loss: 1.106
[23,     3] loss: 1.093
[24,     3] loss: 1.027
[25,     3] loss: 1.099
[26,     3] loss: 1.017
[27,     3] loss: 1.133
[28,     3] loss: 1.008
[29,     3] loss: 0.981
[30,     3] loss: 0.985
[31,     3] loss: 1.044
[32,     3] loss: 0.985
[33,     3] loss: 0.905
[34,     3] loss: 0.975
[35,     3] loss: 1.028
[36,     3] loss: 0.934
[37,     3] loss: 0.964
[38,     3] loss: 0.939
[39,     3] loss: 0.924
[40,     3] loss: 0.971
[41,     3] loss: 0.856
[42,     3] loss: 0.955
[43,     3] loss: 0.906
[44,     3] loss: 0.890
[45,     3] loss: 0.833
[46,     3] loss: 0.906
[47,     3] loss: 0.842
[48,     3] loss: 0.915
[49,     3] loss: 0.902
[50,     3] loss: 0.900
[51,     3] loss: 0.882
[52,     3] loss: 0.899
[53,     3] loss: 0.849
[54,     3] loss: 0.841
[55,     3] loss: 0.835
[56,     3] loss: 0.863
[57,     3] loss: 0.851
[58,     3] loss: 0.838
[59,     3] loss: 0.795
[60,     3] loss: 0.829
[61,     3] loss: 0.844
[62,     3] loss: 0.824
[63,     3] loss: 0.868
[64,     3] loss: 0.782
[65,     3] loss: 0.768
[66,     3] loss: 0.822
[67,     3] loss: 0.796
[68,     3] loss: 0.871
[69,     3] loss: 0.783
[70,     3] loss: 0.798
[71,     3] loss: 0.766
[72,     3] loss: 0.854
[73,     3] loss: 0.763
[74,     3] loss: 0.761
[75,     3] loss: 0.822
[76,     3] loss: 0.781
[77,     3] loss: 0.754
[78,     3] loss: 0.742
[79,     3] loss: 0.753
[80,     3] loss: 0.762
[81,     3] loss: 0.757
[82,     3] loss: 0.739
[83,     3] loss: 0.754
[84,     3] loss: 0.778
[85,     3] loss: 0.748
[86,     3] loss: 0.778
[87,     3] loss: 0.769
[88,     3] loss: 0.791
[89,     3] loss: 0.813
[90,     3] loss: 0.769
[91,     3] loss: 0.807
[92,     3] loss: 0.801
[93,     3] loss: 0.812
[94,     3] loss: 0.770
[95,     3] loss: 0.841
[96,     3] loss: 0.777
[97,     3] loss: 0.789
[98,     3] loss: 0.844
[99,     3] loss: 0.784
[100,     3] loss: 0.807
[101,     3] loss: 0.774
[102,     3] loss: 0.803
[103,     3] loss: 0.767
[104,     3] loss: 0.851
[105,     3] loss: 0.791
[106,     3] loss: 0.755
[107,     3] loss: 0.755
[108,     3] loss: 0.766
[109,     3] loss: 0.778
[110,     3] loss: 0.768
[111,     3] loss: 0.766
[112,     3] loss: 0.745
[113,     3] loss: 0.741
[114,     3] loss: 0.742
[115,     3] loss: 0.727
[116,     3] loss: 0.728
[117,     3] loss: 0.741
[118,     3] loss: 0.731
[119,     3] loss: 0.722
[120,     3] loss: 0.726
[121,     3] loss: 0.733
[122,     3] loss: 0.722
[123,     3] loss: 0.745
[124,     3] loss: 0.731
[125,     3] loss: 0.722
[126,     3] loss: 0.721
[127,     3] loss: 0.728
[128,     3] loss: 0.729
[129,     3] loss: 0.720
[130,     3] loss: 0.725
[131,     3] loss: 0.714
[132,     3] loss: 0.714
[133,     3] loss: 0.719
[134,     3] loss: 0.723
[135,     3] loss: 0.740
[136,     3] loss: 0.720
[137,     3] loss: 0.747
[138,     3] loss: 0.718
[139,     3] loss: 0.728
[140,     3] loss: 0.726
[141,     3] loss: 0.724
[142,     3] loss: 0.739
[143,     3] loss: 0.731
[144,     3] loss: 0.720
[145,     3] loss: 0.722
[146,     3] loss: 0.733
[147,     3] loss: 0.720
[148,     3] loss: 0.746
[149,     3] loss: 0.723
Early stopping applied (best metric=0.5176287889480591)
Finished Training
Total time taken: 33.17310357093811
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.381
[3,     3] loss: 1.381
[4,     3] loss: 1.395
[5,     3] loss: 1.388
[6,     3] loss: 1.383
[7,     3] loss: 1.377
[8,     3] loss: 1.383
[9,     3] loss: 1.373
[10,     3] loss: 1.355
[11,     3] loss: 1.369
[12,     3] loss: 1.337
[13,     3] loss: 1.344
[14,     3] loss: 1.302
[15,     3] loss: 1.238
[16,     3] loss: 1.253
[17,     3] loss: 1.216
[18,     3] loss: 1.222
[19,     3] loss: 1.182
[20,     3] loss: 1.176
[21,     3] loss: 1.101
[22,     3] loss: 1.108
[23,     3] loss: 1.105
[24,     3] loss: 1.096
[25,     3] loss: 1.006
[26,     3] loss: 1.054
[27,     3] loss: 1.142
[28,     3] loss: 1.029
[29,     3] loss: 0.997
[30,     3] loss: 0.935
[31,     3] loss: 0.981
[32,     3] loss: 0.886
[33,     3] loss: 1.020
[34,     3] loss: 0.947
[35,     3] loss: 0.914
[36,     3] loss: 0.872
[37,     3] loss: 0.912
[38,     3] loss: 0.874
[39,     3] loss: 0.898
[40,     3] loss: 0.881
[41,     3] loss: 0.837
[42,     3] loss: 0.876
[43,     3] loss: 0.866
[44,     3] loss: 0.837
[45,     3] loss: 0.860
[46,     3] loss: 0.951
[47,     3] loss: 0.835
[48,     3] loss: 0.935
[49,     3] loss: 0.840
[50,     3] loss: 0.991
[51,     3] loss: 0.841
[52,     3] loss: 0.918
[53,     3] loss: 0.854
[54,     3] loss: 0.850
[55,     3] loss: 0.897
[56,     3] loss: 0.849
[57,     3] loss: 0.841
[58,     3] loss: 0.816
[59,     3] loss: 0.849
[60,     3] loss: 0.793
[61,     3] loss: 0.805
[62,     3] loss: 0.800
[63,     3] loss: 0.764
[64,     3] loss: 0.796
[65,     3] loss: 0.807
[66,     3] loss: 0.810
[67,     3] loss: 0.773
[68,     3] loss: 0.828
[69,     3] loss: 0.863
[70,     3] loss: 0.806
[71,     3] loss: 0.763
[72,     3] loss: 0.867
[73,     3] loss: 0.825
[74,     3] loss: 0.831
[75,     3] loss: 0.809
[76,     3] loss: 0.857
[77,     3] loss: 0.823
[78,     3] loss: 0.778
[79,     3] loss: 0.798
[80,     3] loss: 0.790
[81,     3] loss: 0.775
[82,     3] loss: 0.816
[83,     3] loss: 0.767
[84,     3] loss: 0.800
[85,     3] loss: 0.749
[86,     3] loss: 0.793
[87,     3] loss: 0.829
[88,     3] loss: 0.756
[89,     3] loss: 0.745
[90,     3] loss: 0.771
[91,     3] loss: 0.763
[92,     3] loss: 0.748
[93,     3] loss: 0.768
[94,     3] loss: 0.754
[95,     3] loss: 0.784
[96,     3] loss: 0.757
Early stopping applied (best metric=0.5341081619262695)
Finished Training
Total time taken: 21.48906636238098
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.389
[3,     3] loss: 1.389
[4,     3] loss: 1.388
[5,     3] loss: 1.391
[6,     3] loss: 1.384
[7,     3] loss: 1.373
[8,     3] loss: 1.388
[9,     3] loss: 1.379
[10,     3] loss: 1.369
[11,     3] loss: 1.361
[12,     3] loss: 1.346
[13,     3] loss: 1.331
[14,     3] loss: 1.285
[15,     3] loss: 1.300
[16,     3] loss: 1.246
[17,     3] loss: 1.206
[18,     3] loss: 1.243
[19,     3] loss: 1.125
[20,     3] loss: 1.054
[21,     3] loss: 1.068
[22,     3] loss: 1.005
[23,     3] loss: 1.243
[24,     3] loss: 1.100
[25,     3] loss: 1.062
[26,     3] loss: 0.970
[27,     3] loss: 0.994
[28,     3] loss: 1.013
[29,     3] loss: 1.081
[30,     3] loss: 0.960
[31,     3] loss: 0.982
[32,     3] loss: 0.916
[33,     3] loss: 0.981
[34,     3] loss: 0.929
[35,     3] loss: 0.968
[36,     3] loss: 0.876
[37,     3] loss: 0.973
[38,     3] loss: 0.824
[39,     3] loss: 0.977
[40,     3] loss: 0.898
[41,     3] loss: 0.902
[42,     3] loss: 0.855
[43,     3] loss: 0.864
[44,     3] loss: 0.942
[45,     3] loss: 0.953
[46,     3] loss: 0.887
[47,     3] loss: 0.875
[48,     3] loss: 0.919
[49,     3] loss: 0.880
[50,     3] loss: 0.886
[51,     3] loss: 0.926
[52,     3] loss: 0.907
[53,     3] loss: 0.958
[54,     3] loss: 0.853
[55,     3] loss: 0.938
[56,     3] loss: 0.913
[57,     3] loss: 0.964
[58,     3] loss: 0.887
[59,     3] loss: 0.910
[60,     3] loss: 0.976
[61,     3] loss: 0.910
[62,     3] loss: 0.966
[63,     3] loss: 0.879
[64,     3] loss: 0.917
[65,     3] loss: 0.882
[66,     3] loss: 0.847
[67,     3] loss: 0.875
[68,     3] loss: 0.840
[69,     3] loss: 0.809
[70,     3] loss: 0.819
[71,     3] loss: 0.822
[72,     3] loss: 0.871
[73,     3] loss: 0.792
[74,     3] loss: 0.832
[75,     3] loss: 0.879
[76,     3] loss: 0.868
[77,     3] loss: 0.777
[78,     3] loss: 0.853
[79,     3] loss: 0.821
[80,     3] loss: 0.814
[81,     3] loss: 0.836
[82,     3] loss: 0.780
[83,     3] loss: 0.866
[84,     3] loss: 0.815
[85,     3] loss: 0.788
[86,     3] loss: 0.805
[87,     3] loss: 0.872
[88,     3] loss: 0.789
[89,     3] loss: 0.794
[90,     3] loss: 0.827
[91,     3] loss: 0.784
[92,     3] loss: 0.818
[93,     3] loss: 0.787
[94,     3] loss: 0.840
[95,     3] loss: 0.832
[96,     3] loss: 0.781
[97,     3] loss: 0.797
[98,     3] loss: 0.769
[99,     3] loss: 0.779
[100,     3] loss: 0.755
[101,     3] loss: 0.751
[102,     3] loss: 0.735
[103,     3] loss: 0.723
[104,     3] loss: 0.731
[105,     3] loss: 0.749
[106,     3] loss: 0.765
[107,     3] loss: 0.738
[108,     3] loss: 0.792
[109,     3] loss: 0.757
[110,     3] loss: 0.763
[111,     3] loss: 0.796
[112,     3] loss: 0.756
[113,     3] loss: 0.808
[114,     3] loss: 0.892
[115,     3] loss: 0.925
[116,     3] loss: 0.810
[117,     3] loss: 0.826
[118,     3] loss: 0.770
[119,     3] loss: 0.787
[120,     3] loss: 0.833
[121,     3] loss: 0.842
[122,     3] loss: 0.780
[123,     3] loss: 0.792
[124,     3] loss: 0.804
[125,     3] loss: 0.757
[126,     3] loss: 0.750
[127,     3] loss: 0.797
[128,     3] loss: 0.766
[129,     3] loss: 0.751
[130,     3] loss: 0.772
[131,     3] loss: 0.778
[132,     3] loss: 0.754
[133,     3] loss: 0.759
[134,     3] loss: 0.782
[135,     3] loss: 0.810
[136,     3] loss: 0.810
[137,     3] loss: 0.764
[138,     3] loss: 0.737
[139,     3] loss: 0.858
[140,     3] loss: 0.966
[141,     3] loss: 0.830
[142,     3] loss: 0.797
[143,     3] loss: 0.838
[144,     3] loss: 0.901
[145,     3] loss: 0.772
[146,     3] loss: 0.777
[147,     3] loss: 0.774
[148,     3] loss: 0.754
[149,     3] loss: 0.746
[150,     3] loss: 0.772
[151,     3] loss: 0.746
[152,     3] loss: 0.743
[153,     3] loss: 0.739
[154,     3] loss: 0.729
Early stopping applied (best metric=0.5482858419418335)
Finished Training
Total time taken: 34.18574666976929
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.387
[3,     3] loss: 1.387
[4,     3] loss: 1.378
[5,     3] loss: 1.391
[6,     3] loss: 1.386
[7,     3] loss: 1.386
[8,     3] loss: 1.388
[9,     3] loss: 1.389
[10,     3] loss: 1.378
[11,     3] loss: 1.382
[12,     3] loss: 1.384
[13,     3] loss: 1.384
[14,     3] loss: 1.383
[15,     3] loss: 1.377
[16,     3] loss: 1.379
[17,     3] loss: 1.381
[18,     3] loss: 1.371
[19,     3] loss: 1.366
[20,     3] loss: 1.357
[21,     3] loss: 1.350
[22,     3] loss: 1.346
[23,     3] loss: 1.323
[24,     3] loss: 1.264
[25,     3] loss: 1.267
[26,     3] loss: 1.235
[27,     3] loss: 1.188
[28,     3] loss: 1.128
[29,     3] loss: 1.127
[30,     3] loss: 1.116
[31,     3] loss: 1.068
[32,     3] loss: 1.133
[33,     3] loss: 1.040
[34,     3] loss: 1.128
[35,     3] loss: 1.053
[36,     3] loss: 1.083
[37,     3] loss: 1.034
[38,     3] loss: 1.031
[39,     3] loss: 0.999
[40,     3] loss: 1.015
[41,     3] loss: 0.966
[42,     3] loss: 0.968
[43,     3] loss: 1.009
[44,     3] loss: 0.911
[45,     3] loss: 0.981
[46,     3] loss: 0.882
[47,     3] loss: 0.955
[48,     3] loss: 0.878
[49,     3] loss: 0.954
[50,     3] loss: 0.912
[51,     3] loss: 0.855
[52,     3] loss: 0.821
[53,     3] loss: 0.831
[54,     3] loss: 0.813
[55,     3] loss: 0.785
[56,     3] loss: 0.914
[57,     3] loss: 0.864
[58,     3] loss: 0.777
[59,     3] loss: 0.803
[60,     3] loss: 0.807
[61,     3] loss: 0.819
[62,     3] loss: 0.804
[63,     3] loss: 0.792
[64,     3] loss: 0.795
[65,     3] loss: 0.857
[66,     3] loss: 0.939
[67,     3] loss: 0.791
[68,     3] loss: 0.896
[69,     3] loss: 0.875
[70,     3] loss: 0.877
[71,     3] loss: 1.087
[72,     3] loss: 0.842
[73,     3] loss: 0.886
[74,     3] loss: 0.816
[75,     3] loss: 0.863
[76,     3] loss: 0.831
[77,     3] loss: 0.802
[78,     3] loss: 0.805
[79,     3] loss: 0.779
[80,     3] loss: 0.784
[81,     3] loss: 0.756
[82,     3] loss: 0.751
[83,     3] loss: 0.756
[84,     3] loss: 0.743
[85,     3] loss: 0.747
[86,     3] loss: 0.741
[87,     3] loss: 0.762
Early stopping applied (best metric=0.5348555445671082)
Finished Training
Total time taken: 19.38205361366272
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.387
[3,     3] loss: 1.393
[4,     3] loss: 1.389
[5,     3] loss: 1.386
[6,     3] loss: 1.385
[7,     3] loss: 1.382
[8,     3] loss: 1.382
[9,     3] loss: 1.380
[10,     3] loss: 1.379
[11,     3] loss: 1.370
[12,     3] loss: 1.370
[13,     3] loss: 1.371
[14,     3] loss: 1.342
[15,     3] loss: 1.331
[16,     3] loss: 1.323
[17,     3] loss: 1.304
[18,     3] loss: 1.261
[19,     3] loss: 1.240
[20,     3] loss: 1.150
[21,     3] loss: 1.121
[22,     3] loss: 1.166
[23,     3] loss: 1.098
[24,     3] loss: 1.056
[25,     3] loss: 1.073
[26,     3] loss: 1.119
[27,     3] loss: 1.106
[28,     3] loss: 0.985
[29,     3] loss: 1.022
[30,     3] loss: 1.054
[31,     3] loss: 0.958
[32,     3] loss: 0.966
[33,     3] loss: 0.962
[34,     3] loss: 0.969
[35,     3] loss: 0.899
[36,     3] loss: 0.925
[37,     3] loss: 0.888
[38,     3] loss: 0.916
[39,     3] loss: 0.928
[40,     3] loss: 1.055
[41,     3] loss: 0.908
[42,     3] loss: 0.926
[43,     3] loss: 0.889
[44,     3] loss: 0.918
[45,     3] loss: 0.853
[46,     3] loss: 0.861
[47,     3] loss: 0.943
[48,     3] loss: 0.875
[49,     3] loss: 0.837
[50,     3] loss: 0.806
[51,     3] loss: 0.839
[52,     3] loss: 0.813
[53,     3] loss: 0.830
[54,     3] loss: 0.804
[55,     3] loss: 0.778
[56,     3] loss: 0.839
[57,     3] loss: 0.805
[58,     3] loss: 0.807
[59,     3] loss: 0.774
[60,     3] loss: 0.787
[61,     3] loss: 0.747
[62,     3] loss: 0.899
[63,     3] loss: 0.805
[64,     3] loss: 0.822
[65,     3] loss: 0.827
[66,     3] loss: 0.819
[67,     3] loss: 0.782
[68,     3] loss: 0.877
[69,     3] loss: 0.867
[70,     3] loss: 0.792
[71,     3] loss: 0.924
[72,     3] loss: 1.058
[73,     3] loss: 1.022
[74,     3] loss: 0.921
[75,     3] loss: 0.960
[76,     3] loss: 0.920
[77,     3] loss: 0.866
Early stopping applied (best metric=0.5393925905227661)
Finished Training
Total time taken: 17.17546033859253
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.388
[3,     3] loss: 1.382
[4,     3] loss: 1.389
[5,     3] loss: 1.382
[6,     3] loss: 1.383
[7,     3] loss: 1.371
[8,     3] loss: 1.368
[9,     3] loss: 1.367
[10,     3] loss: 1.367
[11,     3] loss: 1.348
[12,     3] loss: 1.347
[13,     3] loss: 1.326
[14,     3] loss: 1.331
[15,     3] loss: 1.247
[16,     3] loss: 1.261
[17,     3] loss: 1.216
[18,     3] loss: 1.242
[19,     3] loss: 1.120
[20,     3] loss: 1.095
[21,     3] loss: 1.078
[22,     3] loss: 1.266
[23,     3] loss: 1.074
[24,     3] loss: 1.073
[25,     3] loss: 1.114
[26,     3] loss: 1.092
[27,     3] loss: 1.033
[28,     3] loss: 1.097
[29,     3] loss: 1.102
[30,     3] loss: 1.021
[31,     3] loss: 1.066
[32,     3] loss: 1.037
[33,     3] loss: 1.014
[34,     3] loss: 1.027
[35,     3] loss: 1.025
[36,     3] loss: 1.008
[37,     3] loss: 0.957
[38,     3] loss: 0.975
[39,     3] loss: 0.915
[40,     3] loss: 0.932
[41,     3] loss: 0.865
[42,     3] loss: 0.892
[43,     3] loss: 0.918
[44,     3] loss: 0.920
[45,     3] loss: 0.941
[46,     3] loss: 0.906
[47,     3] loss: 0.817
[48,     3] loss: 0.936
[49,     3] loss: 0.891
[50,     3] loss: 0.847
[51,     3] loss: 0.860
[52,     3] loss: 0.861
[53,     3] loss: 0.926
[54,     3] loss: 0.862
[55,     3] loss: 0.832
[56,     3] loss: 0.873
[57,     3] loss: 1.008
[58,     3] loss: 0.951
[59,     3] loss: 0.862
[60,     3] loss: 1.014
[61,     3] loss: 0.869
[62,     3] loss: 0.936
[63,     3] loss: 0.843
[64,     3] loss: 0.851
[65,     3] loss: 0.888
[66,     3] loss: 0.814
[67,     3] loss: 0.812
[68,     3] loss: 0.809
[69,     3] loss: 0.842
[70,     3] loss: 0.819
[71,     3] loss: 0.817
[72,     3] loss: 0.774
[73,     3] loss: 0.799
[74,     3] loss: 0.829
[75,     3] loss: 0.795
[76,     3] loss: 0.759
[77,     3] loss: 0.866
[78,     3] loss: 0.779
[79,     3] loss: 0.819
[80,     3] loss: 0.853
[81,     3] loss: 0.779
[82,     3] loss: 0.786
[83,     3] loss: 0.875
[84,     3] loss: 0.789
[85,     3] loss: 0.812
[86,     3] loss: 0.791
[87,     3] loss: 0.874
[88,     3] loss: 0.777
[89,     3] loss: 0.789
[90,     3] loss: 0.809
[91,     3] loss: 0.858
[92,     3] loss: 0.772
[93,     3] loss: 0.809
Early stopping applied (best metric=0.5339577198028564)
Finished Training
Total time taken: 20.631056308746338
{'S-palmitoylation-C Validation Accuracy': 0.6901261313488388, 'S-palmitoylation-C Validation Sensitivity': 0.23643564356435642, 'S-palmitoylation-C Validation Specificity': 0.8038442236026886, 'S-palmitoylation-C Validation Precision': 0.23467705219688503, 'S-palmitoylation-C AUC ROC': 0.5383784894416415, 'S-palmitoylation-C AUC PR': 0.22201451006507192, 'S-palmitoylation-C MCC': 0.040969171434296056, 'S-palmitoylation-C F1': 0.21853850276572853, 'Validation Loss (S-palmitoylation-C)': 0.5541582345962525, 'Hydroxylation-K Validation Accuracy': 0.7190898345153665, 'Hydroxylation-K Validation Sensitivity': 0.7296296296296296, 'Hydroxylation-K Validation Specificity': 0.7175438596491228, 'Hydroxylation-K Validation Precision': 0.41879555085437437, 'Hydroxylation-K AUC ROC': 0.7846003898635477, 'Hydroxylation-K AUC PR': 0.5722536247939011, 'Hydroxylation-K MCC': 0.38488290125724883, 'Hydroxylation-K F1': 0.5219106786283151, 'Validation Loss (Hydroxylation-K)': 0.5300572117169698, 'Validation Loss (total)': 1.0842154582341512, 'TimeToTrain': 20.712019316355388}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006747593502063256,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9573053566852886,
 'loss_weight_S-palmitoylation-C': 0.0030655899539934195,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1127977231,
 'sample_weights': [0.033590571033805486, 0.06401512958700979],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.853818378409535,
 'weight_decay_Hydroxylation-K': 3.96092486656823,
 'weight_decay_S-palmitoylation-C': 5.059763500344523}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.389
[3,     3] loss: 1.391
[4,     3] loss: 1.383
[5,     3] loss: 1.386
[6,     3] loss: 1.383
[7,     3] loss: 1.381
[8,     3] loss: 1.373
[9,     3] loss: 1.370
[10,     3] loss: 1.366
[11,     3] loss: 1.348
[12,     3] loss: 1.330
[13,     3] loss: 1.316
[14,     3] loss: 1.285
[15,     3] loss: 1.269
[16,     3] loss: 1.252
[17,     3] loss: 1.173
[18,     3] loss: 1.143
[19,     3] loss: 1.090
[20,     3] loss: 1.114
[21,     3] loss: 1.060
[22,     3] loss: 1.012
[23,     3] loss: 1.139
[24,     3] loss: 1.113
[25,     3] loss: 1.066
[26,     3] loss: 0.978
[27,     3] loss: 0.981
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002258500585124476,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.413354677567569,
 'loss_weight_S-palmitoylation-C': 0.4803094913512247,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2414894343,
 'sample_weights': [0.0030655899539934195, 0.9573053566852886],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.92390096159158,
 'weight_decay_Hydroxylation-K': 0.3931978697285903,
 'weight_decay_S-palmitoylation-C': 5.043961595571315}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.387
[3,     3] loss: 1.383
[4,     3] loss: 1.389
[5,     3] loss: 1.377
[6,     3] loss: 1.380
[7,     3] loss: 1.377
[8,     3] loss: 1.360
[9,     3] loss: 1.347
[10,     3] loss: 1.335
[11,     3] loss: 1.289
[12,     3] loss: 1.278
[13,     3] loss: 1.233
[14,     3] loss: 1.166
[15,     3] loss: 1.108
[16,     3] loss: 1.188
[17,     3] loss: 1.169
[18,     3] loss: 1.100
[19,     3] loss: 1.106
[20,     3] loss: 1.179
[21,     3] loss: 1.029
[22,     3] loss: 1.068
[23,     3] loss: 1.001
[24,     3] loss: 0.983
[25,     3] loss: 0.931
[26,     3] loss: 1.020
[27,     3] loss: 1.018
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0021348288952055933,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9760775191836778,
 'loss_weight_S-palmitoylation-C': 0.192087291594843,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 880212036,
 'sample_weights': [0.4803094913512247, 0.413354677567569],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.506911750195433,
 'weight_decay_Hydroxylation-K': 0.24295714311770444,
 'weight_decay_S-palmitoylation-C': 2.8148737338694323}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.391
[3,     3] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0004715572645820515,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9929829303872084,
 'loss_weight_S-palmitoylation-C': 0.1046937721188749,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1466400105,
 'sample_weights': [0.192087291594843, 0.9760775191836778],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.664053382932998,
 'weight_decay_Hydroxylation-K': 4.42622531097659,
 'weight_decay_S-palmitoylation-C': 3.0693335327901474}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.390
[3,     3] loss: 1.390
[4,     3] loss: 1.391
[5,     3] loss: 1.385
[6,     3] loss: 1.386
[7,     3] loss: 1.385
[8,     3] loss: 1.386
[9,     3] loss: 1.374
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002608242073484135,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5637754366720465,
 'loss_weight_S-palmitoylation-C': 0.615000462490087,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 171023005,
 'sample_weights': [0.1046937721188749, 0.9929829303872084],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.902387579956034,
 'weight_decay_Hydroxylation-K': 1.8973458327517554,
 'weight_decay_S-palmitoylation-C': 5.351302719524099}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.395
[3,     3] loss: 1.385
[4,     3] loss: 1.396
[5,     3] loss: 1.374
[6,     3] loss: 1.397
[7,     3] loss: 1.379
[8,     3] loss: 1.399
[9,     3] loss: 1.398
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0039746066189045096,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8938856674318614,
 'loss_weight_S-palmitoylation-C': 0.2365621567602219,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 805700115,
 'sample_weights': [0.615000462490087, 0.5637754366720465],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.044870772126823,
 'weight_decay_Hydroxylation-K': 4.758709784752563,
 'weight_decay_S-palmitoylation-C': 5.761239506097979}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.386
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022315513894675086,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.08305162277839148,
 'loss_weight_S-palmitoylation-C': 0.2590808905538573,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4253761169,
 'sample_weights': [0.2365621567602219, 0.8938856674318614],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.633410082992272,
 'weight_decay_Hydroxylation-K': 3.257903208920709,
 'weight_decay_S-palmitoylation-C': 3.884815082321361}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.385
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0002681791531301422,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9078693169223556,
 'loss_weight_S-palmitoylation-C': 0.08436342210252995,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1773208769,
 'sample_weights': [0.2590808905538573, 0.08305162277839148],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.041826001638613,
 'weight_decay_Hydroxylation-K': 3.596348652535408,
 'weight_decay_S-palmitoylation-C': 6.461281000527191}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.390
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 3.0264647262113163e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.07349707673748257,
 'loss_weight_S-palmitoylation-C': 0.053389790594451536,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 754949772,
 'sample_weights': [0.08436342210252995, 0.9078693169223556],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.4610033818900545,
 'weight_decay_Hydroxylation-K': 7.11504175986731,
 'weight_decay_S-palmitoylation-C': 4.191775561726981}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.390
[3,     3] loss: 1.390
[4,     3] loss: 1.392
[5,     3] loss: 1.388
[6,     3] loss: 1.388
[7,     3] loss: 1.400
[8,     3] loss: 1.381
[9,     3] loss: 1.385
[10,     3] loss: 1.392
[11,     3] loss: 1.380
[12,     3] loss: 1.396
[13,     3] loss: 1.390
[14,     3] loss: 1.388
[15,     3] loss: 1.398
[16,     3] loss: 1.396
[17,     3] loss: 1.394
[18,     3] loss: 1.391
[19,     3] loss: 1.389
[20,     3] loss: 1.383
[21,     3] loss: 1.393
[22,     3] loss: 1.387
[23,     3] loss: 1.383
[24,     3] loss: 1.385
[25,     3] loss: 1.386
[26,     3] loss: 1.382
[27,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0038425917186809882,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9833774757613339,
 'loss_weight_S-palmitoylation-C': 0.05822123414949315,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2998073691,
 'sample_weights': [0.053389790594451536, 0.07349707673748257],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.852333876159834,
 'weight_decay_Hydroxylation-K': 5.476480722437902,
 'weight_decay_S-palmitoylation-C': 6.058998074867124}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.391
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028392837634788506,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.25446448810555333,
 'loss_weight_S-palmitoylation-C': 0.24759422725880234,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1810644150,
 'sample_weights': [0.05822123414949315, 0.9833774757613339],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.955623966523918,
 'weight_decay_Hydroxylation-K': 3.7418392950665726,
 'weight_decay_S-palmitoylation-C': 0.39529623632737954}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.392
[3,     3] loss: 1.381
[4,     3] loss: 1.389
[5,     3] loss: 1.392
[6,     3] loss: 1.387
[7,     3] loss: 1.381
[8,     3] loss: 1.374
[9,     3] loss: 1.358
[10,     3] loss: 1.340
[11,     3] loss: 1.325
[12,     3] loss: 1.253
[13,     3] loss: 1.203
[14,     3] loss: 1.249
[15,     3] loss: 1.146
[16,     3] loss: 1.122
[17,     3] loss: 1.058
[18,     3] loss: 0.961
[19,     3] loss: 0.943
[20,     3] loss: 0.995
[21,     3] loss: 1.102
[22,     3] loss: 1.177
[23,     3] loss: 1.123
[24,     3] loss: 1.224
[25,     3] loss: 1.109
[26,     3] loss: 1.179
[27,     3] loss: 1.186
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005049393298669569,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9510428463703902,
 'loss_weight_S-palmitoylation-C': 0.003749784082633073,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3281920598,
 'sample_weights': [0.24759422725880234, 0.25446448810555333],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.86581545125908,
 'weight_decay_Hydroxylation-K': 1.739111202426507,
 'weight_decay_S-palmitoylation-C': 5.411004641193499}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.391
[3,     3] loss: 1.382
[4,     3] loss: 1.377
[5,     3] loss: 1.388
[6,     3] loss: 1.385
[7,     3] loss: 1.378
[8,     3] loss: 1.380
[9,     3] loss: 1.375
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0044078374398531985,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.997167604830544,
 'loss_weight_S-palmitoylation-C': 0.2682556015627622,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3080261224,
 'sample_weights': [0.003749784082633073, 0.9510428463703902],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7069625217652553,
 'weight_decay_Hydroxylation-K': 2.830883750591403,
 'weight_decay_S-palmitoylation-C': 2.344223447473113}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.369
[3,     3] loss: 1.415
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006611873094511149,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4815608125653308,
 'loss_weight_S-palmitoylation-C': 0.3438902684953915,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2736852943,
 'sample_weights': [0.2682556015627622, 0.997167604830544],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.456994070403917,
 'weight_decay_Hydroxylation-K': 2.9498153921886097,
 'weight_decay_S-palmitoylation-C': 3.9234941295905816}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.399
[3,     3] loss: 1.390
[4,     3] loss: 1.382
[5,     3] loss: 1.387
[6,     3] loss: 1.388
[7,     3] loss: 1.373
[8,     3] loss: 1.377
[9,     3] loss: 1.383
[10,     3] loss: 1.368
[11,     3] loss: 1.348
[12,     3] loss: 1.372
[13,     3] loss: 1.356
[14,     3] loss: 1.318
[15,     3] loss: 1.332
[16,     3] loss: 1.297
[17,     3] loss: 1.259
[18,     3] loss: 1.268
[19,     3] loss: 1.186
[20,     3] loss: 1.169
[21,     3] loss: 1.190
[22,     3] loss: 1.119
[23,     3] loss: 1.139
[24,     3] loss: 1.131
[25,     3] loss: 1.089
[26,     3] loss: 1.107
[27,     3] loss: 1.082
[28,     3] loss: 1.057
[29,     3] loss: 1.049
[30,     3] loss: 1.044
[31,     3] loss: 1.003
[32,     3] loss: 0.969
[33,     3] loss: 1.029
[34,     3] loss: 0.967
[35,     3] loss: 0.961
[36,     3] loss: 1.081
[37,     3] loss: 0.986
[38,     3] loss: 0.903
[39,     3] loss: 0.931
[40,     3] loss: 0.965
[41,     3] loss: 0.925
[42,     3] loss: 0.850
[43,     3] loss: 1.018
[44,     3] loss: 0.927
[45,     3] loss: 0.959
[46,     3] loss: 0.867
[47,     3] loss: 0.902
[48,     3] loss: 0.850
[49,     3] loss: 0.827
[50,     3] loss: 0.826
[51,     3] loss: 0.817
[52,     3] loss: 0.814
[53,     3] loss: 0.789
[54,     3] loss: 0.822
[55,     3] loss: 0.779
[56,     3] loss: 0.824
[57,     3] loss: 0.797
[58,     3] loss: 0.788
[59,     3] loss: 0.799
[60,     3] loss: 0.788
[61,     3] loss: 0.777
[62,     3] loss: 0.780
[63,     3] loss: 0.800
[64,     3] loss: 0.749
[65,     3] loss: 0.765
[66,     3] loss: 0.766
[67,     3] loss: 0.799
[68,     3] loss: 0.808
[69,     3] loss: 0.883
[70,     3] loss: 0.798
[71,     3] loss: 0.834
[72,     3] loss: 0.855
[73,     3] loss: 0.828
[74,     3] loss: 0.814
Early stopping applied (best metric=0.5204867720603943)
Finished Training
Total time taken: 16.45205307006836
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.388
[3,     3] loss: 1.387
[4,     3] loss: 1.388
[5,     3] loss: 1.386
[6,     3] loss: 1.388
[7,     3] loss: 1.394
[8,     3] loss: 1.387
[9,     3] loss: 1.380
[10,     3] loss: 1.378
[11,     3] loss: 1.383
[12,     3] loss: 1.372
[13,     3] loss: 1.372
[14,     3] loss: 1.368
[15,     3] loss: 1.349
[16,     3] loss: 1.333
[17,     3] loss: 1.314
[18,     3] loss: 1.283
[19,     3] loss: 1.302
[20,     3] loss: 1.236
[21,     3] loss: 1.214
[22,     3] loss: 1.152
[23,     3] loss: 1.107
[24,     3] loss: 1.150
[25,     3] loss: 1.126
[26,     3] loss: 1.235
[27,     3] loss: 1.125
[28,     3] loss: 1.110
[29,     3] loss: 1.212
[30,     3] loss: 1.049
[31,     3] loss: 1.064
[32,     3] loss: 0.977
[33,     3] loss: 0.973
[34,     3] loss: 1.005
[35,     3] loss: 1.023
[36,     3] loss: 0.970
[37,     3] loss: 0.895
[38,     3] loss: 0.910
[39,     3] loss: 0.874
[40,     3] loss: 0.901
[41,     3] loss: 0.934
[42,     3] loss: 0.933
[43,     3] loss: 0.932
[44,     3] loss: 0.871
[45,     3] loss: 0.845
[46,     3] loss: 0.848
[47,     3] loss: 0.887
[48,     3] loss: 0.882
[49,     3] loss: 0.939
[50,     3] loss: 0.904
[51,     3] loss: 0.975
[52,     3] loss: 0.899
[53,     3] loss: 0.817
[54,     3] loss: 0.823
[55,     3] loss: 0.840
[56,     3] loss: 0.814
[57,     3] loss: 0.834
[58,     3] loss: 0.821
[59,     3] loss: 0.898
[60,     3] loss: 0.826
[61,     3] loss: 0.824
[62,     3] loss: 0.830
[63,     3] loss: 0.827
[64,     3] loss: 0.833
[65,     3] loss: 0.846
[66,     3] loss: 0.828
[67,     3] loss: 0.836
[68,     3] loss: 0.778
[69,     3] loss: 0.809
[70,     3] loss: 0.869
[71,     3] loss: 0.838
[72,     3] loss: 0.818
[73,     3] loss: 0.812
[74,     3] loss: 0.779
[75,     3] loss: 0.758
[76,     3] loss: 0.766
[77,     3] loss: 0.769
[78,     3] loss: 0.796
[79,     3] loss: 0.767
[80,     3] loss: 0.751
[81,     3] loss: 0.760
[82,     3] loss: 0.758
[83,     3] loss: 0.748
[84,     3] loss: 0.771
[85,     3] loss: 0.760
[86,     3] loss: 0.754
[87,     3] loss: 0.732
Early stopping applied (best metric=0.521241307258606)
Finished Training
Total time taken: 19.357077598571777
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.383
[3,     3] loss: 1.375
[4,     3] loss: 1.384
[5,     3] loss: 1.381
[6,     3] loss: 1.390
[7,     3] loss: 1.377
[8,     3] loss: 1.381
[9,     3] loss: 1.377
[10,     3] loss: 1.375
[11,     3] loss: 1.350
[12,     3] loss: 1.339
[13,     3] loss: 1.326
[14,     3] loss: 1.332
[15,     3] loss: 1.277
[16,     3] loss: 1.242
[17,     3] loss: 1.294
[18,     3] loss: 1.254
[19,     3] loss: 1.205
[20,     3] loss: 1.199
[21,     3] loss: 1.155
[22,     3] loss: 1.142
[23,     3] loss: 1.081
[24,     3] loss: 1.143
[25,     3] loss: 1.083
[26,     3] loss: 1.020
[27,     3] loss: 1.013
[28,     3] loss: 1.086
[29,     3] loss: 0.969
[30,     3] loss: 1.044
[31,     3] loss: 1.026
[32,     3] loss: 1.028
[33,     3] loss: 0.991
[34,     3] loss: 0.948
[35,     3] loss: 0.875
[36,     3] loss: 0.949
[37,     3] loss: 0.893
[38,     3] loss: 0.903
[39,     3] loss: 1.035
[40,     3] loss: 0.951
[41,     3] loss: 0.939
[42,     3] loss: 0.907
[43,     3] loss: 0.929
[44,     3] loss: 0.840
[45,     3] loss: 0.843
[46,     3] loss: 0.886
[47,     3] loss: 0.853
[48,     3] loss: 0.860
[49,     3] loss: 0.807
[50,     3] loss: 0.862
[51,     3] loss: 0.829
[52,     3] loss: 0.824
[53,     3] loss: 0.836
[54,     3] loss: 0.855
[55,     3] loss: 0.771
[56,     3] loss: 0.814
[57,     3] loss: 0.777
[58,     3] loss: 0.903
[59,     3] loss: 0.797
[60,     3] loss: 0.883
[61,     3] loss: 0.811
[62,     3] loss: 0.802
[63,     3] loss: 0.801
[64,     3] loss: 0.801
[65,     3] loss: 0.791
[66,     3] loss: 0.804
[67,     3] loss: 0.788
[68,     3] loss: 0.827
[69,     3] loss: 0.856
[70,     3] loss: 0.936
[71,     3] loss: 1.022
[72,     3] loss: 0.842
[73,     3] loss: 0.875
[74,     3] loss: 0.950
[75,     3] loss: 0.923
[76,     3] loss: 0.888
[77,     3] loss: 0.946
[78,     3] loss: 0.841
Early stopping applied (best metric=0.5226220488548279)
Finished Training
Total time taken: 17.34404969215393
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.385
[3,     3] loss: 1.387
[4,     3] loss: 1.386
[5,     3] loss: 1.385
[6,     3] loss: 1.384
[7,     3] loss: 1.383
[8,     3] loss: 1.377
[9,     3] loss: 1.381
[10,     3] loss: 1.373
[11,     3] loss: 1.366
[12,     3] loss: 1.362
[13,     3] loss: 1.329
[14,     3] loss: 1.345
[15,     3] loss: 1.295
[16,     3] loss: 1.327
[17,     3] loss: 1.290
[18,     3] loss: 1.303
[19,     3] loss: 1.268
[20,     3] loss: 1.258
[21,     3] loss: 1.223
[22,     3] loss: 1.144
[23,     3] loss: 1.183
[24,     3] loss: 1.131
[25,     3] loss: 1.112
[26,     3] loss: 1.040
[27,     3] loss: 1.060
[28,     3] loss: 1.196
[29,     3] loss: 1.023
[30,     3] loss: 1.000
[31,     3] loss: 1.143
[32,     3] loss: 1.101
[33,     3] loss: 1.055
[34,     3] loss: 1.015
[35,     3] loss: 0.981
[36,     3] loss: 0.935
[37,     3] loss: 1.003
[38,     3] loss: 0.976
[39,     3] loss: 0.935
[40,     3] loss: 1.038
[41,     3] loss: 0.905
[42,     3] loss: 0.916
[43,     3] loss: 0.965
[44,     3] loss: 0.984
[45,     3] loss: 0.921
[46,     3] loss: 0.913
[47,     3] loss: 0.916
[48,     3] loss: 0.899
[49,     3] loss: 0.835
[50,     3] loss: 0.934
[51,     3] loss: 0.878
[52,     3] loss: 0.859
[53,     3] loss: 0.842
[54,     3] loss: 0.836
[55,     3] loss: 0.821
[56,     3] loss: 0.794
[57,     3] loss: 0.814
[58,     3] loss: 0.805
[59,     3] loss: 0.802
[60,     3] loss: 0.813
[61,     3] loss: 0.780
[62,     3] loss: 0.784
[63,     3] loss: 0.794
[64,     3] loss: 0.794
[65,     3] loss: 0.807
[66,     3] loss: 0.772
[67,     3] loss: 0.787
[68,     3] loss: 0.842
[69,     3] loss: 0.812
[70,     3] loss: 0.833
[71,     3] loss: 0.813
[72,     3] loss: 0.786
[73,     3] loss: 0.775
[74,     3] loss: 0.834
[75,     3] loss: 0.953
[76,     3] loss: 0.950
[77,     3] loss: 0.891
[78,     3] loss: 0.915
[79,     3] loss: 0.905
[80,     3] loss: 0.848
[81,     3] loss: 0.851
[82,     3] loss: 0.831
[83,     3] loss: 0.803
[84,     3] loss: 0.783
[85,     3] loss: 0.785
[86,     3] loss: 0.791
[87,     3] loss: 0.748
[88,     3] loss: 0.781
[89,     3] loss: 0.771
[90,     3] loss: 0.747
[91,     3] loss: 0.752
[92,     3] loss: 0.755
[93,     3] loss: 0.742
[94,     3] loss: 0.760
[95,     3] loss: 0.785
[96,     3] loss: 0.823
Early stopping applied (best metric=0.49543818831443787)
Finished Training
Total time taken: 21.38905668258667
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.391
[3,     3] loss: 1.380
[4,     3] loss: 1.392
[5,     3] loss: 1.388
[6,     3] loss: 1.385
[7,     3] loss: 1.379
[8,     3] loss: 1.383
[9,     3] loss: 1.369
[10,     3] loss: 1.366
[11,     3] loss: 1.375
[12,     3] loss: 1.364
[13,     3] loss: 1.336
[14,     3] loss: 1.333
[15,     3] loss: 1.326
[16,     3] loss: 1.274
[17,     3] loss: 1.268
[18,     3] loss: 1.321
[19,     3] loss: 1.208
[20,     3] loss: 1.215
[21,     3] loss: 1.188
[22,     3] loss: 1.256
[23,     3] loss: 1.162
[24,     3] loss: 1.136
[25,     3] loss: 1.100
[26,     3] loss: 1.126
[27,     3] loss: 1.063
[28,     3] loss: 1.157
[29,     3] loss: 0.965
[30,     3] loss: 1.070
[31,     3] loss: 1.063
[32,     3] loss: 1.019
[33,     3] loss: 0.932
[34,     3] loss: 1.036
[35,     3] loss: 0.960
[36,     3] loss: 1.011
[37,     3] loss: 0.993
[38,     3] loss: 0.946
[39,     3] loss: 1.030
[40,     3] loss: 0.945
[41,     3] loss: 0.921
[42,     3] loss: 0.882
[43,     3] loss: 0.928
[44,     3] loss: 0.906
[45,     3] loss: 0.894
[46,     3] loss: 0.943
[47,     3] loss: 0.863
[48,     3] loss: 0.975
[49,     3] loss: 0.984
[50,     3] loss: 0.961
[51,     3] loss: 1.001
[52,     3] loss: 0.945
[53,     3] loss: 0.874
[54,     3] loss: 0.902
[55,     3] loss: 0.894
[56,     3] loss: 0.847
[57,     3] loss: 0.838
[58,     3] loss: 0.790
[59,     3] loss: 0.848
[60,     3] loss: 0.886
[61,     3] loss: 0.825
[62,     3] loss: 0.825
[63,     3] loss: 0.936
[64,     3] loss: 0.785
[65,     3] loss: 0.859
[66,     3] loss: 0.892
[67,     3] loss: 0.880
[68,     3] loss: 0.862
[69,     3] loss: 0.825
[70,     3] loss: 0.806
[71,     3] loss: 0.792
Early stopping applied (best metric=0.4861612021923065)
Finished Training
Total time taken: 15.883056879043579
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.389
[3,     3] loss: 1.384
[4,     3] loss: 1.386
[5,     3] loss: 1.383
[6,     3] loss: 1.386
[7,     3] loss: 1.385
[8,     3] loss: 1.380
[9,     3] loss: 1.372
[10,     3] loss: 1.364
[11,     3] loss: 1.367
[12,     3] loss: 1.369
[13,     3] loss: 1.347
[14,     3] loss: 1.343
[15,     3] loss: 1.323
[16,     3] loss: 1.307
[17,     3] loss: 1.300
[18,     3] loss: 1.272
[19,     3] loss: 1.274
[20,     3] loss: 1.262
[21,     3] loss: 1.201
[22,     3] loss: 1.198
[23,     3] loss: 1.148
[24,     3] loss: 1.201
[25,     3] loss: 1.142
[26,     3] loss: 1.097
[27,     3] loss: 1.187
[28,     3] loss: 1.288
[29,     3] loss: 1.174
[30,     3] loss: 1.120
[31,     3] loss: 1.057
[32,     3] loss: 1.044
[33,     3] loss: 1.111
[34,     3] loss: 1.039
[35,     3] loss: 1.075
[36,     3] loss: 0.944
[37,     3] loss: 1.101
[38,     3] loss: 1.020
[39,     3] loss: 0.951
[40,     3] loss: 0.945
[41,     3] loss: 0.944
[42,     3] loss: 0.970
[43,     3] loss: 0.851
[44,     3] loss: 0.893
[45,     3] loss: 0.893
[46,     3] loss: 0.896
[47,     3] loss: 0.921
[48,     3] loss: 0.987
[49,     3] loss: 0.835
[50,     3] loss: 0.907
[51,     3] loss: 0.917
[52,     3] loss: 0.910
[53,     3] loss: 0.849
[54,     3] loss: 0.868
[55,     3] loss: 0.888
[56,     3] loss: 0.814
[57,     3] loss: 0.811
[58,     3] loss: 0.856
[59,     3] loss: 0.848
[60,     3] loss: 0.832
[61,     3] loss: 0.822
[62,     3] loss: 0.799
[63,     3] loss: 0.817
[64,     3] loss: 0.787
[65,     3] loss: 0.800
[66,     3] loss: 0.789
[67,     3] loss: 0.808
[68,     3] loss: 0.823
[69,     3] loss: 0.786
[70,     3] loss: 0.790
[71,     3] loss: 0.876
[72,     3] loss: 0.890
[73,     3] loss: 0.819
[74,     3] loss: 0.923
[75,     3] loss: 0.914
Early stopping applied (best metric=0.4942391812801361)
Finished Training
Total time taken: 16.735045433044434
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.378
[3,     3] loss: 1.387
[4,     3] loss: 1.378
[5,     3] loss: 1.391
[6,     3] loss: 1.384
[7,     3] loss: 1.401
[8,     3] loss: 1.376
[9,     3] loss: 1.386
[10,     3] loss: 1.366
[11,     3] loss: 1.382
[12,     3] loss: 1.367
[13,     3] loss: 1.371
[14,     3] loss: 1.356
[15,     3] loss: 1.339
[16,     3] loss: 1.300
[17,     3] loss: 1.281
[18,     3] loss: 1.297
[19,     3] loss: 1.277
[20,     3] loss: 1.181
[21,     3] loss: 1.222
[22,     3] loss: 1.161
[23,     3] loss: 1.125
[24,     3] loss: 1.229
[25,     3] loss: 1.084
[26,     3] loss: 1.158
[27,     3] loss: 1.029
[28,     3] loss: 0.980
[29,     3] loss: 1.004
[30,     3] loss: 1.002
[31,     3] loss: 0.950
[32,     3] loss: 0.974
[33,     3] loss: 0.942
[34,     3] loss: 1.007
[35,     3] loss: 1.044
[36,     3] loss: 0.937
[37,     3] loss: 0.964
[38,     3] loss: 0.990
[39,     3] loss: 0.872
[40,     3] loss: 0.918
[41,     3] loss: 0.902
[42,     3] loss: 0.866
[43,     3] loss: 0.892
[44,     3] loss: 0.944
[45,     3] loss: 1.017
[46,     3] loss: 0.939
[47,     3] loss: 1.093
[48,     3] loss: 0.914
[49,     3] loss: 0.909
[50,     3] loss: 0.949
[51,     3] loss: 0.962
[52,     3] loss: 0.903
[53,     3] loss: 0.912
[54,     3] loss: 0.869
[55,     3] loss: 0.834
[56,     3] loss: 0.832
[57,     3] loss: 0.814
[58,     3] loss: 0.805
[59,     3] loss: 0.813
[60,     3] loss: 0.806
[61,     3] loss: 0.793
[62,     3] loss: 0.798
[63,     3] loss: 0.801
[64,     3] loss: 0.789
[65,     3] loss: 0.798
[66,     3] loss: 0.808
[67,     3] loss: 0.754
[68,     3] loss: 0.793
[69,     3] loss: 0.794
[70,     3] loss: 0.782
[71,     3] loss: 0.867
[72,     3] loss: 0.828
[73,     3] loss: 0.783
[74,     3] loss: 0.776
Early stopping applied (best metric=0.5065839290618896)
Finished Training
Total time taken: 16.536044120788574
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.390
[3,     3] loss: 1.382
[4,     3] loss: 1.385
[5,     3] loss: 1.386
[6,     3] loss: 1.380
[7,     3] loss: 1.381
[8,     3] loss: 1.370
[9,     3] loss: 1.369
[10,     3] loss: 1.358
[11,     3] loss: 1.344
[12,     3] loss: 1.343
[13,     3] loss: 1.316
[14,     3] loss: 1.318
[15,     3] loss: 1.307
[16,     3] loss: 1.228
[17,     3] loss: 1.260
[18,     3] loss: 1.245
[19,     3] loss: 1.212
[20,     3] loss: 1.149
[21,     3] loss: 1.166
[22,     3] loss: 1.161
[23,     3] loss: 1.116
[24,     3] loss: 1.178
[25,     3] loss: 1.201
[26,     3] loss: 1.214
[27,     3] loss: 1.109
[28,     3] loss: 1.084
[29,     3] loss: 1.056
[30,     3] loss: 1.004
[31,     3] loss: 1.020
[32,     3] loss: 1.073
[33,     3] loss: 1.037
[34,     3] loss: 1.051
[35,     3] loss: 1.049
[36,     3] loss: 0.937
[37,     3] loss: 0.975
[38,     3] loss: 1.032
[39,     3] loss: 0.954
[40,     3] loss: 0.894
[41,     3] loss: 0.934
[42,     3] loss: 0.971
[43,     3] loss: 0.881
[44,     3] loss: 0.936
[45,     3] loss: 0.914
[46,     3] loss: 0.876
[47,     3] loss: 0.909
[48,     3] loss: 0.997
[49,     3] loss: 0.937
[50,     3] loss: 0.869
[51,     3] loss: 0.843
[52,     3] loss: 0.914
[53,     3] loss: 0.832
[54,     3] loss: 0.837
[55,     3] loss: 0.888
[56,     3] loss: 0.829
[57,     3] loss: 0.855
[58,     3] loss: 0.872
[59,     3] loss: 0.830
[60,     3] loss: 0.843
[61,     3] loss: 0.864
[62,     3] loss: 0.876
[63,     3] loss: 0.945
[64,     3] loss: 0.928
[65,     3] loss: 0.900
[66,     3] loss: 0.871
[67,     3] loss: 0.955
[68,     3] loss: 0.828
[69,     3] loss: 0.787
[70,     3] loss: 0.809
[71,     3] loss: 0.807
[72,     3] loss: 0.792
[73,     3] loss: 0.815
[74,     3] loss: 0.798
[75,     3] loss: 0.828
[76,     3] loss: 0.843
[77,     3] loss: 0.789
[78,     3] loss: 0.798
[79,     3] loss: 0.805
[80,     3] loss: 0.781
[81,     3] loss: 0.788
[82,     3] loss: 0.811
[83,     3] loss: 0.799
[84,     3] loss: 0.792
[85,     3] loss: 0.852
[86,     3] loss: 0.769
[87,     3] loss: 0.791
Early stopping applied (best metric=0.5005209445953369)
Finished Training
Total time taken: 19.290053129196167
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.387
[3,     3] loss: 1.390
[4,     3] loss: 1.385
[5,     3] loss: 1.384
[6,     3] loss: 1.384
[7,     3] loss: 1.373
[8,     3] loss: 1.380
[9,     3] loss: 1.377
[10,     3] loss: 1.364
[11,     3] loss: 1.357
[12,     3] loss: 1.363
[13,     3] loss: 1.329
[14,     3] loss: 1.310
[15,     3] loss: 1.254
[16,     3] loss: 1.238
[17,     3] loss: 1.316
[18,     3] loss: 1.265
[19,     3] loss: 1.239
[20,     3] loss: 1.207
[21,     3] loss: 1.139
[22,     3] loss: 1.190
[23,     3] loss: 1.163
[24,     3] loss: 1.077
[25,     3] loss: 1.160
[26,     3] loss: 1.104
[27,     3] loss: 1.054
[28,     3] loss: 1.095
[29,     3] loss: 1.028
[30,     3] loss: 1.107
[31,     3] loss: 1.122
[32,     3] loss: 1.120
[33,     3] loss: 1.069
[34,     3] loss: 1.093
[35,     3] loss: 1.084
[36,     3] loss: 1.098
[37,     3] loss: 1.034
[38,     3] loss: 0.990
[39,     3] loss: 0.986
[40,     3] loss: 0.992
[41,     3] loss: 0.976
[42,     3] loss: 1.131
[43,     3] loss: 0.953
[44,     3] loss: 1.059
[45,     3] loss: 1.072
[46,     3] loss: 1.055
[47,     3] loss: 0.945
[48,     3] loss: 0.960
[49,     3] loss: 1.000
[50,     3] loss: 0.969
[51,     3] loss: 0.974
[52,     3] loss: 0.931
[53,     3] loss: 0.942
[54,     3] loss: 0.906
[55,     3] loss: 0.853
[56,     3] loss: 0.885
[57,     3] loss: 0.936
[58,     3] loss: 0.849
[59,     3] loss: 0.829
[60,     3] loss: 0.837
[61,     3] loss: 0.956
[62,     3] loss: 0.812
[63,     3] loss: 0.847
[64,     3] loss: 0.991
[65,     3] loss: 0.955
[66,     3] loss: 0.846
[67,     3] loss: 0.843
[68,     3] loss: 0.812
[69,     3] loss: 0.831
[70,     3] loss: 0.856
[71,     3] loss: 0.847
[72,     3] loss: 0.945
[73,     3] loss: 0.849
[74,     3] loss: 0.845
[75,     3] loss: 0.852
[76,     3] loss: 0.815
[77,     3] loss: 0.814
[78,     3] loss: 0.825
[79,     3] loss: 0.878
[80,     3] loss: 0.835
[81,     3] loss: 0.828
[82,     3] loss: 0.790
[83,     3] loss: 0.790
[84,     3] loss: 0.814
[85,     3] loss: 0.777
[86,     3] loss: 0.785
[87,     3] loss: 0.785
[88,     3] loss: 0.824
[89,     3] loss: 0.787
[90,     3] loss: 0.828
[91,     3] loss: 0.934
[92,     3] loss: 0.862
[93,     3] loss: 1.007
[94,     3] loss: 0.835
[95,     3] loss: 1.178
[96,     3] loss: 1.036
[97,     3] loss: 0.906
[98,     3] loss: 0.943
[99,     3] loss: 0.862
[100,     3] loss: 0.893
[101,     3] loss: 0.825
[102,     3] loss: 0.820
[103,     3] loss: 0.811
[104,     3] loss: 0.828
[105,     3] loss: 0.855
[106,     3] loss: 0.835
[107,     3] loss: 0.802
Early stopping applied (best metric=0.48845306038856506)
Finished Training
Total time taken: 23.836064338684082
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.390
[3,     3] loss: 1.386
[4,     3] loss: 1.387
[5,     3] loss: 1.384
[6,     3] loss: 1.380
[7,     3] loss: 1.386
[8,     3] loss: 1.387
[9,     3] loss: 1.380
[10,     3] loss: 1.369
[11,     3] loss: 1.372
[12,     3] loss: 1.363
[13,     3] loss: 1.343
[14,     3] loss: 1.338
[15,     3] loss: 1.320
[16,     3] loss: 1.306
[17,     3] loss: 1.282
[18,     3] loss: 1.242
[19,     3] loss: 1.207
[20,     3] loss: 1.179
[21,     3] loss: 1.144
[22,     3] loss: 1.089
[23,     3] loss: 1.226
[24,     3] loss: 1.107
[25,     3] loss: 1.050
[26,     3] loss: 1.088
[27,     3] loss: 1.130
[28,     3] loss: 1.011
[29,     3] loss: 1.085
[30,     3] loss: 0.967
[31,     3] loss: 0.932
[32,     3] loss: 1.017
[33,     3] loss: 0.932
[34,     3] loss: 0.929
[35,     3] loss: 1.006
[36,     3] loss: 0.992
[37,     3] loss: 0.916
[38,     3] loss: 1.029
[39,     3] loss: 0.935
[40,     3] loss: 0.901
[41,     3] loss: 0.911
[42,     3] loss: 0.875
[43,     3] loss: 0.892
[44,     3] loss: 0.895
[45,     3] loss: 0.916
[46,     3] loss: 0.867
[47,     3] loss: 0.987
[48,     3] loss: 0.866
[49,     3] loss: 0.841
[50,     3] loss: 0.858
[51,     3] loss: 0.866
[52,     3] loss: 0.789
[53,     3] loss: 0.852
[54,     3] loss: 0.831
[55,     3] loss: 0.760
[56,     3] loss: 0.772
[57,     3] loss: 0.846
[58,     3] loss: 0.911
[59,     3] loss: 0.898
[60,     3] loss: 0.876
[61,     3] loss: 0.841
[62,     3] loss: 0.805
[63,     3] loss: 0.818
[64,     3] loss: 0.838
[65,     3] loss: 0.815
[66,     3] loss: 0.798
[67,     3] loss: 0.820
[68,     3] loss: 0.837
[69,     3] loss: 0.800
[70,     3] loss: 0.797
[71,     3] loss: 0.824
[72,     3] loss: 0.987
[73,     3] loss: 0.938
[74,     3] loss: 0.902
[75,     3] loss: 0.882
[76,     3] loss: 0.911
[77,     3] loss: 0.830
[78,     3] loss: 0.867
[79,     3] loss: 0.938
[80,     3] loss: 0.948
[81,     3] loss: 0.885
[82,     3] loss: 0.919
[83,     3] loss: 0.794
[84,     3] loss: 0.921
[85,     3] loss: 0.821
[86,     3] loss: 0.835
[87,     3] loss: 0.774
[88,     3] loss: 0.828
[89,     3] loss: 0.781
[90,     3] loss: 0.806
[91,     3] loss: 0.874
[92,     3] loss: 0.869
[93,     3] loss: 0.819
[94,     3] loss: 0.959
[95,     3] loss: 0.888
[96,     3] loss: 0.991
Early stopping applied (best metric=0.48715296387672424)
Finished Training
Total time taken: 21.315661430358887
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.392
[3,     3] loss: 1.387
[4,     3] loss: 1.390
[5,     3] loss: 1.381
[6,     3] loss: 1.385
[7,     3] loss: 1.391
[8,     3] loss: 1.379
[9,     3] loss: 1.386
[10,     3] loss: 1.386
[11,     3] loss: 1.379
[12,     3] loss: 1.368
[13,     3] loss: 1.375
[14,     3] loss: 1.363
[15,     3] loss: 1.335
[16,     3] loss: 1.326
[17,     3] loss: 1.310
[18,     3] loss: 1.273
[19,     3] loss: 1.245
[20,     3] loss: 1.280
[21,     3] loss: 1.193
[22,     3] loss: 1.147
[23,     3] loss: 1.168
[24,     3] loss: 1.208
[25,     3] loss: 1.132
[26,     3] loss: 1.255
[27,     3] loss: 1.289
[28,     3] loss: 1.172
[29,     3] loss: 1.121
[30,     3] loss: 1.012
[31,     3] loss: 1.041
[32,     3] loss: 1.011
[33,     3] loss: 1.010
[34,     3] loss: 1.015
[35,     3] loss: 0.991
[36,     3] loss: 1.025
[37,     3] loss: 0.923
[38,     3] loss: 0.928
[39,     3] loss: 0.978
[40,     3] loss: 0.861
[41,     3] loss: 0.917
[42,     3] loss: 1.013
[43,     3] loss: 0.858
[44,     3] loss: 0.908
[45,     3] loss: 0.897
[46,     3] loss: 1.000
[47,     3] loss: 0.967
[48,     3] loss: 0.906
[49,     3] loss: 1.069
[50,     3] loss: 0.890
[51,     3] loss: 0.952
[52,     3] loss: 0.914
[53,     3] loss: 0.838
[54,     3] loss: 0.862
[55,     3] loss: 0.795
[56,     3] loss: 0.779
[57,     3] loss: 0.777
[58,     3] loss: 0.782
[59,     3] loss: 0.807
[60,     3] loss: 0.754
[61,     3] loss: 0.777
[62,     3] loss: 0.749
[63,     3] loss: 0.739
[64,     3] loss: 0.767
[65,     3] loss: 0.763
[66,     3] loss: 0.764
[67,     3] loss: 0.761
[68,     3] loss: 0.815
[69,     3] loss: 0.755
[70,     3] loss: 0.757
[71,     3] loss: 0.760
[72,     3] loss: 0.755
[73,     3] loss: 0.756
[74,     3] loss: 0.740
[75,     3] loss: 0.783
Early stopping applied (best metric=0.5143083333969116)
Finished Training
Total time taken: 16.62304425239563
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.390
[3,     3] loss: 1.391
[4,     3] loss: 1.386
[5,     3] loss: 1.384
[6,     3] loss: 1.387
[7,     3] loss: 1.387
[8,     3] loss: 1.383
[9,     3] loss: 1.385
[10,     3] loss: 1.371
[11,     3] loss: 1.364
[12,     3] loss: 1.363
[13,     3] loss: 1.344
[14,     3] loss: 1.316
[15,     3] loss: 1.301
[16,     3] loss: 1.313
[17,     3] loss: 1.290
[18,     3] loss: 1.189
[19,     3] loss: 1.224
[20,     3] loss: 1.173
[21,     3] loss: 1.161
[22,     3] loss: 1.080
[23,     3] loss: 1.077
[24,     3] loss: 1.089
[25,     3] loss: 1.012
[26,     3] loss: 0.994
[27,     3] loss: 0.983
[28,     3] loss: 1.014
[29,     3] loss: 0.905
[30,     3] loss: 0.936
[31,     3] loss: 1.030
[32,     3] loss: 0.968
[33,     3] loss: 0.906
[34,     3] loss: 0.965
[35,     3] loss: 0.906
[36,     3] loss: 0.936
[37,     3] loss: 0.887
[38,     3] loss: 0.936
[39,     3] loss: 0.912
[40,     3] loss: 0.954
[41,     3] loss: 0.960
[42,     3] loss: 1.016
[43,     3] loss: 0.870
[44,     3] loss: 0.941
[45,     3] loss: 0.838
[46,     3] loss: 0.837
[47,     3] loss: 0.952
[48,     3] loss: 0.827
[49,     3] loss: 0.830
[50,     3] loss: 0.893
[51,     3] loss: 0.857
[52,     3] loss: 0.796
[53,     3] loss: 0.805
[54,     3] loss: 0.810
[55,     3] loss: 0.830
[56,     3] loss: 0.819
[57,     3] loss: 0.804
[58,     3] loss: 0.798
[59,     3] loss: 0.782
[60,     3] loss: 0.780
[61,     3] loss: 0.823
[62,     3] loss: 0.782
[63,     3] loss: 0.807
[64,     3] loss: 0.784
[65,     3] loss: 0.813
[66,     3] loss: 0.865
[67,     3] loss: 0.797
[68,     3] loss: 0.773
Early stopping applied (best metric=0.5562094449996948)
Finished Training
Total time taken: 15.336040258407593
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.392
[3,     3] loss: 1.375
[4,     3] loss: 1.392
[5,     3] loss: 1.386
[6,     3] loss: 1.379
[7,     3] loss: 1.389
[8,     3] loss: 1.378
[9,     3] loss: 1.368
[10,     3] loss: 1.366
[11,     3] loss: 1.344
[12,     3] loss: 1.320
[13,     3] loss: 1.311
[14,     3] loss: 1.315
[15,     3] loss: 1.262
[16,     3] loss: 1.245
[17,     3] loss: 1.193
[18,     3] loss: 1.166
[19,     3] loss: 1.200
[20,     3] loss: 1.114
[21,     3] loss: 1.106
[22,     3] loss: 1.098
[23,     3] loss: 1.145
[24,     3] loss: 1.043
[25,     3] loss: 0.994
[26,     3] loss: 1.023
[27,     3] loss: 1.004
[28,     3] loss: 0.974
[29,     3] loss: 0.979
[30,     3] loss: 0.913
[31,     3] loss: 1.053
[32,     3] loss: 1.005
[33,     3] loss: 0.947
[34,     3] loss: 0.953
[35,     3] loss: 0.959
[36,     3] loss: 0.872
[37,     3] loss: 0.949
[38,     3] loss: 0.934
[39,     3] loss: 0.840
[40,     3] loss: 0.883
[41,     3] loss: 0.900
[42,     3] loss: 0.836
[43,     3] loss: 0.841
[44,     3] loss: 0.838
[45,     3] loss: 0.852
[46,     3] loss: 0.796
[47,     3] loss: 0.789
[48,     3] loss: 0.820
[49,     3] loss: 0.766
[50,     3] loss: 0.791
[51,     3] loss: 0.873
[52,     3] loss: 0.796
[53,     3] loss: 0.818
[54,     3] loss: 0.794
[55,     3] loss: 0.758
[56,     3] loss: 0.819
[57,     3] loss: 0.798
[58,     3] loss: 0.799
[59,     3] loss: 0.782
[60,     3] loss: 0.760
[61,     3] loss: 0.768
[62,     3] loss: 0.813
[63,     3] loss: 0.812
[64,     3] loss: 0.803
[65,     3] loss: 0.786
[66,     3] loss: 0.794
[67,     3] loss: 0.862
[68,     3] loss: 0.844
[69,     3] loss: 0.851
[70,     3] loss: 0.861
[71,     3] loss: 0.797
[72,     3] loss: 0.820
[73,     3] loss: 0.864
[74,     3] loss: 0.795
[75,     3] loss: 0.803
[76,     3] loss: 0.773
[77,     3] loss: 0.772
[78,     3] loss: 0.763
[79,     3] loss: 0.836
[80,     3] loss: 0.837
[81,     3] loss: 0.853
[82,     3] loss: 0.871
Early stopping applied (best metric=0.5245675444602966)
Finished Training
Total time taken: 18.330050468444824
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.385
[3,     3] loss: 1.380
[4,     3] loss: 1.386
[5,     3] loss: 1.381
[6,     3] loss: 1.377
[7,     3] loss: 1.379
[8,     3] loss: 1.373
[9,     3] loss: 1.367
[10,     3] loss: 1.371
[11,     3] loss: 1.357
[12,     3] loss: 1.350
[13,     3] loss: 1.350
[14,     3] loss: 1.324
[15,     3] loss: 1.335
[16,     3] loss: 1.331
[17,     3] loss: 1.262
[18,     3] loss: 1.252
[19,     3] loss: 1.217
[20,     3] loss: 1.190
[21,     3] loss: 1.218
[22,     3] loss: 1.165
[23,     3] loss: 1.085
[24,     3] loss: 1.077
[25,     3] loss: 1.039
[26,     3] loss: 1.131
[27,     3] loss: 1.049
[28,     3] loss: 1.035
[29,     3] loss: 0.962
[30,     3] loss: 0.880
[31,     3] loss: 0.933
[32,     3] loss: 0.924
[33,     3] loss: 0.915
[34,     3] loss: 0.877
[35,     3] loss: 0.938
[36,     3] loss: 0.840
[37,     3] loss: 0.887
[38,     3] loss: 0.874
[39,     3] loss: 0.951
[40,     3] loss: 0.855
[41,     3] loss: 0.831
[42,     3] loss: 0.858
[43,     3] loss: 0.828
[44,     3] loss: 0.835
[45,     3] loss: 0.870
[46,     3] loss: 0.825
[47,     3] loss: 0.840
[48,     3] loss: 0.828
[49,     3] loss: 0.892
[50,     3] loss: 0.875
[51,     3] loss: 0.809
[52,     3] loss: 0.894
[53,     3] loss: 0.881
[54,     3] loss: 0.782
[55,     3] loss: 0.879
[56,     3] loss: 0.813
[57,     3] loss: 0.797
[58,     3] loss: 0.816
[59,     3] loss: 0.845
[60,     3] loss: 0.869
[61,     3] loss: 0.809
[62,     3] loss: 0.792
[63,     3] loss: 0.780
[64,     3] loss: 0.817
[65,     3] loss: 0.826
[66,     3] loss: 0.782
[67,     3] loss: 0.764
[68,     3] loss: 0.817
[69,     3] loss: 0.836
[70,     3] loss: 0.812
[71,     3] loss: 0.764
[72,     3] loss: 0.870
[73,     3] loss: 0.857
[74,     3] loss: 0.777
[75,     3] loss: 0.821
[76,     3] loss: 0.800
[77,     3] loss: 0.778
[78,     3] loss: 0.864
[79,     3] loss: 0.830
[80,     3] loss: 0.823
[81,     3] loss: 0.785
Early stopping applied (best metric=0.49907225370407104)
Finished Training
Total time taken: 18.02505087852478
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.391
[3,     3] loss: 1.386
[4,     3] loss: 1.384
[5,     3] loss: 1.381
[6,     3] loss: 1.373
[7,     3] loss: 1.373
[8,     3] loss: 1.357
[9,     3] loss: 1.344
[10,     3] loss: 1.344
[11,     3] loss: 1.333
[12,     3] loss: 1.305
[13,     3] loss: 1.309
[14,     3] loss: 1.257
[15,     3] loss: 1.217
[16,     3] loss: 1.268
[17,     3] loss: 1.214
[18,     3] loss: 1.208
[19,     3] loss: 1.184
[20,     3] loss: 1.188
[21,     3] loss: 1.065
[22,     3] loss: 1.128
[23,     3] loss: 1.041
[24,     3] loss: 1.174
[25,     3] loss: 1.144
[26,     3] loss: 1.041
[27,     3] loss: 1.023
[28,     3] loss: 1.105
[29,     3] loss: 0.958
[30,     3] loss: 1.111
[31,     3] loss: 0.900
[32,     3] loss: 1.016
[33,     3] loss: 0.926
[34,     3] loss: 0.956
[35,     3] loss: 0.913
[36,     3] loss: 1.036
[37,     3] loss: 1.107
[38,     3] loss: 0.958
[39,     3] loss: 0.910
[40,     3] loss: 1.009
[41,     3] loss: 0.959
[42,     3] loss: 0.991
[43,     3] loss: 0.858
[44,     3] loss: 0.960
[45,     3] loss: 1.006
[46,     3] loss: 0.949
[47,     3] loss: 0.894
[48,     3] loss: 0.907
[49,     3] loss: 0.906
[50,     3] loss: 0.934
[51,     3] loss: 0.947
[52,     3] loss: 0.910
[53,     3] loss: 0.827
[54,     3] loss: 0.857
[55,     3] loss: 0.862
[56,     3] loss: 0.797
[57,     3] loss: 0.905
[58,     3] loss: 0.831
[59,     3] loss: 0.933
[60,     3] loss: 1.076
[61,     3] loss: 0.885
[62,     3] loss: 0.836
[63,     3] loss: 0.816
[64,     3] loss: 0.824
[65,     3] loss: 0.861
[66,     3] loss: 0.803
[67,     3] loss: 0.801
[68,     3] loss: 0.792
[69,     3] loss: 0.844
[70,     3] loss: 0.844
[71,     3] loss: 0.776
[72,     3] loss: 0.776
[73,     3] loss: 0.823
[74,     3] loss: 0.875
[75,     3] loss: 0.904
[76,     3] loss: 0.838
[77,     3] loss: 0.903
[78,     3] loss: 0.844
[79,     3] loss: 0.895
[80,     3] loss: 0.881
[81,     3] loss: 0.847
[82,     3] loss: 0.848
[83,     3] loss: 0.787
[84,     3] loss: 0.781
[85,     3] loss: 0.787
[86,     3] loss: 0.757
Early stopping applied (best metric=0.5013425946235657)
Finished Training
Total time taken: 19.122051000595093
{'S-palmitoylation-C Validation Accuracy': 0.6983920931082503, 'S-palmitoylation-C Validation Sensitivity': 0.21042904290429043, 'S-palmitoylation-C Validation Specificity': 0.8207101488915884, 'S-palmitoylation-C Validation Precision': 0.22903999727584834, 'S-palmitoylation-C AUC ROC': 0.5377924031651504, 'S-palmitoylation-C AUC PR': 0.22280194145295215, 'S-palmitoylation-C MCC': 0.0322188388586182, 'S-palmitoylation-C F1': 0.20448140761914974, 'Validation Loss (S-palmitoylation-C)': 0.5547433932622273, 'Hydroxylation-K Validation Accuracy': 0.7664007092198581, 'Hydroxylation-K Validation Sensitivity': 0.8281481481481482, 'Hydroxylation-K Validation Specificity': 0.7508771929824561, 'Hydroxylation-K Validation Precision': 0.4744648723596092, 'Hydroxylation-K AUC ROC': 0.8608187134502924, 'Hydroxylation-K AUC PR': 0.637375154034878, 'Hydroxylation-K MCC': 0.4915247345371887, 'Hydroxylation-K F1': 0.5979491583342158, 'Validation Loss (Hydroxylation-K)': 0.507893317937851, 'Validation Loss (total)': 1.0626367012659708, 'TimeToTrain': 18.371626615524292}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003954016639345798,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.07635678017448598,
 'loss_weight_S-palmitoylation-C': 0.2600627863107856,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 593627170,
 'sample_weights': [0.3438902684953915, 0.4815608125653308],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.167211950025917,
 'weight_decay_Hydroxylation-K': 0.14703561978378293,
 'weight_decay_S-palmitoylation-C': 2.578378716145429}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.390
[3,     3] loss: 1.382
[4,     3] loss: 1.387
[5,     3] loss: 1.391
[6,     3] loss: 1.402
[7,     3] loss: 1.379
[8,     3] loss: 1.367
[9,     3] loss: 1.373
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019200587588481446,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8184093910052773,
 'loss_weight_S-palmitoylation-C': 0.03079714748706846,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1969572677,
 'sample_weights': [0.2600627863107856, 0.07635678017448598],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.930692068616811,
 'weight_decay_Hydroxylation-K': 2.987917670382635,
 'weight_decay_S-palmitoylation-C': 1.6054790642187267}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.389
[3,     3] loss: 1.386
[4,     3] loss: 1.386
[5,     3] loss: 1.385
[6,     3] loss: 1.383
[7,     3] loss: 1.386
[8,     3] loss: 1.369
[9,     3] loss: 1.371
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023637696061904008,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3914510403005492,
 'loss_weight_S-palmitoylation-C': 0.026805654161209336,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1435539578,
 'sample_weights': [0.03079714748706846, 0.8184093910052773],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.8885683197706244,
 'weight_decay_Hydroxylation-K': 1.3439724966575728,
 'weight_decay_S-palmitoylation-C': 0.0781582348467793}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.383
[3,     3] loss: 1.393
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00015657678612123653,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4286893340918468,
 'loss_weight_S-palmitoylation-C': 0.32749506755963426,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2024422361,
 'sample_weights': [0.026805654161209336, 0.3914510403005492],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.297372130624457,
 'weight_decay_Hydroxylation-K': 4.136646951020761,
 'weight_decay_S-palmitoylation-C': 3.6648838644392496}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.383
[3,     3] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004355437918191978,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4007213666105672,
 'loss_weight_S-palmitoylation-C': 0.7896865096698531,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2436570941,
 'sample_weights': [0.32749506755963426, 0.4286893340918468],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.25946770648682,
 'weight_decay_Hydroxylation-K': 0.2895951432112218,
 'weight_decay_S-palmitoylation-C': 3.067823513334594}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006929306386822336,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1578614687389261,
 'loss_weight_S-palmitoylation-C': 0.05551568841578183,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1636474873,
 'sample_weights': [0.7896865096698531, 0.4007213666105672],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.484566213352068,
 'weight_decay_Hydroxylation-K': 0.38200948281335756,
 'weight_decay_S-palmitoylation-C': 0.24424282858026491}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.389
[3,     3] loss: 1.371
[4,     3] loss: 1.366
[5,     3] loss: 1.330
[6,     3] loss: 1.345
[7,     3] loss: 1.309
[8,     3] loss: 1.209
[9,     3] loss: 1.177
[10,     3] loss: 1.186
[11,     3] loss: 1.173
[12,     3] loss: 1.179
[13,     3] loss: 1.175
[14,     3] loss: 1.033
[15,     3] loss: 1.313
[16,     3] loss: 1.245
[17,     3] loss: 1.208
[18,     3] loss: 1.156
[19,     3] loss: 1.065
[20,     3] loss: 0.988
[21,     3] loss: 1.261
[22,     3] loss: 1.118
[23,     3] loss: 1.144
[24,     3] loss: 1.190
[25,     3] loss: 1.086
[26,     3] loss: 1.007
[27,     3] loss: 1.223
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007045520531721796,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5879846036698664,
 'loss_weight_S-palmitoylation-C': 0.8770240593993465,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 894705189,
 'sample_weights': [0.05551568841578183, 0.1578614687389261],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8691896927681411,
 'weight_decay_Hydroxylation-K': 8.208196572525079,
 'weight_decay_S-palmitoylation-C': 5.535801131007399}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.388
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004247128404351883,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.37226164121896965,
 'loss_weight_S-palmitoylation-C': 0.04231467299072233,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2099534986,
 'sample_weights': [0.8770240593993465, 0.5879846036698664],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.345741313045785,
 'weight_decay_Hydroxylation-K': 0.5834482903336233,
 'weight_decay_S-palmitoylation-C': 1.4686141148937846}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.374
[3,     3] loss: 1.426
[4,     3] loss: 1.401
[5,     3] loss: 1.386
[6,     3] loss: 1.387
[7,     3] loss: 1.384
[8,     3] loss: 1.386
[9,     3] loss: 1.378
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015101663196769987,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.40123159821537613,
 'loss_weight_S-palmitoylation-C': 0.21495608716642106,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 483351106,
 'sample_weights': [0.04231467299072233, 0.37226164121896965],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.997581119746098,
 'weight_decay_Hydroxylation-K': 0.062462388487329434,
 'weight_decay_S-palmitoylation-C': 0.5670845281382315}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.385
[3,     3] loss: 1.385
[4,     3] loss: 1.390
[5,     3] loss: 1.388
[6,     3] loss: 1.372
[7,     3] loss: 1.358
[8,     3] loss: 1.337
[9,     3] loss: 1.331
[10,     3] loss: 1.275
[11,     3] loss: 1.271
[12,     3] loss: 1.222
[13,     3] loss: 1.276
[14,     3] loss: 1.225
[15,     3] loss: 1.130
[16,     3] loss: 1.074
[17,     3] loss: 1.116
[18,     3] loss: 1.132
[19,     3] loss: 1.151
[20,     3] loss: 1.067
[21,     3] loss: 1.133
[22,     3] loss: 1.039
[23,     3] loss: 1.061
[24,     3] loss: 1.063
[25,     3] loss: 1.009
[26,     3] loss: 0.987
[27,     3] loss: 1.039
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015262216336883647,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8386470912655531,
 'loss_weight_S-palmitoylation-C': 0.20745438912063338,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3754727359,
 'sample_weights': [0.21495608716642106, 0.40123159821537613],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.9009326761077,
 'weight_decay_Hydroxylation-K': 1.642962088361017,
 'weight_decay_S-palmitoylation-C': 4.531740153124893}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.389
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018967251118285765,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5047315095220919,
 'loss_weight_S-palmitoylation-C': 0.22735420905932482,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3093822635,
 'sample_weights': [0.20745438912063338, 0.8386470912655531],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.054630690571472,
 'weight_decay_Hydroxylation-K': 3.0189466233838766,
 'weight_decay_S-palmitoylation-C': 3.6374640560257294}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.383
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006755811432220394,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9012123966404028,
 'loss_weight_S-palmitoylation-C': 0.08247863648525555,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 55839032,
 'sample_weights': [0.22735420905932482, 0.5047315095220919],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.368411387498415,
 'weight_decay_Hydroxylation-K': 4.586962322423305,
 'weight_decay_S-palmitoylation-C': 3.698684625291772}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.384
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000858862428553769,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9466820540346415,
 'loss_weight_S-palmitoylation-C': 0.02030393223169602,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4223776756,
 'sample_weights': [0.08247863648525555, 0.9012123966404028],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.740829718736583,
 'weight_decay_Hydroxylation-K': 4.563667181498593,
 'weight_decay_S-palmitoylation-C': 6.573000694925587}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.390
[3,     3] loss: 1.387
[4,     3] loss: 1.387
[5,     3] loss: 1.385
[6,     3] loss: 1.375
[7,     3] loss: 1.375
[8,     3] loss: 1.372
[9,     3] loss: 1.370
[10,     3] loss: 1.350
[11,     3] loss: 1.332
[12,     3] loss: 1.319
[13,     3] loss: 1.340
[14,     3] loss: 1.305
[15,     3] loss: 1.234
[16,     3] loss: 1.223
[17,     3] loss: 1.236
[18,     3] loss: 1.197
[19,     3] loss: 1.140
[20,     3] loss: 1.101
[21,     3] loss: 1.082
[22,     3] loss: 0.984
[23,     3] loss: 1.068
[24,     3] loss: 1.107
[25,     3] loss: 1.096
[26,     3] loss: 1.034
[27,     3] loss: 0.994
[28,     3] loss: 1.027
[29,     3] loss: 0.961
[30,     3] loss: 0.947
[31,     3] loss: 0.956
[32,     3] loss: 0.979
[33,     3] loss: 0.886
[34,     3] loss: 0.948
[35,     3] loss: 0.918
[36,     3] loss: 0.846
[37,     3] loss: 0.930
[38,     3] loss: 0.881
[39,     3] loss: 0.875
[40,     3] loss: 0.838
[41,     3] loss: 0.870
[42,     3] loss: 0.878
[43,     3] loss: 0.954
[44,     3] loss: 0.883
[45,     3] loss: 0.960
[46,     3] loss: 0.928
[47,     3] loss: 0.948
[48,     3] loss: 0.915
[49,     3] loss: 0.939
[50,     3] loss: 0.898
[51,     3] loss: 0.927
[52,     3] loss: 0.878
[53,     3] loss: 0.851
[54,     3] loss: 0.905
[55,     3] loss: 0.884
[56,     3] loss: 0.812
[57,     3] loss: 0.861
[58,     3] loss: 0.846
[59,     3] loss: 0.856
[60,     3] loss: 0.916
[61,     3] loss: 0.824
[62,     3] loss: 0.869
[63,     3] loss: 0.789
[64,     3] loss: 0.809
[65,     3] loss: 0.851
[66,     3] loss: 0.795
[67,     3] loss: 0.820
[68,     3] loss: 0.792
[69,     3] loss: 0.855
[70,     3] loss: 0.807
[71,     3] loss: 0.816
[72,     3] loss: 0.891
[73,     3] loss: 0.856
[74,     3] loss: 1.004
[75,     3] loss: 0.859
Early stopping applied (best metric=0.5067650675773621)
Finished Training
Total time taken: 16.705042839050293
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.386
[3,     3] loss: 1.383
[4,     3] loss: 1.383
[5,     3] loss: 1.381
[6,     3] loss: 1.384
[7,     3] loss: 1.371
[8,     3] loss: 1.365
[9,     3] loss: 1.337
[10,     3] loss: 1.323
[11,     3] loss: 1.298
[12,     3] loss: 1.281
[13,     3] loss: 1.229
[14,     3] loss: 1.147
[15,     3] loss: 1.169
[16,     3] loss: 1.193
[17,     3] loss: 1.219
[18,     3] loss: 1.138
[19,     3] loss: 1.125
[20,     3] loss: 1.146
[21,     3] loss: 1.051
[22,     3] loss: 1.116
[23,     3] loss: 1.039
[24,     3] loss: 0.927
[25,     3] loss: 0.998
[26,     3] loss: 1.043
[27,     3] loss: 0.962
[28,     3] loss: 0.958
[29,     3] loss: 0.993
[30,     3] loss: 0.905
[31,     3] loss: 1.040
[32,     3] loss: 0.997
[33,     3] loss: 0.956
[34,     3] loss: 0.984
[35,     3] loss: 0.932
[36,     3] loss: 0.978
[37,     3] loss: 0.951
[38,     3] loss: 1.026
[39,     3] loss: 0.937
[40,     3] loss: 0.885
[41,     3] loss: 0.899
[42,     3] loss: 0.919
[43,     3] loss: 0.881
[44,     3] loss: 0.976
[45,     3] loss: 0.875
[46,     3] loss: 0.911
[47,     3] loss: 0.857
[48,     3] loss: 1.015
[49,     3] loss: 0.876
[50,     3] loss: 0.929
[51,     3] loss: 0.928
[52,     3] loss: 0.879
[53,     3] loss: 0.930
[54,     3] loss: 0.854
[55,     3] loss: 0.996
[56,     3] loss: 0.893
[57,     3] loss: 0.883
[58,     3] loss: 0.926
[59,     3] loss: 0.841
[60,     3] loss: 0.827
[61,     3] loss: 0.859
[62,     3] loss: 0.920
[63,     3] loss: 0.833
[64,     3] loss: 0.922
[65,     3] loss: 0.940
Early stopping applied (best metric=0.5423545837402344)
Finished Training
Total time taken: 14.571038246154785
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.401
[2,     3] loss: 1.391
[3,     3] loss: 1.391
[4,     3] loss: 1.384
[5,     3] loss: 1.384
[6,     3] loss: 1.379
[7,     3] loss: 1.382
[8,     3] loss: 1.373
[9,     3] loss: 1.367
[10,     3] loss: 1.363
[11,     3] loss: 1.345
[12,     3] loss: 1.317
[13,     3] loss: 1.330
[14,     3] loss: 1.256
[15,     3] loss: 1.224
[16,     3] loss: 1.235
[17,     3] loss: 1.180
[18,     3] loss: 1.190
[19,     3] loss: 1.106
[20,     3] loss: 1.198
[21,     3] loss: 1.058
[22,     3] loss: 1.069
[23,     3] loss: 1.027
[24,     3] loss: 1.043
[25,     3] loss: 0.921
[26,     3] loss: 0.948
[27,     3] loss: 0.950
[28,     3] loss: 0.915
[29,     3] loss: 1.064
[30,     3] loss: 0.878
[31,     3] loss: 0.869
[32,     3] loss: 0.978
[33,     3] loss: 0.840
[34,     3] loss: 0.907
[35,     3] loss: 0.899
[36,     3] loss: 0.819
[37,     3] loss: 0.855
[38,     3] loss: 0.857
[39,     3] loss: 0.831
[40,     3] loss: 0.819
[41,     3] loss: 0.840
[42,     3] loss: 0.902
[43,     3] loss: 0.890
[44,     3] loss: 0.879
[45,     3] loss: 0.887
[46,     3] loss: 0.796
[47,     3] loss: 0.872
[48,     3] loss: 0.819
[49,     3] loss: 0.815
[50,     3] loss: 0.836
[51,     3] loss: 0.853
[52,     3] loss: 0.860
[53,     3] loss: 0.811
[54,     3] loss: 0.792
[55,     3] loss: 0.796
[56,     3] loss: 0.803
[57,     3] loss: 0.817
[58,     3] loss: 0.796
[59,     3] loss: 0.794
[60,     3] loss: 0.798
[61,     3] loss: 0.803
[62,     3] loss: 0.864
[63,     3] loss: 0.924
[64,     3] loss: 0.968
[65,     3] loss: 0.826
[66,     3] loss: 0.833
[67,     3] loss: 0.869
[68,     3] loss: 0.838
[69,     3] loss: 0.795
[70,     3] loss: 0.784
[71,     3] loss: 0.784
[72,     3] loss: 0.783
Early stopping applied (best metric=0.5384628176689148)
Finished Training
Total time taken: 16.11104941368103
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.387
[3,     3] loss: 1.388
[4,     3] loss: 1.383
[5,     3] loss: 1.392
[6,     3] loss: 1.381
[7,     3] loss: 1.388
[8,     3] loss: 1.380
[9,     3] loss: 1.366
[10,     3] loss: 1.379
[11,     3] loss: 1.362
[12,     3] loss: 1.369
[13,     3] loss: 1.332
[14,     3] loss: 1.334
[15,     3] loss: 1.316
[16,     3] loss: 1.313
[17,     3] loss: 1.285
[18,     3] loss: 1.289
[19,     3] loss: 1.236
[20,     3] loss: 1.173
[21,     3] loss: 1.180
[22,     3] loss: 1.165
[23,     3] loss: 1.063
[24,     3] loss: 1.083
[25,     3] loss: 1.033
[26,     3] loss: 1.039
[27,     3] loss: 0.998
[28,     3] loss: 0.980
[29,     3] loss: 1.074
[30,     3] loss: 0.956
[31,     3] loss: 0.946
[32,     3] loss: 0.998
[33,     3] loss: 0.966
[34,     3] loss: 1.019
[35,     3] loss: 0.948
[36,     3] loss: 0.931
[37,     3] loss: 0.941
[38,     3] loss: 0.935
[39,     3] loss: 0.948
[40,     3] loss: 1.015
[41,     3] loss: 0.911
[42,     3] loss: 0.927
[43,     3] loss: 0.895
[44,     3] loss: 0.913
[45,     3] loss: 1.007
[46,     3] loss: 0.897
[47,     3] loss: 0.899
[48,     3] loss: 0.884
[49,     3] loss: 0.901
[50,     3] loss: 0.813
[51,     3] loss: 0.950
[52,     3] loss: 0.872
[53,     3] loss: 0.863
[54,     3] loss: 0.856
[55,     3] loss: 0.837
[56,     3] loss: 0.938
[57,     3] loss: 0.962
[58,     3] loss: 0.858
[59,     3] loss: 0.825
[60,     3] loss: 0.891
[61,     3] loss: 0.881
[62,     3] loss: 0.827
[63,     3] loss: 0.818
[64,     3] loss: 0.794
[65,     3] loss: 0.832
[66,     3] loss: 0.788
[67,     3] loss: 0.776
[68,     3] loss: 0.798
[69,     3] loss: 0.856
[70,     3] loss: 0.781
[71,     3] loss: 0.801
[72,     3] loss: 0.778
[73,     3] loss: 0.811
[74,     3] loss: 0.810
Early stopping applied (best metric=0.5100868940353394)
Finished Training
Total time taken: 16.50504183769226
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.406
[2,     3] loss: 1.389
[3,     3] loss: 1.382
[4,     3] loss: 1.383
[5,     3] loss: 1.385
[6,     3] loss: 1.383
[7,     3] loss: 1.387
[8,     3] loss: 1.388
[9,     3] loss: 1.377
[10,     3] loss: 1.379
[11,     3] loss: 1.357
[12,     3] loss: 1.353
[13,     3] loss: 1.342
[14,     3] loss: 1.329
[15,     3] loss: 1.319
[16,     3] loss: 1.301
[17,     3] loss: 1.252
[18,     3] loss: 1.161
[19,     3] loss: 1.184
[20,     3] loss: 1.188
[21,     3] loss: 1.111
[22,     3] loss: 1.127
[23,     3] loss: 1.084
[24,     3] loss: 1.052
[25,     3] loss: 1.102
[26,     3] loss: 1.004
[27,     3] loss: 1.034
[28,     3] loss: 1.142
[29,     3] loss: 1.055
[30,     3] loss: 1.027
[31,     3] loss: 0.982
[32,     3] loss: 1.021
[33,     3] loss: 1.054
[34,     3] loss: 0.936
[35,     3] loss: 0.975
[36,     3] loss: 0.906
[37,     3] loss: 0.919
[38,     3] loss: 0.881
[39,     3] loss: 0.983
[40,     3] loss: 0.903
[41,     3] loss: 1.005
[42,     3] loss: 0.965
[43,     3] loss: 0.943
[44,     3] loss: 0.923
[45,     3] loss: 0.904
[46,     3] loss: 0.933
[47,     3] loss: 0.941
[48,     3] loss: 0.938
[49,     3] loss: 0.863
[50,     3] loss: 0.845
[51,     3] loss: 0.871
[52,     3] loss: 0.836
[53,     3] loss: 0.877
[54,     3] loss: 0.908
[55,     3] loss: 0.890
[56,     3] loss: 0.929
[57,     3] loss: 0.914
[58,     3] loss: 0.874
[59,     3] loss: 0.855
[60,     3] loss: 0.868
[61,     3] loss: 0.895
[62,     3] loss: 0.905
[63,     3] loss: 0.852
[64,     3] loss: 0.832
[65,     3] loss: 0.874
[66,     3] loss: 0.880
[67,     3] loss: 0.839
[68,     3] loss: 0.844
[69,     3] loss: 0.852
[70,     3] loss: 0.803
[71,     3] loss: 0.889
[72,     3] loss: 0.845
[73,     3] loss: 0.810
[74,     3] loss: 0.861
[75,     3] loss: 0.818
[76,     3] loss: 0.847
[77,     3] loss: 0.861
[78,     3] loss: 0.858
[79,     3] loss: 0.870
[80,     3] loss: 0.812
[81,     3] loss: 0.826
[82,     3] loss: 0.849
[83,     3] loss: 0.811
[84,     3] loss: 0.889
[85,     3] loss: 0.906
[86,     3] loss: 0.816
[87,     3] loss: 0.829
[88,     3] loss: 0.848
[89,     3] loss: 0.797
[90,     3] loss: 0.780
[91,     3] loss: 0.806
[92,     3] loss: 0.792
[93,     3] loss: 0.774
[94,     3] loss: 0.789
[95,     3] loss: 0.761
[96,     3] loss: 0.796
Early stopping applied (best metric=0.5162304639816284)
Finished Training
Total time taken: 21.40205693244934
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.384
[3,     3] loss: 1.382
[4,     3] loss: 1.379
[5,     3] loss: 1.380
[6,     3] loss: 1.368
[7,     3] loss: 1.363
[8,     3] loss: 1.343
[9,     3] loss: 1.323
[10,     3] loss: 1.299
[11,     3] loss: 1.309
[12,     3] loss: 1.236
[13,     3] loss: 1.261
[14,     3] loss: 1.256
[15,     3] loss: 1.210
[16,     3] loss: 1.145
[17,     3] loss: 1.147
[18,     3] loss: 1.127
[19,     3] loss: 1.094
[20,     3] loss: 1.084
[21,     3] loss: 1.034
[22,     3] loss: 1.042
[23,     3] loss: 1.035
[24,     3] loss: 0.942
[25,     3] loss: 1.004
[26,     3] loss: 1.084
[27,     3] loss: 0.940
[28,     3] loss: 0.969
[29,     3] loss: 0.935
[30,     3] loss: 1.001
[31,     3] loss: 0.992
[32,     3] loss: 1.029
[33,     3] loss: 0.960
[34,     3] loss: 1.042
[35,     3] loss: 1.000
[36,     3] loss: 0.925
[37,     3] loss: 0.973
[38,     3] loss: 0.869
[39,     3] loss: 0.868
[40,     3] loss: 0.858
[41,     3] loss: 0.893
[42,     3] loss: 0.892
[43,     3] loss: 0.935
[44,     3] loss: 0.924
[45,     3] loss: 0.959
[46,     3] loss: 0.887
[47,     3] loss: 0.885
[48,     3] loss: 0.857
[49,     3] loss: 0.831
[50,     3] loss: 0.837
[51,     3] loss: 0.836
[52,     3] loss: 0.847
[53,     3] loss: 0.833
[54,     3] loss: 0.857
[55,     3] loss: 0.840
[56,     3] loss: 0.836
[57,     3] loss: 0.832
[58,     3] loss: 0.857
[59,     3] loss: 0.858
[60,     3] loss: 0.794
[61,     3] loss: 0.894
[62,     3] loss: 0.834
[63,     3] loss: 0.791
[64,     3] loss: 0.805
[65,     3] loss: 0.853
[66,     3] loss: 0.828
[67,     3] loss: 0.792
[68,     3] loss: 0.791
[69,     3] loss: 0.807
Early stopping applied (best metric=0.5276985764503479)
Finished Training
Total time taken: 15.392041683197021
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.387
[3,     3] loss: 1.384
[4,     3] loss: 1.387
[5,     3] loss: 1.385
[6,     3] loss: 1.385
[7,     3] loss: 1.372
[8,     3] loss: 1.375
[9,     3] loss: 1.370
[10,     3] loss: 1.365
[11,     3] loss: 1.339
[12,     3] loss: 1.344
[13,     3] loss: 1.292
[14,     3] loss: 1.257
[15,     3] loss: 1.273
[16,     3] loss: 1.216
[17,     3] loss: 1.168
[18,     3] loss: 1.149
[19,     3] loss: 1.183
[20,     3] loss: 1.155
[21,     3] loss: 1.057
[22,     3] loss: 1.077
[23,     3] loss: 1.123
[24,     3] loss: 1.010
[25,     3] loss: 1.043
[26,     3] loss: 1.004
[27,     3] loss: 0.971
[28,     3] loss: 0.999
[29,     3] loss: 1.182
[30,     3] loss: 1.075
[31,     3] loss: 0.960
[32,     3] loss: 1.108
[33,     3] loss: 1.007
[34,     3] loss: 0.989
[35,     3] loss: 0.974
[36,     3] loss: 0.984
[37,     3] loss: 1.002
[38,     3] loss: 1.068
[39,     3] loss: 0.902
[40,     3] loss: 0.920
[41,     3] loss: 0.951
[42,     3] loss: 0.872
[43,     3] loss: 0.880
[44,     3] loss: 0.846
[45,     3] loss: 0.920
[46,     3] loss: 0.951
[47,     3] loss: 0.839
[48,     3] loss: 0.852
[49,     3] loss: 0.859
[50,     3] loss: 0.833
[51,     3] loss: 0.914
[52,     3] loss: 0.876
[53,     3] loss: 0.975
[54,     3] loss: 0.963
[55,     3] loss: 0.855
[56,     3] loss: 0.855
[57,     3] loss: 0.875
[58,     3] loss: 0.872
[59,     3] loss: 0.845
[60,     3] loss: 0.785
[61,     3] loss: 0.774
[62,     3] loss: 0.779
[63,     3] loss: 0.747
[64,     3] loss: 0.793
[65,     3] loss: 0.759
[66,     3] loss: 0.795
[67,     3] loss: 0.752
[68,     3] loss: 0.798
[69,     3] loss: 0.827
[70,     3] loss: 0.800
[71,     3] loss: 0.815
[72,     3] loss: 0.929
[73,     3] loss: 0.896
Early stopping applied (best metric=0.5291069746017456)
Finished Training
Total time taken: 16.292040824890137
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.380
[3,     3] loss: 1.382
[4,     3] loss: 1.386
[5,     3] loss: 1.383
[6,     3] loss: 1.378
[7,     3] loss: 1.362
[8,     3] loss: 1.354
[9,     3] loss: 1.342
[10,     3] loss: 1.315
[11,     3] loss: 1.319
[12,     3] loss: 1.258
[13,     3] loss: 1.237
[14,     3] loss: 1.190
[15,     3] loss: 1.203
[16,     3] loss: 1.234
[17,     3] loss: 1.107
[18,     3] loss: 1.096
[19,     3] loss: 1.056
[20,     3] loss: 1.069
[21,     3] loss: 1.170
[22,     3] loss: 0.949
[23,     3] loss: 1.026
[24,     3] loss: 1.075
[25,     3] loss: 1.118
[26,     3] loss: 1.003
[27,     3] loss: 1.037
[28,     3] loss: 1.034
[29,     3] loss: 1.004
[30,     3] loss: 0.938
[31,     3] loss: 0.939
[32,     3] loss: 1.031
[33,     3] loss: 0.888
[34,     3] loss: 0.925
[35,     3] loss: 0.986
[36,     3] loss: 0.937
[37,     3] loss: 0.913
[38,     3] loss: 0.952
[39,     3] loss: 1.168
[40,     3] loss: 0.922
[41,     3] loss: 0.878
[42,     3] loss: 0.903
[43,     3] loss: 0.855
[44,     3] loss: 0.854
[45,     3] loss: 0.921
[46,     3] loss: 0.930
[47,     3] loss: 0.930
[48,     3] loss: 0.855
[49,     3] loss: 0.850
[50,     3] loss: 0.894
[51,     3] loss: 0.947
[52,     3] loss: 0.853
[53,     3] loss: 0.883
[54,     3] loss: 0.807
[55,     3] loss: 0.860
[56,     3] loss: 0.915
[57,     3] loss: 0.901
[58,     3] loss: 0.825
[59,     3] loss: 0.864
[60,     3] loss: 0.881
[61,     3] loss: 0.870
[62,     3] loss: 0.808
[63,     3] loss: 0.857
[64,     3] loss: 0.807
[65,     3] loss: 0.801
[66,     3] loss: 0.795
[67,     3] loss: 0.823
[68,     3] loss: 0.788
[69,     3] loss: 0.837
[70,     3] loss: 0.786
Early stopping applied (best metric=0.522756814956665)
Finished Training
Total time taken: 15.600056171417236
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.403
[3,     3] loss: 1.386
[4,     3] loss: 1.387
[5,     3] loss: 1.385
[6,     3] loss: 1.387
[7,     3] loss: 1.392
[8,     3] loss: 1.375
[9,     3] loss: 1.378
[10,     3] loss: 1.378
[11,     3] loss: 1.376
[12,     3] loss: 1.366
[13,     3] loss: 1.346
[14,     3] loss: 1.327
[15,     3] loss: 1.322
[16,     3] loss: 1.294
[17,     3] loss: 1.223
[18,     3] loss: 1.239
[19,     3] loss: 1.225
[20,     3] loss: 1.159
[21,     3] loss: 1.149
[22,     3] loss: 1.191
[23,     3] loss: 1.161
[24,     3] loss: 1.162
[25,     3] loss: 1.105
[26,     3] loss: 1.106
[27,     3] loss: 1.016
[28,     3] loss: 1.014
[29,     3] loss: 1.024
[30,     3] loss: 1.037
[31,     3] loss: 0.968
[32,     3] loss: 0.948
[33,     3] loss: 1.038
[34,     3] loss: 1.066
[35,     3] loss: 0.933
[36,     3] loss: 0.973
[37,     3] loss: 1.007
[38,     3] loss: 1.120
[39,     3] loss: 0.958
[40,     3] loss: 1.072
[41,     3] loss: 1.007
[42,     3] loss: 0.954
[43,     3] loss: 0.954
[44,     3] loss: 0.929
[45,     3] loss: 0.940
[46,     3] loss: 0.924
[47,     3] loss: 0.912
[48,     3] loss: 0.899
[49,     3] loss: 0.959
[50,     3] loss: 0.896
[51,     3] loss: 0.834
[52,     3] loss: 0.872
[53,     3] loss: 0.867
[54,     3] loss: 0.849
[55,     3] loss: 0.950
[56,     3] loss: 0.790
[57,     3] loss: 0.936
[58,     3] loss: 0.975
[59,     3] loss: 1.098
[60,     3] loss: 0.983
[61,     3] loss: 1.034
[62,     3] loss: 1.077
[63,     3] loss: 1.004
[64,     3] loss: 1.009
[65,     3] loss: 0.959
[66,     3] loss: 0.871
[67,     3] loss: 0.904
[68,     3] loss: 0.879
[69,     3] loss: 0.852
[70,     3] loss: 0.842
[71,     3] loss: 0.850
[72,     3] loss: 0.817
Early stopping applied (best metric=0.48967793583869934)
Finished Training
Total time taken: 16.029059410095215
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.391
[3,     3] loss: 1.393
[4,     3] loss: 1.393
[5,     3] loss: 1.389
[6,     3] loss: 1.386
[7,     3] loss: 1.382
[8,     3] loss: 1.382
[9,     3] loss: 1.383
[10,     3] loss: 1.379
[11,     3] loss: 1.382
[12,     3] loss: 1.368
[13,     3] loss: 1.357
[14,     3] loss: 1.360
[15,     3] loss: 1.340
[16,     3] loss: 1.320
[17,     3] loss: 1.261
[18,     3] loss: 1.298
[19,     3] loss: 1.358
[20,     3] loss: 1.251
[21,     3] loss: 1.184
[22,     3] loss: 1.191
[23,     3] loss: 1.186
[24,     3] loss: 1.070
[25,     3] loss: 1.092
[26,     3] loss: 1.074
[27,     3] loss: 1.016
[28,     3] loss: 0.998
[29,     3] loss: 0.973
[30,     3] loss: 1.060
[31,     3] loss: 0.896
[32,     3] loss: 0.881
[33,     3] loss: 0.951
[34,     3] loss: 0.909
[35,     3] loss: 0.902
[36,     3] loss: 0.914
[37,     3] loss: 0.910
[38,     3] loss: 1.020
[39,     3] loss: 1.079
[40,     3] loss: 0.917
[41,     3] loss: 1.028
[42,     3] loss: 0.894
[43,     3] loss: 0.924
[44,     3] loss: 0.870
[45,     3] loss: 0.912
[46,     3] loss: 0.843
[47,     3] loss: 0.864
[48,     3] loss: 0.889
[49,     3] loss: 0.863
[50,     3] loss: 0.931
[51,     3] loss: 0.907
[52,     3] loss: 0.824
[53,     3] loss: 0.912
[54,     3] loss: 0.893
[55,     3] loss: 0.911
[56,     3] loss: 0.839
[57,     3] loss: 0.884
[58,     3] loss: 0.876
[59,     3] loss: 0.909
[60,     3] loss: 0.903
[61,     3] loss: 0.813
[62,     3] loss: 0.847
[63,     3] loss: 0.812
[64,     3] loss: 0.831
[65,     3] loss: 0.786
[66,     3] loss: 0.768
[67,     3] loss: 0.759
[68,     3] loss: 0.759
[69,     3] loss: 0.765
[70,     3] loss: 0.768
[71,     3] loss: 0.746
[72,     3] loss: 0.805
[73,     3] loss: 0.774
[74,     3] loss: 0.810
[75,     3] loss: 0.858
[76,     3] loss: 0.843
Early stopping applied (best metric=0.4894455373287201)
Finished Training
Total time taken: 17.02706217765808
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.396
[3,     3] loss: 1.385
[4,     3] loss: 1.393
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.382
[8,     3] loss: 1.387
[9,     3] loss: 1.384
[10,     3] loss: 1.381
[11,     3] loss: 1.379
[12,     3] loss: 1.378
[13,     3] loss: 1.367
[14,     3] loss: 1.353
[15,     3] loss: 1.341
[16,     3] loss: 1.355
[17,     3] loss: 1.291
[18,     3] loss: 1.267
[19,     3] loss: 1.260
[20,     3] loss: 1.238
[21,     3] loss: 1.151
[22,     3] loss: 1.087
[23,     3] loss: 1.082
[24,     3] loss: 1.101
[25,     3] loss: 1.031
[26,     3] loss: 1.006
[27,     3] loss: 1.051
[28,     3] loss: 0.978
[29,     3] loss: 1.097
[30,     3] loss: 1.058
[31,     3] loss: 1.059
[32,     3] loss: 1.030
[33,     3] loss: 0.984
[34,     3] loss: 0.932
[35,     3] loss: 0.987
[36,     3] loss: 0.930
[37,     3] loss: 0.894
[38,     3] loss: 0.953
[39,     3] loss: 0.884
[40,     3] loss: 0.894
[41,     3] loss: 0.940
[42,     3] loss: 1.021
[43,     3] loss: 1.041
[44,     3] loss: 1.073
[45,     3] loss: 0.889
[46,     3] loss: 0.927
[47,     3] loss: 0.904
[48,     3] loss: 0.906
[49,     3] loss: 0.869
[50,     3] loss: 0.866
[51,     3] loss: 0.875
[52,     3] loss: 0.837
[53,     3] loss: 0.802
[54,     3] loss: 0.859
[55,     3] loss: 0.826
[56,     3] loss: 0.773
[57,     3] loss: 0.854
[58,     3] loss: 0.857
[59,     3] loss: 0.829
[60,     3] loss: 0.907
[61,     3] loss: 0.801
[62,     3] loss: 0.807
[63,     3] loss: 0.830
[64,     3] loss: 0.889
[65,     3] loss: 0.798
[66,     3] loss: 0.830
[67,     3] loss: 0.823
[68,     3] loss: 0.856
[69,     3] loss: 0.861
[70,     3] loss: 0.861
[71,     3] loss: 0.871
[72,     3] loss: 0.860
[73,     3] loss: 0.818
[74,     3] loss: 0.863
[75,     3] loss: 0.824
Early stopping applied (best metric=0.5250641107559204)
Finished Training
Total time taken: 16.786237001419067
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.391
[3,     3] loss: 1.379
[4,     3] loss: 1.385
[5,     3] loss: 1.383
[6,     3] loss: 1.382
[7,     3] loss: 1.374
[8,     3] loss: 1.361
[9,     3] loss: 1.355
[10,     3] loss: 1.335
[11,     3] loss: 1.306
[12,     3] loss: 1.269
[13,     3] loss: 1.294
[14,     3] loss: 1.228
[15,     3] loss: 1.201
[16,     3] loss: 1.181
[17,     3] loss: 1.154
[18,     3] loss: 1.167
[19,     3] loss: 1.168
[20,     3] loss: 1.078
[21,     3] loss: 1.089
[22,     3] loss: 1.023
[23,     3] loss: 1.075
[24,     3] loss: 1.013
[25,     3] loss: 1.030
[26,     3] loss: 1.030
[27,     3] loss: 0.964
[28,     3] loss: 1.048
[29,     3] loss: 1.001
[30,     3] loss: 1.144
[31,     3] loss: 1.086
[32,     3] loss: 0.915
[33,     3] loss: 0.956
[34,     3] loss: 1.009
[35,     3] loss: 0.953
[36,     3] loss: 0.898
[37,     3] loss: 0.893
[38,     3] loss: 0.875
[39,     3] loss: 0.942
[40,     3] loss: 0.999
[41,     3] loss: 0.839
[42,     3] loss: 0.839
[43,     3] loss: 0.844
[44,     3] loss: 0.911
[45,     3] loss: 0.908
[46,     3] loss: 0.856
[47,     3] loss: 0.820
[48,     3] loss: 0.873
[49,     3] loss: 0.909
[50,     3] loss: 0.820
[51,     3] loss: 0.880
[52,     3] loss: 0.883
[53,     3] loss: 0.849
[54,     3] loss: 0.877
[55,     3] loss: 0.866
[56,     3] loss: 0.838
[57,     3] loss: 0.818
[58,     3] loss: 0.825
[59,     3] loss: 0.823
[60,     3] loss: 0.816
[61,     3] loss: 0.766
[62,     3] loss: 0.854
[63,     3] loss: 0.832
[64,     3] loss: 0.789
[65,     3] loss: 0.833
[66,     3] loss: 0.784
[67,     3] loss: 0.756
[68,     3] loss: 0.800
[69,     3] loss: 0.788
[70,     3] loss: 0.799
[71,     3] loss: 0.803
[72,     3] loss: 0.777
[73,     3] loss: 0.801
[74,     3] loss: 0.801
[75,     3] loss: 0.780
[76,     3] loss: 0.778
[77,     3] loss: 0.778
Early stopping applied (best metric=0.5355707406997681)
Finished Training
Total time taken: 17.137048482894897
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.389
[3,     3] loss: 1.385
[4,     3] loss: 1.387
[5,     3] loss: 1.378
[6,     3] loss: 1.379
[7,     3] loss: 1.381
[8,     3] loss: 1.387
[9,     3] loss: 1.378
[10,     3] loss: 1.385
[11,     3] loss: 1.380
[12,     3] loss: 1.374
[13,     3] loss: 1.374
[14,     3] loss: 1.363
[15,     3] loss: 1.342
[16,     3] loss: 1.352
[17,     3] loss: 1.322
[18,     3] loss: 1.307
[19,     3] loss: 1.261
[20,     3] loss: 1.231
[21,     3] loss: 1.275
[22,     3] loss: 1.241
[23,     3] loss: 1.159
[24,     3] loss: 1.175
[25,     3] loss: 1.102
[26,     3] loss: 1.058
[27,     3] loss: 1.124
[28,     3] loss: 1.053
[29,     3] loss: 1.130
[30,     3] loss: 1.084
[31,     3] loss: 1.085
[32,     3] loss: 1.026
[33,     3] loss: 1.051
[34,     3] loss: 0.974
[35,     3] loss: 0.976
[36,     3] loss: 0.960
[37,     3] loss: 0.949
[38,     3] loss: 0.995
[39,     3] loss: 1.085
[40,     3] loss: 0.909
[41,     3] loss: 0.943
[42,     3] loss: 0.916
[43,     3] loss: 0.873
[44,     3] loss: 0.876
[45,     3] loss: 0.843
[46,     3] loss: 0.938
[47,     3] loss: 0.881
[48,     3] loss: 0.908
[49,     3] loss: 0.844
[50,     3] loss: 0.860
[51,     3] loss: 0.826
[52,     3] loss: 0.803
[53,     3] loss: 0.832
[54,     3] loss: 0.804
[55,     3] loss: 0.805
[56,     3] loss: 0.805
[57,     3] loss: 0.852
[58,     3] loss: 0.933
[59,     3] loss: 1.039
[60,     3] loss: 0.935
[61,     3] loss: 0.876
[62,     3] loss: 1.023
[63,     3] loss: 0.894
[64,     3] loss: 1.013
[65,     3] loss: 0.913
[66,     3] loss: 0.845
[67,     3] loss: 0.849
[68,     3] loss: 0.840
[69,     3] loss: 0.875
[70,     3] loss: 0.824
[71,     3] loss: 0.771
[72,     3] loss: 0.795
[73,     3] loss: 0.869
[74,     3] loss: 0.831
[75,     3] loss: 0.831
[76,     3] loss: 0.829
[77,     3] loss: 0.790
[78,     3] loss: 0.774
[79,     3] loss: 0.846
[80,     3] loss: 0.838
[81,     3] loss: 0.769
[82,     3] loss: 0.810
[83,     3] loss: 0.766
[84,     3] loss: 0.783
Early stopping applied (best metric=0.5157827138900757)
Finished Training
Total time taken: 18.794050455093384
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.387
[3,     3] loss: 1.386
[4,     3] loss: 1.385
[5,     3] loss: 1.385
[6,     3] loss: 1.385
[7,     3] loss: 1.381
[8,     3] loss: 1.380
[9,     3] loss: 1.374
[10,     3] loss: 1.369
[11,     3] loss: 1.372
[12,     3] loss: 1.351
[13,     3] loss: 1.350
[14,     3] loss: 1.307
[15,     3] loss: 1.304
[16,     3] loss: 1.246
[17,     3] loss: 1.209
[18,     3] loss: 1.194
[19,     3] loss: 1.137
[20,     3] loss: 1.207
[21,     3] loss: 1.130
[22,     3] loss: 1.162
[23,     3] loss: 1.204
[24,     3] loss: 1.079
[25,     3] loss: 1.119
[26,     3] loss: 1.091
[27,     3] loss: 1.128
[28,     3] loss: 1.193
[29,     3] loss: 1.175
[30,     3] loss: 1.164
[31,     3] loss: 1.134
[32,     3] loss: 1.106
[33,     3] loss: 1.074
[34,     3] loss: 1.111
[35,     3] loss: 1.018
[36,     3] loss: 1.017
[37,     3] loss: 1.037
[38,     3] loss: 0.898
[39,     3] loss: 0.922
[40,     3] loss: 1.060
[41,     3] loss: 0.984
[42,     3] loss: 0.933
[43,     3] loss: 0.927
[44,     3] loss: 0.998
[45,     3] loss: 0.978
[46,     3] loss: 0.949
[47,     3] loss: 0.928
[48,     3] loss: 0.961
[49,     3] loss: 0.949
[50,     3] loss: 0.979
[51,     3] loss: 0.902
[52,     3] loss: 0.892
[53,     3] loss: 0.856
[54,     3] loss: 0.849
[55,     3] loss: 0.879
[56,     3] loss: 0.801
[57,     3] loss: 0.833
[58,     3] loss: 0.832
[59,     3] loss: 0.943
[60,     3] loss: 0.972
[61,     3] loss: 0.934
[62,     3] loss: 0.922
[63,     3] loss: 0.884
[64,     3] loss: 0.861
[65,     3] loss: 0.935
[66,     3] loss: 0.943
[67,     3] loss: 0.953
[68,     3] loss: 0.847
Early stopping applied (best metric=0.49276819825172424)
Finished Training
Total time taken: 15.19504165649414
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.383
[3,     3] loss: 1.391
[4,     3] loss: 1.387
[5,     3] loss: 1.387
[6,     3] loss: 1.382
[7,     3] loss: 1.370
[8,     3] loss: 1.366
[9,     3] loss: 1.368
[10,     3] loss: 1.333
[11,     3] loss: 1.327
[12,     3] loss: 1.302
[13,     3] loss: 1.266
[14,     3] loss: 1.246
[15,     3] loss: 1.269
[16,     3] loss: 1.222
[17,     3] loss: 1.157
[18,     3] loss: 1.245
[19,     3] loss: 1.171
[20,     3] loss: 1.175
[21,     3] loss: 1.096
[22,     3] loss: 1.179
[23,     3] loss: 1.145
[24,     3] loss: 1.055
[25,     3] loss: 1.155
[26,     3] loss: 1.107
[27,     3] loss: 1.080
[28,     3] loss: 1.102
[29,     3] loss: 1.127
[30,     3] loss: 1.002
[31,     3] loss: 0.954
[32,     3] loss: 0.952
[33,     3] loss: 0.962
[34,     3] loss: 1.011
[35,     3] loss: 0.968
[36,     3] loss: 1.072
[37,     3] loss: 1.013
[38,     3] loss: 1.049
[39,     3] loss: 1.063
[40,     3] loss: 0.971
[41,     3] loss: 0.939
[42,     3] loss: 0.886
[43,     3] loss: 0.978
[44,     3] loss: 1.015
[45,     3] loss: 0.863
[46,     3] loss: 0.905
[47,     3] loss: 0.925
[48,     3] loss: 0.856
[49,     3] loss: 0.849
[50,     3] loss: 0.891
[51,     3] loss: 0.833
[52,     3] loss: 0.823
[53,     3] loss: 0.824
[54,     3] loss: 0.829
[55,     3] loss: 0.883
[56,     3] loss: 0.821
[57,     3] loss: 0.819
[58,     3] loss: 0.827
[59,     3] loss: 0.812
[60,     3] loss: 0.826
[61,     3] loss: 0.908
[62,     3] loss: 0.838
[63,     3] loss: 0.810
[64,     3] loss: 0.797
[65,     3] loss: 0.772
[66,     3] loss: 0.774
[67,     3] loss: 0.779
[68,     3] loss: 0.817
[69,     3] loss: 0.820
[70,     3] loss: 0.797
[71,     3] loss: 0.801
[72,     3] loss: 0.790
[73,     3] loss: 0.808
[74,     3] loss: 0.778
[75,     3] loss: 0.797
[76,     3] loss: 0.776
[77,     3] loss: 0.762
[78,     3] loss: 0.763
[79,     3] loss: 0.780
[80,     3] loss: 0.774
[81,     3] loss: 0.772
[82,     3] loss: 0.848
[83,     3] loss: 0.901
[84,     3] loss: 0.776
[85,     3] loss: 0.780
[86,     3] loss: 0.779
[87,     3] loss: 0.809
[88,     3] loss: 0.767
[89,     3] loss: 0.796
[90,     3] loss: 0.768
[91,     3] loss: 0.785
[92,     3] loss: 0.760
[93,     3] loss: 0.777
[94,     3] loss: 0.771
[95,     3] loss: 0.763
[96,     3] loss: 0.758
[97,     3] loss: 0.766
[98,     3] loss: 0.747
[99,     3] loss: 0.747
Early stopping applied (best metric=0.4909696578979492)
Finished Training
Total time taken: 22.10574746131897
{'S-palmitoylation-C Validation Accuracy': 0.7165960184082455, 'S-palmitoylation-C Validation Sensitivity': 0.18363036303630365, 'S-palmitoylation-C Validation Specificity': 0.8501950695832234, 'S-palmitoylation-C Validation Precision': 0.240015683714184, 'S-palmitoylation-C AUC ROC': 0.5420714648591227, 'S-palmitoylation-C AUC PR': 0.2237890025447479, 'S-palmitoylation-C MCC': 0.038879612266910904, 'S-palmitoylation-C F1': 0.1967430536645491, 'Validation Loss (S-palmitoylation-C)': 0.5542965888977051, 'Hydroxylation-K Validation Accuracy': 0.74524231678487, 'Hydroxylation-K Validation Sensitivity': 0.7992592592592592, 'Hydroxylation-K Validation Specificity': 0.7315789473684211, 'Hydroxylation-K Validation Precision': 0.45329329397662954, 'Hydroxylation-K AUC ROC': 0.8319883040935673, 'Hydroxylation-K AUC PR': 0.6195537136846772, 'Hydroxylation-K MCC': 0.4534791941673543, 'Hydroxylation-K F1': 0.5652631119259399, 'Validation Loss (Hydroxylation-K)': 0.515516072511673, 'Validation Loss (total)': 1.0698126395543417, 'TimeToTrain': 17.043507639567057}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003936793137110857,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.19752152402102602,
 'loss_weight_S-palmitoylation-C': 0.9603979501309304,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3164365792,
 'sample_weights': [0.02030393223169602, 0.9466820540346415],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.796576179969195,
 'weight_decay_Hydroxylation-K': 0.08298748718292526,
 'weight_decay_S-palmitoylation-C': 9.450881613010065}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.394
[3,     3] loss: 1.384
[4,     3] loss: 1.384
[5,     3] loss: 1.383
[6,     3] loss: 1.395
[7,     3] loss: 1.392
[8,     3] loss: 1.378
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0038719185698142646,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8349149968841498,
 'loss_weight_S-palmitoylation-C': 0.014382321083939886,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1370603684,
 'sample_weights': [0.9603979501309304, 0.19752152402102602],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.896027204215096,
 'weight_decay_Hydroxylation-K': 0.4920110018082974,
 'weight_decay_S-palmitoylation-C': 7.7913333618769816}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.385
[3,     3] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002017979105165103,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.982481857729057,
 'loss_weight_S-palmitoylation-C': 0.8977941478768647,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3526759877,
 'sample_weights': [0.014382321083939886, 0.8349149968841498],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.247453747411248,
 'weight_decay_Hydroxylation-K': 7.677460318811675,
 'weight_decay_S-palmitoylation-C': 8.25007057231667}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.388
[3,     3] loss: 1.390
[4,     3] loss: 1.385
[5,     3] loss: 1.386
[6,     3] loss: 1.395
[7,     3] loss: 1.381
[8,     3] loss: 1.388
[9,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009123346305976428,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7567320717174576,
 'loss_weight_S-palmitoylation-C': 0.019450158572445905,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2902076241,
 'sample_weights': [0.8977941478768647, 0.982481857729057],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.877733497340062,
 'weight_decay_Hydroxylation-K': 4.521609105140771,
 'weight_decay_S-palmitoylation-C': 6.88114610058189}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.389
[3,     3] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003855371659252941,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.15480582128469575,
 'loss_weight_S-palmitoylation-C': 0.013663950890583743,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2406860341,
 'sample_weights': [0.019450158572445905, 0.7567320717174576],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.9365054393367185,
 'weight_decay_Hydroxylation-K': 2.156632151517841,
 'weight_decay_S-palmitoylation-C': 2.9533367351078117}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.385
[3,     3] loss: 1.379
[4,     3] loss: 1.376
[5,     3] loss: 1.377
[6,     3] loss: 1.369
[7,     3] loss: 1.329
[8,     3] loss: 1.284
[9,     3] loss: 1.257
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00113961216737109,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9546996920697314,
 'loss_weight_S-palmitoylation-C': 0.22852737339819076,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 185155557,
 'sample_weights': [0.013663950890583743, 0.15480582128469575],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.068028926584207,
 'weight_decay_Hydroxylation-K': 5.41959620507545,
 'weight_decay_S-palmitoylation-C': 6.133495703419856}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.393
[3,     3] loss: 1.385
[4,     3] loss: 1.379
[5,     3] loss: 1.370
[6,     3] loss: 1.369
[7,     3] loss: 1.353
[8,     3] loss: 1.323
[9,     3] loss: 1.317
[10,     3] loss: 1.279
[11,     3] loss: 1.299
[12,     3] loss: 1.214
[13,     3] loss: 1.232
[14,     3] loss: 1.101
[15,     3] loss: 1.084
[16,     3] loss: 1.137
[17,     3] loss: 0.983
[18,     3] loss: 1.012
[19,     3] loss: 1.084
[20,     3] loss: 1.029
[21,     3] loss: 1.093
[22,     3] loss: 0.997
[23,     3] loss: 1.053
[24,     3] loss: 1.010
[25,     3] loss: 0.960
[26,     3] loss: 0.991
[27,     3] loss: 0.967
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002075812135373686,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9838774003994486,
 'loss_weight_S-palmitoylation-C': 0.2841201291387427,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4035115827,
 'sample_weights': [0.22852737339819076, 0.9546996920697314],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.807557726016113,
 'weight_decay_Hydroxylation-K': 1.3541479700679178,
 'weight_decay_S-palmitoylation-C': 2.097026025445912}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.396
[3,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00546188942595674,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.573138286845893,
 'loss_weight_S-palmitoylation-C': 0.7604311186261676,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1899183047,
 'sample_weights': [0.2841201291387427, 0.9838774003994486],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.0917868794246792,
 'weight_decay_Hydroxylation-K': 9.827601792670587,
 'weight_decay_S-palmitoylation-C': 2.895595687287503}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.393
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008108608576187839,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3240873064843681,
 'loss_weight_S-palmitoylation-C': 0.039432308361873156,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4030937325,
 'sample_weights': [0.7604311186261676, 0.573138286845893],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.845254182454202,
 'weight_decay_Hydroxylation-K': 6.011088116935868,
 'weight_decay_S-palmitoylation-C': 0.28081896430214504}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.386
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016157582193799085,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9819104684387151,
 'loss_weight_S-palmitoylation-C': 0.05380065907098175,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3871200645,
 'sample_weights': [0.039432308361873156, 0.3240873064843681],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.525329539613635,
 'weight_decay_Hydroxylation-K': 3.5663173977153813,
 'weight_decay_S-palmitoylation-C': 6.500907057609392}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.387
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008374404338298223,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8662452158692829,
 'loss_weight_S-palmitoylation-C': 0.14809912389771773,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3204011285,
 'sample_weights': [0.05380065907098175, 0.9819104684387151],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.68600950884984,
 'weight_decay_Hydroxylation-K': 3.842766771592816,
 'weight_decay_S-palmitoylation-C': 3.7247734020551406}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.389
[3,     3] loss: 1.389
[4,     3] loss: 1.394
[5,     3] loss: 1.386
[6,     3] loss: 1.382
[7,     3] loss: 1.387
[8,     3] loss: 1.392
[9,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005302426898292741,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5727095411235036,
 'loss_weight_S-palmitoylation-C': 0.4666581423380466,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 935565601,
 'sample_weights': [0.14809912389771773, 0.8662452158692829],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.753264037692728,
 'weight_decay_Hydroxylation-K': 7.375067154735545,
 'weight_decay_S-palmitoylation-C': 1.4956391413264631}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.389
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018699313657936142,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.370871109623124,
 'loss_weight_S-palmitoylation-C': 0.08401536362760867,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3569189088,
 'sample_weights': [0.4666581423380466, 0.5727095411235036],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.9358257186807215,
 'weight_decay_Hydroxylation-K': 2.756012207715921,
 'weight_decay_S-palmitoylation-C': 0.4155749746799351}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.398
[3,     3] loss: 1.389
[4,     3] loss: 1.389
[5,     3] loss: 1.383
[6,     3] loss: 1.386
[7,     3] loss: 1.378
[8,     3] loss: 1.383
[9,     3] loss: 1.370
[10,     3] loss: 1.364
[11,     3] loss: 1.341
[12,     3] loss: 1.326
[13,     3] loss: 1.270
[14,     3] loss: 1.318
[15,     3] loss: 1.210
[16,     3] loss: 1.162
[17,     3] loss: 1.198
[18,     3] loss: 1.089
[19,     3] loss: 1.076
[20,     3] loss: 1.078
[21,     3] loss: 1.060
[22,     3] loss: 1.076
[23,     3] loss: 1.079
[24,     3] loss: 1.046
[25,     3] loss: 1.063
[26,     3] loss: 0.979
[27,     3] loss: 1.051
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002687161044422625,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8600864948218097,
 'loss_weight_S-palmitoylation-C': 0.2584698432660415,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 73031041,
 'sample_weights': [0.08401536362760867, 0.370871109623124],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.937060877567994,
 'weight_decay_Hydroxylation-K': 5.14532172405335,
 'weight_decay_S-palmitoylation-C': 5.198241070661256}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.393
[3,     3] loss: 1.397
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0002495699233067203,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9860592815876437,
 'loss_weight_S-palmitoylation-C': 0.6685370988935321,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 273241550,
 'sample_weights': [0.2584698432660415, 0.8600864948218097],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.612900527301269,
 'weight_decay_Hydroxylation-K': 3.6861947047174093,
 'weight_decay_S-palmitoylation-C': 6.712743029561781}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.390
[3,     3] loss: 1.385
[4,     3] loss: 1.384
[5,     3] loss: 1.387
[6,     3] loss: 1.384
[7,     3] loss: 1.385
[8,     3] loss: 1.379
[9,     3] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001448836441838278,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24008691352686368,
 'loss_weight_S-palmitoylation-C': 0.16379121132564867,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1636745469,
 'sample_weights': [0.6685370988935321, 0.9860592815876437],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.0185374011043,
 'weight_decay_Hydroxylation-K': 0.8900739317864728,
 'weight_decay_S-palmitoylation-C': 3.3001692888993155}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.380
[3,     3] loss: 1.370
[4,     3] loss: 1.354
[5,     3] loss: 1.342
[6,     3] loss: 1.288
[7,     3] loss: 1.277
[8,     3] loss: 1.217
[9,     3] loss: 1.184
[10,     3] loss: 1.143
[11,     3] loss: 1.158
[12,     3] loss: 1.185
[13,     3] loss: 1.164
[14,     3] loss: 1.065
[15,     3] loss: 1.104
[16,     3] loss: 1.295
[17,     3] loss: 1.143
[18,     3] loss: 1.111
[19,     3] loss: 1.056
[20,     3] loss: 1.094
[21,     3] loss: 1.014
[22,     3] loss: 1.121
[23,     3] loss: 0.939
[24,     3] loss: 1.082
[25,     3] loss: 0.965
[26,     3] loss: 0.914
[27,     3] loss: 0.919
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0029457291790435025,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7787483498488653,
 'loss_weight_S-palmitoylation-C': 0.3467536226900264,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2554207352,
 'sample_weights': [0.16379121132564867, 0.24008691352686368],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.223580564943958,
 'weight_decay_Hydroxylation-K': 7.588550029442324,
 'weight_decay_S-palmitoylation-C': 7.0683666766459785}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.399
[2,     3] loss: 1.386
[3,     3] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005104131880348037,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.13281002821378463,
 'loss_weight_S-palmitoylation-C': 0.24267039911327415,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1658852499,
 'sample_weights': [0.3467536226900264, 0.7787483498488653],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.948957110686921,
 'weight_decay_Hydroxylation-K': 7.7463358229076285,
 'weight_decay_S-palmitoylation-C': 6.3265143438093645}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.405
[2,     3] loss: 1.383
[3,     3] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013530241025396233,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9795940081274226,
 'loss_weight_S-palmitoylation-C': 0.2154879330878145,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3343306526,
 'sample_weights': [0.24267039911327415, 0.13281002821378463],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.869066367334804,
 'weight_decay_Hydroxylation-K': 5.346386978749035,
 'weight_decay_S-palmitoylation-C': 5.114307006643638}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.388
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011069723434539117,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7766601697944959,
 'loss_weight_S-palmitoylation-C': 0.3092376448588313,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2660702767,
 'sample_weights': [0.2154879330878145, 0.9795940081274226],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.249258218506627,
 'weight_decay_Hydroxylation-K': 6.03881238238381,
 'weight_decay_S-palmitoylation-C': 0.9672761220936067}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.384
[3,     3] loss: 1.389
[4,     3] loss: 1.390
[5,     3] loss: 1.393
[6,     3] loss: 1.391
[7,     3] loss: 1.379
[8,     3] loss: 1.386
[9,     3] loss: 1.385
[10,     3] loss: 1.383
[11,     3] loss: 1.382
[12,     3] loss: 1.377
[13,     3] loss: 1.382
[14,     3] loss: 1.364
[15,     3] loss: 1.368
[16,     3] loss: 1.341
[17,     3] loss: 1.340
[18,     3] loss: 1.285
[19,     3] loss: 1.293
[20,     3] loss: 1.254
[21,     3] loss: 1.287
[22,     3] loss: 1.236
[23,     3] loss: 1.217
[24,     3] loss: 1.180
[25,     3] loss: 1.266
[26,     3] loss: 1.219
[27,     3] loss: 1.112
[28,     3] loss: 1.112
[29,     3] loss: 1.139
[30,     3] loss: 1.145
[31,     3] loss: 1.144
[32,     3] loss: 1.066
[33,     3] loss: 1.192
[34,     3] loss: 1.127
[35,     3] loss: 1.003
[36,     3] loss: 1.050
[37,     3] loss: 1.062
[38,     3] loss: 1.052
[39,     3] loss: 0.992
[40,     3] loss: 1.113
[41,     3] loss: 0.959
[42,     3] loss: 0.975
[43,     3] loss: 0.966
[44,     3] loss: 0.975
[45,     3] loss: 0.914
[46,     3] loss: 0.900
[47,     3] loss: 0.932
[48,     3] loss: 0.937
[49,     3] loss: 0.980
[50,     3] loss: 0.886
[51,     3] loss: 0.896
[52,     3] loss: 0.880
[53,     3] loss: 0.983
[54,     3] loss: 0.947
[55,     3] loss: 0.915
[56,     3] loss: 0.943
[57,     3] loss: 0.889
[58,     3] loss: 0.956
[59,     3] loss: 0.907
[60,     3] loss: 1.033
[61,     3] loss: 0.977
[62,     3] loss: 0.932
[63,     3] loss: 0.906
[64,     3] loss: 0.857
[65,     3] loss: 0.825
[66,     3] loss: 0.851
[67,     3] loss: 0.876
[68,     3] loss: 0.826
[69,     3] loss: 0.837
[70,     3] loss: 0.799
[71,     3] loss: 0.789
[72,     3] loss: 0.796
Early stopping applied (best metric=0.5096203088760376)
Finished Training
Total time taken: 16.033825397491455
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.391
[3,     3] loss: 1.388
[4,     3] loss: 1.382
[5,     3] loss: 1.385
[6,     3] loss: 1.388
[7,     3] loss: 1.389
[8,     3] loss: 1.389
[9,     3] loss: 1.387
[10,     3] loss: 1.387
[11,     3] loss: 1.378
[12,     3] loss: 1.389
[13,     3] loss: 1.376
[14,     3] loss: 1.374
[15,     3] loss: 1.368
[16,     3] loss: 1.373
[17,     3] loss: 1.351
[18,     3] loss: 1.353
[19,     3] loss: 1.324
[20,     3] loss: 1.306
[21,     3] loss: 1.317
[22,     3] loss: 1.259
[23,     3] loss: 1.262
[24,     3] loss: 1.229
[25,     3] loss: 1.225
[26,     3] loss: 1.203
[27,     3] loss: 1.199
[28,     3] loss: 1.108
[29,     3] loss: 1.087
[30,     3] loss: 1.126
[31,     3] loss: 1.060
[32,     3] loss: 1.019
[33,     3] loss: 1.040
[34,     3] loss: 1.100
[35,     3] loss: 0.997
[36,     3] loss: 1.013
[37,     3] loss: 0.960
[38,     3] loss: 0.989
[39,     3] loss: 1.010
[40,     3] loss: 1.088
[41,     3] loss: 1.001
[42,     3] loss: 1.050
[43,     3] loss: 1.073
[44,     3] loss: 1.120
[45,     3] loss: 1.169
[46,     3] loss: 1.033
[47,     3] loss: 1.070
[48,     3] loss: 1.037
[49,     3] loss: 1.044
[50,     3] loss: 0.936
[51,     3] loss: 1.034
[52,     3] loss: 0.912
[53,     3] loss: 0.892
[54,     3] loss: 0.976
[55,     3] loss: 0.897
[56,     3] loss: 0.864
[57,     3] loss: 0.897
[58,     3] loss: 0.868
[59,     3] loss: 0.906
[60,     3] loss: 0.837
[61,     3] loss: 0.838
[62,     3] loss: 0.952
[63,     3] loss: 0.901
[64,     3] loss: 0.875
[65,     3] loss: 0.877
[66,     3] loss: 0.917
[67,     3] loss: 0.943
[68,     3] loss: 0.859
[69,     3] loss: 0.845
[70,     3] loss: 0.854
[71,     3] loss: 0.843
[72,     3] loss: 0.869
Early stopping applied (best metric=0.5194659233093262)
Finished Training
Total time taken: 16.010042905807495
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.394
[3,     3] loss: 1.387
[4,     3] loss: 1.380
[5,     3] loss: 1.384
[6,     3] loss: 1.382
[7,     3] loss: 1.388
[8,     3] loss: 1.383
[9,     3] loss: 1.376
[10,     3] loss: 1.369
[11,     3] loss: 1.362
[12,     3] loss: 1.328
[13,     3] loss: 1.302
[14,     3] loss: 1.269
[15,     3] loss: 1.279
[16,     3] loss: 1.209
[17,     3] loss: 1.254
[18,     3] loss: 1.244
[19,     3] loss: 1.233
[20,     3] loss: 1.127
[21,     3] loss: 1.229
[22,     3] loss: 1.170
[23,     3] loss: 1.076
[24,     3] loss: 1.153
[25,     3] loss: 1.089
[26,     3] loss: 1.069
[27,     3] loss: 1.080
[28,     3] loss: 1.068
[29,     3] loss: 1.130
[30,     3] loss: 1.144
[31,     3] loss: 1.080
[32,     3] loss: 1.082
[33,     3] loss: 0.990
[34,     3] loss: 1.044
[35,     3] loss: 1.064
[36,     3] loss: 1.008
[37,     3] loss: 0.981
[38,     3] loss: 0.946
[39,     3] loss: 0.961
[40,     3] loss: 0.888
[41,     3] loss: 0.896
[42,     3] loss: 0.913
[43,     3] loss: 0.913
[44,     3] loss: 1.063
[45,     3] loss: 0.910
[46,     3] loss: 0.822
[47,     3] loss: 0.835
[48,     3] loss: 0.859
[49,     3] loss: 0.823
[50,     3] loss: 0.822
[51,     3] loss: 0.832
[52,     3] loss: 0.780
[53,     3] loss: 0.798
[54,     3] loss: 0.793
[55,     3] loss: 0.867
[56,     3] loss: 0.910
[57,     3] loss: 0.786
[58,     3] loss: 0.839
[59,     3] loss: 0.843
[60,     3] loss: 0.799
[61,     3] loss: 0.807
[62,     3] loss: 0.806
[63,     3] loss: 0.788
[64,     3] loss: 0.793
[65,     3] loss: 0.784
[66,     3] loss: 0.772
[67,     3] loss: 0.771
[68,     3] loss: 0.781
[69,     3] loss: 0.927
[70,     3] loss: 0.905
[71,     3] loss: 0.842
[72,     3] loss: 0.823
[73,     3] loss: 0.845
[74,     3] loss: 0.832
[75,     3] loss: 0.835
[76,     3] loss: 0.806
Early stopping applied (best metric=0.519493043422699)
Finished Training
Total time taken: 16.910045862197876
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.393
[3,     3] loss: 1.383
[4,     3] loss: 1.385
[5,     3] loss: 1.381
[6,     3] loss: 1.381
[7,     3] loss: 1.379
[8,     3] loss: 1.386
[9,     3] loss: 1.383
[10,     3] loss: 1.376
[11,     3] loss: 1.374
[12,     3] loss: 1.355
[13,     3] loss: 1.340
[14,     3] loss: 1.304
[15,     3] loss: 1.267
[16,     3] loss: 1.317
[17,     3] loss: 1.302
[18,     3] loss: 1.296
[19,     3] loss: 1.207
[20,     3] loss: 1.226
[21,     3] loss: 1.164
[22,     3] loss: 1.119
[23,     3] loss: 1.228
[24,     3] loss: 1.056
[25,     3] loss: 1.121
[26,     3] loss: 1.063
[27,     3] loss: 1.005
[28,     3] loss: 1.044
[29,     3] loss: 0.974
[30,     3] loss: 0.993
[31,     3] loss: 1.102
[32,     3] loss: 0.991
[33,     3] loss: 0.970
[34,     3] loss: 1.063
[35,     3] loss: 1.012
[36,     3] loss: 0.977
[37,     3] loss: 0.955
[38,     3] loss: 1.046
[39,     3] loss: 1.044
[40,     3] loss: 1.060
[41,     3] loss: 1.031
[42,     3] loss: 0.943
[43,     3] loss: 0.960
[44,     3] loss: 0.966
[45,     3] loss: 0.876
[46,     3] loss: 0.920
[47,     3] loss: 0.959
[48,     3] loss: 0.932
[49,     3] loss: 0.887
[50,     3] loss: 0.963
[51,     3] loss: 0.903
[52,     3] loss: 0.914
[53,     3] loss: 0.865
[54,     3] loss: 0.850
[55,     3] loss: 0.864
[56,     3] loss: 0.863
[57,     3] loss: 0.833
[58,     3] loss: 0.802
[59,     3] loss: 0.834
[60,     3] loss: 0.829
[61,     3] loss: 0.839
[62,     3] loss: 0.860
[63,     3] loss: 0.796
[64,     3] loss: 0.820
[65,     3] loss: 0.939
[66,     3] loss: 0.828
[67,     3] loss: 0.873
[68,     3] loss: 0.822
[69,     3] loss: 0.799
[70,     3] loss: 0.801
[71,     3] loss: 0.788
[72,     3] loss: 0.771
Early stopping applied (best metric=0.48193714022636414)
Finished Training
Total time taken: 16.08904719352722
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.379
[3,     3] loss: 1.383
[4,     3] loss: 1.382
[5,     3] loss: 1.384
[6,     3] loss: 1.372
[7,     3] loss: 1.368
[8,     3] loss: 1.363
[9,     3] loss: 1.370
[10,     3] loss: 1.353
[11,     3] loss: 1.331
[12,     3] loss: 1.283
[13,     3] loss: 1.245
[14,     3] loss: 1.297
[15,     3] loss: 1.248
[16,     3] loss: 1.185
[17,     3] loss: 1.217
[18,     3] loss: 1.146
[19,     3] loss: 1.142
[20,     3] loss: 1.129
[21,     3] loss: 1.098
[22,     3] loss: 1.109
[23,     3] loss: 1.089
[24,     3] loss: 1.166
[25,     3] loss: 1.097
[26,     3] loss: 1.127
[27,     3] loss: 0.991
[28,     3] loss: 0.964
[29,     3] loss: 0.967
[30,     3] loss: 0.999
[31,     3] loss: 1.036
[32,     3] loss: 0.887
[33,     3] loss: 0.939
[34,     3] loss: 1.032
[35,     3] loss: 0.988
[36,     3] loss: 1.038
[37,     3] loss: 1.057
[38,     3] loss: 0.984
[39,     3] loss: 1.007
[40,     3] loss: 0.955
[41,     3] loss: 0.929
[42,     3] loss: 0.967
[43,     3] loss: 0.892
[44,     3] loss: 0.992
[45,     3] loss: 0.906
[46,     3] loss: 0.857
[47,     3] loss: 0.924
[48,     3] loss: 0.883
[49,     3] loss: 0.956
[50,     3] loss: 0.915
[51,     3] loss: 0.938
[52,     3] loss: 1.190
[53,     3] loss: 1.432
[54,     3] loss: 1.001
[55,     3] loss: 1.239
[56,     3] loss: 1.181
[57,     3] loss: 1.123
[58,     3] loss: 1.172
[59,     3] loss: 1.134
[60,     3] loss: 1.113
[61,     3] loss: 1.037
[62,     3] loss: 1.038
[63,     3] loss: 1.105
[64,     3] loss: 0.966
[65,     3] loss: 0.945
Early stopping applied (best metric=0.4677651524543762)
Finished Training
Total time taken: 14.489039897918701
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.382
[3,     3] loss: 1.380
[4,     3] loss: 1.399
[5,     3] loss: 1.375
[6,     3] loss: 1.379
[7,     3] loss: 1.383
[8,     3] loss: 1.383
[9,     3] loss: 1.381
[10,     3] loss: 1.370
[11,     3] loss: 1.362
[12,     3] loss: 1.352
[13,     3] loss: 1.332
[14,     3] loss: 1.320
[15,     3] loss: 1.322
[16,     3] loss: 1.268
[17,     3] loss: 1.251
[18,     3] loss: 1.123
[19,     3] loss: 1.145
[20,     3] loss: 1.224
[21,     3] loss: 1.221
[22,     3] loss: 1.107
[23,     3] loss: 1.102
[24,     3] loss: 1.047
[25,     3] loss: 0.993
[26,     3] loss: 1.069
[27,     3] loss: 1.022
[28,     3] loss: 1.086
[29,     3] loss: 0.991
[30,     3] loss: 0.967
[31,     3] loss: 1.026
[32,     3] loss: 0.979
[33,     3] loss: 1.027
[34,     3] loss: 0.999
[35,     3] loss: 0.931
[36,     3] loss: 0.905
[37,     3] loss: 0.923
[38,     3] loss: 1.005
[39,     3] loss: 0.982
[40,     3] loss: 0.892
[41,     3] loss: 0.968
[42,     3] loss: 0.931
[43,     3] loss: 0.931
[44,     3] loss: 0.969
[45,     3] loss: 0.953
[46,     3] loss: 0.980
[47,     3] loss: 0.923
[48,     3] loss: 1.011
[49,     3] loss: 0.980
[50,     3] loss: 0.902
[51,     3] loss: 0.930
[52,     3] loss: 0.904
[53,     3] loss: 0.847
[54,     3] loss: 0.925
[55,     3] loss: 0.850
[56,     3] loss: 0.848
[57,     3] loss: 0.831
[58,     3] loss: 0.791
[59,     3] loss: 0.794
[60,     3] loss: 0.799
[61,     3] loss: 0.789
[62,     3] loss: 0.776
[63,     3] loss: 0.826
[64,     3] loss: 0.821
[65,     3] loss: 0.783
[66,     3] loss: 0.793
[67,     3] loss: 0.832
[68,     3] loss: 0.791
[69,     3] loss: 0.847
[70,     3] loss: 0.802
[71,     3] loss: 0.893
[72,     3] loss: 0.840
Early stopping applied (best metric=0.513722836971283)
Finished Training
Total time taken: 16.116703748703003
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.392
[3,     3] loss: 1.386
[4,     3] loss: 1.390
[5,     3] loss: 1.375
[6,     3] loss: 1.373
[7,     3] loss: 1.361
[8,     3] loss: 1.365
[9,     3] loss: 1.347
[10,     3] loss: 1.314
[11,     3] loss: 1.300
[12,     3] loss: 1.231
[13,     3] loss: 1.263
[14,     3] loss: 1.189
[15,     3] loss: 1.177
[16,     3] loss: 1.124
[17,     3] loss: 1.089
[18,     3] loss: 1.076
[19,     3] loss: 1.119
[20,     3] loss: 1.148
[21,     3] loss: 1.095
[22,     3] loss: 1.064
[23,     3] loss: 1.023
[24,     3] loss: 1.024
[25,     3] loss: 1.027
[26,     3] loss: 0.942
[27,     3] loss: 1.033
[28,     3] loss: 1.036
[29,     3] loss: 1.019
[30,     3] loss: 1.008
[31,     3] loss: 0.913
[32,     3] loss: 0.960
[33,     3] loss: 0.926
[34,     3] loss: 1.039
[35,     3] loss: 0.953
[36,     3] loss: 0.936
[37,     3] loss: 0.915
[38,     3] loss: 0.963
[39,     3] loss: 0.910
[40,     3] loss: 0.893
[41,     3] loss: 0.921
[42,     3] loss: 0.929
[43,     3] loss: 0.975
[44,     3] loss: 0.954
[45,     3] loss: 0.876
[46,     3] loss: 0.884
[47,     3] loss: 0.935
[48,     3] loss: 0.899
[49,     3] loss: 0.854
[50,     3] loss: 0.848
[51,     3] loss: 0.794
[52,     3] loss: 0.814
[53,     3] loss: 0.848
[54,     3] loss: 0.810
[55,     3] loss: 0.841
[56,     3] loss: 0.800
[57,     3] loss: 0.801
[58,     3] loss: 0.847
[59,     3] loss: 0.825
[60,     3] loss: 0.812
[61,     3] loss: 0.795
[62,     3] loss: 0.846
[63,     3] loss: 0.804
[64,     3] loss: 0.818
[65,     3] loss: 0.841
[66,     3] loss: 0.802
[67,     3] loss: 0.880
[68,     3] loss: 0.814
[69,     3] loss: 0.844
[70,     3] loss: 0.832
[71,     3] loss: 0.804
Early stopping applied (best metric=0.534440279006958)
Finished Training
Total time taken: 15.873589277267456
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.388
[3,     3] loss: 1.394
[4,     3] loss: 1.388
[5,     3] loss: 1.389
[6,     3] loss: 1.394
[7,     3] loss: 1.390
[8,     3] loss: 1.379
[9,     3] loss: 1.380
[10,     3] loss: 1.379
[11,     3] loss: 1.377
[12,     3] loss: 1.365
[13,     3] loss: 1.341
[14,     3] loss: 1.346
[15,     3] loss: 1.281
[16,     3] loss: 1.267
[17,     3] loss: 1.226
[18,     3] loss: 1.206
[19,     3] loss: 1.181
[20,     3] loss: 1.216
[21,     3] loss: 1.095
[22,     3] loss: 1.090
[23,     3] loss: 1.034
[24,     3] loss: 1.123
[25,     3] loss: 1.106
[26,     3] loss: 1.017
[27,     3] loss: 1.052
[28,     3] loss: 1.015
[29,     3] loss: 0.906
[30,     3] loss: 0.894
[31,     3] loss: 0.931
[32,     3] loss: 1.066
[33,     3] loss: 0.968
[34,     3] loss: 0.970
[35,     3] loss: 1.059
[36,     3] loss: 0.982
[37,     3] loss: 0.976
[38,     3] loss: 0.897
[39,     3] loss: 0.919
[40,     3] loss: 1.022
[41,     3] loss: 1.002
[42,     3] loss: 1.001
[43,     3] loss: 0.907
[44,     3] loss: 0.940
[45,     3] loss: 0.958
[46,     3] loss: 0.935
[47,     3] loss: 0.981
[48,     3] loss: 0.887
[49,     3] loss: 0.914
[50,     3] loss: 0.876
[51,     3] loss: 0.887
[52,     3] loss: 0.857
[53,     3] loss: 0.818
[54,     3] loss: 0.909
[55,     3] loss: 0.874
[56,     3] loss: 0.877
[57,     3] loss: 0.835
[58,     3] loss: 0.847
[59,     3] loss: 0.852
[60,     3] loss: 0.827
[61,     3] loss: 0.872
[62,     3] loss: 0.811
[63,     3] loss: 0.810
[64,     3] loss: 0.870
[65,     3] loss: 0.914
[66,     3] loss: 0.861
[67,     3] loss: 0.839
[68,     3] loss: 0.866
[69,     3] loss: 0.841
[70,     3] loss: 0.838
[71,     3] loss: 0.797
[72,     3] loss: 0.860
[73,     3] loss: 0.865
Early stopping applied (best metric=0.5472830533981323)
Finished Training
Total time taken: 16.284061908721924
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.384
[3,     3] loss: 1.389
[4,     3] loss: 1.391
[5,     3] loss: 1.386
[6,     3] loss: 1.384
[7,     3] loss: 1.384
[8,     3] loss: 1.376
[9,     3] loss: 1.375
[10,     3] loss: 1.363
[11,     3] loss: 1.359
[12,     3] loss: 1.347
[13,     3] loss: 1.342
[14,     3] loss: 1.315
[15,     3] loss: 1.282
[16,     3] loss: 1.258
[17,     3] loss: 1.221
[18,     3] loss: 1.319
[19,     3] loss: 1.199
[20,     3] loss: 1.237
[21,     3] loss: 1.150
[22,     3] loss: 1.107
[23,     3] loss: 1.175
[24,     3] loss: 1.207
[25,     3] loss: 1.229
[26,     3] loss: 1.262
[27,     3] loss: 1.048
[28,     3] loss: 1.202
[29,     3] loss: 1.144
[30,     3] loss: 1.131
[31,     3] loss: 1.062
[32,     3] loss: 1.021
[33,     3] loss: 1.045
[34,     3] loss: 1.009
[35,     3] loss: 1.141
[36,     3] loss: 1.003
[37,     3] loss: 0.952
[38,     3] loss: 0.908
[39,     3] loss: 0.982
[40,     3] loss: 0.992
[41,     3] loss: 0.926
[42,     3] loss: 0.895
[43,     3] loss: 0.882
[44,     3] loss: 0.824
[45,     3] loss: 0.845
[46,     3] loss: 0.865
[47,     3] loss: 0.852
[48,     3] loss: 0.961
[49,     3] loss: 0.879
[50,     3] loss: 0.906
[51,     3] loss: 0.913
[52,     3] loss: 0.929
[53,     3] loss: 0.844
[54,     3] loss: 0.824
[55,     3] loss: 0.829
[56,     3] loss: 0.829
[57,     3] loss: 0.817
[58,     3] loss: 0.897
[59,     3] loss: 0.876
[60,     3] loss: 0.802
[61,     3] loss: 0.911
[62,     3] loss: 0.942
[63,     3] loss: 0.867
[64,     3] loss: 0.814
[65,     3] loss: 0.798
[66,     3] loss: 0.830
[67,     3] loss: 0.850
[68,     3] loss: 0.889
[69,     3] loss: 0.817
[70,     3] loss: 0.822
[71,     3] loss: 0.827
[72,     3] loss: 0.822
[73,     3] loss: 0.846
[74,     3] loss: 0.785
[75,     3] loss: 0.821
[76,     3] loss: 0.800
[77,     3] loss: 0.802
[78,     3] loss: 0.793
[79,     3] loss: 0.821
[80,     3] loss: 0.799
[81,     3] loss: 0.782
[82,     3] loss: 0.787
[83,     3] loss: 0.818
[84,     3] loss: 0.865
[85,     3] loss: 0.770
Early stopping applied (best metric=0.473249226808548)
Finished Training
Total time taken: 19.037062406539917
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.385
[3,     3] loss: 1.382
[4,     3] loss: 1.382
[5,     3] loss: 1.382
[6,     3] loss: 1.386
[7,     3] loss: 1.368
[8,     3] loss: 1.372
[9,     3] loss: 1.364
[10,     3] loss: 1.348
[11,     3] loss: 1.334
[12,     3] loss: 1.314
[13,     3] loss: 1.303
[14,     3] loss: 1.267
[15,     3] loss: 1.177
[16,     3] loss: 1.231
[17,     3] loss: 1.194
[18,     3] loss: 1.215
[19,     3] loss: 1.154
[20,     3] loss: 1.142
[21,     3] loss: 1.057
[22,     3] loss: 1.173
[23,     3] loss: 0.995
[24,     3] loss: 1.077
[25,     3] loss: 1.115
[26,     3] loss: 1.010
[27,     3] loss: 0.957
[28,     3] loss: 1.023
[29,     3] loss: 0.987
[30,     3] loss: 1.076
[31,     3] loss: 0.957
[32,     3] loss: 1.025
[33,     3] loss: 1.059
[34,     3] loss: 1.013
[35,     3] loss: 1.069
[36,     3] loss: 1.045
[37,     3] loss: 0.978
[38,     3] loss: 1.017
[39,     3] loss: 0.959
[40,     3] loss: 1.010
[41,     3] loss: 0.908
[42,     3] loss: 0.917
[43,     3] loss: 0.898
[44,     3] loss: 0.951
[45,     3] loss: 0.899
[46,     3] loss: 0.901
[47,     3] loss: 0.940
[48,     3] loss: 0.927
[49,     3] loss: 1.018
[50,     3] loss: 1.008
[51,     3] loss: 0.964
[52,     3] loss: 1.011
[53,     3] loss: 0.976
[54,     3] loss: 0.942
[55,     3] loss: 0.912
[56,     3] loss: 0.906
[57,     3] loss: 0.885
[58,     3] loss: 0.919
[59,     3] loss: 0.889
[60,     3] loss: 0.951
[61,     3] loss: 0.989
[62,     3] loss: 0.884
[63,     3] loss: 0.868
[64,     3] loss: 0.930
[65,     3] loss: 0.815
[66,     3] loss: 0.813
[67,     3] loss: 0.814
[68,     3] loss: 0.797
[69,     3] loss: 0.883
[70,     3] loss: 0.873
[71,     3] loss: 0.838
[72,     3] loss: 0.905
[73,     3] loss: 0.973
[74,     3] loss: 0.940
[75,     3] loss: 0.909
[76,     3] loss: 0.848
[77,     3] loss: 0.911
[78,     3] loss: 0.818
[79,     3] loss: 0.851
[80,     3] loss: 0.856
[81,     3] loss: 0.817
[82,     3] loss: 0.882
[83,     3] loss: 0.898
[84,     3] loss: 0.884
[85,     3] loss: 0.883
[86,     3] loss: 0.875
[87,     3] loss: 0.851
[88,     3] loss: 0.913
[89,     3] loss: 0.800
[90,     3] loss: 0.824
[91,     3] loss: 0.854
[92,     3] loss: 0.793
[93,     3] loss: 0.790
[94,     3] loss: 0.774
[95,     3] loss: 0.779
[96,     3] loss: 0.772
[97,     3] loss: 0.765
[98,     3] loss: 0.770
[99,     3] loss: 0.764
[100,     3] loss: 0.784
[101,     3] loss: 0.767
[102,     3] loss: 0.788
[103,     3] loss: 0.769
[104,     3] loss: 0.759
[105,     3] loss: 0.750
[106,     3] loss: 0.776
[107,     3] loss: 0.819
[108,     3] loss: 0.820
[109,     3] loss: 0.789
[110,     3] loss: 0.796
[111,     3] loss: 0.790
[112,     3] loss: 0.853
[113,     3] loss: 0.786
[114,     3] loss: 0.802
[115,     3] loss: 0.782
[116,     3] loss: 0.803
[117,     3] loss: 0.798
[118,     3] loss: 0.784
Early stopping applied (best metric=0.5027036666870117)
Finished Training
Total time taken: 26.31707191467285
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.379
[2,     3] loss: 1.388
[3,     3] loss: 1.382
[4,     3] loss: 1.379
[5,     3] loss: 1.376
[6,     3] loss: 1.385
[7,     3] loss: 1.372
[8,     3] loss: 1.367
[9,     3] loss: 1.366
[10,     3] loss: 1.344
[11,     3] loss: 1.319
[12,     3] loss: 1.307
[13,     3] loss: 1.257
[14,     3] loss: 1.256
[15,     3] loss: 1.231
[16,     3] loss: 1.173
[17,     3] loss: 1.280
[18,     3] loss: 1.237
[19,     3] loss: 1.202
[20,     3] loss: 1.116
[21,     3] loss: 1.130
[22,     3] loss: 1.142
[23,     3] loss: 1.161
[24,     3] loss: 1.117
[25,     3] loss: 1.089
[26,     3] loss: 1.043
[27,     3] loss: 0.997
[28,     3] loss: 1.003
[29,     3] loss: 0.919
[30,     3] loss: 1.021
[31,     3] loss: 0.907
[32,     3] loss: 0.950
[33,     3] loss: 0.998
[34,     3] loss: 0.918
[35,     3] loss: 0.933
[36,     3] loss: 0.971
[37,     3] loss: 0.951
[38,     3] loss: 0.877
[39,     3] loss: 0.925
[40,     3] loss: 0.892
[41,     3] loss: 0.890
[42,     3] loss: 0.876
[43,     3] loss: 0.928
[44,     3] loss: 0.896
[45,     3] loss: 0.904
[46,     3] loss: 1.065
[47,     3] loss: 0.903
[48,     3] loss: 0.865
[49,     3] loss: 0.843
[50,     3] loss: 0.819
[51,     3] loss: 0.835
[52,     3] loss: 0.824
[53,     3] loss: 0.777
[54,     3] loss: 0.869
[55,     3] loss: 0.795
[56,     3] loss: 0.809
[57,     3] loss: 0.806
[58,     3] loss: 0.847
[59,     3] loss: 0.820
[60,     3] loss: 0.831
[61,     3] loss: 0.816
[62,     3] loss: 0.776
[63,     3] loss: 0.807
[64,     3] loss: 0.800
[65,     3] loss: 0.855
[66,     3] loss: 0.783
[67,     3] loss: 0.792
Early stopping applied (best metric=0.5247504115104675)
Finished Training
Total time taken: 15.03804349899292
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.383
[3,     3] loss: 1.395
[4,     3] loss: 1.386
[5,     3] loss: 1.379
[6,     3] loss: 1.385
[7,     3] loss: 1.387
[8,     3] loss: 1.367
[9,     3] loss: 1.357
[10,     3] loss: 1.343
[11,     3] loss: 1.308
[12,     3] loss: 1.283
[13,     3] loss: 1.243
[14,     3] loss: 1.251
[15,     3] loss: 1.189
[16,     3] loss: 1.143
[17,     3] loss: 1.121
[18,     3] loss: 1.056
[19,     3] loss: 1.011
[20,     3] loss: 1.096
[21,     3] loss: 1.019
[22,     3] loss: 0.951
[23,     3] loss: 0.971
[24,     3] loss: 0.943
[25,     3] loss: 1.027
[26,     3] loss: 0.906
[27,     3] loss: 0.888
[28,     3] loss: 0.936
[29,     3] loss: 0.943
[30,     3] loss: 0.911
[31,     3] loss: 0.959
[32,     3] loss: 0.846
[33,     3] loss: 0.928
[34,     3] loss: 0.845
[35,     3] loss: 0.899
[36,     3] loss: 1.034
[37,     3] loss: 0.898
[38,     3] loss: 0.858
[39,     3] loss: 0.905
[40,     3] loss: 0.883
[41,     3] loss: 0.892
[42,     3] loss: 0.886
[43,     3] loss: 0.883
[44,     3] loss: 0.867
[45,     3] loss: 0.924
[46,     3] loss: 0.952
[47,     3] loss: 0.916
[48,     3] loss: 0.888
[49,     3] loss: 0.876
[50,     3] loss: 0.837
[51,     3] loss: 0.904
[52,     3] loss: 0.831
[53,     3] loss: 0.812
[54,     3] loss: 0.837
[55,     3] loss: 0.893
[56,     3] loss: 0.779
[57,     3] loss: 0.803
[58,     3] loss: 0.826
[59,     3] loss: 0.827
[60,     3] loss: 0.846
[61,     3] loss: 0.800
[62,     3] loss: 0.855
[63,     3] loss: 0.793
[64,     3] loss: 0.806
[65,     3] loss: 0.827
[66,     3] loss: 0.814
[67,     3] loss: 0.806
[68,     3] loss: 0.826
[69,     3] loss: 0.785
[70,     3] loss: 0.773
[71,     3] loss: 0.797
[72,     3] loss: 0.783
[73,     3] loss: 0.808
[74,     3] loss: 0.811
[75,     3] loss: 0.787
[76,     3] loss: 0.798
[77,     3] loss: 0.752
[78,     3] loss: 0.759
[79,     3] loss: 0.794
[80,     3] loss: 0.739
[81,     3] loss: 0.766
[82,     3] loss: 0.756
[83,     3] loss: 0.787
[84,     3] loss: 0.769
[85,     3] loss: 0.819
Early stopping applied (best metric=0.5516159534454346)
Finished Training
Total time taken: 18.99668836593628
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.393
[3,     3] loss: 1.380
[4,     3] loss: 1.384
[5,     3] loss: 1.375
[6,     3] loss: 1.380
[7,     3] loss: 1.354
[8,     3] loss: 1.352
[9,     3] loss: 1.334
[10,     3] loss: 1.294
[11,     3] loss: 1.294
[12,     3] loss: 1.252
[13,     3] loss: 1.243
[14,     3] loss: 1.241
[15,     3] loss: 1.264
[16,     3] loss: 1.157
[17,     3] loss: 1.169
[18,     3] loss: 1.213
[19,     3] loss: 1.190
[20,     3] loss: 1.224
[21,     3] loss: 1.128
[22,     3] loss: 1.087
[23,     3] loss: 1.051
[24,     3] loss: 1.051
[25,     3] loss: 1.068
[26,     3] loss: 1.062
[27,     3] loss: 1.022
[28,     3] loss: 1.135
[29,     3] loss: 1.033
[30,     3] loss: 0.989
[31,     3] loss: 0.965
[32,     3] loss: 0.928
[33,     3] loss: 0.908
[34,     3] loss: 0.932
[35,     3] loss: 1.000
[36,     3] loss: 1.021
[37,     3] loss: 0.996
[38,     3] loss: 0.993
[39,     3] loss: 0.939
[40,     3] loss: 0.917
[41,     3] loss: 1.023
[42,     3] loss: 0.923
[43,     3] loss: 0.868
[44,     3] loss: 0.848
[45,     3] loss: 0.951
[46,     3] loss: 0.960
[47,     3] loss: 0.904
[48,     3] loss: 0.843
[49,     3] loss: 0.833
[50,     3] loss: 0.849
[51,     3] loss: 0.901
[52,     3] loss: 0.907
[53,     3] loss: 0.952
[54,     3] loss: 0.915
[55,     3] loss: 0.925
[56,     3] loss: 0.983
[57,     3] loss: 0.892
[58,     3] loss: 0.911
[59,     3] loss: 0.925
[60,     3] loss: 0.963
[61,     3] loss: 0.874
[62,     3] loss: 0.869
[63,     3] loss: 0.841
[64,     3] loss: 0.804
[65,     3] loss: 0.868
[66,     3] loss: 0.811
[67,     3] loss: 0.809
[68,     3] loss: 0.815
[69,     3] loss: 0.775
[70,     3] loss: 0.825
[71,     3] loss: 0.802
[72,     3] loss: 0.828
[73,     3] loss: 0.892
[74,     3] loss: 0.902
[75,     3] loss: 1.033
[76,     3] loss: 1.058
[77,     3] loss: 0.835
[78,     3] loss: 1.004
[79,     3] loss: 0.861
Early stopping applied (best metric=0.5343594551086426)
Finished Training
Total time taken: 17.674068689346313
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.383
[3,     3] loss: 1.379
[4,     3] loss: 1.388
[5,     3] loss: 1.379
[6,     3] loss: 1.380
[7,     3] loss: 1.387
[8,     3] loss: 1.382
[9,     3] loss: 1.375
[10,     3] loss: 1.365
[11,     3] loss: 1.355
[12,     3] loss: 1.338
[13,     3] loss: 1.298
[14,     3] loss: 1.269
[15,     3] loss: 1.280
[16,     3] loss: 1.248
[17,     3] loss: 1.173
[18,     3] loss: 1.155
[19,     3] loss: 1.107
[20,     3] loss: 1.149
[21,     3] loss: 1.078
[22,     3] loss: 1.052
[23,     3] loss: 1.158
[24,     3] loss: 1.071
[25,     3] loss: 1.051
[26,     3] loss: 1.042
[27,     3] loss: 1.016
[28,     3] loss: 0.961
[29,     3] loss: 0.989
[30,     3] loss: 1.008
[31,     3] loss: 1.042
[32,     3] loss: 0.982
[33,     3] loss: 0.997
[34,     3] loss: 0.986
[35,     3] loss: 0.955
[36,     3] loss: 0.959
[37,     3] loss: 1.048
[38,     3] loss: 0.972
[39,     3] loss: 0.951
[40,     3] loss: 1.015
[41,     3] loss: 1.003
[42,     3] loss: 0.980
[43,     3] loss: 0.914
[44,     3] loss: 0.907
[45,     3] loss: 0.915
[46,     3] loss: 0.864
[47,     3] loss: 0.955
[48,     3] loss: 0.855
[49,     3] loss: 0.925
[50,     3] loss: 0.851
[51,     3] loss: 0.819
[52,     3] loss: 0.914
[53,     3] loss: 0.854
[54,     3] loss: 0.854
[55,     3] loss: 0.968
[56,     3] loss: 0.894
[57,     3] loss: 0.998
[58,     3] loss: 0.890
[59,     3] loss: 0.987
[60,     3] loss: 1.053
[61,     3] loss: 0.881
[62,     3] loss: 0.890
[63,     3] loss: 0.880
[64,     3] loss: 0.874
[65,     3] loss: 0.862
[66,     3] loss: 0.923
[67,     3] loss: 0.864
[68,     3] loss: 0.810
[69,     3] loss: 0.855
[70,     3] loss: 0.853
Early stopping applied (best metric=0.4933564364910126)
Finished Training
Total time taken: 15.651042938232422
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.377
[3,     3] loss: 1.386
[4,     3] loss: 1.376
[5,     3] loss: 1.389
[6,     3] loss: 1.373
[7,     3] loss: 1.374
[8,     3] loss: 1.382
[9,     3] loss: 1.360
[10,     3] loss: 1.328
[11,     3] loss: 1.316
[12,     3] loss: 1.265
[13,     3] loss: 1.239
[14,     3] loss: 1.214
[15,     3] loss: 1.179
[16,     3] loss: 1.145
[17,     3] loss: 1.103
[18,     3] loss: 1.062
[19,     3] loss: 1.114
[20,     3] loss: 1.156
[21,     3] loss: 1.077
[22,     3] loss: 1.104
[23,     3] loss: 0.944
[24,     3] loss: 1.010
[25,     3] loss: 0.981
[26,     3] loss: 0.959
[27,     3] loss: 0.977
[28,     3] loss: 0.958
[29,     3] loss: 0.899
[30,     3] loss: 1.109
[31,     3] loss: 0.985
[32,     3] loss: 0.969
[33,     3] loss: 1.097
[34,     3] loss: 1.131
[35,     3] loss: 0.988
[36,     3] loss: 0.991
[37,     3] loss: 1.074
[38,     3] loss: 1.083
[39,     3] loss: 1.000
[40,     3] loss: 1.042
[41,     3] loss: 0.892
[42,     3] loss: 0.986
[43,     3] loss: 0.920
[44,     3] loss: 0.879
[45,     3] loss: 0.947
[46,     3] loss: 0.850
[47,     3] loss: 0.881
[48,     3] loss: 0.926
[49,     3] loss: 0.860
[50,     3] loss: 0.806
[51,     3] loss: 0.873
[52,     3] loss: 0.864
[53,     3] loss: 0.945
[54,     3] loss: 0.903
[55,     3] loss: 0.894
[56,     3] loss: 0.869
[57,     3] loss: 0.868
[58,     3] loss: 0.865
[59,     3] loss: 0.845
[60,     3] loss: 0.792
[61,     3] loss: 0.796
[62,     3] loss: 0.836
[63,     3] loss: 0.842
[64,     3] loss: 0.891
[65,     3] loss: 0.815
[66,     3] loss: 0.841
[67,     3] loss: 0.845
[68,     3] loss: 0.944
[69,     3] loss: 0.856
[70,     3] loss: 0.860
[71,     3] loss: 0.873
[72,     3] loss: 0.881
[73,     3] loss: 0.970
[74,     3] loss: 0.846
[75,     3] loss: 0.838
[76,     3] loss: 0.834
[77,     3] loss: 0.832
[78,     3] loss: 0.832
[79,     3] loss: 0.906
[80,     3] loss: 0.844
Early stopping applied (best metric=0.5178437829017639)
Finished Training
Total time taken: 17.829047441482544
{'S-palmitoylation-C Validation Accuracy': 0.646510520047638, 'S-palmitoylation-C Validation Sensitivity': 0.3231683168316832, 'S-palmitoylation-C Validation Specificity': 0.727566390107954, 'S-palmitoylation-C Validation Precision': 0.2354292149940488, 'S-palmitoylation-C AUC ROC': 0.543298599946067, 'S-palmitoylation-C AUC PR': 0.22725339353294605, 'S-palmitoylation-C MCC': 0.048198822134883995, 'S-palmitoylation-C F1': 0.2528096944545439, 'Validation Loss (S-palmitoylation-C)': 0.5538155754407247, 'Hydroxylation-K Validation Accuracy': 0.6867612293144207, 'Hydroxylation-K Validation Sensitivity': 0.8266666666666667, 'Hydroxylation-K Validation Specificity': 0.6508771929824562, 'Hydroxylation-K Validation Precision': 0.3913629617489607, 'Hydroxylation-K AUC ROC': 0.8242105263157895, 'Hydroxylation-K AUC PR': 0.5500541594876959, 'Hydroxylation-K MCC': 0.4009039833824644, 'Hydroxylation-K F1': 0.5213987833375439, 'Validation Loss (Hydroxylation-K)': 0.5127737780412038, 'Validation Loss (total)': 1.06658935546875, 'TimeToTrain': 17.223292096455893}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0004438142493050488,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.894267254795297,
 'loss_weight_S-palmitoylation-C': 0.11981174961763841,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3124295651,
 'sample_weights': [0.3092376448588313, 0.7766601697944959],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.712024462765417,
 'weight_decay_Hydroxylation-K': 7.183519404200036,
 'weight_decay_S-palmitoylation-C': 0.942877976958542}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.388
[3,     3] loss: 1.381
[4,     3] loss: 1.389
[5,     3] loss: 1.387
[6,     3] loss: 1.378
[7,     3] loss: 1.379
[8,     3] loss: 1.363
[9,     3] loss: 1.365
[10,     3] loss: 1.360
[11,     3] loss: 1.362
[12,     3] loss: 1.351
[13,     3] loss: 1.361
[14,     3] loss: 1.327
[15,     3] loss: 1.325
[16,     3] loss: 1.312
[17,     3] loss: 1.281
[18,     3] loss: 1.272
[19,     3] loss: 1.243
[20,     3] loss: 1.293
[21,     3] loss: 1.224
[22,     3] loss: 1.239
[23,     3] loss: 1.151
[24,     3] loss: 1.188
[25,     3] loss: 1.142
[26,     3] loss: 1.086
[27,     3] loss: 1.197
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0026700096130092433,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9395048739594971,
 'loss_weight_S-palmitoylation-C': 0.02029094437033227,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 236565060,
 'sample_weights': [0.11981174961763841, 0.894267254795297],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.865578086725787,
 'weight_decay_Hydroxylation-K': 5.8818245526244946,
 'weight_decay_S-palmitoylation-C': 4.39732629083186}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.385
[3,     3] loss: 1.385
[4,     3] loss: 1.388
[5,     3] loss: 1.383
[6,     3] loss: 1.387
[7,     3] loss: 1.390
[8,     3] loss: 1.387
[9,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017871796819132158,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7131536032972013,
 'loss_weight_S-palmitoylation-C': 0.09562608312792643,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2587459615,
 'sample_weights': [0.02029094437033227, 0.9395048739594971],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.335425585216039,
 'weight_decay_Hydroxylation-K': 3.554280225360983,
 'weight_decay_S-palmitoylation-C': 8.582225509087316}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.382
[3,     3] loss: 1.397
[4,     3] loss: 1.386
[5,     3] loss: 1.379
[6,     3] loss: 1.387
[7,     3] loss: 1.389
[8,     3] loss: 1.383
[9,     3] loss: 1.378
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016259111189591798,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.35042986791067177,
 'loss_weight_S-palmitoylation-C': 0.3494948575791297,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 249682842,
 'sample_weights': [0.09562608312792643, 0.7131536032972013],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.691457225360548,
 'weight_decay_Hydroxylation-K': 0.5178724293795214,
 'weight_decay_S-palmitoylation-C': 5.48990153654626}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.381
[3,     3] loss: 1.373
[4,     3] loss: 1.394
[5,     3] loss: 1.390
[6,     3] loss: 1.380
[7,     3] loss: 1.362
[8,     3] loss: 1.355
[9,     3] loss: 1.332
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015854547913774406,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9585878045412839,
 'loss_weight_S-palmitoylation-C': 0.001583706443016013,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 400056509,
 'sample_weights': [0.3494948575791297, 0.35042986791067177],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.489679800063044,
 'weight_decay_Hydroxylation-K': 4.902927596475813,
 'weight_decay_S-palmitoylation-C': 4.468920128173815}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.391
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016611013355275807,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5309223375645755,
 'loss_weight_S-palmitoylation-C': 0.48025372250096743,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1454765703,
 'sample_weights': [0.001583706443016013, 0.9585878045412839],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.691132490845952,
 'weight_decay_Hydroxylation-K': 0.6273016532996585,
 'weight_decay_S-palmitoylation-C': 7.363469850737405}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.376
[3,     3] loss: 1.400
[4,     3] loss: 1.396
[5,     3] loss: 1.379
[6,     3] loss: 1.382
[7,     3] loss: 1.386
[8,     3] loss: 1.367
[9,     3] loss: 1.367
[10,     3] loss: 1.370
[11,     3] loss: 1.344
[12,     3] loss: 1.311
[13,     3] loss: 1.298
[14,     3] loss: 1.231
[15,     3] loss: 1.182
[16,     3] loss: 1.133
[17,     3] loss: 1.219
[18,     3] loss: 1.187
[19,     3] loss: 1.179
[20,     3] loss: 1.176
[21,     3] loss: 1.085
[22,     3] loss: 1.047
[23,     3] loss: 1.043
[24,     3] loss: 1.025
[25,     3] loss: 1.102
[26,     3] loss: 1.121
[27,     3] loss: 1.087
[28,     3] loss: 1.127
[29,     3] loss: 1.058
[30,     3] loss: 1.075
[31,     3] loss: 0.977
[32,     3] loss: 0.962
[33,     3] loss: 0.921
[34,     3] loss: 0.985
[35,     3] loss: 0.985
[36,     3] loss: 0.888
[37,     3] loss: 0.997
[38,     3] loss: 0.918
[39,     3] loss: 0.890
[40,     3] loss: 0.877
[41,     3] loss: 0.903
[42,     3] loss: 1.007
[43,     3] loss: 0.863
[44,     3] loss: 0.880
[45,     3] loss: 0.881
[46,     3] loss: 0.876
[47,     3] loss: 0.891
[48,     3] loss: 0.928
[49,     3] loss: 1.112
[50,     3] loss: 0.862
[51,     3] loss: 0.949
[52,     3] loss: 0.949
[53,     3] loss: 0.924
[54,     3] loss: 0.807
[55,     3] loss: 0.849
[56,     3] loss: 0.904
[57,     3] loss: 0.943
[58,     3] loss: 0.900
[59,     3] loss: 0.897
[60,     3] loss: 0.836
[61,     3] loss: 0.807
[62,     3] loss: 0.806
[63,     3] loss: 0.757
[64,     3] loss: 0.765
[65,     3] loss: 0.725
[66,     3] loss: 0.835
[67,     3] loss: 0.735
[68,     3] loss: 0.750
[69,     3] loss: 0.787
[70,     3] loss: 0.863
[71,     3] loss: 0.784
[72,     3] loss: 0.817
[73,     3] loss: 0.805
Early stopping applied (best metric=0.5138210654258728)
Finished Training
Total time taken: 16.2350435256958
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.380
[3,     3] loss: 1.394
[4,     3] loss: 1.381
[5,     3] loss: 1.373
[6,     3] loss: 1.377
[7,     3] loss: 1.365
[8,     3] loss: 1.358
[9,     3] loss: 1.313
[10,     3] loss: 1.280
[11,     3] loss: 1.210
[12,     3] loss: 1.164
[13,     3] loss: 1.125
[14,     3] loss: 1.145
[15,     3] loss: 1.166
[16,     3] loss: 1.142
[17,     3] loss: 1.063
[18,     3] loss: 1.049
[19,     3] loss: 1.077
[20,     3] loss: 1.001
[21,     3] loss: 0.992
[22,     3] loss: 0.954
[23,     3] loss: 1.059
[24,     3] loss: 1.028
[25,     3] loss: 0.986
[26,     3] loss: 0.975
[27,     3] loss: 0.934
[28,     3] loss: 1.038
[29,     3] loss: 0.967
[30,     3] loss: 0.961
[31,     3] loss: 0.895
[32,     3] loss: 0.925
[33,     3] loss: 0.922
[34,     3] loss: 0.912
[35,     3] loss: 0.910
[36,     3] loss: 0.989
[37,     3] loss: 0.938
[38,     3] loss: 0.901
[39,     3] loss: 0.925
[40,     3] loss: 0.955
[41,     3] loss: 0.849
[42,     3] loss: 0.868
[43,     3] loss: 0.870
[44,     3] loss: 0.897
[45,     3] loss: 0.823
[46,     3] loss: 0.888
[47,     3] loss: 0.867
[48,     3] loss: 0.847
[49,     3] loss: 0.910
[50,     3] loss: 0.896
[51,     3] loss: 0.882
[52,     3] loss: 0.885
[53,     3] loss: 0.927
[54,     3] loss: 0.932
[55,     3] loss: 0.923
[56,     3] loss: 0.872
[57,     3] loss: 0.956
[58,     3] loss: 0.920
[59,     3] loss: 0.945
[60,     3] loss: 1.011
[61,     3] loss: 0.862
[62,     3] loss: 1.013
[63,     3] loss: 1.016
[64,     3] loss: 0.957
[65,     3] loss: 0.962
[66,     3] loss: 0.907
[67,     3] loss: 0.950
Early stopping applied (best metric=0.535479724407196)
Finished Training
Total time taken: 15.050324201583862
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.377
[2,     3] loss: 1.389
[3,     3] loss: 1.399
[4,     3] loss: 1.386
[5,     3] loss: 1.383
[6,     3] loss: 1.379
[7,     3] loss: 1.371
[8,     3] loss: 1.362
[9,     3] loss: 1.361
[10,     3] loss: 1.291
[11,     3] loss: 1.307
[12,     3] loss: 1.206
[13,     3] loss: 1.254
[14,     3] loss: 1.154
[15,     3] loss: 1.203
[16,     3] loss: 1.122
[17,     3] loss: 1.197
[18,     3] loss: 1.110
[19,     3] loss: 0.984
[20,     3] loss: 1.088
[21,     3] loss: 0.989
[22,     3] loss: 1.200
[23,     3] loss: 1.240
[24,     3] loss: 1.025
[25,     3] loss: 1.061
[26,     3] loss: 1.181
[27,     3] loss: 1.074
[28,     3] loss: 1.166
[29,     3] loss: 1.117
[30,     3] loss: 1.111
[31,     3] loss: 1.046
[32,     3] loss: 1.007
[33,     3] loss: 0.974
[34,     3] loss: 1.037
[35,     3] loss: 0.876
[36,     3] loss: 0.907
[37,     3] loss: 0.886
[38,     3] loss: 0.946
[39,     3] loss: 0.937
[40,     3] loss: 0.904
[41,     3] loss: 0.921
[42,     3] loss: 0.921
[43,     3] loss: 0.882
[44,     3] loss: 0.870
[45,     3] loss: 0.843
[46,     3] loss: 0.966
[47,     3] loss: 1.399
[48,     3] loss: 1.252
[49,     3] loss: 1.053
[50,     3] loss: 1.158
[51,     3] loss: 1.084
[52,     3] loss: 1.083
[53,     3] loss: 1.069
[54,     3] loss: 0.956
[55,     3] loss: 1.012
[56,     3] loss: 0.896
[57,     3] loss: 0.898
[58,     3] loss: 0.878
[59,     3] loss: 0.902
[60,     3] loss: 0.920
[61,     3] loss: 0.975
[62,     3] loss: 0.902
[63,     3] loss: 0.932
[64,     3] loss: 0.845
Early stopping applied (best metric=0.5391914248466492)
Finished Training
Total time taken: 14.192038774490356
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.383
[3,     3] loss: 1.390
[4,     3] loss: 1.390
[5,     3] loss: 1.375
[6,     3] loss: 1.371
[7,     3] loss: 1.353
[8,     3] loss: 1.359
[9,     3] loss: 1.326
[10,     3] loss: 1.329
[11,     3] loss: 1.296
[12,     3] loss: 1.304
[13,     3] loss: 1.246
[14,     3] loss: 1.230
[15,     3] loss: 1.164
[16,     3] loss: 1.207
[17,     3] loss: 1.128
[18,     3] loss: 1.189
[19,     3] loss: 1.029
[20,     3] loss: 1.077
[21,     3] loss: 1.038
[22,     3] loss: 0.997
[23,     3] loss: 1.007
[24,     3] loss: 1.001
[25,     3] loss: 0.970
[26,     3] loss: 0.979
[27,     3] loss: 0.940
[28,     3] loss: 0.916
[29,     3] loss: 0.907
[30,     3] loss: 0.884
[31,     3] loss: 0.930
[32,     3] loss: 0.930
[33,     3] loss: 0.889
[34,     3] loss: 0.886
[35,     3] loss: 0.939
[36,     3] loss: 0.856
[37,     3] loss: 0.840
[38,     3] loss: 0.800
[39,     3] loss: 0.852
[40,     3] loss: 0.771
[41,     3] loss: 0.741
[42,     3] loss: 0.752
[43,     3] loss: 0.770
[44,     3] loss: 0.801
[45,     3] loss: 0.842
[46,     3] loss: 0.807
[47,     3] loss: 0.785
[48,     3] loss: 0.831
[49,     3] loss: 0.817
[50,     3] loss: 0.799
[51,     3] loss: 0.784
[52,     3] loss: 0.796
[53,     3] loss: 0.794
[54,     3] loss: 0.904
[55,     3] loss: 0.826
[56,     3] loss: 0.858
[57,     3] loss: 0.762
[58,     3] loss: 0.811
[59,     3] loss: 0.761
[60,     3] loss: 0.768
[61,     3] loss: 0.748
[62,     3] loss: 0.752
[63,     3] loss: 0.787
[64,     3] loss: 0.793
[65,     3] loss: 0.946
[66,     3] loss: 0.917
[67,     3] loss: 0.928
[68,     3] loss: 0.896
[69,     3] loss: 0.828
[70,     3] loss: 0.806
[71,     3] loss: 0.765
[72,     3] loss: 0.748
Early stopping applied (best metric=0.5107430815696716)
Finished Training
Total time taken: 16.085045099258423
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.383
[3,     3] loss: 1.390
[4,     3] loss: 1.385
[5,     3] loss: 1.383
[6,     3] loss: 1.388
[7,     3] loss: 1.381
[8,     3] loss: 1.382
[9,     3] loss: 1.384
[10,     3] loss: 1.376
[11,     3] loss: 1.352
[12,     3] loss: 1.342
[13,     3] loss: 1.330
[14,     3] loss: 1.298
[15,     3] loss: 1.204
[16,     3] loss: 1.208
[17,     3] loss: 1.169
[18,     3] loss: 1.095
[19,     3] loss: 1.077
[20,     3] loss: 1.054
[21,     3] loss: 1.153
[22,     3] loss: 1.225
[23,     3] loss: 1.186
[24,     3] loss: 1.064
[25,     3] loss: 1.121
[26,     3] loss: 1.082
[27,     3] loss: 1.085
[28,     3] loss: 0.998
[29,     3] loss: 1.014
[30,     3] loss: 0.951
[31,     3] loss: 0.961
[32,     3] loss: 0.937
[33,     3] loss: 1.100
[34,     3] loss: 0.867
[35,     3] loss: 0.887
[36,     3] loss: 0.849
[37,     3] loss: 0.855
[38,     3] loss: 1.020
[39,     3] loss: 0.915
[40,     3] loss: 0.909
[41,     3] loss: 0.897
[42,     3] loss: 0.963
[43,     3] loss: 0.832
[44,     3] loss: 0.864
[45,     3] loss: 0.843
[46,     3] loss: 0.867
[47,     3] loss: 0.832
[48,     3] loss: 0.935
[49,     3] loss: 0.851
[50,     3] loss: 0.850
[51,     3] loss: 0.838
[52,     3] loss: 0.915
[53,     3] loss: 1.009
[54,     3] loss: 0.986
[55,     3] loss: 0.976
[56,     3] loss: 0.884
[57,     3] loss: 0.897
[58,     3] loss: 0.908
[59,     3] loss: 0.852
[60,     3] loss: 0.884
[61,     3] loss: 0.877
[62,     3] loss: 0.922
[63,     3] loss: 0.845
[64,     3] loss: 0.799
[65,     3] loss: 0.815
[66,     3] loss: 0.824
[67,     3] loss: 0.789
[68,     3] loss: 0.827
Early stopping applied (best metric=0.5058974623680115)
Finished Training
Total time taken: 15.091404438018799
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.397
[3,     3] loss: 1.378
[4,     3] loss: 1.380
[5,     3] loss: 1.362
[6,     3] loss: 1.349
[7,     3] loss: 1.315
[8,     3] loss: 1.295
[9,     3] loss: 1.231
[10,     3] loss: 1.205
[11,     3] loss: 1.222
[12,     3] loss: 1.226
[13,     3] loss: 1.197
[14,     3] loss: 1.180
[15,     3] loss: 1.159
[16,     3] loss: 1.279
[17,     3] loss: 1.146
[18,     3] loss: 1.278
[19,     3] loss: 1.177
[20,     3] loss: 1.085
[21,     3] loss: 1.114
[22,     3] loss: 1.050
[23,     3] loss: 0.980
[24,     3] loss: 0.902
[25,     3] loss: 0.979
[26,     3] loss: 1.211
[27,     3] loss: 1.059
[28,     3] loss: 1.022
[29,     3] loss: 1.112
[30,     3] loss: 1.074
[31,     3] loss: 1.020
[32,     3] loss: 1.011
[33,     3] loss: 1.023
[34,     3] loss: 0.981
[35,     3] loss: 0.943
[36,     3] loss: 0.940
[37,     3] loss: 0.883
[38,     3] loss: 0.876
[39,     3] loss: 0.980
[40,     3] loss: 1.041
[41,     3] loss: 0.970
[42,     3] loss: 0.970
[43,     3] loss: 0.944
[44,     3] loss: 0.901
[45,     3] loss: 0.903
[46,     3] loss: 0.938
[47,     3] loss: 0.819
[48,     3] loss: 0.837
[49,     3] loss: 0.878
[50,     3] loss: 0.933
[51,     3] loss: 0.825
[52,     3] loss: 0.802
[53,     3] loss: 0.802
[54,     3] loss: 0.836
[55,     3] loss: 0.899
[56,     3] loss: 0.855
[57,     3] loss: 0.804
[58,     3] loss: 0.803
[59,     3] loss: 0.782
[60,     3] loss: 0.767
[61,     3] loss: 0.752
[62,     3] loss: 0.754
[63,     3] loss: 0.736
[64,     3] loss: 0.796
[65,     3] loss: 0.921
[66,     3] loss: 0.832
[67,     3] loss: 0.916
[68,     3] loss: 0.933
[69,     3] loss: 0.928
[70,     3] loss: 0.814
[71,     3] loss: 0.833
[72,     3] loss: 0.826
[73,     3] loss: 0.887
[74,     3] loss: 0.783
[75,     3] loss: 0.826
Early stopping applied (best metric=0.5409837961196899)
Finished Training
Total time taken: 16.765059232711792
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.391
[3,     3] loss: 1.384
[4,     3] loss: 1.376
[5,     3] loss: 1.381
[6,     3] loss: 1.378
[7,     3] loss: 1.376
[8,     3] loss: 1.374
[9,     3] loss: 1.377
[10,     3] loss: 1.382
[11,     3] loss: 1.323
[12,     3] loss: 1.380
[13,     3] loss: 1.314
[14,     3] loss: 1.309
[15,     3] loss: 1.270
[16,     3] loss: 1.240
[17,     3] loss: 1.145
[18,     3] loss: 1.091
[19,     3] loss: 1.139
[20,     3] loss: 1.077
[21,     3] loss: 1.046
[22,     3] loss: 1.319
[23,     3] loss: 1.419
[24,     3] loss: 1.125
[25,     3] loss: 1.234
[26,     3] loss: 1.179
[27,     3] loss: 1.183
[28,     3] loss: 1.127
[29,     3] loss: 1.113
[30,     3] loss: 1.088
[31,     3] loss: 0.993
[32,     3] loss: 0.930
[33,     3] loss: 0.917
[34,     3] loss: 1.028
[35,     3] loss: 0.972
[36,     3] loss: 0.948
[37,     3] loss: 0.905
[38,     3] loss: 0.949
[39,     3] loss: 0.860
[40,     3] loss: 0.872
[41,     3] loss: 0.865
[42,     3] loss: 0.949
[43,     3] loss: 0.976
[44,     3] loss: 0.905
[45,     3] loss: 0.917
[46,     3] loss: 0.879
[47,     3] loss: 0.862
[48,     3] loss: 0.853
[49,     3] loss: 0.817
[50,     3] loss: 0.783
[51,     3] loss: 0.840
[52,     3] loss: 0.887
[53,     3] loss: 1.022
[54,     3] loss: 0.857
[55,     3] loss: 0.863
[56,     3] loss: 0.871
[57,     3] loss: 0.931
[58,     3] loss: 0.838
[59,     3] loss: 0.909
[60,     3] loss: 0.826
[61,     3] loss: 0.793
[62,     3] loss: 0.785
[63,     3] loss: 0.746
[64,     3] loss: 0.760
[65,     3] loss: 0.798
[66,     3] loss: 0.863
[67,     3] loss: 0.855
[68,     3] loss: 0.890
Early stopping applied (best metric=0.5425381660461426)
Finished Training
Total time taken: 15.267044305801392
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.388
[3,     3] loss: 1.379
[4,     3] loss: 1.391
[5,     3] loss: 1.384
[6,     3] loss: 1.379
[7,     3] loss: 1.387
[8,     3] loss: 1.386
[9,     3] loss: 1.355
[10,     3] loss: 1.353
[11,     3] loss: 1.337
[12,     3] loss: 1.338
[13,     3] loss: 1.291
[14,     3] loss: 1.327
[15,     3] loss: 1.275
[16,     3] loss: 1.244
[17,     3] loss: 1.221
[18,     3] loss: 1.189
[19,     3] loss: 1.276
[20,     3] loss: 1.126
[21,     3] loss: 1.107
[22,     3] loss: 1.142
[23,     3] loss: 1.024
[24,     3] loss: 1.054
[25,     3] loss: 1.079
[26,     3] loss: 0.987
[27,     3] loss: 1.058
[28,     3] loss: 0.953
[29,     3] loss: 1.005
[30,     3] loss: 1.087
[31,     3] loss: 1.047
[32,     3] loss: 0.979
[33,     3] loss: 1.054
[34,     3] loss: 0.954
[35,     3] loss: 0.922
[36,     3] loss: 0.989
[37,     3] loss: 0.986
[38,     3] loss: 0.902
[39,     3] loss: 1.005
[40,     3] loss: 0.947
[41,     3] loss: 0.944
[42,     3] loss: 0.913
[43,     3] loss: 0.884
[44,     3] loss: 0.830
[45,     3] loss: 0.837
[46,     3] loss: 0.855
[47,     3] loss: 0.800
[48,     3] loss: 0.847
[49,     3] loss: 0.857
[50,     3] loss: 0.797
[51,     3] loss: 0.793
[52,     3] loss: 0.769
[53,     3] loss: 0.798
[54,     3] loss: 0.928
[55,     3] loss: 0.887
[56,     3] loss: 0.804
[57,     3] loss: 0.889
[58,     3] loss: 0.937
[59,     3] loss: 0.936
[60,     3] loss: 0.854
[61,     3] loss: 0.829
[62,     3] loss: 0.781
[63,     3] loss: 0.742
[64,     3] loss: 0.764
[65,     3] loss: 0.758
[66,     3] loss: 0.766
[67,     3] loss: 0.793
[68,     3] loss: 0.780
[69,     3] loss: 0.768
Early stopping applied (best metric=0.5409500002861023)
Finished Training
Total time taken: 15.386040925979614
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.384
[3,     3] loss: 1.391
[4,     3] loss: 1.372
[5,     3] loss: 1.364
[6,     3] loss: 1.352
[7,     3] loss: 1.326
[8,     3] loss: 1.319
[9,     3] loss: 1.233
[10,     3] loss: 1.248
[11,     3] loss: 1.242
[12,     3] loss: 1.305
[13,     3] loss: 1.329
[14,     3] loss: 1.215
[15,     3] loss: 1.159
[16,     3] loss: 1.211
[17,     3] loss: 1.078
[18,     3] loss: 1.052
[19,     3] loss: 1.028
[20,     3] loss: 0.994
[21,     3] loss: 1.092
[22,     3] loss: 1.052
[23,     3] loss: 0.988
[24,     3] loss: 1.119
[25,     3] loss: 0.917
[26,     3] loss: 0.938
[27,     3] loss: 0.919
[28,     3] loss: 0.903
[29,     3] loss: 0.947
[30,     3] loss: 0.943
[31,     3] loss: 1.011
[32,     3] loss: 0.918
[33,     3] loss: 0.877
[34,     3] loss: 1.030
[35,     3] loss: 0.896
[36,     3] loss: 0.872
[37,     3] loss: 0.886
[38,     3] loss: 0.837
[39,     3] loss: 0.789
[40,     3] loss: 0.771
[41,     3] loss: 0.845
[42,     3] loss: 0.909
[43,     3] loss: 0.858
[44,     3] loss: 0.865
[45,     3] loss: 0.960
[46,     3] loss: 0.891
[47,     3] loss: 0.847
[48,     3] loss: 0.883
[49,     3] loss: 0.894
[50,     3] loss: 0.912
[51,     3] loss: 0.804
[52,     3] loss: 0.815
[53,     3] loss: 0.824
[54,     3] loss: 0.750
[55,     3] loss: 0.749
[56,     3] loss: 0.736
[57,     3] loss: 0.739
[58,     3] loss: 0.734
[59,     3] loss: 0.755
[60,     3] loss: 0.868
[61,     3] loss: 0.844
[62,     3] loss: 0.801
[63,     3] loss: 0.870
[64,     3] loss: 0.827
[65,     3] loss: 0.858
[66,     3] loss: 0.809
[67,     3] loss: 0.795
[68,     3] loss: 0.769
[69,     3] loss: 0.790
[70,     3] loss: 0.747
[71,     3] loss: 0.743
Early stopping applied (best metric=0.5231271982192993)
Finished Training
Total time taken: 15.745044469833374
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.394
[3,     3] loss: 1.385
[4,     3] loss: 1.385
[5,     3] loss: 1.389
[6,     3] loss: 1.381
[7,     3] loss: 1.385
[8,     3] loss: 1.393
[9,     3] loss: 1.384
[10,     3] loss: 1.382
[11,     3] loss: 1.384
[12,     3] loss: 1.373
[13,     3] loss: 1.341
[14,     3] loss: 1.310
[15,     3] loss: 1.299
[16,     3] loss: 1.361
[17,     3] loss: 1.196
[18,     3] loss: 1.198
[19,     3] loss: 1.180
[20,     3] loss: 1.182
[21,     3] loss: 1.162
[22,     3] loss: 1.110
[23,     3] loss: 1.187
[24,     3] loss: 1.116
[25,     3] loss: 1.048
[26,     3] loss: 1.019
[27,     3] loss: 1.046
[28,     3] loss: 1.048
[29,     3] loss: 1.011
[30,     3] loss: 1.013
[31,     3] loss: 1.070
[32,     3] loss: 1.064
[33,     3] loss: 1.014
[34,     3] loss: 0.921
[35,     3] loss: 0.911
[36,     3] loss: 0.940
[37,     3] loss: 0.863
[38,     3] loss: 1.039
[39,     3] loss: 0.934
[40,     3] loss: 0.985
[41,     3] loss: 0.910
[42,     3] loss: 0.909
[43,     3] loss: 0.862
[44,     3] loss: 0.846
[45,     3] loss: 0.878
[46,     3] loss: 0.916
[47,     3] loss: 0.869
[48,     3] loss: 0.831
[49,     3] loss: 0.914
[50,     3] loss: 0.907
[51,     3] loss: 0.857
[52,     3] loss: 0.887
[53,     3] loss: 0.833
[54,     3] loss: 0.832
[55,     3] loss: 0.808
[56,     3] loss: 0.870
[57,     3] loss: 0.843
[58,     3] loss: 0.830
[59,     3] loss: 0.852
[60,     3] loss: 0.821
[61,     3] loss: 0.783
[62,     3] loss: 0.754
[63,     3] loss: 0.783
[64,     3] loss: 0.856
[65,     3] loss: 0.811
[66,     3] loss: 0.864
[67,     3] loss: 0.780
[68,     3] loss: 0.768
[69,     3] loss: 0.821
[70,     3] loss: 0.764
[71,     3] loss: 0.765
[72,     3] loss: 0.914
[73,     3] loss: 0.814
[74,     3] loss: 0.841
[75,     3] loss: 0.913
[76,     3] loss: 0.817
[77,     3] loss: 0.791
[78,     3] loss: 0.844
[79,     3] loss: 0.825
[80,     3] loss: 0.852
[81,     3] loss: 0.816
[82,     3] loss: 0.780
[83,     3] loss: 0.783
[84,     3] loss: 0.808
[85,     3] loss: 0.888
[86,     3] loss: 0.752
[87,     3] loss: 0.755
[88,     3] loss: 0.802
[89,     3] loss: 0.788
[90,     3] loss: 0.837
[91,     3] loss: 0.785
[92,     3] loss: 0.825
[93,     3] loss: 0.811
Early stopping applied (best metric=0.5186731815338135)
Finished Training
Total time taken: 20.79405689239502
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.388
[3,     3] loss: 1.389
[4,     3] loss: 1.385
[5,     3] loss: 1.377
[6,     3] loss: 1.381
[7,     3] loss: 1.378
[8,     3] loss: 1.389
[9,     3] loss: 1.367
[10,     3] loss: 1.367
[11,     3] loss: 1.342
[12,     3] loss: 1.317
[13,     3] loss: 1.274
[14,     3] loss: 1.272
[15,     3] loss: 1.245
[16,     3] loss: 1.215
[17,     3] loss: 1.187
[18,     3] loss: 1.103
[19,     3] loss: 1.070
[20,     3] loss: 1.058
[21,     3] loss: 1.228
[22,     3] loss: 1.126
[23,     3] loss: 1.140
[24,     3] loss: 1.096
[25,     3] loss: 1.028
[26,     3] loss: 1.007
[27,     3] loss: 0.962
[28,     3] loss: 1.023
[29,     3] loss: 1.005
[30,     3] loss: 0.986
[31,     3] loss: 0.990
[32,     3] loss: 1.055
[33,     3] loss: 0.952
[34,     3] loss: 0.960
[35,     3] loss: 0.980
[36,     3] loss: 0.918
[37,     3] loss: 0.934
[38,     3] loss: 0.874
[39,     3] loss: 0.901
[40,     3] loss: 0.875
[41,     3] loss: 0.858
[42,     3] loss: 0.870
[43,     3] loss: 0.798
[44,     3] loss: 0.822
[45,     3] loss: 0.816
[46,     3] loss: 0.805
[47,     3] loss: 0.804
[48,     3] loss: 0.822
[49,     3] loss: 0.801
[50,     3] loss: 0.873
[51,     3] loss: 0.818
[52,     3] loss: 0.805
[53,     3] loss: 0.972
[54,     3] loss: 0.888
[55,     3] loss: 0.863
[56,     3] loss: 0.877
[57,     3] loss: 0.844
[58,     3] loss: 0.886
[59,     3] loss: 0.830
[60,     3] loss: 0.879
[61,     3] loss: 0.906
[62,     3] loss: 0.918
[63,     3] loss: 1.042
[64,     3] loss: 0.976
[65,     3] loss: 0.932
[66,     3] loss: 0.965
[67,     3] loss: 0.905
[68,     3] loss: 0.815
[69,     3] loss: 0.887
Early stopping applied (best metric=0.5418068170547485)
Finished Training
Total time taken: 15.36528205871582
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.396
[3,     3] loss: 1.386
[4,     3] loss: 1.389
[5,     3] loss: 1.380
[6,     3] loss: 1.377
[7,     3] loss: 1.379
[8,     3] loss: 1.375
[9,     3] loss: 1.378
[10,     3] loss: 1.341
[11,     3] loss: 1.349
[12,     3] loss: 1.302
[13,     3] loss: 1.251
[14,     3] loss: 1.269
[15,     3] loss: 1.251
[16,     3] loss: 1.205
[17,     3] loss: 1.226
[18,     3] loss: 1.234
[19,     3] loss: 1.261
[20,     3] loss: 1.205
[21,     3] loss: 1.137
[22,     3] loss: 1.118
[23,     3] loss: 1.096
[24,     3] loss: 1.071
[25,     3] loss: 1.123
[26,     3] loss: 1.049
[27,     3] loss: 1.024
[28,     3] loss: 1.094
[29,     3] loss: 1.133
[30,     3] loss: 0.934
[31,     3] loss: 0.961
[32,     3] loss: 0.993
[33,     3] loss: 0.930
[34,     3] loss: 0.910
[35,     3] loss: 0.942
[36,     3] loss: 0.908
[37,     3] loss: 0.922
[38,     3] loss: 0.983
[39,     3] loss: 0.831
[40,     3] loss: 0.871
[41,     3] loss: 0.821
[42,     3] loss: 0.827
[43,     3] loss: 0.852
[44,     3] loss: 0.837
[45,     3] loss: 0.847
[46,     3] loss: 0.825
[47,     3] loss: 0.806
[48,     3] loss: 0.897
[49,     3] loss: 0.824
[50,     3] loss: 0.881
[51,     3] loss: 0.932
[52,     3] loss: 0.926
[53,     3] loss: 0.893
[54,     3] loss: 0.868
[55,     3] loss: 0.819
[56,     3] loss: 0.854
[57,     3] loss: 1.085
[58,     3] loss: 0.831
[59,     3] loss: 0.884
[60,     3] loss: 0.834
[61,     3] loss: 0.825
[62,     3] loss: 0.816
[63,     3] loss: 0.896
[64,     3] loss: 0.830
[65,     3] loss: 0.986
[66,     3] loss: 0.961
[67,     3] loss: 0.919
[68,     3] loss: 0.867
[69,     3] loss: 0.886
[70,     3] loss: 0.904
[71,     3] loss: 0.817
[72,     3] loss: 0.855
[73,     3] loss: 0.831
[74,     3] loss: 0.839
[75,     3] loss: 0.821
[76,     3] loss: 0.820
[77,     3] loss: 0.798
Early stopping applied (best metric=0.5256620645523071)
Finished Training
Total time taken: 17.136045455932617
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.383
[3,     3] loss: 1.384
[4,     3] loss: 1.380
[5,     3] loss: 1.375
[6,     3] loss: 1.361
[7,     3] loss: 1.371
[8,     3] loss: 1.336
[9,     3] loss: 1.295
[10,     3] loss: 1.259
[11,     3] loss: 1.242
[12,     3] loss: 1.179
[13,     3] loss: 1.235
[14,     3] loss: 1.119
[15,     3] loss: 1.067
[16,     3] loss: 1.135
[17,     3] loss: 1.103
[18,     3] loss: 1.049
[19,     3] loss: 1.082
[20,     3] loss: 1.030
[21,     3] loss: 0.989
[22,     3] loss: 1.061
[23,     3] loss: 1.045
[24,     3] loss: 1.064
[25,     3] loss: 1.033
[26,     3] loss: 1.081
[27,     3] loss: 0.939
[28,     3] loss: 0.902
[29,     3] loss: 0.938
[30,     3] loss: 0.942
[31,     3] loss: 1.159
[32,     3] loss: 1.011
[33,     3] loss: 0.973
[34,     3] loss: 1.016
[35,     3] loss: 0.987
[36,     3] loss: 0.944
[37,     3] loss: 0.861
[38,     3] loss: 0.870
[39,     3] loss: 0.871
[40,     3] loss: 0.857
[41,     3] loss: 0.858
[42,     3] loss: 0.817
[43,     3] loss: 0.797
[44,     3] loss: 0.804
[45,     3] loss: 0.835
[46,     3] loss: 0.852
[47,     3] loss: 0.822
[48,     3] loss: 0.856
[49,     3] loss: 0.850
[50,     3] loss: 0.889
[51,     3] loss: 0.823
[52,     3] loss: 0.804
[53,     3] loss: 0.851
[54,     3] loss: 0.825
[55,     3] loss: 0.781
[56,     3] loss: 0.765
[57,     3] loss: 0.764
[58,     3] loss: 0.800
[59,     3] loss: 0.846
[60,     3] loss: 0.870
[61,     3] loss: 1.012
[62,     3] loss: 0.884
[63,     3] loss: 0.955
[64,     3] loss: 1.051
[65,     3] loss: 1.034
[66,     3] loss: 0.899
Early stopping applied (best metric=0.534010648727417)
Finished Training
Total time taken: 14.77204179763794
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.391
[3,     3] loss: 1.386
[4,     3] loss: 1.375
[5,     3] loss: 1.358
[6,     3] loss: 1.385
[7,     3] loss: 1.367
[8,     3] loss: 1.357
[9,     3] loss: 1.321
[10,     3] loss: 1.326
[11,     3] loss: 1.242
[12,     3] loss: 1.248
[13,     3] loss: 1.166
[14,     3] loss: 1.222
[15,     3] loss: 1.192
[16,     3] loss: 1.072
[17,     3] loss: 1.086
[18,     3] loss: 1.086
[19,     3] loss: 0.988
[20,     3] loss: 1.130
[21,     3] loss: 0.946
[22,     3] loss: 1.071
[23,     3] loss: 1.179
[24,     3] loss: 1.105
[25,     3] loss: 1.031
[26,     3] loss: 1.070
[27,     3] loss: 1.026
[28,     3] loss: 1.054
[29,     3] loss: 1.173
[30,     3] loss: 0.982
[31,     3] loss: 1.059
[32,     3] loss: 1.072
[33,     3] loss: 0.979
[34,     3] loss: 0.952
[35,     3] loss: 1.003
[36,     3] loss: 0.956
[37,     3] loss: 0.834
[38,     3] loss: 0.841
[39,     3] loss: 0.999
[40,     3] loss: 0.998
[41,     3] loss: 0.903
[42,     3] loss: 0.854
[43,     3] loss: 0.869
[44,     3] loss: 0.917
[45,     3] loss: 0.851
[46,     3] loss: 0.863
[47,     3] loss: 0.845
[48,     3] loss: 0.921
[49,     3] loss: 0.927
[50,     3] loss: 0.978
[51,     3] loss: 0.939
[52,     3] loss: 0.983
[53,     3] loss: 0.813
[54,     3] loss: 0.881
[55,     3] loss: 0.851
[56,     3] loss: 0.855
[57,     3] loss: 0.820
[58,     3] loss: 0.944
[59,     3] loss: 0.887
[60,     3] loss: 0.812
[61,     3] loss: 0.820
[62,     3] loss: 0.831
[63,     3] loss: 0.790
[64,     3] loss: 0.781
[65,     3] loss: 0.837
[66,     3] loss: 0.781
[67,     3] loss: 0.857
[68,     3] loss: 0.804
[69,     3] loss: 0.808
Early stopping applied (best metric=0.5258394479751587)
Finished Training
Total time taken: 15.397042036056519
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.367
[3,     3] loss: 1.390
[4,     3] loss: 1.381
[5,     3] loss: 1.371
[6,     3] loss: 1.366
[7,     3] loss: 1.342
[8,     3] loss: 1.307
[9,     3] loss: 1.336
[10,     3] loss: 1.224
[11,     3] loss: 1.228
[12,     3] loss: 1.156
[13,     3] loss: 1.158
[14,     3] loss: 1.254
[15,     3] loss: 1.082
[16,     3] loss: 1.193
[17,     3] loss: 1.114
[18,     3] loss: 1.158
[19,     3] loss: 1.244
[20,     3] loss: 1.113
[21,     3] loss: 1.017
[22,     3] loss: 1.045
[23,     3] loss: 1.120
[24,     3] loss: 1.046
[25,     3] loss: 0.946
[26,     3] loss: 0.930
[27,     3] loss: 0.998
[28,     3] loss: 0.984
[29,     3] loss: 0.953
[30,     3] loss: 0.950
[31,     3] loss: 0.826
[32,     3] loss: 0.953
[33,     3] loss: 0.878
[34,     3] loss: 0.941
[35,     3] loss: 0.880
[36,     3] loss: 0.799
[37,     3] loss: 0.883
[38,     3] loss: 1.009
[39,     3] loss: 0.937
[40,     3] loss: 0.975
[41,     3] loss: 1.057
[42,     3] loss: 0.969
[43,     3] loss: 1.048
[44,     3] loss: 0.941
[45,     3] loss: 0.891
[46,     3] loss: 0.850
[47,     3] loss: 0.822
[48,     3] loss: 0.854
[49,     3] loss: 0.892
[50,     3] loss: 0.839
[51,     3] loss: 0.810
[52,     3] loss: 0.878
[53,     3] loss: 0.827
[54,     3] loss: 0.839
[55,     3] loss: 0.863
[56,     3] loss: 0.849
[57,     3] loss: 0.831
[58,     3] loss: 0.809
[59,     3] loss: 0.794
[60,     3] loss: 0.866
[61,     3] loss: 0.776
[62,     3] loss: 0.738
[63,     3] loss: 0.760
[64,     3] loss: 0.769
[65,     3] loss: 0.774
[66,     3] loss: 0.792
[67,     3] loss: 0.822
[68,     3] loss: 0.812
[69,     3] loss: 0.830
[70,     3] loss: 0.821
[71,     3] loss: 0.862
[72,     3] loss: 0.813
[73,     3] loss: 0.786
[74,     3] loss: 0.761
[75,     3] loss: 0.837
[76,     3] loss: 0.868
[77,     3] loss: 0.858
[78,     3] loss: 0.853
[79,     3] loss: 0.787
[80,     3] loss: 0.779
[81,     3] loss: 0.882
[82,     3] loss: 0.771
[83,     3] loss: 0.752
[84,     3] loss: 0.774
[85,     3] loss: 0.839
[86,     3] loss: 0.778
[87,     3] loss: 0.863
[88,     3] loss: 0.833
[89,     3] loss: 0.821
[90,     3] loss: 0.773
[91,     3] loss: 0.846
[92,     3] loss: 0.753
[93,     3] loss: 0.767
[94,     3] loss: 0.754
[95,     3] loss: 0.746
[96,     3] loss: 0.738
[97,     3] loss: 1.029
[98,     3] loss: 1.271
[99,     3] loss: 1.346
[100,     3] loss: 1.182
[101,     3] loss: 1.262
[102,     3] loss: 1.207
[103,     3] loss: 1.131
[104,     3] loss: 1.111
[105,     3] loss: 0.997
[106,     3] loss: 0.972
[107,     3] loss: 0.955
[108,     3] loss: 0.904
[109,     3] loss: 0.903
Early stopping applied (best metric=0.5345999598503113)
Finished Training
Total time taken: 24.294066905975342
{'S-palmitoylation-C Validation Accuracy': 0.6456471661930178, 'S-palmitoylation-C Validation Sensitivity': 0.30349834983498347, 'S-palmitoylation-C Validation Specificity': 0.7314050283252961, 'S-palmitoylation-C Validation Precision': 0.2360211899749033, 'S-palmitoylation-C AUC ROC': 0.5337260326524003, 'S-palmitoylation-C AUC PR': 0.22104770245418243, 'S-palmitoylation-C MCC': 0.03833729301174034, 'S-palmitoylation-C F1': 0.22716569307535134, 'Validation Loss (S-palmitoylation-C)': 0.5542932669321696, 'Hydroxylation-K Validation Accuracy': 0.6563829787234042, 'Hydroxylation-K Validation Sensitivity': 0.8148148148148148, 'Hydroxylation-K Validation Specificity': 0.6175438596491228, 'Hydroxylation-K Validation Precision': 0.3764589339227964, 'Hydroxylation-K AUC ROC': 0.8222222222222222, 'Hydroxylation-K AUC PR': 0.6277177791770957, 'Hydroxylation-K MCC': 0.3680974232942928, 'Hydroxylation-K F1': 0.5007812046235691, 'Validation Loss (Hydroxylation-K)': 0.5288882692654927, 'Validation Loss (total)': 1.0831815322240195, 'TimeToTrain': 16.505038674672445}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015669730765389895,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4320489474563738,
 'loss_weight_S-palmitoylation-C': 0.8235575846769646,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1975651329,
 'sample_weights': [0.48025372250096743, 0.5309223375645755],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7948411174410033,
 'weight_decay_Hydroxylation-K': 2.167418832699994,
 'weight_decay_S-palmitoylation-C': 0.4462672832147279}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.386
[3,     3] loss: 1.377
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028035679428744307,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5934109686906447,
 'loss_weight_S-palmitoylation-C': 0.6560208119808394,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 868239836,
 'sample_weights': [0.8235575846769646, 0.4320489474563738],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.0742666779903893,
 'weight_decay_Hydroxylation-K': 9.893555824249644,
 'weight_decay_S-palmitoylation-C': 1.4338981690469683}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.378
[2,     3] loss: 1.392
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007176927102095653,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8297677738772823,
 'loss_weight_S-palmitoylation-C': 0.9072285029251591,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4189312655,
 'sample_weights': [0.6560208119808394, 0.5934109686906447],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.298991328701396,
 'weight_decay_Hydroxylation-K': 4.578607277009327,
 'weight_decay_S-palmitoylation-C': 8.96507582379938}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.373
[2,     3] loss: 1.395
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016222619076078789,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.47184065583640195,
 'loss_weight_S-palmitoylation-C': 0.9735396895081461,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3565769122,
 'sample_weights': [0.9072285029251591, 0.8297677738772823],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3749548382068593,
 'weight_decay_Hydroxylation-K': 3.345866833912732,
 'weight_decay_S-palmitoylation-C': 0.03192981842018407}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.384
[3,     3] loss: 1.389
[4,     3] loss: 1.386
[5,     3] loss: 1.368
[6,     3] loss: 1.360
[7,     3] loss: 1.339
[8,     3] loss: 1.311
[9,     3] loss: 1.258
[10,     3] loss: 1.257
[11,     3] loss: 1.160
[12,     3] loss: 1.172
[13,     3] loss: 1.149
[14,     3] loss: 1.064
[15,     3] loss: 1.232
[16,     3] loss: 1.053
[17,     3] loss: 1.020
[18,     3] loss: 1.004
[19,     3] loss: 0.986
[20,     3] loss: 0.976
[21,     3] loss: 0.900
[22,     3] loss: 0.893
[23,     3] loss: 0.925
[24,     3] loss: 0.923
[25,     3] loss: 0.976
[26,     3] loss: 1.058
[27,     3] loss: 0.912
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013798765064038025,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.626877021213462,
 'loss_weight_S-palmitoylation-C': 0.3331433809570359,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3383968054,
 'sample_weights': [0.9735396895081461, 0.47184065583640195],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.706483752037133,
 'weight_decay_Hydroxylation-K': 0.5755336327494918,
 'weight_decay_S-palmitoylation-C': 6.79285677701251}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.383
[3,     3] loss: 1.378
[4,     3] loss: 1.387
[5,     3] loss: 1.369
[6,     3] loss: 1.349
[7,     3] loss: 1.318
[8,     3] loss: 1.284
[9,     3] loss: 1.228
[10,     3] loss: 1.210
[11,     3] loss: 1.195
[12,     3] loss: 1.145
[13,     3] loss: 1.126
[14,     3] loss: 1.101
[15,     3] loss: 1.053
[16,     3] loss: 1.066
[17,     3] loss: 1.139
[18,     3] loss: 1.041
[19,     3] loss: 1.117
[20,     3] loss: 1.027
[21,     3] loss: 0.975
[22,     3] loss: 1.036
[23,     3] loss: 0.967
[24,     3] loss: 0.937
[25,     3] loss: 0.927
[26,     3] loss: 0.912
[27,     3] loss: 1.090
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003898412687217661,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.16023642492243514,
 'loss_weight_S-palmitoylation-C': 0.41711232104778295,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1096019112,
 'sample_weights': [0.3331433809570359, 0.626877021213462],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5176390634042134,
 'weight_decay_Hydroxylation-K': 2.009134704223243,
 'weight_decay_S-palmitoylation-C': 5.587070896657407}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.390
[3,     3] loss: 1.387
[4,     3] loss: 1.382
[5,     3] loss: 1.385
[6,     3] loss: 1.384
[7,     3] loss: 1.380
[8,     3] loss: 1.389
[9,     3] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003824741491329669,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4240314558639222,
 'loss_weight_S-palmitoylation-C': 0.9778958625343565,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1319998492,
 'sample_weights': [0.41711232104778295, 0.16023642492243514],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.229024100111422,
 'weight_decay_Hydroxylation-K': 3.6118828331226984,
 'weight_decay_S-palmitoylation-C': 0.2799639943631512}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.381
[3,     3] loss: 1.387
[4,     3] loss: 1.384
[5,     3] loss: 1.386
[6,     3] loss: 1.380
[7,     3] loss: 1.376
[8,     3] loss: 1.377
[9,     3] loss: 1.375
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001049982569195415,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6625681779495838,
 'loss_weight_S-palmitoylation-C': 0.37709591728194947,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1243533684,
 'sample_weights': [0.9778958625343565, 0.4240314558639222],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.542036613031447,
 'weight_decay_Hydroxylation-K': 4.5078072552432,
 'weight_decay_S-palmitoylation-C': 0.1581937154940214}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.388
[3,     3] loss: 1.387
[4,     3] loss: 1.391
[5,     3] loss: 1.383
[6,     3] loss: 1.385
[7,     3] loss: 1.377
[8,     3] loss: 1.383
[9,     3] loss: 1.363
[10,     3] loss: 1.362
[11,     3] loss: 1.348
[12,     3] loss: 1.340
[13,     3] loss: 1.280
[14,     3] loss: 1.288
[15,     3] loss: 1.290
[16,     3] loss: 1.247
[17,     3] loss: 1.214
[18,     3] loss: 1.198
[19,     3] loss: 1.161
[20,     3] loss: 1.121
[21,     3] loss: 1.122
[22,     3] loss: 1.282
[23,     3] loss: 1.244
[24,     3] loss: 1.300
[25,     3] loss: 1.157
[26,     3] loss: 1.109
[27,     3] loss: 1.101
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025718697685998,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4801776780790328,
 'loss_weight_S-palmitoylation-C': 0.5148457951196042,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2172605184,
 'sample_weights': [0.37709591728194947, 0.6625681779495838],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.041824174070996,
 'weight_decay_Hydroxylation-K': 3.40860790608375,
 'weight_decay_S-palmitoylation-C': 8.127479326691148}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.399
[3,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005365595839153486,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9980703861134493,
 'loss_weight_S-palmitoylation-C': 0.2976044652799379,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3092490257,
 'sample_weights': [0.5148457951196042, 0.4801776780790328],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.1069702295424,
 'weight_decay_Hydroxylation-K': 6.9307175501851885,
 'weight_decay_S-palmitoylation-C': 6.616481340343821}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.389
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006296410620660777,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6247095067456793,
 'loss_weight_S-palmitoylation-C': 0.164957906297982,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3748600628,
 'sample_weights': [0.2976044652799379, 0.9980703861134493],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.584556551985363,
 'weight_decay_Hydroxylation-K': 0.68515625420033,
 'weight_decay_S-palmitoylation-C': 2.6452035854251372}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.381
[3,     3] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 5.048160727637936e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6085448571845079,
 'loss_weight_S-palmitoylation-C': 0.23806246302064007,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 845146959,
 'sample_weights': [0.164957906297982, 0.6247095067456793],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3281965549281987,
 'weight_decay_Hydroxylation-K': 9.250465912549394,
 'weight_decay_S-palmitoylation-C': 4.381984808293628}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.403
[2,     3] loss: 1.396
[3,     3] loss: 1.394
[4,     3] loss: 1.389
[5,     3] loss: 1.385
[6,     3] loss: 1.386
[7,     3] loss: 1.373
[8,     3] loss: 1.389
[9,     3] loss: 1.388
[10,     3] loss: 1.379
[11,     3] loss: 1.390
[12,     3] loss: 1.387
[13,     3] loss: 1.385
[14,     3] loss: 1.385
[15,     3] loss: 1.386
[16,     3] loss: 1.380
[17,     3] loss: 1.381
[18,     3] loss: 1.400
[19,     3] loss: 1.390
[20,     3] loss: 1.382
[21,     3] loss: 1.382
[22,     3] loss: 1.384
[23,     3] loss: 1.388
[24,     3] loss: 1.378
[25,     3] loss: 1.389
[26,     3] loss: 1.378
[27,     3] loss: 1.388
[28,     3] loss: 1.380
[29,     3] loss: 1.391
[30,     3] loss: 1.388
[31,     3] loss: 1.378
[32,     3] loss: 1.385
[33,     3] loss: 1.383
[34,     3] loss: 1.383
[35,     3] loss: 1.389
[36,     3] loss: 1.381
[37,     3] loss: 1.381
[38,     3] loss: 1.382
[39,     3] loss: 1.386
[40,     3] loss: 1.381
[41,     3] loss: 1.384
[42,     3] loss: 1.369
[43,     3] loss: 1.367
[44,     3] loss: 1.378
[45,     3] loss: 1.376
[46,     3] loss: 1.379
[47,     3] loss: 1.384
[48,     3] loss: 1.364
[49,     3] loss: 1.363
[50,     3] loss: 1.366
[51,     3] loss: 1.369
[52,     3] loss: 1.378
[53,     3] loss: 1.369
[54,     3] loss: 1.371
[55,     3] loss: 1.365
[56,     3] loss: 1.367
[57,     3] loss: 1.364
[58,     3] loss: 1.372
[59,     3] loss: 1.352
[60,     3] loss: 1.356
[61,     3] loss: 1.358
[62,     3] loss: 1.360
[63,     3] loss: 1.357
[64,     3] loss: 1.341
[65,     3] loss: 1.344
[66,     3] loss: 1.347
[67,     3] loss: 1.342
[68,     3] loss: 1.338
[69,     3] loss: 1.338
[70,     3] loss: 1.328
[71,     3] loss: 1.333
[72,     3] loss: 1.333
[73,     3] loss: 1.306
[74,     3] loss: 1.321
[75,     3] loss: 1.321
[76,     3] loss: 1.305
[77,     3] loss: 1.294
[78,     3] loss: 1.309
[79,     3] loss: 1.328
[80,     3] loss: 1.273
[81,     3] loss: 1.288
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003639353611213111,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5181889552581253,
 'loss_weight_S-palmitoylation-C': 0.08335638288614111,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1478194014,
 'sample_weights': [0.23806246302064007, 0.6085448571845079],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.660190332638434,
 'weight_decay_Hydroxylation-K': 0.23492337203086233,
 'weight_decay_S-palmitoylation-C': 3.221046899726928}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.402
[2,     3] loss: 1.390
[3,     3] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011476689218013927,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21446274752106878,
 'loss_weight_S-palmitoylation-C': 0.9573561900706081,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 779600822,
 'sample_weights': [0.08335638288614111, 0.5181889552581253],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.25464731362886,
 'weight_decay_Hydroxylation-K': 0.4564336824606814,
 'weight_decay_S-palmitoylation-C': 1.2465740795578808}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.394
[3,     3] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003684689268843743,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6033556194816374,
 'loss_weight_S-palmitoylation-C': 0.6400178595970941,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3516471351,
 'sample_weights': [0.9573561900706081, 0.21446274752106878],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.96821738763547,
 'weight_decay_Hydroxylation-K': 0.36885985176357083,
 'weight_decay_S-palmitoylation-C': 3.2831640134506435}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.377
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025979071651789035,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.44309870104776977,
 'loss_weight_S-palmitoylation-C': 0.7144014903329694,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 120449029,
 'sample_weights': [0.6400178595970941, 0.6033556194816374],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.078763913957229,
 'weight_decay_Hydroxylation-K': 4.714857733605667,
 'weight_decay_S-palmitoylation-C': 2.2088076448971736}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.390
[3,     3] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0038927779071025164,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.11737895398317351,
 'loss_weight_S-palmitoylation-C': 0.33114897035304275,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3768412759,
 'sample_weights': [0.7144014903329694, 0.44309870104776977],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.638518924136951,
 'weight_decay_Hydroxylation-K': 0.9410973915259735,
 'weight_decay_S-palmitoylation-C': 4.422767228177432}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.391
[3,     3] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035929738314820353,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.06627779649374493,
 'loss_weight_S-palmitoylation-C': 0.09891000805045583,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3586101702,
 'sample_weights': [0.33114897035304275, 0.11737895398317351],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.990618276728203,
 'weight_decay_Hydroxylation-K': 2.1671902722384555,
 'weight_decay_S-palmitoylation-C': 1.0410134606308485}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.381
[3,     3] loss: 1.380
[4,     3] loss: 1.384
[5,     3] loss: 1.381
[6,     3] loss: 1.391
[7,     3] loss: 1.371
[8,     3] loss: 1.380
[9,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007948634769650033,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4534472742366848,
 'loss_weight_S-palmitoylation-C': 0.47433014932796386,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2199809274,
 'sample_weights': [0.09891000805045583, 0.06627779649374493],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.175615445531552,
 'weight_decay_Hydroxylation-K': 0.2091924608568133,
 'weight_decay_S-palmitoylation-C': 4.85470786070114}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.393
[3,     3] loss: 1.385
[4,     3] loss: 1.387
[5,     3] loss: 1.383
[6,     3] loss: 1.377
[7,     3] loss: 1.382
[8,     3] loss: 1.382
[9,     3] loss: 1.377
[10,     3] loss: 1.353
[11,     3] loss: 1.341
[12,     3] loss: 1.348
[13,     3] loss: 1.299
[14,     3] loss: 1.284
[15,     3] loss: 1.311
[16,     3] loss: 1.278
[17,     3] loss: 1.186
[18,     3] loss: 1.190
[19,     3] loss: 1.141
[20,     3] loss: 1.139
[21,     3] loss: 1.065
[22,     3] loss: 1.121
[23,     3] loss: 0.989
[24,     3] loss: 1.050
[25,     3] loss: 1.162
[26,     3] loss: 0.947
[27,     3] loss: 1.113
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007415937225224206,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7463321805184879,
 'loss_weight_S-palmitoylation-C': 0.10339420760752088,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4046839696,
 'sample_weights': [0.47433014932796386, 0.4534472742366848],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.585882248004019,
 'weight_decay_Hydroxylation-K': 2.9582079639770473,
 'weight_decay_S-palmitoylation-C': 5.017409108749175}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.389
[3,     3] loss: 1.383
[4,     3] loss: 1.387
[5,     3] loss: 1.383
[6,     3] loss: 1.385
[7,     3] loss: 1.374
[8,     3] loss: 1.390
[9,     3] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017598782990150968,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4895375543238016,
 'loss_weight_S-palmitoylation-C': 0.8908243010669361,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4280168792,
 'sample_weights': [0.10339420760752088, 0.7463321805184879],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.0974009665139057,
 'weight_decay_Hydroxylation-K': 5.286883983406616,
 'weight_decay_S-palmitoylation-C': 0.48479212014625855}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.390
[3,     3] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007273447498153376,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8286767026356727,
 'loss_weight_S-palmitoylation-C': 0.7354502823483371,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3932676704,
 'sample_weights': [0.8908243010669361, 0.4895375543238016],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8583622168609724,
 'weight_decay_Hydroxylation-K': 8.963662007943217,
 'weight_decay_S-palmitoylation-C': 0.9657644506173444}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.385
[3,     3] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014977103202964723,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5192334389873131,
 'loss_weight_S-palmitoylation-C': 0.4785576771858115,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 269990701,
 'sample_weights': [0.7354502823483371, 0.8286767026356727],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.406587664291075,
 'weight_decay_Hydroxylation-K': 8.97165552851964,
 'weight_decay_S-palmitoylation-C': 6.89954113133318}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.382
[2,     3] loss: 1.382
[3,     3] loss: 1.382
[4,     3] loss: 1.390
[5,     3] loss: 1.385
[6,     3] loss: 1.384
[7,     3] loss: 1.375
[8,     3] loss: 1.378
[9,     3] loss: 1.366
[10,     3] loss: 1.353
[11,     3] loss: 1.347
[12,     3] loss: 1.329
[13,     3] loss: 1.295
[14,     3] loss: 1.277
[15,     3] loss: 1.242
[16,     3] loss: 1.237
[17,     3] loss: 1.196
[18,     3] loss: 1.167
[19,     3] loss: 1.139
[20,     3] loss: 1.132
[21,     3] loss: 1.155
[22,     3] loss: 1.184
[23,     3] loss: 1.143
[24,     3] loss: 1.033
[25,     3] loss: 1.011
[26,     3] loss: 1.049
[27,     3] loss: 1.064
[28,     3] loss: 1.022
[29,     3] loss: 0.998
[30,     3] loss: 1.083
[31,     3] loss: 1.047
[32,     3] loss: 0.986
[33,     3] loss: 1.054
[34,     3] loss: 0.967
[35,     3] loss: 0.952
[36,     3] loss: 0.945
[37,     3] loss: 0.915
[38,     3] loss: 1.016
[39,     3] loss: 0.922
[40,     3] loss: 0.930
[41,     3] loss: 0.920
[42,     3] loss: 0.869
[43,     3] loss: 0.882
[44,     3] loss: 0.893
[45,     3] loss: 0.893
[46,     3] loss: 0.851
[47,     3] loss: 0.931
[48,     3] loss: 0.855
[49,     3] loss: 0.910
[50,     3] loss: 0.863
[51,     3] loss: 0.873
[52,     3] loss: 1.053
[53,     3] loss: 1.037
[54,     3] loss: 1.003
[55,     3] loss: 0.915
[56,     3] loss: 0.890
[57,     3] loss: 0.870
[58,     3] loss: 0.859
[59,     3] loss: 0.808
[60,     3] loss: 0.817
[61,     3] loss: 0.827
[62,     3] loss: 0.784
[63,     3] loss: 0.789
[64,     3] loss: 0.770
[65,     3] loss: 0.764
[66,     3] loss: 0.771
[67,     3] loss: 0.784
[68,     3] loss: 0.792
[69,     3] loss: 0.770
[70,     3] loss: 0.846
[71,     3] loss: 0.790
[72,     3] loss: 0.799
[73,     3] loss: 0.887
[74,     3] loss: 0.851
[75,     3] loss: 0.865
Early stopping applied (best metric=0.5152714252471924)
Finished Training
Total time taken: 16.763052463531494
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.389
[3,     3] loss: 1.385
[4,     3] loss: 1.384
[5,     3] loss: 1.382
[6,     3] loss: 1.379
[7,     3] loss: 1.378
[8,     3] loss: 1.378
[9,     3] loss: 1.377
[10,     3] loss: 1.354
[11,     3] loss: 1.346
[12,     3] loss: 1.344
[13,     3] loss: 1.359
[14,     3] loss: 1.301
[15,     3] loss: 1.246
[16,     3] loss: 1.223
[17,     3] loss: 1.152
[18,     3] loss: 1.137
[19,     3] loss: 1.113
[20,     3] loss: 1.031
[21,     3] loss: 1.077
[22,     3] loss: 1.027
[23,     3] loss: 1.085
[24,     3] loss: 1.121
[25,     3] loss: 1.159
[26,     3] loss: 1.089
[27,     3] loss: 1.000
[28,     3] loss: 0.994
[29,     3] loss: 1.042
[30,     3] loss: 0.998
[31,     3] loss: 1.038
[32,     3] loss: 1.058
[33,     3] loss: 1.009
[34,     3] loss: 0.944
[35,     3] loss: 0.991
[36,     3] loss: 0.902
[37,     3] loss: 0.899
[38,     3] loss: 0.902
[39,     3] loss: 0.947
[40,     3] loss: 0.915
[41,     3] loss: 0.931
[42,     3] loss: 0.943
[43,     3] loss: 0.929
[44,     3] loss: 0.963
[45,     3] loss: 0.970
[46,     3] loss: 0.977
[47,     3] loss: 0.924
[48,     3] loss: 0.882
[49,     3] loss: 0.935
[50,     3] loss: 0.894
[51,     3] loss: 0.894
[52,     3] loss: 0.898
[53,     3] loss: 0.877
[54,     3] loss: 0.894
[55,     3] loss: 0.896
[56,     3] loss: 0.884
[57,     3] loss: 0.844
[58,     3] loss: 0.954
[59,     3] loss: 0.908
[60,     3] loss: 0.876
[61,     3] loss: 0.864
[62,     3] loss: 0.858
[63,     3] loss: 0.813
[64,     3] loss: 0.805
[65,     3] loss: 0.808
[66,     3] loss: 0.839
[67,     3] loss: 0.820
[68,     3] loss: 0.875
[69,     3] loss: 0.810
Early stopping applied (best metric=0.5148622989654541)
Finished Training
Total time taken: 15.46206283569336
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.383
[3,     3] loss: 1.389
[4,     3] loss: 1.386
[5,     3] loss: 1.380
[6,     3] loss: 1.386
[7,     3] loss: 1.382
[8,     3] loss: 1.387
[9,     3] loss: 1.377
[10,     3] loss: 1.377
[11,     3] loss: 1.379
[12,     3] loss: 1.365
[13,     3] loss: 1.352
[14,     3] loss: 1.346
[15,     3] loss: 1.319
[16,     3] loss: 1.275
[17,     3] loss: 1.256
[18,     3] loss: 1.207
[19,     3] loss: 1.201
[20,     3] loss: 1.183
[21,     3] loss: 1.246
[22,     3] loss: 1.118
[23,     3] loss: 1.140
[24,     3] loss: 1.168
[25,     3] loss: 1.133
[26,     3] loss: 1.056
[27,     3] loss: 0.991
[28,     3] loss: 0.999
[29,     3] loss: 1.030
[30,     3] loss: 1.019
[31,     3] loss: 0.950
[32,     3] loss: 1.082
[33,     3] loss: 0.954
[34,     3] loss: 0.908
[35,     3] loss: 1.047
[36,     3] loss: 1.023
[37,     3] loss: 0.967
[38,     3] loss: 0.926
[39,     3] loss: 0.898
[40,     3] loss: 0.898
[41,     3] loss: 0.871
[42,     3] loss: 0.881
[43,     3] loss: 0.930
[44,     3] loss: 0.882
[45,     3] loss: 1.014
[46,     3] loss: 0.914
[47,     3] loss: 0.900
[48,     3] loss: 0.930
[49,     3] loss: 0.928
[50,     3] loss: 0.877
[51,     3] loss: 0.828
[52,     3] loss: 0.853
[53,     3] loss: 0.879
[54,     3] loss: 0.856
[55,     3] loss: 0.836
[56,     3] loss: 0.808
[57,     3] loss: 0.797
[58,     3] loss: 0.823
[59,     3] loss: 0.784
[60,     3] loss: 0.841
[61,     3] loss: 0.825
[62,     3] loss: 0.927
[63,     3] loss: 0.832
[64,     3] loss: 0.845
[65,     3] loss: 0.847
[66,     3] loss: 0.820
[67,     3] loss: 0.810
[68,     3] loss: 0.809
[69,     3] loss: 0.786
[70,     3] loss: 0.790
[71,     3] loss: 0.801
[72,     3] loss: 0.801
[73,     3] loss: 0.788
[74,     3] loss: 0.767
Early stopping applied (best metric=0.5159887671470642)
Finished Training
Total time taken: 16.503052949905396
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.384
[3,     3] loss: 1.386
[4,     3] loss: 1.385
[5,     3] loss: 1.383
[6,     3] loss: 1.402
[7,     3] loss: 1.397
[8,     3] loss: 1.389
[9,     3] loss: 1.380
[10,     3] loss: 1.382
[11,     3] loss: 1.377
[12,     3] loss: 1.361
[13,     3] loss: 1.343
[14,     3] loss: 1.342
[15,     3] loss: 1.323
[16,     3] loss: 1.283
[17,     3] loss: 1.223
[18,     3] loss: 1.262
[19,     3] loss: 1.138
[20,     3] loss: 1.217
[21,     3] loss: 1.194
[22,     3] loss: 1.193
[23,     3] loss: 1.222
[24,     3] loss: 1.184
[25,     3] loss: 1.168
[26,     3] loss: 1.079
[27,     3] loss: 1.102
[28,     3] loss: 1.129
[29,     3] loss: 1.013
[30,     3] loss: 1.081
[31,     3] loss: 1.092
[32,     3] loss: 1.020
[33,     3] loss: 0.993
[34,     3] loss: 1.023
[35,     3] loss: 1.066
[36,     3] loss: 0.938
[37,     3] loss: 0.983
[38,     3] loss: 0.950
[39,     3] loss: 1.116
[40,     3] loss: 1.112
[41,     3] loss: 1.016
[42,     3] loss: 1.018
[43,     3] loss: 1.021
[44,     3] loss: 1.027
[45,     3] loss: 0.964
[46,     3] loss: 0.955
[47,     3] loss: 0.997
[48,     3] loss: 0.891
[49,     3] loss: 0.970
[50,     3] loss: 0.922
[51,     3] loss: 0.927
[52,     3] loss: 0.901
[53,     3] loss: 0.932
[54,     3] loss: 0.852
[55,     3] loss: 0.940
[56,     3] loss: 0.894
[57,     3] loss: 0.888
[58,     3] loss: 0.917
[59,     3] loss: 1.003
[60,     3] loss: 1.113
[61,     3] loss: 1.205
[62,     3] loss: 0.949
[63,     3] loss: 1.156
[64,     3] loss: 1.010
[65,     3] loss: 0.986
[66,     3] loss: 1.102
[67,     3] loss: 0.988
[68,     3] loss: 0.989
[69,     3] loss: 0.924
[70,     3] loss: 0.910
[71,     3] loss: 0.896
[72,     3] loss: 0.822
[73,     3] loss: 0.823
[74,     3] loss: 0.831
[75,     3] loss: 0.794
[76,     3] loss: 0.793
[77,     3] loss: 0.824
[78,     3] loss: 0.777
[79,     3] loss: 0.868
[80,     3] loss: 0.863
[81,     3] loss: 0.927
[82,     3] loss: 0.844
[83,     3] loss: 0.833
[84,     3] loss: 0.818
[85,     3] loss: 0.938
Early stopping applied (best metric=0.5272587537765503)
Finished Training
Total time taken: 18.99523138999939
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.389
[3,     3] loss: 1.388
[4,     3] loss: 1.388
[5,     3] loss: 1.385
[6,     3] loss: 1.380
[7,     3] loss: 1.382
[8,     3] loss: 1.381
[9,     3] loss: 1.381
[10,     3] loss: 1.368
[11,     3] loss: 1.364
[12,     3] loss: 1.348
[13,     3] loss: 1.335
[14,     3] loss: 1.313
[15,     3] loss: 1.277
[16,     3] loss: 1.229
[17,     3] loss: 1.220
[18,     3] loss: 1.180
[19,     3] loss: 1.186
[20,     3] loss: 1.139
[21,     3] loss: 1.118
[22,     3] loss: 1.214
[23,     3] loss: 1.141
[24,     3] loss: 1.160
[25,     3] loss: 1.097
[26,     3] loss: 1.102
[27,     3] loss: 1.018
[28,     3] loss: 0.963
[29,     3] loss: 0.973
[30,     3] loss: 0.988
[31,     3] loss: 0.942
[32,     3] loss: 1.026
[33,     3] loss: 0.944
[34,     3] loss: 0.983
[35,     3] loss: 0.956
[36,     3] loss: 1.003
[37,     3] loss: 1.035
[38,     3] loss: 0.977
[39,     3] loss: 0.950
[40,     3] loss: 0.923
[41,     3] loss: 0.931
[42,     3] loss: 0.848
[43,     3] loss: 0.850
[44,     3] loss: 0.863
[45,     3] loss: 0.857
[46,     3] loss: 0.873
[47,     3] loss: 0.865
[48,     3] loss: 0.846
[49,     3] loss: 1.019
[50,     3] loss: 0.900
[51,     3] loss: 0.891
[52,     3] loss: 0.890
[53,     3] loss: 0.948
[54,     3] loss: 1.030
[55,     3] loss: 0.896
[56,     3] loss: 1.001
[57,     3] loss: 0.902
[58,     3] loss: 0.852
[59,     3] loss: 0.862
[60,     3] loss: 0.843
[61,     3] loss: 0.834
[62,     3] loss: 0.805
[63,     3] loss: 0.839
[64,     3] loss: 0.844
[65,     3] loss: 0.798
[66,     3] loss: 0.811
[67,     3] loss: 0.794
[68,     3] loss: 0.861
[69,     3] loss: 0.808
[70,     3] loss: 0.799
[71,     3] loss: 0.819
[72,     3] loss: 0.810
[73,     3] loss: 0.847
[74,     3] loss: 0.834
[75,     3] loss: 0.834
[76,     3] loss: 0.790
[77,     3] loss: 0.830
[78,     3] loss: 0.788
[79,     3] loss: 0.811
[80,     3] loss: 0.841
[81,     3] loss: 0.819
Early stopping applied (best metric=0.5182452201843262)
Finished Training
Total time taken: 18.014235973358154
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.386
[3,     3] loss: 1.375
[4,     3] loss: 1.386
[5,     3] loss: 1.382
[6,     3] loss: 1.384
[7,     3] loss: 1.369
[8,     3] loss: 1.350
[9,     3] loss: 1.351
[10,     3] loss: 1.344
[11,     3] loss: 1.276
[12,     3] loss: 1.269
[13,     3] loss: 1.265
[14,     3] loss: 1.180
[15,     3] loss: 1.189
[16,     3] loss: 1.163
[17,     3] loss: 1.187
[18,     3] loss: 1.140
[19,     3] loss: 1.138
[20,     3] loss: 1.034
[21,     3] loss: 1.140
[22,     3] loss: 1.047
[23,     3] loss: 0.988
[24,     3] loss: 0.978
[25,     3] loss: 1.094
[26,     3] loss: 0.960
[27,     3] loss: 0.958
[28,     3] loss: 0.970
[29,     3] loss: 0.937
[30,     3] loss: 0.950
[31,     3] loss: 0.896
[32,     3] loss: 0.953
[33,     3] loss: 1.187
[34,     3] loss: 1.091
[35,     3] loss: 0.985
[36,     3] loss: 1.020
[37,     3] loss: 1.006
[38,     3] loss: 0.969
[39,     3] loss: 1.022
[40,     3] loss: 0.947
[41,     3] loss: 0.867
[42,     3] loss: 0.843
[43,     3] loss: 0.863
[44,     3] loss: 0.925
[45,     3] loss: 0.868
[46,     3] loss: 0.848
[47,     3] loss: 0.945
[48,     3] loss: 0.887
[49,     3] loss: 0.891
[50,     3] loss: 0.858
[51,     3] loss: 0.848
[52,     3] loss: 0.848
[53,     3] loss: 0.850
[54,     3] loss: 0.859
[55,     3] loss: 0.839
[56,     3] loss: 0.797
[57,     3] loss: 0.830
[58,     3] loss: 0.934
[59,     3] loss: 0.820
[60,     3] loss: 0.836
[61,     3] loss: 0.916
[62,     3] loss: 0.840
[63,     3] loss: 0.895
[64,     3] loss: 0.835
[65,     3] loss: 0.840
[66,     3] loss: 0.964
[67,     3] loss: 0.865
[68,     3] loss: 0.884
[69,     3] loss: 0.879
[70,     3] loss: 0.827
[71,     3] loss: 0.848
[72,     3] loss: 0.826
[73,     3] loss: 0.790
Early stopping applied (best metric=0.5300800204277039)
Finished Training
Total time taken: 16.28904366493225
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.388
[3,     3] loss: 1.385
[4,     3] loss: 1.376
[5,     3] loss: 1.384
[6,     3] loss: 1.372
[7,     3] loss: 1.369
[8,     3] loss: 1.363
[9,     3] loss: 1.351
[10,     3] loss: 1.317
[11,     3] loss: 1.320
[12,     3] loss: 1.246
[13,     3] loss: 1.264
[14,     3] loss: 1.162
[15,     3] loss: 1.185
[16,     3] loss: 1.123
[17,     3] loss: 1.139
[18,     3] loss: 1.092
[19,     3] loss: 1.011
[20,     3] loss: 1.037
[21,     3] loss: 0.930
[22,     3] loss: 0.947
[23,     3] loss: 0.908
[24,     3] loss: 0.931
[25,     3] loss: 1.243
[26,     3] loss: 1.213
[27,     3] loss: 1.010
[28,     3] loss: 1.023
[29,     3] loss: 1.045
[30,     3] loss: 1.015
[31,     3] loss: 1.029
[32,     3] loss: 1.010
[33,     3] loss: 1.011
[34,     3] loss: 0.908
[35,     3] loss: 0.899
[36,     3] loss: 0.914
[37,     3] loss: 0.855
[38,     3] loss: 0.902
[39,     3] loss: 0.872
[40,     3] loss: 0.850
[41,     3] loss: 0.852
[42,     3] loss: 0.845
[43,     3] loss: 0.882
[44,     3] loss: 0.893
[45,     3] loss: 0.889
[46,     3] loss: 0.954
[47,     3] loss: 0.867
[48,     3] loss: 0.895
[49,     3] loss: 0.892
[50,     3] loss: 0.844
[51,     3] loss: 0.852
[52,     3] loss: 0.864
[53,     3] loss: 0.887
[54,     3] loss: 0.886
[55,     3] loss: 0.924
[56,     3] loss: 0.929
[57,     3] loss: 0.866
[58,     3] loss: 0.899
[59,     3] loss: 0.846
[60,     3] loss: 0.839
[61,     3] loss: 0.841
[62,     3] loss: 0.818
[63,     3] loss: 0.806
[64,     3] loss: 0.786
[65,     3] loss: 0.805
[66,     3] loss: 0.774
Early stopping applied (best metric=0.5304241180419922)
Finished Training
Total time taken: 14.817395448684692
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.391
[3,     3] loss: 1.385
[4,     3] loss: 1.389
[5,     3] loss: 1.382
[6,     3] loss: 1.384
[7,     3] loss: 1.382
[8,     3] loss: 1.375
[9,     3] loss: 1.374
[10,     3] loss: 1.367
[11,     3] loss: 1.356
[12,     3] loss: 1.341
[13,     3] loss: 1.330
[14,     3] loss: 1.269
[15,     3] loss: 1.244
[16,     3] loss: 1.250
[17,     3] loss: 1.178
[18,     3] loss: 1.199
[19,     3] loss: 1.147
[20,     3] loss: 1.208
[21,     3] loss: 1.143
[22,     3] loss: 1.157
[23,     3] loss: 1.079
[24,     3] loss: 1.113
[25,     3] loss: 1.096
[26,     3] loss: 1.099
[27,     3] loss: 0.969
[28,     3] loss: 1.079
[29,     3] loss: 1.079
[30,     3] loss: 0.947
[31,     3] loss: 0.984
[32,     3] loss: 0.908
[33,     3] loss: 0.927
[34,     3] loss: 0.931
[35,     3] loss: 0.852
[36,     3] loss: 0.842
[37,     3] loss: 0.878
[38,     3] loss: 0.897
[39,     3] loss: 0.892
[40,     3] loss: 0.995
[41,     3] loss: 1.063
[42,     3] loss: 0.943
[43,     3] loss: 0.936
[44,     3] loss: 0.850
[45,     3] loss: 0.857
[46,     3] loss: 0.815
[47,     3] loss: 0.891
[48,     3] loss: 0.884
[49,     3] loss: 0.885
[50,     3] loss: 0.834
[51,     3] loss: 0.810
[52,     3] loss: 0.827
[53,     3] loss: 0.824
[54,     3] loss: 0.861
[55,     3] loss: 0.797
[56,     3] loss: 0.794
[57,     3] loss: 0.877
[58,     3] loss: 0.888
[59,     3] loss: 0.889
[60,     3] loss: 0.817
[61,     3] loss: 0.855
[62,     3] loss: 0.784
[63,     3] loss: 0.824
[64,     3] loss: 0.812
[65,     3] loss: 0.791
[66,     3] loss: 0.793
[67,     3] loss: 0.819
Early stopping applied (best metric=0.5344685316085815)
Finished Training
Total time taken: 14.937039613723755
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.383
[3,     3] loss: 1.395
[4,     3] loss: 1.387
[5,     3] loss: 1.381
[6,     3] loss: 1.372
[7,     3] loss: 1.378
[8,     3] loss: 1.364
[9,     3] loss: 1.368
[10,     3] loss: 1.353
[11,     3] loss: 1.325
[12,     3] loss: 1.282
[13,     3] loss: 1.263
[14,     3] loss: 1.210
[15,     3] loss: 1.222
[16,     3] loss: 1.129
[17,     3] loss: 1.108
[18,     3] loss: 1.160
[19,     3] loss: 1.079
[20,     3] loss: 1.146
[21,     3] loss: 1.132
[22,     3] loss: 1.055
[23,     3] loss: 1.019
[24,     3] loss: 0.984
[25,     3] loss: 1.056
[26,     3] loss: 1.088
[27,     3] loss: 0.969
[28,     3] loss: 0.988
[29,     3] loss: 0.985
[30,     3] loss: 0.956
[31,     3] loss: 1.041
[32,     3] loss: 0.945
[33,     3] loss: 0.962
[34,     3] loss: 0.979
[35,     3] loss: 1.035
[36,     3] loss: 0.921
[37,     3] loss: 0.916
[38,     3] loss: 0.998
[39,     3] loss: 1.033
[40,     3] loss: 0.921
[41,     3] loss: 1.014
[42,     3] loss: 0.919
[43,     3] loss: 0.986
[44,     3] loss: 0.909
[45,     3] loss: 0.890
[46,     3] loss: 0.953
[47,     3] loss: 0.852
[48,     3] loss: 0.913
[49,     3] loss: 0.856
[50,     3] loss: 0.899
[51,     3] loss: 0.919
[52,     3] loss: 1.006
[53,     3] loss: 0.844
[54,     3] loss: 0.905
[55,     3] loss: 0.903
[56,     3] loss: 0.876
[57,     3] loss: 0.856
[58,     3] loss: 0.913
[59,     3] loss: 0.879
[60,     3] loss: 0.902
[61,     3] loss: 0.868
[62,     3] loss: 0.841
[63,     3] loss: 0.828
[64,     3] loss: 0.846
[65,     3] loss: 0.970
[66,     3] loss: 1.019
[67,     3] loss: 0.926
[68,     3] loss: 0.884
[69,     3] loss: 0.887
[70,     3] loss: 0.829
[71,     3] loss: 0.890
[72,     3] loss: 0.824
[73,     3] loss: 0.795
[74,     3] loss: 0.807
[75,     3] loss: 0.809
[76,     3] loss: 0.779
[77,     3] loss: 0.841
[78,     3] loss: 0.863
[79,     3] loss: 0.832
[80,     3] loss: 0.798
[81,     3] loss: 0.772
[82,     3] loss: 0.851
[83,     3] loss: 0.820
[84,     3] loss: 0.840
[85,     3] loss: 0.813
[86,     3] loss: 0.858
[87,     3] loss: 0.980
[88,     3] loss: 0.901
Early stopping applied (best metric=0.507431149482727)
Finished Training
Total time taken: 19.67804980278015
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.397
[2,     3] loss: 1.387
[3,     3] loss: 1.382
[4,     3] loss: 1.378
[5,     3] loss: 1.383
[6,     3] loss: 1.382
[7,     3] loss: 1.380
[8,     3] loss: 1.376
[9,     3] loss: 1.379
[10,     3] loss: 1.375
[11,     3] loss: 1.363
[12,     3] loss: 1.349
[13,     3] loss: 1.343
[14,     3] loss: 1.309
[15,     3] loss: 1.298
[16,     3] loss: 1.231
[17,     3] loss: 1.192
[18,     3] loss: 1.157
[19,     3] loss: 1.204
[20,     3] loss: 1.065
[21,     3] loss: 1.149
[22,     3] loss: 1.021
[23,     3] loss: 1.196
[24,     3] loss: 1.056
[25,     3] loss: 1.153
[26,     3] loss: 1.110
[27,     3] loss: 1.057
[28,     3] loss: 1.067
[29,     3] loss: 1.120
[30,     3] loss: 1.001
[31,     3] loss: 0.967
[32,     3] loss: 1.089
[33,     3] loss: 0.944
[34,     3] loss: 0.993
[35,     3] loss: 0.938
[36,     3] loss: 0.951
[37,     3] loss: 1.063
[38,     3] loss: 0.950
[39,     3] loss: 1.041
[40,     3] loss: 0.861
[41,     3] loss: 0.981
[42,     3] loss: 0.945
[43,     3] loss: 0.972
[44,     3] loss: 1.047
[45,     3] loss: 1.008
[46,     3] loss: 1.025
[47,     3] loss: 1.054
[48,     3] loss: 1.032
[49,     3] loss: 0.951
[50,     3] loss: 0.931
[51,     3] loss: 1.014
[52,     3] loss: 0.950
[53,     3] loss: 0.949
[54,     3] loss: 0.991
[55,     3] loss: 0.889
[56,     3] loss: 0.873
[57,     3] loss: 0.896
[58,     3] loss: 0.903
[59,     3] loss: 0.858
[60,     3] loss: 0.842
[61,     3] loss: 0.818
[62,     3] loss: 0.845
[63,     3] loss: 0.813
[64,     3] loss: 0.792
[65,     3] loss: 0.814
[66,     3] loss: 0.846
[67,     3] loss: 0.850
Early stopping applied (best metric=0.48944926261901855)
Finished Training
Total time taken: 15.001040935516357
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.382
[3,     3] loss: 1.387
[4,     3] loss: 1.390
[5,     3] loss: 1.391
[6,     3] loss: 1.386
[7,     3] loss: 1.384
[8,     3] loss: 1.388
[9,     3] loss: 1.383
[10,     3] loss: 1.380
[11,     3] loss: 1.375
[12,     3] loss: 1.379
[13,     3] loss: 1.363
[14,     3] loss: 1.357
[15,     3] loss: 1.350
[16,     3] loss: 1.307
[17,     3] loss: 1.271
[18,     3] loss: 1.234
[19,     3] loss: 1.186
[20,     3] loss: 1.208
[21,     3] loss: 1.125
[22,     3] loss: 1.224
[23,     3] loss: 1.147
[24,     3] loss: 1.171
[25,     3] loss: 1.117
[26,     3] loss: 1.096
[27,     3] loss: 1.066
[28,     3] loss: 1.092
[29,     3] loss: 1.087
[30,     3] loss: 1.057
[31,     3] loss: 1.031
[32,     3] loss: 0.948
[33,     3] loss: 0.992
[34,     3] loss: 0.974
[35,     3] loss: 0.998
[36,     3] loss: 0.934
[37,     3] loss: 1.023
[38,     3] loss: 0.964
[39,     3] loss: 0.954
[40,     3] loss: 0.985
[41,     3] loss: 0.905
[42,     3] loss: 0.866
[43,     3] loss: 0.917
[44,     3] loss: 0.939
[45,     3] loss: 0.918
[46,     3] loss: 0.981
[47,     3] loss: 1.033
[48,     3] loss: 0.891
[49,     3] loss: 0.902
[50,     3] loss: 0.950
[51,     3] loss: 0.888
[52,     3] loss: 0.920
[53,     3] loss: 0.846
[54,     3] loss: 0.832
[55,     3] loss: 0.800
[56,     3] loss: 0.847
[57,     3] loss: 0.887
[58,     3] loss: 0.911
[59,     3] loss: 0.866
[60,     3] loss: 0.861
[61,     3] loss: 0.905
[62,     3] loss: 0.830
[63,     3] loss: 0.854
[64,     3] loss: 0.829
[65,     3] loss: 0.875
[66,     3] loss: 1.018
[67,     3] loss: 1.120
[68,     3] loss: 0.924
[69,     3] loss: 0.929
Early stopping applied (best metric=0.5208002328872681)
Finished Training
Total time taken: 15.415038824081421
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.381
[4,     3] loss: 1.388
[5,     3] loss: 1.380
[6,     3] loss: 1.382
[7,     3] loss: 1.363
[8,     3] loss: 1.372
[9,     3] loss: 1.355
[10,     3] loss: 1.335
[11,     3] loss: 1.323
[12,     3] loss: 1.268
[13,     3] loss: 1.238
[14,     3] loss: 1.282
[15,     3] loss: 1.240
[16,     3] loss: 1.198
[17,     3] loss: 1.129
[18,     3] loss: 1.170
[19,     3] loss: 1.232
[20,     3] loss: 1.068
[21,     3] loss: 1.094
[22,     3] loss: 1.085
[23,     3] loss: 1.140
[24,     3] loss: 1.014
[25,     3] loss: 1.014
[26,     3] loss: 0.948
[27,     3] loss: 1.017
[28,     3] loss: 1.054
[29,     3] loss: 0.924
[30,     3] loss: 1.051
[31,     3] loss: 1.038
[32,     3] loss: 0.945
[33,     3] loss: 0.928
[34,     3] loss: 0.974
[35,     3] loss: 1.027
[36,     3] loss: 0.903
[37,     3] loss: 0.948
[38,     3] loss: 0.991
[39,     3] loss: 0.966
[40,     3] loss: 0.897
[41,     3] loss: 0.868
[42,     3] loss: 0.930
[43,     3] loss: 0.909
[44,     3] loss: 0.854
[45,     3] loss: 0.992
[46,     3] loss: 0.851
[47,     3] loss: 0.858
[48,     3] loss: 0.895
[49,     3] loss: 0.851
[50,     3] loss: 0.822
[51,     3] loss: 0.815
[52,     3] loss: 0.806
[53,     3] loss: 0.821
[54,     3] loss: 0.856
[55,     3] loss: 0.911
[56,     3] loss: 0.854
[57,     3] loss: 0.889
[58,     3] loss: 0.839
[59,     3] loss: 0.896
[60,     3] loss: 0.847
[61,     3] loss: 0.820
[62,     3] loss: 0.846
[63,     3] loss: 0.815
[64,     3] loss: 0.818
[65,     3] loss: 0.767
[66,     3] loss: 0.797
[67,     3] loss: 0.827
[68,     3] loss: 0.846
[69,     3] loss: 0.793
Early stopping applied (best metric=0.5498465895652771)
Finished Training
Total time taken: 15.381648778915405
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.379
[3,     3] loss: 1.387
[4,     3] loss: 1.380
[5,     3] loss: 1.378
[6,     3] loss: 1.376
[7,     3] loss: 1.380
[8,     3] loss: 1.373
[9,     3] loss: 1.376
[10,     3] loss: 1.362
[11,     3] loss: 1.339
[12,     3] loss: 1.326
[13,     3] loss: 1.310
[14,     3] loss: 1.279
[15,     3] loss: 1.205
[16,     3] loss: 1.206
[17,     3] loss: 1.154
[18,     3] loss: 1.102
[19,     3] loss: 1.122
[20,     3] loss: 1.093
[21,     3] loss: 1.120
[22,     3] loss: 1.119
[23,     3] loss: 1.001
[24,     3] loss: 0.976
[25,     3] loss: 1.047
[26,     3] loss: 1.022
[27,     3] loss: 1.188
[28,     3] loss: 1.037
[29,     3] loss: 1.188
[30,     3] loss: 0.974
[31,     3] loss: 1.143
[32,     3] loss: 0.985
[33,     3] loss: 1.042
[34,     3] loss: 1.084
[35,     3] loss: 0.973
[36,     3] loss: 0.950
[37,     3] loss: 0.890
[38,     3] loss: 0.913
[39,     3] loss: 0.959
[40,     3] loss: 0.899
[41,     3] loss: 0.901
[42,     3] loss: 0.965
[43,     3] loss: 0.900
[44,     3] loss: 0.846
[45,     3] loss: 0.921
[46,     3] loss: 0.880
[47,     3] loss: 0.869
[48,     3] loss: 0.853
[49,     3] loss: 0.836
[50,     3] loss: 0.896
[51,     3] loss: 0.839
[52,     3] loss: 0.824
[53,     3] loss: 0.893
[54,     3] loss: 0.853
[55,     3] loss: 0.879
[56,     3] loss: 0.842
[57,     3] loss: 0.861
[58,     3] loss: 0.893
[59,     3] loss: 0.996
[60,     3] loss: 0.860
[61,     3] loss: 0.871
[62,     3] loss: 0.858
[63,     3] loss: 0.868
[64,     3] loss: 0.887
[65,     3] loss: 0.822
[66,     3] loss: 0.834
[67,     3] loss: 0.859
[68,     3] loss: 0.848
[69,     3] loss: 0.881
[70,     3] loss: 0.826
[71,     3] loss: 0.846
[72,     3] loss: 0.855
[73,     3] loss: 0.784
[74,     3] loss: 0.812
[75,     3] loss: 0.834
[76,     3] loss: 0.901
Early stopping applied (best metric=0.532200813293457)
Finished Training
Total time taken: 16.893041849136353
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.397
[3,     3] loss: 1.388
[4,     3] loss: 1.381
[5,     3] loss: 1.385
[6,     3] loss: 1.383
[7,     3] loss: 1.383
[8,     3] loss: 1.390
[9,     3] loss: 1.385
[10,     3] loss: 1.374
[11,     3] loss: 1.390
[12,     3] loss: 1.372
[13,     3] loss: 1.376
[14,     3] loss: 1.370
[15,     3] loss: 1.371
[16,     3] loss: 1.335
[17,     3] loss: 1.338
[18,     3] loss: 1.292
[19,     3] loss: 1.282
[20,     3] loss: 1.229
[21,     3] loss: 1.210
[22,     3] loss: 1.201
[23,     3] loss: 1.141
[24,     3] loss: 1.164
[25,     3] loss: 1.090
[26,     3] loss: 1.087
[27,     3] loss: 1.116
[28,     3] loss: 1.064
[29,     3] loss: 1.053
[30,     3] loss: 0.998
[31,     3] loss: 1.008
[32,     3] loss: 0.952
[33,     3] loss: 0.948
[34,     3] loss: 0.968
[35,     3] loss: 0.971
[36,     3] loss: 1.011
[37,     3] loss: 1.103
[38,     3] loss: 1.049
[39,     3] loss: 0.953
[40,     3] loss: 1.025
[41,     3] loss: 1.033
[42,     3] loss: 0.998
[43,     3] loss: 0.963
[44,     3] loss: 0.987
[45,     3] loss: 0.928
[46,     3] loss: 0.965
[47,     3] loss: 1.091
[48,     3] loss: 0.968
[49,     3] loss: 0.955
[50,     3] loss: 0.917
[51,     3] loss: 0.966
[52,     3] loss: 0.867
[53,     3] loss: 0.932
[54,     3] loss: 0.945
[55,     3] loss: 0.903
[56,     3] loss: 1.013
[57,     3] loss: 0.896
[58,     3] loss: 1.065
[59,     3] loss: 0.978
[60,     3] loss: 1.044
[61,     3] loss: 1.044
[62,     3] loss: 0.963
[63,     3] loss: 0.967
[64,     3] loss: 0.999
[65,     3] loss: 0.903
[66,     3] loss: 0.892
[67,     3] loss: 0.877
[68,     3] loss: 0.844
[69,     3] loss: 0.861
[70,     3] loss: 0.808
Early stopping applied (best metric=0.4984463155269623)
Finished Training
Total time taken: 15.641038656234741
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.387
[3,     3] loss: 1.384
[4,     3] loss: 1.386
[5,     3] loss: 1.386
[6,     3] loss: 1.394
[7,     3] loss: 1.384
[8,     3] loss: 1.383
[9,     3] loss: 1.381
[10,     3] loss: 1.379
[11,     3] loss: 1.389
[12,     3] loss: 1.381
[13,     3] loss: 1.381
[14,     3] loss: 1.371
[15,     3] loss: 1.359
[16,     3] loss: 1.343
[17,     3] loss: 1.315
[18,     3] loss: 1.276
[19,     3] loss: 1.227
[20,     3] loss: 1.230
[21,     3] loss: 1.255
[22,     3] loss: 1.198
[23,     3] loss: 1.115
[24,     3] loss: 1.149
[25,     3] loss: 1.022
[26,     3] loss: 1.042
[27,     3] loss: 1.108
[28,     3] loss: 1.040
[29,     3] loss: 1.046
[30,     3] loss: 0.971
[31,     3] loss: 0.976
[32,     3] loss: 1.049
[33,     3] loss: 0.992
[34,     3] loss: 1.008
[35,     3] loss: 1.082
[36,     3] loss: 0.958
[37,     3] loss: 0.896
[38,     3] loss: 0.957
[39,     3] loss: 0.969
[40,     3] loss: 0.887
[41,     3] loss: 0.923
[42,     3] loss: 0.982
[43,     3] loss: 0.971
[44,     3] loss: 0.995
[45,     3] loss: 0.923
[46,     3] loss: 0.905
[47,     3] loss: 0.877
[48,     3] loss: 0.841
[49,     3] loss: 0.912
[50,     3] loss: 0.849
[51,     3] loss: 0.857
[52,     3] loss: 0.865
[53,     3] loss: 0.811
[54,     3] loss: 0.804
[55,     3] loss: 0.821
[56,     3] loss: 0.815
[57,     3] loss: 0.844
[58,     3] loss: 0.857
[59,     3] loss: 0.897
[60,     3] loss: 0.785
[61,     3] loss: 0.796
[62,     3] loss: 0.821
[63,     3] loss: 0.812
[64,     3] loss: 0.852
[65,     3] loss: 0.885
[66,     3] loss: 0.913
[67,     3] loss: 0.898
[68,     3] loss: 0.864
[69,     3] loss: 0.833
[70,     3] loss: 0.932
[71,     3] loss: 0.979
[72,     3] loss: 0.983
[73,     3] loss: 0.853
[74,     3] loss: 1.014
[75,     3] loss: 0.834
[76,     3] loss: 0.909
Early stopping applied (best metric=0.530207097530365)
Finished Training
Total time taken: 17.097043752670288
{'S-palmitoylation-C Validation Accuracy': 0.7142910809068014, 'S-palmitoylation-C Validation Sensitivity': 0.19405940594059407, 'S-palmitoylation-C Validation Specificity': 0.8446959455852047, 'S-palmitoylation-C Validation Precision': 0.24290851562559462, 'S-palmitoylation-C AUC ROC': 0.5515010140507818, 'S-palmitoylation-C AUC PR': 0.23115545124302306, 'S-palmitoylation-C MCC': 0.04304185895479659, 'S-palmitoylation-C F1': 0.19741219215264225, 'Validation Loss (S-palmitoylation-C)': 0.5540158549944559, 'Hydroxylation-K Validation Accuracy': 0.7296099290780141, 'Hydroxylation-K Validation Sensitivity': 0.7644444444444445, 'Hydroxylation-K Validation Specificity': 0.7210526315789474, 'Hydroxylation-K Validation Precision': 0.4289189514189514, 'Hydroxylation-K AUC ROC': 0.8285964912280702, 'Hydroxylation-K AUC PR': 0.6022599298001168, 'Hydroxylation-K MCC': 0.4139349718722037, 'Hydroxylation-K F1': 0.5379931583668726, 'Validation Loss (Hydroxylation-K)': 0.5209987064202627, 'Validation Loss (total)': 1.075014559427897, 'TimeToTrain': 16.45920112927755}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008842193340384736,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6247982377739983,
 'loss_weight_S-palmitoylation-C': 0.1028932593454428,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1799686187,
 'sample_weights': [0.4785576771858115, 0.5192334389873131],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.334055662883119,
 'weight_decay_Hydroxylation-K': 4.422390339049429,
 'weight_decay_S-palmitoylation-C': 9.604833675058796}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.392
[3,     3] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0049065334367118995,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6729137538936132,
 'loss_weight_S-palmitoylation-C': 0.1499259121625377,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 394290114,
 'sample_weights': [0.1028932593454428, 0.6247982377739983],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.040231184840449,
 'weight_decay_Hydroxylation-K': 0.9690514466515426,
 'weight_decay_S-palmitoylation-C': 4.64338386525607}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.397
[3,     3] loss: 1.394
[4,     3] loss: 1.386
[5,     3] loss: 1.385
[6,     3] loss: 1.388
[7,     3] loss: 1.388
[8,     3] loss: 1.377
[9,     3] loss: 1.377
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005507323269875986,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.03231381660069321,
 'loss_weight_S-palmitoylation-C': 0.6559272482631175,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2987875674,
 'sample_weights': [0.1499259121625377, 0.6729137538936132],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.1092000587848614,
 'weight_decay_Hydroxylation-K': 7.757967939100081,
 'weight_decay_S-palmitoylation-C': 3.3351695336721887}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.397
[3,     3] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011261303147913912,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4866693209599316,
 'loss_weight_S-palmitoylation-C': 0.029861341200508137,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 610175346,
 'sample_weights': [0.6559272482631175, 0.03231381660069321],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.37656598207833,
 'weight_decay_Hydroxylation-K': 2.1441302501017407,
 'weight_decay_S-palmitoylation-C': 9.449550344580793}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.384
[3,     3] loss: 1.392
[4,     3] loss: 1.382
[5,     3] loss: 1.392
[6,     3] loss: 1.375
[7,     3] loss: 1.375
[8,     3] loss: 1.378
[9,     3] loss: 1.369
[10,     3] loss: 1.327
[11,     3] loss: 1.303
[12,     3] loss: 1.335
[13,     3] loss: 1.288
[14,     3] loss: 1.218
[15,     3] loss: 1.294
[16,     3] loss: 1.176
[17,     3] loss: 1.237
[18,     3] loss: 1.090
[19,     3] loss: 1.094
[20,     3] loss: 1.204
[21,     3] loss: 1.055
[22,     3] loss: 1.167
[23,     3] loss: 1.047
[24,     3] loss: 0.988
[25,     3] loss: 1.066
[26,     3] loss: 0.981
[27,     3] loss: 0.916
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015788333427751624,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.08926586173375907,
 'loss_weight_S-palmitoylation-C': 0.5564156557442576,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 597139160,
 'sample_weights': [0.029861341200508137, 0.4866693209599316],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.652151081990847,
 'weight_decay_Hydroxylation-K': 4.711891395398871,
 'weight_decay_S-palmitoylation-C': 0.40490115558802353}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.390
[3,     3] loss: 1.384
[4,     3] loss: 1.384
[5,     3] loss: 1.382
[6,     3] loss: 1.374
[7,     3] loss: 1.371
[8,     3] loss: 1.358
[9,     3] loss: 1.359
[10,     3] loss: 1.329
[11,     3] loss: 1.315
[12,     3] loss: 1.254
[13,     3] loss: 1.243
[14,     3] loss: 1.245
[15,     3] loss: 1.193
[16,     3] loss: 1.187
[17,     3] loss: 1.133
[18,     3] loss: 1.095
[19,     3] loss: 1.153
[20,     3] loss: 1.086
[21,     3] loss: 1.137
[22,     3] loss: 1.005
[23,     3] loss: 1.023
[24,     3] loss: 1.057
[25,     3] loss: 0.976
[26,     3] loss: 0.928
[27,     3] loss: 0.937
[28,     3] loss: 0.922
[29,     3] loss: 1.059
[30,     3] loss: 0.955
[31,     3] loss: 0.870
[32,     3] loss: 1.034
[33,     3] loss: 1.051
[34,     3] loss: 1.104
[35,     3] loss: 1.103
[36,     3] loss: 0.954
[37,     3] loss: 0.943
[38,     3] loss: 0.936
[39,     3] loss: 0.954
[40,     3] loss: 0.872
[41,     3] loss: 0.904
[42,     3] loss: 0.858
[43,     3] loss: 0.863
[44,     3] loss: 0.825
[45,     3] loss: 0.836
[46,     3] loss: 0.849
[47,     3] loss: 1.007
[48,     3] loss: 0.848
[49,     3] loss: 1.004
[50,     3] loss: 0.830
[51,     3] loss: 0.831
[52,     3] loss: 0.844
[53,     3] loss: 0.846
[54,     3] loss: 0.771
[55,     3] loss: 0.802
[56,     3] loss: 0.880
[57,     3] loss: 0.786
[58,     3] loss: 0.809
[59,     3] loss: 0.806
[60,     3] loss: 0.822
[61,     3] loss: 0.910
[62,     3] loss: 0.891
[63,     3] loss: 0.895
[64,     3] loss: 0.821
[65,     3] loss: 0.885
[66,     3] loss: 0.876
[67,     3] loss: 0.869
[68,     3] loss: 0.829
[69,     3] loss: 0.847
Early stopping applied (best metric=0.5200697183609009)
Finished Training
Total time taken: 15.485440969467163
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.386
[3,     3] loss: 1.383
[4,     3] loss: 1.377
[5,     3] loss: 1.396
[6,     3] loss: 1.386
[7,     3] loss: 1.384
[8,     3] loss: 1.392
[9,     3] loss: 1.392
[10,     3] loss: 1.386
[11,     3] loss: 1.383
[12,     3] loss: 1.386
[13,     3] loss: 1.388
[14,     3] loss: 1.383
[15,     3] loss: 1.382
[16,     3] loss: 1.376
[17,     3] loss: 1.367
[18,     3] loss: 1.336
[19,     3] loss: 1.329
[20,     3] loss: 1.323
[21,     3] loss: 1.294
[22,     3] loss: 1.256
[23,     3] loss: 1.195
[24,     3] loss: 1.174
[25,     3] loss: 1.154
[26,     3] loss: 1.133
[27,     3] loss: 1.118
[28,     3] loss: 1.133
[29,     3] loss: 1.031
[30,     3] loss: 1.015
[31,     3] loss: 0.995
[32,     3] loss: 0.955
[33,     3] loss: 0.947
[34,     3] loss: 1.049
[35,     3] loss: 1.020
[36,     3] loss: 1.097
[37,     3] loss: 0.950
[38,     3] loss: 0.899
[39,     3] loss: 0.972
[40,     3] loss: 0.925
[41,     3] loss: 0.934
[42,     3] loss: 0.933
[43,     3] loss: 0.919
[44,     3] loss: 0.951
[45,     3] loss: 0.864
[46,     3] loss: 0.880
[47,     3] loss: 0.916
[48,     3] loss: 0.880
[49,     3] loss: 0.910
[50,     3] loss: 0.956
[51,     3] loss: 0.884
[52,     3] loss: 0.916
[53,     3] loss: 0.879
[54,     3] loss: 0.887
[55,     3] loss: 0.925
[56,     3] loss: 0.932
[57,     3] loss: 0.879
[58,     3] loss: 0.816
[59,     3] loss: 0.884
[60,     3] loss: 0.813
[61,     3] loss: 0.867
[62,     3] loss: 0.893
[63,     3] loss: 0.770
[64,     3] loss: 0.766
[65,     3] loss: 0.802
[66,     3] loss: 0.772
[67,     3] loss: 0.798
[68,     3] loss: 0.774
[69,     3] loss: 0.767
[70,     3] loss: 0.803
Early stopping applied (best metric=0.5213456153869629)
Finished Training
Total time taken: 15.531054735183716
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.366
[3,     3] loss: 1.404
[4,     3] loss: 1.395
[5,     3] loss: 1.399
[6,     3] loss: 1.385
[7,     3] loss: 1.387
[8,     3] loss: 1.386
[9,     3] loss: 1.381
[10,     3] loss: 1.377
[11,     3] loss: 1.373
[12,     3] loss: 1.364
[13,     3] loss: 1.352
[14,     3] loss: 1.340
[15,     3] loss: 1.308
[16,     3] loss: 1.328
[17,     3] loss: 1.263
[18,     3] loss: 1.248
[19,     3] loss: 1.220
[20,     3] loss: 1.106
[21,     3] loss: 1.074
[22,     3] loss: 1.031
[23,     3] loss: 1.107
[24,     3] loss: 0.985
[25,     3] loss: 1.127
[26,     3] loss: 0.948
[27,     3] loss: 1.150
[28,     3] loss: 1.250
[29,     3] loss: 1.175
[30,     3] loss: 1.026
[31,     3] loss: 1.058
[32,     3] loss: 1.052
[33,     3] loss: 0.957
[34,     3] loss: 0.975
[35,     3] loss: 1.051
[36,     3] loss: 0.896
[37,     3] loss: 0.872
[38,     3] loss: 0.909
[39,     3] loss: 0.833
[40,     3] loss: 0.932
[41,     3] loss: 0.888
[42,     3] loss: 0.928
[43,     3] loss: 1.024
[44,     3] loss: 0.910
[45,     3] loss: 0.994
[46,     3] loss: 0.978
[47,     3] loss: 0.945
[48,     3] loss: 0.944
[49,     3] loss: 0.892
[50,     3] loss: 0.819
[51,     3] loss: 0.883
[52,     3] loss: 0.878
[53,     3] loss: 0.897
[54,     3] loss: 0.903
[55,     3] loss: 0.873
[56,     3] loss: 0.835
[57,     3] loss: 0.837
[58,     3] loss: 0.791
[59,     3] loss: 0.849
[60,     3] loss: 0.926
[61,     3] loss: 0.830
[62,     3] loss: 0.790
[63,     3] loss: 0.950
[64,     3] loss: 0.861
[65,     3] loss: 0.845
[66,     3] loss: 0.801
[67,     3] loss: 0.794
[68,     3] loss: 0.767
[69,     3] loss: 0.746
[70,     3] loss: 0.763
Early stopping applied (best metric=0.5141955614089966)
Finished Training
Total time taken: 15.653355360031128
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.386
[3,     3] loss: 1.388
[4,     3] loss: 1.389
[5,     3] loss: 1.385
[6,     3] loss: 1.380
[7,     3] loss: 1.379
[8,     3] loss: 1.375
[9,     3] loss: 1.358
[10,     3] loss: 1.361
[11,     3] loss: 1.345
[12,     3] loss: 1.315
[13,     3] loss: 1.325
[14,     3] loss: 1.318
[15,     3] loss: 1.261
[16,     3] loss: 1.250
[17,     3] loss: 1.194
[18,     3] loss: 1.200
[19,     3] loss: 1.119
[20,     3] loss: 1.025
[21,     3] loss: 1.032
[22,     3] loss: 1.135
[23,     3] loss: 1.079
[24,     3] loss: 1.077
[25,     3] loss: 1.095
[26,     3] loss: 1.044
[27,     3] loss: 1.057
[28,     3] loss: 1.044
[29,     3] loss: 1.084
[30,     3] loss: 1.133
[31,     3] loss: 1.116
[32,     3] loss: 1.043
[33,     3] loss: 1.028
[34,     3] loss: 1.034
[35,     3] loss: 1.023
[36,     3] loss: 0.948
[37,     3] loss: 0.877
[38,     3] loss: 0.915
[39,     3] loss: 0.877
[40,     3] loss: 0.863
[41,     3] loss: 0.982
[42,     3] loss: 0.896
[43,     3] loss: 0.872
[44,     3] loss: 0.932
[45,     3] loss: 0.914
[46,     3] loss: 0.913
[47,     3] loss: 0.847
[48,     3] loss: 0.853
[49,     3] loss: 0.851
[50,     3] loss: 0.850
[51,     3] loss: 0.825
[52,     3] loss: 0.882
[53,     3] loss: 0.877
[54,     3] loss: 0.823
[55,     3] loss: 0.846
[56,     3] loss: 0.882
[57,     3] loss: 0.943
[58,     3] loss: 0.921
[59,     3] loss: 0.811
[60,     3] loss: 0.862
[61,     3] loss: 0.811
[62,     3] loss: 0.884
[63,     3] loss: 0.894
[64,     3] loss: 0.856
[65,     3] loss: 0.778
[66,     3] loss: 0.859
[67,     3] loss: 0.830
[68,     3] loss: 0.812
Early stopping applied (best metric=0.505716860294342)
Finished Training
Total time taken: 15.208038330078125
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.387
[3,     3] loss: 1.384
[4,     3] loss: 1.378
[5,     3] loss: 1.387
[6,     3] loss: 1.382
[7,     3] loss: 1.367
[8,     3] loss: 1.364
[9,     3] loss: 1.354
[10,     3] loss: 1.319
[11,     3] loss: 1.300
[12,     3] loss: 1.327
[13,     3] loss: 1.251
[14,     3] loss: 1.260
[15,     3] loss: 1.239
[16,     3] loss: 1.191
[17,     3] loss: 1.097
[18,     3] loss: 1.081
[19,     3] loss: 1.027
[20,     3] loss: 1.068
[21,     3] loss: 0.992
[22,     3] loss: 0.976
[23,     3] loss: 1.206
[24,     3] loss: 1.051
[25,     3] loss: 1.159
[26,     3] loss: 1.069
[27,     3] loss: 1.002
[28,     3] loss: 1.040
[29,     3] loss: 1.043
[30,     3] loss: 1.150
[31,     3] loss: 0.967
[32,     3] loss: 0.971
[33,     3] loss: 0.961
[34,     3] loss: 0.950
[35,     3] loss: 1.008
[36,     3] loss: 0.929
[37,     3] loss: 0.919
[38,     3] loss: 0.880
[39,     3] loss: 0.934
[40,     3] loss: 0.947
[41,     3] loss: 0.929
[42,     3] loss: 0.934
[43,     3] loss: 0.885
[44,     3] loss: 0.911
[45,     3] loss: 0.937
[46,     3] loss: 0.864
[47,     3] loss: 0.858
[48,     3] loss: 0.835
[49,     3] loss: 0.875
[50,     3] loss: 0.820
[51,     3] loss: 0.793
[52,     3] loss: 0.804
[53,     3] loss: 0.833
[54,     3] loss: 0.851
[55,     3] loss: 0.825
[56,     3] loss: 0.820
[57,     3] loss: 0.769
[58,     3] loss: 0.929
[59,     3] loss: 0.794
[60,     3] loss: 0.777
[61,     3] loss: 0.812
[62,     3] loss: 0.895
[63,     3] loss: 0.837
[64,     3] loss: 0.888
[65,     3] loss: 0.993
[66,     3] loss: 0.889
[67,     3] loss: 0.929
Early stopping applied (best metric=0.5071406364440918)
Finished Training
Total time taken: 14.94403624534607
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.387
[3,     3] loss: 1.387
[4,     3] loss: 1.377
[5,     3] loss: 1.384
[6,     3] loss: 1.386
[7,     3] loss: 1.377
[8,     3] loss: 1.382
[9,     3] loss: 1.359
[10,     3] loss: 1.347
[11,     3] loss: 1.291
[12,     3] loss: 1.274
[13,     3] loss: 1.213
[14,     3] loss: 1.200
[15,     3] loss: 1.122
[16,     3] loss: 1.149
[17,     3] loss: 1.117
[18,     3] loss: 1.077
[19,     3] loss: 1.057
[20,     3] loss: 0.949
[21,     3] loss: 1.109
[22,     3] loss: 1.023
[23,     3] loss: 1.016
[24,     3] loss: 1.099
[25,     3] loss: 0.996
[26,     3] loss: 0.961
[27,     3] loss: 0.925
[28,     3] loss: 0.950
[29,     3] loss: 0.930
[30,     3] loss: 0.867
[31,     3] loss: 0.896
[32,     3] loss: 0.881
[33,     3] loss: 0.851
[34,     3] loss: 0.881
[35,     3] loss: 0.839
[36,     3] loss: 0.842
[37,     3] loss: 0.882
[38,     3] loss: 0.831
[39,     3] loss: 0.889
[40,     3] loss: 0.886
[41,     3] loss: 0.823
[42,     3] loss: 0.889
[43,     3] loss: 0.843
[44,     3] loss: 0.828
[45,     3] loss: 0.858
[46,     3] loss: 0.811
[47,     3] loss: 0.937
[48,     3] loss: 0.934
[49,     3] loss: 0.890
[50,     3] loss: 0.861
[51,     3] loss: 0.873
[52,     3] loss: 0.878
[53,     3] loss: 0.847
[54,     3] loss: 0.905
[55,     3] loss: 0.832
[56,     3] loss: 0.837
[57,     3] loss: 0.872
[58,     3] loss: 0.840
[59,     3] loss: 0.836
[60,     3] loss: 0.913
[61,     3] loss: 0.872
[62,     3] loss: 0.813
[63,     3] loss: 0.888
[64,     3] loss: 0.816
[65,     3] loss: 0.788
[66,     3] loss: 0.769
[67,     3] loss: 0.775
[68,     3] loss: 0.766
[69,     3] loss: 0.771
[70,     3] loss: 0.768
[71,     3] loss: 0.789
[72,     3] loss: 0.777
[73,     3] loss: 0.816
[74,     3] loss: 0.939
[75,     3] loss: 0.838
Early stopping applied (best metric=0.5432435274124146)
Finished Training
Total time taken: 16.76705551147461
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.380
[3,     3] loss: 1.369
[4,     3] loss: 1.373
[5,     3] loss: 1.350
[6,     3] loss: 1.317
[7,     3] loss: 1.280
[8,     3] loss: 1.327
[9,     3] loss: 1.290
[10,     3] loss: 1.221
[11,     3] loss: 1.231
[12,     3] loss: 1.136
[13,     3] loss: 1.151
[14,     3] loss: 1.102
[15,     3] loss: 1.178
[16,     3] loss: 1.135
[17,     3] loss: 1.089
[18,     3] loss: 1.064
[19,     3] loss: 1.039
[20,     3] loss: 1.042
[21,     3] loss: 1.012
[22,     3] loss: 1.034
[23,     3] loss: 1.053
[24,     3] loss: 0.964
[25,     3] loss: 1.187
[26,     3] loss: 0.987
[27,     3] loss: 0.899
[28,     3] loss: 0.944
[29,     3] loss: 0.953
[30,     3] loss: 0.976
[31,     3] loss: 0.914
[32,     3] loss: 0.948
[33,     3] loss: 0.898
[34,     3] loss: 0.855
[35,     3] loss: 1.004
[36,     3] loss: 0.876
[37,     3] loss: 0.839
[38,     3] loss: 0.888
[39,     3] loss: 0.852
[40,     3] loss: 0.839
[41,     3] loss: 0.806
[42,     3] loss: 0.792
[43,     3] loss: 0.779
[44,     3] loss: 0.812
[45,     3] loss: 0.903
[46,     3] loss: 0.777
[47,     3] loss: 0.809
[48,     3] loss: 0.804
[49,     3] loss: 0.820
[50,     3] loss: 0.821
[51,     3] loss: 0.794
[52,     3] loss: 0.831
[53,     3] loss: 0.813
[54,     3] loss: 0.984
[55,     3] loss: 0.872
[56,     3] loss: 0.908
[57,     3] loss: 0.872
[58,     3] loss: 0.914
[59,     3] loss: 0.877
[60,     3] loss: 0.860
[61,     3] loss: 0.904
[62,     3] loss: 0.851
[63,     3] loss: 0.832
[64,     3] loss: 0.801
[65,     3] loss: 0.834
[66,     3] loss: 0.790
[67,     3] loss: 0.847
[68,     3] loss: 0.903
[69,     3] loss: 0.982
Early stopping applied (best metric=0.5406064987182617)
Finished Training
Total time taken: 15.432631254196167
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.391
[3,     3] loss: 1.385
[4,     3] loss: 1.390
[5,     3] loss: 1.394
[6,     3] loss: 1.387
[7,     3] loss: 1.388
[8,     3] loss: 1.386
[9,     3] loss: 1.386
[10,     3] loss: 1.386
[11,     3] loss: 1.386
[12,     3] loss: 1.383
[13,     3] loss: 1.390
[14,     3] loss: 1.384
[15,     3] loss: 1.387
[16,     3] loss: 1.384
[17,     3] loss: 1.382
[18,     3] loss: 1.381
[19,     3] loss: 1.376
[20,     3] loss: 1.370
[21,     3] loss: 1.361
[22,     3] loss: 1.328
[23,     3] loss: 1.313
[24,     3] loss: 1.274
[25,     3] loss: 1.299
[26,     3] loss: 1.206
[27,     3] loss: 1.223
[28,     3] loss: 1.202
[29,     3] loss: 1.111
[30,     3] loss: 1.143
[31,     3] loss: 1.135
[32,     3] loss: 1.020
[33,     3] loss: 1.106
[34,     3] loss: 1.075
[35,     3] loss: 1.049
[36,     3] loss: 1.015
[37,     3] loss: 0.994
[38,     3] loss: 1.051
[39,     3] loss: 0.999
[40,     3] loss: 1.062
[41,     3] loss: 1.087
[42,     3] loss: 1.004
[43,     3] loss: 0.986
[44,     3] loss: 0.965
[45,     3] loss: 0.966
[46,     3] loss: 1.029
[47,     3] loss: 0.971
[48,     3] loss: 1.000
[49,     3] loss: 0.952
[50,     3] loss: 0.887
[51,     3] loss: 1.068
[52,     3] loss: 0.952
[53,     3] loss: 0.977
[54,     3] loss: 0.896
[55,     3] loss: 0.924
[56,     3] loss: 0.850
[57,     3] loss: 0.862
[58,     3] loss: 0.842
[59,     3] loss: 0.801
[60,     3] loss: 0.868
[61,     3] loss: 0.816
[62,     3] loss: 0.868
[63,     3] loss: 0.813
[64,     3] loss: 0.984
[65,     3] loss: 0.837
[66,     3] loss: 0.848
[67,     3] loss: 1.020
[68,     3] loss: 0.972
[69,     3] loss: 0.960
[70,     3] loss: 0.919
[71,     3] loss: 0.923
[72,     3] loss: 0.899
[73,     3] loss: 0.867
[74,     3] loss: 0.843
[75,     3] loss: 0.853
[76,     3] loss: 0.834
[77,     3] loss: 0.833
[78,     3] loss: 0.779
[79,     3] loss: 0.785
[80,     3] loss: 0.808
[81,     3] loss: 0.851
Early stopping applied (best metric=0.5057305097579956)
Finished Training
Total time taken: 18.044044733047485
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.385
[3,     3] loss: 1.386
[4,     3] loss: 1.369
[5,     3] loss: 1.381
[6,     3] loss: 1.393
[7,     3] loss: 1.380
[8,     3] loss: 1.380
[9,     3] loss: 1.372
[10,     3] loss: 1.365
[11,     3] loss: 1.350
[12,     3] loss: 1.344
[13,     3] loss: 1.306
[14,     3] loss: 1.277
[15,     3] loss: 1.228
[16,     3] loss: 1.215
[17,     3] loss: 1.206
[18,     3] loss: 1.158
[19,     3] loss: 1.119
[20,     3] loss: 1.113
[21,     3] loss: 1.089
[22,     3] loss: 1.067
[23,     3] loss: 1.022
[24,     3] loss: 1.029
[25,     3] loss: 1.075
[26,     3] loss: 1.084
[27,     3] loss: 1.014
[28,     3] loss: 1.108
[29,     3] loss: 1.066
[30,     3] loss: 1.019
[31,     3] loss: 1.021
[32,     3] loss: 0.996
[33,     3] loss: 0.970
[34,     3] loss: 1.013
[35,     3] loss: 1.043
[36,     3] loss: 0.975
[37,     3] loss: 0.953
[38,     3] loss: 1.020
[39,     3] loss: 0.895
[40,     3] loss: 1.023
[41,     3] loss: 1.017
[42,     3] loss: 0.907
[43,     3] loss: 0.912
[44,     3] loss: 0.923
[45,     3] loss: 0.915
[46,     3] loss: 0.864
[47,     3] loss: 0.848
[48,     3] loss: 0.900
[49,     3] loss: 0.918
[50,     3] loss: 0.876
[51,     3] loss: 0.926
[52,     3] loss: 0.903
[53,     3] loss: 0.954
[54,     3] loss: 0.848
[55,     3] loss: 0.932
[56,     3] loss: 0.945
[57,     3] loss: 0.946
[58,     3] loss: 0.898
[59,     3] loss: 1.001
[60,     3] loss: 0.863
[61,     3] loss: 0.925
[62,     3] loss: 1.014
[63,     3] loss: 0.848
[64,     3] loss: 0.900
[65,     3] loss: 0.862
[66,     3] loss: 0.825
[67,     3] loss: 0.903
[68,     3] loss: 0.839
[69,     3] loss: 0.777
[70,     3] loss: 0.811
[71,     3] loss: 0.812
[72,     3] loss: 0.792
[73,     3] loss: 0.766
[74,     3] loss: 0.754
[75,     3] loss: 0.789
[76,     3] loss: 0.789
[77,     3] loss: 0.763
[78,     3] loss: 0.766
[79,     3] loss: 0.762
[80,     3] loss: 0.780
[81,     3] loss: 0.768
Early stopping applied (best metric=0.4826523959636688)
Finished Training
Total time taken: 18.0900456905365
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.374
[3,     3] loss: 1.387
[4,     3] loss: 1.391
[5,     3] loss: 1.382
[6,     3] loss: 1.382
[7,     3] loss: 1.374
[8,     3] loss: 1.351
[9,     3] loss: 1.348
[10,     3] loss: 1.347
[11,     3] loss: 1.281
[12,     3] loss: 1.271
[13,     3] loss: 1.181
[14,     3] loss: 1.137
[15,     3] loss: 1.176
[16,     3] loss: 1.090
[17,     3] loss: 1.257
[18,     3] loss: 1.300
[19,     3] loss: 1.070
[20,     3] loss: 1.120
[21,     3] loss: 1.063
[22,     3] loss: 1.123
[23,     3] loss: 1.025
[24,     3] loss: 1.063
[25,     3] loss: 1.142
[26,     3] loss: 1.043
[27,     3] loss: 0.961
[28,     3] loss: 1.171
[29,     3] loss: 1.085
[30,     3] loss: 1.132
[31,     3] loss: 1.088
[32,     3] loss: 0.995
[33,     3] loss: 1.030
[34,     3] loss: 1.003
[35,     3] loss: 0.914
[36,     3] loss: 0.970
[37,     3] loss: 0.896
[38,     3] loss: 0.948
[39,     3] loss: 1.029
[40,     3] loss: 0.925
[41,     3] loss: 0.889
[42,     3] loss: 0.960
[43,     3] loss: 0.962
[44,     3] loss: 1.021
[45,     3] loss: 0.919
[46,     3] loss: 0.896
[47,     3] loss: 0.982
[48,     3] loss: 0.933
[49,     3] loss: 0.955
[50,     3] loss: 0.910
[51,     3] loss: 0.899
[52,     3] loss: 0.934
[53,     3] loss: 1.048
[54,     3] loss: 1.085
[55,     3] loss: 0.978
[56,     3] loss: 0.899
[57,     3] loss: 0.876
[58,     3] loss: 0.885
[59,     3] loss: 0.840
[60,     3] loss: 0.800
[61,     3] loss: 0.797
[62,     3] loss: 0.877
[63,     3] loss: 0.805
[64,     3] loss: 0.890
[65,     3] loss: 0.900
[66,     3] loss: 0.830
[67,     3] loss: 0.800
[68,     3] loss: 0.842
[69,     3] loss: 0.867
[70,     3] loss: 0.860
[71,     3] loss: 0.874
[72,     3] loss: 0.871
[73,     3] loss: 0.887
[74,     3] loss: 0.850
[75,     3] loss: 0.897
[76,     3] loss: 0.951
[77,     3] loss: 1.018
[78,     3] loss: 0.805
[79,     3] loss: 0.965
Early stopping applied (best metric=0.5039102435112)
Finished Training
Total time taken: 17.67905879020691
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.386
[3,     3] loss: 1.387
[4,     3] loss: 1.391
[5,     3] loss: 1.390
[6,     3] loss: 1.382
[7,     3] loss: 1.373
[8,     3] loss: 1.377
[9,     3] loss: 1.360
[10,     3] loss: 1.365
[11,     3] loss: 1.325
[12,     3] loss: 1.308
[13,     3] loss: 1.284
[14,     3] loss: 1.258
[15,     3] loss: 1.231
[16,     3] loss: 1.207
[17,     3] loss: 1.210
[18,     3] loss: 1.120
[19,     3] loss: 1.188
[20,     3] loss: 1.148
[21,     3] loss: 1.157
[22,     3] loss: 1.289
[23,     3] loss: 1.165
[24,     3] loss: 1.124
[25,     3] loss: 1.155
[26,     3] loss: 1.151
[27,     3] loss: 1.122
[28,     3] loss: 1.022
[29,     3] loss: 1.081
[30,     3] loss: 0.979
[31,     3] loss: 0.906
[32,     3] loss: 0.967
[33,     3] loss: 0.921
[34,     3] loss: 1.065
[35,     3] loss: 0.971
[36,     3] loss: 0.971
[37,     3] loss: 1.180
[38,     3] loss: 1.073
[39,     3] loss: 1.032
[40,     3] loss: 1.017
[41,     3] loss: 1.071
[42,     3] loss: 0.948
[43,     3] loss: 0.897
[44,     3] loss: 0.883
[45,     3] loss: 0.847
[46,     3] loss: 0.869
[47,     3] loss: 0.986
[48,     3] loss: 0.837
[49,     3] loss: 0.824
[50,     3] loss: 0.886
[51,     3] loss: 0.835
[52,     3] loss: 0.785
[53,     3] loss: 0.802
[54,     3] loss: 0.812
[55,     3] loss: 0.889
[56,     3] loss: 0.821
[57,     3] loss: 0.823
[58,     3] loss: 0.782
[59,     3] loss: 0.870
[60,     3] loss: 0.816
[61,     3] loss: 0.797
[62,     3] loss: 0.815
[63,     3] loss: 0.848
[64,     3] loss: 0.847
[65,     3] loss: 0.798
[66,     3] loss: 0.824
[67,     3] loss: 0.819
[68,     3] loss: 0.887
[69,     3] loss: 0.835
[70,     3] loss: 0.866
[71,     3] loss: 0.841
[72,     3] loss: 0.836
[73,     3] loss: 0.878
[74,     3] loss: 0.848
[75,     3] loss: 0.802
[76,     3] loss: 0.803
[77,     3] loss: 0.832
[78,     3] loss: 0.768
[79,     3] loss: 0.769
[80,     3] loss: 0.764
[81,     3] loss: 0.744
[82,     3] loss: 0.761
[83,     3] loss: 0.738
Early stopping applied (best metric=0.5153317451477051)
Finished Training
Total time taken: 18.56404685974121
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.394
[2,     3] loss: 1.386
[3,     3] loss: 1.381
[4,     3] loss: 1.387
[5,     3] loss: 1.379
[6,     3] loss: 1.370
[7,     3] loss: 1.344
[8,     3] loss: 1.319
[9,     3] loss: 1.324
[10,     3] loss: 1.309
[11,     3] loss: 1.258
[12,     3] loss: 1.310
[13,     3] loss: 1.270
[14,     3] loss: 1.236
[15,     3] loss: 1.169
[16,     3] loss: 1.159
[17,     3] loss: 1.266
[18,     3] loss: 1.021
[19,     3] loss: 1.084
[20,     3] loss: 1.035
[21,     3] loss: 1.205
[22,     3] loss: 1.060
[23,     3] loss: 0.994
[24,     3] loss: 0.984
[25,     3] loss: 1.069
[26,     3] loss: 0.906
[27,     3] loss: 1.029
[28,     3] loss: 1.034
[29,     3] loss: 1.011
[30,     3] loss: 0.981
[31,     3] loss: 1.035
[32,     3] loss: 1.061
[33,     3] loss: 0.982
[34,     3] loss: 0.939
[35,     3] loss: 0.982
[36,     3] loss: 0.961
[37,     3] loss: 0.893
[38,     3] loss: 0.918
[39,     3] loss: 0.921
[40,     3] loss: 0.880
[41,     3] loss: 0.865
[42,     3] loss: 0.857
[43,     3] loss: 0.899
[44,     3] loss: 0.884
[45,     3] loss: 0.918
[46,     3] loss: 0.959
[47,     3] loss: 0.948
[48,     3] loss: 1.025
[49,     3] loss: 0.933
[50,     3] loss: 0.891
[51,     3] loss: 0.921
[52,     3] loss: 0.913
[53,     3] loss: 0.867
[54,     3] loss: 0.876
[55,     3] loss: 0.938
[56,     3] loss: 1.019
[57,     3] loss: 0.967
[58,     3] loss: 0.857
[59,     3] loss: 0.916
[60,     3] loss: 0.827
[61,     3] loss: 0.919
[62,     3] loss: 0.909
[63,     3] loss: 0.813
[64,     3] loss: 0.917
[65,     3] loss: 0.871
[66,     3] loss: 0.792
[67,     3] loss: 0.796
[68,     3] loss: 0.817
[69,     3] loss: 0.798
[70,     3] loss: 0.802
[71,     3] loss: 0.796
[72,     3] loss: 0.748
[73,     3] loss: 0.807
[74,     3] loss: 0.763
[75,     3] loss: 0.777
Early stopping applied (best metric=0.535000741481781)
Finished Training
Total time taken: 16.72007393836975
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.391
[3,     3] loss: 1.385
[4,     3] loss: 1.394
[5,     3] loss: 1.396
[6,     3] loss: 1.391
[7,     3] loss: 1.383
[8,     3] loss: 1.388
[9,     3] loss: 1.381
[10,     3] loss: 1.372
[11,     3] loss: 1.365
[12,     3] loss: 1.350
[13,     3] loss: 1.332
[14,     3] loss: 1.307
[15,     3] loss: 1.231
[16,     3] loss: 1.206
[17,     3] loss: 1.172
[18,     3] loss: 1.178
[19,     3] loss: 1.174
[20,     3] loss: 1.290
[21,     3] loss: 1.184
[22,     3] loss: 1.131
[23,     3] loss: 1.004
[24,     3] loss: 1.029
[25,     3] loss: 1.075
[26,     3] loss: 1.032
[27,     3] loss: 1.039
[28,     3] loss: 1.146
[29,     3] loss: 0.950
[30,     3] loss: 1.021
[31,     3] loss: 0.986
[32,     3] loss: 0.990
[33,     3] loss: 0.947
[34,     3] loss: 0.903
[35,     3] loss: 1.016
[36,     3] loss: 0.904
[37,     3] loss: 0.992
[38,     3] loss: 0.969
[39,     3] loss: 0.987
[40,     3] loss: 1.040
[41,     3] loss: 0.956
[42,     3] loss: 0.930
[43,     3] loss: 0.908
[44,     3] loss: 0.911
[45,     3] loss: 0.896
[46,     3] loss: 0.847
[47,     3] loss: 0.827
[48,     3] loss: 0.945
[49,     3] loss: 0.891
[50,     3] loss: 0.922
[51,     3] loss: 0.854
[52,     3] loss: 0.995
[53,     3] loss: 1.183
[54,     3] loss: 1.023
[55,     3] loss: 1.011
[56,     3] loss: 0.922
[57,     3] loss: 1.022
[58,     3] loss: 0.892
[59,     3] loss: 0.871
[60,     3] loss: 0.842
[61,     3] loss: 0.796
[62,     3] loss: 0.790
[63,     3] loss: 0.772
[64,     3] loss: 0.785
[65,     3] loss: 0.764
[66,     3] loss: 0.815
[67,     3] loss: 0.812
[68,     3] loss: 0.864
[69,     3] loss: 0.893
[70,     3] loss: 0.920
[71,     3] loss: 0.913
[72,     3] loss: 0.935
[73,     3] loss: 0.904
[74,     3] loss: 0.900
[75,     3] loss: 0.883
Early stopping applied (best metric=0.5238940715789795)
Finished Training
Total time taken: 16.721652030944824
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.385
[3,     3] loss: 1.392
[4,     3] loss: 1.379
[5,     3] loss: 1.391
[6,     3] loss: 1.377
[7,     3] loss: 1.371
[8,     3] loss: 1.364
[9,     3] loss: 1.357
[10,     3] loss: 1.344
[11,     3] loss: 1.305
[12,     3] loss: 1.277
[13,     3] loss: 1.295
[14,     3] loss: 1.163
[15,     3] loss: 1.218
[16,     3] loss: 1.133
[17,     3] loss: 1.168
[18,     3] loss: 1.245
[19,     3] loss: 1.106
[20,     3] loss: 1.169
[21,     3] loss: 1.109
[22,     3] loss: 1.163
[23,     3] loss: 1.108
[24,     3] loss: 1.120
[25,     3] loss: 1.060
[26,     3] loss: 1.030
[27,     3] loss: 1.061
[28,     3] loss: 0.973
[29,     3] loss: 1.020
[30,     3] loss: 0.939
[31,     3] loss: 1.047
[32,     3] loss: 1.032
[33,     3] loss: 0.930
[34,     3] loss: 0.942
[35,     3] loss: 0.901
[36,     3] loss: 0.960
[37,     3] loss: 0.948
[38,     3] loss: 0.991
[39,     3] loss: 0.960
[40,     3] loss: 0.934
[41,     3] loss: 0.967
[42,     3] loss: 0.917
[43,     3] loss: 0.866
[44,     3] loss: 1.063
[45,     3] loss: 0.970
[46,     3] loss: 0.874
[47,     3] loss: 0.930
[48,     3] loss: 0.906
[49,     3] loss: 0.900
[50,     3] loss: 0.898
[51,     3] loss: 0.861
[52,     3] loss: 0.809
[53,     3] loss: 0.925
[54,     3] loss: 0.823
[55,     3] loss: 0.799
[56,     3] loss: 0.821
[57,     3] loss: 0.807
[58,     3] loss: 0.796
[59,     3] loss: 0.927
[60,     3] loss: 0.919
[61,     3] loss: 1.103
[62,     3] loss: 1.226
[63,     3] loss: 0.982
[64,     3] loss: 1.132
[65,     3] loss: 0.985
[66,     3] loss: 1.043
[67,     3] loss: 0.931
[68,     3] loss: 0.911
[69,     3] loss: 0.864
[70,     3] loss: 0.810
[71,     3] loss: 0.861
[72,     3] loss: 0.886
[73,     3] loss: 0.799
Early stopping applied (best metric=0.49266692996025085)
Finished Training
Total time taken: 16.3180410861969
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.384
[3,     3] loss: 1.387
[4,     3] loss: 1.390
[5,     3] loss: 1.388
[6,     3] loss: 1.387
[7,     3] loss: 1.384
[8,     3] loss: 1.378
[9,     3] loss: 1.372
[10,     3] loss: 1.367
[11,     3] loss: 1.364
[12,     3] loss: 1.344
[13,     3] loss: 1.315
[14,     3] loss: 1.289
[15,     3] loss: 1.255
[16,     3] loss: 1.207
[17,     3] loss: 1.196
[18,     3] loss: 1.106
[19,     3] loss: 1.179
[20,     3] loss: 1.022
[21,     3] loss: 1.093
[22,     3] loss: 1.131
[23,     3] loss: 1.121
[24,     3] loss: 1.241
[25,     3] loss: 1.254
[26,     3] loss: 1.174
[27,     3] loss: 1.220
[28,     3] loss: 1.171
[29,     3] loss: 1.104
[30,     3] loss: 1.086
[31,     3] loss: 1.065
[32,     3] loss: 1.048
[33,     3] loss: 1.017
[34,     3] loss: 0.957
[35,     3] loss: 1.011
[36,     3] loss: 0.954
[37,     3] loss: 0.864
[38,     3] loss: 0.919
[39,     3] loss: 1.015
[40,     3] loss: 0.919
[41,     3] loss: 1.113
[42,     3] loss: 1.086
[43,     3] loss: 1.029
[44,     3] loss: 0.929
[45,     3] loss: 0.969
[46,     3] loss: 0.960
[47,     3] loss: 0.961
[48,     3] loss: 0.899
[49,     3] loss: 0.890
[50,     3] loss: 0.927
[51,     3] loss: 0.895
[52,     3] loss: 0.829
[53,     3] loss: 0.862
[54,     3] loss: 1.028
[55,     3] loss: 0.960
[56,     3] loss: 0.874
[57,     3] loss: 0.862
[58,     3] loss: 0.915
[59,     3] loss: 0.901
[60,     3] loss: 0.875
[61,     3] loss: 0.837
[62,     3] loss: 0.811
[63,     3] loss: 0.810
[64,     3] loss: 0.804
[65,     3] loss: 0.857
[66,     3] loss: 0.773
[67,     3] loss: 0.763
[68,     3] loss: 0.832
[69,     3] loss: 0.777
[70,     3] loss: 0.828
[71,     3] loss: 0.878
[72,     3] loss: 0.923
[73,     3] loss: 0.866
[74,     3] loss: 0.848
[75,     3] loss: 0.945
[76,     3] loss: 0.843
[77,     3] loss: 0.886
[78,     3] loss: 0.861
[79,     3] loss: 0.813
[80,     3] loss: 0.795
[81,     3] loss: 0.764
[82,     3] loss: 0.758
[83,     3] loss: 0.772
[84,     3] loss: 0.778
[85,     3] loss: 0.787
[86,     3] loss: 0.798
[87,     3] loss: 0.750
[88,     3] loss: 0.760
[89,     3] loss: 0.749
[90,     3] loss: 0.746
Early stopping applied (best metric=0.516728937625885)
Finished Training
Total time taken: 20.205252170562744
{'S-palmitoylation-C Validation Accuracy': 0.6896527344562279, 'S-palmitoylation-C Validation Sensitivity': 0.2316831683168317, 'S-palmitoylation-C Validation Specificity': 0.8044460981565764, 'S-palmitoylation-C Validation Precision': 0.23283492375110207, 'S-palmitoylation-C AUC ROC': 0.5415005127811516, 'S-palmitoylation-C AUC PR': 0.2248223864236156, 'S-palmitoylation-C MCC': 0.03866461413722124, 'S-palmitoylation-C F1': 0.20962350146973757, 'Validation Loss (S-palmitoylation-C)': 0.5543788790702819, 'Hydroxylation-K Validation Accuracy': 0.722547281323877, 'Hydroxylation-K Validation Sensitivity': 0.794074074074074, 'Hydroxylation-K Validation Specificity': 0.7052631578947368, 'Hydroxylation-K Validation Precision': 0.42157311820658167, 'Hydroxylation-K AUC ROC': 0.8377972709551657, 'Hydroxylation-K AUC PR': 0.6297926446713537, 'Hydroxylation-K MCC': 0.42108044636783326, 'Hydroxylation-K F1': 0.5422681698333872, 'Validation Loss (Hydroxylation-K)': 0.5152155995368958, 'Validation Loss (total)': 1.0695944945017497, 'TimeToTrain': 16.75758851369222}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017973176539176619,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.38853125975414315,
 'loss_weight_S-palmitoylation-C': 0.482113415498581,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2158169676,
 'sample_weights': [0.5564156557442576, 0.08926586173375907],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.0628490232280186,
 'weight_decay_Hydroxylation-K': 8.97488516752338,
 'weight_decay_S-palmitoylation-C': 7.985118674302073}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.383
[3,     3] loss: 1.388
[4,     3] loss: 1.382
[5,     3] loss: 1.389
[6,     3] loss: 1.384
[7,     3] loss: 1.373
[8,     3] loss: 1.360
[9,     3] loss: 1.332
[10,     3] loss: 1.314
[11,     3] loss: 1.289
[12,     3] loss: 1.236
[13,     3] loss: 1.208
[14,     3] loss: 1.097
[15,     3] loss: 1.104
[16,     3] loss: 1.090
[17,     3] loss: 1.073
[18,     3] loss: 1.134
[19,     3] loss: 1.027
[20,     3] loss: 1.035
[21,     3] loss: 1.099
[22,     3] loss: 0.927
[23,     3] loss: 0.960
[24,     3] loss: 1.008
[25,     3] loss: 0.942
[26,     3] loss: 1.005
[27,     3] loss: 0.986
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017781237221128996,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.10674567937073925,
 'loss_weight_S-palmitoylation-C': 0.6671594138001884,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1010974710,
 'sample_weights': [0.482113415498581, 0.38853125975414315],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.99949085433333,
 'weight_decay_Hydroxylation-K': 3.665617223332778,
 'weight_decay_S-palmitoylation-C': 0.37945637572506324}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.386
[3,     3] loss: 1.375
[4,     3] loss: 1.371
[5,     3] loss: 1.386
[6,     3] loss: 1.366
[7,     3] loss: 1.363
[8,     3] loss: 1.319
[9,     3] loss: 1.306
[10,     3] loss: 1.283
[11,     3] loss: 1.268
[12,     3] loss: 1.236
[13,     3] loss: 1.150
[14,     3] loss: 1.200
[15,     3] loss: 1.155
[16,     3] loss: 1.116
[17,     3] loss: 1.060
[18,     3] loss: 1.055
[19,     3] loss: 1.003
[20,     3] loss: 0.952
[21,     3] loss: 1.009
[22,     3] loss: 1.016
[23,     3] loss: 1.070
[24,     3] loss: 1.191
[25,     3] loss: 1.227
[26,     3] loss: 1.039
[27,     3] loss: 1.084
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007920143105737325,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.06280565113540429,
 'loss_weight_S-palmitoylation-C': 0.6701424060935802,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1056074741,
 'sample_weights': [0.6671594138001884, 0.10674567937073925],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.900297293592646,
 'weight_decay_Hydroxylation-K': 6.706313274710308,
 'weight_decay_S-palmitoylation-C': 1.655766458511223}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.384
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014428522968410722,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.39231633843355807,
 'loss_weight_S-palmitoylation-C': 0.9278828436325866,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2957190236,
 'sample_weights': [0.6701424060935802, 0.06280565113540429],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.2902751279031093,
 'weight_decay_Hydroxylation-K': 1.6025434130637213,
 'weight_decay_S-palmitoylation-C': 0.6892931898732266}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.384
[3,     3] loss: 1.388
[4,     3] loss: 1.392
[5,     3] loss: 1.387
[6,     3] loss: 1.381
[7,     3] loss: 1.384
[8,     3] loss: 1.380
[9,     3] loss: 1.380
[10,     3] loss: 1.375
[11,     3] loss: 1.373
[12,     3] loss: 1.354
[13,     3] loss: 1.331
[14,     3] loss: 1.315
[15,     3] loss: 1.296
[16,     3] loss: 1.267
[17,     3] loss: 1.253
[18,     3] loss: 1.220
[19,     3] loss: 1.252
[20,     3] loss: 1.143
[21,     3] loss: 1.044
[22,     3] loss: 1.101
[23,     3] loss: 1.069
[24,     3] loss: 1.125
[25,     3] loss: 1.006
[26,     3] loss: 0.962
[27,     3] loss: 1.148
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00261273674514193,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9704927465321117,
 'loss_weight_S-palmitoylation-C': 0.09777878241133982,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2355116559,
 'sample_weights': [0.9278828436325866, 0.39231633843355807],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.191649478222375,
 'weight_decay_Hydroxylation-K': 2.3904124458901155,
 'weight_decay_S-palmitoylation-C': 9.674217202220156}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.384
[3,     3] loss: 1.399
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003190448029244163,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.10946429420090512,
 'loss_weight_S-palmitoylation-C': 0.45036755430208825,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2705351732,
 'sample_weights': [0.09777878241133982, 0.9704927465321117],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.875782373051864,
 'weight_decay_Hydroxylation-K': 5.800656476302086,
 'weight_decay_S-palmitoylation-C': 1.2362087149425638}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.385
[3,     3] loss: 1.393
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0021102866940465653,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9975352635323922,
 'loss_weight_S-palmitoylation-C': 0.3212345136824288,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3077388278,
 'sample_weights': [0.45036755430208825, 0.10946429420090512],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.083329180743316,
 'weight_decay_Hydroxylation-K': 3.022907328700594,
 'weight_decay_S-palmitoylation-C': 5.509085329139334}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.395
[3,     3] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00255163249763821,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7145525678240866,
 'loss_weight_S-palmitoylation-C': 0.6706225651463147,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2684832237,
 'sample_weights': [0.3212345136824288, 0.9975352635323922],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.637312354221654,
 'weight_decay_Hydroxylation-K': 1.5787329413186209,
 'weight_decay_S-palmitoylation-C': 9.069626875591158}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.380
[3,     3] loss: 1.378
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009694682319897383,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.385480255300075,
 'loss_weight_S-palmitoylation-C': 0.4946037492225299,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4013193820,
 'sample_weights': [0.6706225651463147, 0.7145525678240866],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.260195959206122,
 'weight_decay_Hydroxylation-K': 2.933101929461165,
 'weight_decay_S-palmitoylation-C': 2.77642423451533}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.389
[3,     3] loss: 1.394
[4,     3] loss: 1.378
[5,     3] loss: 1.383
[6,     3] loss: 1.380
[7,     3] loss: 1.369
[8,     3] loss: 1.384
[9,     3] loss: 1.373
[10,     3] loss: 1.368
[11,     3] loss: 1.372
[12,     3] loss: 1.349
[13,     3] loss: 1.326
[14,     3] loss: 1.308
[15,     3] loss: 1.299
[16,     3] loss: 1.273
[17,     3] loss: 1.168
[18,     3] loss: 1.155
[19,     3] loss: 1.204
[20,     3] loss: 1.152
[21,     3] loss: 1.170
[22,     3] loss: 1.059
[23,     3] loss: 0.977
[24,     3] loss: 1.010
[25,     3] loss: 1.047
[26,     3] loss: 0.956
[27,     3] loss: 1.034
[28,     3] loss: 0.953
[29,     3] loss: 1.136
[30,     3] loss: 1.034
[31,     3] loss: 1.097
[32,     3] loss: 0.918
[33,     3] loss: 0.957
[34,     3] loss: 0.902
[35,     3] loss: 1.069
[36,     3] loss: 0.984
[37,     3] loss: 1.056
[38,     3] loss: 0.948
[39,     3] loss: 0.940
[40,     3] loss: 0.948
[41,     3] loss: 0.891
[42,     3] loss: 0.992
[43,     3] loss: 0.886
[44,     3] loss: 1.012
[45,     3] loss: 1.040
[46,     3] loss: 0.908
[47,     3] loss: 0.952
[48,     3] loss: 0.952
[49,     3] loss: 0.854
[50,     3] loss: 0.864
[51,     3] loss: 0.789
[52,     3] loss: 0.813
[53,     3] loss: 0.881
[54,     3] loss: 0.811
[55,     3] loss: 0.874
[56,     3] loss: 0.783
[57,     3] loss: 0.809
[58,     3] loss: 0.806
[59,     3] loss: 0.897
[60,     3] loss: 0.784
[61,     3] loss: 0.801
[62,     3] loss: 0.795
[63,     3] loss: 0.790
[64,     3] loss: 0.814
[65,     3] loss: 0.812
[66,     3] loss: 0.810
[67,     3] loss: 0.838
Early stopping applied (best metric=0.5104928016662598)
Finished Training
Total time taken: 15.073046922683716
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.386
[3,     3] loss: 1.384
[4,     3] loss: 1.382
[5,     3] loss: 1.375
[6,     3] loss: 1.360
[7,     3] loss: 1.374
[8,     3] loss: 1.344
[9,     3] loss: 1.340
[10,     3] loss: 1.316
[11,     3] loss: 1.266
[12,     3] loss: 1.303
[13,     3] loss: 1.233
[14,     3] loss: 1.176
[15,     3] loss: 1.137
[16,     3] loss: 1.200
[17,     3] loss: 1.183
[18,     3] loss: 1.095
[19,     3] loss: 1.066
[20,     3] loss: 1.117
[21,     3] loss: 1.052
[22,     3] loss: 1.057
[23,     3] loss: 0.983
[24,     3] loss: 1.068
[25,     3] loss: 0.942
[26,     3] loss: 1.006
[27,     3] loss: 0.881
[28,     3] loss: 0.895
[29,     3] loss: 0.878
[30,     3] loss: 0.873
[31,     3] loss: 0.809
[32,     3] loss: 0.821
[33,     3] loss: 0.866
[34,     3] loss: 0.941
[35,     3] loss: 0.956
[36,     3] loss: 0.866
[37,     3] loss: 0.914
[38,     3] loss: 0.952
[39,     3] loss: 0.885
[40,     3] loss: 0.852
[41,     3] loss: 0.832
[42,     3] loss: 0.851
[43,     3] loss: 0.831
[44,     3] loss: 0.799
[45,     3] loss: 0.802
[46,     3] loss: 0.805
[47,     3] loss: 0.768
[48,     3] loss: 0.842
[49,     3] loss: 0.865
[50,     3] loss: 0.824
[51,     3] loss: 0.789
[52,     3] loss: 0.806
[53,     3] loss: 0.806
[54,     3] loss: 0.799
[55,     3] loss: 0.808
[56,     3] loss: 0.796
[57,     3] loss: 0.867
[58,     3] loss: 0.822
[59,     3] loss: 0.773
[60,     3] loss: 0.765
[61,     3] loss: 0.831
[62,     3] loss: 0.820
[63,     3] loss: 0.858
[64,     3] loss: 0.816
[65,     3] loss: 0.766
[66,     3] loss: 0.840
[67,     3] loss: 0.807
[68,     3] loss: 0.774
[69,     3] loss: 0.813
[70,     3] loss: 0.864
[71,     3] loss: 0.838
[72,     3] loss: 0.846
[73,     3] loss: 0.893
[74,     3] loss: 0.912
[75,     3] loss: 0.857
[76,     3] loss: 0.865
Early stopping applied (best metric=0.5373169183731079)
Finished Training
Total time taken: 17.026044845581055
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.384
[3,     3] loss: 1.383
[4,     3] loss: 1.382
[5,     3] loss: 1.377
[6,     3] loss: 1.373
[7,     3] loss: 1.367
[8,     3] loss: 1.374
[9,     3] loss: 1.360
[10,     3] loss: 1.342
[11,     3] loss: 1.326
[12,     3] loss: 1.268
[13,     3] loss: 1.282
[14,     3] loss: 1.200
[15,     3] loss: 1.251
[16,     3] loss: 1.162
[17,     3] loss: 1.165
[18,     3] loss: 1.075
[19,     3] loss: 1.037
[20,     3] loss: 1.101
[21,     3] loss: 1.042
[22,     3] loss: 1.011
[23,     3] loss: 1.038
[24,     3] loss: 1.024
[25,     3] loss: 1.011
[26,     3] loss: 0.977
[27,     3] loss: 0.928
[28,     3] loss: 0.899
[29,     3] loss: 0.942
[30,     3] loss: 1.003
[31,     3] loss: 0.876
[32,     3] loss: 0.848
[33,     3] loss: 0.962
[34,     3] loss: 0.898
[35,     3] loss: 0.830
[36,     3] loss: 0.884
[37,     3] loss: 0.836
[38,     3] loss: 0.776
[39,     3] loss: 0.861
[40,     3] loss: 0.817
[41,     3] loss: 0.806
[42,     3] loss: 0.889
[43,     3] loss: 0.789
[44,     3] loss: 0.791
[45,     3] loss: 0.783
[46,     3] loss: 0.858
[47,     3] loss: 0.909
[48,     3] loss: 0.851
[49,     3] loss: 0.874
[50,     3] loss: 0.852
[51,     3] loss: 0.817
[52,     3] loss: 0.792
[53,     3] loss: 0.769
[54,     3] loss: 0.845
[55,     3] loss: 0.793
[56,     3] loss: 0.837
[57,     3] loss: 0.863
[58,     3] loss: 0.799
[59,     3] loss: 0.826
[60,     3] loss: 0.964
[61,     3] loss: 0.877
[62,     3] loss: 0.924
[63,     3] loss: 0.995
[64,     3] loss: 0.824
[65,     3] loss: 0.922
[66,     3] loss: 0.884
[67,     3] loss: 0.789
[68,     3] loss: 0.876
[69,     3] loss: 0.794
[70,     3] loss: 0.828
[71,     3] loss: 0.789
[72,     3] loss: 0.794
[73,     3] loss: 0.765
[74,     3] loss: 0.760
Early stopping applied (best metric=0.5388501882553101)
Finished Training
Total time taken: 16.581040859222412
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.387
[3,     3] loss: 1.380
[4,     3] loss: 1.383
[5,     3] loss: 1.379
[6,     3] loss: 1.375
[7,     3] loss: 1.368
[8,     3] loss: 1.363
[9,     3] loss: 1.367
[10,     3] loss: 1.363
[11,     3] loss: 1.349
[12,     3] loss: 1.317
[13,     3] loss: 1.308
[14,     3] loss: 1.324
[15,     3] loss: 1.249
[16,     3] loss: 1.277
[17,     3] loss: 1.163
[18,     3] loss: 1.233
[19,     3] loss: 1.182
[20,     3] loss: 1.141
[21,     3] loss: 1.078
[22,     3] loss: 1.043
[23,     3] loss: 1.047
[24,     3] loss: 0.959
[25,     3] loss: 0.926
[26,     3] loss: 0.909
[27,     3] loss: 0.983
[28,     3] loss: 0.970
[29,     3] loss: 0.937
[30,     3] loss: 0.904
[31,     3] loss: 1.035
[32,     3] loss: 0.860
[33,     3] loss: 0.920
[34,     3] loss: 0.905
[35,     3] loss: 0.881
[36,     3] loss: 0.990
[37,     3] loss: 1.079
[38,     3] loss: 1.028
[39,     3] loss: 0.903
[40,     3] loss: 0.874
[41,     3] loss: 0.823
[42,     3] loss: 0.866
[43,     3] loss: 0.840
[44,     3] loss: 0.806
[45,     3] loss: 0.842
[46,     3] loss: 0.788
[47,     3] loss: 0.822
[48,     3] loss: 0.787
[49,     3] loss: 0.802
[50,     3] loss: 0.866
[51,     3] loss: 0.793
[52,     3] loss: 0.779
[53,     3] loss: 0.816
[54,     3] loss: 0.864
[55,     3] loss: 0.846
[56,     3] loss: 0.906
[57,     3] loss: 0.840
[58,     3] loss: 0.866
[59,     3] loss: 0.810
[60,     3] loss: 0.813
[61,     3] loss: 0.788
[62,     3] loss: 0.807
[63,     3] loss: 0.799
[64,     3] loss: 0.745
[65,     3] loss: 0.829
[66,     3] loss: 0.769
[67,     3] loss: 0.797
[68,     3] loss: 0.789
[69,     3] loss: 0.846
[70,     3] loss: 0.762
[71,     3] loss: 0.781
Early stopping applied (best metric=0.521419107913971)
Finished Training
Total time taken: 15.918732404708862
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.383
[3,     3] loss: 1.383
[4,     3] loss: 1.381
[5,     3] loss: 1.388
[6,     3] loss: 1.375
[7,     3] loss: 1.367
[8,     3] loss: 1.371
[9,     3] loss: 1.349
[10,     3] loss: 1.335
[11,     3] loss: 1.300
[12,     3] loss: 1.291
[13,     3] loss: 1.239
[14,     3] loss: 1.223
[15,     3] loss: 1.248
[16,     3] loss: 1.280
[17,     3] loss: 1.139
[18,     3] loss: 1.162
[19,     3] loss: 1.175
[20,     3] loss: 1.060
[21,     3] loss: 1.077
[22,     3] loss: 1.018
[23,     3] loss: 1.004
[24,     3] loss: 0.920
[25,     3] loss: 0.968
[26,     3] loss: 0.975
[27,     3] loss: 0.908
[28,     3] loss: 0.962
[29,     3] loss: 0.958
[30,     3] loss: 0.903
[31,     3] loss: 0.973
[32,     3] loss: 0.920
[33,     3] loss: 0.978
[34,     3] loss: 0.921
[35,     3] loss: 0.985
[36,     3] loss: 1.030
[37,     3] loss: 0.930
[38,     3] loss: 0.910
[39,     3] loss: 0.874
[40,     3] loss: 0.865
[41,     3] loss: 0.840
[42,     3] loss: 0.872
[43,     3] loss: 0.798
[44,     3] loss: 0.830
[45,     3] loss: 0.977
[46,     3] loss: 0.809
[47,     3] loss: 0.890
[48,     3] loss: 0.858
[49,     3] loss: 0.979
[50,     3] loss: 0.827
[51,     3] loss: 0.840
[52,     3] loss: 0.928
[53,     3] loss: 0.951
[54,     3] loss: 1.001
[55,     3] loss: 1.173
[56,     3] loss: 0.956
[57,     3] loss: 1.059
[58,     3] loss: 0.972
[59,     3] loss: 0.992
[60,     3] loss: 0.922
[61,     3] loss: 0.953
[62,     3] loss: 0.849
[63,     3] loss: 0.891
[64,     3] loss: 0.806
[65,     3] loss: 0.801
[66,     3] loss: 0.781
[67,     3] loss: 0.819
[68,     3] loss: 0.768
[69,     3] loss: 0.758
Early stopping applied (best metric=0.5090633034706116)
Finished Training
Total time taken: 15.493038177490234
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.390
[3,     3] loss: 1.389
[4,     3] loss: 1.381
[5,     3] loss: 1.384
[6,     3] loss: 1.379
[7,     3] loss: 1.382
[8,     3] loss: 1.369
[9,     3] loss: 1.373
[10,     3] loss: 1.356
[11,     3] loss: 1.330
[12,     3] loss: 1.334
[13,     3] loss: 1.287
[14,     3] loss: 1.309
[15,     3] loss: 1.212
[16,     3] loss: 1.217
[17,     3] loss: 1.218
[18,     3] loss: 1.151
[19,     3] loss: 1.189
[20,     3] loss: 1.087
[21,     3] loss: 1.152
[22,     3] loss: 1.123
[23,     3] loss: 1.109
[24,     3] loss: 1.050
[25,     3] loss: 1.031
[26,     3] loss: 1.127
[27,     3] loss: 0.997
[28,     3] loss: 0.980
[29,     3] loss: 0.943
[30,     3] loss: 0.994
[31,     3] loss: 0.948
[32,     3] loss: 1.001
[33,     3] loss: 0.827
[34,     3] loss: 0.912
[35,     3] loss: 0.890
[36,     3] loss: 0.809
[37,     3] loss: 0.879
[38,     3] loss: 0.878
[39,     3] loss: 0.861
[40,     3] loss: 0.946
[41,     3] loss: 0.871
[42,     3] loss: 0.906
[43,     3] loss: 0.856
[44,     3] loss: 0.943
[45,     3] loss: 0.803
[46,     3] loss: 0.859
[47,     3] loss: 0.877
[48,     3] loss: 0.857
[49,     3] loss: 0.852
[50,     3] loss: 0.834
[51,     3] loss: 0.815
[52,     3] loss: 0.762
[53,     3] loss: 0.790
[54,     3] loss: 0.819
[55,     3] loss: 0.793
[56,     3] loss: 0.777
[57,     3] loss: 0.799
[58,     3] loss: 0.804
[59,     3] loss: 0.789
[60,     3] loss: 0.794
[61,     3] loss: 0.745
[62,     3] loss: 0.812
[63,     3] loss: 0.800
[64,     3] loss: 0.797
[65,     3] loss: 0.781
[66,     3] loss: 0.779
[67,     3] loss: 0.816
[68,     3] loss: 0.761
[69,     3] loss: 0.757
[70,     3] loss: 0.785
Early stopping applied (best metric=0.5506707429885864)
Finished Training
Total time taken: 15.667053937911987
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.383
[2,     3] loss: 1.386
[3,     3] loss: 1.396
[4,     3] loss: 1.387
[5,     3] loss: 1.381
[6,     3] loss: 1.379
[7,     3] loss: 1.382
[8,     3] loss: 1.363
[9,     3] loss: 1.370
[10,     3] loss: 1.355
[11,     3] loss: 1.342
[12,     3] loss: 1.302
[13,     3] loss: 1.257
[14,     3] loss: 1.293
[15,     3] loss: 1.245
[16,     3] loss: 1.219
[17,     3] loss: 1.236
[18,     3] loss: 1.211
[19,     3] loss: 1.195
[20,     3] loss: 1.138
[21,     3] loss: 1.188
[22,     3] loss: 1.125
[23,     3] loss: 1.131
[24,     3] loss: 1.058
[25,     3] loss: 1.050
[26,     3] loss: 1.054
[27,     3] loss: 1.097
[28,     3] loss: 1.050
[29,     3] loss: 1.019
[30,     3] loss: 0.972
[31,     3] loss: 0.957
[32,     3] loss: 1.044
[33,     3] loss: 0.958
[34,     3] loss: 1.109
[35,     3] loss: 1.046
[36,     3] loss: 1.012
[37,     3] loss: 0.933
[38,     3] loss: 0.961
[39,     3] loss: 0.913
[40,     3] loss: 0.892
[41,     3] loss: 0.959
[42,     3] loss: 0.940
[43,     3] loss: 0.849
[44,     3] loss: 0.895
[45,     3] loss: 0.825
[46,     3] loss: 0.798
[47,     3] loss: 0.831
[48,     3] loss: 0.877
[49,     3] loss: 0.825
[50,     3] loss: 0.848
[51,     3] loss: 0.813
[52,     3] loss: 0.810
[53,     3] loss: 0.881
[54,     3] loss: 0.912
[55,     3] loss: 0.799
[56,     3] loss: 0.875
[57,     3] loss: 0.822
[58,     3] loss: 0.831
[59,     3] loss: 0.853
[60,     3] loss: 0.823
[61,     3] loss: 0.888
[62,     3] loss: 0.830
[63,     3] loss: 0.862
[64,     3] loss: 0.820
[65,     3] loss: 0.844
[66,     3] loss: 0.858
[67,     3] loss: 0.769
[68,     3] loss: 0.845
[69,     3] loss: 0.923
[70,     3] loss: 0.817
[71,     3] loss: 0.826
[72,     3] loss: 0.818
[73,     3] loss: 0.794
[74,     3] loss: 0.804
[75,     3] loss: 0.790
[76,     3] loss: 0.732
[77,     3] loss: 0.777
Early stopping applied (best metric=0.5211288332939148)
Finished Training
Total time taken: 17.245043516159058
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.399
[3,     3] loss: 1.383
[4,     3] loss: 1.386
[5,     3] loss: 1.392
[6,     3] loss: 1.385
[7,     3] loss: 1.388
[8,     3] loss: 1.382
[9,     3] loss: 1.371
[10,     3] loss: 1.377
[11,     3] loss: 1.374
[12,     3] loss: 1.373
[13,     3] loss: 1.358
[14,     3] loss: 1.339
[15,     3] loss: 1.308
[16,     3] loss: 1.330
[17,     3] loss: 1.250
[18,     3] loss: 1.259
[19,     3] loss: 1.207
[20,     3] loss: 1.147
[21,     3] loss: 1.151
[22,     3] loss: 1.131
[23,     3] loss: 1.145
[24,     3] loss: 1.088
[25,     3] loss: 1.056
[26,     3] loss: 1.114
[27,     3] loss: 0.969
[28,     3] loss: 1.092
[29,     3] loss: 1.014
[30,     3] loss: 1.187
[31,     3] loss: 1.044
[32,     3] loss: 1.030
[33,     3] loss: 0.955
[34,     3] loss: 1.057
[35,     3] loss: 0.974
[36,     3] loss: 0.913
[37,     3] loss: 1.074
[38,     3] loss: 1.028
[39,     3] loss: 0.970
[40,     3] loss: 0.974
[41,     3] loss: 0.902
[42,     3] loss: 0.939
[43,     3] loss: 0.883
[44,     3] loss: 0.860
[45,     3] loss: 0.875
[46,     3] loss: 0.798
[47,     3] loss: 0.858
[48,     3] loss: 0.936
[49,     3] loss: 1.060
[50,     3] loss: 0.953
[51,     3] loss: 0.939
[52,     3] loss: 0.951
[53,     3] loss: 0.923
[54,     3] loss: 0.969
[55,     3] loss: 0.895
[56,     3] loss: 0.889
[57,     3] loss: 0.880
[58,     3] loss: 0.850
[59,     3] loss: 0.785
[60,     3] loss: 0.837
[61,     3] loss: 0.851
[62,     3] loss: 0.833
[63,     3] loss: 0.862
[64,     3] loss: 0.840
[65,     3] loss: 0.881
[66,     3] loss: 0.846
[67,     3] loss: 0.914
[68,     3] loss: 0.807
[69,     3] loss: 0.847
[70,     3] loss: 0.795
[71,     3] loss: 0.859
[72,     3] loss: 0.921
[73,     3] loss: 0.982
[74,     3] loss: 0.791
[75,     3] loss: 1.005
[76,     3] loss: 0.892
[77,     3] loss: 0.936
[78,     3] loss: 0.877
[79,     3] loss: 0.878
[80,     3] loss: 0.869
[81,     3] loss: 0.858
[82,     3] loss: 0.800
[83,     3] loss: 0.760
[84,     3] loss: 0.788
[85,     3] loss: 0.770
[86,     3] loss: 0.764
[87,     3] loss: 0.758
[88,     3] loss: 0.754
[89,     3] loss: 0.778
[90,     3] loss: 0.784
Early stopping applied (best metric=0.5169001817703247)
Finished Training
Total time taken: 20.170050621032715
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.383
[3,     3] loss: 1.393
[4,     3] loss: 1.380
[5,     3] loss: 1.385
[6,     3] loss: 1.375
[7,     3] loss: 1.370
[8,     3] loss: 1.372
[9,     3] loss: 1.347
[10,     3] loss: 1.347
[11,     3] loss: 1.315
[12,     3] loss: 1.288
[13,     3] loss: 1.263
[14,     3] loss: 1.223
[15,     3] loss: 1.236
[16,     3] loss: 1.283
[17,     3] loss: 1.174
[18,     3] loss: 1.164
[19,     3] loss: 1.099
[20,     3] loss: 1.050
[21,     3] loss: 1.026
[22,     3] loss: 1.109
[23,     3] loss: 1.049
[24,     3] loss: 1.118
[25,     3] loss: 1.139
[26,     3] loss: 1.118
[27,     3] loss: 1.000
[28,     3] loss: 1.010
[29,     3] loss: 1.041
[30,     3] loss: 1.043
[31,     3] loss: 0.985
[32,     3] loss: 1.014
[33,     3] loss: 1.047
[34,     3] loss: 0.981
[35,     3] loss: 0.981
[36,     3] loss: 1.006
[37,     3] loss: 0.962
[38,     3] loss: 0.927
[39,     3] loss: 0.921
[40,     3] loss: 0.888
[41,     3] loss: 0.912
[42,     3] loss: 0.926
[43,     3] loss: 0.868
[44,     3] loss: 0.936
[45,     3] loss: 0.977
[46,     3] loss: 0.834
[47,     3] loss: 0.885
[48,     3] loss: 0.878
[49,     3] loss: 0.904
[50,     3] loss: 0.821
[51,     3] loss: 0.858
[52,     3] loss: 0.803
[53,     3] loss: 0.782
[54,     3] loss: 0.820
[55,     3] loss: 0.814
[56,     3] loss: 0.853
[57,     3] loss: 0.812
[58,     3] loss: 0.817
[59,     3] loss: 0.843
[60,     3] loss: 0.765
[61,     3] loss: 0.826
[62,     3] loss: 0.768
[63,     3] loss: 0.806
[64,     3] loss: 0.786
[65,     3] loss: 0.823
[66,     3] loss: 0.840
[67,     3] loss: 0.983
Early stopping applied (best metric=0.5125147700309753)
Finished Training
Total time taken: 14.962036609649658
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.384
[3,     3] loss: 1.391
[4,     3] loss: 1.369
[5,     3] loss: 1.390
[6,     3] loss: 1.380
[7,     3] loss: 1.372
[8,     3] loss: 1.366
[9,     3] loss: 1.356
[10,     3] loss: 1.326
[11,     3] loss: 1.290
[12,     3] loss: 1.251
[13,     3] loss: 1.232
[14,     3] loss: 1.160
[15,     3] loss: 1.215
[16,     3] loss: 1.135
[17,     3] loss: 1.107
[18,     3] loss: 1.056
[19,     3] loss: 1.043
[20,     3] loss: 1.028
[21,     3] loss: 1.089
[22,     3] loss: 0.993
[23,     3] loss: 1.029
[24,     3] loss: 0.898
[25,     3] loss: 0.961
[26,     3] loss: 0.966
[27,     3] loss: 0.931
[28,     3] loss: 0.919
[29,     3] loss: 0.959
[30,     3] loss: 0.876
[31,     3] loss: 0.884
[32,     3] loss: 0.939
[33,     3] loss: 1.024
[34,     3] loss: 0.870
[35,     3] loss: 0.835
[36,     3] loss: 0.867
[37,     3] loss: 0.845
[38,     3] loss: 0.857
[39,     3] loss: 0.865
[40,     3] loss: 0.848
[41,     3] loss: 0.879
[42,     3] loss: 0.820
[43,     3] loss: 0.851
[44,     3] loss: 0.818
[45,     3] loss: 1.007
[46,     3] loss: 0.826
[47,     3] loss: 0.879
[48,     3] loss: 0.829
[49,     3] loss: 0.824
[50,     3] loss: 0.795
[51,     3] loss: 0.774
[52,     3] loss: 0.800
[53,     3] loss: 0.823
[54,     3] loss: 0.799
[55,     3] loss: 0.788
[56,     3] loss: 0.782
[57,     3] loss: 0.878
[58,     3] loss: 0.821
[59,     3] loss: 0.789
[60,     3] loss: 0.854
[61,     3] loss: 0.851
[62,     3] loss: 0.819
[63,     3] loss: 0.795
[64,     3] loss: 0.863
[65,     3] loss: 0.884
[66,     3] loss: 0.759
[67,     3] loss: 0.795
[68,     3] loss: 0.852
[69,     3] loss: 0.829
[70,     3] loss: 0.973
[71,     3] loss: 0.807
[72,     3] loss: 0.895
[73,     3] loss: 0.852
[74,     3] loss: 0.818
[75,     3] loss: 0.801
[76,     3] loss: 0.811
[77,     3] loss: 0.749
[78,     3] loss: 0.743
[79,     3] loss: 0.752
[80,     3] loss: 0.749
[81,     3] loss: 0.756
[82,     3] loss: 0.729
[83,     3] loss: 0.733
[84,     3] loss: 0.754
[85,     3] loss: 0.751
[86,     3] loss: 0.741
[87,     3] loss: 0.756
[88,     3] loss: 0.720
[89,     3] loss: 0.737
[90,     3] loss: 0.744
[91,     3] loss: 0.723
[92,     3] loss: 0.731
[93,     3] loss: 0.720
[94,     3] loss: 0.727
Early stopping applied (best metric=0.5055170655250549)
Finished Training
Total time taken: 21.014065504074097
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.389
[3,     3] loss: 1.383
[4,     3] loss: 1.376
[5,     3] loss: 1.380
[6,     3] loss: 1.361
[7,     3] loss: 1.351
[8,     3] loss: 1.344
[9,     3] loss: 1.337
[10,     3] loss: 1.344
[11,     3] loss: 1.298
[12,     3] loss: 1.272
[13,     3] loss: 1.261
[14,     3] loss: 1.246
[15,     3] loss: 1.206
[16,     3] loss: 1.204
[17,     3] loss: 1.258
[18,     3] loss: 1.227
[19,     3] loss: 1.124
[20,     3] loss: 1.085
[21,     3] loss: 1.076
[22,     3] loss: 1.042
[23,     3] loss: 1.070
[24,     3] loss: 1.146
[25,     3] loss: 1.101
[26,     3] loss: 1.122
[27,     3] loss: 1.129
[28,     3] loss: 0.971
[29,     3] loss: 1.043
[30,     3] loss: 1.069
[31,     3] loss: 0.978
[32,     3] loss: 0.920
[33,     3] loss: 0.949
[34,     3] loss: 0.925
[35,     3] loss: 0.881
[36,     3] loss: 0.831
[37,     3] loss: 0.937
[38,     3] loss: 0.867
[39,     3] loss: 0.866
[40,     3] loss: 0.826
[41,     3] loss: 0.871
[42,     3] loss: 0.842
[43,     3] loss: 0.830
[44,     3] loss: 0.769
[45,     3] loss: 0.833
[46,     3] loss: 0.787
[47,     3] loss: 0.787
[48,     3] loss: 0.843
[49,     3] loss: 0.894
[50,     3] loss: 0.778
[51,     3] loss: 0.867
[52,     3] loss: 0.896
[53,     3] loss: 0.840
[54,     3] loss: 0.814
[55,     3] loss: 0.792
[56,     3] loss: 0.800
[57,     3] loss: 0.845
[58,     3] loss: 0.819
[59,     3] loss: 0.810
[60,     3] loss: 0.871
[61,     3] loss: 0.873
[62,     3] loss: 0.800
[63,     3] loss: 0.781
[64,     3] loss: 0.785
[65,     3] loss: 0.788
[66,     3] loss: 0.759
[67,     3] loss: 0.754
[68,     3] loss: 0.810
[69,     3] loss: 0.777
[70,     3] loss: 0.769
[71,     3] loss: 0.751
[72,     3] loss: 0.798
[73,     3] loss: 0.824
Early stopping applied (best metric=0.5154054164886475)
Finished Training
Total time taken: 16.323041915893555
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.390
[3,     3] loss: 1.384
[4,     3] loss: 1.390
[5,     3] loss: 1.384
[6,     3] loss: 1.382
[7,     3] loss: 1.382
[8,     3] loss: 1.373
[9,     3] loss: 1.373
[10,     3] loss: 1.375
[11,     3] loss: 1.364
[12,     3] loss: 1.354
[13,     3] loss: 1.359
[14,     3] loss: 1.288
[15,     3] loss: 1.218
[16,     3] loss: 1.286
[17,     3] loss: 1.245
[18,     3] loss: 1.185
[19,     3] loss: 1.255
[20,     3] loss: 1.113
[21,     3] loss: 1.099
[22,     3] loss: 1.105
[23,     3] loss: 1.092
[24,     3] loss: 1.032
[25,     3] loss: 1.053
[26,     3] loss: 1.037
[27,     3] loss: 1.064
[28,     3] loss: 1.043
[29,     3] loss: 1.035
[30,     3] loss: 0.926
[31,     3] loss: 0.954
[32,     3] loss: 0.983
[33,     3] loss: 0.922
[34,     3] loss: 0.888
[35,     3] loss: 0.900
[36,     3] loss: 0.886
[37,     3] loss: 0.936
[38,     3] loss: 0.864
[39,     3] loss: 0.840
[40,     3] loss: 0.831
[41,     3] loss: 0.892
[42,     3] loss: 0.962
[43,     3] loss: 0.879
[44,     3] loss: 0.843
[45,     3] loss: 0.942
[46,     3] loss: 0.939
[47,     3] loss: 0.875
[48,     3] loss: 0.956
[49,     3] loss: 0.896
[50,     3] loss: 0.877
[51,     3] loss: 0.827
[52,     3] loss: 0.821
[53,     3] loss: 0.789
[54,     3] loss: 0.845
[55,     3] loss: 0.820
[56,     3] loss: 0.804
[57,     3] loss: 0.777
[58,     3] loss: 0.843
[59,     3] loss: 0.759
[60,     3] loss: 0.780
[61,     3] loss: 0.816
[62,     3] loss: 0.818
[63,     3] loss: 0.906
[64,     3] loss: 0.853
[65,     3] loss: 0.804
[66,     3] loss: 0.777
[67,     3] loss: 0.852
[68,     3] loss: 0.803
[69,     3] loss: 0.901
[70,     3] loss: 0.840
[71,     3] loss: 0.821
[72,     3] loss: 0.801
[73,     3] loss: 0.797
[74,     3] loss: 0.857
[75,     3] loss: 0.805
[76,     3] loss: 0.779
[77,     3] loss: 0.847
[78,     3] loss: 0.801
[79,     3] loss: 0.782
[80,     3] loss: 0.773
[81,     3] loss: 0.755
[82,     3] loss: 0.811
[83,     3] loss: 0.768
[84,     3] loss: 0.759
[85,     3] loss: 0.773
[86,     3] loss: 0.739
[87,     3] loss: 0.748
[88,     3] loss: 0.753
[89,     3] loss: 0.742
[90,     3] loss: 0.751
[91,     3] loss: 0.733
[92,     3] loss: 0.763
[93,     3] loss: 0.766
[94,     3] loss: 0.861
[95,     3] loss: 0.995
[96,     3] loss: 0.991
[97,     3] loss: 0.929
[98,     3] loss: 0.923
[99,     3] loss: 0.882
[100,     3] loss: 0.911
[101,     3] loss: 0.845
[102,     3] loss: 0.829
[103,     3] loss: 0.858
[104,     3] loss: 0.791
[105,     3] loss: 0.750
[106,     3] loss: 0.776
[107,     3] loss: 0.744
[108,     3] loss: 0.741
Early stopping applied (best metric=0.5163008570671082)
Finished Training
Total time taken: 24.161062717437744
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.386
[3,     3] loss: 1.383
[4,     3] loss: 1.381
[5,     3] loss: 1.386
[6,     3] loss: 1.382
[7,     3] loss: 1.375
[8,     3] loss: 1.390
[9,     3] loss: 1.367
[10,     3] loss: 1.350
[11,     3] loss: 1.356
[12,     3] loss: 1.341
[13,     3] loss: 1.327
[14,     3] loss: 1.308
[15,     3] loss: 1.242
[16,     3] loss: 1.261
[17,     3] loss: 1.207
[18,     3] loss: 1.191
[19,     3] loss: 1.163
[20,     3] loss: 1.156
[21,     3] loss: 1.112
[22,     3] loss: 1.170
[23,     3] loss: 1.093
[24,     3] loss: 1.150
[25,     3] loss: 1.086
[26,     3] loss: 1.005
[27,     3] loss: 1.033
[28,     3] loss: 0.987
[29,     3] loss: 0.973
[30,     3] loss: 0.944
[31,     3] loss: 0.916
[32,     3] loss: 0.954
[33,     3] loss: 0.900
[34,     3] loss: 0.902
[35,     3] loss: 0.963
[36,     3] loss: 0.958
[37,     3] loss: 0.975
[38,     3] loss: 1.008
[39,     3] loss: 0.966
[40,     3] loss: 1.027
[41,     3] loss: 1.074
[42,     3] loss: 0.996
[43,     3] loss: 0.970
[44,     3] loss: 0.963
[45,     3] loss: 0.894
[46,     3] loss: 0.956
[47,     3] loss: 0.940
[48,     3] loss: 0.866
[49,     3] loss: 0.851
[50,     3] loss: 0.838
[51,     3] loss: 0.865
[52,     3] loss: 0.882
[53,     3] loss: 0.902
[54,     3] loss: 0.903
[55,     3] loss: 0.832
[56,     3] loss: 0.969
[57,     3] loss: 0.948
[58,     3] loss: 0.960
[59,     3] loss: 0.921
[60,     3] loss: 0.965
[61,     3] loss: 0.855
[62,     3] loss: 0.908
[63,     3] loss: 0.941
[64,     3] loss: 0.884
[65,     3] loss: 0.963
[66,     3] loss: 0.847
[67,     3] loss: 0.936
Early stopping applied (best metric=0.5304804444313049)
Finished Training
Total time taken: 15.032039165496826
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.393
[2,     3] loss: 1.384
[3,     3] loss: 1.385
[4,     3] loss: 1.379
[5,     3] loss: 1.382
[6,     3] loss: 1.370
[7,     3] loss: 1.377
[8,     3] loss: 1.365
[9,     3] loss: 1.335
[10,     3] loss: 1.334
[11,     3] loss: 1.309
[12,     3] loss: 1.298
[13,     3] loss: 1.262
[14,     3] loss: 1.216
[15,     3] loss: 1.165
[16,     3] loss: 1.120
[17,     3] loss: 1.188
[18,     3] loss: 1.149
[19,     3] loss: 1.074
[20,     3] loss: 1.111
[21,     3] loss: 1.200
[22,     3] loss: 1.034
[23,     3] loss: 1.012
[24,     3] loss: 1.021
[25,     3] loss: 0.972
[26,     3] loss: 1.010
[27,     3] loss: 0.980
[28,     3] loss: 1.002
[29,     3] loss: 0.979
[30,     3] loss: 0.930
[31,     3] loss: 0.957
[32,     3] loss: 0.945
[33,     3] loss: 0.940
[34,     3] loss: 1.010
[35,     3] loss: 0.979
[36,     3] loss: 0.978
[37,     3] loss: 1.007
[38,     3] loss: 0.887
[39,     3] loss: 0.934
[40,     3] loss: 0.863
[41,     3] loss: 0.864
[42,     3] loss: 0.907
[43,     3] loss: 0.866
[44,     3] loss: 0.921
[45,     3] loss: 0.856
[46,     3] loss: 0.897
[47,     3] loss: 0.827
[48,     3] loss: 0.786
[49,     3] loss: 0.774
[50,     3] loss: 0.828
[51,     3] loss: 0.787
[52,     3] loss: 0.824
[53,     3] loss: 0.847
[54,     3] loss: 0.803
[55,     3] loss: 0.829
[56,     3] loss: 0.769
[57,     3] loss: 0.833
[58,     3] loss: 0.842
[59,     3] loss: 0.887
[60,     3] loss: 0.873
[61,     3] loss: 0.900
[62,     3] loss: 0.819
[63,     3] loss: 0.837
[64,     3] loss: 0.793
[65,     3] loss: 0.817
[66,     3] loss: 0.854
[67,     3] loss: 0.938
[68,     3] loss: 0.896
[69,     3] loss: 0.847
Early stopping applied (best metric=0.5215769410133362)
Finished Training
Total time taken: 15.484039783477783
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.382
[3,     3] loss: 1.390
[4,     3] loss: 1.380
[5,     3] loss: 1.383
[6,     3] loss: 1.378
[7,     3] loss: 1.387
[8,     3] loss: 1.380
[9,     3] loss: 1.379
[10,     3] loss: 1.365
[11,     3] loss: 1.354
[12,     3] loss: 1.332
[13,     3] loss: 1.327
[14,     3] loss: 1.291
[15,     3] loss: 1.276
[16,     3] loss: 1.214
[17,     3] loss: 1.232
[18,     3] loss: 1.192
[19,     3] loss: 1.106
[20,     3] loss: 1.040
[21,     3] loss: 1.073
[22,     3] loss: 1.074
[23,     3] loss: 1.013
[24,     3] loss: 1.080
[25,     3] loss: 1.218
[26,     3] loss: 0.988
[27,     3] loss: 1.003
[28,     3] loss: 1.068
[29,     3] loss: 1.075
[30,     3] loss: 1.101
[31,     3] loss: 1.000
[32,     3] loss: 0.938
[33,     3] loss: 0.962
[34,     3] loss: 0.884
[35,     3] loss: 0.907
[36,     3] loss: 0.906
[37,     3] loss: 0.972
[38,     3] loss: 1.003
[39,     3] loss: 0.864
[40,     3] loss: 0.913
[41,     3] loss: 0.903
[42,     3] loss: 0.927
[43,     3] loss: 0.897
[44,     3] loss: 0.887
[45,     3] loss: 0.867
[46,     3] loss: 0.888
[47,     3] loss: 0.894
[48,     3] loss: 0.892
[49,     3] loss: 0.991
[50,     3] loss: 0.910
[51,     3] loss: 0.926
[52,     3] loss: 0.889
[53,     3] loss: 0.878
[54,     3] loss: 0.856
[55,     3] loss: 0.840
[56,     3] loss: 0.885
[57,     3] loss: 0.838
[58,     3] loss: 0.903
[59,     3] loss: 0.782
[60,     3] loss: 0.960
[61,     3] loss: 0.932
[62,     3] loss: 0.912
[63,     3] loss: 0.878
[64,     3] loss: 0.864
[65,     3] loss: 0.841
[66,     3] loss: 0.876
[67,     3] loss: 0.930
[68,     3] loss: 0.824
[69,     3] loss: 0.772
[70,     3] loss: 0.810
[71,     3] loss: 0.803
[72,     3] loss: 0.771
[73,     3] loss: 0.903
Early stopping applied (best metric=0.49921587109565735)
Finished Training
Total time taken: 16.33803963661194
{'S-palmitoylation-C Validation Accuracy': 0.6708937472037909, 'S-palmitoylation-C Validation Sensitivity': 0.28805280528052807, 'S-palmitoylation-C Validation Specificity': 0.7668544834627418, 'S-palmitoylation-C Validation Precision': 0.24331552457218333, 'S-palmitoylation-C AUC ROC': 0.5518360481372061, 'S-palmitoylation-C AUC PR': 0.23116377928687945, 'S-palmitoylation-C MCC': 0.05408848966959794, 'S-palmitoylation-C F1': 0.24421554844157117, 'Validation Loss (S-palmitoylation-C)': 0.5530474384625753, 'Hydroxylation-K Validation Accuracy': 0.6927304964539007, 'Hydroxylation-K Validation Sensitivity': 0.7933333333333333, 'Hydroxylation-K Validation Specificity': 0.6684210526315789, 'Hydroxylation-K Validation Precision': 0.3948843116964559, 'Hydroxylation-K AUC ROC': 0.8083820662768031, 'Hydroxylation-K AUC PR': 0.5566749180060372, 'Hydroxylation-K MCC': 0.38767571138870943, 'Hydroxylation-K F1': 0.5162383964338424, 'Validation Loss (Hydroxylation-K)': 0.5204568962256114, 'Validation Loss (total)': 1.073504344622294, 'TimeToTrain': 17.099225107828776}
{'CNNType': 'Musite',
 'CV_Repeats': 5,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_S-palmitoylation-C': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_S-palmitoylation-C': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['balanced', 'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010009716998232807,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3032824221609758,
 'loss_weight_S-palmitoylation-C': 0.9443880638805753,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1035814335,
 'sample_weights': [0.4946037492225299, 0.385480255300075],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7577645893492235,
 'weight_decay_Hydroxylation-K': 2.560335480400073,
 'weight_decay_S-palmitoylation-C': 0.21560639276347213}
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.384
[3,     3] loss: 1.380
[4,     3] loss: 1.384
[5,     3] loss: 1.385
[6,     3] loss: 1.365
[7,     3] loss: 1.372
[8,     3] loss: 1.376
[9,     3] loss: 1.360
[10,     3] loss: 1.333
[11,     3] loss: 1.350
[12,     3] loss: 1.342
[13,     3] loss: 1.347
[14,     3] loss: 1.255
[15,     3] loss: 1.294
[16,     3] loss: 1.191
[17,     3] loss: 1.241
[18,     3] loss: 1.288
[19,     3] loss: 1.163
[20,     3] loss: 1.091
[21,     3] loss: 1.087
[22,     3] loss: 1.052
[23,     3] loss: 0.981
[24,     3] loss: 1.072
[25,     3] loss: 1.007
[26,     3] loss: 1.075
[27,     3] loss: 1.094
[28,     3] loss: 1.047
[29,     3] loss: 0.970
[30,     3] loss: 0.966
[31,     3] loss: 1.037
[32,     3] loss: 1.090
[33,     3] loss: 0.989
[34,     3] loss: 0.921
[35,     3] loss: 0.925
[36,     3] loss: 1.010
[37,     3] loss: 1.083
[38,     3] loss: 0.861
[39,     3] loss: 0.920
[40,     3] loss: 0.967
[41,     3] loss: 0.883
[42,     3] loss: 1.022
[43,     3] loss: 0.866
[44,     3] loss: 0.890
[45,     3] loss: 0.969
[46,     3] loss: 0.880
[47,     3] loss: 0.847
[48,     3] loss: 0.905
[49,     3] loss: 0.889
[50,     3] loss: 0.828
[51,     3] loss: 0.816
[52,     3] loss: 0.817
[53,     3] loss: 0.800
[54,     3] loss: 0.841
[55,     3] loss: 0.776
[56,     3] loss: 0.815
[57,     3] loss: 0.816
[58,     3] loss: 0.784
[59,     3] loss: 0.769
[60,     3] loss: 0.807
[61,     3] loss: 0.746
[62,     3] loss: 0.772
[63,     3] loss: 0.781
[64,     3] loss: 0.765
[65,     3] loss: 0.759
[66,     3] loss: 0.739
[67,     3] loss: 0.744
[68,     3] loss: 0.729
[69,     3] loss: 0.772
[70,     3] loss: 0.734
[71,     3] loss: 0.742
[72,     3] loss: 0.811
[73,     3] loss: 0.722
[74,     3] loss: 0.834
Early stopping applied (best metric=0.49688422679901123)
Finished Training
Total time taken: 17.39204430580139
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.379
[3,     3] loss: 1.402
[4,     3] loss: 1.392
[5,     3] loss: 1.382
[6,     3] loss: 1.387
[7,     3] loss: 1.389
[8,     3] loss: 1.382
[9,     3] loss: 1.385
[10,     3] loss: 1.381
[11,     3] loss: 1.376
[12,     3] loss: 1.382
[13,     3] loss: 1.370
[14,     3] loss: 1.370
[15,     3] loss: 1.357
[16,     3] loss: 1.350
[17,     3] loss: 1.361
[18,     3] loss: 1.309
[19,     3] loss: 1.309
[20,     3] loss: 1.278
[21,     3] loss: 1.258
[22,     3] loss: 1.317
[23,     3] loss: 1.235
[24,     3] loss: 1.145
[25,     3] loss: 1.180
[26,     3] loss: 1.192
[27,     3] loss: 1.148
[28,     3] loss: 1.099
[29,     3] loss: 1.093
[30,     3] loss: 1.063
[31,     3] loss: 1.098
[32,     3] loss: 1.105
[33,     3] loss: 1.039
[34,     3] loss: 0.955
[35,     3] loss: 0.983
[36,     3] loss: 1.020
[37,     3] loss: 0.932
[38,     3] loss: 0.954
[39,     3] loss: 0.951
[40,     3] loss: 0.954
[41,     3] loss: 0.933
[42,     3] loss: 1.030
[43,     3] loss: 0.894
[44,     3] loss: 0.989
[45,     3] loss: 0.898
[46,     3] loss: 0.840
[47,     3] loss: 0.868
[48,     3] loss: 0.823
[49,     3] loss: 0.908
[50,     3] loss: 0.998
[51,     3] loss: 0.882
[52,     3] loss: 0.861
[53,     3] loss: 0.949
[54,     3] loss: 0.916
[55,     3] loss: 0.877
[56,     3] loss: 0.864
[57,     3] loss: 0.838
[58,     3] loss: 0.902
[59,     3] loss: 0.842
[60,     3] loss: 0.790
[61,     3] loss: 0.809
[62,     3] loss: 0.809
[63,     3] loss: 0.840
[64,     3] loss: 0.772
[65,     3] loss: 0.798
[66,     3] loss: 0.758
[67,     3] loss: 0.757
[68,     3] loss: 0.760
[69,     3] loss: 0.768
[70,     3] loss: 0.739
[71,     3] loss: 0.785
[72,     3] loss: 0.753
[73,     3] loss: 0.770
[74,     3] loss: 0.793
[75,     3] loss: 0.804
[76,     3] loss: 0.792
[77,     3] loss: 0.777
Early stopping applied (best metric=0.47312673926353455)
Finished Training
Total time taken: 18.07304310798645
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.400
[2,     3] loss: 1.383
[3,     3] loss: 1.383
[4,     3] loss: 1.381
[5,     3] loss: 1.386
[6,     3] loss: 1.390
[7,     3] loss: 1.391
[8,     3] loss: 1.383
[9,     3] loss: 1.385
[10,     3] loss: 1.384
[11,     3] loss: 1.378
[12,     3] loss: 1.372
[13,     3] loss: 1.370
[14,     3] loss: 1.377
[15,     3] loss: 1.374
[16,     3] loss: 1.351
[17,     3] loss: 1.326
[18,     3] loss: 1.306
[19,     3] loss: 1.325
[20,     3] loss: 1.264
[21,     3] loss: 1.247
[22,     3] loss: 1.255
[23,     3] loss: 1.167
[24,     3] loss: 1.154
[25,     3] loss: 1.105
[26,     3] loss: 1.158
[27,     3] loss: 1.134
[28,     3] loss: 1.039
[29,     3] loss: 1.112
[30,     3] loss: 0.940
[31,     3] loss: 1.055
[32,     3] loss: 1.032
[33,     3] loss: 0.980
[34,     3] loss: 0.966
[35,     3] loss: 0.938
[36,     3] loss: 0.966
[37,     3] loss: 0.955
[38,     3] loss: 0.913
[39,     3] loss: 0.914
[40,     3] loss: 0.960
[41,     3] loss: 0.869
[42,     3] loss: 1.014
[43,     3] loss: 0.932
[44,     3] loss: 0.907
[45,     3] loss: 0.983
[46,     3] loss: 0.933
[47,     3] loss: 0.929
[48,     3] loss: 0.859
[49,     3] loss: 0.816
[50,     3] loss: 0.919
[51,     3] loss: 0.879
[52,     3] loss: 0.800
[53,     3] loss: 0.799
[54,     3] loss: 0.853
[55,     3] loss: 0.795
[56,     3] loss: 0.778
[57,     3] loss: 0.820
[58,     3] loss: 0.777
[59,     3] loss: 0.763
[60,     3] loss: 0.779
[61,     3] loss: 0.831
[62,     3] loss: 0.773
[63,     3] loss: 0.741
[64,     3] loss: 0.822
[65,     3] loss: 0.779
[66,     3] loss: 0.803
[67,     3] loss: 0.782
[68,     3] loss: 0.790
[69,     3] loss: 0.733
[70,     3] loss: 0.811
[71,     3] loss: 0.844
[72,     3] loss: 0.760
[73,     3] loss: 0.758
[74,     3] loss: 0.798
[75,     3] loss: 0.808
[76,     3] loss: 0.742
[77,     3] loss: 0.804
Early stopping applied (best metric=0.49468088150024414)
Finished Training
Total time taken: 18.1170437335968
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.392
[2,     3] loss: 1.390
[3,     3] loss: 1.394
[4,     3] loss: 1.392
[5,     3] loss: 1.383
[6,     3] loss: 1.382
[7,     3] loss: 1.385
[8,     3] loss: 1.377
[9,     3] loss: 1.388
[10,     3] loss: 1.383
[11,     3] loss: 1.392
[12,     3] loss: 1.382
[13,     3] loss: 1.396
[14,     3] loss: 1.385
[15,     3] loss: 1.384
[16,     3] loss: 1.378
[17,     3] loss: 1.375
[18,     3] loss: 1.370
[19,     3] loss: 1.355
[20,     3] loss: 1.352
[21,     3] loss: 1.333
[22,     3] loss: 1.290
[23,     3] loss: 1.288
[24,     3] loss: 1.205
[25,     3] loss: 1.180
[26,     3] loss: 1.172
[27,     3] loss: 1.169
[28,     3] loss: 1.059
[29,     3] loss: 1.134
[30,     3] loss: 1.107
[31,     3] loss: 1.083
[32,     3] loss: 1.067
[33,     3] loss: 1.034
[34,     3] loss: 1.034
[35,     3] loss: 1.045
[36,     3] loss: 1.116
[37,     3] loss: 0.918
[38,     3] loss: 1.058
[39,     3] loss: 0.900
[40,     3] loss: 0.975
[41,     3] loss: 0.905
[42,     3] loss: 0.936
[43,     3] loss: 0.933
[44,     3] loss: 1.005
[45,     3] loss: 0.846
[46,     3] loss: 0.912
[47,     3] loss: 0.803
[48,     3] loss: 0.931
[49,     3] loss: 0.952
[50,     3] loss: 1.047
[51,     3] loss: 0.929
[52,     3] loss: 0.931
[53,     3] loss: 0.951
[54,     3] loss: 0.805
[55,     3] loss: 0.809
[56,     3] loss: 0.915
[57,     3] loss: 0.877
[58,     3] loss: 0.853
[59,     3] loss: 0.832
[60,     3] loss: 0.833
[61,     3] loss: 0.833
[62,     3] loss: 0.814
[63,     3] loss: 0.845
[64,     3] loss: 0.879
[65,     3] loss: 0.789
[66,     3] loss: 0.790
[67,     3] loss: 0.776
[68,     3] loss: 0.822
[69,     3] loss: 0.888
[70,     3] loss: 0.771
[71,     3] loss: 0.773
[72,     3] loss: 0.794
[73,     3] loss: 0.758
[74,     3] loss: 0.760
[75,     3] loss: 0.898
[76,     3] loss: 0.789
[77,     3] loss: 0.741
[78,     3] loss: 0.794
[79,     3] loss: 0.743
[80,     3] loss: 0.753
[81,     3] loss: 0.753
[82,     3] loss: 0.761
[83,     3] loss: 0.780
[84,     3] loss: 0.744
[85,     3] loss: 0.862
[86,     3] loss: 0.849
[87,     3] loss: 0.798
[88,     3] loss: 0.833
[89,     3] loss: 0.757
[90,     3] loss: 0.821
[91,     3] loss: 0.938
[92,     3] loss: 0.763
[93,     3] loss: 0.870
[94,     3] loss: 0.754
[95,     3] loss: 0.762
[96,     3] loss: 0.785
[97,     3] loss: 0.752
Early stopping applied (best metric=0.5033509135246277)
Finished Training
Total time taken: 22.87805676460266
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.395
[3,     3] loss: 1.382
[4,     3] loss: 1.402
[5,     3] loss: 1.371
[6,     3] loss: 1.376
[7,     3] loss: 1.375
[8,     3] loss: 1.375
[9,     3] loss: 1.359
[10,     3] loss: 1.352
[11,     3] loss: 1.340
[12,     3] loss: 1.323
[13,     3] loss: 1.311
[14,     3] loss: 1.244
[15,     3] loss: 1.215
[16,     3] loss: 1.247
[17,     3] loss: 1.191
[18,     3] loss: 1.171
[19,     3] loss: 1.143
[20,     3] loss: 1.227
[21,     3] loss: 1.162
[22,     3] loss: 1.054
[23,     3] loss: 1.155
[24,     3] loss: 1.012
[25,     3] loss: 1.046
[26,     3] loss: 1.043
[27,     3] loss: 1.030
[28,     3] loss: 1.015
[29,     3] loss: 0.981
[30,     3] loss: 1.009
[31,     3] loss: 1.025
[32,     3] loss: 0.939
[33,     3] loss: 0.955
[34,     3] loss: 0.963
[35,     3] loss: 0.889
[36,     3] loss: 0.907
[37,     3] loss: 0.920
[38,     3] loss: 0.962
[39,     3] loss: 0.887
[40,     3] loss: 0.933
[41,     3] loss: 0.855
[42,     3] loss: 0.839
[43,     3] loss: 0.937
[44,     3] loss: 0.882
[45,     3] loss: 0.834
[46,     3] loss: 0.814
[47,     3] loss: 0.795
[48,     3] loss: 0.805
[49,     3] loss: 0.885
[50,     3] loss: 0.825
[51,     3] loss: 0.870
[52,     3] loss: 0.826
[53,     3] loss: 0.798
[54,     3] loss: 0.823
[55,     3] loss: 0.818
[56,     3] loss: 0.766
[57,     3] loss: 0.818
[58,     3] loss: 0.854
[59,     3] loss: 0.858
[60,     3] loss: 0.771
[61,     3] loss: 0.934
[62,     3] loss: 0.826
[63,     3] loss: 0.880
[64,     3] loss: 0.857
[65,     3] loss: 0.790
[66,     3] loss: 0.801
[67,     3] loss: 0.783
[68,     3] loss: 0.846
[69,     3] loss: 0.833
[70,     3] loss: 0.755
[71,     3] loss: 0.735
[72,     3] loss: 0.786
[73,     3] loss: 0.735
[74,     3] loss: 0.739
[75,     3] loss: 0.739
Early stopping applied (best metric=0.4975029528141022)
Finished Training
Total time taken: 17.78204584121704
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.412
[3,     3] loss: 1.392
[4,     3] loss: 1.397
[5,     3] loss: 1.391
[6,     3] loss: 1.390
[7,     3] loss: 1.385
[8,     3] loss: 1.382
[9,     3] loss: 1.396
[10,     3] loss: 1.386
[11,     3] loss: 1.381
[12,     3] loss: 1.375
[13,     3] loss: 1.379
[14,     3] loss: 1.377
[15,     3] loss: 1.365
[16,     3] loss: 1.368
[17,     3] loss: 1.351
[18,     3] loss: 1.364
[19,     3] loss: 1.324
[20,     3] loss: 1.285
[21,     3] loss: 1.320
[22,     3] loss: 1.244
[23,     3] loss: 1.222
[24,     3] loss: 1.177
[25,     3] loss: 1.184
[26,     3] loss: 1.142
[27,     3] loss: 1.166
[28,     3] loss: 1.179
[29,     3] loss: 1.018
[30,     3] loss: 1.146
[31,     3] loss: 1.003
[32,     3] loss: 1.061
[33,     3] loss: 1.009
[34,     3] loss: 1.042
[35,     3] loss: 0.986
[36,     3] loss: 0.958
[37,     3] loss: 0.937
[38,     3] loss: 0.898
[39,     3] loss: 0.929
[40,     3] loss: 0.940
[41,     3] loss: 0.963
[42,     3] loss: 0.978
[43,     3] loss: 0.965
[44,     3] loss: 0.846
[45,     3] loss: 0.923
[46,     3] loss: 0.894
[47,     3] loss: 0.927
[48,     3] loss: 0.876
[49,     3] loss: 0.963
[50,     3] loss: 0.830
[51,     3] loss: 0.866
[52,     3] loss: 0.858
[53,     3] loss: 0.786
[54,     3] loss: 0.792
[55,     3] loss: 0.889
[56,     3] loss: 0.853
[57,     3] loss: 0.837
[58,     3] loss: 0.826
[59,     3] loss: 0.848
[60,     3] loss: 0.857
[61,     3] loss: 0.853
[62,     3] loss: 0.796
[63,     3] loss: 0.832
[64,     3] loss: 0.785
[65,     3] loss: 0.800
[66,     3] loss: 0.789
[67,     3] loss: 0.802
[68,     3] loss: 0.856
[69,     3] loss: 0.801
[70,     3] loss: 0.827
[71,     3] loss: 0.763
[72,     3] loss: 0.795
[73,     3] loss: 0.931
[74,     3] loss: 0.808
[75,     3] loss: 0.871
[76,     3] loss: 0.814
[77,     3] loss: 0.777
[78,     3] loss: 0.781
Early stopping applied (best metric=0.5276973247528076)
Finished Training
Total time taken: 18.523048400878906
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.388
[3,     3] loss: 1.380
[4,     3] loss: 1.392
[5,     3] loss: 1.389
[6,     3] loss: 1.388
[7,     3] loss: 1.387
[8,     3] loss: 1.386
[9,     3] loss: 1.391
[10,     3] loss: 1.383
[11,     3] loss: 1.387
[12,     3] loss: 1.384
[13,     3] loss: 1.386
[14,     3] loss: 1.382
[15,     3] loss: 1.378
[16,     3] loss: 1.369
[17,     3] loss: 1.370
[18,     3] loss: 1.360
[19,     3] loss: 1.339
[20,     3] loss: 1.340
[21,     3] loss: 1.320
[22,     3] loss: 1.318
[23,     3] loss: 1.306
[24,     3] loss: 1.268
[25,     3] loss: 1.238
[26,     3] loss: 1.233
[27,     3] loss: 1.150
[28,     3] loss: 1.138
[29,     3] loss: 1.114
[30,     3] loss: 1.022
[31,     3] loss: 1.104
[32,     3] loss: 1.080
[33,     3] loss: 1.024
[34,     3] loss: 1.032
[35,     3] loss: 1.030
[36,     3] loss: 1.024
[37,     3] loss: 0.997
[38,     3] loss: 0.965
[39,     3] loss: 0.936
[40,     3] loss: 0.850
[41,     3] loss: 0.990
[42,     3] loss: 0.903
[43,     3] loss: 0.870
[44,     3] loss: 0.858
[45,     3] loss: 0.882
[46,     3] loss: 0.848
[47,     3] loss: 0.839
[48,     3] loss: 0.970
[49,     3] loss: 0.821
[50,     3] loss: 0.835
[51,     3] loss: 0.835
[52,     3] loss: 0.843
[53,     3] loss: 0.811
[54,     3] loss: 0.905
[55,     3] loss: 0.845
[56,     3] loss: 0.848
[57,     3] loss: 0.819
[58,     3] loss: 0.933
[59,     3] loss: 0.869
[60,     3] loss: 0.792
[61,     3] loss: 0.826
[62,     3] loss: 0.803
[63,     3] loss: 0.858
[64,     3] loss: 0.936
[65,     3] loss: 0.802
[66,     3] loss: 0.889
[67,     3] loss: 0.865
[68,     3] loss: 0.776
[69,     3] loss: 0.802
[70,     3] loss: 0.762
[71,     3] loss: 0.778
[72,     3] loss: 0.798
[73,     3] loss: 0.767
[74,     3] loss: 0.736
[75,     3] loss: 0.753
[76,     3] loss: 0.727
[77,     3] loss: 0.737
[78,     3] loss: 0.739
[79,     3] loss: 0.758
[80,     3] loss: 0.835
[81,     3] loss: 0.743
[82,     3] loss: 0.722
[83,     3] loss: 0.719
[84,     3] loss: 0.732
[85,     3] loss: 0.720
[86,     3] loss: 0.732
[87,     3] loss: 0.811
[88,     3] loss: 0.725
[89,     3] loss: 0.872
[90,     3] loss: 0.752
[91,     3] loss: 0.737
[92,     3] loss: 0.735
[93,     3] loss: 0.729
[94,     3] loss: 0.750
[95,     3] loss: 0.742
[96,     3] loss: 0.749
[97,     3] loss: 0.715
[98,     3] loss: 0.736
[99,     3] loss: 0.731
[100,     3] loss: 0.726
[101,     3] loss: 0.798
[102,     3] loss: 0.796
Early stopping applied (best metric=0.5097775459289551)
Finished Training
Total time taken: 24.1370587348938
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.390
[3,     3] loss: 1.383
[4,     3] loss: 1.380
[5,     3] loss: 1.379
[6,     3] loss: 1.373
[7,     3] loss: 1.390
[8,     3] loss: 1.374
[9,     3] loss: 1.378
[10,     3] loss: 1.355
[11,     3] loss: 1.337
[12,     3] loss: 1.317
[13,     3] loss: 1.297
[14,     3] loss: 1.275
[15,     3] loss: 1.274
[16,     3] loss: 1.184
[17,     3] loss: 1.186
[18,     3] loss: 1.183
[19,     3] loss: 1.100
[20,     3] loss: 1.186
[21,     3] loss: 1.054
[22,     3] loss: 1.080
[23,     3] loss: 1.068
[24,     3] loss: 1.155
[25,     3] loss: 1.004
[26,     3] loss: 1.095
[27,     3] loss: 1.105
[28,     3] loss: 1.007
[29,     3] loss: 0.956
[30,     3] loss: 0.959
[31,     3] loss: 0.952
[32,     3] loss: 0.937
[33,     3] loss: 0.957
[34,     3] loss: 1.017
[35,     3] loss: 1.049
[36,     3] loss: 1.007
[37,     3] loss: 1.034
[38,     3] loss: 0.872
[39,     3] loss: 0.991
[40,     3] loss: 0.938
[41,     3] loss: 0.906
[42,     3] loss: 0.889
[43,     3] loss: 0.915
[44,     3] loss: 0.848
[45,     3] loss: 0.847
[46,     3] loss: 0.800
[47,     3] loss: 0.824
[48,     3] loss: 0.847
[49,     3] loss: 0.823
[50,     3] loss: 0.816
[51,     3] loss: 0.802
[52,     3] loss: 0.813
[53,     3] loss: 0.915
[54,     3] loss: 0.979
[55,     3] loss: 0.795
[56,     3] loss: 0.884
[57,     3] loss: 0.779
[58,     3] loss: 0.845
[59,     3] loss: 0.827
[60,     3] loss: 0.761
[61,     3] loss: 0.788
[62,     3] loss: 0.851
[63,     3] loss: 0.733
[64,     3] loss: 0.786
[65,     3] loss: 0.773
[66,     3] loss: 0.796
[67,     3] loss: 0.763
[68,     3] loss: 0.766
[69,     3] loss: 0.806
[70,     3] loss: 0.917
[71,     3] loss: 0.859
[72,     3] loss: 0.798
[73,     3] loss: 0.939
[74,     3] loss: 0.855
[75,     3] loss: 0.844
[76,     3] loss: 0.783
[77,     3] loss: 0.814
[78,     3] loss: 0.778
[79,     3] loss: 0.763
[80,     3] loss: 0.823
[81,     3] loss: 0.790
[82,     3] loss: 0.766
[83,     3] loss: 0.824
[84,     3] loss: 0.773
[85,     3] loss: 0.761
[86,     3] loss: 0.809
[87,     3] loss: 0.825
[88,     3] loss: 0.775
[89,     3] loss: 0.746
[90,     3] loss: 0.742
Early stopping applied (best metric=0.5271220207214355)
Finished Training
Total time taken: 21.4150493144989
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.380
[3,     3] loss: 1.384
[4,     3] loss: 1.384
[5,     3] loss: 1.375
[6,     3] loss: 1.370
[7,     3] loss: 1.360
[8,     3] loss: 1.344
[9,     3] loss: 1.335
[10,     3] loss: 1.296
[11,     3] loss: 1.278
[12,     3] loss: 1.245
[13,     3] loss: 1.241
[14,     3] loss: 1.205
[15,     3] loss: 1.122
[16,     3] loss: 1.132
[17,     3] loss: 1.103
[18,     3] loss: 1.015
[19,     3] loss: 1.052
[20,     3] loss: 1.116
[21,     3] loss: 0.981
[22,     3] loss: 1.015
[23,     3] loss: 0.940
[24,     3] loss: 0.990
[25,     3] loss: 0.957
[26,     3] loss: 0.935
[27,     3] loss: 1.015
[28,     3] loss: 1.043
[29,     3] loss: 0.940
[30,     3] loss: 0.912
[31,     3] loss: 1.051
[32,     3] loss: 0.901
[33,     3] loss: 0.947
[34,     3] loss: 0.855
[35,     3] loss: 0.867
[36,     3] loss: 0.905
[37,     3] loss: 0.836
[38,     3] loss: 0.839
[39,     3] loss: 0.824
[40,     3] loss: 0.790
[41,     3] loss: 0.794
[42,     3] loss: 0.786
[43,     3] loss: 0.780
[44,     3] loss: 0.744
[45,     3] loss: 0.745
[46,     3] loss: 0.752
[47,     3] loss: 0.749
[48,     3] loss: 0.751
[49,     3] loss: 0.759
[50,     3] loss: 0.752
[51,     3] loss: 0.760
[52,     3] loss: 0.765
[53,     3] loss: 0.778
[54,     3] loss: 0.772
[55,     3] loss: 0.812
[56,     3] loss: 0.754
[57,     3] loss: 0.747
[58,     3] loss: 0.733
[59,     3] loss: 0.730
[60,     3] loss: 0.818
[61,     3] loss: 0.898
[62,     3] loss: 0.799
[63,     3] loss: 0.917
[64,     3] loss: 0.902
[65,     3] loss: 0.806
[66,     3] loss: 0.816
[67,     3] loss: 0.825
[68,     3] loss: 0.801
[69,     3] loss: 0.796
[70,     3] loss: 0.776
[71,     3] loss: 0.754
Early stopping applied (best metric=0.5120078325271606)
Finished Training
Total time taken: 16.926040649414062
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.387
[3,     3] loss: 1.380
[4,     3] loss: 1.383
[5,     3] loss: 1.366
[6,     3] loss: 1.384
[7,     3] loss: 1.379
[8,     3] loss: 1.378
[9,     3] loss: 1.380
[10,     3] loss: 1.378
[11,     3] loss: 1.355
[12,     3] loss: 1.329
[13,     3] loss: 1.322
[14,     3] loss: 1.294
[15,     3] loss: 1.309
[16,     3] loss: 1.209
[17,     3] loss: 1.193
[18,     3] loss: 1.169
[19,     3] loss: 1.080
[20,     3] loss: 1.078
[21,     3] loss: 1.029
[22,     3] loss: 1.075
[23,     3] loss: 1.069
[24,     3] loss: 1.016
[25,     3] loss: 1.043
[26,     3] loss: 0.939
[27,     3] loss: 1.010
[28,     3] loss: 0.977
[29,     3] loss: 0.959
[30,     3] loss: 0.941
[31,     3] loss: 0.894
[32,     3] loss: 0.914
[33,     3] loss: 0.879
[34,     3] loss: 0.909
[35,     3] loss: 0.848
[36,     3] loss: 0.884
[37,     3] loss: 0.851
[38,     3] loss: 0.905
[39,     3] loss: 0.922
[40,     3] loss: 0.880
[41,     3] loss: 0.804
[42,     3] loss: 0.884
[43,     3] loss: 0.818
[44,     3] loss: 0.777
[45,     3] loss: 0.865
[46,     3] loss: 0.846
[47,     3] loss: 0.918
[48,     3] loss: 0.809
[49,     3] loss: 0.885
[50,     3] loss: 0.797
[51,     3] loss: 0.841
[52,     3] loss: 0.790
[53,     3] loss: 0.766
[54,     3] loss: 0.798
[55,     3] loss: 0.763
[56,     3] loss: 0.741
[57,     3] loss: 0.849
[58,     3] loss: 0.824
[59,     3] loss: 0.768
[60,     3] loss: 0.796
[61,     3] loss: 0.791
[62,     3] loss: 0.762
[63,     3] loss: 0.976
[64,     3] loss: 0.979
[65,     3] loss: 0.846
[66,     3] loss: 0.934
[67,     3] loss: 0.885
[68,     3] loss: 0.778
[69,     3] loss: 0.802
[70,     3] loss: 0.786
[71,     3] loss: 0.773
[72,     3] loss: 0.766
[73,     3] loss: 0.750
[74,     3] loss: 0.750
[75,     3] loss: 0.738
Early stopping applied (best metric=0.4993111193180084)
Finished Training
Total time taken: 18.06604313850403
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.384
[2,     3] loss: 1.385
[3,     3] loss: 1.379
[4,     3] loss: 1.387
[5,     3] loss: 1.379
[6,     3] loss: 1.383
[7,     3] loss: 1.382
[8,     3] loss: 1.362
[9,     3] loss: 1.360
[10,     3] loss: 1.349
[11,     3] loss: 1.334
[12,     3] loss: 1.299
[13,     3] loss: 1.309
[14,     3] loss: 1.240
[15,     3] loss: 1.292
[16,     3] loss: 1.243
[17,     3] loss: 1.210
[18,     3] loss: 1.184
[19,     3] loss: 1.156
[20,     3] loss: 1.151
[21,     3] loss: 1.109
[22,     3] loss: 1.161
[23,     3] loss: 1.088
[24,     3] loss: 1.235
[25,     3] loss: 1.084
[26,     3] loss: 1.068
[27,     3] loss: 1.022
[28,     3] loss: 0.988
[29,     3] loss: 1.028
[30,     3] loss: 1.016
[31,     3] loss: 0.998
[32,     3] loss: 0.971
[33,     3] loss: 0.990
[34,     3] loss: 0.963
[35,     3] loss: 0.891
[36,     3] loss: 0.947
[37,     3] loss: 0.936
[38,     3] loss: 0.916
[39,     3] loss: 0.915
[40,     3] loss: 1.132
[41,     3] loss: 0.874
[42,     3] loss: 0.913
[43,     3] loss: 1.021
[44,     3] loss: 0.905
[45,     3] loss: 1.082
[46,     3] loss: 0.984
[47,     3] loss: 0.943
[48,     3] loss: 0.992
[49,     3] loss: 0.928
[50,     3] loss: 0.978
[51,     3] loss: 0.963
[52,     3] loss: 0.875
[53,     3] loss: 0.895
[54,     3] loss: 0.848
[55,     3] loss: 0.836
[56,     3] loss: 0.885
[57,     3] loss: 0.811
[58,     3] loss: 0.818
[59,     3] loss: 0.821
[60,     3] loss: 0.796
[61,     3] loss: 0.883
[62,     3] loss: 0.810
[63,     3] loss: 0.790
[64,     3] loss: 0.775
[65,     3] loss: 0.797
[66,     3] loss: 0.787
[67,     3] loss: 0.764
[68,     3] loss: 0.775
[69,     3] loss: 0.758
[70,     3] loss: 0.855
[71,     3] loss: 0.823
[72,     3] loss: 0.835
[73,     3] loss: 0.756
[74,     3] loss: 0.924
[75,     3] loss: 0.875
[76,     3] loss: 0.938
[77,     3] loss: 0.904
[78,     3] loss: 0.831
[79,     3] loss: 0.792
[80,     3] loss: 0.798
[81,     3] loss: 0.839
[82,     3] loss: 0.769
[83,     3] loss: 0.790
[84,     3] loss: 0.815
[85,     3] loss: 0.754
[86,     3] loss: 0.779
[87,     3] loss: 0.793
[88,     3] loss: 0.817
[89,     3] loss: 0.740
[90,     3] loss: 0.748
[91,     3] loss: 0.827
[92,     3] loss: 0.757
[93,     3] loss: 0.733
[94,     3] loss: 0.761
[95,     3] loss: 0.732
[96,     3] loss: 0.831
[97,     3] loss: 0.728
[98,     3] loss: 0.773
[99,     3] loss: 0.743
[100,     3] loss: 0.750
[101,     3] loss: 0.727
[102,     3] loss: 0.733
[103,     3] loss: 0.827
[104,     3] loss: 0.752
[105,     3] loss: 0.748
[106,     3] loss: 0.755
[107,     3] loss: 0.762
[108,     3] loss: 0.733
[109,     3] loss: 0.726
[110,     3] loss: 0.791
[111,     3] loss: 0.763
Early stopping applied (best metric=0.5211927890777588)
Finished Training
Total time taken: 26.63606572151184
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.384
[3,     3] loss: 1.383
[4,     3] loss: 1.383
[5,     3] loss: 1.379
[6,     3] loss: 1.377
[7,     3] loss: 1.381
[8,     3] loss: 1.377
[9,     3] loss: 1.350
[10,     3] loss: 1.350
[11,     3] loss: 1.337
[12,     3] loss: 1.321
[13,     3] loss: 1.309
[14,     3] loss: 1.275
[15,     3] loss: 1.242
[16,     3] loss: 1.205
[17,     3] loss: 1.202
[18,     3] loss: 1.188
[19,     3] loss: 1.185
[20,     3] loss: 1.131
[21,     3] loss: 1.117
[22,     3] loss: 1.136
[23,     3] loss: 1.160
[24,     3] loss: 1.044
[25,     3] loss: 0.996
[26,     3] loss: 1.092
[27,     3] loss: 1.018
[28,     3] loss: 0.983
[29,     3] loss: 1.024
[30,     3] loss: 1.085
[31,     3] loss: 0.945
[32,     3] loss: 0.950
[33,     3] loss: 0.940
[34,     3] loss: 0.921
[35,     3] loss: 0.907
[36,     3] loss: 0.946
[37,     3] loss: 0.959
[38,     3] loss: 0.881
[39,     3] loss: 0.945
[40,     3] loss: 0.990
[41,     3] loss: 0.827
[42,     3] loss: 1.005
[43,     3] loss: 0.840
[44,     3] loss: 0.854
[45,     3] loss: 0.879
[46,     3] loss: 0.813
[47,     3] loss: 0.849
[48,     3] loss: 0.828
[49,     3] loss: 0.775
[50,     3] loss: 0.905
[51,     3] loss: 0.848
[52,     3] loss: 0.809
[53,     3] loss: 0.762
[54,     3] loss: 0.767
[55,     3] loss: 0.777
[56,     3] loss: 0.752
[57,     3] loss: 0.803
[58,     3] loss: 0.809
[59,     3] loss: 0.746
[60,     3] loss: 0.758
[61,     3] loss: 0.766
[62,     3] loss: 0.762
[63,     3] loss: 0.726
[64,     3] loss: 0.725
[65,     3] loss: 0.750
[66,     3] loss: 0.802
[67,     3] loss: 0.788
[68,     3] loss: 0.826
[69,     3] loss: 0.762
[70,     3] loss: 0.802
[71,     3] loss: 0.783
[72,     3] loss: 0.938
Early stopping applied (best metric=0.49139687418937683)
Finished Training
Total time taken: 17.446054697036743
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.396
[2,     3] loss: 1.384
[3,     3] loss: 1.396
[4,     3] loss: 1.384
[5,     3] loss: 1.382
[6,     3] loss: 1.392
[7,     3] loss: 1.387
[8,     3] loss: 1.375
[9,     3] loss: 1.373
[10,     3] loss: 1.375
[11,     3] loss: 1.371
[12,     3] loss: 1.365
[13,     3] loss: 1.353
[14,     3] loss: 1.344
[15,     3] loss: 1.321
[16,     3] loss: 1.351
[17,     3] loss: 1.265
[18,     3] loss: 1.258
[19,     3] loss: 1.229
[20,     3] loss: 1.217
[21,     3] loss: 1.184
[22,     3] loss: 1.122
[23,     3] loss: 1.138
[24,     3] loss: 1.158
[25,     3] loss: 1.110
[26,     3] loss: 1.098
[27,     3] loss: 1.016
[28,     3] loss: 1.059
[29,     3] loss: 0.966
[30,     3] loss: 0.919
[31,     3] loss: 0.886
[32,     3] loss: 0.961
[33,     3] loss: 0.896
[34,     3] loss: 0.886
[35,     3] loss: 0.875
[36,     3] loss: 0.844
[37,     3] loss: 0.899
[38,     3] loss: 0.853
[39,     3] loss: 0.869
[40,     3] loss: 0.921
[41,     3] loss: 0.947
[42,     3] loss: 0.946
[43,     3] loss: 0.885
[44,     3] loss: 0.835
[45,     3] loss: 0.846
[46,     3] loss: 0.822
[47,     3] loss: 0.811
[48,     3] loss: 0.852
[49,     3] loss: 0.818
[50,     3] loss: 0.781
[51,     3] loss: 0.793
[52,     3] loss: 0.782
[53,     3] loss: 0.783
[54,     3] loss: 0.800
[55,     3] loss: 0.805
[56,     3] loss: 0.787
[57,     3] loss: 0.800
[58,     3] loss: 0.739
[59,     3] loss: 0.745
[60,     3] loss: 0.847
[61,     3] loss: 0.961
[62,     3] loss: 0.780
[63,     3] loss: 0.764
[64,     3] loss: 0.735
[65,     3] loss: 0.873
[66,     3] loss: 0.869
[67,     3] loss: 0.813
[68,     3] loss: 0.775
[69,     3] loss: 0.797
[70,     3] loss: 0.771
[71,     3] loss: 0.759
[72,     3] loss: 0.813
[73,     3] loss: 0.789
[74,     3] loss: 0.749
[75,     3] loss: 0.759
Early stopping applied (best metric=0.5225870609283447)
Finished Training
Total time taken: 18.167651891708374
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.385
[2,     3] loss: 1.386
[3,     3] loss: 1.392
[4,     3] loss: 1.384
[5,     3] loss: 1.385
[6,     3] loss: 1.378
[7,     3] loss: 1.388
[8,     3] loss: 1.386
[9,     3] loss: 1.381
[10,     3] loss: 1.376
[11,     3] loss: 1.370
[12,     3] loss: 1.365
[13,     3] loss: 1.360
[14,     3] loss: 1.339
[15,     3] loss: 1.334
[16,     3] loss: 1.321
[17,     3] loss: 1.305
[18,     3] loss: 1.267
[19,     3] loss: 1.267
[20,     3] loss: 1.244
[21,     3] loss: 1.239
[22,     3] loss: 1.193
[23,     3] loss: 1.125
[24,     3] loss: 1.059
[25,     3] loss: 1.034
[26,     3] loss: 1.016
[27,     3] loss: 1.016
[28,     3] loss: 0.988
[29,     3] loss: 1.022
[30,     3] loss: 1.080
[31,     3] loss: 0.950
[32,     3] loss: 1.029
[33,     3] loss: 0.961
[34,     3] loss: 0.928
[35,     3] loss: 0.960
[36,     3] loss: 0.871
[37,     3] loss: 0.926
[38,     3] loss: 0.873
[39,     3] loss: 0.872
[40,     3] loss: 0.863
[41,     3] loss: 0.982
[42,     3] loss: 0.936
[43,     3] loss: 0.947
[44,     3] loss: 0.849
[45,     3] loss: 0.920
[46,     3] loss: 0.974
[47,     3] loss: 0.852
[48,     3] loss: 0.874
[49,     3] loss: 0.941
[50,     3] loss: 0.842
[51,     3] loss: 0.882
[52,     3] loss: 0.862
[53,     3] loss: 0.905
[54,     3] loss: 0.809
[55,     3] loss: 0.797
[56,     3] loss: 0.798
[57,     3] loss: 0.865
[58,     3] loss: 0.832
[59,     3] loss: 0.775
[60,     3] loss: 0.809
[61,     3] loss: 0.865
[62,     3] loss: 0.871
[63,     3] loss: 0.860
[64,     3] loss: 0.767
[65,     3] loss: 0.796
[66,     3] loss: 0.791
[67,     3] loss: 0.766
[68,     3] loss: 0.778
[69,     3] loss: 0.755
[70,     3] loss: 0.776
[71,     3] loss: 0.822
[72,     3] loss: 0.868
[73,     3] loss: 0.784
[74,     3] loss: 0.763
[75,     3] loss: 0.770
[76,     3] loss: 0.802
[77,     3] loss: 0.828
[78,     3] loss: 0.967
Early stopping applied (best metric=0.48237672448158264)
Finished Training
Total time taken: 18.86504578590393
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.390
[2,     3] loss: 1.387
[3,     3] loss: 1.391
[4,     3] loss: 1.370
[5,     3] loss: 1.387
[6,     3] loss: 1.372
[7,     3] loss: 1.360
[8,     3] loss: 1.350
[9,     3] loss: 1.342
[10,     3] loss: 1.305
[11,     3] loss: 1.289
[12,     3] loss: 1.285
[13,     3] loss: 1.317
[14,     3] loss: 1.221
[15,     3] loss: 1.213
[16,     3] loss: 1.237
[17,     3] loss: 1.228
[18,     3] loss: 1.190
[19,     3] loss: 1.177
[20,     3] loss: 1.130
[21,     3] loss: 1.081
[22,     3] loss: 1.096
[23,     3] loss: 1.153
[24,     3] loss: 1.050
[25,     3] loss: 1.062
[26,     3] loss: 1.044
[27,     3] loss: 1.084
[28,     3] loss: 0.972
[29,     3] loss: 1.067
[30,     3] loss: 1.044
[31,     3] loss: 0.952
[32,     3] loss: 0.940
[33,     3] loss: 1.009
[34,     3] loss: 0.965
[35,     3] loss: 0.905
[36,     3] loss: 0.951
[37,     3] loss: 0.912
[38,     3] loss: 0.905
[39,     3] loss: 0.869
[40,     3] loss: 1.003
[41,     3] loss: 0.856
[42,     3] loss: 0.868
[43,     3] loss: 0.864
[44,     3] loss: 0.844
[45,     3] loss: 0.813
[46,     3] loss: 0.799
[47,     3] loss: 0.947
[48,     3] loss: 0.783
[49,     3] loss: 0.783
[50,     3] loss: 0.777
[51,     3] loss: 0.775
[52,     3] loss: 0.793
[53,     3] loss: 0.767
[54,     3] loss: 0.754
[55,     3] loss: 0.807
[56,     3] loss: 0.802
[57,     3] loss: 0.765
[58,     3] loss: 0.864
[59,     3] loss: 0.747
[60,     3] loss: 0.773
[61,     3] loss: 0.937
[62,     3] loss: 0.901
[63,     3] loss: 0.774
[64,     3] loss: 0.803
[65,     3] loss: 0.816
[66,     3] loss: 0.813
[67,     3] loss: 0.777
[68,     3] loss: 0.765
[69,     3] loss: 0.772
[70,     3] loss: 0.759
[71,     3] loss: 0.766
[72,     3] loss: 0.753
[73,     3] loss: 0.773
[74,     3] loss: 0.769
[75,     3] loss: 0.810
[76,     3] loss: 0.760
[77,     3] loss: 0.719
[78,     3] loss: 0.758
Early stopping applied (best metric=0.4951605200767517)
Finished Training
Total time taken: 18.952048778533936
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.381
[2,     3] loss: 1.384
[3,     3] loss: 1.397
[4,     3] loss: 1.387
[5,     3] loss: 1.383
[6,     3] loss: 1.384
[7,     3] loss: 1.383
[8,     3] loss: 1.376
[9,     3] loss: 1.375
[10,     3] loss: 1.371
[11,     3] loss: 1.363
[12,     3] loss: 1.338
[13,     3] loss: 1.337
[14,     3] loss: 1.307
[15,     3] loss: 1.280
[16,     3] loss: 1.233
[17,     3] loss: 1.267
[18,     3] loss: 1.203
[19,     3] loss: 1.277
[20,     3] loss: 1.183
[21,     3] loss: 1.206
[22,     3] loss: 1.139
[23,     3] loss: 1.168
[24,     3] loss: 1.120
[25,     3] loss: 1.031
[26,     3] loss: 1.043
[27,     3] loss: 1.082
[28,     3] loss: 1.006
[29,     3] loss: 1.096
[30,     3] loss: 0.905
[31,     3] loss: 1.017
[32,     3] loss: 1.096
[33,     3] loss: 1.029
[34,     3] loss: 0.936
[35,     3] loss: 1.064
[36,     3] loss: 0.933
[37,     3] loss: 1.016
[38,     3] loss: 0.895
[39,     3] loss: 0.919
[40,     3] loss: 0.963
[41,     3] loss: 0.854
[42,     3] loss: 0.889
[43,     3] loss: 0.939
[44,     3] loss: 0.865
[45,     3] loss: 0.864
[46,     3] loss: 0.884
[47,     3] loss: 0.873
[48,     3] loss: 0.817
[49,     3] loss: 0.769
[50,     3] loss: 0.802
[51,     3] loss: 0.796
[52,     3] loss: 0.778
[53,     3] loss: 0.773
[54,     3] loss: 0.801
[55,     3] loss: 0.762
[56,     3] loss: 0.751
[57,     3] loss: 0.739
[58,     3] loss: 0.844
[59,     3] loss: 0.834
[60,     3] loss: 0.810
[61,     3] loss: 0.834
[62,     3] loss: 0.853
[63,     3] loss: 0.832
[64,     3] loss: 0.805
[65,     3] loss: 0.767
[66,     3] loss: 0.772
[67,     3] loss: 0.756
[68,     3] loss: 0.783
[69,     3] loss: 0.766
[70,     3] loss: 0.753
[71,     3] loss: 0.777
[72,     3] loss: 0.790
[73,     3] loss: 0.781
[74,     3] loss: 0.733
[75,     3] loss: 0.742
[76,     3] loss: 0.733
Early stopping applied (best metric=0.5162612199783325)
Finished Training
Total time taken: 18.486045122146606
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.386
[2,     3] loss: 1.379
[3,     3] loss: 1.390
[4,     3] loss: 1.384
[5,     3] loss: 1.385
[6,     3] loss: 1.381
[7,     3] loss: 1.390
[8,     3] loss: 1.387
[9,     3] loss: 1.377
[10,     3] loss: 1.402
[11,     3] loss: 1.385
[12,     3] loss: 1.376
[13,     3] loss: 1.383
[14,     3] loss: 1.374
[15,     3] loss: 1.372
[16,     3] loss: 1.365
[17,     3] loss: 1.352
[18,     3] loss: 1.346
[19,     3] loss: 1.329
[20,     3] loss: 1.336
[21,     3] loss: 1.265
[22,     3] loss: 1.251
[23,     3] loss: 1.220
[24,     3] loss: 1.244
[25,     3] loss: 1.202
[26,     3] loss: 1.120
[27,     3] loss: 1.119
[28,     3] loss: 1.147
[29,     3] loss: 1.098
[30,     3] loss: 1.085
[31,     3] loss: 1.109
[32,     3] loss: 1.155
[33,     3] loss: 1.081
[34,     3] loss: 1.014
[35,     3] loss: 1.049
[36,     3] loss: 1.017
[37,     3] loss: 0.963
[38,     3] loss: 1.009
[39,     3] loss: 0.982
[40,     3] loss: 1.076
[41,     3] loss: 0.944
[42,     3] loss: 0.992
[43,     3] loss: 0.919
[44,     3] loss: 0.898
[45,     3] loss: 0.845
[46,     3] loss: 0.871
[47,     3] loss: 0.821
[48,     3] loss: 0.811
[49,     3] loss: 0.818
[50,     3] loss: 0.841
[51,     3] loss: 0.860
[52,     3] loss: 0.828
[53,     3] loss: 0.834
[54,     3] loss: 0.801
[55,     3] loss: 0.839
[56,     3] loss: 0.787
[57,     3] loss: 0.874
[58,     3] loss: 0.787
[59,     3] loss: 0.772
[60,     3] loss: 0.764
[61,     3] loss: 0.788
[62,     3] loss: 0.773
[63,     3] loss: 0.773
[64,     3] loss: 0.774
[65,     3] loss: 0.737
[66,     3] loss: 0.742
[67,     3] loss: 0.731
[68,     3] loss: 0.745
[69,     3] loss: 0.766
[70,     3] loss: 0.748
[71,     3] loss: 0.777
[72,     3] loss: 0.710
[73,     3] loss: 0.763
[74,     3] loss: 0.767
[75,     3] loss: 0.716
[76,     3] loss: 0.735
[77,     3] loss: 0.729
[78,     3] loss: 0.747
[79,     3] loss: 0.747
[80,     3] loss: 0.739
[81,     3] loss: 0.720
Early stopping applied (best metric=0.47956275939941406)
Finished Training
Total time taken: 19.815051317214966
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.398
[2,     3] loss: 1.388
[3,     3] loss: 1.384
[4,     3] loss: 1.392
[5,     3] loss: 1.379
[6,     3] loss: 1.385
[7,     3] loss: 1.377
[8,     3] loss: 1.380
[9,     3] loss: 1.377
[10,     3] loss: 1.364
[11,     3] loss: 1.368
[12,     3] loss: 1.362
[13,     3] loss: 1.349
[14,     3] loss: 1.318
[15,     3] loss: 1.292
[16,     3] loss: 1.281
[17,     3] loss: 1.283
[18,     3] loss: 1.315
[19,     3] loss: 1.276
[20,     3] loss: 1.221
[21,     3] loss: 1.286
[22,     3] loss: 1.249
[23,     3] loss: 1.212
[24,     3] loss: 1.154
[25,     3] loss: 1.148
[26,     3] loss: 1.200
[27,     3] loss: 1.052
[28,     3] loss: 1.048
[29,     3] loss: 0.988
[30,     3] loss: 0.994
[31,     3] loss: 0.972
[32,     3] loss: 0.928
[33,     3] loss: 0.913
[34,     3] loss: 0.953
[35,     3] loss: 0.885
[36,     3] loss: 0.911
[37,     3] loss: 0.838
[38,     3] loss: 0.929
[39,     3] loss: 0.845
[40,     3] loss: 0.849
[41,     3] loss: 0.792
[42,     3] loss: 0.845
[43,     3] loss: 0.821
[44,     3] loss: 0.811
[45,     3] loss: 0.886
[46,     3] loss: 0.889
[47,     3] loss: 0.912
[48,     3] loss: 0.906
[49,     3] loss: 0.826
[50,     3] loss: 0.867
[51,     3] loss: 0.918
[52,     3] loss: 0.925
[53,     3] loss: 0.792
[54,     3] loss: 0.806
[55,     3] loss: 0.813
[56,     3] loss: 0.913
[57,     3] loss: 0.896
[58,     3] loss: 0.781
[59,     3] loss: 0.832
[60,     3] loss: 0.781
[61,     3] loss: 0.801
[62,     3] loss: 0.776
[63,     3] loss: 0.760
[64,     3] loss: 0.744
[65,     3] loss: 0.759
[66,     3] loss: 0.799
[67,     3] loss: 0.729
[68,     3] loss: 0.754
[69,     3] loss: 0.728
[70,     3] loss: 0.731
[71,     3] loss: 0.751
[72,     3] loss: 0.720
[73,     3] loss: 0.732
[74,     3] loss: 0.727
[75,     3] loss: 0.738
Early stopping applied (best metric=0.5302227139472961)
Finished Training
Total time taken: 18.43305492401123
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.385
[3,     3] loss: 1.384
[4,     3] loss: 1.382
[5,     3] loss: 1.374
[6,     3] loss: 1.385
[7,     3] loss: 1.371
[8,     3] loss: 1.362
[9,     3] loss: 1.346
[10,     3] loss: 1.356
[11,     3] loss: 1.325
[12,     3] loss: 1.280
[13,     3] loss: 1.289
[14,     3] loss: 1.241
[15,     3] loss: 1.242
[16,     3] loss: 1.118
[17,     3] loss: 1.154
[18,     3] loss: 1.265
[19,     3] loss: 1.095
[20,     3] loss: 1.227
[21,     3] loss: 1.179
[22,     3] loss: 1.028
[23,     3] loss: 1.131
[24,     3] loss: 0.967
[25,     3] loss: 1.051
[26,     3] loss: 0.973
[27,     3] loss: 1.020
[28,     3] loss: 0.917
[29,     3] loss: 0.992
[30,     3] loss: 0.943
[31,     3] loss: 0.940
[32,     3] loss: 1.119
[33,     3] loss: 0.955
[34,     3] loss: 0.878
[35,     3] loss: 0.957
[36,     3] loss: 0.956
[37,     3] loss: 0.936
[38,     3] loss: 0.965
[39,     3] loss: 0.867
[40,     3] loss: 0.948
[41,     3] loss: 0.945
[42,     3] loss: 0.940
[43,     3] loss: 0.910
[44,     3] loss: 0.958
[45,     3] loss: 0.907
[46,     3] loss: 0.879
[47,     3] loss: 0.948
[48,     3] loss: 0.852
[49,     3] loss: 0.890
[50,     3] loss: 0.889
[51,     3] loss: 0.812
[52,     3] loss: 0.857
[53,     3] loss: 0.817
[54,     3] loss: 0.789
[55,     3] loss: 0.867
[56,     3] loss: 0.795
[57,     3] loss: 0.823
[58,     3] loss: 0.792
[59,     3] loss: 0.781
[60,     3] loss: 0.775
[61,     3] loss: 0.858
[62,     3] loss: 0.861
[63,     3] loss: 0.828
[64,     3] loss: 0.821
[65,     3] loss: 0.826
[66,     3] loss: 0.806
[67,     3] loss: 0.757
[68,     3] loss: 0.786
[69,     3] loss: 0.742
[70,     3] loss: 0.751
[71,     3] loss: 0.735
[72,     3] loss: 0.749
[73,     3] loss: 0.732
[74,     3] loss: 0.735
[75,     3] loss: 0.726
[76,     3] loss: 0.725
Early stopping applied (best metric=0.47763359546661377)
Finished Training
Total time taken: 18.63404631614685
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.384
[3,     3] loss: 1.384
[4,     3] loss: 1.388
[5,     3] loss: 1.378
[6,     3] loss: 1.382
[7,     3] loss: 1.384
[8,     3] loss: 1.377
[9,     3] loss: 1.383
[10,     3] loss: 1.374
[11,     3] loss: 1.372
[12,     3] loss: 1.374
[13,     3] loss: 1.333
[14,     3] loss: 1.335
[15,     3] loss: 1.313
[16,     3] loss: 1.295
[17,     3] loss: 1.300
[18,     3] loss: 1.268
[19,     3] loss: 1.264
[20,     3] loss: 1.242
[21,     3] loss: 1.205
[22,     3] loss: 1.197
[23,     3] loss: 1.116
[24,     3] loss: 1.135
[25,     3] loss: 1.073
[26,     3] loss: 0.995
[27,     3] loss: 1.070
[28,     3] loss: 1.004
[29,     3] loss: 1.073
[30,     3] loss: 1.039
[31,     3] loss: 0.995
[32,     3] loss: 0.927
[33,     3] loss: 0.958
[34,     3] loss: 1.030
[35,     3] loss: 0.961
[36,     3] loss: 0.902
[37,     3] loss: 0.957
[38,     3] loss: 0.971
[39,     3] loss: 0.846
[40,     3] loss: 0.839
[41,     3] loss: 0.884
[42,     3] loss: 0.915
[43,     3] loss: 0.970
[44,     3] loss: 0.893
[45,     3] loss: 0.825
[46,     3] loss: 0.853
[47,     3] loss: 0.848
[48,     3] loss: 0.909
[49,     3] loss: 0.902
[50,     3] loss: 0.855
[51,     3] loss: 0.994
[52,     3] loss: 0.978
[53,     3] loss: 0.886
[54,     3] loss: 0.879
[55,     3] loss: 0.837
[56,     3] loss: 0.858
[57,     3] loss: 0.797
[58,     3] loss: 0.850
[59,     3] loss: 0.852
[60,     3] loss: 0.853
[61,     3] loss: 0.891
[62,     3] loss: 0.852
[63,     3] loss: 0.846
[64,     3] loss: 0.875
[65,     3] loss: 0.840
[66,     3] loss: 0.845
[67,     3] loss: 0.785
[68,     3] loss: 0.913
[69,     3] loss: 0.817
[70,     3] loss: 0.787
[71,     3] loss: 0.833
[72,     3] loss: 0.806
[73,     3] loss: 0.762
[74,     3] loss: 0.763
[75,     3] loss: 0.759
[76,     3] loss: 0.742
[77,     3] loss: 0.771
[78,     3] loss: 0.731
[79,     3] loss: 0.730
[80,     3] loss: 0.722
[81,     3] loss: 0.781
[82,     3] loss: 0.747
[83,     3] loss: 0.721
[84,     3] loss: 0.716
[85,     3] loss: 0.726
[86,     3] loss: 0.758
[87,     3] loss: 0.738
[88,     3] loss: 0.763
[89,     3] loss: 0.730
[90,     3] loss: 0.764
[91,     3] loss: 0.723
[92,     3] loss: 0.769
[93,     3] loss: 0.757
[94,     3] loss: 0.723
[95,     3] loss: 0.745
[96,     3] loss: 0.769
[97,     3] loss: 0.721
[98,     3] loss: 0.725
[99,     3] loss: 0.736
[100,     3] loss: 0.751
Early stopping applied (best metric=0.5066184997558594)
Finished Training
Total time taken: 24.699063539505005
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.391
[2,     3] loss: 1.392
[3,     3] loss: 1.390
[4,     3] loss: 1.384
[5,     3] loss: 1.391
[6,     3] loss: 1.387
[7,     3] loss: 1.394
[8,     3] loss: 1.385
[9,     3] loss: 1.371
[10,     3] loss: 1.372
[11,     3] loss: 1.391
[12,     3] loss: 1.378
[13,     3] loss: 1.370
[14,     3] loss: 1.356
[15,     3] loss: 1.345
[16,     3] loss: 1.336
[17,     3] loss: 1.283
[18,     3] loss: 1.289
[19,     3] loss: 1.268
[20,     3] loss: 1.208
[21,     3] loss: 1.205
[22,     3] loss: 1.132
[23,     3] loss: 1.104
[24,     3] loss: 1.095
[25,     3] loss: 0.972
[26,     3] loss: 1.015
[27,     3] loss: 1.079
[28,     3] loss: 1.004
[29,     3] loss: 1.044
[30,     3] loss: 0.961
[31,     3] loss: 1.074
[32,     3] loss: 0.972
[33,     3] loss: 1.181
[34,     3] loss: 1.171
[35,     3] loss: 0.985
[36,     3] loss: 1.106
[37,     3] loss: 1.008
[38,     3] loss: 1.049
[39,     3] loss: 1.063
[40,     3] loss: 1.012
[41,     3] loss: 0.923
[42,     3] loss: 0.909
[43,     3] loss: 0.904
[44,     3] loss: 0.845
[45,     3] loss: 0.832
[46,     3] loss: 0.831
[47,     3] loss: 0.903
[48,     3] loss: 0.905
[49,     3] loss: 0.857
[50,     3] loss: 0.896
[51,     3] loss: 0.813
[52,     3] loss: 0.800
[53,     3] loss: 0.847
[54,     3] loss: 0.805
[55,     3] loss: 0.804
[56,     3] loss: 0.760
[57,     3] loss: 0.819
[58,     3] loss: 0.770
[59,     3] loss: 0.768
[60,     3] loss: 0.792
[61,     3] loss: 0.792
[62,     3] loss: 0.786
[63,     3] loss: 0.742
[64,     3] loss: 0.768
[65,     3] loss: 0.817
[66,     3] loss: 0.868
[67,     3] loss: 0.754
[68,     3] loss: 0.946
[69,     3] loss: 0.754
[70,     3] loss: 0.937
[71,     3] loss: 0.774
[72,     3] loss: 0.866
[73,     3] loss: 0.828
[74,     3] loss: 0.782
Early stopping applied (best metric=0.49087485671043396)
Finished Training
Total time taken: 18.30406165122986
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.388
[2,     3] loss: 1.389
[3,     3] loss: 1.387
[4,     3] loss: 1.386
[5,     3] loss: 1.382
[6,     3] loss: 1.389
[7,     3] loss: 1.383
[8,     3] loss: 1.375
[9,     3] loss: 1.382
[10,     3] loss: 1.373
[11,     3] loss: 1.365
[12,     3] loss: 1.352
[13,     3] loss: 1.339
[14,     3] loss: 1.318
[15,     3] loss: 1.305
[16,     3] loss: 1.252
[17,     3] loss: 1.227
[18,     3] loss: 1.206
[19,     3] loss: 1.158
[20,     3] loss: 1.126
[21,     3] loss: 1.122
[22,     3] loss: 1.188
[23,     3] loss: 1.096
[24,     3] loss: 1.206
[25,     3] loss: 1.057
[26,     3] loss: 1.016
[27,     3] loss: 1.072
[28,     3] loss: 1.053
[29,     3] loss: 1.053
[30,     3] loss: 0.970
[31,     3] loss: 1.009
[32,     3] loss: 1.105
[33,     3] loss: 1.099
[34,     3] loss: 1.009
[35,     3] loss: 0.980
[36,     3] loss: 1.028
[37,     3] loss: 0.968
[38,     3] loss: 1.005
[39,     3] loss: 1.057
[40,     3] loss: 1.043
[41,     3] loss: 0.980
[42,     3] loss: 0.965
[43,     3] loss: 1.042
[44,     3] loss: 0.931
[45,     3] loss: 0.850
[46,     3] loss: 0.913
[47,     3] loss: 0.886
[48,     3] loss: 0.854
[49,     3] loss: 0.821
[50,     3] loss: 0.821
[51,     3] loss: 0.874
[52,     3] loss: 0.812
[53,     3] loss: 0.805
[54,     3] loss: 0.935
[55,     3] loss: 0.830
[56,     3] loss: 0.948
[57,     3] loss: 0.934
[58,     3] loss: 0.830
[59,     3] loss: 0.980
[60,     3] loss: 1.005
[61,     3] loss: 0.815
[62,     3] loss: 0.923
[63,     3] loss: 0.811
[64,     3] loss: 0.905
[65,     3] loss: 0.827
[66,     3] loss: 0.835
[67,     3] loss: 0.817
[68,     3] loss: 0.896
[69,     3] loss: 0.789
[70,     3] loss: 0.811
[71,     3] loss: 0.771
[72,     3] loss: 0.845
[73,     3] loss: 0.809
Early stopping applied (best metric=0.5176140666007996)
Finished Training
Total time taken: 18.531047344207764
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.395
[2,     3] loss: 1.388
[3,     3] loss: 1.380
[4,     3] loss: 1.388
[5,     3] loss: 1.384
[6,     3] loss: 1.379
[7,     3] loss: 1.376
[8,     3] loss: 1.367
[9,     3] loss: 1.357
[10,     3] loss: 1.357
[11,     3] loss: 1.345
[12,     3] loss: 1.296
[13,     3] loss: 1.308
[14,     3] loss: 1.318
[15,     3] loss: 1.264
[16,     3] loss: 1.306
[17,     3] loss: 1.244
[18,     3] loss: 1.211
[19,     3] loss: 1.256
[20,     3] loss: 1.242
[21,     3] loss: 1.208
[22,     3] loss: 1.232
[23,     3] loss: 1.224
[24,     3] loss: 1.105
[25,     3] loss: 1.050
[26,     3] loss: 1.107
[27,     3] loss: 1.002
[28,     3] loss: 0.959
[29,     3] loss: 0.970
[30,     3] loss: 0.973
[31,     3] loss: 0.967
[32,     3] loss: 1.029
[33,     3] loss: 1.076
[34,     3] loss: 0.966
[35,     3] loss: 0.966
[36,     3] loss: 1.100
[37,     3] loss: 0.977
[38,     3] loss: 0.915
[39,     3] loss: 0.868
[40,     3] loss: 0.884
[41,     3] loss: 0.900
[42,     3] loss: 0.838
[43,     3] loss: 0.853
[44,     3] loss: 0.898
[45,     3] loss: 0.855
[46,     3] loss: 0.811
[47,     3] loss: 0.793
[48,     3] loss: 0.789
[49,     3] loss: 0.809
[50,     3] loss: 0.856
[51,     3] loss: 0.845
[52,     3] loss: 0.852
[53,     3] loss: 0.813
[54,     3] loss: 0.795
[55,     3] loss: 0.890
[56,     3] loss: 0.843
[57,     3] loss: 0.875
[58,     3] loss: 0.848
[59,     3] loss: 0.856
[60,     3] loss: 0.819
[61,     3] loss: 0.775
[62,     3] loss: 0.796
[63,     3] loss: 0.777
[64,     3] loss: 0.902
[65,     3] loss: 0.800
[66,     3] loss: 0.773
[67,     3] loss: 0.757
[68,     3] loss: 0.824
[69,     3] loss: 0.760
[70,     3] loss: 0.780
[71,     3] loss: 0.886
[72,     3] loss: 0.742
[73,     3] loss: 0.727
[74,     3] loss: 0.751
Early stopping applied (best metric=0.5116879343986511)
Finished Training
Total time taken: 20.260051012039185
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.389
[2,     3] loss: 1.386
[3,     3] loss: 1.382
[4,     3] loss: 1.381
[5,     3] loss: 1.373
[6,     3] loss: 1.375
[7,     3] loss: 1.387
[8,     3] loss: 1.368
[9,     3] loss: 1.352
[10,     3] loss: 1.373
[11,     3] loss: 1.340
[12,     3] loss: 1.302
[13,     3] loss: 1.327
[14,     3] loss: 1.296
[15,     3] loss: 1.227
[16,     3] loss: 1.284
[17,     3] loss: 1.162
[18,     3] loss: 1.196
[19,     3] loss: 1.148
[20,     3] loss: 1.086
[21,     3] loss: 1.228
[22,     3] loss: 1.062
[23,     3] loss: 1.094
[24,     3] loss: 1.001
[25,     3] loss: 0.961
[26,     3] loss: 1.027
[27,     3] loss: 0.943
[28,     3] loss: 1.013
[29,     3] loss: 1.004
[30,     3] loss: 0.930
[31,     3] loss: 1.019
[32,     3] loss: 0.967
[33,     3] loss: 0.963
[34,     3] loss: 0.898
[35,     3] loss: 0.949
[36,     3] loss: 0.948
[37,     3] loss: 0.968
[38,     3] loss: 0.888
[39,     3] loss: 0.955
[40,     3] loss: 1.023
[41,     3] loss: 0.941
[42,     3] loss: 0.902
[43,     3] loss: 0.883
[44,     3] loss: 0.949
[45,     3] loss: 0.904
[46,     3] loss: 1.070
[47,     3] loss: 1.029
[48,     3] loss: 0.831
[49,     3] loss: 0.878
[50,     3] loss: 0.850
[51,     3] loss: 0.845
[52,     3] loss: 0.855
[53,     3] loss: 0.898
[54,     3] loss: 0.898
[55,     3] loss: 0.786
[56,     3] loss: 0.812
[57,     3] loss: 0.771
[58,     3] loss: 0.877
[59,     3] loss: 0.772
[60,     3] loss: 0.785
[61,     3] loss: 0.823
[62,     3] loss: 0.812
[63,     3] loss: 0.778
[64,     3] loss: 0.835
[65,     3] loss: 0.739
[66,     3] loss: 0.817
[67,     3] loss: 0.767
[68,     3] loss: 0.755
[69,     3] loss: 0.759
[70,     3] loss: 0.747
[71,     3] loss: 0.743
[72,     3] loss: 0.737
[73,     3] loss: 0.790
[74,     3] loss: 0.816
[75,     3] loss: 0.739
[76,     3] loss: 0.883
[77,     3] loss: 0.868
[78,     3] loss: 0.823
[79,     3] loss: 0.935
[80,     3] loss: 0.866
[81,     3] loss: 0.920
[82,     3] loss: 0.886
[83,     3] loss: 0.819
[84,     3] loss: 0.802
[85,     3] loss: 0.841
[86,     3] loss: 0.801
[87,     3] loss: 0.800
Early stopping applied (best metric=0.46645626425743103)
Finished Training
Total time taken: 21.88905096054077
(2525,)
Loaded folder code/Thesis/dataset/train/S-palmitoylation-C/indices (12598 samples)
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
1905 4040
144 305
[1,     1] loss: 1.387
[2,     3] loss: 1.385
[3,     3] loss: 1.388
[4,     3] loss: 1.396
[5,     3] loss: 1.388
[6,     3] loss: 1.378
[7,     3] loss: 1.379
[8,     3] loss: 1.375
[9,     3] loss: 1.359
[10,     3] loss: 1.371
[11,     3] loss: 1.344
[12,     3] loss: 1.351
[13,     3] loss: 1.325
[14,     3] loss: 1.305
[15,     3] loss: 1.344
[16,     3] loss: 1.275
[17,     3] loss: 1.269
[18,     3] loss: 1.308
[19,     3] loss: 1.222
[20,     3] loss: 1.196
[21,     3] loss: 1.216
[22,     3] loss: 1.230
[23,     3] loss: 1.179
[24,     3] loss: 1.161
[25,     3] loss: 1.169
[26,     3] loss: 1.136
[27,     3] loss: 1.063
[28,     3] loss: 1.095
[29,     3] loss: 1.121
[30,     3] loss: 1.079
[31,     3] loss: 1.055
[32,     3] loss: 1.009
[33,     3] loss: 0.959
[34,     3] loss: 0.926
[35,     3] loss: 0.967
[36,     3] loss: 0.933
[37,     3] loss: 0.994
[38,     3] loss: 0.934
[39,     3] loss: 0.906
[40,     3] loss: 0.915
[41,     3] loss: 0.869
[42,     3] loss: 0.891
[43,     3] loss: 0.965
[44,     3] loss: 0.823
[45,     3] loss: 0.898
[46,     3] loss: 0.843
[47,     3] loss: 0.888
[48,     3] loss: 0.885
[49,     3] loss: 0.885
[50,     3] loss: 0.870
[51,     3] loss: 0.879
[52,     3] loss: 0.954
[53,     3] loss: 0.932
[54,     3] loss: 0.906
[55,     3] loss: 0.906
[56,     3] loss: 0.870
[57,     3] loss: 0.846
[58,     3] loss: 0.826
[59,     3] loss: 0.842
[60,     3] loss: 0.883
[61,     3] loss: 0.847
[62,     3] loss: 0.813
[63,     3] loss: 0.766
[64,     3] loss: 0.777
[65,     3] loss: 0.839
[66,     3] loss: 0.768
[67,     3] loss: 0.793
[68,     3] loss: 0.776
[69,     3] loss: 0.828
[70,     3] loss: 0.791
[71,     3] loss: 0.750
[72,     3] loss: 0.738
[73,     3] loss: 0.738
[74,     3] loss: 0.752
[75,     3] loss: 0.753
[76,     3] loss: 0.826
[77,     3] loss: 0.800
[78,     3] loss: 0.725
[79,     3] loss: 0.753
[80,     3] loss: 0.726
[81,     3] loss: 0.752
[82,     3] loss: 0.763
[83,     3] loss: 0.726
[84,     3] loss: 0.824
[85,     3] loss: 1.057
[86,     3] loss: 0.801
[87,     3] loss: 0.849
[88,     3] loss: 0.792
[89,     3] loss: 0.930
[90,     3] loss: 0.862
[91,     3] loss: 0.839
[92,     3] loss: 0.900
[93,     3] loss: 0.779
[94,     3] loss: 0.794
[95,     3] loss: 0.766
[96,     3] loss: 0.781
[97,     3] loss: 0.751
[98,     3] loss: 0.752
[99,     3] loss: 0.737
[100,     3] loss: 0.752
[101,     3] loss: 0.759
[102,     3] loss: 0.734
[103,     3] loss: 0.729
[104,     3] loss: 0.735
[105,     3] loss: 0.727
[106,     3] loss: 0.734
[107,     3] loss: 0.733
[108,     3] loss: 0.760
[109,     3] loss: 0.715
[110,     3] loss: 0.719
[111,     3] loss: 0.746
[112,     3] loss: 0.725
[113,     3] loss: 0.730
[114,     3] loss: 0.715
[115,     3] loss: 0.767
Early stopping applied (best metric=0.4895917773246765)
Finished Training
Total time taken: 28.764070510864258
results!
{'gpu_mode': True, 'epochs': 200, 'batch_size': 2048, 'learning_rate': 0.0010009716998232807, 'test_data_ratio': 0.2, 'data_sample_mode': ['balanced', 'oversample'], 'crossValidation': True, 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'folds': 5, 'earlyStopping': True, 'ValidationMetric': 'Validation Loss (Hydroxylation-K)', 'earlyStoppingPatience': 50, 'CV_Repeats': 5, 'Experiment Name': 'Model architecture - added max, ranges, bceloss', 'CreateFigures': False, 'weight_decay': 2.7577645893492235, 'embeddingType': 'adaptiveEmbedding', 'LSTM_layers': 1, 'LSTM_hidden_size': 64, 'LSTM_dropout': 0, 'MultiTask': True, 'MultiTask_sample_method': 'balanced', 'UseUncertaintyBasedLoss': False, 'useLrWeight': False, 'CNNType': 'Musite', 'FCType': 'Adapt', 'layerToSplitOn': 'FC', 'dontAverageLoss': False, 'useWeightDecayWeight': False, 'SeperateTuningLRandWD': True, 'aminoAcid': ['S-palmitoylation-C', 'Hydroxylation-K'], 'n_trials': 500, 'FloatsToTune': {'learning_rate': [1e-05, 0.01], 'weight_decay': [0, 10], 'weight_decay_Hydroxylation-K': [0, 10], 'weight_decay_S-palmitoylation-C': [0, 10], 'loss_weight_Hydroxylation-K': [1e-05, 0.9999], 'loss_weight_S-palmitoylation-C': [1e-05, 0.9999]}, 'IntsToTune': {}, 'weight_decay_Hydroxylation-K': 2.560335480400073, 'weight_decay_S-palmitoylation-C': 0.21560639276347213, 'loss_weight_Hydroxylation-K': 0.3032824221609758, 'loss_weight_S-palmitoylation-C': 0.9443880638805753, 'random_state': 1035814360, 'current_CV_Repeat': 5, 'sample_weights': [0.9443880638805753, 0.3032824221609758], 'WeightDecayWeights': [], 'currentFold': 4}
{'S-palmitoylation-C Validation Accuracy': 0.6822978065117803, 'S-palmitoylation-C Validation Sensitivity': 0.2605148514851485, 'S-palmitoylation-C Validation Specificity': 0.7880250159553104, 'S-palmitoylation-C Validation Precision': 0.237124991447134, 'S-palmitoylation-C AUC ROC': 0.5467858881254309, 'S-palmitoylation-C AUC PR': 0.22561024808010188, 'S-palmitoylation-C MCC': 0.04742648799541836, 'S-palmitoylation-C F1': 0.24074201189401864, 'Validation Loss (S-palmitoylation-C)': 0.5544225859642029, 'Hydroxylation-K Validation Accuracy': 0.7032801418439716, 'Hydroxylation-K Validation Sensitivity': 0.8164444444444444, 'Hydroxylation-K Validation Specificity': 0.6747368421052632, 'Hydroxylation-K Validation Precision': 0.40358239338635366, 'Hydroxylation-K AUC ROC': 0.8406549707602339, 'Hydroxylation-K AUC PR': 0.6072040475786681, 'Hydroxylation-K MCC': 0.40815988679328247, 'Hydroxylation-K F1': 0.5338679858023296, 'Validation Loss (Hydroxylation-K)': 0.5016279685497284, 'Validation Loss (total)': 1.0560505628585815, 'TimeToTrain': 20.047675342559813}
{'S-palmitoylation-C Validation Accuracy': 0.0466173412058358, 'S-palmitoylation-C Validation Sensitivity': 0.09148657721799562, 'S-palmitoylation-C Validation Specificity': 0.08042458978138836, 'S-palmitoylation-C Validation Precision': 0.016195141101893216, 'S-palmitoylation-C AUC ROC': 0.01499335093306104, 'S-palmitoylation-C AUC PR': 0.008900869910792046, 'S-palmitoylation-C MCC': 0.019838749363036548, 'S-palmitoylation-C F1': 0.04001307390155812, 'Validation Loss (S-palmitoylation-C)': 0.0018636741343956134, 'Hydroxylation-K Validation Accuracy': 0.08713310892782565, 'Hydroxylation-K Validation Sensitivity': 0.09015989454498126, 'Hydroxylation-K Validation Specificity': 0.11264674434711236, 'Hydroxylation-K Validation Precision': 0.08548804007126505, 'Hydroxylation-K AUC ROC': 0.055216434449667895, 'Hydroxylation-K AUC PR': 0.1379276590661047, 'Hydroxylation-K MCC': 0.11066108630894476, 'Hydroxylation-K F1': 0.07809504297808569, 'Validation Loss (Hydroxylation-K)': 0.017940803655858203, 'Validation Loss (total)': 0.017937881434700115, 'TimeToTrain': 3.110504961211737}
