{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008623157728682145,
 'learning_rate_Hydroxylation-K': 0.009679779474379159,
 'learning_rate_Hydroxylation-P': 0.003081948538979397,
 'log_base': 1.4757343429763212,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1542209707,
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.3517852242495465,
 'weight_decay_Hydroxylation-K': 6.403487466469454,
 'weight_decay_Hydroxylation-P': 6.060107088030007}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1813.749
[2,     1] loss: 1808.812
[3,     1] loss: 1831.404
[4,     1] loss: 1820.688
[5,     1] loss: 1810.565
[6,     1] loss: 1812.365
[7,     1] loss: 1808.251
[8,     1] loss: 1807.334
[9,     1] loss: 1823.614
[10,     1] loss: 1809.767
[11,     1] loss: 1803.536
[12,     1] loss: 1820.182
[13,     1] loss: 1803.782
[14,     1] loss: 1807.613
[15,     1] loss: 1792.436
[16,     1] loss: 1789.041
[17,     1] loss: 1774.294
[18,     1] loss: 1776.249
[19,     1] loss: 1719.373
[20,     1] loss: 1670.944
[21,     1] loss: 1649.281
[22,     1] loss: 1642.703
[23,     1] loss: 1620.020
[24,     1] loss: 1582.010
[25,     1] loss: 1507.191
[26,     1] loss: 1502.044
[27,     1] loss: 1556.060
[28,     1] loss: 1483.982
[29,     1] loss: 1475.944
[30,     1] loss: 1417.351
[31,     1] loss: 1438.521
[32,     1] loss: 1447.506
[33,     1] loss: 1441.464
[34,     1] loss: 1367.321
[35,     1] loss: 1357.582
[36,     1] loss: 1423.967
[37,     1] loss: 1393.756
[38,     1] loss: 1325.658
[39,     1] loss: 1318.821
[40,     1] loss: 1298.729
[41,     1] loss: 1260.502
[42,     1] loss: 1232.534
[43,     1] loss: 1290.121
[44,     1] loss: 1279.706
[45,     1] loss: 1130.975
[46,     1] loss: 1358.469
[47,     1] loss: 1146.110
[48,     1] loss: 1173.061
[49,     1] loss: 1223.697
[50,     1] loss: 1091.377
[51,     1] loss: 1264.715
Early stopping applied (best metric=0.8756399154663086)
Finished Training
Total time taken: 13.819478988647461
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1811.007
[2,     1] loss: 1834.599
[3,     1] loss: 1814.025
[4,     1] loss: 1814.885
[5,     1] loss: 1822.884
[6,     1] loss: 1816.569
[7,     1] loss: 1814.170
[8,     1] loss: 1806.581
[9,     1] loss: 1808.123
[10,     1] loss: 1810.604
[11,     1] loss: 1809.018
[12,     1] loss: 1807.816
[13,     1] loss: 1818.947
[14,     1] loss: 1808.146
[15,     1] loss: 1806.719
[16,     1] loss: 1803.979
[17,     1] loss: 1802.983
[18,     1] loss: 1803.380
[19,     1] loss: 1793.065
[20,     1] loss: 1798.978
[21,     1] loss: 1770.337
[22,     1] loss: 1751.256
[23,     1] loss: 1755.072
[24,     1] loss: 1688.478
[25,     1] loss: 1683.883
[26,     1] loss: 1632.922
[27,     1] loss: 1648.040
[28,     1] loss: 1601.944
[29,     1] loss: 1623.994
[30,     1] loss: 1537.827
[31,     1] loss: 1483.033
[32,     1] loss: 1485.798
[33,     1] loss: 1432.498
[34,     1] loss: 1419.788
[35,     1] loss: 1550.633
[36,     1] loss: 1444.839
[37,     1] loss: 1439.655
[38,     1] loss: 1464.083
[39,     1] loss: 1374.570
[40,     1] loss: 1360.588
[41,     1] loss: 1347.196
[42,     1] loss: 1298.919
[43,     1] loss: 1258.711
[44,     1] loss: 1294.771
[45,     1] loss: 1210.749
[46,     1] loss: 1297.905
[47,     1] loss: 1362.348
[48,     1] loss: 1459.560
[49,     1] loss: 1246.300
Early stopping applied (best metric=0.8870666027069092)
Finished Training
Total time taken: 7.293658256530762
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1809.030
[2,     1] loss: 1829.582
[3,     1] loss: 1863.281
[4,     1] loss: 1813.855
[5,     1] loss: 1806.098
[6,     1] loss: 1828.351
[7,     1] loss: 1817.711
[8,     1] loss: 1817.910
[9,     1] loss: 1806.451
[10,     1] loss: 1813.901
[11,     1] loss: 1811.331
[12,     1] loss: 1822.378
[13,     1] loss: 1813.219
[14,     1] loss: 1811.656
[15,     1] loss: 1809.538
[16,     1] loss: 1811.424
[17,     1] loss: 1812.064
[18,     1] loss: 1808.612
[19,     1] loss: 1808.190
[20,     1] loss: 1805.783
[21,     1] loss: 1798.464
[22,     1] loss: 1801.231
[23,     1] loss: 1799.088
[24,     1] loss: 1793.343
[25,     1] loss: 1781.846
[26,     1] loss: 1772.012
[27,     1] loss: 1727.547
[28,     1] loss: 1706.131
[29,     1] loss: 1668.673
[30,     1] loss: 1663.237
[31,     1] loss: 1612.131
[32,     1] loss: 1587.550
[33,     1] loss: 1537.895
[34,     1] loss: 1564.066
[35,     1] loss: 1482.281
[36,     1] loss: 1457.635
[37,     1] loss: 1524.775
[38,     1] loss: 1510.339
[39,     1] loss: 1508.140
[40,     1] loss: 1446.805
[41,     1] loss: 1441.429
[42,     1] loss: 1473.278
[43,     1] loss: 1392.203
[44,     1] loss: 1453.413
[45,     1] loss: 1354.237
[46,     1] loss: 1606.168
[47,     1] loss: 1452.043
[48,     1] loss: 1398.852
[49,     1] loss: 1320.903
[50,     1] loss: 1400.447
[51,     1] loss: 1356.630
[52,     1] loss: 1283.067
[53,     1] loss: 1356.731
[54,     1] loss: 1263.691
[55,     1] loss: 1330.744
[56,     1] loss: 1217.652
[57,     1] loss: 1268.233
[58,     1] loss: 1233.298
[59,     1] loss: 1160.312
[60,     1] loss: 1111.924
[61,     1] loss: 1117.977
[62,     1] loss: 1202.002
[63,     1] loss: 1107.953
[64,     1] loss: 1069.429
[65,     1] loss: 1017.140
[66,     1] loss: 1085.369
[67,     1] loss: 1383.564
[68,     1] loss: 1307.793
Early stopping applied (best metric=0.8614376783370972)
Finished Training
Total time taken: 10.244027853012085
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1812.948
[2,     1] loss: 1810.315
[3,     1] loss: 1817.111
[4,     1] loss: 1826.121
[5,     1] loss: 1813.152
[6,     1] loss: 1812.972
[7,     1] loss: 1810.215
[8,     1] loss: 1816.133
[9,     1] loss: 1803.998
[10,     1] loss: 1806.400
[11,     1] loss: 1805.010
[12,     1] loss: 1816.702
[13,     1] loss: 1796.843
[14,     1] loss: 1790.096
[15,     1] loss: 1769.892
[16,     1] loss: 1753.159
[17,     1] loss: 1713.511
[18,     1] loss: 1714.854
[19,     1] loss: 1644.248
[20,     1] loss: 1632.103
[21,     1] loss: 1562.495
[22,     1] loss: 1511.001
[23,     1] loss: 1562.259
[24,     1] loss: 1539.560
[25,     1] loss: 1465.906
[26,     1] loss: 1499.776
[27,     1] loss: 1415.067
[28,     1] loss: 1423.275
[29,     1] loss: 1481.667
[30,     1] loss: 1419.004
[31,     1] loss: 1416.991
[32,     1] loss: 1342.351
[33,     1] loss: 1345.756
[34,     1] loss: 1427.264
[35,     1] loss: 1318.865
[36,     1] loss: 1334.802
[37,     1] loss: 1324.144
[38,     1] loss: 1327.648
[39,     1] loss: 1268.774
[40,     1] loss: 1346.081
[41,     1] loss: 1200.973
[42,     1] loss: 1246.772
[43,     1] loss: 1345.878
[44,     1] loss: 1289.692
[45,     1] loss: 1198.325
[46,     1] loss: 1234.664
[47,     1] loss: 1159.022
[48,     1] loss: 1112.418
[49,     1] loss: 1252.705
[50,     1] loss: 1162.417
[51,     1] loss: 1037.911
[52,     1] loss: 1199.261
[53,     1] loss: 1022.037
[54,     1] loss: 1085.353
[55,     1] loss: 1220.987
[56,     1] loss: 1455.741
Early stopping applied (best metric=0.7918350696563721)
Finished Training
Total time taken: 10.259093046188354
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1823.725
[2,     1] loss: 1823.719
[3,     1] loss: 1820.750
[4,     1] loss: 1821.775
[5,     1] loss: 1815.373
[6,     1] loss: 1808.029
[7,     1] loss: 1813.369
[8,     1] loss: 1808.807
[9,     1] loss: 1816.309
[10,     1] loss: 1805.057
[11,     1] loss: 1802.834
[12,     1] loss: 1789.646
[13,     1] loss: 1773.093
[14,     1] loss: 1757.028
[15,     1] loss: 1703.098
[16,     1] loss: 1694.323
[17,     1] loss: 1640.044
[18,     1] loss: 1666.704
[19,     1] loss: 1648.491
[20,     1] loss: 1556.420
[21,     1] loss: 1606.029
[22,     1] loss: 1581.208
[23,     1] loss: 1632.603
[24,     1] loss: 1533.326
[25,     1] loss: 1545.880
[26,     1] loss: 1532.136
[27,     1] loss: 1525.224
[28,     1] loss: 1511.401
[29,     1] loss: 1516.986
[30,     1] loss: 1470.303
[31,     1] loss: 1478.272
[32,     1] loss: 1487.829
[33,     1] loss: 1462.296
[34,     1] loss: 1432.127
[35,     1] loss: 1445.711
[36,     1] loss: 1406.570
[37,     1] loss: 1331.985
[38,     1] loss: 1370.694
[39,     1] loss: 1397.116
[40,     1] loss: 1445.861
[41,     1] loss: 1387.654
[42,     1] loss: 1343.830
[43,     1] loss: 1339.540
[44,     1] loss: 1424.308
[45,     1] loss: 1621.181
[46,     1] loss: 1301.065
[47,     1] loss: 1409.499
[48,     1] loss: 1344.099
[49,     1] loss: 1325.559
[50,     1] loss: 1343.091
[51,     1] loss: 1298.586
[52,     1] loss: 1228.620
[53,     1] loss: 1212.240
[54,     1] loss: 1233.416
[55,     1] loss: 1190.089
[56,     1] loss: 1182.826
[57,     1] loss: 1171.240
[58,     1] loss: 1100.974
[59,     1] loss: 1147.152
Early stopping applied (best metric=0.7352936267852783)
Finished Training
Total time taken: 11.057204008102417
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1817.212
[2,     1] loss: 1972.522
[3,     1] loss: 1817.652
[4,     1] loss: 1815.729
[5,     1] loss: 1814.953
[6,     1] loss: 1818.538
[7,     1] loss: 1817.233
[8,     1] loss: 1813.539
[9,     1] loss: 1811.045
[10,     1] loss: 1811.291
[11,     1] loss: 1812.467
[12,     1] loss: 1810.049
[13,     1] loss: 1811.643
[14,     1] loss: 1811.649
[15,     1] loss: 1815.221
[16,     1] loss: 1813.984
[17,     1] loss: 1816.256
[18,     1] loss: 1811.119
[19,     1] loss: 1812.934
[20,     1] loss: 1812.059
[21,     1] loss: 1812.203
[22,     1] loss: 1815.479
Early stopping applied (best metric=1.0965888500213623)
Finished Training
Total time taken: 4.217714071273804
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1822.280
[2,     1] loss: 1815.620
[3,     1] loss: 1814.587
[4,     1] loss: 1810.400
[5,     1] loss: 1813.534
[6,     1] loss: 1809.240
[7,     1] loss: 1810.774
[8,     1] loss: 1814.119
[9,     1] loss: 1812.559
[10,     1] loss: 1797.788
[11,     1] loss: 1793.603
[12,     1] loss: 1769.543
[13,     1] loss: 1745.773
[14,     1] loss: 1705.377
[15,     1] loss: 1660.915
[16,     1] loss: 1593.057
[17,     1] loss: 1624.785
[18,     1] loss: 1595.810
[19,     1] loss: 1531.785
[20,     1] loss: 1522.273
[21,     1] loss: 1536.201
[22,     1] loss: 1541.188
[23,     1] loss: 1509.806
[24,     1] loss: 1490.947
[25,     1] loss: 1468.559
[26,     1] loss: 1443.599
[27,     1] loss: 1478.810
[28,     1] loss: 1404.363
[29,     1] loss: 1462.375
[30,     1] loss: 1407.061
[31,     1] loss: 1384.837
[32,     1] loss: 1362.392
[33,     1] loss: 1334.694
[34,     1] loss: 1400.676
[35,     1] loss: 1288.518
[36,     1] loss: 1269.132
[37,     1] loss: 1254.187
[38,     1] loss: 1244.668
[39,     1] loss: 1288.088
[40,     1] loss: 1417.575
[41,     1] loss: 1206.509
[42,     1] loss: 1376.117
[43,     1] loss: 1243.405
[44,     1] loss: 1301.067
[45,     1] loss: 1223.010
[46,     1] loss: 1287.698
[47,     1] loss: 1159.672
[48,     1] loss: 1263.276
[49,     1] loss: 1035.805
[50,     1] loss: 1125.526
Early stopping applied (best metric=0.8422220945358276)
Finished Training
Total time taken: 9.578001499176025
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1815.070
[2,     1] loss: 1849.098
[3,     1] loss: 1820.031
[4,     1] loss: 1818.005
[5,     1] loss: 1812.367
[6,     1] loss: 1816.753
[7,     1] loss: 1809.656
[8,     1] loss: 1813.518
[9,     1] loss: 1801.440
[10,     1] loss: 1821.839
[11,     1] loss: 1814.270
[12,     1] loss: 1807.298
[13,     1] loss: 1813.458
[14,     1] loss: 1816.598
[15,     1] loss: 1806.248
[16,     1] loss: 1811.587
[17,     1] loss: 1808.716
[18,     1] loss: 1799.950
[19,     1] loss: 1803.920
[20,     1] loss: 1793.041
[21,     1] loss: 1792.045
[22,     1] loss: 1772.059
[23,     1] loss: 1758.205
[24,     1] loss: 1719.833
[25,     1] loss: 1694.568
[26,     1] loss: 1670.030
[27,     1] loss: 1607.415
[28,     1] loss: 1564.030
[29,     1] loss: 1597.618
[30,     1] loss: 1589.129
[31,     1] loss: 1495.255
[32,     1] loss: 1551.105
[33,     1] loss: 1498.489
[34,     1] loss: 1547.418
[35,     1] loss: 1568.751
[36,     1] loss: 1497.971
[37,     1] loss: 1483.442
[38,     1] loss: 1405.020
[39,     1] loss: 1420.973
[40,     1] loss: 1465.436
[41,     1] loss: 1419.855
[42,     1] loss: 1363.355
[43,     1] loss: 1412.800
[44,     1] loss: 1324.703
[45,     1] loss: 1363.896
[46,     1] loss: 1301.862
[47,     1] loss: 1250.035
[48,     1] loss: 1190.103
[49,     1] loss: 1206.558
[50,     1] loss: 1166.794
[51,     1] loss: 1258.938
[52,     1] loss: 1361.049
[53,     1] loss: 1224.493
[54,     1] loss: 1305.682
[55,     1] loss: 1295.171
[56,     1] loss: 1134.158
[57,     1] loss: 1173.268
[58,     1] loss: 1211.793
[59,     1] loss: 1222.486
[60,     1] loss: 1175.202
Early stopping applied (best metric=0.8828651309013367)
Finished Training
Total time taken: 8.404332637786865
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1802.794
[2,     1] loss: 1822.311
[3,     1] loss: 1847.320
[4,     1] loss: 1813.205
[5,     1] loss: 1815.243
[6,     1] loss: 1808.224
[7,     1] loss: 1838.611
[8,     1] loss: 1802.028
[9,     1] loss: 1809.342
[10,     1] loss: 1816.914
[11,     1] loss: 1808.238
[12,     1] loss: 1801.297
[13,     1] loss: 1804.811
[14,     1] loss: 1795.540
[15,     1] loss: 1789.802
[16,     1] loss: 1774.340
[17,     1] loss: 1749.922
[18,     1] loss: 1707.869
[19,     1] loss: 1680.771
[20,     1] loss: 1617.182
[21,     1] loss: 1602.636
[22,     1] loss: 1613.699
[23,     1] loss: 1572.126
[24,     1] loss: 1494.514
[25,     1] loss: 1517.763
[26,     1] loss: 1609.121
[27,     1] loss: 1485.004
[28,     1] loss: 1534.869
[29,     1] loss: 1497.343
[30,     1] loss: 1421.170
[31,     1] loss: 1507.513
[32,     1] loss: 1464.674
[33,     1] loss: 1394.146
[34,     1] loss: 1382.005
[35,     1] loss: 1384.552
[36,     1] loss: 1289.078
[37,     1] loss: 1382.696
[38,     1] loss: 1231.334
[39,     1] loss: 1348.469
[40,     1] loss: 1411.795
[41,     1] loss: 1252.547
[42,     1] loss: 1365.977
[43,     1] loss: 1273.759
[44,     1] loss: 1331.407
[45,     1] loss: 1299.637
[46,     1] loss: 1239.573
[47,     1] loss: 1315.789
[48,     1] loss: 1207.871
[49,     1] loss: 1243.367
[50,     1] loss: 1140.492
[51,     1] loss: 1186.549
[52,     1] loss: 1057.470
Early stopping applied (best metric=0.8961906433105469)
Finished Training
Total time taken: 7.134594202041626
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1825.058
[2,     1] loss: 1835.657
[3,     1] loss: 1818.565
[4,     1] loss: 1818.715
[5,     1] loss: 1817.650
[6,     1] loss: 1818.837
[7,     1] loss: 1816.874
[8,     1] loss: 1813.564
[9,     1] loss: 1828.150
[10,     1] loss: 1812.607
[11,     1] loss: 1813.386
[12,     1] loss: 1811.702
[13,     1] loss: 1816.769
[14,     1] loss: 1813.943
[15,     1] loss: 1815.232
[16,     1] loss: 1810.689
[17,     1] loss: 1814.234
[18,     1] loss: 1806.176
[19,     1] loss: 1804.301
[20,     1] loss: 1798.069
[21,     1] loss: 1781.119
[22,     1] loss: 1768.109
[23,     1] loss: 1728.702
[24,     1] loss: 1689.018
[25,     1] loss: 1640.683
[26,     1] loss: 1597.707
[27,     1] loss: 1593.124
[28,     1] loss: 1586.116
[29,     1] loss: 1488.758
[30,     1] loss: 1505.657
[31,     1] loss: 1464.072
[32,     1] loss: 1483.964
[33,     1] loss: 1471.230
[34,     1] loss: 1433.203
[35,     1] loss: 1518.404
[36,     1] loss: 1498.114
[37,     1] loss: 1435.148
[38,     1] loss: 1467.893
[39,     1] loss: 1398.882
[40,     1] loss: 1358.968
[41,     1] loss: 1336.530
[42,     1] loss: 1339.260
[43,     1] loss: 1332.542
[44,     1] loss: 1244.184
[45,     1] loss: 1316.343
[46,     1] loss: 1319.236
[47,     1] loss: 1324.331
[48,     1] loss: 1283.694
[49,     1] loss: 1521.933
[50,     1] loss: 1316.662
[51,     1] loss: 1419.173
[52,     1] loss: 1178.514
[53,     1] loss: 1285.590
[54,     1] loss: 1211.834
[55,     1] loss: 1270.212
[56,     1] loss: 1175.691
[57,     1] loss: 1177.352
[58,     1] loss: 1155.596
[59,     1] loss: 1177.308
[60,     1] loss: 1058.386
Early stopping applied (best metric=0.838355302810669)
Finished Training
Total time taken: 8.1502206325531
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1823.228
[2,     1] loss: 1930.940
[3,     1] loss: 1827.670
[4,     1] loss: 1823.075
[5,     1] loss: 1814.018
[6,     1] loss: 1813.795
[7,     1] loss: 1818.693
[8,     1] loss: 1815.218
[9,     1] loss: 1808.480
[10,     1] loss: 1811.811
[11,     1] loss: 1807.902
[12,     1] loss: 1814.571
[13,     1] loss: 1810.289
[14,     1] loss: 1813.639
[15,     1] loss: 1809.273
[16,     1] loss: 1811.177
[17,     1] loss: 1812.745
[18,     1] loss: 1816.206
[19,     1] loss: 1811.590
[20,     1] loss: 1810.570
[21,     1] loss: 1814.560
[22,     1] loss: 1812.750
[23,     1] loss: 1810.363
[24,     1] loss: 1808.497
[25,     1] loss: 1807.382
[26,     1] loss: 1808.996
[27,     1] loss: 1809.980
[28,     1] loss: 1808.302
[29,     1] loss: 1800.499
[30,     1] loss: 1798.812
[31,     1] loss: 1797.829
[32,     1] loss: 1784.598
[33,     1] loss: 1760.863
[34,     1] loss: 1749.182
[35,     1] loss: 1694.971
[36,     1] loss: 1674.042
[37,     1] loss: 1640.512
[38,     1] loss: 1586.628
[39,     1] loss: 1596.867
[40,     1] loss: 1660.672
[41,     1] loss: 1613.685
[42,     1] loss: 1541.305
[43,     1] loss: 1642.165
[44,     1] loss: 1492.634
[45,     1] loss: 1561.995
[46,     1] loss: 1597.913
[47,     1] loss: 1589.312
[48,     1] loss: 1565.633
[49,     1] loss: 1550.528
[50,     1] loss: 1505.901
[51,     1] loss: 1532.979
[52,     1] loss: 1528.519
[53,     1] loss: 1588.584
[54,     1] loss: 1473.278
[55,     1] loss: 1568.334
[56,     1] loss: 1462.966
[57,     1] loss: 1482.609
[58,     1] loss: 1590.952
[59,     1] loss: 1453.959
[60,     1] loss: 1377.507
[61,     1] loss: 1551.997
[62,     1] loss: 1365.406
[63,     1] loss: 1445.855
Early stopping applied (best metric=0.9580825567245483)
Finished Training
Total time taken: 8.564807891845703
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1809.818
[2,     1] loss: 1862.894
[3,     1] loss: 1831.147
[4,     1] loss: 1806.035
[5,     1] loss: 1819.890
[6,     1] loss: 1834.283
[7,     1] loss: 1818.477
[8,     1] loss: 1818.306
[9,     1] loss: 1815.164
[10,     1] loss: 1816.807
[11,     1] loss: 1809.535
[12,     1] loss: 1812.112
[13,     1] loss: 1809.850
[14,     1] loss: 1811.403
[15,     1] loss: 1811.303
[16,     1] loss: 1817.449
[17,     1] loss: 1811.424
[18,     1] loss: 1812.023
[19,     1] loss: 1809.655
[20,     1] loss: 1812.398
[21,     1] loss: 1812.758
[22,     1] loss: 1811.821
[23,     1] loss: 1810.904
[24,     1] loss: 1811.448
[25,     1] loss: 1810.264
[26,     1] loss: 1809.009
[27,     1] loss: 1813.256
[28,     1] loss: 1811.277
[29,     1] loss: 1819.451
[30,     1] loss: 1809.092
[31,     1] loss: 1806.238
[32,     1] loss: 1806.643
[33,     1] loss: 1807.885
[34,     1] loss: 1804.882
[35,     1] loss: 1801.808
[36,     1] loss: 1788.230
[37,     1] loss: 1769.589
[38,     1] loss: 1751.969
[39,     1] loss: 1734.048
[40,     1] loss: 1712.910
[41,     1] loss: 1694.240
[42,     1] loss: 1660.896
[43,     1] loss: 1673.082
[44,     1] loss: 1657.812
[45,     1] loss: 1620.994
[46,     1] loss: 1638.918
[47,     1] loss: 1487.176
[48,     1] loss: 1534.683
[49,     1] loss: 1516.970
[50,     1] loss: 1504.320
[51,     1] loss: 1420.614
[52,     1] loss: 1450.641
[53,     1] loss: 1403.475
[54,     1] loss: 1430.216
[55,     1] loss: 1349.239
[56,     1] loss: 1433.080
[57,     1] loss: 1445.518
[58,     1] loss: 1402.187
[59,     1] loss: 1314.303
[60,     1] loss: 1386.797
[61,     1] loss: 1438.819
[62,     1] loss: 1252.337
[63,     1] loss: 1412.730
[64,     1] loss: 1245.880
[65,     1] loss: 1339.465
[66,     1] loss: 1273.301
[67,     1] loss: 1254.954
[68,     1] loss: 1291.583
[69,     1] loss: 1383.605
[70,     1] loss: 1224.494
[71,     1] loss: 1291.383
[72,     1] loss: 1188.582
[73,     1] loss: 1146.086
[74,     1] loss: 1254.707
Early stopping applied (best metric=0.8116438388824463)
Finished Training
Total time taken: 10.038050174713135
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1816.234
[2,     1] loss: 1851.696
[3,     1] loss: 1825.947
[4,     1] loss: 1816.333
[5,     1] loss: 1817.852
[6,     1] loss: 1810.593
[7,     1] loss: 1818.107
[8,     1] loss: 1829.970
[9,     1] loss: 1814.131
[10,     1] loss: 1813.473
[11,     1] loss: 1817.403
[12,     1] loss: 1807.763
[13,     1] loss: 1811.962
[14,     1] loss: 1807.751
[15,     1] loss: 1805.997
[16,     1] loss: 1817.450
[17,     1] loss: 1816.864
[18,     1] loss: 1800.991
[19,     1] loss: 1800.193
[20,     1] loss: 1801.879
[21,     1] loss: 1794.607
[22,     1] loss: 1784.198
[23,     1] loss: 1775.524
[24,     1] loss: 1757.454
[25,     1] loss: 1743.859
[26,     1] loss: 1674.931
[27,     1] loss: 1660.707
[28,     1] loss: 1615.925
[29,     1] loss: 1574.109
[30,     1] loss: 1562.986
[31,     1] loss: 1587.527
[32,     1] loss: 1535.827
[33,     1] loss: 1458.200
[34,     1] loss: 1484.396
[35,     1] loss: 1504.993
[36,     1] loss: 1533.807
[37,     1] loss: 1501.155
[38,     1] loss: 1463.896
[39,     1] loss: 1434.260
[40,     1] loss: 1502.886
[41,     1] loss: 1435.229
[42,     1] loss: 1374.083
[43,     1] loss: 1413.085
[44,     1] loss: 1344.287
[45,     1] loss: 1329.308
[46,     1] loss: 1358.511
[47,     1] loss: 1286.277
[48,     1] loss: 1277.645
[49,     1] loss: 1280.561
[50,     1] loss: 1407.799
[51,     1] loss: 1533.219
[52,     1] loss: 1360.800
[53,     1] loss: 1282.456
[54,     1] loss: 1263.292
[55,     1] loss: 1305.536
[56,     1] loss: 1202.259
[57,     1] loss: 1212.540
[58,     1] loss: 1259.217
[59,     1] loss: 1203.900
[60,     1] loss: 1176.495
[61,     1] loss: 1239.575
[62,     1] loss: 1144.111
[63,     1] loss: 1144.768
[64,     1] loss: 1066.480
[65,     1] loss: 1034.870
[66,     1] loss: 1111.745
Early stopping applied (best metric=0.7799073457717896)
Finished Training
Total time taken: 9.644990682601929
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1811.788
[2,     1] loss: 1816.819
[3,     1] loss: 1861.139
[4,     1] loss: 1828.429
[5,     1] loss: 1813.342
[6,     1] loss: 1820.291
[7,     1] loss: 1812.469
[8,     1] loss: 1815.554
[9,     1] loss: 1811.648
[10,     1] loss: 1814.703
[11,     1] loss: 1810.964
[12,     1] loss: 1812.368
[13,     1] loss: 1813.229
[14,     1] loss: 1810.432
[15,     1] loss: 1814.352
[16,     1] loss: 1811.330
[17,     1] loss: 1809.786
[18,     1] loss: 1809.250
[19,     1] loss: 1809.785
[20,     1] loss: 1810.166
[21,     1] loss: 1813.381
[22,     1] loss: 1806.422
[23,     1] loss: 1810.253
[24,     1] loss: 1804.083
[25,     1] loss: 1802.404
[26,     1] loss: 1797.425
[27,     1] loss: 1792.512
[28,     1] loss: 1769.788
[29,     1] loss: 1744.352
[30,     1] loss: 1700.578
[31,     1] loss: 1656.978
[32,     1] loss: 1570.405
[33,     1] loss: 1594.074
[34,     1] loss: 1569.138
[35,     1] loss: 1467.691
[36,     1] loss: 1565.336
[37,     1] loss: 1502.509
[38,     1] loss: 1470.076
[39,     1] loss: 1530.114
[40,     1] loss: 1536.268
[41,     1] loss: 1515.742
[42,     1] loss: 1453.542
[43,     1] loss: 1454.807
[44,     1] loss: 1469.945
[45,     1] loss: 1405.434
[46,     1] loss: 1456.034
[47,     1] loss: 1355.256
[48,     1] loss: 1397.571
[49,     1] loss: 1406.176
[50,     1] loss: 1363.240
[51,     1] loss: 1307.600
[52,     1] loss: 1344.962
[53,     1] loss: 1273.400
[54,     1] loss: 1303.718
[55,     1] loss: 1315.631
[56,     1] loss: 1312.314
[57,     1] loss: 1306.723
[58,     1] loss: 1276.794
[59,     1] loss: 1324.633
[60,     1] loss: 1360.167
[61,     1] loss: 1266.155
[62,     1] loss: 1245.141
[63,     1] loss: 1338.706
[64,     1] loss: 1227.507
[65,     1] loss: 1305.746
[66,     1] loss: 1191.290
[67,     1] loss: 1188.036
[68,     1] loss: 1210.973
[69,     1] loss: 1027.119
[70,     1] loss: 1158.428
[71,     1] loss: 1174.209
[72,     1] loss: 1021.858
[73,     1] loss: 1078.303
[74,     1] loss: 1071.127
[75,     1] loss: 1019.835
[76,     1] loss: 977.698
[77,     1] loss: 1029.283
[78,     1] loss: 832.996
[79,     1] loss: 977.195
[80,     1] loss: 1285.728
[81,     1] loss: 2146.742
[82,     1] loss: 953.978
[83,     1] loss: 1433.959
[84,     1] loss: 1114.696
[85,     1] loss: 1173.332
[86,     1] loss: 1244.611
[87,     1] loss: 1254.651
[88,     1] loss: 1117.968
[89,     1] loss: 1036.076
[90,     1] loss: 1104.497
[91,     1] loss: 1071.969
[92,     1] loss: 971.561
[93,     1] loss: 1038.439
[94,     1] loss: 976.657
[95,     1] loss: 990.639
[96,     1] loss: 901.307
[97,     1] loss: 921.941
[98,     1] loss: 925.116
[99,     1] loss: 846.622
[100,     1] loss: 753.344
[101,     1] loss: 863.780
[102,     1] loss: 750.847
[103,     1] loss: 755.040
[104,     1] loss: 685.846
Early stopping applied (best metric=0.846744179725647)
Finished Training
Total time taken: 15.774862051010132
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1813.297
[2,     1] loss: 1841.759
[3,     1] loss: 1833.444
[4,     1] loss: 1818.821
[5,     1] loss: 1819.131
[6,     1] loss: 1815.731
[7,     1] loss: 1818.271
[8,     1] loss: 1812.614
[9,     1] loss: 1816.072
[10,     1] loss: 1810.801
[11,     1] loss: 1809.532
[12,     1] loss: 1820.413
[13,     1] loss: 1818.196
[14,     1] loss: 1813.428
[15,     1] loss: 1813.772
[16,     1] loss: 1815.880
[17,     1] loss: 1818.197
[18,     1] loss: 1817.725
[19,     1] loss: 1814.433
[20,     1] loss: 1809.923
[21,     1] loss: 1815.513
[22,     1] loss: 1815.245
[23,     1] loss: 1814.319
[24,     1] loss: 1810.897
[25,     1] loss: 1813.414
[26,     1] loss: 1813.200
[27,     1] loss: 1813.505
[28,     1] loss: 1812.660
[29,     1] loss: 1814.360
[30,     1] loss: 1810.959
[31,     1] loss: 1809.820
[32,     1] loss: 1807.413
[33,     1] loss: 1803.741
[34,     1] loss: 1796.785
[35,     1] loss: 1785.461
[36,     1] loss: 1767.428
[37,     1] loss: 1740.882
[38,     1] loss: 1708.069
[39,     1] loss: 1666.102
[40,     1] loss: 1626.445
[41,     1] loss: 1606.869
[42,     1] loss: 1553.405
[43,     1] loss: 1653.830
[44,     1] loss: 1781.927
[45,     1] loss: 1589.554
[46,     1] loss: 1653.280
[47,     1] loss: 1586.703
[48,     1] loss: 1590.359
[49,     1] loss: 1625.128
[50,     1] loss: 1588.018
[51,     1] loss: 1593.785
[52,     1] loss: 1546.313
[53,     1] loss: 1525.550
[54,     1] loss: 1527.992
[55,     1] loss: 1513.251
[56,     1] loss: 1510.987
[57,     1] loss: 1472.332
[58,     1] loss: 1460.773
[59,     1] loss: 1436.206
[60,     1] loss: 1434.965
[61,     1] loss: 1462.375
[62,     1] loss: 1403.255
[63,     1] loss: 1438.611
[64,     1] loss: 1310.914
[65,     1] loss: 1367.521
[66,     1] loss: 1267.240
[67,     1] loss: 1417.615
[68,     1] loss: 1398.458
[69,     1] loss: 1305.052
[70,     1] loss: 1321.658
[71,     1] loss: 1408.462
[72,     1] loss: 1261.430
[73,     1] loss: 1233.997
[74,     1] loss: 1279.573
[75,     1] loss: 1288.923
[76,     1] loss: 1211.463
[77,     1] loss: 1141.303
[78,     1] loss: 1187.505
[79,     1] loss: 1149.627
[80,     1] loss: 1171.717
[81,     1] loss: 1353.028
[82,     1] loss: 1296.509
[83,     1] loss: 1244.276
[84,     1] loss: 1218.710
[85,     1] loss: 1175.172
[86,     1] loss: 1176.014
Early stopping applied (best metric=0.7542853951454163)
Finished Training
Total time taken: 12.992952585220337
{'Hydroxylation-K Validation Accuracy': 0.732919621749409, 'Hydroxylation-K Validation Sensitivity': 0.7785185185185185, 'Hydroxylation-K Validation Specificity': 0.7210526315789474, 'Hydroxylation-K Validation Precision': 0.45012503921946645, 'Hydroxylation-K AUC ROC': 0.8019688109161793, 'Hydroxylation-K AUC PR': 0.598832095308295, 'Hydroxylation-K MCC': 0.4289011557823134, 'Hydroxylation-K F1': 0.5591935863939862, 'Validation Loss (Hydroxylation-K)': 0.4378623386224111, 'Hydroxylation-P Validation Accuracy': 0.7225372485322235, 'Hydroxylation-P Validation Sensitivity': 0.7207936507936508, 'Hydroxylation-P Validation Specificity': 0.7225248142051972, 'Hydroxylation-P Validation Precision': 0.3970751327886772, 'Hydroxylation-P AUC ROC': 0.786677645720366, 'Hydroxylation-P AUC PR': 0.5212033977484448, 'Hydroxylation-P MCC': 0.3723857100715678, 'Hydroxylation-P F1': 0.500315979844927, 'Validation Loss (Hydroxylation-P)': 0.4193482061227163, 'Validation Loss (total)': 0.8572105487187703, 'TimeToTrain': 9.811599238713582}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017402604182154527,
 'learning_rate_Hydroxylation-K': 0.000586773001702289,
 'learning_rate_Hydroxylation-P': 0.006092558869931663,
 'log_base': 2.942315748466565,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 837941708,
 'sample_weights': [4.293092528272209, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.773781053044815,
 'weight_decay_Hydroxylation-K': 2.6725411612709182,
 'weight_decay_Hydroxylation-P': 1.0631696283684766}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1231.761
[2,     1] loss: 1237.201
[3,     1] loss: 1239.082
[4,     1] loss: 1232.744
[5,     1] loss: 1229.762
[6,     1] loss: 1230.890
[7,     1] loss: 1223.933
[8,     1] loss: 1218.741
[9,     1] loss: 1207.855
[10,     1] loss: 1168.332
[11,     1] loss: 1148.384
[12,     1] loss: 1127.624
[13,     1] loss: 1092.503
[14,     1] loss: 1046.414
[15,     1] loss: 1055.043
[16,     1] loss: 1022.167
[17,     1] loss: 1048.120
[18,     1] loss: 987.333
[19,     1] loss: 1029.923
[20,     1] loss: 1036.785
[21,     1] loss: 1011.005
[22,     1] loss: 971.902
[23,     1] loss: 966.768
[24,     1] loss: 995.609
[25,     1] loss: 943.440
[26,     1] loss: 919.858
[27,     1] loss: 924.994
[28,     1] loss: 962.317
[29,     1] loss: 942.961
[30,     1] loss: 930.121
[31,     1] loss: 926.259
[32,     1] loss: 956.272
[33,     1] loss: 925.915
[34,     1] loss: 938.940
[35,     1] loss: 908.863
[36,     1] loss: 916.753
[37,     1] loss: 880.608
[38,     1] loss: 897.951
[39,     1] loss: 897.647
[40,     1] loss: 860.684
[41,     1] loss: 854.079
[42,     1] loss: 862.340
[43,     1] loss: 874.773
[44,     1] loss: 855.525
[45,     1] loss: 843.257
[46,     1] loss: 867.570
[47,     1] loss: 883.249
[48,     1] loss: 805.178
[49,     1] loss: 780.158
[50,     1] loss: 799.011
[51,     1] loss: 790.804
[52,     1] loss: 808.740
[53,     1] loss: 772.838
[54,     1] loss: 775.300
[55,     1] loss: 810.186
[56,     1] loss: 736.252
Early stopping applied (best metric=0.9579132199287415)
Finished Training
Total time taken: 10.074556112289429
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1235.718
[2,     1] loss: 1234.743
[3,     1] loss: 1237.133
[4,     1] loss: 1236.174
[5,     1] loss: 1233.019
[6,     1] loss: 1233.678
[7,     1] loss: 1231.869
[8,     1] loss: 1226.483
[9,     1] loss: 1222.396
[10,     1] loss: 1214.643
[11,     1] loss: 1203.473
[12,     1] loss: 1172.444
[13,     1] loss: 1155.672
[14,     1] loss: 1107.746
[15,     1] loss: 1067.088
[16,     1] loss: 1073.880
[17,     1] loss: 1024.531
[18,     1] loss: 1039.985
[19,     1] loss: 1041.696
[20,     1] loss: 1015.398
[21,     1] loss: 1039.835
[22,     1] loss: 1037.938
[23,     1] loss: 1009.294
[24,     1] loss: 1051.606
[25,     1] loss: 966.912
[26,     1] loss: 992.442
[27,     1] loss: 996.770
[28,     1] loss: 965.507
[29,     1] loss: 967.900
[30,     1] loss: 956.900
[31,     1] loss: 971.396
[32,     1] loss: 966.207
[33,     1] loss: 920.455
[34,     1] loss: 999.849
[35,     1] loss: 905.859
[36,     1] loss: 927.962
[37,     1] loss: 914.744
[38,     1] loss: 910.654
[39,     1] loss: 872.185
[40,     1] loss: 852.704
[41,     1] loss: 903.886
[42,     1] loss: 885.403
[43,     1] loss: 885.271
[44,     1] loss: 855.616
[45,     1] loss: 857.570
[46,     1] loss: 813.602
[47,     1] loss: 822.069
[48,     1] loss: 818.179
[49,     1] loss: 878.780
[50,     1] loss: 794.717
[51,     1] loss: 822.690
[52,     1] loss: 807.690
[53,     1] loss: 787.642
[54,     1] loss: 791.826
[55,     1] loss: 810.279
[56,     1] loss: 801.976
[57,     1] loss: 754.622
[58,     1] loss: 760.052
[59,     1] loss: 737.304
[60,     1] loss: 770.871
[61,     1] loss: 762.851
[62,     1] loss: 734.291
[63,     1] loss: 763.278
[64,     1] loss: 719.653
[65,     1] loss: 714.116
Early stopping applied (best metric=0.8466912508010864)
Finished Training
Total time taken: 9.674018621444702
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.154
[2,     1] loss: 1235.734
[3,     1] loss: 1235.370
[4,     1] loss: 1233.738
[5,     1] loss: 1227.706
[6,     1] loss: 1223.742
[7,     1] loss: 1210.144
[8,     1] loss: 1198.770
[9,     1] loss: 1180.355
[10,     1] loss: 1156.427
[11,     1] loss: 1104.153
[12,     1] loss: 1105.468
[13,     1] loss: 1052.383
[14,     1] loss: 1043.221
[15,     1] loss: 1065.590
[16,     1] loss: 1045.319
[17,     1] loss: 1049.705
[18,     1] loss: 1064.727
[19,     1] loss: 997.250
[20,     1] loss: 996.379
[21,     1] loss: 1016.781
[22,     1] loss: 935.739
[23,     1] loss: 1009.003
[24,     1] loss: 993.966
[25,     1] loss: 969.378
[26,     1] loss: 1002.825
[27,     1] loss: 959.888
[28,     1] loss: 961.942
[29,     1] loss: 942.847
[30,     1] loss: 940.987
[31,     1] loss: 929.895
[32,     1] loss: 925.421
[33,     1] loss: 950.891
[34,     1] loss: 946.648
[35,     1] loss: 864.520
[36,     1] loss: 945.309
[37,     1] loss: 901.394
[38,     1] loss: 919.732
[39,     1] loss: 926.653
[40,     1] loss: 876.709
[41,     1] loss: 868.894
[42,     1] loss: 878.906
[43,     1] loss: 889.125
[44,     1] loss: 879.198
[45,     1] loss: 884.151
[46,     1] loss: 824.752
[47,     1] loss: 829.273
[48,     1] loss: 828.471
[49,     1] loss: 877.611
[50,     1] loss: 848.667
[51,     1] loss: 804.168
[52,     1] loss: 820.722
[53,     1] loss: 819.053
[54,     1] loss: 810.922
[55,     1] loss: 842.826
[56,     1] loss: 734.333
[57,     1] loss: 846.467
[58,     1] loss: 803.590
[59,     1] loss: 763.552
[60,     1] loss: 732.115
[61,     1] loss: 745.457
[62,     1] loss: 801.766
[63,     1] loss: 699.296
[64,     1] loss: 742.553
[65,     1] loss: 714.106
[66,     1] loss: 709.877
[67,     1] loss: 689.148
[68,     1] loss: 714.058
[69,     1] loss: 698.967
[70,     1] loss: 686.391
[71,     1] loss: 665.311
[72,     1] loss: 670.178
[73,     1] loss: 640.660
[74,     1] loss: 654.860
[75,     1] loss: 635.032
[76,     1] loss: 635.998
[77,     1] loss: 639.897
[78,     1] loss: 665.725
[79,     1] loss: 649.012
[80,     1] loss: 581.671
[81,     1] loss: 620.866
[82,     1] loss: 551.717
[83,     1] loss: 580.290
[84,     1] loss: 555.932
[85,     1] loss: 551.521
[86,     1] loss: 591.320
[87,     1] loss: 642.827
[88,     1] loss: 570.457
[89,     1] loss: 545.923
[90,     1] loss: 541.862
[91,     1] loss: 497.780
Early stopping applied (best metric=0.7558296322822571)
Finished Training
Total time taken: 14.374653577804565
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.218
[2,     1] loss: 1236.504
[3,     1] loss: 1232.982
[4,     1] loss: 1236.219
[5,     1] loss: 1234.293
[6,     1] loss: 1233.490
[7,     1] loss: 1227.779
[8,     1] loss: 1218.161
[9,     1] loss: 1212.658
[10,     1] loss: 1192.867
[11,     1] loss: 1173.996
[12,     1] loss: 1146.834
[13,     1] loss: 1126.894
[14,     1] loss: 1104.765
[15,     1] loss: 1060.612
[16,     1] loss: 1064.784
[17,     1] loss: 1071.841
[18,     1] loss: 1079.500
[19,     1] loss: 1082.560
[20,     1] loss: 1034.692
[21,     1] loss: 1036.407
[22,     1] loss: 1023.377
[23,     1] loss: 1020.704
[24,     1] loss: 1006.767
[25,     1] loss: 975.376
[26,     1] loss: 985.486
[27,     1] loss: 984.379
[28,     1] loss: 979.753
[29,     1] loss: 979.233
[30,     1] loss: 957.152
[31,     1] loss: 971.142
[32,     1] loss: 944.659
[33,     1] loss: 958.661
[34,     1] loss: 928.521
[35,     1] loss: 901.417
[36,     1] loss: 922.611
[37,     1] loss: 913.618
[38,     1] loss: 917.467
[39,     1] loss: 884.255
[40,     1] loss: 897.032
[41,     1] loss: 834.987
[42,     1] loss: 900.714
[43,     1] loss: 895.347
[44,     1] loss: 846.407
[45,     1] loss: 871.263
[46,     1] loss: 878.787
[47,     1] loss: 913.017
[48,     1] loss: 838.920
[49,     1] loss: 837.945
[50,     1] loss: 831.788
[51,     1] loss: 802.204
[52,     1] loss: 863.582
[53,     1] loss: 762.850
[54,     1] loss: 804.828
[55,     1] loss: 801.172
[56,     1] loss: 776.921
[57,     1] loss: 797.474
[58,     1] loss: 759.978
[59,     1] loss: 743.322
[60,     1] loss: 737.442
[61,     1] loss: 759.562
[62,     1] loss: 757.152
[63,     1] loss: 765.424
[64,     1] loss: 748.945
[65,     1] loss: 747.120
[66,     1] loss: 719.484
[67,     1] loss: 690.254
[68,     1] loss: 693.558
[69,     1] loss: 688.839
[70,     1] loss: 707.690
[71,     1] loss: 670.031
[72,     1] loss: 646.254
[73,     1] loss: 626.588
[74,     1] loss: 665.691
[75,     1] loss: 617.277
[76,     1] loss: 618.600
[77,     1] loss: 568.063
[78,     1] loss: 583.536
[79,     1] loss: 647.197
[80,     1] loss: 596.360
[81,     1] loss: 579.540
[82,     1] loss: 638.395
[83,     1] loss: 596.025
Early stopping applied (best metric=0.8092844486236572)
Finished Training
Total time taken: 12.551461458206177
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1238.053
[2,     1] loss: 1235.546
[3,     1] loss: 1232.895
[4,     1] loss: 1233.775
[5,     1] loss: 1230.061
[6,     1] loss: 1227.568
[7,     1] loss: 1216.104
[8,     1] loss: 1197.841
[9,     1] loss: 1182.989
[10,     1] loss: 1155.821
[11,     1] loss: 1111.435
[12,     1] loss: 1094.639
[13,     1] loss: 1040.597
[14,     1] loss: 1071.702
[15,     1] loss: 1023.736
[16,     1] loss: 1082.498
[17,     1] loss: 1066.227
[18,     1] loss: 985.277
[19,     1] loss: 1047.471
[20,     1] loss: 1009.423
[21,     1] loss: 976.435
[22,     1] loss: 1032.953
[23,     1] loss: 1009.031
[24,     1] loss: 990.615
[25,     1] loss: 999.066
[26,     1] loss: 975.831
[27,     1] loss: 948.983
[28,     1] loss: 977.483
[29,     1] loss: 942.727
[30,     1] loss: 962.559
[31,     1] loss: 926.373
[32,     1] loss: 915.461
[33,     1] loss: 972.713
[34,     1] loss: 920.334
[35,     1] loss: 922.908
[36,     1] loss: 916.660
[37,     1] loss: 898.039
[38,     1] loss: 880.799
[39,     1] loss: 914.965
[40,     1] loss: 888.051
[41,     1] loss: 862.856
[42,     1] loss: 863.820
[43,     1] loss: 872.969
[44,     1] loss: 868.064
[45,     1] loss: 855.928
[46,     1] loss: 878.783
[47,     1] loss: 802.259
[48,     1] loss: 831.980
[49,     1] loss: 780.127
Early stopping applied (best metric=0.8339416980743408)
Finished Training
Total time taken: 8.255196332931519
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1238.769
[2,     1] loss: 1234.646
[3,     1] loss: 1230.182
[4,     1] loss: 1236.552
[5,     1] loss: 1232.545
[6,     1] loss: 1227.792
[7,     1] loss: 1220.842
[8,     1] loss: 1203.631
[9,     1] loss: 1192.247
[10,     1] loss: 1169.733
[11,     1] loss: 1141.403
[12,     1] loss: 1104.250
[13,     1] loss: 1069.280
[14,     1] loss: 1092.754
[15,     1] loss: 1058.130
[16,     1] loss: 1028.501
[17,     1] loss: 1026.163
[18,     1] loss: 1028.670
[19,     1] loss: 1031.344
[20,     1] loss: 1001.907
[21,     1] loss: 980.685
[22,     1] loss: 1021.227
[23,     1] loss: 985.504
[24,     1] loss: 1015.173
[25,     1] loss: 980.725
[26,     1] loss: 971.866
[27,     1] loss: 959.634
[28,     1] loss: 967.979
[29,     1] loss: 971.685
[30,     1] loss: 963.350
[31,     1] loss: 930.061
[32,     1] loss: 933.680
[33,     1] loss: 978.206
[34,     1] loss: 959.243
[35,     1] loss: 943.463
[36,     1] loss: 909.215
[37,     1] loss: 893.894
[38,     1] loss: 907.785
[39,     1] loss: 929.399
[40,     1] loss: 926.549
[41,     1] loss: 870.595
[42,     1] loss: 880.898
[43,     1] loss: 859.636
[44,     1] loss: 846.607
[45,     1] loss: 883.238
[46,     1] loss: 835.738
[47,     1] loss: 905.335
[48,     1] loss: 872.008
[49,     1] loss: 858.771
[50,     1] loss: 866.761
[51,     1] loss: 877.297
[52,     1] loss: 856.807
[53,     1] loss: 837.509
[54,     1] loss: 814.626
[55,     1] loss: 785.822
[56,     1] loss: 826.225
[57,     1] loss: 798.439
[58,     1] loss: 794.469
[59,     1] loss: 759.752
[60,     1] loss: 740.288
[61,     1] loss: 757.071
[62,     1] loss: 765.193
[63,     1] loss: 719.539
[64,     1] loss: 767.322
[65,     1] loss: 734.209
[66,     1] loss: 688.729
[67,     1] loss: 727.843
[68,     1] loss: 762.579
[69,     1] loss: 711.733
[70,     1] loss: 704.478
[71,     1] loss: 698.676
[72,     1] loss: 665.764
[73,     1] loss: 729.893
[74,     1] loss: 648.314
[75,     1] loss: 664.719
[76,     1] loss: 708.718
[77,     1] loss: 662.302
[78,     1] loss: 690.182
[79,     1] loss: 667.568
[80,     1] loss: 629.980
[81,     1] loss: 647.432
[82,     1] loss: 608.854
[83,     1] loss: 602.892
[84,     1] loss: 560.242
[85,     1] loss: 587.839
[86,     1] loss: 618.991
[87,     1] loss: 568.522
[88,     1] loss: 632.060
[89,     1] loss: 554.610
[90,     1] loss: 659.343
[91,     1] loss: 590.440
[92,     1] loss: 545.008
[93,     1] loss: 565.257
[94,     1] loss: 568.625
[95,     1] loss: 552.278
[96,     1] loss: 492.677
[97,     1] loss: 562.300
[98,     1] loss: 497.945
[99,     1] loss: 565.531
[100,     1] loss: 531.762
[101,     1] loss: 523.685
[102,     1] loss: 512.498
[103,     1] loss: 515.727
[104,     1] loss: 515.385
[105,     1] loss: 463.244
[106,     1] loss: 516.636
[107,     1] loss: 497.257
[108,     1] loss: 474.492
[109,     1] loss: 449.307
[110,     1] loss: 511.149
[111,     1] loss: 465.263
[112,     1] loss: 477.933
[113,     1] loss: 539.037
[114,     1] loss: 536.775
[115,     1] loss: 444.247
[116,     1] loss: 489.629
[117,     1] loss: 419.504
[118,     1] loss: 412.723
[119,     1] loss: 442.386
[120,     1] loss: 476.744
[121,     1] loss: 438.161
[122,     1] loss: 477.900
[123,     1] loss: 449.943
[124,     1] loss: 426.969
[125,     1] loss: 400.204
[126,     1] loss: 446.719
[127,     1] loss: 436.586
[128,     1] loss: 454.457
[129,     1] loss: 459.703
[130,     1] loss: 407.626
[131,     1] loss: 447.461
[132,     1] loss: 456.239
[133,     1] loss: 418.791
[134,     1] loss: 455.172
[135,     1] loss: 379.779
[136,     1] loss: 473.308
[137,     1] loss: 419.861
[138,     1] loss: 384.172
[139,     1] loss: 396.389
[140,     1] loss: 398.037
[141,     1] loss: 454.441
[142,     1] loss: 414.205
[143,     1] loss: 443.172
[144,     1] loss: 366.033
[145,     1] loss: 397.784
[146,     1] loss: 376.668
[147,     1] loss: 341.756
[148,     1] loss: 342.951
[149,     1] loss: 359.696
[150,     1] loss: 403.354
[151,     1] loss: 350.912
[152,     1] loss: 344.626
[153,     1] loss: 348.360
Early stopping applied (best metric=0.6418553590774536)
Finished Training
Total time taken: 26.24235987663269
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1238.405
[2,     1] loss: 1232.538
[3,     1] loss: 1240.646
[4,     1] loss: 1235.104
[5,     1] loss: 1236.042
[6,     1] loss: 1236.967
[7,     1] loss: 1231.035
[8,     1] loss: 1226.629
[9,     1] loss: 1230.514
[10,     1] loss: 1223.681
[11,     1] loss: 1219.583
[12,     1] loss: 1207.107
[13,     1] loss: 1188.605
[14,     1] loss: 1170.618
[15,     1] loss: 1148.780
[16,     1] loss: 1114.372
[17,     1] loss: 1093.039
[18,     1] loss: 1105.940
[19,     1] loss: 1062.000
[20,     1] loss: 1059.342
[21,     1] loss: 1046.815
[22,     1] loss: 1049.677
[23,     1] loss: 1028.556
[24,     1] loss: 991.488
[25,     1] loss: 959.542
[26,     1] loss: 993.163
[27,     1] loss: 984.227
[28,     1] loss: 956.599
[29,     1] loss: 1002.951
[30,     1] loss: 970.492
[31,     1] loss: 948.252
[32,     1] loss: 893.730
[33,     1] loss: 907.822
[34,     1] loss: 937.105
[35,     1] loss: 893.974
[36,     1] loss: 904.591
[37,     1] loss: 870.133
[38,     1] loss: 852.597
[39,     1] loss: 854.807
[40,     1] loss: 902.412
[41,     1] loss: 850.922
[42,     1] loss: 851.978
[43,     1] loss: 808.149
[44,     1] loss: 811.066
[45,     1] loss: 803.472
[46,     1] loss: 832.582
[47,     1] loss: 812.274
[48,     1] loss: 805.703
[49,     1] loss: 852.922
Early stopping applied (best metric=0.9411370754241943)
Finished Training
Total time taken: 8.830256938934326
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.504
[2,     1] loss: 1232.649
[3,     1] loss: 1234.033
[4,     1] loss: 1230.394
[5,     1] loss: 1225.454
[6,     1] loss: 1222.136
[7,     1] loss: 1209.156
[8,     1] loss: 1173.011
[9,     1] loss: 1139.397
[10,     1] loss: 1100.616
[11,     1] loss: 1072.054
[12,     1] loss: 1049.132
[13,     1] loss: 1044.906
[14,     1] loss: 1070.841
[15,     1] loss: 1049.061
[16,     1] loss: 987.722
[17,     1] loss: 980.641
[18,     1] loss: 1016.116
[19,     1] loss: 1004.786
[20,     1] loss: 1044.702
[21,     1] loss: 990.689
[22,     1] loss: 988.048
[23,     1] loss: 977.802
[24,     1] loss: 955.570
[25,     1] loss: 978.442
[26,     1] loss: 982.122
[27,     1] loss: 945.809
[28,     1] loss: 979.742
[29,     1] loss: 992.169
[30,     1] loss: 909.551
[31,     1] loss: 955.530
[32,     1] loss: 920.415
[33,     1] loss: 898.314
[34,     1] loss: 942.788
[35,     1] loss: 881.314
[36,     1] loss: 869.111
[37,     1] loss: 865.635
Early stopping applied (best metric=0.9333009719848633)
Finished Training
Total time taken: 7.092072248458862
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.052
[2,     1] loss: 1239.037
[3,     1] loss: 1236.847
[4,     1] loss: 1235.081
[5,     1] loss: 1232.605
[6,     1] loss: 1229.787
[7,     1] loss: 1228.287
[8,     1] loss: 1223.011
[9,     1] loss: 1216.693
[10,     1] loss: 1193.277
[11,     1] loss: 1171.784
[12,     1] loss: 1159.172
[13,     1] loss: 1110.346
[14,     1] loss: 1090.221
[15,     1] loss: 1088.262
[16,     1] loss: 1059.505
[17,     1] loss: 1024.999
[18,     1] loss: 1085.398
[19,     1] loss: 1005.643
[20,     1] loss: 1024.229
[21,     1] loss: 1005.239
[22,     1] loss: 1054.557
[23,     1] loss: 1000.084
[24,     1] loss: 999.023
[25,     1] loss: 1009.170
[26,     1] loss: 993.974
[27,     1] loss: 986.766
[28,     1] loss: 970.052
[29,     1] loss: 983.139
[30,     1] loss: 957.048
[31,     1] loss: 932.052
[32,     1] loss: 935.877
[33,     1] loss: 945.487
[34,     1] loss: 921.350
[35,     1] loss: 931.394
[36,     1] loss: 917.415
[37,     1] loss: 923.567
[38,     1] loss: 929.142
[39,     1] loss: 890.298
[40,     1] loss: 891.569
[41,     1] loss: 875.545
[42,     1] loss: 948.166
[43,     1] loss: 887.096
[44,     1] loss: 895.344
[45,     1] loss: 866.590
[46,     1] loss: 849.415
[47,     1] loss: 847.892
[48,     1] loss: 843.564
[49,     1] loss: 789.171
[50,     1] loss: 823.746
[51,     1] loss: 789.753
[52,     1] loss: 789.302
[53,     1] loss: 818.455
[54,     1] loss: 795.123
[55,     1] loss: 781.337
[56,     1] loss: 804.854
[57,     1] loss: 756.308
[58,     1] loss: 751.006
[59,     1] loss: 782.939
[60,     1] loss: 747.247
[61,     1] loss: 796.166
[62,     1] loss: 714.645
[63,     1] loss: 700.854
[64,     1] loss: 742.847
[65,     1] loss: 705.964
[66,     1] loss: 742.716
[67,     1] loss: 715.209
[68,     1] loss: 686.359
[69,     1] loss: 689.893
[70,     1] loss: 694.637
[71,     1] loss: 681.515
[72,     1] loss: 639.788
[73,     1] loss: 667.760
[74,     1] loss: 637.841
[75,     1] loss: 636.527
[76,     1] loss: 689.402
[77,     1] loss: 638.627
Early stopping applied (best metric=0.8379361629486084)
Finished Training
Total time taken: 13.206994771957397
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1239.581
[2,     1] loss: 1235.740
[3,     1] loss: 1238.403
[4,     1] loss: 1235.096
[5,     1] loss: 1235.972
[6,     1] loss: 1238.371
[7,     1] loss: 1233.266
[8,     1] loss: 1234.206
[9,     1] loss: 1230.542
[10,     1] loss: 1237.733
[11,     1] loss: 1228.005
[12,     1] loss: 1221.461
[13,     1] loss: 1210.417
[14,     1] loss: 1193.213
[15,     1] loss: 1168.069
[16,     1] loss: 1148.985
[17,     1] loss: 1106.196
[18,     1] loss: 1096.102
[19,     1] loss: 1071.824
[20,     1] loss: 1065.363
[21,     1] loss: 1055.769
[22,     1] loss: 1058.326
[23,     1] loss: 1042.650
[24,     1] loss: 1006.632
[25,     1] loss: 1051.606
[26,     1] loss: 1023.526
[27,     1] loss: 1011.551
[28,     1] loss: 1001.223
[29,     1] loss: 996.476
[30,     1] loss: 1007.700
[31,     1] loss: 1015.072
[32,     1] loss: 963.867
[33,     1] loss: 975.728
[34,     1] loss: 977.458
[35,     1] loss: 971.861
[36,     1] loss: 950.654
[37,     1] loss: 937.486
[38,     1] loss: 938.396
[39,     1] loss: 919.692
[40,     1] loss: 975.141
[41,     1] loss: 932.852
[42,     1] loss: 911.652
[43,     1] loss: 912.697
[44,     1] loss: 900.798
[45,     1] loss: 905.565
[46,     1] loss: 878.752
[47,     1] loss: 804.981
[48,     1] loss: 901.592
[49,     1] loss: 862.551
[50,     1] loss: 846.669
[51,     1] loss: 841.218
[52,     1] loss: 820.104
[53,     1] loss: 881.256
[54,     1] loss: 768.891
[55,     1] loss: 790.961
[56,     1] loss: 778.989
[57,     1] loss: 772.132
[58,     1] loss: 758.549
[59,     1] loss: 800.640
[60,     1] loss: 719.048
[61,     1] loss: 836.349
[62,     1] loss: 761.157
[63,     1] loss: 655.598
[64,     1] loss: 699.720
[65,     1] loss: 746.858
[66,     1] loss: 677.357
[67,     1] loss: 687.192
[68,     1] loss: 659.648
[69,     1] loss: 653.864
[70,     1] loss: 662.858
[71,     1] loss: 716.828
[72,     1] loss: 653.508
[73,     1] loss: 666.008
[74,     1] loss: 603.449
[75,     1] loss: 625.526
[76,     1] loss: 592.882
[77,     1] loss: 582.654
[78,     1] loss: 560.485
[79,     1] loss: 569.504
[80,     1] loss: 602.258
[81,     1] loss: 579.645
[82,     1] loss: 601.572
[83,     1] loss: 600.239
[84,     1] loss: 559.122
[85,     1] loss: 571.177
[86,     1] loss: 532.753
[87,     1] loss: 553.308
[88,     1] loss: 548.564
[89,     1] loss: 529.996
[90,     1] loss: 556.925
[91,     1] loss: 515.661
Early stopping applied (best metric=0.7429906129837036)
Finished Training
Total time taken: 17.04111957550049
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.896
[2,     1] loss: 1235.175
[3,     1] loss: 1231.620
[4,     1] loss: 1231.046
[5,     1] loss: 1232.219
[6,     1] loss: 1231.477
[7,     1] loss: 1222.522
[8,     1] loss: 1219.939
[9,     1] loss: 1190.999
[10,     1] loss: 1181.773
[11,     1] loss: 1143.778
[12,     1] loss: 1109.657
[13,     1] loss: 1078.323
[14,     1] loss: 1079.196
[15,     1] loss: 1060.033
[16,     1] loss: 1070.563
[17,     1] loss: 1021.862
[18,     1] loss: 1028.313
[19,     1] loss: 1058.396
[20,     1] loss: 1005.064
[21,     1] loss: 1014.871
[22,     1] loss: 994.994
[23,     1] loss: 989.322
[24,     1] loss: 993.595
[25,     1] loss: 1023.983
[26,     1] loss: 999.439
[27,     1] loss: 991.932
[28,     1] loss: 996.936
[29,     1] loss: 940.001
[30,     1] loss: 948.251
[31,     1] loss: 917.930
[32,     1] loss: 942.329
[33,     1] loss: 981.183
[34,     1] loss: 968.946
[35,     1] loss: 924.399
[36,     1] loss: 941.036
[37,     1] loss: 937.331
[38,     1] loss: 884.657
[39,     1] loss: 929.800
[40,     1] loss: 894.411
[41,     1] loss: 912.709
[42,     1] loss: 888.036
[43,     1] loss: 857.389
[44,     1] loss: 850.675
[45,     1] loss: 843.536
[46,     1] loss: 878.640
[47,     1] loss: 850.970
[48,     1] loss: 856.225
[49,     1] loss: 889.602
[50,     1] loss: 797.340
[51,     1] loss: 790.963
[52,     1] loss: 836.222
[53,     1] loss: 828.719
[54,     1] loss: 804.809
[55,     1] loss: 816.107
[56,     1] loss: 769.225
[57,     1] loss: 782.631
[58,     1] loss: 784.578
Early stopping applied (best metric=0.8675305843353271)
Finished Training
Total time taken: 10.818142652511597
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.782
[2,     1] loss: 1232.751
[3,     1] loss: 1235.033
[4,     1] loss: 1232.762
[5,     1] loss: 1232.777
[6,     1] loss: 1227.003
[7,     1] loss: 1229.071
[8,     1] loss: 1226.938
[9,     1] loss: 1217.998
[10,     1] loss: 1200.489
[11,     1] loss: 1171.075
[12,     1] loss: 1158.043
[13,     1] loss: 1127.743
[14,     1] loss: 1099.037
[15,     1] loss: 1070.195
[16,     1] loss: 1082.536
[17,     1] loss: 1070.726
[18,     1] loss: 1111.304
[19,     1] loss: 1082.034
[20,     1] loss: 1042.486
[21,     1] loss: 1027.155
[22,     1] loss: 1018.591
[23,     1] loss: 1014.231
[24,     1] loss: 993.794
[25,     1] loss: 1019.709
[26,     1] loss: 1017.244
[27,     1] loss: 1017.463
[28,     1] loss: 995.366
[29,     1] loss: 1000.935
[30,     1] loss: 1013.399
[31,     1] loss: 949.480
[32,     1] loss: 1002.423
[33,     1] loss: 972.025
[34,     1] loss: 969.781
[35,     1] loss: 950.421
[36,     1] loss: 963.214
[37,     1] loss: 949.485
[38,     1] loss: 937.299
[39,     1] loss: 891.134
[40,     1] loss: 942.033
[41,     1] loss: 911.653
[42,     1] loss: 857.420
[43,     1] loss: 904.525
[44,     1] loss: 857.638
[45,     1] loss: 880.271
[46,     1] loss: 874.529
[47,     1] loss: 889.633
[48,     1] loss: 818.635
[49,     1] loss: 841.191
[50,     1] loss: 868.495
[51,     1] loss: 892.897
[52,     1] loss: 788.093
[53,     1] loss: 863.697
[54,     1] loss: 769.130
[55,     1] loss: 883.304
[56,     1] loss: 799.559
[57,     1] loss: 883.426
[58,     1] loss: 789.574
[59,     1] loss: 812.694
[60,     1] loss: 762.854
[61,     1] loss: 757.239
[62,     1] loss: 735.838
[63,     1] loss: 744.623
[64,     1] loss: 685.768
[65,     1] loss: 663.662
[66,     1] loss: 738.874
[67,     1] loss: 691.327
[68,     1] loss: 734.933
[69,     1] loss: 752.932
[70,     1] loss: 651.414
[71,     1] loss: 617.084
[72,     1] loss: 675.761
[73,     1] loss: 636.036
[74,     1] loss: 653.495
[75,     1] loss: 670.172
[76,     1] loss: 618.148
[77,     1] loss: 608.080
[78,     1] loss: 587.824
[79,     1] loss: 612.098
[80,     1] loss: 583.362
[81,     1] loss: 620.222
[82,     1] loss: 593.642
[83,     1] loss: 548.781
[84,     1] loss: 568.795
[85,     1] loss: 549.889
[86,     1] loss: 501.417
[87,     1] loss: 476.319
[88,     1] loss: 522.680
[89,     1] loss: 559.342
[90,     1] loss: 509.532
[91,     1] loss: 503.330
[92,     1] loss: 483.896
[93,     1] loss: 494.694
[94,     1] loss: 510.095
[95,     1] loss: 513.251
Early stopping applied (best metric=0.6135909557342529)
Finished Training
Total time taken: 14.490176439285278
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.959
[2,     1] loss: 1235.754
[3,     1] loss: 1235.945
[4,     1] loss: 1231.895
[5,     1] loss: 1234.352
[6,     1] loss: 1230.639
[7,     1] loss: 1230.328
[8,     1] loss: 1228.157
[9,     1] loss: 1219.388
[10,     1] loss: 1211.508
[11,     1] loss: 1191.873
[12,     1] loss: 1161.236
[13,     1] loss: 1137.531
[14,     1] loss: 1101.254
[15,     1] loss: 1086.117
[16,     1] loss: 1089.601
[17,     1] loss: 1054.665
[18,     1] loss: 1042.083
[19,     1] loss: 999.799
[20,     1] loss: 1010.965
[21,     1] loss: 1038.245
[22,     1] loss: 1010.030
[23,     1] loss: 1014.184
[24,     1] loss: 913.017
[25,     1] loss: 945.810
[26,     1] loss: 983.440
[27,     1] loss: 943.864
[28,     1] loss: 948.630
[29,     1] loss: 949.793
[30,     1] loss: 914.322
[31,     1] loss: 947.260
[32,     1] loss: 941.792
[33,     1] loss: 945.640
[34,     1] loss: 964.050
[35,     1] loss: 900.216
[36,     1] loss: 887.960
[37,     1] loss: 874.962
[38,     1] loss: 882.004
[39,     1] loss: 882.988
[40,     1] loss: 856.541
[41,     1] loss: 874.652
[42,     1] loss: 874.366
[43,     1] loss: 857.494
[44,     1] loss: 827.367
[45,     1] loss: 841.037
[46,     1] loss: 840.584
[47,     1] loss: 799.298
[48,     1] loss: 815.401
[49,     1] loss: 809.383
[50,     1] loss: 800.316
[51,     1] loss: 772.094
[52,     1] loss: 738.472
[53,     1] loss: 815.319
Early stopping applied (best metric=0.9423022270202637)
Finished Training
Total time taken: 8.47974705696106
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.974
[2,     1] loss: 1235.269
[3,     1] loss: 1233.012
[4,     1] loss: 1237.327
[5,     1] loss: 1233.456
[6,     1] loss: 1231.784
[7,     1] loss: 1230.942
[8,     1] loss: 1220.044
[9,     1] loss: 1210.728
[10,     1] loss: 1198.223
[11,     1] loss: 1181.328
[12,     1] loss: 1148.363
[13,     1] loss: 1136.720
[14,     1] loss: 1088.076
[15,     1] loss: 1058.263
[16,     1] loss: 1078.432
[17,     1] loss: 1050.491
[18,     1] loss: 1031.726
[19,     1] loss: 1031.912
[20,     1] loss: 1003.622
[21,     1] loss: 1013.724
[22,     1] loss: 1015.268
[23,     1] loss: 1037.599
[24,     1] loss: 1028.735
[25,     1] loss: 994.346
[26,     1] loss: 1009.593
[27,     1] loss: 997.273
[28,     1] loss: 999.910
[29,     1] loss: 987.796
[30,     1] loss: 981.137
[31,     1] loss: 934.896
[32,     1] loss: 933.701
[33,     1] loss: 950.390
[34,     1] loss: 936.266
[35,     1] loss: 955.433
[36,     1] loss: 913.269
[37,     1] loss: 923.391
[38,     1] loss: 893.349
[39,     1] loss: 927.984
[40,     1] loss: 879.225
[41,     1] loss: 886.818
[42,     1] loss: 873.370
[43,     1] loss: 864.331
[44,     1] loss: 885.841
[45,     1] loss: 824.615
[46,     1] loss: 846.360
[47,     1] loss: 781.304
[48,     1] loss: 819.163
[49,     1] loss: 825.443
[50,     1] loss: 796.236
[51,     1] loss: 837.145
[52,     1] loss: 797.712
[53,     1] loss: 762.115
[54,     1] loss: 832.138
[55,     1] loss: 772.735
[56,     1] loss: 770.963
[57,     1] loss: 734.253
[58,     1] loss: 749.689
[59,     1] loss: 731.974
[60,     1] loss: 772.801
[61,     1] loss: 705.824
[62,     1] loss: 710.637
[63,     1] loss: 649.048
[64,     1] loss: 745.917
[65,     1] loss: 763.397
[66,     1] loss: 691.929
[67,     1] loss: 726.150
[68,     1] loss: 688.486
[69,     1] loss: 693.925
[70,     1] loss: 689.766
[71,     1] loss: 674.072
[72,     1] loss: 634.473
Early stopping applied (best metric=0.8168079257011414)
Finished Training
Total time taken: 11.324777364730835
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1237.603
[2,     1] loss: 1238.450
[3,     1] loss: 1238.052
[4,     1] loss: 1233.672
[5,     1] loss: 1234.192
[6,     1] loss: 1228.360
[7,     1] loss: 1215.880
[8,     1] loss: 1202.018
[9,     1] loss: 1177.492
[10,     1] loss: 1132.456
[11,     1] loss: 1088.643
[12,     1] loss: 1092.336
[13,     1] loss: 1089.204
[14,     1] loss: 1090.805
[15,     1] loss: 1018.623
[16,     1] loss: 1048.334
[17,     1] loss: 991.469
[18,     1] loss: 997.235
[19,     1] loss: 978.986
[20,     1] loss: 969.509
[21,     1] loss: 973.763
[22,     1] loss: 995.224
[23,     1] loss: 971.280
[24,     1] loss: 980.692
[25,     1] loss: 946.779
[26,     1] loss: 970.915
[27,     1] loss: 959.377
[28,     1] loss: 960.900
[29,     1] loss: 929.550
[30,     1] loss: 931.521
[31,     1] loss: 896.189
[32,     1] loss: 885.317
[33,     1] loss: 928.744
[34,     1] loss: 896.204
[35,     1] loss: 968.075
[36,     1] loss: 859.934
[37,     1] loss: 885.203
[38,     1] loss: 866.868
[39,     1] loss: 910.883
[40,     1] loss: 912.041
[41,     1] loss: 850.589
[42,     1] loss: 831.807
[43,     1] loss: 820.993
[44,     1] loss: 838.130
[45,     1] loss: 808.849
[46,     1] loss: 818.206
[47,     1] loss: 797.060
[48,     1] loss: 820.608
[49,     1] loss: 824.444
[50,     1] loss: 828.260
[51,     1] loss: 767.956
[52,     1] loss: 800.829
[53,     1] loss: 756.590
[54,     1] loss: 752.640
[55,     1] loss: 749.587
[56,     1] loss: 751.888
[57,     1] loss: 753.201
[58,     1] loss: 702.639
[59,     1] loss: 663.353
[60,     1] loss: 700.143
[61,     1] loss: 712.504
[62,     1] loss: 732.659
[63,     1] loss: 686.016
[64,     1] loss: 656.305
[65,     1] loss: 646.792
[66,     1] loss: 671.681
[67,     1] loss: 644.260
[68,     1] loss: 652.158
[69,     1] loss: 627.370
[70,     1] loss: 636.492
Early stopping applied (best metric=0.801912248134613)
Finished Training
Total time taken: 10.879210233688354
{'Hydroxylation-K Validation Accuracy': 0.7618794326241135, 'Hydroxylation-K Validation Sensitivity': 0.6474074074074074, 'Hydroxylation-K Validation Specificity': 0.7912280701754386, 'Hydroxylation-K Validation Precision': 0.4415845429080723, 'Hydroxylation-K AUC ROC': 0.7939181286549708, 'Hydroxylation-K AUC PR': 0.5415525549824994, 'Hydroxylation-K MCC': 0.38606136082482523, 'Hydroxylation-K F1': 0.5174537931204598, 'Validation Loss (Hydroxylation-K)': 0.4510871668656667, 'Hydroxylation-P Validation Accuracy': 0.7896293758354059, 'Hydroxylation-P Validation Sensitivity': 0.754021164021164, 'Hydroxylation-P Validation Specificity': 0.7973140805027682, 'Hydroxylation-P Validation Precision': 0.450469995004169, 'Hydroxylation-P AUC ROC': 0.8549229170278848, 'Hydroxylation-P AUC PR': 0.5839554261314485, 'Hydroxylation-P MCC': 0.4623934112335471, 'Hydroxylation-P F1': 0.5604844114227973, 'Validation Loss (Hydroxylation-P)': 0.37178112467130026, 'Validation Loss (total)': 0.822868291536967, 'TimeToTrain': 12.222316217422485}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010054257592051062,
 'learning_rate_Hydroxylation-K': 0.008856003699596856,
 'learning_rate_Hydroxylation-P': 0.0010623236321020738,
 'log_base': 1.5528172463703749,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3660567260,
 'sample_weights': [1.5480784594902244, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.026721143026084,
 'weight_decay_Hydroxylation-K': 4.541719302258169,
 'weight_decay_Hydroxylation-P': 1.190499678144843}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1729.098
[2,     1] loss: 1713.776
[3,     1] loss: 1713.260
[4,     1] loss: 1712.971
[5,     1] loss: 1711.087
[6,     1] loss: 1706.239
[7,     1] loss: 1701.550
[8,     1] loss: 1704.045
[9,     1] loss: 1695.718
[10,     1] loss: 1700.726
[11,     1] loss: 1692.285
[12,     1] loss: 1689.105
[13,     1] loss: 1675.412
[14,     1] loss: 1665.025
[15,     1] loss: 1653.708
[16,     1] loss: 1623.204
[17,     1] loss: 1593.081
[18,     1] loss: 1581.913
[19,     1] loss: 1556.919
[20,     1] loss: 1518.588
[21,     1] loss: 1489.092
[22,     1] loss: 1488.332
[23,     1] loss: 1463.988
[24,     1] loss: 1462.614
[25,     1] loss: 1457.745
[26,     1] loss: 1454.072
[27,     1] loss: 1392.279
[28,     1] loss: 1496.124
[29,     1] loss: 1444.381
[30,     1] loss: 1442.033
[31,     1] loss: 1434.443
[32,     1] loss: 1411.586
[33,     1] loss: 1428.904
[34,     1] loss: 1407.191
[35,     1] loss: 1431.062
[36,     1] loss: 1375.044
[37,     1] loss: 1395.768
[38,     1] loss: 1366.348
[39,     1] loss: 1312.350
[40,     1] loss: 1427.865
[41,     1] loss: 1342.282
[42,     1] loss: 1298.203
[43,     1] loss: 1310.490
[44,     1] loss: 1325.073
[45,     1] loss: 1418.221
[46,     1] loss: 1301.652
[47,     1] loss: 1301.061
[48,     1] loss: 1240.767
[49,     1] loss: 1285.648
[50,     1] loss: 1275.237
[51,     1] loss: 1277.460
[52,     1] loss: 1281.461
[53,     1] loss: 1247.943
[54,     1] loss: 1237.310
[55,     1] loss: 1220.121
[56,     1] loss: 1294.854
[57,     1] loss: 1274.060
[58,     1] loss: 1252.006
[59,     1] loss: 1222.821
[60,     1] loss: 1163.040
[61,     1] loss: 1158.739
[62,     1] loss: 1111.647
[63,     1] loss: 1073.914
[64,     1] loss: 1134.816
[65,     1] loss: 1125.882
[66,     1] loss: 1140.890
[67,     1] loss: 1088.881
[68,     1] loss: 1194.396
[69,     1] loss: 1048.047
[70,     1] loss: 1047.979
[71,     1] loss: 1007.299
[72,     1] loss: 1022.127
[73,     1] loss: 1063.042
[74,     1] loss: 989.188
[75,     1] loss: 965.130
[76,     1] loss: 917.198
[77,     1] loss: 945.248
[78,     1] loss: 983.500
[79,     1] loss: 929.320
[80,     1] loss: 1073.627
[81,     1] loss: 1072.457
[82,     1] loss: 859.160
[83,     1] loss: 889.426
[84,     1] loss: 947.493
[85,     1] loss: 924.071
[86,     1] loss: 900.652
[87,     1] loss: 892.845
[88,     1] loss: 794.329
Early stopping applied (best metric=0.8250026702880859)
Finished Training
Total time taken: 15.516199111938477
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1703.251
[2,     1] loss: 1713.198
[3,     1] loss: 1702.367
[4,     1] loss: 1708.809
[5,     1] loss: 1715.049
[6,     1] loss: 1702.741
[7,     1] loss: 1705.347
[8,     1] loss: 1700.597
[9,     1] loss: 1703.300
[10,     1] loss: 1703.581
[11,     1] loss: 1688.070
[12,     1] loss: 1690.357
[13,     1] loss: 1674.327
[14,     1] loss: 1669.531
[15,     1] loss: 1646.273
[16,     1] loss: 1616.147
[17,     1] loss: 1586.009
[18,     1] loss: 1572.916
[19,     1] loss: 1543.263
[20,     1] loss: 1512.474
[21,     1] loss: 1454.273
[22,     1] loss: 1445.564
[23,     1] loss: 1505.020
[24,     1] loss: 1462.409
[25,     1] loss: 1437.773
[26,     1] loss: 1430.692
[27,     1] loss: 1427.527
[28,     1] loss: 1407.256
[29,     1] loss: 1359.804
[30,     1] loss: 1376.693
[31,     1] loss: 1334.397
[32,     1] loss: 1393.659
[33,     1] loss: 1373.987
[34,     1] loss: 1360.958
[35,     1] loss: 1391.918
[36,     1] loss: 1375.489
[37,     1] loss: 1394.208
[38,     1] loss: 1331.552
[39,     1] loss: 1356.964
[40,     1] loss: 1330.694
[41,     1] loss: 1322.862
[42,     1] loss: 1343.146
[43,     1] loss: 1314.991
[44,     1] loss: 1289.131
[45,     1] loss: 1235.769
[46,     1] loss: 1230.473
[47,     1] loss: 1232.708
[48,     1] loss: 1237.844
[49,     1] loss: 1280.263
[50,     1] loss: 1182.812
[51,     1] loss: 1227.723
[52,     1] loss: 1283.550
[53,     1] loss: 1233.990
[54,     1] loss: 1211.464
[55,     1] loss: 1187.964
[56,     1] loss: 1115.933
[57,     1] loss: 1133.826
[58,     1] loss: 1117.193
[59,     1] loss: 1165.317
[60,     1] loss: 1090.928
[61,     1] loss: 1180.591
[62,     1] loss: 1039.847
[63,     1] loss: 1206.787
[64,     1] loss: 1093.344
[65,     1] loss: 1094.072
[66,     1] loss: 1132.367
[67,     1] loss: 991.770
[68,     1] loss: 1045.774
[69,     1] loss: 1022.951
[70,     1] loss: 972.747
Early stopping applied (best metric=0.8398025035858154)
Finished Training
Total time taken: 12.088993072509766
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1713.787
[2,     1] loss: 1706.477
[3,     1] loss: 1708.925
[4,     1] loss: 1701.137
[5,     1] loss: 1710.779
[6,     1] loss: 1708.223
[7,     1] loss: 1704.325
[8,     1] loss: 1710.647
[9,     1] loss: 1714.538
[10,     1] loss: 1702.534
[11,     1] loss: 1702.652
[12,     1] loss: 1692.934
[13,     1] loss: 1704.749
[14,     1] loss: 1692.090
[15,     1] loss: 1688.807
[16,     1] loss: 1673.927
[17,     1] loss: 1660.819
[18,     1] loss: 1653.027
[19,     1] loss: 1629.161
[20,     1] loss: 1615.400
[21,     1] loss: 1587.683
[22,     1] loss: 1523.623
[23,     1] loss: 1599.971
[24,     1] loss: 1516.442
[25,     1] loss: 1506.491
[26,     1] loss: 1503.889
[27,     1] loss: 1473.280
[28,     1] loss: 1420.797
[29,     1] loss: 1417.065
[30,     1] loss: 1431.110
[31,     1] loss: 1453.774
[32,     1] loss: 1392.228
[33,     1] loss: 1374.343
[34,     1] loss: 1349.121
[35,     1] loss: 1376.518
[36,     1] loss: 1348.433
[37,     1] loss: 1348.847
[38,     1] loss: 1331.391
[39,     1] loss: 1331.865
[40,     1] loss: 1357.318
[41,     1] loss: 1254.120
[42,     1] loss: 1288.254
[43,     1] loss: 1256.496
[44,     1] loss: 1254.667
[45,     1] loss: 1262.809
[46,     1] loss: 1230.909
[47,     1] loss: 1231.344
[48,     1] loss: 1174.429
[49,     1] loss: 1179.154
[50,     1] loss: 1195.421
[51,     1] loss: 1186.058
[52,     1] loss: 1068.649
[53,     1] loss: 1085.556
[54,     1] loss: 1147.533
[55,     1] loss: 1084.632
Early stopping applied (best metric=0.8953874111175537)
Finished Training
Total time taken: 8.671964168548584
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1712.501
[2,     1] loss: 1706.835
[3,     1] loss: 1706.167
[4,     1] loss: 1706.196
[5,     1] loss: 1714.598
[6,     1] loss: 1708.971
[7,     1] loss: 1701.628
[8,     1] loss: 1707.041
[9,     1] loss: 1701.850
[10,     1] loss: 1700.261
[11,     1] loss: 1699.379
[12,     1] loss: 1694.665
[13,     1] loss: 1688.574
[14,     1] loss: 1681.041
[15,     1] loss: 1670.988
[16,     1] loss: 1656.074
[17,     1] loss: 1644.636
[18,     1] loss: 1601.245
[19,     1] loss: 1582.036
[20,     1] loss: 1568.808
[21,     1] loss: 1531.504
[22,     1] loss: 1524.940
[23,     1] loss: 1495.514
[24,     1] loss: 1526.610
[25,     1] loss: 1468.291
[26,     1] loss: 1447.878
[27,     1] loss: 1479.167
[28,     1] loss: 1426.939
[29,     1] loss: 1359.867
[30,     1] loss: 1444.283
[31,     1] loss: 1398.053
[32,     1] loss: 1466.347
[33,     1] loss: 1436.100
[34,     1] loss: 1398.235
[35,     1] loss: 1401.012
[36,     1] loss: 1476.609
[37,     1] loss: 1373.500
[38,     1] loss: 1383.896
[39,     1] loss: 1369.470
[40,     1] loss: 1356.415
[41,     1] loss: 1383.706
[42,     1] loss: 1363.446
[43,     1] loss: 1302.978
[44,     1] loss: 1339.256
[45,     1] loss: 1257.242
[46,     1] loss: 1361.909
[47,     1] loss: 1325.285
[48,     1] loss: 1281.598
[49,     1] loss: 1276.080
[50,     1] loss: 1258.590
[51,     1] loss: 1290.864
[52,     1] loss: 1232.569
[53,     1] loss: 1237.528
[54,     1] loss: 1213.544
[55,     1] loss: 1210.765
[56,     1] loss: 1190.567
[57,     1] loss: 1182.694
[58,     1] loss: 1191.204
[59,     1] loss: 1155.681
[60,     1] loss: 1193.243
[61,     1] loss: 1134.744
[62,     1] loss: 1215.424
[63,     1] loss: 1100.860
[64,     1] loss: 1099.554
[65,     1] loss: 1151.074
[66,     1] loss: 1089.805
[67,     1] loss: 1037.487
[68,     1] loss: 1084.502
[69,     1] loss: 1075.643
[70,     1] loss: 1076.136
[71,     1] loss: 1038.754
[72,     1] loss: 1029.772
[73,     1] loss: 1075.473
[74,     1] loss: 980.247
[75,     1] loss: 1082.950
[76,     1] loss: 1019.691
[77,     1] loss: 1006.614
Early stopping applied (best metric=0.8036720752716064)
Finished Training
Total time taken: 11.25387692451477
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1712.649
[2,     1] loss: 1710.262
[3,     1] loss: 1710.485
[4,     1] loss: 1708.102
[5,     1] loss: 1707.550
[6,     1] loss: 1706.078
[7,     1] loss: 1709.157
[8,     1] loss: 1705.326
[9,     1] loss: 1702.242
[10,     1] loss: 1703.947
[11,     1] loss: 1698.223
[12,     1] loss: 1690.954
[13,     1] loss: 1687.759
[14,     1] loss: 1665.171
[15,     1] loss: 1648.310
[16,     1] loss: 1629.884
[17,     1] loss: 1605.036
[18,     1] loss: 1579.728
[19,     1] loss: 1557.726
[20,     1] loss: 1560.323
[21,     1] loss: 1506.591
[22,     1] loss: 1513.059
[23,     1] loss: 1448.194
[24,     1] loss: 1485.993
[25,     1] loss: 1456.402
[26,     1] loss: 1422.851
[27,     1] loss: 1471.382
[28,     1] loss: 1411.668
[29,     1] loss: 1377.811
[30,     1] loss: 1375.694
[31,     1] loss: 1398.109
[32,     1] loss: 1415.640
[33,     1] loss: 1368.489
[34,     1] loss: 1390.620
[35,     1] loss: 1336.752
[36,     1] loss: 1318.926
[37,     1] loss: 1314.062
[38,     1] loss: 1295.643
[39,     1] loss: 1313.160
[40,     1] loss: 1228.409
[41,     1] loss: 1255.876
[42,     1] loss: 1215.736
[43,     1] loss: 1228.145
[44,     1] loss: 1202.083
[45,     1] loss: 1221.837
[46,     1] loss: 1171.876
[47,     1] loss: 1180.354
[48,     1] loss: 1136.391
[49,     1] loss: 1111.898
[50,     1] loss: 1105.887
[51,     1] loss: 1119.750
[52,     1] loss: 1112.047
[53,     1] loss: 1092.965
Early stopping applied (best metric=0.8777034878730774)
Finished Training
Total time taken: 7.339857816696167
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1710.431
[2,     1] loss: 1714.462
[3,     1] loss: 1704.785
[4,     1] loss: 1708.059
[5,     1] loss: 1704.025
[6,     1] loss: 1704.762
[7,     1] loss: 1704.814
[8,     1] loss: 1713.149
[9,     1] loss: 1708.301
[10,     1] loss: 1701.525
[11,     1] loss: 1703.094
[12,     1] loss: 1698.457
[13,     1] loss: 1694.309
[14,     1] loss: 1689.603
[15,     1] loss: 1689.007
[16,     1] loss: 1672.878
[17,     1] loss: 1658.702
[18,     1] loss: 1647.306
[19,     1] loss: 1609.687
[20,     1] loss: 1587.314
[21,     1] loss: 1575.971
[22,     1] loss: 1578.444
[23,     1] loss: 1527.962
[24,     1] loss: 1555.152
[25,     1] loss: 1522.940
[26,     1] loss: 1511.840
[27,     1] loss: 1503.929
[28,     1] loss: 1475.417
[29,     1] loss: 1455.835
[30,     1] loss: 1450.109
[31,     1] loss: 1412.375
[32,     1] loss: 1362.360
[33,     1] loss: 1376.103
[34,     1] loss: 1391.803
[35,     1] loss: 1366.018
[36,     1] loss: 1377.781
[37,     1] loss: 1431.338
[38,     1] loss: 1406.528
[39,     1] loss: 1402.629
[40,     1] loss: 1356.673
[41,     1] loss: 1367.814
[42,     1] loss: 1370.642
[43,     1] loss: 1319.566
[44,     1] loss: 1342.320
[45,     1] loss: 1377.311
[46,     1] loss: 1364.830
[47,     1] loss: 1287.474
[48,     1] loss: 1273.798
[49,     1] loss: 1227.116
[50,     1] loss: 1250.517
[51,     1] loss: 1282.616
[52,     1] loss: 1225.255
[53,     1] loss: 1210.688
[54,     1] loss: 1227.864
[55,     1] loss: 1160.141
[56,     1] loss: 1121.233
[57,     1] loss: 1092.318
[58,     1] loss: 1053.601
[59,     1] loss: 1109.119
[60,     1] loss: 1180.655
[61,     1] loss: 1081.943
[62,     1] loss: 1087.724
[63,     1] loss: 1086.095
[64,     1] loss: 1075.556
[65,     1] loss: 1004.023
[66,     1] loss: 1010.143
[67,     1] loss: 1080.650
[68,     1] loss: 1024.510
[69,     1] loss: 1045.099
Early stopping applied (best metric=0.779809296131134)
Finished Training
Total time taken: 10.5771164894104
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1718.717
[2,     1] loss: 1705.453
[3,     1] loss: 1707.176
[4,     1] loss: 1712.218
[5,     1] loss: 1710.878
[6,     1] loss: 1704.834
[7,     1] loss: 1705.120
[8,     1] loss: 1697.919
[9,     1] loss: 1704.254
[10,     1] loss: 1701.762
[11,     1] loss: 1689.498
[12,     1] loss: 1686.990
[13,     1] loss: 1674.503
[14,     1] loss: 1665.837
[15,     1] loss: 1659.808
[16,     1] loss: 1633.067
[17,     1] loss: 1617.265
[18,     1] loss: 1599.180
[19,     1] loss: 1585.812
[20,     1] loss: 1556.986
[21,     1] loss: 1516.314
[22,     1] loss: 1519.046
[23,     1] loss: 1540.014
[24,     1] loss: 1438.265
[25,     1] loss: 1480.575
[26,     1] loss: 1433.209
[27,     1] loss: 1422.306
[28,     1] loss: 1479.270
[29,     1] loss: 1420.945
[30,     1] loss: 1429.403
[31,     1] loss: 1465.239
[32,     1] loss: 1371.600
[33,     1] loss: 1380.282
[34,     1] loss: 1413.378
[35,     1] loss: 1373.074
[36,     1] loss: 1363.709
[37,     1] loss: 1357.221
[38,     1] loss: 1328.460
[39,     1] loss: 1316.987
[40,     1] loss: 1328.981
[41,     1] loss: 1342.266
[42,     1] loss: 1236.145
[43,     1] loss: 1300.957
[44,     1] loss: 1332.660
[45,     1] loss: 1326.401
[46,     1] loss: 1258.520
[47,     1] loss: 1238.651
[48,     1] loss: 1241.517
[49,     1] loss: 1293.804
[50,     1] loss: 1246.376
[51,     1] loss: 1158.928
[52,     1] loss: 1118.892
[53,     1] loss: 1217.683
[54,     1] loss: 1188.196
[55,     1] loss: 1192.683
[56,     1] loss: 1099.382
[57,     1] loss: 1285.440
[58,     1] loss: 1109.305
[59,     1] loss: 1095.864
[60,     1] loss: 1097.056
[61,     1] loss: 1148.651
[62,     1] loss: 1136.378
[63,     1] loss: 1118.566
[64,     1] loss: 1195.523
[65,     1] loss: 1104.400
[66,     1] loss: 1084.886
[67,     1] loss: 1102.082
[68,     1] loss: 1054.401
[69,     1] loss: 1021.336
[70,     1] loss: 966.257
[71,     1] loss: 1001.463
[72,     1] loss: 967.494
[73,     1] loss: 1064.802
[74,     1] loss: 942.317
[75,     1] loss: 1066.565
[76,     1] loss: 931.183
[77,     1] loss: 1006.123
[78,     1] loss: 992.219
[79,     1] loss: 867.937
[80,     1] loss: 913.158
[81,     1] loss: 914.875
[82,     1] loss: 886.717
[83,     1] loss: 874.933
Early stopping applied (best metric=0.8481085300445557)
Finished Training
Total time taken: 13.074998140335083
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1717.335
[2,     1] loss: 1710.607
[3,     1] loss: 1705.464
[4,     1] loss: 1703.843
[5,     1] loss: 1699.397
[6,     1] loss: 1707.306
[7,     1] loss: 1705.220
[8,     1] loss: 1703.689
[9,     1] loss: 1696.051
[10,     1] loss: 1688.750
[11,     1] loss: 1684.365
[12,     1] loss: 1671.064
[13,     1] loss: 1656.828
[14,     1] loss: 1625.293
[15,     1] loss: 1599.422
[16,     1] loss: 1569.301
[17,     1] loss: 1534.882
[18,     1] loss: 1507.640
[19,     1] loss: 1470.008
[20,     1] loss: 1443.767
[21,     1] loss: 1477.681
[22,     1] loss: 1432.258
[23,     1] loss: 1409.010
[24,     1] loss: 1423.351
[25,     1] loss: 1454.442
[26,     1] loss: 1383.140
[27,     1] loss: 1437.360
[28,     1] loss: 1405.088
[29,     1] loss: 1412.771
[30,     1] loss: 1344.211
[31,     1] loss: 1365.407
[32,     1] loss: 1427.156
[33,     1] loss: 1409.143
[34,     1] loss: 1414.036
[35,     1] loss: 1391.456
[36,     1] loss: 1350.060
[37,     1] loss: 1385.243
[38,     1] loss: 1365.015
[39,     1] loss: 1374.246
[40,     1] loss: 1404.575
[41,     1] loss: 1340.123
[42,     1] loss: 1320.804
[43,     1] loss: 1306.172
[44,     1] loss: 1383.577
[45,     1] loss: 1296.606
[46,     1] loss: 1321.812
[47,     1] loss: 1285.271
[48,     1] loss: 1325.194
[49,     1] loss: 1243.453
[50,     1] loss: 1215.359
[51,     1] loss: 1323.610
[52,     1] loss: 1209.543
[53,     1] loss: 1241.619
[54,     1] loss: 1182.612
[55,     1] loss: 1228.224
[56,     1] loss: 1199.298
[57,     1] loss: 1163.227
[58,     1] loss: 1112.365
[59,     1] loss: 1135.623
[60,     1] loss: 1136.773
[61,     1] loss: 1157.587
[62,     1] loss: 1091.701
[63,     1] loss: 1092.227
[64,     1] loss: 1037.399
[65,     1] loss: 1048.205
[66,     1] loss: 1131.117
[67,     1] loss: 1102.958
[68,     1] loss: 1090.261
[69,     1] loss: 1006.558
[70,     1] loss: 991.881
[71,     1] loss: 960.709
Early stopping applied (best metric=0.9310506582260132)
Finished Training
Total time taken: 13.307086944580078
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1710.143
[2,     1] loss: 1709.345
[3,     1] loss: 1710.715
[4,     1] loss: 1707.556
[5,     1] loss: 1705.956
[6,     1] loss: 1707.660
[7,     1] loss: 1703.189
[8,     1] loss: 1705.379
[9,     1] loss: 1702.823
[10,     1] loss: 1698.253
[11,     1] loss: 1693.267
[12,     1] loss: 1692.989
[13,     1] loss: 1686.818
[14,     1] loss: 1670.399
[15,     1] loss: 1654.067
[16,     1] loss: 1653.900
[17,     1] loss: 1619.008
[18,     1] loss: 1565.174
[19,     1] loss: 1570.222
[20,     1] loss: 1523.227
[21,     1] loss: 1513.745
[22,     1] loss: 1478.794
[23,     1] loss: 1451.156
[24,     1] loss: 1434.235
[25,     1] loss: 1407.743
[26,     1] loss: 1400.004
[27,     1] loss: 1410.650
[28,     1] loss: 1428.784
[29,     1] loss: 1359.010
[30,     1] loss: 1365.057
[31,     1] loss: 1452.991
[32,     1] loss: 1422.291
[33,     1] loss: 1385.150
[34,     1] loss: 1411.210
[35,     1] loss: 1357.739
[36,     1] loss: 1352.981
[37,     1] loss: 1335.363
[38,     1] loss: 1378.626
[39,     1] loss: 1307.256
[40,     1] loss: 1289.233
[41,     1] loss: 1331.767
[42,     1] loss: 1328.591
[43,     1] loss: 1314.080
[44,     1] loss: 1347.182
[45,     1] loss: 1365.375
[46,     1] loss: 1311.457
[47,     1] loss: 1296.496
[48,     1] loss: 1297.663
[49,     1] loss: 1271.009
[50,     1] loss: 1257.218
[51,     1] loss: 1321.360
[52,     1] loss: 1335.376
[53,     1] loss: 1234.515
[54,     1] loss: 1186.488
[55,     1] loss: 1201.728
[56,     1] loss: 1182.885
[57,     1] loss: 1220.554
[58,     1] loss: 1130.322
[59,     1] loss: 1146.563
[60,     1] loss: 1194.290
[61,     1] loss: 1159.607
[62,     1] loss: 1164.815
[63,     1] loss: 1119.575
[64,     1] loss: 1030.295
[65,     1] loss: 1077.988
[66,     1] loss: 1066.219
[67,     1] loss: 1071.109
[68,     1] loss: 1108.460
[69,     1] loss: 943.402
[70,     1] loss: 995.823
[71,     1] loss: 1022.150
[72,     1] loss: 1013.597
Early stopping applied (best metric=0.9070255756378174)
Finished Training
Total time taken: 13.491493463516235
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1716.286
[2,     1] loss: 1709.733
[3,     1] loss: 1711.832
[4,     1] loss: 1711.869
[5,     1] loss: 1705.837
[6,     1] loss: 1709.911
[7,     1] loss: 1708.036
[8,     1] loss: 1707.531
[9,     1] loss: 1713.138
[10,     1] loss: 1708.075
[11,     1] loss: 1707.741
[12,     1] loss: 1700.805
[13,     1] loss: 1699.321
[14,     1] loss: 1712.552
[15,     1] loss: 1693.010
[16,     1] loss: 1689.516
[17,     1] loss: 1680.924
[18,     1] loss: 1670.473
[19,     1] loss: 1657.329
[20,     1] loss: 1636.011
[21,     1] loss: 1618.014
[22,     1] loss: 1594.252
[23,     1] loss: 1587.661
[24,     1] loss: 1560.832
[25,     1] loss: 1534.716
[26,     1] loss: 1480.798
[27,     1] loss: 1464.080
[28,     1] loss: 1460.197
[29,     1] loss: 1466.376
[30,     1] loss: 1451.951
[31,     1] loss: 1483.268
[32,     1] loss: 1409.692
[33,     1] loss: 1342.576
[34,     1] loss: 1347.180
[35,     1] loss: 1390.753
[36,     1] loss: 1361.014
[37,     1] loss: 1412.335
[38,     1] loss: 1354.651
[39,     1] loss: 1376.982
[40,     1] loss: 1354.238
[41,     1] loss: 1392.451
[42,     1] loss: 1322.323
[43,     1] loss: 1271.789
[44,     1] loss: 1308.876
[45,     1] loss: 1314.982
[46,     1] loss: 1311.514
[47,     1] loss: 1253.746
[48,     1] loss: 1318.185
[49,     1] loss: 1259.089
[50,     1] loss: 1233.439
[51,     1] loss: 1159.605
[52,     1] loss: 1188.560
[53,     1] loss: 1250.580
[54,     1] loss: 1147.881
[55,     1] loss: 1164.890
[56,     1] loss: 1174.390
[57,     1] loss: 1089.287
[58,     1] loss: 1118.078
[59,     1] loss: 1142.031
[60,     1] loss: 1126.987
[61,     1] loss: 1038.159
[62,     1] loss: 1028.010
[63,     1] loss: 1045.174
Early stopping applied (best metric=0.8861978650093079)
Finished Training
Total time taken: 10.53061580657959
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1715.204
[2,     1] loss: 1710.745
[3,     1] loss: 1713.410
[4,     1] loss: 1707.239
[5,     1] loss: 1704.786
[6,     1] loss: 1705.078
[7,     1] loss: 1708.167
[8,     1] loss: 1700.120
[9,     1] loss: 1705.158
[10,     1] loss: 1701.105
[11,     1] loss: 1697.093
[12,     1] loss: 1694.200
[13,     1] loss: 1689.377
[14,     1] loss: 1683.059
[15,     1] loss: 1672.964
[16,     1] loss: 1661.445
[17,     1] loss: 1639.782
[18,     1] loss: 1619.309
[19,     1] loss: 1619.164
[20,     1] loss: 1571.310
[21,     1] loss: 1580.488
[22,     1] loss: 1528.190
[23,     1] loss: 1497.548
[24,     1] loss: 1483.234
[25,     1] loss: 1499.193
[26,     1] loss: 1467.726
[27,     1] loss: 1411.150
[28,     1] loss: 1529.337
[29,     1] loss: 1444.533
[30,     1] loss: 1438.359
[31,     1] loss: 1440.887
[32,     1] loss: 1413.132
[33,     1] loss: 1441.395
[34,     1] loss: 1435.213
[35,     1] loss: 1421.735
[36,     1] loss: 1421.594
[37,     1] loss: 1389.012
[38,     1] loss: 1379.918
[39,     1] loss: 1371.536
[40,     1] loss: 1381.450
[41,     1] loss: 1429.028
[42,     1] loss: 1384.675
[43,     1] loss: 1339.313
[44,     1] loss: 1395.952
[45,     1] loss: 1322.773
[46,     1] loss: 1333.812
[47,     1] loss: 1344.166
[48,     1] loss: 1304.275
[49,     1] loss: 1296.234
[50,     1] loss: 1264.114
[51,     1] loss: 1249.681
[52,     1] loss: 1281.696
[53,     1] loss: 1256.192
[54,     1] loss: 1238.680
[55,     1] loss: 1224.750
[56,     1] loss: 1245.054
[57,     1] loss: 1239.600
[58,     1] loss: 1143.021
[59,     1] loss: 1195.458
[60,     1] loss: 1147.660
[61,     1] loss: 1267.943
[62,     1] loss: 1140.358
[63,     1] loss: 1163.632
[64,     1] loss: 1165.520
[65,     1] loss: 1094.548
[66,     1] loss: 1146.070
[67,     1] loss: 1102.792
[68,     1] loss: 1048.922
[69,     1] loss: 1081.080
[70,     1] loss: 1023.536
[71,     1] loss: 1045.355
[72,     1] loss: 1014.813
[73,     1] loss: 1067.290
[74,     1] loss: 1058.607
[75,     1] loss: 929.902
[76,     1] loss: 996.428
[77,     1] loss: 1010.119
[78,     1] loss: 985.884
[79,     1] loss: 976.781
Early stopping applied (best metric=0.7387120723724365)
Finished Training
Total time taken: 13.986049175262451
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1703.990
[2,     1] loss: 1711.361
[3,     1] loss: 1702.933
[4,     1] loss: 1707.445
[5,     1] loss: 1710.265
[6,     1] loss: 1704.629
[7,     1] loss: 1700.153
[8,     1] loss: 1701.177
[9,     1] loss: 1697.233
[10,     1] loss: 1689.150
[11,     1] loss: 1684.031
[12,     1] loss: 1664.991
[13,     1] loss: 1637.668
[14,     1] loss: 1618.202
[15,     1] loss: 1594.516
[16,     1] loss: 1564.127
[17,     1] loss: 1551.363
[18,     1] loss: 1514.695
[19,     1] loss: 1496.646
[20,     1] loss: 1459.643
[21,     1] loss: 1482.822
[22,     1] loss: 1494.231
[23,     1] loss: 1411.473
[24,     1] loss: 1430.815
[25,     1] loss: 1421.482
[26,     1] loss: 1389.313
[27,     1] loss: 1422.678
[28,     1] loss: 1394.876
[29,     1] loss: 1442.101
[30,     1] loss: 1403.242
[31,     1] loss: 1365.174
[32,     1] loss: 1411.467
[33,     1] loss: 1392.728
[34,     1] loss: 1369.592
[35,     1] loss: 1417.971
[36,     1] loss: 1364.095
[37,     1] loss: 1389.859
[38,     1] loss: 1284.220
[39,     1] loss: 1310.097
[40,     1] loss: 1366.431
[41,     1] loss: 1271.853
[42,     1] loss: 1262.822
[43,     1] loss: 1310.563
[44,     1] loss: 1237.729
[45,     1] loss: 1250.880
[46,     1] loss: 1273.520
[47,     1] loss: 1292.660
[48,     1] loss: 1231.270
[49,     1] loss: 1249.301
[50,     1] loss: 1286.955
[51,     1] loss: 1308.024
[52,     1] loss: 1234.934
[53,     1] loss: 1195.738
[54,     1] loss: 1239.551
[55,     1] loss: 1243.872
[56,     1] loss: 1156.849
[57,     1] loss: 1170.212
[58,     1] loss: 1130.022
[59,     1] loss: 1120.555
[60,     1] loss: 1192.684
[61,     1] loss: 1120.683
[62,     1] loss: 1201.273
[63,     1] loss: 1078.970
[64,     1] loss: 1072.783
[65,     1] loss: 1145.169
[66,     1] loss: 1166.156
[67,     1] loss: 1117.286
[68,     1] loss: 1089.360
[69,     1] loss: 1042.700
[70,     1] loss: 1077.678
[71,     1] loss: 1018.161
[72,     1] loss: 1038.603
[73,     1] loss: 1098.509
[74,     1] loss: 1039.071
[75,     1] loss: 972.920
[76,     1] loss: 1051.663
[77,     1] loss: 1080.084
[78,     1] loss: 1001.231
[79,     1] loss: 1083.228
[80,     1] loss: 1037.155
[81,     1] loss: 1012.214
[82,     1] loss: 1052.313
Early stopping applied (best metric=0.8171546459197998)
Finished Training
Total time taken: 13.047975540161133
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1705.007
[2,     1] loss: 1711.271
[3,     1] loss: 1706.918
[4,     1] loss: 1708.243
[5,     1] loss: 1707.496
[6,     1] loss: 1708.821
[7,     1] loss: 1707.925
[8,     1] loss: 1702.731
[9,     1] loss: 1703.345
[10,     1] loss: 1700.940
[11,     1] loss: 1697.822
[12,     1] loss: 1684.635
[13,     1] loss: 1675.588
[14,     1] loss: 1664.503
[15,     1] loss: 1651.267
[16,     1] loss: 1619.649
[17,     1] loss: 1576.186
[18,     1] loss: 1556.435
[19,     1] loss: 1534.433
[20,     1] loss: 1532.197
[21,     1] loss: 1500.726
[22,     1] loss: 1498.450
[23,     1] loss: 1473.800
[24,     1] loss: 1393.278
[25,     1] loss: 1476.602
[26,     1] loss: 1455.857
[27,     1] loss: 1490.789
[28,     1] loss: 1435.266
[29,     1] loss: 1415.439
[30,     1] loss: 1411.863
[31,     1] loss: 1425.414
[32,     1] loss: 1384.454
[33,     1] loss: 1389.444
[34,     1] loss: 1396.054
[35,     1] loss: 1403.888
[36,     1] loss: 1322.154
[37,     1] loss: 1392.083
[38,     1] loss: 1301.990
[39,     1] loss: 1344.529
[40,     1] loss: 1337.170
[41,     1] loss: 1354.509
[42,     1] loss: 1311.288
[43,     1] loss: 1241.161
[44,     1] loss: 1264.460
[45,     1] loss: 1221.480
[46,     1] loss: 1226.010
[47,     1] loss: 1195.831
[48,     1] loss: 1222.945
[49,     1] loss: 1149.584
[50,     1] loss: 1184.797
[51,     1] loss: 1201.235
[52,     1] loss: 1195.781
[53,     1] loss: 1207.687
[54,     1] loss: 1167.736
[55,     1] loss: 1191.338
[56,     1] loss: 1098.043
[57,     1] loss: 1140.941
[58,     1] loss: 1125.990
[59,     1] loss: 1067.974
[60,     1] loss: 1097.956
Early stopping applied (best metric=0.8377562761306763)
Finished Training
Total time taken: 11.01759147644043
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1703.264
[2,     1] loss: 1712.182
[3,     1] loss: 1707.116
[4,     1] loss: 1708.651
[5,     1] loss: 1708.221
[6,     1] loss: 1702.686
[7,     1] loss: 1711.346
[8,     1] loss: 1707.924
[9,     1] loss: 1705.980
[10,     1] loss: 1701.347
[11,     1] loss: 1698.864
[12,     1] loss: 1704.690
[13,     1] loss: 1698.826
[14,     1] loss: 1696.316
[15,     1] loss: 1688.960
[16,     1] loss: 1683.633
[17,     1] loss: 1673.371
[18,     1] loss: 1654.760
[19,     1] loss: 1636.885
[20,     1] loss: 1612.248
[21,     1] loss: 1593.994
[22,     1] loss: 1561.703
[23,     1] loss: 1538.178
[24,     1] loss: 1546.712
[25,     1] loss: 1475.147
[26,     1] loss: 1477.829
[27,     1] loss: 1420.664
[28,     1] loss: 1406.695
[29,     1] loss: 1451.801
[30,     1] loss: 1422.085
[31,     1] loss: 1410.663
[32,     1] loss: 1404.130
[33,     1] loss: 1375.104
[34,     1] loss: 1377.408
[35,     1] loss: 1460.757
[36,     1] loss: 1305.435
[37,     1] loss: 1353.520
[38,     1] loss: 1319.621
[39,     1] loss: 1305.552
[40,     1] loss: 1368.576
[41,     1] loss: 1354.029
[42,     1] loss: 1337.704
[43,     1] loss: 1298.317
[44,     1] loss: 1296.303
[45,     1] loss: 1285.831
[46,     1] loss: 1262.950
[47,     1] loss: 1238.586
[48,     1] loss: 1198.793
[49,     1] loss: 1184.438
[50,     1] loss: 1198.228
[51,     1] loss: 1228.617
[52,     1] loss: 1122.201
[53,     1] loss: 1147.188
[54,     1] loss: 1234.964
[55,     1] loss: 1120.669
[56,     1] loss: 1168.624
[57,     1] loss: 1134.696
[58,     1] loss: 1141.959
[59,     1] loss: 1139.383
[60,     1] loss: 1151.699
[61,     1] loss: 1089.582
[62,     1] loss: 1046.322
[63,     1] loss: 1082.521
[64,     1] loss: 1116.139
[65,     1] loss: 1008.389
[66,     1] loss: 1068.300
[67,     1] loss: 1004.106
[68,     1] loss: 1106.227
[69,     1] loss: 1117.004
[70,     1] loss: 1059.899
[71,     1] loss: 984.518
[72,     1] loss: 971.141
[73,     1] loss: 1000.146
[74,     1] loss: 999.021
[75,     1] loss: 990.051
[76,     1] loss: 965.899
[77,     1] loss: 895.513
[78,     1] loss: 887.574
[79,     1] loss: 902.735
[80,     1] loss: 958.697
[81,     1] loss: 925.824
[82,     1] loss: 943.529
[83,     1] loss: 831.939
[84,     1] loss: 812.478
[85,     1] loss: 891.793
[86,     1] loss: 898.486
[87,     1] loss: 791.109
[88,     1] loss: 844.031
[89,     1] loss: 863.665
[90,     1] loss: 848.542
[91,     1] loss: 838.851
Early stopping applied (best metric=0.7548490762710571)
Finished Training
Total time taken: 16.349985599517822
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1711.059
[2,     1] loss: 1713.133
[3,     1] loss: 1713.264
[4,     1] loss: 1714.835
[5,     1] loss: 1709.153
[6,     1] loss: 1714.537
[7,     1] loss: 1706.813
[8,     1] loss: 1719.746
[9,     1] loss: 1713.763
[10,     1] loss: 1705.685
[11,     1] loss: 1708.826
[12,     1] loss: 1698.727
[13,     1] loss: 1698.885
[14,     1] loss: 1694.708
[15,     1] loss: 1686.001
[16,     1] loss: 1682.009
[17,     1] loss: 1670.300
[18,     1] loss: 1652.496
[19,     1] loss: 1638.630
[20,     1] loss: 1619.173
[21,     1] loss: 1584.207
[22,     1] loss: 1557.576
[23,     1] loss: 1519.073
[24,     1] loss: 1520.427
[25,     1] loss: 1513.566
[26,     1] loss: 1456.485
[27,     1] loss: 1499.731
[28,     1] loss: 1415.156
[29,     1] loss: 1421.777
[30,     1] loss: 1452.809
[31,     1] loss: 1394.976
[32,     1] loss: 1425.147
[33,     1] loss: 1432.832
[34,     1] loss: 1465.071
[35,     1] loss: 1340.280
[36,     1] loss: 1421.946
[37,     1] loss: 1331.052
[38,     1] loss: 1346.644
[39,     1] loss: 1375.973
[40,     1] loss: 1352.087
[41,     1] loss: 1367.194
[42,     1] loss: 1347.641
[43,     1] loss: 1307.732
[44,     1] loss: 1340.457
[45,     1] loss: 1307.999
[46,     1] loss: 1357.931
[47,     1] loss: 1237.790
[48,     1] loss: 1252.946
[49,     1] loss: 1244.138
[50,     1] loss: 1249.237
[51,     1] loss: 1230.993
[52,     1] loss: 1272.396
[53,     1] loss: 1182.346
[54,     1] loss: 1168.189
[55,     1] loss: 1159.631
Early stopping applied (best metric=0.9338037371635437)
Finished Training
Total time taken: 9.183070182800293
{'Hydroxylation-K Validation Accuracy': 0.7407801418439717, 'Hydroxylation-K Validation Sensitivity': 0.7222222222222222, 'Hydroxylation-K Validation Specificity': 0.7456140350877193, 'Hydroxylation-K Validation Precision': 0.42787006509142733, 'Hydroxylation-K AUC ROC': 0.7950682261208577, 'Hydroxylation-K AUC PR': 0.590675900902242, 'Hydroxylation-K MCC': 0.39974351587168727, 'Hydroxylation-K F1': 0.5326244823716089, 'Validation Loss (Hydroxylation-K)': 0.4475074311097463, 'Hydroxylation-P Validation Accuracy': 0.763373805052197, 'Hydroxylation-P Validation Sensitivity': 0.7441798941798942, 'Hydroxylation-P Validation Specificity': 0.7674871564666567, 'Hydroxylation-P Validation Precision': 0.4174602168317934, 'Hydroxylation-P AUC ROC': 0.8286307811734267, 'Hydroxylation-P AUC PR': 0.565439013685156, 'Hydroxylation-P MCC': 0.4234274175464363, 'Hydroxylation-P F1': 0.5298939858618835, 'Validation Loss (Hydroxylation-P)': 0.39756162961324054, 'Validation Loss (total)': 0.8450690587361653, 'TimeToTrain': 11.962458260854085}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008803084416689028,
 'learning_rate_Hydroxylation-K': 0.007287356382296542,
 'learning_rate_Hydroxylation-P': 0.007263175345112306,
 'log_base': 2.8819648609686737,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3702570684,
 'sample_weights': [3.7963921078721783, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.288645596700545,
 'weight_decay_Hydroxylation-K': 5.908373532271098,
 'weight_decay_Hydroxylation-P': 2.028936719289851}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1244.163
[2,     1] loss: 1282.656
[3,     1] loss: 1253.526
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00843267429849223,
 'learning_rate_Hydroxylation-K': 0.004102893484317027,
 'learning_rate_Hydroxylation-P': 0.005482201194869042,
 'log_base': 2.0720139400149287,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 465344147,
 'sample_weights': [1.5772194885663509, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.965754694523163,
 'weight_decay_Hydroxylation-K': 1.2525625154374231,
 'weight_decay_Hydroxylation-P': 4.011325095055657}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1392.645
[2,     1] loss: 1399.393
[3,     1] loss: 1414.850
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024199622374338177,
 'learning_rate_Hydroxylation-K': 8.567262834644608e-05,
 'learning_rate_Hydroxylation-P': 0.004854721088781084,
 'log_base': 2.755225191747167,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2729406801,
 'sample_weights': [2.291551002439412, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.933792579661834,
 'weight_decay_Hydroxylation-K': 5.732765015265016,
 'weight_decay_Hydroxylation-P': 5.65197472094352}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1254.856
[2,     1] loss: 1254.130
[3,     1] loss: 1251.077
[4,     1] loss: 1256.585
[5,     1] loss: 1250.034
[6,     1] loss: 1249.837
[7,     1] loss: 1239.501
[8,     1] loss: 1216.060
[9,     1] loss: 1187.259
[10,     1] loss: 1149.793
[11,     1] loss: 1107.995
[12,     1] loss: 1061.345
[13,     1] loss: 1063.718
[14,     1] loss: 1039.744
[15,     1] loss: 1047.276
[16,     1] loss: 1017.772
[17,     1] loss: 1032.857
[18,     1] loss: 1000.632
[19,     1] loss: 1010.553
[20,     1] loss: 982.657
[21,     1] loss: 1020.545
[22,     1] loss: 1008.905
[23,     1] loss: 973.833
[24,     1] loss: 956.667
[25,     1] loss: 972.780
[26,     1] loss: 964.043
[27,     1] loss: 950.868
[28,     1] loss: 903.810
[29,     1] loss: 955.201
[30,     1] loss: 980.738
[31,     1] loss: 910.700
[32,     1] loss: 877.771
[33,     1] loss: 874.022
[34,     1] loss: 922.975
[35,     1] loss: 886.826
[36,     1] loss: 887.178
[37,     1] loss: 870.956
[38,     1] loss: 889.112
[39,     1] loss: 863.705
[40,     1] loss: 889.199
[41,     1] loss: 875.683
[42,     1] loss: 817.552
[43,     1] loss: 837.595
[44,     1] loss: 786.457
[45,     1] loss: 804.973
[46,     1] loss: 789.892
[47,     1] loss: 774.176
[48,     1] loss: 758.168
[49,     1] loss: 779.475
[50,     1] loss: 777.732
[51,     1] loss: 895.307
[52,     1] loss: 779.783
[53,     1] loss: 756.059
[54,     1] loss: 789.366
[55,     1] loss: 751.602
[56,     1] loss: 744.475
[57,     1] loss: 741.263
[58,     1] loss: 721.702
[59,     1] loss: 684.318
[60,     1] loss: 717.124
[61,     1] loss: 657.129
[62,     1] loss: 686.928
[63,     1] loss: 707.729
[64,     1] loss: 615.183
[65,     1] loss: 662.364
[66,     1] loss: 598.873
[67,     1] loss: 651.280
[68,     1] loss: 625.496
[69,     1] loss: 599.975
[70,     1] loss: 570.620
[71,     1] loss: 593.326
Early stopping applied (best metric=0.8306880593299866)
Finished Training
Total time taken: 12.661494493484497
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1257.414
[2,     1] loss: 1264.263
[3,     1] loss: 1255.719
[4,     1] loss: 1257.022
[5,     1] loss: 1253.779
[6,     1] loss: 1255.509
[7,     1] loss: 1246.388
[8,     1] loss: 1241.172
[9,     1] loss: 1229.200
[10,     1] loss: 1203.934
[11,     1] loss: 1192.766
[12,     1] loss: 1162.778
[13,     1] loss: 1137.479
[14,     1] loss: 1121.252
[15,     1] loss: 1056.466
[16,     1] loss: 1067.128
[17,     1] loss: 1044.078
[18,     1] loss: 1053.146
[19,     1] loss: 1028.119
[20,     1] loss: 1030.500
[21,     1] loss: 1013.472
[22,     1] loss: 984.760
[23,     1] loss: 996.430
[24,     1] loss: 1004.422
[25,     1] loss: 1005.433
[26,     1] loss: 975.805
[27,     1] loss: 982.972
[28,     1] loss: 941.247
[29,     1] loss: 958.842
[30,     1] loss: 922.192
[31,     1] loss: 908.903
[32,     1] loss: 949.162
[33,     1] loss: 883.977
[34,     1] loss: 901.847
[35,     1] loss: 937.471
[36,     1] loss: 876.216
[37,     1] loss: 871.653
[38,     1] loss: 824.291
[39,     1] loss: 829.248
[40,     1] loss: 829.908
[41,     1] loss: 844.208
[42,     1] loss: 815.547
Early stopping applied (best metric=0.9094890356063843)
Finished Training
Total time taken: 7.189460754394531
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1257.939
[2,     1] loss: 1255.896
[3,     1] loss: 1251.521
[4,     1] loss: 1253.574
[5,     1] loss: 1253.953
[6,     1] loss: 1246.662
[7,     1] loss: 1233.110
[8,     1] loss: 1218.705
[9,     1] loss: 1183.210
[10,     1] loss: 1174.753
[11,     1] loss: 1126.833
[12,     1] loss: 1111.862
[13,     1] loss: 1094.467
[14,     1] loss: 1078.813
[15,     1] loss: 1147.944
[16,     1] loss: 1095.801
[17,     1] loss: 1032.447
[18,     1] loss: 1023.965
[19,     1] loss: 1025.911
[20,     1] loss: 1036.907
[21,     1] loss: 970.077
[22,     1] loss: 995.160
[23,     1] loss: 960.507
[24,     1] loss: 993.903
[25,     1] loss: 1017.505
[26,     1] loss: 969.050
[27,     1] loss: 939.027
[28,     1] loss: 925.638
[29,     1] loss: 942.287
[30,     1] loss: 926.467
[31,     1] loss: 920.359
[32,     1] loss: 915.337
[33,     1] loss: 861.028
[34,     1] loss: 855.287
[35,     1] loss: 855.676
[36,     1] loss: 876.672
[37,     1] loss: 865.320
[38,     1] loss: 890.957
[39,     1] loss: 950.592
[40,     1] loss: 852.912
[41,     1] loss: 906.985
[42,     1] loss: 847.335
[43,     1] loss: 834.120
[44,     1] loss: 785.753
[45,     1] loss: 801.619
[46,     1] loss: 773.826
[47,     1] loss: 764.568
[48,     1] loss: 788.295
[49,     1] loss: 731.540
[50,     1] loss: 772.106
[51,     1] loss: 720.439
[52,     1] loss: 738.804
[53,     1] loss: 694.325
[54,     1] loss: 685.204
[55,     1] loss: 692.226
[56,     1] loss: 647.332
[57,     1] loss: 668.828
[58,     1] loss: 633.370
[59,     1] loss: 698.876
[60,     1] loss: 686.225
[61,     1] loss: 1008.125
[62,     1] loss: 969.965
[63,     1] loss: 815.386
[64,     1] loss: 764.127
[65,     1] loss: 892.448
[66,     1] loss: 829.626
[67,     1] loss: 759.565
[68,     1] loss: 794.086
[69,     1] loss: 774.294
[70,     1] loss: 694.170
[71,     1] loss: 686.630
[72,     1] loss: 734.614
[73,     1] loss: 705.753
[74,     1] loss: 666.244
[75,     1] loss: 678.632
[76,     1] loss: 568.069
[77,     1] loss: 659.981
[78,     1] loss: 593.770
[79,     1] loss: 677.763
[80,     1] loss: 603.560
[81,     1] loss: 586.934
[82,     1] loss: 579.006
[83,     1] loss: 600.886
[84,     1] loss: 578.375
[85,     1] loss: 570.385
[86,     1] loss: 537.487
[87,     1] loss: 554.372
[88,     1] loss: 481.715
[89,     1] loss: 503.553
[90,     1] loss: 511.314
[91,     1] loss: 428.413
[92,     1] loss: 531.961
[93,     1] loss: 524.119
[94,     1] loss: 420.523
[95,     1] loss: 563.853
[96,     1] loss: 472.030
[97,     1] loss: 510.961
[98,     1] loss: 561.011
Early stopping applied (best metric=0.7507848739624023)
Finished Training
Total time taken: 16.63792109489441
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1260.748
[2,     1] loss: 1254.244
[3,     1] loss: 1255.185
[4,     1] loss: 1255.335
[5,     1] loss: 1246.602
[6,     1] loss: 1241.019
[7,     1] loss: 1232.042
[8,     1] loss: 1212.047
[9,     1] loss: 1176.177
[10,     1] loss: 1169.933
[11,     1] loss: 1106.894
[12,     1] loss: 1077.549
[13,     1] loss: 1023.450
[14,     1] loss: 1063.739
[15,     1] loss: 1046.313
[16,     1] loss: 1023.139
[17,     1] loss: 1027.052
[18,     1] loss: 1050.952
[19,     1] loss: 991.938
[20,     1] loss: 979.521
[21,     1] loss: 1014.435
[22,     1] loss: 1000.341
[23,     1] loss: 987.297
[24,     1] loss: 921.912
[25,     1] loss: 934.378
[26,     1] loss: 902.663
[27,     1] loss: 902.686
[28,     1] loss: 884.813
[29,     1] loss: 931.696
[30,     1] loss: 900.405
[31,     1] loss: 894.489
[32,     1] loss: 882.211
[33,     1] loss: 918.442
[34,     1] loss: 843.845
[35,     1] loss: 873.305
[36,     1] loss: 840.467
[37,     1] loss: 897.864
[38,     1] loss: 810.111
[39,     1] loss: 800.980
[40,     1] loss: 847.966
[41,     1] loss: 834.614
[42,     1] loss: 816.029
[43,     1] loss: 782.919
[44,     1] loss: 797.098
[45,     1] loss: 744.012
[46,     1] loss: 749.059
[47,     1] loss: 721.590
[48,     1] loss: 709.943
[49,     1] loss: 652.341
[50,     1] loss: 750.318
[51,     1] loss: 691.669
[52,     1] loss: 751.530
Early stopping applied (best metric=0.91749107837677)
Finished Training
Total time taken: 8.984792947769165
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1262.492
[2,     1] loss: 1256.752
[3,     1] loss: 1262.409
[4,     1] loss: 1254.549
[5,     1] loss: 1253.873
[6,     1] loss: 1247.685
[7,     1] loss: 1233.143
[8,     1] loss: 1212.095
[9,     1] loss: 1168.943
[10,     1] loss: 1141.005
[11,     1] loss: 1095.435
[12,     1] loss: 1092.334
[13,     1] loss: 1043.224
[14,     1] loss: 1070.051
[15,     1] loss: 1032.431
[16,     1] loss: 1051.661
[17,     1] loss: 1032.569
[18,     1] loss: 1049.549
[19,     1] loss: 1052.973
[20,     1] loss: 1054.618
[21,     1] loss: 1025.490
[22,     1] loss: 1024.232
[23,     1] loss: 1042.606
[24,     1] loss: 996.100
[25,     1] loss: 975.214
[26,     1] loss: 943.795
[27,     1] loss: 989.360
[28,     1] loss: 969.766
[29,     1] loss: 1015.052
[30,     1] loss: 974.219
[31,     1] loss: 984.782
[32,     1] loss: 915.666
[33,     1] loss: 901.729
[34,     1] loss: 902.930
[35,     1] loss: 930.081
[36,     1] loss: 919.506
[37,     1] loss: 947.041
[38,     1] loss: 865.044
[39,     1] loss: 874.628
[40,     1] loss: 857.584
[41,     1] loss: 892.750
[42,     1] loss: 845.606
[43,     1] loss: 805.524
[44,     1] loss: 860.740
[45,     1] loss: 830.310
[46,     1] loss: 798.493
[47,     1] loss: 815.656
[48,     1] loss: 838.349
[49,     1] loss: 759.559
[50,     1] loss: 866.921
[51,     1] loss: 826.170
[52,     1] loss: 845.124
[53,     1] loss: 759.129
[54,     1] loss: 746.955
[55,     1] loss: 767.158
[56,     1] loss: 726.939
[57,     1] loss: 688.316
[58,     1] loss: 743.435
[59,     1] loss: 707.261
[60,     1] loss: 681.218
[61,     1] loss: 744.584
[62,     1] loss: 827.873
[63,     1] loss: 681.140
[64,     1] loss: 750.545
[65,     1] loss: 739.747
[66,     1] loss: 719.145
[67,     1] loss: 717.387
[68,     1] loss: 747.582
Early stopping applied (best metric=0.7472697496414185)
Finished Training
Total time taken: 11.414600849151611
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1254.478
[2,     1] loss: 1259.240
[3,     1] loss: 1255.314
[4,     1] loss: 1253.918
[5,     1] loss: 1252.320
[6,     1] loss: 1246.043
[7,     1] loss: 1235.568
[8,     1] loss: 1210.747
[9,     1] loss: 1190.051
[10,     1] loss: 1147.940
[11,     1] loss: 1129.001
[12,     1] loss: 1090.439
[13,     1] loss: 1083.302
[14,     1] loss: 1052.395
[15,     1] loss: 1054.574
[16,     1] loss: 1015.699
[17,     1] loss: 1045.872
[18,     1] loss: 1077.267
[19,     1] loss: 1042.227
[20,     1] loss: 1043.274
[21,     1] loss: 1024.696
[22,     1] loss: 996.180
[23,     1] loss: 1023.983
[24,     1] loss: 951.551
[25,     1] loss: 940.983
[26,     1] loss: 944.781
[27,     1] loss: 924.611
[28,     1] loss: 1035.185
[29,     1] loss: 921.452
[30,     1] loss: 954.463
[31,     1] loss: 926.153
[32,     1] loss: 939.871
[33,     1] loss: 918.208
[34,     1] loss: 882.711
[35,     1] loss: 950.808
[36,     1] loss: 902.133
[37,     1] loss: 874.358
[38,     1] loss: 938.869
[39,     1] loss: 893.361
[40,     1] loss: 889.773
[41,     1] loss: 908.305
[42,     1] loss: 850.353
[43,     1] loss: 863.467
[44,     1] loss: 827.433
[45,     1] loss: 877.410
[46,     1] loss: 820.694
[47,     1] loss: 864.214
[48,     1] loss: 817.010
[49,     1] loss: 843.375
[50,     1] loss: 772.108
[51,     1] loss: 772.451
[52,     1] loss: 750.592
[53,     1] loss: 729.850
Early stopping applied (best metric=0.8732527494430542)
Finished Training
Total time taken: 7.99958872795105
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1259.614
[2,     1] loss: 1257.677
[3,     1] loss: 1252.053
[4,     1] loss: 1256.845
[5,     1] loss: 1244.387
[6,     1] loss: 1232.026
[7,     1] loss: 1201.128
[8,     1] loss: 1169.693
[9,     1] loss: 1132.422
[10,     1] loss: 1100.937
[11,     1] loss: 1072.082
[12,     1] loss: 1075.003
[13,     1] loss: 1021.362
[14,     1] loss: 1088.874
[15,     1] loss: 1025.026
[16,     1] loss: 1012.381
[17,     1] loss: 1026.239
[18,     1] loss: 1028.305
[19,     1] loss: 1005.844
[20,     1] loss: 1026.542
[21,     1] loss: 1000.240
[22,     1] loss: 963.708
[23,     1] loss: 951.756
[24,     1] loss: 966.554
[25,     1] loss: 1018.722
[26,     1] loss: 907.062
[27,     1] loss: 942.932
[28,     1] loss: 919.483
[29,     1] loss: 937.258
[30,     1] loss: 886.901
[31,     1] loss: 879.427
[32,     1] loss: 886.201
[33,     1] loss: 873.537
[34,     1] loss: 870.409
[35,     1] loss: 859.040
[36,     1] loss: 835.463
[37,     1] loss: 794.062
[38,     1] loss: 850.704
[39,     1] loss: 768.143
[40,     1] loss: 761.953
[41,     1] loss: 787.966
[42,     1] loss: 766.135
[43,     1] loss: 775.991
[44,     1] loss: 810.298
[45,     1] loss: 749.625
[46,     1] loss: 844.835
[47,     1] loss: 778.362
[48,     1] loss: 765.579
[49,     1] loss: 730.211
[50,     1] loss: 706.097
[51,     1] loss: 712.615
[52,     1] loss: 712.025
[53,     1] loss: 685.023
[54,     1] loss: 684.938
[55,     1] loss: 690.119
[56,     1] loss: 650.399
[57,     1] loss: 668.512
[58,     1] loss: 686.534
Early stopping applied (best metric=0.8657777309417725)
Finished Training
Total time taken: 9.859665870666504
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1253.847
[2,     1] loss: 1259.258
[3,     1] loss: 1257.066
[4,     1] loss: 1254.923
[5,     1] loss: 1256.621
[6,     1] loss: 1250.150
[7,     1] loss: 1248.450
[8,     1] loss: 1246.354
[9,     1] loss: 1228.366
[10,     1] loss: 1203.471
[11,     1] loss: 1175.035
[12,     1] loss: 1143.817
[13,     1] loss: 1125.591
[14,     1] loss: 1086.025
[15,     1] loss: 1081.617
[16,     1] loss: 1043.908
[17,     1] loss: 1063.681
[18,     1] loss: 1043.063
[19,     1] loss: 1054.810
[20,     1] loss: 1064.313
[21,     1] loss: 1027.825
[22,     1] loss: 1005.572
[23,     1] loss: 1036.791
[24,     1] loss: 983.405
[25,     1] loss: 1007.589
[26,     1] loss: 964.620
[27,     1] loss: 931.432
[28,     1] loss: 988.783
[29,     1] loss: 951.858
[30,     1] loss: 907.503
[31,     1] loss: 884.042
[32,     1] loss: 909.866
[33,     1] loss: 872.789
[34,     1] loss: 919.740
[35,     1] loss: 919.360
[36,     1] loss: 909.625
[37,     1] loss: 876.412
[38,     1] loss: 949.207
[39,     1] loss: 888.875
[40,     1] loss: 843.772
[41,     1] loss: 848.897
[42,     1] loss: 778.897
[43,     1] loss: 820.877
[44,     1] loss: 895.967
[45,     1] loss: 850.426
[46,     1] loss: 833.844
[47,     1] loss: 815.038
[48,     1] loss: 800.358
[49,     1] loss: 871.439
[50,     1] loss: 812.865
[51,     1] loss: 816.288
[52,     1] loss: 812.345
[53,     1] loss: 728.750
[54,     1] loss: 817.101
[55,     1] loss: 758.335
[56,     1] loss: 743.369
[57,     1] loss: 715.349
[58,     1] loss: 667.331
[59,     1] loss: 702.674
[60,     1] loss: 714.787
[61,     1] loss: 704.417
[62,     1] loss: 710.238
[63,     1] loss: 690.391
[64,     1] loss: 646.803
[65,     1] loss: 682.348
Early stopping applied (best metric=0.7673634886741638)
Finished Training
Total time taken: 10.599367141723633
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1260.098
[2,     1] loss: 1256.282
[3,     1] loss: 1253.501
[4,     1] loss: 1252.439
[5,     1] loss: 1253.889
[6,     1] loss: 1246.052
[7,     1] loss: 1233.248
[8,     1] loss: 1203.785
[9,     1] loss: 1180.867
[10,     1] loss: 1153.818
[11,     1] loss: 1119.600
[12,     1] loss: 1092.186
[13,     1] loss: 1061.078
[14,     1] loss: 1062.391
[15,     1] loss: 1078.448
[16,     1] loss: 1039.578
[17,     1] loss: 1054.426
[18,     1] loss: 1057.240
[19,     1] loss: 1033.978
[20,     1] loss: 1005.191
[21,     1] loss: 1014.935
[22,     1] loss: 1013.662
[23,     1] loss: 1015.295
[24,     1] loss: 994.011
[25,     1] loss: 960.055
[26,     1] loss: 931.398
[27,     1] loss: 960.035
[28,     1] loss: 938.374
[29,     1] loss: 906.610
[30,     1] loss: 926.293
[31,     1] loss: 896.406
[32,     1] loss: 936.202
[33,     1] loss: 954.144
[34,     1] loss: 898.983
[35,     1] loss: 922.098
[36,     1] loss: 892.225
[37,     1] loss: 845.468
[38,     1] loss: 882.895
[39,     1] loss: 845.248
[40,     1] loss: 849.585
[41,     1] loss: 833.432
[42,     1] loss: 868.691
[43,     1] loss: 884.374
[44,     1] loss: 829.865
[45,     1] loss: 788.883
[46,     1] loss: 779.186
[47,     1] loss: 802.985
[48,     1] loss: 765.005
[49,     1] loss: 733.778
[50,     1] loss: 798.382
[51,     1] loss: 754.089
[52,     1] loss: 729.095
Early stopping applied (best metric=0.75562584400177)
Finished Training
Total time taken: 10.072762250900269
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1263.969
[2,     1] loss: 1257.457
[3,     1] loss: 1253.767
[4,     1] loss: 1253.753
[5,     1] loss: 1251.658
[6,     1] loss: 1240.958
[7,     1] loss: 1220.891
[8,     1] loss: 1204.261
[9,     1] loss: 1169.659
[10,     1] loss: 1153.231
[11,     1] loss: 1127.802
[12,     1] loss: 1100.974
[13,     1] loss: 1051.791
[14,     1] loss: 1073.109
[15,     1] loss: 1057.856
[16,     1] loss: 1036.545
[17,     1] loss: 1072.758
[18,     1] loss: 1049.827
[19,     1] loss: 989.347
[20,     1] loss: 1006.402
[21,     1] loss: 977.236
[22,     1] loss: 987.149
[23,     1] loss: 985.740
[24,     1] loss: 971.641
[25,     1] loss: 940.798
[26,     1] loss: 918.268
[27,     1] loss: 949.840
[28,     1] loss: 938.694
[29,     1] loss: 941.805
[30,     1] loss: 925.619
[31,     1] loss: 881.627
[32,     1] loss: 874.014
[33,     1] loss: 894.115
[34,     1] loss: 885.289
[35,     1] loss: 884.574
[36,     1] loss: 878.074
[37,     1] loss: 832.941
[38,     1] loss: 869.884
[39,     1] loss: 891.246
[40,     1] loss: 825.761
[41,     1] loss: 841.671
[42,     1] loss: 811.756
[43,     1] loss: 837.993
[44,     1] loss: 864.739
[45,     1] loss: 842.605
[46,     1] loss: 773.011
[47,     1] loss: 878.318
[48,     1] loss: 739.832
[49,     1] loss: 775.409
[50,     1] loss: 730.894
[51,     1] loss: 754.349
[52,     1] loss: 718.556
[53,     1] loss: 733.721
[54,     1] loss: 755.781
[55,     1] loss: 675.871
[56,     1] loss: 714.469
[57,     1] loss: 676.688
[58,     1] loss: 727.057
[59,     1] loss: 668.846
[60,     1] loss: 697.683
[61,     1] loss: 692.106
[62,     1] loss: 618.987
[63,     1] loss: 622.199
[64,     1] loss: 682.272
Early stopping applied (best metric=0.8556559085845947)
Finished Training
Total time taken: 11.454396963119507
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1259.769
[2,     1] loss: 1253.641
[3,     1] loss: 1256.094
[4,     1] loss: 1258.266
[5,     1] loss: 1253.740
[6,     1] loss: 1247.738
[7,     1] loss: 1240.339
[8,     1] loss: 1220.290
[9,     1] loss: 1192.148
[10,     1] loss: 1155.443
[11,     1] loss: 1101.486
[12,     1] loss: 1080.442
[13,     1] loss: 1063.499
[14,     1] loss: 1028.678
[15,     1] loss: 1041.984
[16,     1] loss: 1022.652
[17,     1] loss: 1038.432
[18,     1] loss: 1058.088
[19,     1] loss: 998.526
[20,     1] loss: 1031.536
[21,     1] loss: 1004.360
[22,     1] loss: 999.360
[23,     1] loss: 1019.174
[24,     1] loss: 960.506
[25,     1] loss: 973.823
[26,     1] loss: 970.498
[27,     1] loss: 941.913
[28,     1] loss: 949.529
[29,     1] loss: 923.477
[30,     1] loss: 937.825
[31,     1] loss: 894.583
[32,     1] loss: 913.927
[33,     1] loss: 927.009
[34,     1] loss: 889.944
[35,     1] loss: 879.425
[36,     1] loss: 899.879
[37,     1] loss: 884.106
[38,     1] loss: 833.961
[39,     1] loss: 812.419
[40,     1] loss: 815.668
[41,     1] loss: 838.853
[42,     1] loss: 816.312
[43,     1] loss: 743.977
[44,     1] loss: 765.288
[45,     1] loss: 777.237
[46,     1] loss: 753.451
[47,     1] loss: 762.831
[48,     1] loss: 825.464
[49,     1] loss: 782.280
[50,     1] loss: 749.423
Early stopping applied (best metric=0.8907980918884277)
Finished Training
Total time taken: 8.692212343215942
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1257.599
[2,     1] loss: 1256.310
[3,     1] loss: 1255.918
[4,     1] loss: 1250.390
[5,     1] loss: 1247.712
[6,     1] loss: 1234.931
[7,     1] loss: 1215.543
[8,     1] loss: 1188.478
[9,     1] loss: 1147.051
[10,     1] loss: 1131.486
[11,     1] loss: 1091.060
[12,     1] loss: 1028.148
[13,     1] loss: 1076.289
[14,     1] loss: 1054.439
[15,     1] loss: 1088.891
[16,     1] loss: 1013.528
[17,     1] loss: 1024.855
[18,     1] loss: 995.125
[19,     1] loss: 1020.038
[20,     1] loss: 1010.409
[21,     1] loss: 1001.579
[22,     1] loss: 1045.363
[23,     1] loss: 1008.205
[24,     1] loss: 1000.137
[25,     1] loss: 969.544
[26,     1] loss: 952.212
[27,     1] loss: 941.920
[28,     1] loss: 930.871
[29,     1] loss: 924.321
[30,     1] loss: 900.563
[31,     1] loss: 901.344
[32,     1] loss: 949.722
[33,     1] loss: 891.356
[34,     1] loss: 909.029
[35,     1] loss: 857.243
[36,     1] loss: 920.546
[37,     1] loss: 876.279
[38,     1] loss: 869.346
[39,     1] loss: 844.800
[40,     1] loss: 847.975
[41,     1] loss: 832.430
[42,     1] loss: 803.270
[43,     1] loss: 870.278
[44,     1] loss: 835.263
[45,     1] loss: 812.657
[46,     1] loss: 789.246
[47,     1] loss: 791.437
[48,     1] loss: 791.293
[49,     1] loss: 750.435
[50,     1] loss: 755.311
[51,     1] loss: 724.183
[52,     1] loss: 719.077
[53,     1] loss: 706.557
[54,     1] loss: 648.590
[55,     1] loss: 662.385
[56,     1] loss: 685.164
[57,     1] loss: 694.745
[58,     1] loss: 698.484
[59,     1] loss: 848.411
[60,     1] loss: 871.232
[61,     1] loss: 717.257
[62,     1] loss: 760.243
Early stopping applied (best metric=0.8170559406280518)
Finished Training
Total time taken: 10.856903553009033
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1258.044
[2,     1] loss: 1254.685
[3,     1] loss: 1253.199
[4,     1] loss: 1250.761
[5,     1] loss: 1256.097
[6,     1] loss: 1251.174
[7,     1] loss: 1245.907
[8,     1] loss: 1233.116
[9,     1] loss: 1218.835
[10,     1] loss: 1181.282
[11,     1] loss: 1143.479
[12,     1] loss: 1131.573
[13,     1] loss: 1098.629
[14,     1] loss: 1110.789
[15,     1] loss: 1100.458
[16,     1] loss: 1064.767
[17,     1] loss: 1039.067
[18,     1] loss: 1070.877
[19,     1] loss: 1055.554
[20,     1] loss: 1050.351
[21,     1] loss: 1046.774
[22,     1] loss: 1039.268
[23,     1] loss: 1017.082
[24,     1] loss: 979.642
[25,     1] loss: 971.976
[26,     1] loss: 993.293
[27,     1] loss: 986.088
[28,     1] loss: 988.439
[29,     1] loss: 1006.328
[30,     1] loss: 957.374
[31,     1] loss: 934.859
[32,     1] loss: 952.627
[33,     1] loss: 929.967
[34,     1] loss: 892.082
[35,     1] loss: 939.900
[36,     1] loss: 884.535
[37,     1] loss: 905.460
[38,     1] loss: 879.789
[39,     1] loss: 840.601
[40,     1] loss: 895.868
[41,     1] loss: 856.150
[42,     1] loss: 813.314
[43,     1] loss: 865.470
[44,     1] loss: 837.368
[45,     1] loss: 788.105
[46,     1] loss: 814.607
[47,     1] loss: 883.720
[48,     1] loss: 810.715
[49,     1] loss: 844.419
[50,     1] loss: 799.442
[51,     1] loss: 883.195
[52,     1] loss: 797.343
[53,     1] loss: 822.189
[54,     1] loss: 762.963
[55,     1] loss: 829.047
[56,     1] loss: 718.768
[57,     1] loss: 789.552
[58,     1] loss: 674.314
[59,     1] loss: 697.505
[60,     1] loss: 659.929
[61,     1] loss: 693.169
[62,     1] loss: 673.230
[63,     1] loss: 653.837
[64,     1] loss: 652.440
[65,     1] loss: 597.159
[66,     1] loss: 681.947
[67,     1] loss: 647.585
[68,     1] loss: 567.383
[69,     1] loss: 593.858
Early stopping applied (best metric=0.7587913274765015)
Finished Training
Total time taken: 10.487847328186035
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1257.778
[2,     1] loss: 1258.450
[3,     1] loss: 1255.532
[4,     1] loss: 1250.813
[5,     1] loss: 1245.068
[6,     1] loss: 1237.925
[7,     1] loss: 1212.011
[8,     1] loss: 1176.306
[9,     1] loss: 1135.023
[10,     1] loss: 1103.062
[11,     1] loss: 1078.193
[12,     1] loss: 1068.309
[13,     1] loss: 1087.739
[14,     1] loss: 1033.020
[15,     1] loss: 1026.167
[16,     1] loss: 1034.578
[17,     1] loss: 991.321
[18,     1] loss: 983.650
[19,     1] loss: 977.989
[20,     1] loss: 1033.019
[21,     1] loss: 947.926
[22,     1] loss: 963.889
[23,     1] loss: 968.507
[24,     1] loss: 945.385
[25,     1] loss: 947.691
[26,     1] loss: 950.534
[27,     1] loss: 916.427
[28,     1] loss: 886.974
[29,     1] loss: 922.985
[30,     1] loss: 930.437
[31,     1] loss: 861.843
[32,     1] loss: 919.639
[33,     1] loss: 862.297
[34,     1] loss: 888.817
[35,     1] loss: 882.592
[36,     1] loss: 899.607
[37,     1] loss: 856.643
[38,     1] loss: 883.967
[39,     1] loss: 844.348
[40,     1] loss: 823.231
[41,     1] loss: 834.876
[42,     1] loss: 815.348
[43,     1] loss: 826.986
[44,     1] loss: 767.692
[45,     1] loss: 811.149
[46,     1] loss: 803.254
[47,     1] loss: 778.518
[48,     1] loss: 706.013
[49,     1] loss: 726.594
[50,     1] loss: 738.340
[51,     1] loss: 749.336
[52,     1] loss: 748.217
[53,     1] loss: 732.807
[54,     1] loss: 726.586
[55,     1] loss: 726.586
[56,     1] loss: 667.735
[57,     1] loss: 774.348
[58,     1] loss: 772.255
[59,     1] loss: 674.371
[60,     1] loss: 670.500
[61,     1] loss: 716.203
[62,     1] loss: 630.156
[63,     1] loss: 687.313
[64,     1] loss: 662.451
[65,     1] loss: 670.561
[66,     1] loss: 603.009
[67,     1] loss: 602.882
[68,     1] loss: 635.349
Early stopping applied (best metric=0.790565013885498)
Finished Training
Total time taken: 9.80927038192749
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1256.657
[2,     1] loss: 1263.414
[3,     1] loss: 1256.828
[4,     1] loss: 1257.755
[5,     1] loss: 1250.902
[6,     1] loss: 1250.344
[7,     1] loss: 1238.670
[8,     1] loss: 1218.567
[9,     1] loss: 1174.415
[10,     1] loss: 1136.420
[11,     1] loss: 1101.324
[12,     1] loss: 1039.761
[13,     1] loss: 1007.397
[14,     1] loss: 1047.419
[15,     1] loss: 1045.097
[16,     1] loss: 1003.307
[17,     1] loss: 1035.666
[18,     1] loss: 1008.189
[19,     1] loss: 999.917
[20,     1] loss: 1012.424
[21,     1] loss: 980.897
[22,     1] loss: 1008.852
[23,     1] loss: 957.866
[24,     1] loss: 999.883
[25,     1] loss: 953.060
[26,     1] loss: 933.670
[27,     1] loss: 935.888
[28,     1] loss: 912.557
[29,     1] loss: 912.579
[30,     1] loss: 878.512
[31,     1] loss: 859.612
[32,     1] loss: 925.421
[33,     1] loss: 897.969
[34,     1] loss: 854.482
[35,     1] loss: 839.970
[36,     1] loss: 849.801
[37,     1] loss: 811.906
[38,     1] loss: 817.006
[39,     1] loss: 815.903
[40,     1] loss: 792.766
[41,     1] loss: 782.470
[42,     1] loss: 815.738
[43,     1] loss: 743.731
[44,     1] loss: 833.742
[45,     1] loss: 773.526
[46,     1] loss: 769.452
[47,     1] loss: 760.448
[48,     1] loss: 791.975
[49,     1] loss: 704.888
[50,     1] loss: 720.743
[51,     1] loss: 706.677
[52,     1] loss: 705.094
[53,     1] loss: 705.444
[54,     1] loss: 707.669
[55,     1] loss: 670.247
[56,     1] loss: 669.282
[57,     1] loss: 685.317
[58,     1] loss: 682.751
[59,     1] loss: 658.872
[60,     1] loss: 634.073
[61,     1] loss: 604.448
[62,     1] loss: 690.672
[63,     1] loss: 899.038
[64,     1] loss: 807.165
[65,     1] loss: 620.738
[66,     1] loss: 833.942
[67,     1] loss: 698.810
[68,     1] loss: 728.831
[69,     1] loss: 761.874
Early stopping applied (best metric=0.8670634031295776)
Finished Training
Total time taken: 10.71781611442566
{'Hydroxylation-K Validation Accuracy': 0.7718971631205673, 'Hydroxylation-K Validation Sensitivity': 0.654074074074074, 'Hydroxylation-K Validation Specificity': 0.8017543859649122, 'Hydroxylation-K Validation Precision': 0.4535721359250771, 'Hydroxylation-K AUC ROC': 0.7834697855750488, 'Hydroxylation-K AUC PR': 0.5424737175711883, 'Hydroxylation-K MCC': 0.40268109718893835, 'Hydroxylation-K F1': 0.5332507685551163, 'Validation Loss (Hydroxylation-K)': 0.4496460060278575, 'Hydroxylation-P Validation Accuracy': 0.7963262101754564, 'Hydroxylation-P Validation Sensitivity': 0.7608465608465609, 'Hydroxylation-P Validation Specificity': 0.8038405905531448, 'Hydroxylation-P Validation Precision': 0.46070269275198744, 'Hydroxylation-P AUC ROC': 0.8448426474185864, 'Hydroxylation-P AUC PR': 0.595447744328872, 'Hydroxylation-P MCC': 0.47558027644092965, 'Hydroxylation-P F1': 0.569514431301796, 'Validation Loss (Hydroxylation-P)': 0.3768654763698578, 'Validation Loss (total)': 0.8265114863713582, 'TimeToTrain': 10.495873387654623}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00015604299885172833,
 'learning_rate_Hydroxylation-K': 0.0012650049991240215,
 'learning_rate_Hydroxylation-P': 0.0033437313190668454,
 'log_base': 1.3719500769630506,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 62213121,
 'sample_weights': [1.6484290989321342, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.329111725645144,
 'weight_decay_Hydroxylation-K': 3.2597009424134225,
 'weight_decay_Hydroxylation-P': 7.44480152957209}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2026.780
[2,     1] loss: 2028.525
[3,     1] loss: 2026.448
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0036048401668211166,
 'learning_rate_Hydroxylation-K': 0.005648485697390149,
 'learning_rate_Hydroxylation-P': 0.004451453681248523,
 'log_base': 2.2572210978910863,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1501537206,
 'sample_weights': [5.279153029431849, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7927435439511865,
 'weight_decay_Hydroxylation-K': 3.688284557413314,
 'weight_decay_Hydroxylation-P': 2.747266007477273}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1344.795
[2,     1] loss: 1340.150
[3,     1] loss: 1340.261
[4,     1] loss: 1339.687
[5,     1] loss: 1327.435
[6,     1] loss: 1326.229
[7,     1] loss: 1303.710
[8,     1] loss: 1255.141
[9,     1] loss: 1199.071
[10,     1] loss: 1166.990
[11,     1] loss: 1166.329
[12,     1] loss: 1153.751
[13,     1] loss: 1118.330
[14,     1] loss: 1111.075
[15,     1] loss: 1142.893
[16,     1] loss: 1098.732
[17,     1] loss: 1102.268
[18,     1] loss: 1065.678
[19,     1] loss: 1058.740
[20,     1] loss: 1056.423
[21,     1] loss: 1020.180
[22,     1] loss: 1050.293
[23,     1] loss: 1028.679
[24,     1] loss: 994.859
[25,     1] loss: 989.095
[26,     1] loss: 1024.875
[27,     1] loss: 990.810
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012523940875084393,
 'learning_rate_Hydroxylation-K': 0.005985260846925355,
 'learning_rate_Hydroxylation-P': 0.0054614065830382065,
 'log_base': 1.3373807304543153,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1458143195,
 'sample_weights': [2.0505742500178674, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4012031508549982,
 'weight_decay_Hydroxylation-K': 1.8890272042858114,
 'weight_decay_Hydroxylation-P': 0.9907915651821653}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2116.484
[2,     1] loss: 2127.230
[3,     1] loss: 2121.242
[4,     1] loss: 2117.486
[5,     1] loss: 2134.453
[6,     1] loss: 2129.874
[7,     1] loss: 2123.549
[8,     1] loss: 2117.392
[9,     1] loss: 2113.009
[10,     1] loss: 2113.006
[11,     1] loss: 2113.830
[12,     1] loss: 2112.077
[13,     1] loss: 2106.048
[14,     1] loss: 2100.634
[15,     1] loss: 2103.235
[16,     1] loss: 2076.076
[17,     1] loss: 2072.233
[18,     1] loss: 2070.781
[19,     1] loss: 2041.106
[20,     1] loss: 2017.370
[21,     1] loss: 2025.655
[22,     1] loss: 1963.684
[23,     1] loss: 1904.793
[24,     1] loss: 1900.841
[25,     1] loss: 1884.441
[26,     1] loss: 1831.560
[27,     1] loss: 1949.261
[28,     1] loss: 1814.058
[29,     1] loss: 1863.931
[30,     1] loss: 1810.287
[31,     1] loss: 1745.785
[32,     1] loss: 1769.347
[33,     1] loss: 1819.727
[34,     1] loss: 1753.635
[35,     1] loss: 1733.947
[36,     1] loss: 1702.980
[37,     1] loss: 1784.335
[38,     1] loss: 1664.381
[39,     1] loss: 1704.548
[40,     1] loss: 1725.921
[41,     1] loss: 1664.894
[42,     1] loss: 1643.969
[43,     1] loss: 1663.784
[44,     1] loss: 1686.678
[45,     1] loss: 1652.501
[46,     1] loss: 1651.676
[47,     1] loss: 1631.900
[48,     1] loss: 1595.994
[49,     1] loss: 1653.102
[50,     1] loss: 1564.105
[51,     1] loss: 1505.558
[52,     1] loss: 1601.868
[53,     1] loss: 1578.096
[54,     1] loss: 1501.186
[55,     1] loss: 1503.117
[56,     1] loss: 1580.166
[57,     1] loss: 1402.671
[58,     1] loss: 1563.888
[59,     1] loss: 1727.399
[60,     1] loss: 1531.357
[61,     1] loss: 1469.267
[62,     1] loss: 1479.853
[63,     1] loss: 1323.551
[64,     1] loss: 1442.752
[65,     1] loss: 1427.084
[66,     1] loss: 1406.038
[67,     1] loss: 1327.739
Early stopping applied (best metric=0.7827524542808533)
Finished Training
Total time taken: 9.273277997970581
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2112.688
[2,     1] loss: 2124.514
[3,     1] loss: 2114.399
[4,     1] loss: 2116.058
[5,     1] loss: 2107.088
[6,     1] loss: 2124.878
[7,     1] loss: 2109.902
[8,     1] loss: 2134.120
[9,     1] loss: 2107.993
[10,     1] loss: 2113.182
[11,     1] loss: 2101.625
[12,     1] loss: 2102.238
[13,     1] loss: 2093.967
[14,     1] loss: 2077.565
[15,     1] loss: 2065.259
[16,     1] loss: 2059.219
[17,     1] loss: 2048.798
[18,     1] loss: 2024.540
[19,     1] loss: 1982.333
[20,     1] loss: 1970.831
[21,     1] loss: 1930.949
[22,     1] loss: 1864.199
[23,     1] loss: 1834.946
[24,     1] loss: 1861.767
[25,     1] loss: 1803.472
[26,     1] loss: 1821.704
[27,     1] loss: 1770.786
[28,     1] loss: 1823.013
[29,     1] loss: 1881.668
[30,     1] loss: 1741.844
[31,     1] loss: 1828.940
[32,     1] loss: 1802.279
[33,     1] loss: 1668.778
[34,     1] loss: 1734.125
[35,     1] loss: 1756.990
[36,     1] loss: 1720.622
[37,     1] loss: 1708.187
[38,     1] loss: 1666.870
[39,     1] loss: 1644.439
[40,     1] loss: 1596.296
[41,     1] loss: 1539.114
[42,     1] loss: 1576.788
[43,     1] loss: 1560.163
[44,     1] loss: 1548.866
[45,     1] loss: 1570.821
[46,     1] loss: 1552.481
[47,     1] loss: 1616.266
[48,     1] loss: 1534.767
[49,     1] loss: 1418.753
[50,     1] loss: 1392.998
[51,     1] loss: 1385.649
[52,     1] loss: 1370.518
[53,     1] loss: 1394.983
[54,     1] loss: 1332.243
Early stopping applied (best metric=0.8386088609695435)
Finished Training
Total time taken: 8.483180046081543
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2119.531
[2,     1] loss: 2119.996
[3,     1] loss: 2118.553
[4,     1] loss: 2128.457
[5,     1] loss: 2119.910
[6,     1] loss: 2119.210
[7,     1] loss: 2115.084
[8,     1] loss: 2116.404
[9,     1] loss: 2117.618
[10,     1] loss: 2114.401
[11,     1] loss: 2112.525
[12,     1] loss: 2110.487
[13,     1] loss: 2098.461
[14,     1] loss: 2101.203
[15,     1] loss: 2090.372
[16,     1] loss: 2061.557
[17,     1] loss: 2036.190
[18,     1] loss: 2016.170
[19,     1] loss: 1996.108
[20,     1] loss: 1982.745
[21,     1] loss: 1918.681
[22,     1] loss: 1889.023
[23,     1] loss: 1855.776
[24,     1] loss: 1861.516
[25,     1] loss: 1839.140
[26,     1] loss: 1828.679
[27,     1] loss: 1815.588
[28,     1] loss: 1758.094
[29,     1] loss: 1884.504
[30,     1] loss: 1732.976
[31,     1] loss: 1712.016
[32,     1] loss: 1856.247
[33,     1] loss: 1778.750
[34,     1] loss: 1811.746
[35,     1] loss: 1776.341
[36,     1] loss: 1868.162
[37,     1] loss: 1704.256
[38,     1] loss: 1659.548
[39,     1] loss: 1673.259
[40,     1] loss: 1747.947
[41,     1] loss: 1770.517
[42,     1] loss: 1682.104
[43,     1] loss: 1727.902
[44,     1] loss: 1624.181
[45,     1] loss: 1688.841
[46,     1] loss: 1594.437
[47,     1] loss: 1583.944
[48,     1] loss: 1584.179
[49,     1] loss: 1593.229
[50,     1] loss: 1734.405
[51,     1] loss: 1581.700
[52,     1] loss: 1626.632
[53,     1] loss: 1520.847
[54,     1] loss: 1476.056
[55,     1] loss: 1483.569
[56,     1] loss: 1672.617
[57,     1] loss: 1586.905
[58,     1] loss: 1498.464
[59,     1] loss: 1394.817
[60,     1] loss: 1499.059
[61,     1] loss: 1524.041
[62,     1] loss: 1554.215
[63,     1] loss: 1346.863
[64,     1] loss: 1433.683
[65,     1] loss: 1377.525
[66,     1] loss: 1444.623
[67,     1] loss: 1591.681
[68,     1] loss: 1386.071
[69,     1] loss: 1334.526
[70,     1] loss: 1381.195
[71,     1] loss: 1302.974
[72,     1] loss: 1279.247
[73,     1] loss: 1318.863
[74,     1] loss: 1262.120
[75,     1] loss: 1290.292
[76,     1] loss: 1298.974
[77,     1] loss: 1145.821
[78,     1] loss: 1112.349
[79,     1] loss: 1185.358
[80,     1] loss: 1227.179
Early stopping applied (best metric=0.7496952414512634)
Finished Training
Total time taken: 14.176406383514404
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2119.987
[2,     1] loss: 2119.334
[3,     1] loss: 2117.112
[4,     1] loss: 2112.962
[5,     1] loss: 2115.691
[6,     1] loss: 2111.886
[7,     1] loss: 2112.468
[8,     1] loss: 2109.979
[9,     1] loss: 2101.019
[10,     1] loss: 2101.566
[11,     1] loss: 2091.207
[12,     1] loss: 2081.739
[13,     1] loss: 2070.338
[14,     1] loss: 2037.185
[15,     1] loss: 2004.642
[16,     1] loss: 2003.072
[17,     1] loss: 1948.506
[18,     1] loss: 1917.517
[19,     1] loss: 1866.731
[20,     1] loss: 1887.730
[21,     1] loss: 1797.510
[22,     1] loss: 1812.118
[23,     1] loss: 1668.768
[24,     1] loss: 1771.293
[25,     1] loss: 1797.718
[26,     1] loss: 1858.847
[27,     1] loss: 1800.040
[28,     1] loss: 1834.866
[29,     1] loss: 1746.137
[30,     1] loss: 1735.838
[31,     1] loss: 1738.419
[32,     1] loss: 1676.342
[33,     1] loss: 1760.202
[34,     1] loss: 1674.567
[35,     1] loss: 1732.588
[36,     1] loss: 1657.442
[37,     1] loss: 1663.686
[38,     1] loss: 1737.185
[39,     1] loss: 1662.860
[40,     1] loss: 1548.009
[41,     1] loss: 1613.690
[42,     1] loss: 1535.593
[43,     1] loss: 1631.497
[44,     1] loss: 1572.230
[45,     1] loss: 1602.182
[46,     1] loss: 1713.872
[47,     1] loss: 1508.729
[48,     1] loss: 1632.275
[49,     1] loss: 1570.790
[50,     1] loss: 1585.744
[51,     1] loss: 1554.901
[52,     1] loss: 1608.969
[53,     1] loss: 1481.963
[54,     1] loss: 1528.915
[55,     1] loss: 1520.206
[56,     1] loss: 1500.568
[57,     1] loss: 1436.578
[58,     1] loss: 1388.292
[59,     1] loss: 1456.548
[60,     1] loss: 1291.045
[61,     1] loss: 1450.553
[62,     1] loss: 1394.354
[63,     1] loss: 1295.076
[64,     1] loss: 1237.239
[65,     1] loss: 1350.561
[66,     1] loss: 1289.460
[67,     1] loss: 1202.761
[68,     1] loss: 1214.013
[69,     1] loss: 1273.917
[70,     1] loss: 1231.892
[71,     1] loss: 1230.925
[72,     1] loss: 1093.225
[73,     1] loss: 1144.637
[74,     1] loss: 1116.534
[75,     1] loss: 1170.573
[76,     1] loss: 1122.483
[77,     1] loss: 1032.901
[78,     1] loss: 1056.432
[79,     1] loss: 1117.123
[80,     1] loss: 981.599
[81,     1] loss: 1147.631
Early stopping applied (best metric=0.8189220428466797)
Finished Training
Total time taken: 13.809413194656372
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 2123.571
[2,     1] loss: 2116.788
[3,     1] loss: 2127.810
[4,     1] loss: 2129.099
[5,     1] loss: 2128.090
[6,     1] loss: 2126.018
[7,     1] loss: 2119.381
[8,     1] loss: 2118.604
[9,     1] loss: 2112.246
[10,     1] loss: 2107.272
[11,     1] loss: 2109.075
[12,     1] loss: 2111.258
[13,     1] loss: 2099.648
[14,     1] loss: 2079.749
[15,     1] loss: 2081.169
[16,     1] loss: 2023.730
[17,     1] loss: 2023.258
[18,     1] loss: 1969.911
[19,     1] loss: 1976.062
[20,     1] loss: 1955.575
[21,     1] loss: 1927.470
[22,     1] loss: 1831.683
[23,     1] loss: 1835.791
[24,     1] loss: 1886.314
[25,     1] loss: 1918.239
[26,     1] loss: 1884.939
[27,     1] loss: 1844.462
[28,     1] loss: 1809.480
[29,     1] loss: 1785.108
[30,     1] loss: 1808.208
[31,     1] loss: 1811.401
[32,     1] loss: 1770.333
[33,     1] loss: 1796.401
[34,     1] loss: 1802.047
[35,     1] loss: 1668.029
[36,     1] loss: 1785.792
[37,     1] loss: 1693.004
[38,     1] loss: 1768.225
[39,     1] loss: 1702.022
[40,     1] loss: 1693.265
[41,     1] loss: 1649.187
[42,     1] loss: 1723.132
[43,     1] loss: 1699.873
[44,     1] loss: 1584.905
[45,     1] loss: 1578.818
[46,     1] loss: 1553.305
[47,     1] loss: 1491.132
[48,     1] loss: 1556.009
[49,     1] loss: 1634.980
[50,     1] loss: 1546.903
[51,     1] loss: 1440.331
[52,     1] loss: 1440.878
[53,     1] loss: 1456.410
[54,     1] loss: 1443.218
[55,     1] loss: 1465.800
[56,     1] loss: 1451.631
[57,     1] loss: 1416.632
[58,     1] loss: 1284.738
[59,     1] loss: 1431.878
[60,     1] loss: 1450.251
[61,     1] loss: 1297.834
[62,     1] loss: 1429.786
[63,     1] loss: 1335.034
[64,     1] loss: 1244.225
Early stopping applied (best metric=0.6816058158874512)
Finished Training
Total time taken: 9.087217807769775
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2124.074
[2,     1] loss: 2115.940
[3,     1] loss: 2115.168
[4,     1] loss: 2116.534
[5,     1] loss: 2111.272
[6,     1] loss: 2112.626
[7,     1] loss: 2107.162
[8,     1] loss: 2109.787
[9,     1] loss: 2098.549
[10,     1] loss: 2113.288
[11,     1] loss: 2095.536
[12,     1] loss: 2086.273
[13,     1] loss: 2080.026
[14,     1] loss: 2042.039
[15,     1] loss: 2032.365
[16,     1] loss: 1991.083
[17,     1] loss: 1988.091
[18,     1] loss: 1934.858
[19,     1] loss: 1923.636
[20,     1] loss: 1904.334
[21,     1] loss: 1855.204
[22,     1] loss: 1802.171
[23,     1] loss: 1854.478
[24,     1] loss: 1830.203
[25,     1] loss: 1860.843
[26,     1] loss: 1837.608
[27,     1] loss: 1706.854
[28,     1] loss: 1874.621
[29,     1] loss: 1847.067
[30,     1] loss: 1724.316
[31,     1] loss: 1682.623
[32,     1] loss: 1818.039
[33,     1] loss: 1797.602
[34,     1] loss: 1769.052
[35,     1] loss: 1700.002
[36,     1] loss: 1707.490
[37,     1] loss: 1792.393
[38,     1] loss: 1644.255
[39,     1] loss: 1720.182
[40,     1] loss: 1688.747
[41,     1] loss: 1670.400
[42,     1] loss: 1664.809
[43,     1] loss: 1580.826
[44,     1] loss: 1764.556
[45,     1] loss: 1584.190
[46,     1] loss: 1584.407
[47,     1] loss: 1638.406
[48,     1] loss: 1508.969
[49,     1] loss: 1516.385
[50,     1] loss: 1574.942
[51,     1] loss: 1580.233
[52,     1] loss: 1468.629
[53,     1] loss: 1516.303
[54,     1] loss: 1437.469
[55,     1] loss: 1482.961
[56,     1] loss: 1491.975
[57,     1] loss: 1442.938
[58,     1] loss: 1421.348
Early stopping applied (best metric=0.7976900339126587)
Finished Training
Total time taken: 7.873165130615234
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2109.221
[2,     1] loss: 2123.333
[3,     1] loss: 2125.178
[4,     1] loss: 2116.404
[5,     1] loss: 2134.514
[6,     1] loss: 2122.602
[7,     1] loss: 2124.783
[8,     1] loss: 2102.975
[9,     1] loss: 2116.081
[10,     1] loss: 2112.683
[11,     1] loss: 2112.126
[12,     1] loss: 2098.784
[13,     1] loss: 2095.483
[14,     1] loss: 2091.137
[15,     1] loss: 2073.371
[16,     1] loss: 2065.347
[17,     1] loss: 2019.239
[18,     1] loss: 1993.584
[19,     1] loss: 1991.773
[20,     1] loss: 1889.786
[21,     1] loss: 1937.188
[22,     1] loss: 1900.039
[23,     1] loss: 1896.934
[24,     1] loss: 1875.292
[25,     1] loss: 1791.039
[26,     1] loss: 1853.511
[27,     1] loss: 1816.818
[28,     1] loss: 1722.548
[29,     1] loss: 1879.913
[30,     1] loss: 1862.203
[31,     1] loss: 1817.185
[32,     1] loss: 1794.887
[33,     1] loss: 1820.251
[34,     1] loss: 1752.893
[35,     1] loss: 1743.148
[36,     1] loss: 1731.500
[37,     1] loss: 1772.782
[38,     1] loss: 1730.553
[39,     1] loss: 1699.216
[40,     1] loss: 1677.406
[41,     1] loss: 1702.515
[42,     1] loss: 1648.679
[43,     1] loss: 1660.814
[44,     1] loss: 1632.938
[45,     1] loss: 1638.438
[46,     1] loss: 1658.863
[47,     1] loss: 1523.758
Early stopping applied (best metric=0.7603201866149902)
Finished Training
Total time taken: 6.364134788513184
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2123.913
[2,     1] loss: 2123.857
[3,     1] loss: 2123.983
[4,     1] loss: 2123.787
[5,     1] loss: 2126.020
[6,     1] loss: 2121.622
[7,     1] loss: 2121.230
[8,     1] loss: 2120.691
[9,     1] loss: 2111.883
[10,     1] loss: 2116.543
[11,     1] loss: 2115.183
[12,     1] loss: 2117.348
[13,     1] loss: 2108.309
[14,     1] loss: 2103.617
[15,     1] loss: 2101.067
[16,     1] loss: 2095.527
[17,     1] loss: 2077.643
[18,     1] loss: 2068.785
[19,     1] loss: 2046.956
[20,     1] loss: 2022.707
[21,     1] loss: 1995.555
[22,     1] loss: 1960.890
[23,     1] loss: 1945.787
[24,     1] loss: 1900.061
[25,     1] loss: 1932.578
[26,     1] loss: 1853.851
[27,     1] loss: 1832.366
[28,     1] loss: 1865.374
[29,     1] loss: 1788.896
[30,     1] loss: 1853.295
[31,     1] loss: 1748.514
[32,     1] loss: 1732.057
[33,     1] loss: 1723.739
[34,     1] loss: 1755.667
[35,     1] loss: 1738.476
[36,     1] loss: 1807.850
[37,     1] loss: 1684.858
[38,     1] loss: 1706.978
[39,     1] loss: 1669.651
[40,     1] loss: 1688.985
[41,     1] loss: 1619.566
[42,     1] loss: 1637.664
[43,     1] loss: 1656.136
[44,     1] loss: 1471.648
[45,     1] loss: 1605.858
[46,     1] loss: 1688.505
[47,     1] loss: 1493.241
[48,     1] loss: 1577.350
[49,     1] loss: 1509.726
[50,     1] loss: 1512.236
[51,     1] loss: 1420.858
Early stopping applied (best metric=0.965287983417511)
Finished Training
Total time taken: 6.904145002365112
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2130.519
[2,     1] loss: 2123.092
[3,     1] loss: 2110.083
[4,     1] loss: 2115.000
[5,     1] loss: 2114.714
[6,     1] loss: 2123.080
[7,     1] loss: 2118.564
[8,     1] loss: 2115.835
[9,     1] loss: 2117.097
[10,     1] loss: 2112.730
[11,     1] loss: 2110.365
[12,     1] loss: 2105.994
[13,     1] loss: 2097.117
[14,     1] loss: 2083.079
[15,     1] loss: 2066.473
[16,     1] loss: 2031.781
[17,     1] loss: 2013.079
[18,     1] loss: 1957.583
[19,     1] loss: 1924.547
[20,     1] loss: 1853.287
[21,     1] loss: 1816.680
[22,     1] loss: 1868.343
[23,     1] loss: 1809.525
[24,     1] loss: 1804.391
[25,     1] loss: 1857.237
[26,     1] loss: 1680.876
[27,     1] loss: 1880.260
[28,     1] loss: 1766.848
[29,     1] loss: 1737.811
[30,     1] loss: 1815.537
[31,     1] loss: 1757.097
[32,     1] loss: 1761.148
[33,     1] loss: 1639.244
[34,     1] loss: 1681.036
[35,     1] loss: 1611.953
[36,     1] loss: 1681.122
[37,     1] loss: 1615.153
[38,     1] loss: 1695.291
[39,     1] loss: 1669.974
[40,     1] loss: 1619.890
[41,     1] loss: 1551.816
[42,     1] loss: 1604.659
[43,     1] loss: 1520.363
Early stopping applied (best metric=0.937138557434082)
Finished Training
Total time taken: 6.859144449234009
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 2140.466
[2,     1] loss: 2125.755
[3,     1] loss: 2133.451
[4,     1] loss: 2122.166
[5,     1] loss: 2124.940
[6,     1] loss: 2125.269
[7,     1] loss: 2119.121
[8,     1] loss: 2120.085
[9,     1] loss: 2118.476
[10,     1] loss: 2116.107
[11,     1] loss: 2116.423
[12,     1] loss: 2112.284
[13,     1] loss: 2105.774
[14,     1] loss: 2098.446
[15,     1] loss: 2093.058
[16,     1] loss: 2075.719
[17,     1] loss: 2056.439
[18,     1] loss: 2032.501
[19,     1] loss: 2026.978
[20,     1] loss: 1961.478
[21,     1] loss: 1946.438
[22,     1] loss: 1927.048
[23,     1] loss: 1915.359
[24,     1] loss: 1877.037
[25,     1] loss: 1895.565
[26,     1] loss: 1857.606
[27,     1] loss: 1843.720
[28,     1] loss: 1795.292
[29,     1] loss: 1883.854
[30,     1] loss: 1804.100
[31,     1] loss: 1791.424
[32,     1] loss: 1750.937
[33,     1] loss: 1811.265
[34,     1] loss: 1711.520
[35,     1] loss: 1741.537
[36,     1] loss: 1740.836
[37,     1] loss: 1748.424
[38,     1] loss: 1680.842
[39,     1] loss: 1726.729
[40,     1] loss: 1721.969
[41,     1] loss: 1756.401
[42,     1] loss: 1816.206
[43,     1] loss: 1580.357
[44,     1] loss: 1629.649
[45,     1] loss: 1741.086
[46,     1] loss: 1649.978
[47,     1] loss: 1560.771
[48,     1] loss: 1632.904
[49,     1] loss: 1588.896
[50,     1] loss: 1524.182
[51,     1] loss: 1580.760
[52,     1] loss: 1527.598
[53,     1] loss: 1430.672
[54,     1] loss: 1673.964
[55,     1] loss: 1486.947
[56,     1] loss: 1527.209
[57,     1] loss: 1462.665
[58,     1] loss: 1420.286
[59,     1] loss: 1451.128
[60,     1] loss: 1391.683
[61,     1] loss: 1319.397
[62,     1] loss: 1385.310
[63,     1] loss: 1397.666
[64,     1] loss: 1341.644
[65,     1] loss: 1235.413
[66,     1] loss: 1468.939
[67,     1] loss: 1206.961
[68,     1] loss: 1347.987
[69,     1] loss: 1467.615
[70,     1] loss: 1346.409
[71,     1] loss: 1385.708
[72,     1] loss: 1247.989
[73,     1] loss: 1291.461
Early stopping applied (best metric=0.7652835249900818)
Finished Training
Total time taken: 10.14721393585205
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2119.781
[2,     1] loss: 2120.776
[3,     1] loss: 2114.843
[4,     1] loss: 2127.048
[5,     1] loss: 2117.748
[6,     1] loss: 2117.002
[7,     1] loss: 2119.978
[8,     1] loss: 2110.595
[9,     1] loss: 2119.425
[10,     1] loss: 2109.922
[11,     1] loss: 2117.157
[12,     1] loss: 2121.312
[13,     1] loss: 2106.110
[14,     1] loss: 2112.209
[15,     1] loss: 2089.418
[16,     1] loss: 2077.949
[17,     1] loss: 2047.431
[18,     1] loss: 2039.603
[19,     1] loss: 2020.857
[20,     1] loss: 1933.044
[21,     1] loss: 1946.396
[22,     1] loss: 1968.212
[23,     1] loss: 1884.785
[24,     1] loss: 1894.482
[25,     1] loss: 1883.094
[26,     1] loss: 1850.881
[27,     1] loss: 1862.958
[28,     1] loss: 1912.103
[29,     1] loss: 1866.191
[30,     1] loss: 1812.301
[31,     1] loss: 1878.397
[32,     1] loss: 1812.149
[33,     1] loss: 1808.358
[34,     1] loss: 1795.975
[35,     1] loss: 1712.368
[36,     1] loss: 1726.953
[37,     1] loss: 1709.009
[38,     1] loss: 1705.836
[39,     1] loss: 1699.218
[40,     1] loss: 1698.148
[41,     1] loss: 1642.827
[42,     1] loss: 1706.652
[43,     1] loss: 1738.081
[44,     1] loss: 1600.691
[45,     1] loss: 1615.134
[46,     1] loss: 1579.618
[47,     1] loss: 1579.697
[48,     1] loss: 1576.703
[49,     1] loss: 1532.345
[50,     1] loss: 1576.862
[51,     1] loss: 1557.833
[52,     1] loss: 1468.525
[53,     1] loss: 1413.705
[54,     1] loss: 1545.204
[55,     1] loss: 1460.902
[56,     1] loss: 1464.313
[57,     1] loss: 1532.763
Early stopping applied (best metric=0.8483395576477051)
Finished Training
Total time taken: 7.673164129257202
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2126.793
[2,     1] loss: 2112.628
[3,     1] loss: 2116.422
[4,     1] loss: 2128.924
[5,     1] loss: 2117.663
[6,     1] loss: 2114.598
[7,     1] loss: 2124.919
[8,     1] loss: 2117.986
[9,     1] loss: 2111.863
[10,     1] loss: 2096.377
[11,     1] loss: 2097.612
[12,     1] loss: 2094.758
[13,     1] loss: 2089.520
[14,     1] loss: 2066.335
[15,     1] loss: 2051.730
[16,     1] loss: 2026.344
[17,     1] loss: 2005.430
[18,     1] loss: 1978.521
[19,     1] loss: 1944.143
[20,     1] loss: 1932.295
[21,     1] loss: 1901.065
[22,     1] loss: 1809.981
[23,     1] loss: 1882.774
[24,     1] loss: 1814.899
[25,     1] loss: 1821.338
[26,     1] loss: 1771.931
[27,     1] loss: 1832.108
[28,     1] loss: 1723.638
[29,     1] loss: 1685.795
[30,     1] loss: 1781.104
[31,     1] loss: 1730.037
[32,     1] loss: 1709.001
[33,     1] loss: 1764.879
[34,     1] loss: 1638.460
[35,     1] loss: 1735.094
[36,     1] loss: 1652.299
[37,     1] loss: 1740.857
[38,     1] loss: 1729.572
[39,     1] loss: 1683.313
[40,     1] loss: 1655.940
[41,     1] loss: 1615.325
[42,     1] loss: 1597.292
Early stopping applied (best metric=0.882172167301178)
Finished Training
Total time taken: 6.261130094528198
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2124.281
[2,     1] loss: 2121.316
[3,     1] loss: 2125.492
[4,     1] loss: 2113.322
[5,     1] loss: 2127.298
[6,     1] loss: 2110.502
[7,     1] loss: 2114.819
[8,     1] loss: 2119.129
[9,     1] loss: 2113.577
[10,     1] loss: 2107.293
[11,     1] loss: 2103.812
[12,     1] loss: 2086.702
[13,     1] loss: 2067.485
[14,     1] loss: 2052.013
[15,     1] loss: 2017.600
[16,     1] loss: 1993.952
[17,     1] loss: 1965.465
[18,     1] loss: 1940.669
[19,     1] loss: 1914.967
[20,     1] loss: 1880.465
[21,     1] loss: 1883.458
[22,     1] loss: 1851.182
[23,     1] loss: 1815.772
[24,     1] loss: 1838.882
[25,     1] loss: 1791.292
[26,     1] loss: 1742.856
[27,     1] loss: 1841.357
[28,     1] loss: 1843.453
[29,     1] loss: 1624.883
[30,     1] loss: 1668.252
[31,     1] loss: 1805.119
[32,     1] loss: 1670.210
[33,     1] loss: 1712.477
[34,     1] loss: 1691.116
[35,     1] loss: 1712.712
[36,     1] loss: 1627.903
[37,     1] loss: 1764.429
[38,     1] loss: 1650.920
[39,     1] loss: 1623.688
[40,     1] loss: 1669.355
[41,     1] loss: 1746.152
[42,     1] loss: 1617.885
[43,     1] loss: 1616.412
[44,     1] loss: 1602.637
[45,     1] loss: 1532.510
[46,     1] loss: 1471.257
[47,     1] loss: 1473.195
[48,     1] loss: 1449.398
[49,     1] loss: 1631.361
[50,     1] loss: 1501.200
[51,     1] loss: 1521.316
[52,     1] loss: 1539.318
[53,     1] loss: 1456.091
[54,     1] loss: 1466.065
[55,     1] loss: 1434.331
[56,     1] loss: 1332.581
[57,     1] loss: 1387.689
[58,     1] loss: 1452.146
[59,     1] loss: 1400.204
[60,     1] loss: 1344.066
[61,     1] loss: 1446.666
[62,     1] loss: 1311.480
[63,     1] loss: 1202.522
[64,     1] loss: 1285.905
Early stopping applied (best metric=0.943760335445404)
Finished Training
Total time taken: 10.099213361740112
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2116.917
[2,     1] loss: 2114.385
[3,     1] loss: 2111.501
[4,     1] loss: 2129.064
[5,     1] loss: 2122.272
[6,     1] loss: 2114.054
[7,     1] loss: 2116.793
[8,     1] loss: 2115.014
[9,     1] loss: 2116.219
[10,     1] loss: 2100.958
[11,     1] loss: 2112.500
[12,     1] loss: 2107.206
[13,     1] loss: 2116.857
[14,     1] loss: 2093.026
[15,     1] loss: 2080.988
[16,     1] loss: 2070.456
[17,     1] loss: 2042.818
[18,     1] loss: 2032.780
[19,     1] loss: 1984.139
[20,     1] loss: 1942.919
[21,     1] loss: 1943.379
[22,     1] loss: 1914.859
[23,     1] loss: 1846.018
[24,     1] loss: 1890.438
[25,     1] loss: 1822.370
[26,     1] loss: 1826.830
[27,     1] loss: 1824.671
[28,     1] loss: 1711.571
[29,     1] loss: 1840.448
[30,     1] loss: 1759.534
[31,     1] loss: 1753.435
[32,     1] loss: 1731.181
[33,     1] loss: 1714.211
[34,     1] loss: 1731.199
[35,     1] loss: 1739.287
[36,     1] loss: 1708.307
[37,     1] loss: 1695.312
[38,     1] loss: 1672.737
[39,     1] loss: 1598.798
[40,     1] loss: 1690.701
[41,     1] loss: 1669.858
[42,     1] loss: 1576.072
[43,     1] loss: 1696.077
[44,     1] loss: 1653.426
[45,     1] loss: 1571.844
[46,     1] loss: 1531.559
[47,     1] loss: 1573.807
[48,     1] loss: 1529.349
[49,     1] loss: 1532.582
[50,     1] loss: 1431.988
[51,     1] loss: 1423.748
[52,     1] loss: 1458.954
[53,     1] loss: 1567.142
[54,     1] loss: 1524.077
[55,     1] loss: 1369.087
[56,     1] loss: 1599.207
[57,     1] loss: 1434.816
[58,     1] loss: 1479.456
[59,     1] loss: 1405.063
[60,     1] loss: 1371.537
[61,     1] loss: 1335.005
[62,     1] loss: 1354.023
[63,     1] loss: 1243.781
[64,     1] loss: 1278.041
[65,     1] loss: 1328.047
Early stopping applied (best metric=0.8394742012023926)
Finished Training
Total time taken: 9.831206560134888
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 2128.693
[2,     1] loss: 2118.010
[3,     1] loss: 2115.942
[4,     1] loss: 2119.368
[5,     1] loss: 2126.431
[6,     1] loss: 2113.237
[7,     1] loss: 2116.111
[8,     1] loss: 2116.742
[9,     1] loss: 2108.772
[10,     1] loss: 2110.548
[11,     1] loss: 2108.013
[12,     1] loss: 2091.271
[13,     1] loss: 2081.878
[14,     1] loss: 2068.291
[15,     1] loss: 2050.764
[16,     1] loss: 1989.066
[17,     1] loss: 1985.105
[18,     1] loss: 1912.531
[19,     1] loss: 1870.693
[20,     1] loss: 1868.099
[21,     1] loss: 1839.279
[22,     1] loss: 1854.881
[23,     1] loss: 1876.142
[24,     1] loss: 1696.859
[25,     1] loss: 1785.475
[26,     1] loss: 1666.209
[27,     1] loss: 1631.313
[28,     1] loss: 1719.248
[29,     1] loss: 1694.846
[30,     1] loss: 1693.150
[31,     1] loss: 1658.452
[32,     1] loss: 1838.784
[33,     1] loss: 1603.647
[34,     1] loss: 1646.487
[35,     1] loss: 1780.920
[36,     1] loss: 1640.102
[37,     1] loss: 1601.356
Early stopping applied (best metric=0.9813027381896973)
Finished Training
Total time taken: 5.782123804092407
{'Hydroxylation-K Validation Accuracy': 0.7523640661938534, 'Hydroxylation-K Validation Sensitivity': 0.8066666666666666, 'Hydroxylation-K Validation Specificity': 0.7385964912280701, 'Hydroxylation-K Validation Precision': 0.451500343803009, 'Hydroxylation-K AUC ROC': 0.8337037037037037, 'Hydroxylation-K AUC PR': 0.6268908659249511, 'Hydroxylation-K MCC': 0.46078162454768107, 'Hydroxylation-K F1': 0.573609448688909, 'Validation Loss (Hydroxylation-K)': 0.39742417335510255, 'Hydroxylation-P Validation Accuracy': 0.7497311642387019, 'Hydroxylation-P Validation Sensitivity': 0.6834391534391534, 'Hydroxylation-P Validation Specificity': 0.7639732654995262, 'Hydroxylation-P Validation Precision': 0.3887014822054277, 'Hydroxylation-P AUC ROC': 0.7876014557983734, 'Hydroxylation-P AUC PR': 0.4986744957871866, 'Hydroxylation-P MCC': 0.37036076944214835, 'Hydroxylation-P F1': 0.49354564504580367, 'Validation Loss (Hydroxylation-P)': 0.44206607937812803, 'Validation Loss (total)': 0.8394902467727661, 'TimeToTrain': 8.841609112421672}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009454024698637915,
 'learning_rate_Hydroxylation-K': 0.0004679284981480023,
 'learning_rate_Hydroxylation-P': 0.005084880181303823,
 'log_base': 1.923991447141401,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 940513534,
 'sample_weights': [5.7468410748981595, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6169136339240273,
 'weight_decay_Hydroxylation-K': 9.57961865619787,
 'weight_decay_Hydroxylation-P': 8.306797157404002}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1448.645
[2,     1] loss: 1464.441
[3,     1] loss: 1485.572
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006162825030343489,
 'learning_rate_Hydroxylation-K': 0.005805477981634833,
 'learning_rate_Hydroxylation-P': 0.0037785925148073845,
 'log_base': 2.2069384708719255,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4206723449,
 'sample_weights': [2.5510976203916025, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.626256288716302,
 'weight_decay_Hydroxylation-K': 3.745608064295193,
 'weight_decay_Hydroxylation-P': 0.8538405230169543}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1351.615
[2,     1] loss: 1356.710
[3,     1] loss: 1354.200
[4,     1] loss: 1355.209
[5,     1] loss: 1355.186
[6,     1] loss: 1341.736
[7,     1] loss: 1346.573
[8,     1] loss: 1327.120
[9,     1] loss: 1289.336
[10,     1] loss: 1284.967
[11,     1] loss: 1237.276
[12,     1] loss: 1216.725
[13,     1] loss: 1191.917
[14,     1] loss: 1139.107
[15,     1] loss: 1208.316
[16,     1] loss: 1119.565
[17,     1] loss: 1136.014
[18,     1] loss: 1119.236
[19,     1] loss: 1108.042
[20,     1] loss: 1115.383
[21,     1] loss: 1078.662
[22,     1] loss: 1027.371
[23,     1] loss: 1112.155
[24,     1] loss: 1040.757
[25,     1] loss: 1077.405
[26,     1] loss: 1034.459
[27,     1] loss: 1015.831
[28,     1] loss: 1040.328
[29,     1] loss: 1012.870
[30,     1] loss: 1019.198
[31,     1] loss: 1074.411
[32,     1] loss: 964.677
[33,     1] loss: 983.615
[34,     1] loss: 944.723
[35,     1] loss: 914.069
[36,     1] loss: 974.649
[37,     1] loss: 998.239
[38,     1] loss: 935.535
[39,     1] loss: 912.697
[40,     1] loss: 923.066
[41,     1] loss: 836.748
[42,     1] loss: 860.963
[43,     1] loss: 927.865
[44,     1] loss: 1078.512
[45,     1] loss: 890.255
[46,     1] loss: 912.496
[47,     1] loss: 903.386
[48,     1] loss: 917.350
[49,     1] loss: 841.299
[50,     1] loss: 827.946
[51,     1] loss: 902.982
[52,     1] loss: 897.941
[53,     1] loss: 752.086
[54,     1] loss: 770.170
[55,     1] loss: 824.009
[56,     1] loss: 822.062
[57,     1] loss: 795.302
[58,     1] loss: 900.233
[59,     1] loss: 993.898
[60,     1] loss: 804.013
[61,     1] loss: 878.330
[62,     1] loss: 809.039
[63,     1] loss: 855.570
[64,     1] loss: 838.642
[65,     1] loss: 758.798
[66,     1] loss: 720.303
[67,     1] loss: 827.120
[68,     1] loss: 743.307
[69,     1] loss: 702.797
[70,     1] loss: 839.076
[71,     1] loss: 1093.460
[72,     1] loss: 814.545
[73,     1] loss: 861.634
[74,     1] loss: 831.690
[75,     1] loss: 841.608
[76,     1] loss: 903.075
[77,     1] loss: 726.070
[78,     1] loss: 738.714
[79,     1] loss: 969.309
[80,     1] loss: 1085.258
[81,     1] loss: 740.415
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028270745424499827,
 'learning_rate_Hydroxylation-K': 0.009835468218483641,
 'learning_rate_Hydroxylation-P': 0.003915712177049281,
 'log_base': 2.727833669846378,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1948184432,
 'sample_weights': [2.108931242078129, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.4798533911349474,
 'weight_decay_Hydroxylation-K': 1.5379686384566094,
 'weight_decay_Hydroxylation-P': 0.3753912222687761}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1265.717
[2,     1] loss: 1261.789
[3,     1] loss: 1261.835
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009824540396758978,
 'learning_rate_Hydroxylation-K': 0.0031159606262816425,
 'learning_rate_Hydroxylation-P': 0.003532160141666275,
 'log_base': 2.024789760304451,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3474000833,
 'sample_weights': [1.6636076001511304, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8117690665212018,
 'weight_decay_Hydroxylation-K': 9.517699245016368,
 'weight_decay_Hydroxylation-P': 9.892812129141667}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1417.397
[2,     1] loss: 1469.126
[3,     1] loss: 1422.129
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002004148339767629,
 'learning_rate_Hydroxylation-K': 0.007100039849290889,
 'learning_rate_Hydroxylation-P': 0.0062212004403302094,
 'log_base': 1.356656632133486,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2831116747,
 'sample_weights': [2.3664406898882517, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.104467974934725,
 'weight_decay_Hydroxylation-K': 5.911512098632733,
 'weight_decay_Hydroxylation-P': 3.098029251724924}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2062.438
[2,     1] loss: 2066.089
[3,     1] loss: 2060.200
[4,     1] loss: 2061.875
[5,     1] loss: 2057.392
[6,     1] loss: 2062.276
[7,     1] loss: 2053.009
[8,     1] loss: 2054.388
[9,     1] loss: 2058.354
[10,     1] loss: 2042.491
[11,     1] loss: 2018.561
[12,     1] loss: 2005.019
[13,     1] loss: 1976.527
[14,     1] loss: 1933.551
[15,     1] loss: 1920.735
[16,     1] loss: 1899.862
[17,     1] loss: 1896.385
[18,     1] loss: 1754.830
[19,     1] loss: 1825.827
[20,     1] loss: 1800.814
[21,     1] loss: 1824.184
[22,     1] loss: 1759.262
[23,     1] loss: 1741.034
[24,     1] loss: 1675.636
[25,     1] loss: 1687.814
[26,     1] loss: 1731.945
[27,     1] loss: 1659.653
[28,     1] loss: 1730.321
[29,     1] loss: 1598.902
[30,     1] loss: 1675.130
[31,     1] loss: 1515.903
[32,     1] loss: 1545.407
[33,     1] loss: 1686.273
[34,     1] loss: 1507.606
[35,     1] loss: 1616.529
[36,     1] loss: 1416.194
[37,     1] loss: 1634.038
[38,     1] loss: 1399.138
[39,     1] loss: 1354.187
[40,     1] loss: 1281.558
[41,     1] loss: 1343.328
[42,     1] loss: 1350.665
[43,     1] loss: 1251.126
[44,     1] loss: 1268.569
[45,     1] loss: 1247.880
[46,     1] loss: 1387.233
Early stopping applied (best metric=0.8801226019859314)
Finished Training
Total time taken: 6.223133563995361
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2075.048
[2,     1] loss: 2067.917
[3,     1] loss: 2062.890
[4,     1] loss: 2070.642
[5,     1] loss: 2062.619
[6,     1] loss: 2064.647
[7,     1] loss: 2056.212
[8,     1] loss: 2056.609
[9,     1] loss: 2057.811
[10,     1] loss: 2040.784
[11,     1] loss: 2033.046
[12,     1] loss: 2032.671
[13,     1] loss: 2004.012
[14,     1] loss: 1970.414
[15,     1] loss: 1925.163
[16,     1] loss: 1883.057
[17,     1] loss: 1815.526
[18,     1] loss: 1829.896
[19,     1] loss: 1794.495
[20,     1] loss: 1713.337
[21,     1] loss: 1756.895
[22,     1] loss: 1775.804
[23,     1] loss: 1718.507
[24,     1] loss: 1675.010
[25,     1] loss: 1720.740
[26,     1] loss: 1707.747
[27,     1] loss: 1678.756
[28,     1] loss: 1643.677
[29,     1] loss: 1588.769
[30,     1] loss: 1573.923
[31,     1] loss: 1593.875
[32,     1] loss: 1615.698
[33,     1] loss: 1596.479
[34,     1] loss: 1562.847
[35,     1] loss: 1589.833
[36,     1] loss: 1545.411
[37,     1] loss: 1544.297
[38,     1] loss: 1455.959
[39,     1] loss: 1394.296
[40,     1] loss: 1435.064
[41,     1] loss: 1346.476
[42,     1] loss: 1463.624
[43,     1] loss: 1364.222
[44,     1] loss: 1351.405
[45,     1] loss: 1285.986
[46,     1] loss: 1170.482
[47,     1] loss: 1237.016
[48,     1] loss: 1230.073
[49,     1] loss: 1467.015
[50,     1] loss: 1162.472
[51,     1] loss: 1478.973
[52,     1] loss: 1146.265
[53,     1] loss: 1391.182
[54,     1] loss: 1260.637
[55,     1] loss: 1068.566
[56,     1] loss: 1254.059
[57,     1] loss: 1192.408
Early stopping applied (best metric=0.8888788223266602)
Finished Training
Total time taken: 8.30717420578003
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2060.401
[2,     1] loss: 2064.473
[3,     1] loss: 2060.946
[4,     1] loss: 2079.863
[5,     1] loss: 2054.378
[6,     1] loss: 2056.716
[7,     1] loss: 2071.464
[8,     1] loss: 2078.470
[9,     1] loss: 2050.667
[10,     1] loss: 2046.817
[11,     1] loss: 2045.037
[12,     1] loss: 2039.439
[13,     1] loss: 2039.001
[14,     1] loss: 2007.384
[15,     1] loss: 2021.911
[16,     1] loss: 1981.862
[17,     1] loss: 1961.866
[18,     1] loss: 1899.139
[19,     1] loss: 1882.406
[20,     1] loss: 1908.442
[21,     1] loss: 1874.587
[22,     1] loss: 1877.361
[23,     1] loss: 1896.691
[24,     1] loss: 1774.621
[25,     1] loss: 1962.848
[26,     1] loss: 1846.752
[27,     1] loss: 1773.908
[28,     1] loss: 1717.168
[29,     1] loss: 1851.361
[30,     1] loss: 1794.140
[31,     1] loss: 1647.943
[32,     1] loss: 1718.107
[33,     1] loss: 1742.539
[34,     1] loss: 1685.152
[35,     1] loss: 1593.189
[36,     1] loss: 1652.356
[37,     1] loss: 1657.999
[38,     1] loss: 1580.006
[39,     1] loss: 1558.352
[40,     1] loss: 1498.849
[41,     1] loss: 1469.894
[42,     1] loss: 1440.883
[43,     1] loss: 1596.899
[44,     1] loss: 1384.825
[45,     1] loss: 1485.189
[46,     1] loss: 1539.189
[47,     1] loss: 1480.087
[48,     1] loss: 1365.004
[49,     1] loss: 1355.135
[50,     1] loss: 1378.806
[51,     1] loss: 1360.616
[52,     1] loss: 1338.881
[53,     1] loss: 1294.208
[54,     1] loss: 1349.146
[55,     1] loss: 1276.181
[56,     1] loss: 1264.933
[57,     1] loss: 1179.875
[58,     1] loss: 1172.493
[59,     1] loss: 1122.330
[60,     1] loss: 1129.426
Early stopping applied (best metric=0.7218985557556152)
Finished Training
Total time taken: 9.331199407577515
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2071.524
[2,     1] loss: 2066.464
[3,     1] loss: 2062.375
[4,     1] loss: 2060.161
[5,     1] loss: 2054.261
[6,     1] loss: 2051.348
[7,     1] loss: 2063.698
[8,     1] loss: 2058.641
[9,     1] loss: 2047.245
[10,     1] loss: 2034.045
[11,     1] loss: 2042.109
[12,     1] loss: 2016.684
[13,     1] loss: 1991.343
[14,     1] loss: 1967.297
[15,     1] loss: 1914.021
[16,     1] loss: 1877.790
[17,     1] loss: 1849.199
[18,     1] loss: 1930.226
[19,     1] loss: 1746.597
[20,     1] loss: 1792.918
[21,     1] loss: 1728.038
[22,     1] loss: 1778.389
[23,     1] loss: 1816.034
[24,     1] loss: 1787.405
[25,     1] loss: 1750.828
[26,     1] loss: 1718.503
[27,     1] loss: 1684.101
[28,     1] loss: 1692.783
[29,     1] loss: 1668.188
[30,     1] loss: 1736.232
[31,     1] loss: 1684.561
[32,     1] loss: 1646.160
[33,     1] loss: 1598.945
[34,     1] loss: 1634.283
[35,     1] loss: 1544.776
[36,     1] loss: 1605.619
[37,     1] loss: 1548.518
[38,     1] loss: 1588.439
[39,     1] loss: 1613.438
[40,     1] loss: 1478.487
[41,     1] loss: 1512.672
[42,     1] loss: 1410.421
[43,     1] loss: 1424.386
[44,     1] loss: 1452.288
[45,     1] loss: 1385.589
[46,     1] loss: 1373.314
[47,     1] loss: 1321.009
[48,     1] loss: 1419.852
[49,     1] loss: 1259.681
[50,     1] loss: 1298.659
[51,     1] loss: 1261.464
[52,     1] loss: 1242.454
[53,     1] loss: 1285.709
[54,     1] loss: 1348.489
[55,     1] loss: 1315.727
[56,     1] loss: 1279.621
[57,     1] loss: 1275.211
Early stopping applied (best metric=0.7335858345031738)
Finished Training
Total time taken: 7.879166841506958
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 2066.259
[2,     1] loss: 2083.812
[3,     1] loss: 2063.232
[4,     1] loss: 2061.639
[5,     1] loss: 2062.247
[6,     1] loss: 2057.730
[7,     1] loss: 2051.070
[8,     1] loss: 2049.346
[9,     1] loss: 2038.175
[10,     1] loss: 2014.841
[11,     1] loss: 1983.485
[12,     1] loss: 1958.360
[13,     1] loss: 1899.398
[14,     1] loss: 1854.681
[15,     1] loss: 1841.666
[16,     1] loss: 1772.648
[17,     1] loss: 1795.303
[18,     1] loss: 1866.059
[19,     1] loss: 1695.788
[20,     1] loss: 1661.800
[21,     1] loss: 1759.308
[22,     1] loss: 1720.392
[23,     1] loss: 1617.558
[24,     1] loss: 1726.957
[25,     1] loss: 1741.421
[26,     1] loss: 1621.244
[27,     1] loss: 1806.614
[28,     1] loss: 1650.324
[29,     1] loss: 1660.839
[30,     1] loss: 1674.452
[31,     1] loss: 1589.713
[32,     1] loss: 1712.624
[33,     1] loss: 1607.052
[34,     1] loss: 1520.885
[35,     1] loss: 1559.708
[36,     1] loss: 1611.724
[37,     1] loss: 1652.619
[38,     1] loss: 1694.446
[39,     1] loss: 1603.200
[40,     1] loss: 1541.081
[41,     1] loss: 1531.857
[42,     1] loss: 1602.262
[43,     1] loss: 1487.534
[44,     1] loss: 1565.329
[45,     1] loss: 1468.789
[46,     1] loss: 1486.862
[47,     1] loss: 1399.835
[48,     1] loss: 1327.499
[49,     1] loss: 1335.568
[50,     1] loss: 1389.810
[51,     1] loss: 1258.307
[52,     1] loss: 1251.162
[53,     1] loss: 1259.565
[54,     1] loss: 1278.335
[55,     1] loss: 1131.518
[56,     1] loss: 1328.730
[57,     1] loss: 1197.971
[58,     1] loss: 1245.198
[59,     1] loss: 1335.883
[60,     1] loss: 1205.491
[61,     1] loss: 1353.416
[62,     1] loss: 1087.886
[63,     1] loss: 1203.685
[64,     1] loss: 1224.746
Early stopping applied (best metric=0.8559290170669556)
Finished Training
Total time taken: 10.122211456298828
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2065.509
[2,     1] loss: 2063.572
[3,     1] loss: 2055.572
[4,     1] loss: 2058.080
[5,     1] loss: 2066.379
[6,     1] loss: 2063.534
[7,     1] loss: 2056.621
[8,     1] loss: 2057.845
[9,     1] loss: 2034.503
[10,     1] loss: 2037.266
[11,     1] loss: 2022.553
[12,     1] loss: 2021.268
[13,     1] loss: 2005.652
[14,     1] loss: 1985.573
[15,     1] loss: 1925.969
[16,     1] loss: 1912.857
[17,     1] loss: 1878.502
[18,     1] loss: 1824.372
[19,     1] loss: 1823.082
[20,     1] loss: 1760.247
[21,     1] loss: 1768.424
[22,     1] loss: 1811.482
[23,     1] loss: 1741.777
[24,     1] loss: 1749.151
[25,     1] loss: 1675.102
[26,     1] loss: 1701.597
[27,     1] loss: 1706.234
[28,     1] loss: 1706.432
[29,     1] loss: 1685.346
[30,     1] loss: 1673.196
[31,     1] loss: 1626.815
[32,     1] loss: 1665.507
[33,     1] loss: 1602.269
[34,     1] loss: 1462.633
[35,     1] loss: 1508.929
[36,     1] loss: 1508.401
[37,     1] loss: 1449.753
[38,     1] loss: 1527.706
[39,     1] loss: 1307.218
[40,     1] loss: 1441.119
[41,     1] loss: 1407.588
[42,     1] loss: 1313.698
[43,     1] loss: 1334.014
[44,     1] loss: 1312.755
[45,     1] loss: 1596.153
[46,     1] loss: 1275.054
[47,     1] loss: 1359.561
[48,     1] loss: 1270.233
[49,     1] loss: 1266.999
[50,     1] loss: 1228.611
[51,     1] loss: 1193.491
[52,     1] loss: 1404.050
Early stopping applied (best metric=0.7934976816177368)
Finished Training
Total time taken: 7.2741539478302
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2063.173
[2,     1] loss: 2049.043
[3,     1] loss: 2081.992
[4,     1] loss: 2068.211
[5,     1] loss: 2056.940
[6,     1] loss: 2061.070
[7,     1] loss: 2054.416
[8,     1] loss: 2044.689
[9,     1] loss: 2059.648
[10,     1] loss: 2036.478
[11,     1] loss: 2036.160
[12,     1] loss: 2004.886
[13,     1] loss: 1985.608
[14,     1] loss: 1957.901
[15,     1] loss: 1917.742
[16,     1] loss: 1895.356
[17,     1] loss: 1809.011
[18,     1] loss: 1783.351
[19,     1] loss: 1732.443
[20,     1] loss: 1743.903
[21,     1] loss: 1821.716
[22,     1] loss: 1782.897
[23,     1] loss: 1760.047
[24,     1] loss: 1759.091
[25,     1] loss: 1732.622
[26,     1] loss: 1778.797
[27,     1] loss: 1621.270
[28,     1] loss: 1687.653
[29,     1] loss: 1719.661
[30,     1] loss: 1651.224
[31,     1] loss: 1668.172
[32,     1] loss: 1654.679
[33,     1] loss: 1561.958
[34,     1] loss: 1777.758
[35,     1] loss: 1460.344
[36,     1] loss: 1608.041
[37,     1] loss: 1565.733
[38,     1] loss: 1629.052
[39,     1] loss: 1593.266
[40,     1] loss: 1517.523
[41,     1] loss: 1592.267
[42,     1] loss: 1595.082
[43,     1] loss: 1503.468
[44,     1] loss: 1506.073
[45,     1] loss: 1604.179
[46,     1] loss: 1355.254
[47,     1] loss: 1574.473
[48,     1] loss: 1416.422
[49,     1] loss: 1456.340
[50,     1] loss: 1254.476
[51,     1] loss: 1323.021
[52,     1] loss: 1331.840
[53,     1] loss: 1260.924
[54,     1] loss: 1238.993
[55,     1] loss: 1157.426
[56,     1] loss: 1272.669
[57,     1] loss: 1125.505
[58,     1] loss: 1295.165
[59,     1] loss: 1152.066
[60,     1] loss: 1291.802
[61,     1] loss: 1099.762
[62,     1] loss: 1340.568
[63,     1] loss: 1226.670
[64,     1] loss: 1358.070
[65,     1] loss: 977.353
Early stopping applied (best metric=0.7414004802703857)
Finished Training
Total time taken: 10.546221733093262
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2067.001
[2,     1] loss: 2058.397
[3,     1] loss: 2073.052
[4,     1] loss: 2054.505
[5,     1] loss: 2062.455
[6,     1] loss: 2063.046
[7,     1] loss: 2069.379
[8,     1] loss: 2064.105
[9,     1] loss: 2053.008
[10,     1] loss: 2059.765
[11,     1] loss: 2035.765
[12,     1] loss: 2032.671
[13,     1] loss: 2011.110
[14,     1] loss: 1979.201
[15,     1] loss: 1930.083
[16,     1] loss: 1909.450
[17,     1] loss: 1863.039
[18,     1] loss: 1834.764
[19,     1] loss: 1830.632
[20,     1] loss: 1793.496
[21,     1] loss: 1825.362
[22,     1] loss: 1735.675
[23,     1] loss: 1805.619
[24,     1] loss: 1734.659
[25,     1] loss: 1699.849
[26,     1] loss: 1692.585
[27,     1] loss: 1626.154
[28,     1] loss: 1742.970
[29,     1] loss: 1610.708
[30,     1] loss: 1626.981
[31,     1] loss: 1650.239
[32,     1] loss: 1631.264
[33,     1] loss: 1608.184
[34,     1] loss: 1546.434
[35,     1] loss: 1561.409
[36,     1] loss: 1553.888
[37,     1] loss: 1568.971
[38,     1] loss: 1458.372
[39,     1] loss: 1578.758
[40,     1] loss: 1504.750
[41,     1] loss: 1362.598
[42,     1] loss: 1390.955
[43,     1] loss: 1495.899
[44,     1] loss: 1441.715
[45,     1] loss: 1341.677
[46,     1] loss: 1465.628
[47,     1] loss: 1341.665
[48,     1] loss: 1385.557
[49,     1] loss: 1461.251
[50,     1] loss: 1240.854
[51,     1] loss: 1353.865
[52,     1] loss: 1357.708
Early stopping applied (best metric=0.8898779153823853)
Finished Training
Total time taken: 8.681185245513916
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2064.823
[2,     1] loss: 2065.553
[3,     1] loss: 2065.127
[4,     1] loss: 2067.191
[5,     1] loss: 2060.968
[6,     1] loss: 2049.243
[7,     1] loss: 2051.758
[8,     1] loss: 2045.323
[9,     1] loss: 2050.780
[10,     1] loss: 2016.837
[11,     1] loss: 2019.770
[12,     1] loss: 1973.994
[13,     1] loss: 1921.974
[14,     1] loss: 1890.298
[15,     1] loss: 1810.076
[16,     1] loss: 1762.162
[17,     1] loss: 1794.406
[18,     1] loss: 1764.630
[19,     1] loss: 1814.224
[20,     1] loss: 1812.335
[21,     1] loss: 1688.234
[22,     1] loss: 1655.200
[23,     1] loss: 1701.647
[24,     1] loss: 1750.506
[25,     1] loss: 1702.585
[26,     1] loss: 1610.525
[27,     1] loss: 1631.187
[28,     1] loss: 1603.031
[29,     1] loss: 1623.389
[30,     1] loss: 1606.318
[31,     1] loss: 1552.820
[32,     1] loss: 1636.424
[33,     1] loss: 1611.325
[34,     1] loss: 1505.710
[35,     1] loss: 1530.749
[36,     1] loss: 1426.790
[37,     1] loss: 1445.008
[38,     1] loss: 1405.695
[39,     1] loss: 1413.851
[40,     1] loss: 1363.753
[41,     1] loss: 1358.293
[42,     1] loss: 1303.549
[43,     1] loss: 1339.228
[44,     1] loss: 1416.429
[45,     1] loss: 1236.679
[46,     1] loss: 1492.584
[47,     1] loss: 1350.949
[48,     1] loss: 1328.883
[49,     1] loss: 1359.853
[50,     1] loss: 1331.534
[51,     1] loss: 1386.358
[52,     1] loss: 1218.803
[53,     1] loss: 1313.980
[54,     1] loss: 1253.502
[55,     1] loss: 1201.507
[56,     1] loss: 1107.155
Early stopping applied (best metric=0.8224449753761292)
Finished Training
Total time taken: 8.06516981124878
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 2068.533
[2,     1] loss: 2073.738
[3,     1] loss: 2066.585
[4,     1] loss: 2065.901
[5,     1] loss: 2063.366
[6,     1] loss: 2062.565
[7,     1] loss: 2065.569
[8,     1] loss: 2051.794
[9,     1] loss: 2046.690
[10,     1] loss: 2030.255
[11,     1] loss: 2008.317
[12,     1] loss: 1983.887
[13,     1] loss: 1954.705
[14,     1] loss: 1913.314
[15,     1] loss: 1881.832
[16,     1] loss: 1887.299
[17,     1] loss: 1827.779
[18,     1] loss: 1752.623
[19,     1] loss: 1868.738
[20,     1] loss: 1743.257
[21,     1] loss: 1799.801
[22,     1] loss: 1862.921
[23,     1] loss: 1802.174
[24,     1] loss: 1702.390
[25,     1] loss: 1726.347
[26,     1] loss: 1717.580
[27,     1] loss: 1711.799
[28,     1] loss: 1667.501
[29,     1] loss: 1757.702
[30,     1] loss: 1710.393
[31,     1] loss: 1715.409
[32,     1] loss: 1640.212
[33,     1] loss: 1608.705
[34,     1] loss: 1511.344
[35,     1] loss: 1488.734
[36,     1] loss: 1498.198
[37,     1] loss: 1454.831
[38,     1] loss: 1498.032
[39,     1] loss: 1336.963
[40,     1] loss: 1472.362
[41,     1] loss: 1466.895
[42,     1] loss: 1631.095
[43,     1] loss: 1432.463
[44,     1] loss: 1453.589
[45,     1] loss: 1485.252
[46,     1] loss: 1427.810
[47,     1] loss: 1429.429
[48,     1] loss: 1272.373
[49,     1] loss: 1413.224
[50,     1] loss: 1330.174
[51,     1] loss: 1228.896
[52,     1] loss: 1365.197
Early stopping applied (best metric=0.7239900827407837)
Finished Training
Total time taken: 7.6111602783203125
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2069.506
[2,     1] loss: 2064.421
[3,     1] loss: 2060.374
[4,     1] loss: 2059.949
[5,     1] loss: 2056.614
[6,     1] loss: 2063.890
[7,     1] loss: 2053.557
[8,     1] loss: 2041.496
[9,     1] loss: 2038.608
[10,     1] loss: 2034.538
[11,     1] loss: 2009.580
[12,     1] loss: 1980.207
[13,     1] loss: 1950.844
[14,     1] loss: 1932.165
[15,     1] loss: 1926.987
[16,     1] loss: 1903.195
[17,     1] loss: 1864.160
[18,     1] loss: 1792.116
[19,     1] loss: 1821.735
[20,     1] loss: 1845.779
[21,     1] loss: 1793.188
[22,     1] loss: 1782.052
[23,     1] loss: 1868.880
[24,     1] loss: 1832.664
[25,     1] loss: 1773.803
[26,     1] loss: 1813.272
[27,     1] loss: 1788.109
[28,     1] loss: 1705.095
[29,     1] loss: 1689.228
[30,     1] loss: 1773.734
[31,     1] loss: 1706.915
[32,     1] loss: 1634.839
[33,     1] loss: 1796.763
[34,     1] loss: 1639.075
[35,     1] loss: 1618.847
[36,     1] loss: 1662.754
[37,     1] loss: 1610.436
[38,     1] loss: 1670.512
[39,     1] loss: 1591.510
[40,     1] loss: 1461.907
[41,     1] loss: 1592.369
[42,     1] loss: 1512.172
[43,     1] loss: 1605.359
[44,     1] loss: 1536.279
[45,     1] loss: 1410.793
[46,     1] loss: 1540.878
[47,     1] loss: 1508.159
[48,     1] loss: 1520.988
[49,     1] loss: 1395.056
[50,     1] loss: 1474.195
[51,     1] loss: 1384.135
[52,     1] loss: 1394.185
[53,     1] loss: 1434.032
[54,     1] loss: 1422.344
[55,     1] loss: 1165.384
[56,     1] loss: 1311.030
[57,     1] loss: 1253.720
[58,     1] loss: 1331.244
[59,     1] loss: 1340.541
[60,     1] loss: 1217.210
[61,     1] loss: 1284.203
[62,     1] loss: 1182.187
[63,     1] loss: 1202.737
[64,     1] loss: 1217.069
[65,     1] loss: 1136.734
[66,     1] loss: 1110.553
[67,     1] loss: 1034.957
[68,     1] loss: 1299.674
[69,     1] loss: 1044.030
[70,     1] loss: 1211.578
[71,     1] loss: 1123.834
Early stopping applied (best metric=0.7859933376312256)
Finished Training
Total time taken: 10.668223857879639
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2070.120
[2,     1] loss: 2060.367
[3,     1] loss: 2056.554
[4,     1] loss: 2056.388
[5,     1] loss: 2062.304
[6,     1] loss: 2064.534
[7,     1] loss: 2061.007
[8,     1] loss: 2057.848
[9,     1] loss: 2057.527
[10,     1] loss: 2048.299
[11,     1] loss: 2050.835
[12,     1] loss: 2056.884
[13,     1] loss: 2033.694
[14,     1] loss: 2012.369
[15,     1] loss: 1986.652
[16,     1] loss: 1974.254
[17,     1] loss: 1905.176
[18,     1] loss: 1871.291
[19,     1] loss: 1862.223
[20,     1] loss: 1875.502
[21,     1] loss: 1737.617
[22,     1] loss: 1764.109
[23,     1] loss: 1792.855
[24,     1] loss: 1717.108
[25,     1] loss: 1798.935
[26,     1] loss: 1677.141
[27,     1] loss: 1753.735
[28,     1] loss: 1763.435
[29,     1] loss: 1732.112
[30,     1] loss: 1742.170
[31,     1] loss: 1696.435
[32,     1] loss: 1615.868
[33,     1] loss: 1672.969
[34,     1] loss: 1635.023
[35,     1] loss: 1628.072
[36,     1] loss: 1601.027
[37,     1] loss: 1498.901
[38,     1] loss: 1525.497
[39,     1] loss: 1626.648
[40,     1] loss: 1416.732
[41,     1] loss: 1374.013
[42,     1] loss: 1494.089
[43,     1] loss: 1481.042
[44,     1] loss: 1378.090
[45,     1] loss: 1455.008
[46,     1] loss: 1338.810
[47,     1] loss: 1204.553
[48,     1] loss: 1344.281
[49,     1] loss: 1256.914
[50,     1] loss: 1307.987
[51,     1] loss: 1270.543
[52,     1] loss: 1231.708
[53,     1] loss: 1247.350
Early stopping applied (best metric=0.8384299278259277)
Finished Training
Total time taken: 8.40917706489563
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2058.343
[2,     1] loss: 2057.129
[3,     1] loss: 2066.016
[4,     1] loss: 2069.771
[5,     1] loss: 2063.065
[6,     1] loss: 2057.016
[7,     1] loss: 2056.222
[8,     1] loss: 2063.184
[9,     1] loss: 2056.091
[10,     1] loss: 2038.160
[11,     1] loss: 2034.552
[12,     1] loss: 2006.567
[13,     1] loss: 1960.830
[14,     1] loss: 1933.487
[15,     1] loss: 1863.661
[16,     1] loss: 1855.234
[17,     1] loss: 1779.914
[18,     1] loss: 1813.176
[19,     1] loss: 1763.599
[20,     1] loss: 1698.981
[21,     1] loss: 1706.895
[22,     1] loss: 1736.580
[23,     1] loss: 1704.236
[24,     1] loss: 1739.381
[25,     1] loss: 1710.907
[26,     1] loss: 1694.180
[27,     1] loss: 1691.298
[28,     1] loss: 1611.643
[29,     1] loss: 1629.517
[30,     1] loss: 1727.443
[31,     1] loss: 1664.578
[32,     1] loss: 1605.001
[33,     1] loss: 1538.016
[34,     1] loss: 1686.941
[35,     1] loss: 1494.885
[36,     1] loss: 1618.649
[37,     1] loss: 1616.486
[38,     1] loss: 1542.211
[39,     1] loss: 1493.278
[40,     1] loss: 1504.782
[41,     1] loss: 1436.363
[42,     1] loss: 1522.572
[43,     1] loss: 1389.025
[44,     1] loss: 1456.933
[45,     1] loss: 1422.382
[46,     1] loss: 1443.852
[47,     1] loss: 1473.668
[48,     1] loss: 1370.042
[49,     1] loss: 1360.600
[50,     1] loss: 1277.244
[51,     1] loss: 1371.911
[52,     1] loss: 1179.754
[53,     1] loss: 1270.289
[54,     1] loss: 1483.798
[55,     1] loss: 1185.186
[56,     1] loss: 1314.849
[57,     1] loss: 1173.869
[58,     1] loss: 1289.568
[59,     1] loss: 1139.032
[60,     1] loss: 1150.070
Early stopping applied (best metric=0.8730909824371338)
Finished Training
Total time taken: 8.957188606262207
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2070.013
[2,     1] loss: 2061.203
[3,     1] loss: 2057.926
[4,     1] loss: 2062.946
[5,     1] loss: 2074.459
[6,     1] loss: 2062.579
[7,     1] loss: 2050.044
[8,     1] loss: 2057.221
[9,     1] loss: 2039.432
[10,     1] loss: 2025.812
[11,     1] loss: 1998.188
[12,     1] loss: 1940.451
[13,     1] loss: 1882.703
[14,     1] loss: 1843.715
[15,     1] loss: 1803.506
[16,     1] loss: 1802.906
[17,     1] loss: 1777.218
[18,     1] loss: 1708.507
[19,     1] loss: 1733.764
[20,     1] loss: 1699.865
[21,     1] loss: 1690.966
[22,     1] loss: 1710.152
[23,     1] loss: 1585.049
[24,     1] loss: 1611.964
[25,     1] loss: 1620.435
[26,     1] loss: 1719.509
[27,     1] loss: 1551.357
[28,     1] loss: 1574.510
[29,     1] loss: 1618.611
[30,     1] loss: 1643.180
[31,     1] loss: 1601.062
[32,     1] loss: 1405.697
[33,     1] loss: 1434.826
Early stopping applied (best metric=1.0177228450775146)
Finished Training
Total time taken: 4.463094234466553
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 2064.572
[2,     1] loss: 2065.453
[3,     1] loss: 2068.842
[4,     1] loss: 2062.980
[5,     1] loss: 2063.303
[6,     1] loss: 2059.448
[7,     1] loss: 2053.352
[8,     1] loss: 2063.121
[9,     1] loss: 2052.686
[10,     1] loss: 2031.097
[11,     1] loss: 2018.559
[12,     1] loss: 1995.688
[13,     1] loss: 1950.183
[14,     1] loss: 1903.669
[15,     1] loss: 1873.165
[16,     1] loss: 1804.926
[17,     1] loss: 1755.628
[18,     1] loss: 1803.855
[19,     1] loss: 1728.369
[20,     1] loss: 1736.694
[21,     1] loss: 1646.540
[22,     1] loss: 1849.208
[23,     1] loss: 1776.375
[24,     1] loss: 1717.065
[25,     1] loss: 1620.814
[26,     1] loss: 1678.245
[27,     1] loss: 1755.131
[28,     1] loss: 1647.263
[29,     1] loss: 1616.646
[30,     1] loss: 1654.784
[31,     1] loss: 1625.588
[32,     1] loss: 1561.680
[33,     1] loss: 1473.567
[34,     1] loss: 1521.679
[35,     1] loss: 1461.917
[36,     1] loss: 1552.082
[37,     1] loss: 1358.910
[38,     1] loss: 1516.292
[39,     1] loss: 1430.192
[40,     1] loss: 1375.683
[41,     1] loss: 1318.849
[42,     1] loss: 1260.974
[43,     1] loss: 1261.433
[44,     1] loss: 1366.484
[45,     1] loss: 1275.591
[46,     1] loss: 1496.027
[47,     1] loss: 1310.950
[48,     1] loss: 1259.759
Early stopping applied (best metric=0.9590556025505066)
Finished Training
Total time taken: 7.514159440994263
{'Hydroxylation-K Validation Accuracy': 0.7518026004728132, 'Hydroxylation-K Validation Sensitivity': 0.7622222222222222, 'Hydroxylation-K Validation Specificity': 0.7491228070175439, 'Hydroxylation-K Validation Precision': 0.43945242293539505, 'Hydroxylation-K AUC ROC': 0.8212280701754386, 'Hydroxylation-K AUC PR': 0.661867369988719, 'Hydroxylation-K MCC': 0.43309092950894984, 'Hydroxylation-K F1': 0.5521997305526717, 'Validation Loss (Hydroxylation-K)': 0.418937752644221, 'Hydroxylation-P Validation Accuracy': 0.7744830888448979, 'Hydroxylation-P Validation Sensitivity': 0.7025925925925925, 'Hydroxylation-P Validation Specificity': 0.7899147089630405, 'Hydroxylation-P Validation Precision': 0.42729731723502645, 'Hydroxylation-P AUC ROC': 0.8091705222997307, 'Hydroxylation-P AUC PR': 0.5331971239189838, 'Hydroxylation-P MCC': 0.41624814962611456, 'Hydroxylation-P F1': 0.5284423729337683, 'Validation Loss (Hydroxylation-P)': 0.4161234935124715, 'Validation Loss (total)': 0.835061244169871, 'TimeToTrain': 8.270174646377564}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0057597308435001085,
 'learning_rate_Hydroxylation-K': 0.00025886763006357464,
 'learning_rate_Hydroxylation-P': 0.005209625845392656,
 'log_base': 1.0644987529605237,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3463432040,
 'sample_weights': [5.4772257049400155, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.892329306292748,
 'weight_decay_Hydroxylation-K': 1.3920286662815984,
 'weight_decay_Hydroxylation-P': 8.6756735466998}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8646.906
[2,     1] loss: 8690.587
[3,     1] loss: 8709.088
[4,     1] loss: 8661.667
[5,     1] loss: 8659.217
[6,     1] loss: 8641.962
[7,     1] loss: 8630.833
[8,     1] loss: 8607.449
[9,     1] loss: 8620.747
[10,     1] loss: 8536.137
[11,     1] loss: 8526.752
[12,     1] loss: 8243.078
[13,     1] loss: 8418.726
[14,     1] loss: 8124.467
[15,     1] loss: 8105.449
[16,     1] loss: 7994.711
[17,     1] loss: 7845.438
[18,     1] loss: 7740.946
[19,     1] loss: 7431.147
[20,     1] loss: 7493.005
[21,     1] loss: 6826.580
[22,     1] loss: 7060.341
[23,     1] loss: 7011.808
[24,     1] loss: 7093.641
[25,     1] loss: 7656.661
[26,     1] loss: 6943.154
[27,     1] loss: 7401.906
[28,     1] loss: 7047.710
[29,     1] loss: 6723.717
[30,     1] loss: 6879.754
[31,     1] loss: 6597.466
[32,     1] loss: 6293.252
[33,     1] loss: 6173.313
[34,     1] loss: 5607.068
[35,     1] loss: 5736.775
[36,     1] loss: 5860.390
[37,     1] loss: 6328.464
[38,     1] loss: 5894.448
[39,     1] loss: 5567.435
[40,     1] loss: 5875.833
[41,     1] loss: 5246.732
[42,     1] loss: 5640.408
[43,     1] loss: 6418.606
[44,     1] loss: 8538.105
[45,     1] loss: 6889.052
Early stopping applied (best metric=0.851502537727356)
Finished Training
Total time taken: 6.19612979888916
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8674.583
[2,     1] loss: 8705.000
[3,     1] loss: 8675.773
[4,     1] loss: 8662.844
[5,     1] loss: 8768.458
[6,     1] loss: 8632.498
[7,     1] loss: 8644.835
[8,     1] loss: 8639.657
[9,     1] loss: 8592.576
[10,     1] loss: 8567.637
[11,     1] loss: 8545.818
[12,     1] loss: 8383.871
[13,     1] loss: 8211.869
[14,     1] loss: 7947.523
[15,     1] loss: 7848.205
[16,     1] loss: 7654.514
[17,     1] loss: 7477.282
[18,     1] loss: 7477.438
[19,     1] loss: 7098.560
[20,     1] loss: 6979.175
[21,     1] loss: 6954.756
[22,     1] loss: 7180.875
[23,     1] loss: 8513.398
[24,     1] loss: 6617.794
[25,     1] loss: 7661.814
[26,     1] loss: 6717.296
[27,     1] loss: 6901.033
[28,     1] loss: 7163.492
[29,     1] loss: 6635.168
[30,     1] loss: 6617.921
[31,     1] loss: 6386.093
[32,     1] loss: 6418.012
[33,     1] loss: 6155.246
[34,     1] loss: 6362.356
[35,     1] loss: 5472.166
[36,     1] loss: 5805.107
[37,     1] loss: 5685.534
[38,     1] loss: 5408.689
[39,     1] loss: 6922.012
[40,     1] loss: 7575.975
[41,     1] loss: 5370.369
[42,     1] loss: 7045.474
[43,     1] loss: 6014.890
Early stopping applied (best metric=0.8990333080291748)
Finished Training
Total time taken: 6.650142669677734
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8736.973
[2,     1] loss: 9048.039
[3,     1] loss: 8685.929
[4,     1] loss: 8730.464
[5,     1] loss: 8691.584
[6,     1] loss: 8667.251
[7,     1] loss: 8648.268
[8,     1] loss: 8667.383
[9,     1] loss: 8660.204
[10,     1] loss: 8663.558
[11,     1] loss: 8649.611
[12,     1] loss: 8633.778
[13,     1] loss: 8658.516
[14,     1] loss: 8649.799
[15,     1] loss: 8646.847
[16,     1] loss: 8668.521
[17,     1] loss: 8677.199
[18,     1] loss: 8659.009
[19,     1] loss: 8656.077
[20,     1] loss: 8647.387
[21,     1] loss: 8654.344
[22,     1] loss: 8650.838
[23,     1] loss: 8643.242
[24,     1] loss: 8636.016
[25,     1] loss: 8622.609
[26,     1] loss: 8601.881
[27,     1] loss: 8575.007
[28,     1] loss: 8479.654
[29,     1] loss: 8436.362
[30,     1] loss: 8385.473
[31,     1] loss: 8214.067
[32,     1] loss: 8056.117
[33,     1] loss: 8068.106
[34,     1] loss: 7929.976
[35,     1] loss: 7832.510
[36,     1] loss: 7412.862
[37,     1] loss: 6938.404
[38,     1] loss: 7392.030
[39,     1] loss: 6501.207
[40,     1] loss: 6948.112
[41,     1] loss: 6157.711
[42,     1] loss: 6467.752
[43,     1] loss: 5909.247
[44,     1] loss: 6506.092
[45,     1] loss: 5977.603
[46,     1] loss: 5766.222
[47,     1] loss: 5923.182
[48,     1] loss: 8688.105
[49,     1] loss: 5865.851
[50,     1] loss: 7375.509
[51,     1] loss: 6705.282
[52,     1] loss: 6650.113
[53,     1] loss: 6997.548
[54,     1] loss: 6634.847
[55,     1] loss: 6208.419
[56,     1] loss: 6199.370
[57,     1] loss: 6136.606
[58,     1] loss: 6530.846
Early stopping applied (best metric=0.9327459335327148)
Finished Training
Total time taken: 9.455202341079712
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8696.659
[2,     1] loss: 8724.653
[3,     1] loss: 8682.994
[4,     1] loss: 8684.622
[5,     1] loss: 8653.392
[6,     1] loss: 8679.759
[7,     1] loss: 8707.766
[8,     1] loss: 8656.090
[9,     1] loss: 8672.558
[10,     1] loss: 8648.243
[11,     1] loss: 8659.169
[12,     1] loss: 8651.848
[13,     1] loss: 8657.598
[14,     1] loss: 8655.195
[15,     1] loss: 8631.036
[16,     1] loss: 8640.766
[17,     1] loss: 8608.633
[18,     1] loss: 8573.812
[19,     1] loss: 8513.932
[20,     1] loss: 8358.500
[21,     1] loss: 8167.432
[22,     1] loss: 8044.171
[23,     1] loss: 7789.478
[24,     1] loss: 7699.968
[25,     1] loss: 7500.939
[26,     1] loss: 7334.237
[27,     1] loss: 7177.449
[28,     1] loss: 7416.408
[29,     1] loss: 7342.387
[30,     1] loss: 7091.876
[31,     1] loss: 6495.923
[32,     1] loss: 7586.038
[33,     1] loss: 6500.152
[34,     1] loss: 7010.826
[35,     1] loss: 6808.477
[36,     1] loss: 6472.672
[37,     1] loss: 6605.416
[38,     1] loss: 5735.105
[39,     1] loss: 5999.264
[40,     1] loss: 7392.065
[41,     1] loss: 5609.821
[42,     1] loss: 7462.046
[43,     1] loss: 6961.281
[44,     1] loss: 6978.471
[45,     1] loss: 6212.027
[46,     1] loss: 6747.032
[47,     1] loss: 6372.708
[48,     1] loss: 6013.729
[49,     1] loss: 6373.496
[50,     1] loss: 5567.546
[51,     1] loss: 5696.101
[52,     1] loss: 5984.551
[53,     1] loss: 5632.939
[54,     1] loss: 5804.374
[55,     1] loss: 5275.592
[56,     1] loss: 5475.083
[57,     1] loss: 4931.812
[58,     1] loss: 5184.984
[59,     1] loss: 5080.586
[60,     1] loss: 5305.664
Early stopping applied (best metric=0.8089890480041504)
Finished Training
Total time taken: 9.512200593948364
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 8682.921
[2,     1] loss: 8650.035
[3,     1] loss: 8644.863
[4,     1] loss: 8616.314
[5,     1] loss: 8665.910
[6,     1] loss: 8729.423
[7,     1] loss: 8593.855
[8,     1] loss: 8441.514
[9,     1] loss: 8389.921
[10,     1] loss: 8249.934
[11,     1] loss: 7911.610
[12,     1] loss: 7956.473
[13,     1] loss: 7630.660
[14,     1] loss: 7494.330
[15,     1] loss: 7489.763
[16,     1] loss: 7589.757
[17,     1] loss: 7670.895
[18,     1] loss: 7350.915
[19,     1] loss: 7847.389
[20,     1] loss: 7092.030
[21,     1] loss: 7088.344
[22,     1] loss: 6874.665
[23,     1] loss: 7001.270
[24,     1] loss: 6546.178
[25,     1] loss: 6562.693
[26,     1] loss: 6706.431
[27,     1] loss: 6555.667
[28,     1] loss: 6361.315
[29,     1] loss: 6960.238
[30,     1] loss: 6150.927
[31,     1] loss: 6534.469
[32,     1] loss: 6369.967
[33,     1] loss: 6181.376
[34,     1] loss: 6187.699
[35,     1] loss: 5721.599
[36,     1] loss: 5582.061
[37,     1] loss: 5732.097
[38,     1] loss: 5513.631
[39,     1] loss: 6344.281
[40,     1] loss: 5953.938
[41,     1] loss: 5442.843
[42,     1] loss: 5366.259
[43,     1] loss: 5855.855
[44,     1] loss: 5692.754
[45,     1] loss: 6372.681
[46,     1] loss: 5081.935
[47,     1] loss: 6037.360
[48,     1] loss: 5036.266
[49,     1] loss: 6299.908
[50,     1] loss: 4894.054
[51,     1] loss: 5869.312
[52,     1] loss: 5139.640
[53,     1] loss: 5150.903
[54,     1] loss: 4986.491
[55,     1] loss: 4871.479
[56,     1] loss: 5207.595
[57,     1] loss: 4687.934
[58,     1] loss: 5926.870
[59,     1] loss: 4464.133
[60,     1] loss: 5685.354
[61,     1] loss: 4441.718
[62,     1] loss: 5600.198
[63,     1] loss: 4621.911
Early stopping applied (best metric=0.8040298223495483)
Finished Training
Total time taken: 9.302197933197021
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8589.040
[2,     1] loss: 8913.114
[3,     1] loss: 8668.190
[4,     1] loss: 8681.193
[5,     1] loss: 8713.239
[6,     1] loss: 8678.773
[7,     1] loss: 8655.662
[8,     1] loss: 8675.335
[9,     1] loss: 8648.708
[10,     1] loss: 8661.261
[11,     1] loss: 8651.001
[12,     1] loss: 8659.551
[13,     1] loss: 8637.236
[14,     1] loss: 8667.269
[15,     1] loss: 8662.259
[16,     1] loss: 8645.259
[17,     1] loss: 8643.730
[18,     1] loss: 8633.465
[19,     1] loss: 8647.326
[20,     1] loss: 8619.720
[21,     1] loss: 8564.213
[22,     1] loss: 8551.657
[23,     1] loss: 8440.107
[24,     1] loss: 8314.086
[25,     1] loss: 8309.175
[26,     1] loss: 8126.049
[27,     1] loss: 7734.341
[28,     1] loss: 7953.937
[29,     1] loss: 7690.662
[30,     1] loss: 7632.406
[31,     1] loss: 7548.188
[32,     1] loss: 7325.843
[33,     1] loss: 7469.368
[34,     1] loss: 7254.099
[35,     1] loss: 7228.125
[36,     1] loss: 7034.625
[37,     1] loss: 8354.367
[38,     1] loss: 6822.362
[39,     1] loss: 7460.109
[40,     1] loss: 6514.148
[41,     1] loss: 7243.331
[42,     1] loss: 6722.916
[43,     1] loss: 6742.536
[44,     1] loss: 6889.586
[45,     1] loss: 6528.691
[46,     1] loss: 6322.202
[47,     1] loss: 6796.930
[48,     1] loss: 7174.347
[49,     1] loss: 6666.955
[50,     1] loss: 6104.553
[51,     1] loss: 6290.143
[52,     1] loss: 6515.675
[53,     1] loss: 6212.935
[54,     1] loss: 6584.608
[55,     1] loss: 6019.456
[56,     1] loss: 5467.737
[57,     1] loss: 5706.781
[58,     1] loss: 5520.338
[59,     1] loss: 5525.889
[60,     1] loss: 6584.933
[61,     1] loss: 4815.824
[62,     1] loss: 6877.122
[63,     1] loss: 5634.328
[64,     1] loss: 5660.754
[65,     1] loss: 5472.979
[66,     1] loss: 6013.254
Early stopping applied (best metric=0.8605948686599731)
Finished Training
Total time taken: 10.875229597091675
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8706.785
[2,     1] loss: 8890.692
[3,     1] loss: 8695.373
[4,     1] loss: 8695.205
[5,     1] loss: 8674.033
[6,     1] loss: 8704.916
[7,     1] loss: 8651.218
[8,     1] loss: 8656.361
[9,     1] loss: 8656.634
[10,     1] loss: 8650.377
[11,     1] loss: 8677.166
[12,     1] loss: 8664.666
[13,     1] loss: 8650.284
[14,     1] loss: 8647.201
[15,     1] loss: 8651.989
[16,     1] loss: 8655.357
[17,     1] loss: 8641.172
[18,     1] loss: 8672.334
[19,     1] loss: 8640.103
[20,     1] loss: 8650.336
[21,     1] loss: 8653.898
[22,     1] loss: 8654.359
[23,     1] loss: 8627.274
[24,     1] loss: 8624.171
[25,     1] loss: 8586.752
[26,     1] loss: 8497.779
[27,     1] loss: 8433.161
[28,     1] loss: 8300.759
[29,     1] loss: 7947.524
[30,     1] loss: 7882.592
[31,     1] loss: 7677.865
[32,     1] loss: 7339.097
[33,     1] loss: 7188.426
[34,     1] loss: 7373.102
[35,     1] loss: 6794.330
[36,     1] loss: 6824.258
[37,     1] loss: 6956.473
[38,     1] loss: 6876.802
[39,     1] loss: 7072.520
[40,     1] loss: 7244.715
[41,     1] loss: 6400.343
[42,     1] loss: 6373.246
[43,     1] loss: 5998.202
[44,     1] loss: 6164.661
[45,     1] loss: 7616.992
[46,     1] loss: 8163.574
[47,     1] loss: 6544.406
[48,     1] loss: 6529.051
[49,     1] loss: 6946.370
[50,     1] loss: 6931.638
[51,     1] loss: 6866.873
[52,     1] loss: 6710.781
[53,     1] loss: 7126.848
[54,     1] loss: 6778.009
[55,     1] loss: 6461.420
[56,     1] loss: 5936.703
[57,     1] loss: 6124.431
[58,     1] loss: 5826.009
[59,     1] loss: 5613.808
[60,     1] loss: 5861.415
[61,     1] loss: 5933.062
[62,     1] loss: 5451.966
[63,     1] loss: 5316.089
[64,     1] loss: 5110.345
[65,     1] loss: 5050.949
[66,     1] loss: 5058.571
Early stopping applied (best metric=0.8786057233810425)
Finished Training
Total time taken: 11.316240787506104
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8652.092
[2,     1] loss: 8674.052
[3,     1] loss: 8760.478
[4,     1] loss: 8649.084
[5,     1] loss: 8641.354
[6,     1] loss: 8656.277
[7,     1] loss: 8659.992
[8,     1] loss: 8653.922
[9,     1] loss: 8659.068
[10,     1] loss: 8656.261
[11,     1] loss: 8634.200
[12,     1] loss: 8632.611
[13,     1] loss: 8620.172
[14,     1] loss: 8562.002
[15,     1] loss: 8487.480
[16,     1] loss: 8366.520
[17,     1] loss: 8435.916
[18,     1] loss: 8081.609
[19,     1] loss: 7884.007
[20,     1] loss: 7796.305
[21,     1] loss: 7554.024
[22,     1] loss: 7824.904
[23,     1] loss: 7768.987
[24,     1] loss: 7483.710
[25,     1] loss: 7425.754
[26,     1] loss: 7275.481
[27,     1] loss: 7396.107
[28,     1] loss: 7048.326
[29,     1] loss: 7260.280
[30,     1] loss: 6793.240
[31,     1] loss: 7005.930
[32,     1] loss: 6706.408
[33,     1] loss: 7018.158
[34,     1] loss: 6548.434
[35,     1] loss: 6688.931
[36,     1] loss: 6367.466
[37,     1] loss: 5991.063
[38,     1] loss: 6021.457
[39,     1] loss: 6336.168
[40,     1] loss: 6243.869
[41,     1] loss: 6100.930
[42,     1] loss: 6013.400
[43,     1] loss: 5994.239
[44,     1] loss: 5887.667
[45,     1] loss: 5911.769
[46,     1] loss: 6440.902
[47,     1] loss: 8051.511
[48,     1] loss: 6851.959
[49,     1] loss: 6757.893
[50,     1] loss: 6280.569
[51,     1] loss: 6877.365
[52,     1] loss: 6882.841
[53,     1] loss: 6646.206
[54,     1] loss: 6708.752
[55,     1] loss: 6266.009
[56,     1] loss: 6369.478
[57,     1] loss: 6542.088
[58,     1] loss: 5956.358
[59,     1] loss: 5763.248
[60,     1] loss: 6040.350
[61,     1] loss: 5657.207
[62,     1] loss: 6325.247
[63,     1] loss: 5903.653
[64,     1] loss: 5704.437
[65,     1] loss: 5581.452
[66,     1] loss: 5062.547
[67,     1] loss: 4954.524
[68,     1] loss: 4967.530
[69,     1] loss: 5278.911
[70,     1] loss: 5314.231
[71,     1] loss: 4901.189
[72,     1] loss: 4476.201
[73,     1] loss: 5956.587
[74,     1] loss: 5542.207
[75,     1] loss: 4528.205
[76,     1] loss: 5849.812
[77,     1] loss: 5074.066
[78,     1] loss: 5645.015
[79,     1] loss: 4567.525
Early stopping applied (best metric=0.7934150695800781)
Finished Training
Total time taken: 12.658268928527832
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8680.238
[2,     1] loss: 8718.370
[3,     1] loss: 8671.822
[4,     1] loss: 8682.060
[5,     1] loss: 8648.868
[6,     1] loss: 8681.608
[7,     1] loss: 8684.242
[8,     1] loss: 8643.708
[9,     1] loss: 8668.211
[10,     1] loss: 8647.177
[11,     1] loss: 8705.041
[12,     1] loss: 8650.752
[13,     1] loss: 8638.931
[14,     1] loss: 8652.284
[15,     1] loss: 8641.120
[16,     1] loss: 8621.497
[17,     1] loss: 8605.141
[18,     1] loss: 8575.133
[19,     1] loss: 8498.721
[20,     1] loss: 8457.486
[21,     1] loss: 8361.283
[22,     1] loss: 8201.260
[23,     1] loss: 8033.703
[24,     1] loss: 8011.707
[25,     1] loss: 7741.699
[26,     1] loss: 7715.843
[27,     1] loss: 7503.531
[28,     1] loss: 7292.836
[29,     1] loss: 7393.318
[30,     1] loss: 7552.355
[31,     1] loss: 7431.468
[32,     1] loss: 7061.946
[33,     1] loss: 7511.129
[34,     1] loss: 7358.395
[35,     1] loss: 6969.109
[36,     1] loss: 7054.654
[37,     1] loss: 6720.182
[38,     1] loss: 6726.838
[39,     1] loss: 6582.521
[40,     1] loss: 6663.451
[41,     1] loss: 6944.068
[42,     1] loss: 5955.533
[43,     1] loss: 6130.173
[44,     1] loss: 6235.994
[45,     1] loss: 5795.235
[46,     1] loss: 5779.648
[47,     1] loss: 5680.108
[48,     1] loss: 5657.707
[49,     1] loss: 5494.539
[50,     1] loss: 5760.482
[51,     1] loss: 5226.912
[52,     1] loss: 5014.076
[53,     1] loss: 5319.334
[54,     1] loss: 6274.415
[55,     1] loss: 8019.385
[56,     1] loss: 6233.425
[57,     1] loss: 6254.205
[58,     1] loss: 5939.411
[59,     1] loss: 6512.381
[60,     1] loss: 5720.301
[61,     1] loss: 5616.688
[62,     1] loss: 5881.878
[63,     1] loss: 5111.880
[64,     1] loss: 5123.280
[65,     1] loss: 5232.756
[66,     1] loss: 5447.166
[67,     1] loss: 4818.090
[68,     1] loss: 4744.221
[69,     1] loss: 4805.185
[70,     1] loss: 5247.721
[71,     1] loss: 8790.508
[72,     1] loss: 7072.473
[73,     1] loss: 6941.585
[74,     1] loss: 6716.728
[75,     1] loss: 6699.345
[76,     1] loss: 6684.551
Early stopping applied (best metric=0.884624719619751)
Finished Training
Total time taken: 11.126233577728271
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 8680.230
[2,     1] loss: 8747.209
[3,     1] loss: 8691.553
[4,     1] loss: 8674.229
[5,     1] loss: 8660.853
[6,     1] loss: 8649.993
[7,     1] loss: 8650.704
[8,     1] loss: 8659.261
[9,     1] loss: 8669.541
[10,     1] loss: 8635.771
[11,     1] loss: 8590.673
[12,     1] loss: 8617.693
[13,     1] loss: 8577.566
[14,     1] loss: 8505.031
[15,     1] loss: 8397.014
[16,     1] loss: 8243.281
[17,     1] loss: 8041.521
[18,     1] loss: 7797.152
[19,     1] loss: 7895.371
[20,     1] loss: 7960.138
[21,     1] loss: 7354.599
[22,     1] loss: 7830.271
[23,     1] loss: 7284.272
[24,     1] loss: 7499.253
[25,     1] loss: 6800.061
[26,     1] loss: 7722.459
[27,     1] loss: 7033.405
[28,     1] loss: 7270.467
[29,     1] loss: 6984.255
[30,     1] loss: 6734.718
[31,     1] loss: 6509.279
[32,     1] loss: 6357.549
[33,     1] loss: 6220.708
[34,     1] loss: 6353.830
[35,     1] loss: 6401.456
[36,     1] loss: 6114.212
[37,     1] loss: 6130.582
[38,     1] loss: 5907.770
[39,     1] loss: 6186.188
[40,     1] loss: 5708.254
[41,     1] loss: 5826.035
[42,     1] loss: 5600.187
[43,     1] loss: 4994.413
[44,     1] loss: 5251.352
[45,     1] loss: 6689.402
[46,     1] loss: 7766.160
[47,     1] loss: 6208.127
[48,     1] loss: 6694.819
[49,     1] loss: 6063.040
[50,     1] loss: 6394.631
[51,     1] loss: 6147.115
[52,     1] loss: 6332.659
[53,     1] loss: 5684.494
[54,     1] loss: 5742.849
[55,     1] loss: 5704.974
[56,     1] loss: 5739.626
[57,     1] loss: 5453.048
[58,     1] loss: 5409.223
Early stopping applied (best metric=0.889279305934906)
Finished Training
Total time taken: 8.161174297332764
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8686.647
[2,     1] loss: 8608.310
[3,     1] loss: 8726.523
[4,     1] loss: 8642.640
[5,     1] loss: 8681.904
[6,     1] loss: 8665.771
[7,     1] loss: 8748.472
[8,     1] loss: 8644.488
[9,     1] loss: 8648.691
[10,     1] loss: 8693.393
[11,     1] loss: 8637.279
[12,     1] loss: 8631.129
[13,     1] loss: 8605.893
[14,     1] loss: 8505.789
[15,     1] loss: 8453.703
[16,     1] loss: 8234.266
[17,     1] loss: 8217.136
[18,     1] loss: 7900.851
[19,     1] loss: 7900.242
[20,     1] loss: 7456.356
[21,     1] loss: 7734.107
[22,     1] loss: 7209.829
[23,     1] loss: 7344.525
[24,     1] loss: 7693.627
[25,     1] loss: 8853.922
[26,     1] loss: 7795.188
[27,     1] loss: 7783.127
[28,     1] loss: 7907.175
[29,     1] loss: 7521.744
[30,     1] loss: 7497.875
[31,     1] loss: 7587.813
[32,     1] loss: 7348.266
[33,     1] loss: 7371.898
[34,     1] loss: 6975.302
[35,     1] loss: 6757.150
[36,     1] loss: 7331.506
[37,     1] loss: 6835.041
[38,     1] loss: 6543.371
[39,     1] loss: 6580.403
[40,     1] loss: 6617.956
[41,     1] loss: 6628.744
[42,     1] loss: 6418.068
[43,     1] loss: 6140.368
[44,     1] loss: 6051.000
[45,     1] loss: 5832.107
[46,     1] loss: 6014.820
[47,     1] loss: 6772.471
[48,     1] loss: 6299.189
[49,     1] loss: 6050.149
[50,     1] loss: 6853.371
[51,     1] loss: 6096.964
[52,     1] loss: 5829.300
[53,     1] loss: 6011.143
[54,     1] loss: 7466.298
[55,     1] loss: 5414.849
[56,     1] loss: 6946.572
[57,     1] loss: 5309.195
[58,     1] loss: 6669.029
[59,     1] loss: 5720.760
[60,     1] loss: 5477.994
[61,     1] loss: 5480.162
[62,     1] loss: 5346.412
[63,     1] loss: 5374.762
[64,     1] loss: 5398.347
[65,     1] loss: 4934.527
[66,     1] loss: 5219.899
[67,     1] loss: 5084.002
[68,     1] loss: 6501.683
[69,     1] loss: 7078.943
[70,     1] loss: 5766.881
[71,     1] loss: 5843.110
[72,     1] loss: 6505.573
[73,     1] loss: 6195.046
[74,     1] loss: 5636.297
Early stopping applied (best metric=0.7525074481964111)
Finished Training
Total time taken: 11.69624376296997
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8703.671
[2,     1] loss: 8678.788
[3,     1] loss: 8587.459
[4,     1] loss: 8769.045
[5,     1] loss: 8592.953
[6,     1] loss: 8614.736
[7,     1] loss: 8617.891
[8,     1] loss: 8569.377
[9,     1] loss: 8514.207
[10,     1] loss: 8427.229
[11,     1] loss: 8173.633
[12,     1] loss: 8080.835
[13,     1] loss: 7811.886
[14,     1] loss: 7690.579
[15,     1] loss: 7209.667
[16,     1] loss: 7230.354
[17,     1] loss: 6735.456
[18,     1] loss: 7452.129
[19,     1] loss: 8302.405
[20,     1] loss: 7708.278
[21,     1] loss: 6948.599
[22,     1] loss: 7281.809
[23,     1] loss: 7280.399
[24,     1] loss: 6991.751
[25,     1] loss: 7030.932
[26,     1] loss: 7031.803
[27,     1] loss: 6852.602
[28,     1] loss: 6857.827
[29,     1] loss: 6794.396
[30,     1] loss: 6936.748
[31,     1] loss: 6451.975
[32,     1] loss: 6429.744
[33,     1] loss: 6351.723
[34,     1] loss: 6175.679
[35,     1] loss: 5906.559
[36,     1] loss: 5691.032
[37,     1] loss: 6336.169
[38,     1] loss: 7257.587
[39,     1] loss: 5754.314
[40,     1] loss: 6553.608
[41,     1] loss: 6009.525
[42,     1] loss: 6202.546
[43,     1] loss: 5573.155
[44,     1] loss: 5623.099
[45,     1] loss: 5244.614
[46,     1] loss: 6173.192
[47,     1] loss: 6202.472
[48,     1] loss: 4636.323
[49,     1] loss: 5823.156
[50,     1] loss: 5265.088
[51,     1] loss: 5209.229
[52,     1] loss: 5073.201
[53,     1] loss: 5677.845
[54,     1] loss: 4829.004
[55,     1] loss: 4697.803
[56,     1] loss: 4718.790
[57,     1] loss: 4233.300
[58,     1] loss: 4023.364
[59,     1] loss: 4477.323
[60,     1] loss: 4621.552
[61,     1] loss: 9708.799
[62,     1] loss: 7441.562
Early stopping applied (best metric=0.8465440273284912)
Finished Training
Total time taken: 8.980189561843872
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8681.022
[2,     1] loss: 8881.176
[3,     1] loss: 8702.611
[4,     1] loss: 8622.665
[5,     1] loss: 8674.830
[6,     1] loss: 8655.963
[7,     1] loss: 8674.575
[8,     1] loss: 8687.454
[9,     1] loss: 8656.551
[10,     1] loss: 8661.701
[11,     1] loss: 8668.279
[12,     1] loss: 8654.562
[13,     1] loss: 8669.294
[14,     1] loss: 8662.771
[15,     1] loss: 8664.331
[16,     1] loss: 8643.139
[17,     1] loss: 8627.749
[18,     1] loss: 8611.688
[19,     1] loss: 8573.575
[20,     1] loss: 8536.161
[21,     1] loss: 8410.406
[22,     1] loss: 8346.077
[23,     1] loss: 8173.591
[24,     1] loss: 8029.134
[25,     1] loss: 7897.840
[26,     1] loss: 7550.179
[27,     1] loss: 7645.326
[28,     1] loss: 7910.101
[29,     1] loss: 8353.275
[30,     1] loss: 7164.863
[31,     1] loss: 7675.569
[32,     1] loss: 7277.104
[33,     1] loss: 7553.055
[34,     1] loss: 7466.847
[35,     1] loss: 7505.233
[36,     1] loss: 7010.397
[37,     1] loss: 7253.616
[38,     1] loss: 7029.793
[39,     1] loss: 7314.840
[40,     1] loss: 6727.924
[41,     1] loss: 6666.125
[42,     1] loss: 6306.231
[43,     1] loss: 6094.398
[44,     1] loss: 6029.898
[45,     1] loss: 6848.597
[46,     1] loss: 6765.567
[47,     1] loss: 6004.389
[48,     1] loss: 6973.421
[49,     1] loss: 6525.505
[50,     1] loss: 6799.781
[51,     1] loss: 6251.652
[52,     1] loss: 6283.180
[53,     1] loss: 5797.978
[54,     1] loss: 5700.683
[55,     1] loss: 5602.382
[56,     1] loss: 5742.450
[57,     1] loss: 7437.670
[58,     1] loss: 5392.974
[59,     1] loss: 6044.932
[60,     1] loss: 6212.250
[61,     1] loss: 6059.839
[62,     1] loss: 5890.080
[63,     1] loss: 5867.915
Early stopping applied (best metric=0.7600266933441162)
Finished Training
Total time taken: 10.100216627120972
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8649.814
[2,     1] loss: 8686.517
[3,     1] loss: 8651.916
[4,     1] loss: 8669.127
[5,     1] loss: 8689.914
[6,     1] loss: 8614.645
[7,     1] loss: 8579.115
[8,     1] loss: 8509.118
[9,     1] loss: 8388.424
[10,     1] loss: 8050.255
[11,     1] loss: 8052.889
[12,     1] loss: 7903.017
[13,     1] loss: 7802.771
[14,     1] loss: 7174.908
[15,     1] loss: 8012.107
[16,     1] loss: 6969.509
[17,     1] loss: 7715.587
[18,     1] loss: 7298.294
[19,     1] loss: 7197.636
[20,     1] loss: 7246.454
[21,     1] loss: 7392.288
[22,     1] loss: 6869.949
[23,     1] loss: 6734.858
[24,     1] loss: 7049.584
[25,     1] loss: 6300.397
[26,     1] loss: 6281.695
[27,     1] loss: 6357.280
[28,     1] loss: 6423.372
[29,     1] loss: 6128.517
[30,     1] loss: 6180.669
[31,     1] loss: 5781.564
[32,     1] loss: 5945.604
[33,     1] loss: 5610.747
[34,     1] loss: 5526.831
[35,     1] loss: 4830.882
[36,     1] loss: 5409.780
[37,     1] loss: 4714.773
[38,     1] loss: 5189.397
[39,     1] loss: 8677.415
[40,     1] loss: 8687.046
[41,     1] loss: 7639.319
[42,     1] loss: 6259.947
Early stopping applied (best metric=0.9205872416496277)
Finished Training
Total time taken: 6.323132038116455
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 8697.261
[2,     1] loss: 8706.129
[3,     1] loss: 8704.377
[4,     1] loss: 8747.295
[5,     1] loss: 8691.875
[6,     1] loss: 8693.981
[7,     1] loss: 8664.554
[8,     1] loss: 8683.693
[9,     1] loss: 8643.221
[10,     1] loss: 8669.654
[11,     1] loss: 8650.575
[12,     1] loss: 8634.398
[13,     1] loss: 8620.602
[14,     1] loss: 8612.732
[15,     1] loss: 8551.361
[16,     1] loss: 8385.235
[17,     1] loss: 8404.111
[18,     1] loss: 8129.257
[19,     1] loss: 8022.886
[20,     1] loss: 7875.190
[21,     1] loss: 7696.467
[22,     1] loss: 7654.966
[23,     1] loss: 7118.341
[24,     1] loss: 7525.912
[25,     1] loss: 7005.354
[26,     1] loss: 7620.368
[27,     1] loss: 6954.516
[28,     1] loss: 7636.460
[29,     1] loss: 7251.955
[30,     1] loss: 7841.764
[31,     1] loss: 7032.252
[32,     1] loss: 7335.441
[33,     1] loss: 7193.903
[34,     1] loss: 6628.754
[35,     1] loss: 6908.582
[36,     1] loss: 6563.173
[37,     1] loss: 6470.146
[38,     1] loss: 6364.342
[39,     1] loss: 6326.571
[40,     1] loss: 5987.268
[41,     1] loss: 5657.673
[42,     1] loss: 5954.722
[43,     1] loss: 5999.799
[44,     1] loss: 5896.188
[45,     1] loss: 8279.389
[46,     1] loss: 6558.547
[47,     1] loss: 6914.104
[48,     1] loss: 6875.754
[49,     1] loss: 6847.781
[50,     1] loss: 6549.731
[51,     1] loss: 6446.547
[52,     1] loss: 7197.310
[53,     1] loss: 6894.976
[54,     1] loss: 6510.404
[55,     1] loss: 6287.082
[56,     1] loss: 6404.137
[57,     1] loss: 6324.728
[58,     1] loss: 5887.318
[59,     1] loss: 5657.447
[60,     1] loss: 5788.382
Early stopping applied (best metric=0.7844404578208923)
Finished Training
Total time taken: 8.964188575744629
{'Hydroxylation-K Validation Accuracy': 0.7392139479905437, 'Hydroxylation-K Validation Sensitivity': 0.8044444444444445, 'Hydroxylation-K Validation Specificity': 0.7228070175438597, 'Hydroxylation-K Validation Precision': 0.43200037154681115, 'Hydroxylation-K AUC ROC': 0.8294541910331384, 'Hydroxylation-K AUC PR': 0.5797182283527783, 'Hydroxylation-K MCC': 0.44073162187654796, 'Hydroxylation-K F1': 0.5582686944355498, 'Validation Loss (Hydroxylation-K)': 0.41050148804982506, 'Hydroxylation-P Validation Accuracy': 0.7362698847774225, 'Hydroxylation-P Validation Sensitivity': 0.7027513227513228, 'Hydroxylation-P Validation Specificity': 0.7435208738590453, 'Hydroxylation-P Validation Precision': 0.38148506709812924, 'Hydroxylation-P AUC ROC': 0.7875307282871251, 'Hydroxylation-P AUC PR': 0.5152166600178799, 'Hydroxylation-P MCC': 0.36682291481025, 'Hydroxylation-P F1': 0.4902777991523125, 'Validation Loss (Hydroxylation-P)': 0.43396026492118833, 'Validation Loss (total)': 0.8444617470105489, 'TimeToTrain': 9.42113273938497}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00908564779977766,
 'learning_rate_Hydroxylation-K': 0.0021235964096116763,
 'learning_rate_Hydroxylation-P': 0.006121489879142293,
 'log_base': 2.8495299823147406,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2706554827,
 'sample_weights': [26.729179449536183, 3.3342051171449456],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6137001108947824,
 'weight_decay_Hydroxylation-K': 6.864777163130798,
 'weight_decay_Hydroxylation-P': 6.604331877401217}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.438
[2,     1] loss: 1283.860
[3,     1] loss: 1245.724
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007394040872249092,
 'learning_rate_Hydroxylation-K': 0.008566363747312183,
 'learning_rate_Hydroxylation-P': 0.003409171080170768,
 'log_base': 1.126941090982517,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3001202541,
 'sample_weights': [1.5942669829556153, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.770952571982416,
 'weight_decay_Hydroxylation-K': 5.66090896370543,
 'weight_decay_Hydroxylation-P': 7.304529348870795}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 4581.831
[2,     1] loss: 4681.236
[3,     1] loss: 4686.776
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005811892894470652,
 'learning_rate_Hydroxylation-K': 0.008241236189491984,
 'learning_rate_Hydroxylation-P': 0.007624651237765916,
 'log_base': 2.110167367738598,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4167435846,
 'sample_weights': [13.9694215707029, 1.7462449661147272],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.262538410287551,
 'weight_decay_Hydroxylation-K': 9.138724566904887,
 'weight_decay_Hydroxylation-P': 4.84352108254043}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1392.007
[2,     1] loss: 1380.823
[3,     1] loss: 1383.776
[4,     1] loss: 1385.273
[5,     1] loss: 1378.998
[6,     1] loss: 1375.295
[7,     1] loss: 1385.756
[8,     1] loss: 1376.698
[9,     1] loss: 1378.235
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004308456353883679,
 'learning_rate_Hydroxylation-K': 0.0013724752992750984,
 'learning_rate_Hydroxylation-P': 0.0008285096274074669,
 'log_base': 1.8840487911502606,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1187478924,
 'sample_weights': [2.2355601597032084, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.130802503576999,
 'weight_decay_Hydroxylation-K': 6.866001030026764,
 'weight_decay_Hydroxylation-P': 6.496558649181528}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1467.311
[2,     1] loss: 1464.511
[3,     1] loss: 1468.000
[4,     1] loss: 1463.782
[5,     1] loss: 1466.789
[6,     1] loss: 1464.218
[7,     1] loss: 1457.546
[8,     1] loss: 1463.223
[9,     1] loss: 1455.067
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004185584349192922,
 'learning_rate_Hydroxylation-K': 0.004104118573912395,
 'learning_rate_Hydroxylation-P': 0.0015915934880002512,
 'log_base': 1.4235435589825947,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 329882236,
 'sample_weights': [2.635589414690096, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.3620408098364534,
 'weight_decay_Hydroxylation-K': 6.4717043790452164,
 'weight_decay_Hydroxylation-P': 1.7028946851851468}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1910.965
[2,     1] loss: 1922.411
[3,     1] loss: 1906.465
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016093387972336021,
 'learning_rate_Hydroxylation-K': 0.0004275665448359785,
 'learning_rate_Hydroxylation-P': 0.007820738628017923,
 'log_base': 2.9453660422914036,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2542092980,
 'sample_weights': [4.727302281614941, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.288456677696922,
 'weight_decay_Hydroxylation-K': 4.270083652760087,
 'weight_decay_Hydroxylation-P': 2.3803658883226606}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.991
[2,     1] loss: 1237.248
[3,     1] loss: 1233.443
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008783435855984643,
 'learning_rate_Hydroxylation-K': 0.009331824380218057,
 'learning_rate_Hydroxylation-P': 0.004779416822517953,
 'log_base': 1.2620432917251592,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2859759938,
 'sample_weights': [1.54544712993636, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.519076881846964,
 'weight_decay_Hydroxylation-K': 4.172812520922639,
 'weight_decay_Hydroxylation-P': 6.7478388142412875}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2425.982
[2,     1] loss: 2432.747
[3,     1] loss: 2433.830
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004995561841999269,
 'learning_rate_Hydroxylation-K': 0.004841299966373983,
 'learning_rate_Hydroxylation-P': 0.009556268344661526,
 'log_base': 1.4597550689845624,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 295496320,
 'sample_weights': [7.173240734284431, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.7819012580444715,
 'weight_decay_Hydroxylation-K': 5.666310965577849,
 'weight_decay_Hydroxylation-P': 5.233644062778975}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1837.746
[2,     1] loss: 1840.458
[3,     1] loss: 1844.093
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014960373608587727,
 'learning_rate_Hydroxylation-K': 0.0021943127237997835,
 'learning_rate_Hydroxylation-P': 0.005781009538741209,
 'log_base': 2.7898081300391993,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2385532527,
 'sample_weights': [4.4133794865120315, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4263710227797288,
 'weight_decay_Hydroxylation-K': 2.125534709985674,
 'weight_decay_Hydroxylation-P': 6.050353217676841}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1259.546
[2,     1] loss: 1254.725
[3,     1] loss: 1251.585
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017726926727102746,
 'learning_rate_Hydroxylation-K': 0.005798160287496809,
 'learning_rate_Hydroxylation-P': 0.00652133570164664,
 'log_base': 2.5101129236475086,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1498127789,
 'sample_weights': [1.6271806720459299, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.0492549306272427,
 'weight_decay_Hydroxylation-K': 3.5693604717265512,
 'weight_decay_Hydroxylation-P': 0.8342997980283035}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1290.495
[2,     1] loss: 1288.687
[3,     1] loss: 1284.568
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008133221891131082,
 'learning_rate_Hydroxylation-K': 0.008593512418874263,
 'learning_rate_Hydroxylation-P': 0.007303459120459277,
 'log_base': 1.1676512690081011,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2264783520,
 'sample_weights': [1.8139659079080022, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.34273129610246866,
 'weight_decay_Hydroxylation-K': 4.2361645389409155,
 'weight_decay_Hydroxylation-P': 6.528182834347586}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3509.625
[2,     1] loss: 3503.989
[3,     1] loss: 3499.596
[4,     1] loss: 3491.543
[5,     1] loss: 3449.544
[6,     1] loss: 3500.788
[7,     1] loss: 3514.050
[8,     1] loss: 3519.182
[9,     1] loss: 3528.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020826538098353067,
 'learning_rate_Hydroxylation-K': 0.0026619123676514707,
 'learning_rate_Hydroxylation-P': 0.005279708165983857,
 'log_base': 2.9954681723248795,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3935852404,
 'sample_weights': [10.770999216104904, 1.3464267697808807],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.4116155548978284,
 'weight_decay_Hydroxylation-K': 6.277456121302927,
 'weight_decay_Hydroxylation-P': 4.74023379087426}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.625
[2,     1] loss: 1230.134
[3,     1] loss: 1226.167
[4,     1] loss: 1229.413
[5,     1] loss: 1227.087
[6,     1] loss: 1215.938
[7,     1] loss: 1212.029
[8,     1] loss: 1185.622
[9,     1] loss: 1158.648
[10,     1] loss: 1113.821
[11,     1] loss: 1090.463
[12,     1] loss: 1077.626
[13,     1] loss: 1067.878
[14,     1] loss: 1039.962
[15,     1] loss: 1051.784
[16,     1] loss: 1063.889
[17,     1] loss: 1054.411
[18,     1] loss: 1029.675
[19,     1] loss: 1028.910
[20,     1] loss: 1017.415
[21,     1] loss: 1042.821
[22,     1] loss: 1009.003
[23,     1] loss: 989.896
[24,     1] loss: 974.268
[25,     1] loss: 946.885
[26,     1] loss: 1009.530
[27,     1] loss: 997.961
[28,     1] loss: 955.229
[29,     1] loss: 995.802
[30,     1] loss: 977.677
[31,     1] loss: 943.734
[32,     1] loss: 966.163
[33,     1] loss: 929.442
[34,     1] loss: 925.644
[35,     1] loss: 918.334
[36,     1] loss: 924.947
[37,     1] loss: 892.098
[38,     1] loss: 954.526
[39,     1] loss: 909.856
[40,     1] loss: 925.126
[41,     1] loss: 894.406
[42,     1] loss: 884.130
[43,     1] loss: 892.193
[44,     1] loss: 839.578
[45,     1] loss: 895.698
[46,     1] loss: 935.322
[47,     1] loss: 837.934
[48,     1] loss: 885.352
[49,     1] loss: 831.653
[50,     1] loss: 824.615
[51,     1] loss: 871.188
[52,     1] loss: 834.965
[53,     1] loss: 801.433
[54,     1] loss: 759.740
[55,     1] loss: 849.685
[56,     1] loss: 774.795
[57,     1] loss: 761.928
[58,     1] loss: 758.347
[59,     1] loss: 804.687
[60,     1] loss: 750.424
[61,     1] loss: 794.532
[62,     1] loss: 767.829
[63,     1] loss: 811.626
[64,     1] loss: 754.233
[65,     1] loss: 730.128
[66,     1] loss: 679.717
[67,     1] loss: 734.468
[68,     1] loss: 717.583
[69,     1] loss: 738.050
[70,     1] loss: 695.457
[71,     1] loss: 748.302
[72,     1] loss: 668.097
[73,     1] loss: 709.755
[74,     1] loss: 702.369
[75,     1] loss: 657.901
[76,     1] loss: 655.688
[77,     1] loss: 660.322
[78,     1] loss: 655.868
[79,     1] loss: 632.020
[80,     1] loss: 621.666
[81,     1] loss: 638.254
[82,     1] loss: 652.911
[83,     1] loss: 583.562
[84,     1] loss: 635.840
[85,     1] loss: 655.349
[86,     1] loss: 594.970
[87,     1] loss: 570.538
[88,     1] loss: 623.486
[89,     1] loss: 517.141
[90,     1] loss: 579.046
[91,     1] loss: 564.349
[92,     1] loss: 549.326
[93,     1] loss: 539.957
[94,     1] loss: 553.145
[95,     1] loss: 556.423
[96,     1] loss: 511.866
Early stopping applied (best metric=0.685511589050293)
Finished Training
Total time taken: 13.529285192489624
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.440
[2,     1] loss: 1228.035
[3,     1] loss: 1225.795
[4,     1] loss: 1222.209
[5,     1] loss: 1213.263
[6,     1] loss: 1201.055
[7,     1] loss: 1169.162
[8,     1] loss: 1132.415
[9,     1] loss: 1102.937
[10,     1] loss: 1067.312
[11,     1] loss: 1029.042
[12,     1] loss: 1031.577
[13,     1] loss: 1020.451
[14,     1] loss: 979.427
[15,     1] loss: 1044.732
[16,     1] loss: 996.622
[17,     1] loss: 1005.484
[18,     1] loss: 1022.120
[19,     1] loss: 979.300
[20,     1] loss: 993.666
[21,     1] loss: 975.169
[22,     1] loss: 998.809
[23,     1] loss: 947.113
[24,     1] loss: 950.921
[25,     1] loss: 934.081
[26,     1] loss: 908.488
[27,     1] loss: 919.567
[28,     1] loss: 949.798
[29,     1] loss: 920.317
[30,     1] loss: 927.266
[31,     1] loss: 932.711
[32,     1] loss: 901.003
[33,     1] loss: 900.369
[34,     1] loss: 888.483
[35,     1] loss: 913.786
[36,     1] loss: 849.280
[37,     1] loss: 891.513
[38,     1] loss: 835.308
[39,     1] loss: 852.186
[40,     1] loss: 863.434
[41,     1] loss: 866.234
[42,     1] loss: 821.055
[43,     1] loss: 827.568
[44,     1] loss: 866.797
[45,     1] loss: 881.714
Early stopping applied (best metric=0.8685450553894043)
Finished Training
Total time taken: 7.500159978866577
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.124
[2,     1] loss: 1231.363
[3,     1] loss: 1228.811
[4,     1] loss: 1229.008
[5,     1] loss: 1227.602
[6,     1] loss: 1225.189
[7,     1] loss: 1223.662
[8,     1] loss: 1218.444
[9,     1] loss: 1203.719
[10,     1] loss: 1191.702
[11,     1] loss: 1169.713
[12,     1] loss: 1125.125
[13,     1] loss: 1093.070
[14,     1] loss: 1056.097
[15,     1] loss: 1086.312
[16,     1] loss: 1053.642
[17,     1] loss: 1055.987
[18,     1] loss: 1047.487
[19,     1] loss: 1045.318
[20,     1] loss: 993.757
[21,     1] loss: 1027.364
[22,     1] loss: 991.683
[23,     1] loss: 1000.476
[24,     1] loss: 994.123
[25,     1] loss: 984.932
[26,     1] loss: 981.372
[27,     1] loss: 970.648
[28,     1] loss: 965.556
[29,     1] loss: 955.712
[30,     1] loss: 946.215
[31,     1] loss: 950.947
[32,     1] loss: 891.419
[33,     1] loss: 955.488
[34,     1] loss: 861.188
[35,     1] loss: 916.001
[36,     1] loss: 911.570
[37,     1] loss: 865.831
[38,     1] loss: 876.949
[39,     1] loss: 876.498
[40,     1] loss: 851.869
[41,     1] loss: 908.903
[42,     1] loss: 812.218
[43,     1] loss: 831.987
Early stopping applied (best metric=0.8745232820510864)
Finished Training
Total time taken: 6.643141031265259
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.130
[2,     1] loss: 1229.523
[3,     1] loss: 1228.856
[4,     1] loss: 1229.037
[5,     1] loss: 1227.087
[6,     1] loss: 1228.495
[7,     1] loss: 1222.282
[8,     1] loss: 1214.400
[9,     1] loss: 1194.030
[10,     1] loss: 1179.208
[11,     1] loss: 1134.573
[12,     1] loss: 1093.052
[13,     1] loss: 1068.480
[14,     1] loss: 1051.796
[15,     1] loss: 1071.747
[16,     1] loss: 1030.297
[17,     1] loss: 1059.677
[18,     1] loss: 1006.139
[19,     1] loss: 1012.984
[20,     1] loss: 979.661
[21,     1] loss: 1014.901
[22,     1] loss: 997.841
[23,     1] loss: 954.920
[24,     1] loss: 989.329
[25,     1] loss: 930.332
[26,     1] loss: 979.268
[27,     1] loss: 961.283
[28,     1] loss: 939.250
[29,     1] loss: 940.847
[30,     1] loss: 908.875
[31,     1] loss: 906.286
[32,     1] loss: 899.617
[33,     1] loss: 903.387
[34,     1] loss: 919.651
[35,     1] loss: 929.297
[36,     1] loss: 888.653
[37,     1] loss: 858.151
[38,     1] loss: 890.596
[39,     1] loss: 854.889
[40,     1] loss: 869.466
[41,     1] loss: 839.022
[42,     1] loss: 865.638
[43,     1] loss: 841.319
Early stopping applied (best metric=0.9265209436416626)
Finished Training
Total time taken: 6.053126096725464
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1229.572
[2,     1] loss: 1232.090
[3,     1] loss: 1231.100
[4,     1] loss: 1230.752
[5,     1] loss: 1234.568
[6,     1] loss: 1227.807
[7,     1] loss: 1220.335
[8,     1] loss: 1217.395
[9,     1] loss: 1209.861
[10,     1] loss: 1187.785
[11,     1] loss: 1175.681
[12,     1] loss: 1123.036
[13,     1] loss: 1116.943
[14,     1] loss: 1060.249
[15,     1] loss: 1068.598
[16,     1] loss: 1022.668
[17,     1] loss: 1012.745
[18,     1] loss: 1041.158
[19,     1] loss: 1012.863
[20,     1] loss: 1031.655
[21,     1] loss: 1001.344
[22,     1] loss: 925.755
[23,     1] loss: 950.259
[24,     1] loss: 973.688
[25,     1] loss: 958.777
[26,     1] loss: 952.284
[27,     1] loss: 957.336
[28,     1] loss: 953.998
[29,     1] loss: 951.189
[30,     1] loss: 937.746
[31,     1] loss: 940.033
[32,     1] loss: 890.198
[33,     1] loss: 925.951
[34,     1] loss: 903.046
[35,     1] loss: 924.759
[36,     1] loss: 857.270
[37,     1] loss: 913.386
[38,     1] loss: 903.124
[39,     1] loss: 874.975
[40,     1] loss: 868.122
[41,     1] loss: 821.465
[42,     1] loss: 891.705
[43,     1] loss: 865.947
[44,     1] loss: 820.837
[45,     1] loss: 840.178
[46,     1] loss: 875.855
[47,     1] loss: 842.514
[48,     1] loss: 792.955
[49,     1] loss: 839.506
[50,     1] loss: 827.771
[51,     1] loss: 823.791
[52,     1] loss: 835.014
[53,     1] loss: 786.428
[54,     1] loss: 784.351
[55,     1] loss: 792.674
[56,     1] loss: 786.606
[57,     1] loss: 789.078
[58,     1] loss: 733.377
[59,     1] loss: 745.068
[60,     1] loss: 718.624
[61,     1] loss: 708.474
[62,     1] loss: 667.554
[63,     1] loss: 695.340
[64,     1] loss: 666.204
[65,     1] loss: 706.589
[66,     1] loss: 696.066
[67,     1] loss: 706.337
[68,     1] loss: 666.767
[69,     1] loss: 638.291
[70,     1] loss: 641.548
Early stopping applied (best metric=0.8629602789878845)
Finished Training
Total time taken: 11.389240264892578
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1237.028
[2,     1] loss: 1231.597
[3,     1] loss: 1229.370
[4,     1] loss: 1227.703
[5,     1] loss: 1229.837
[6,     1] loss: 1228.627
[7,     1] loss: 1222.529
[8,     1] loss: 1219.189
[9,     1] loss: 1202.614
[10,     1] loss: 1186.063
[11,     1] loss: 1162.924
[12,     1] loss: 1132.067
[13,     1] loss: 1119.626
[14,     1] loss: 1095.320
[15,     1] loss: 1045.592
[16,     1] loss: 1050.840
[17,     1] loss: 1034.244
[18,     1] loss: 1046.010
[19,     1] loss: 1041.579
[20,     1] loss: 1003.369
[21,     1] loss: 1012.152
[22,     1] loss: 959.184
[23,     1] loss: 975.412
[24,     1] loss: 1006.569
[25,     1] loss: 964.106
[26,     1] loss: 988.669
[27,     1] loss: 941.263
[28,     1] loss: 937.018
[29,     1] loss: 899.229
[30,     1] loss: 908.694
[31,     1] loss: 902.487
[32,     1] loss: 903.648
[33,     1] loss: 881.282
[34,     1] loss: 942.129
[35,     1] loss: 882.816
[36,     1] loss: 887.401
[37,     1] loss: 857.643
[38,     1] loss: 850.327
[39,     1] loss: 825.302
[40,     1] loss: 846.853
[41,     1] loss: 839.612
[42,     1] loss: 838.129
[43,     1] loss: 890.329
Early stopping applied (best metric=0.8463438749313354)
Finished Training
Total time taken: 5.801124095916748
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.744
[2,     1] loss: 1230.727
[3,     1] loss: 1225.748
[4,     1] loss: 1231.238
[5,     1] loss: 1225.764
[6,     1] loss: 1222.526
[7,     1] loss: 1218.521
[8,     1] loss: 1205.936
[9,     1] loss: 1183.911
[10,     1] loss: 1157.859
[11,     1] loss: 1112.067
[12,     1] loss: 1064.205
[13,     1] loss: 1088.102
[14,     1] loss: 1073.393
[15,     1] loss: 1053.730
[16,     1] loss: 1017.200
[17,     1] loss: 1019.383
[18,     1] loss: 1019.877
[19,     1] loss: 1024.026
[20,     1] loss: 976.539
[21,     1] loss: 987.682
[22,     1] loss: 972.597
[23,     1] loss: 993.106
[24,     1] loss: 996.522
[25,     1] loss: 1004.752
[26,     1] loss: 935.924
[27,     1] loss: 939.015
[28,     1] loss: 922.953
[29,     1] loss: 943.389
[30,     1] loss: 961.381
[31,     1] loss: 930.599
[32,     1] loss: 921.364
[33,     1] loss: 911.876
[34,     1] loss: 919.153
[35,     1] loss: 957.237
[36,     1] loss: 895.441
[37,     1] loss: 882.032
[38,     1] loss: 856.783
[39,     1] loss: 852.534
[40,     1] loss: 906.951
[41,     1] loss: 835.473
[42,     1] loss: 879.838
[43,     1] loss: 821.931
[44,     1] loss: 840.641
[45,     1] loss: 829.684
[46,     1] loss: 815.185
[47,     1] loss: 773.866
[48,     1] loss: 858.794
[49,     1] loss: 808.175
[50,     1] loss: 809.194
[51,     1] loss: 796.138
[52,     1] loss: 782.490
[53,     1] loss: 739.125
[54,     1] loss: 884.577
[55,     1] loss: 748.309
[56,     1] loss: 824.997
Early stopping applied (best metric=0.8168914318084717)
Finished Training
Total time taken: 8.885185956954956
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.117
[2,     1] loss: 1230.538
[3,     1] loss: 1231.018
[4,     1] loss: 1228.419
[5,     1] loss: 1221.768
[6,     1] loss: 1212.933
[7,     1] loss: 1205.490
[8,     1] loss: 1164.761
[9,     1] loss: 1133.619
[10,     1] loss: 1098.376
[11,     1] loss: 1108.381
[12,     1] loss: 1060.323
[13,     1] loss: 1088.527
[14,     1] loss: 1061.819
[15,     1] loss: 1060.511
[16,     1] loss: 1029.386
[17,     1] loss: 1007.621
[18,     1] loss: 1009.115
[19,     1] loss: 996.936
[20,     1] loss: 996.448
[21,     1] loss: 972.985
[22,     1] loss: 991.495
[23,     1] loss: 982.613
[24,     1] loss: 972.698
[25,     1] loss: 996.669
[26,     1] loss: 966.164
[27,     1] loss: 978.910
[28,     1] loss: 940.742
[29,     1] loss: 946.620
[30,     1] loss: 927.982
[31,     1] loss: 937.335
[32,     1] loss: 943.872
[33,     1] loss: 877.552
[34,     1] loss: 891.692
[35,     1] loss: 922.134
[36,     1] loss: 925.116
[37,     1] loss: 924.146
[38,     1] loss: 874.689
[39,     1] loss: 854.476
[40,     1] loss: 877.289
[41,     1] loss: 882.193
[42,     1] loss: 895.211
[43,     1] loss: 857.152
[44,     1] loss: 840.021
[45,     1] loss: 842.017
[46,     1] loss: 905.528
[47,     1] loss: 840.421
[48,     1] loss: 856.271
[49,     1] loss: 850.222
[50,     1] loss: 791.019
[51,     1] loss: 842.203
[52,     1] loss: 803.627
[53,     1] loss: 757.445
[54,     1] loss: 766.176
[55,     1] loss: 760.805
[56,     1] loss: 761.512
[57,     1] loss: 804.678
[58,     1] loss: 812.450
[59,     1] loss: 774.292
[60,     1] loss: 730.922
[61,     1] loss: 714.181
[62,     1] loss: 713.090
[63,     1] loss: 698.377
[64,     1] loss: 739.318
Early stopping applied (best metric=0.7705276012420654)
Finished Training
Total time taken: 9.237195014953613
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.252
[2,     1] loss: 1226.980
[3,     1] loss: 1228.090
[4,     1] loss: 1226.317
[5,     1] loss: 1223.764
[6,     1] loss: 1225.611
[7,     1] loss: 1215.425
[8,     1] loss: 1198.407
[9,     1] loss: 1175.744
[10,     1] loss: 1134.258
[11,     1] loss: 1119.442
[12,     1] loss: 1063.833
[13,     1] loss: 1052.646
[14,     1] loss: 1076.849
[15,     1] loss: 1041.857
[16,     1] loss: 1011.233
[17,     1] loss: 1026.868
[18,     1] loss: 1035.466
[19,     1] loss: 1011.676
[20,     1] loss: 1039.150
[21,     1] loss: 1031.218
[22,     1] loss: 1021.358
[23,     1] loss: 1007.942
[24,     1] loss: 981.328
[25,     1] loss: 961.978
[26,     1] loss: 971.287
[27,     1] loss: 969.870
[28,     1] loss: 991.635
[29,     1] loss: 980.392
[30,     1] loss: 927.201
[31,     1] loss: 938.495
[32,     1] loss: 911.141
[33,     1] loss: 938.033
[34,     1] loss: 934.033
[35,     1] loss: 885.161
[36,     1] loss: 909.810
[37,     1] loss: 881.550
[38,     1] loss: 907.146
[39,     1] loss: 868.429
[40,     1] loss: 848.140
[41,     1] loss: 881.859
[42,     1] loss: 911.273
[43,     1] loss: 840.408
[44,     1] loss: 846.553
[45,     1] loss: 916.323
[46,     1] loss: 869.760
[47,     1] loss: 816.779
[48,     1] loss: 832.932
[49,     1] loss: 831.762
[50,     1] loss: 783.026
[51,     1] loss: 857.127
[52,     1] loss: 775.084
[53,     1] loss: 826.134
[54,     1] loss: 751.545
[55,     1] loss: 781.404
[56,     1] loss: 751.197
[57,     1] loss: 720.969
[58,     1] loss: 763.239
[59,     1] loss: 728.078
[60,     1] loss: 678.507
[61,     1] loss: 711.055
[62,     1] loss: 712.067
[63,     1] loss: 689.438
[64,     1] loss: 694.629
[65,     1] loss: 643.429
Early stopping applied (best metric=0.8151290416717529)
Finished Training
Total time taken: 9.4721999168396
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1236.332
[2,     1] loss: 1229.212
[3,     1] loss: 1229.949
[4,     1] loss: 1228.553
[5,     1] loss: 1235.102
[6,     1] loss: 1227.013
[7,     1] loss: 1223.191
[8,     1] loss: 1215.536
[9,     1] loss: 1203.492
[10,     1] loss: 1182.683
[11,     1] loss: 1155.608
[12,     1] loss: 1116.305
[13,     1] loss: 1085.045
[14,     1] loss: 1087.824
[15,     1] loss: 1052.468
[16,     1] loss: 1038.022
[17,     1] loss: 1020.925
[18,     1] loss: 1029.650
[19,     1] loss: 1011.243
[20,     1] loss: 979.813
[21,     1] loss: 991.109
[22,     1] loss: 1035.874
[23,     1] loss: 980.680
[24,     1] loss: 985.015
[25,     1] loss: 980.975
[26,     1] loss: 934.797
[27,     1] loss: 920.595
[28,     1] loss: 916.425
[29,     1] loss: 926.952
[30,     1] loss: 942.553
[31,     1] loss: 964.409
[32,     1] loss: 901.880
[33,     1] loss: 894.138
[34,     1] loss: 923.300
[35,     1] loss: 907.361
[36,     1] loss: 886.334
[37,     1] loss: 891.196
[38,     1] loss: 886.123
[39,     1] loss: 868.550
[40,     1] loss: 830.280
[41,     1] loss: 854.382
[42,     1] loss: 869.901
[43,     1] loss: 913.122
[44,     1] loss: 811.718
[45,     1] loss: 849.041
[46,     1] loss: 874.673
[47,     1] loss: 837.478
[48,     1] loss: 818.544
[49,     1] loss: 786.166
[50,     1] loss: 791.470
[51,     1] loss: 772.083
[52,     1] loss: 782.099
[53,     1] loss: 769.660
[54,     1] loss: 723.818
Early stopping applied (best metric=0.8283017873764038)
Finished Training
Total time taken: 8.318174362182617
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1231.328
[2,     1] loss: 1232.742
[3,     1] loss: 1231.841
[4,     1] loss: 1224.727
[5,     1] loss: 1233.177
[6,     1] loss: 1222.585
[7,     1] loss: 1223.735
[8,     1] loss: 1215.907
[9,     1] loss: 1205.172
[10,     1] loss: 1185.987
[11,     1] loss: 1166.107
[12,     1] loss: 1125.074
[13,     1] loss: 1086.445
[14,     1] loss: 1069.523
[15,     1] loss: 1059.872
[16,     1] loss: 1028.100
[17,     1] loss: 1007.687
[18,     1] loss: 1017.271
[19,     1] loss: 1015.079
[20,     1] loss: 993.050
[21,     1] loss: 1050.502
[22,     1] loss: 980.141
[23,     1] loss: 957.483
[24,     1] loss: 1011.437
[25,     1] loss: 955.263
[26,     1] loss: 941.963
[27,     1] loss: 948.825
[28,     1] loss: 955.219
[29,     1] loss: 910.883
[30,     1] loss: 965.930
[31,     1] loss: 875.622
[32,     1] loss: 933.974
[33,     1] loss: 918.135
[34,     1] loss: 962.389
[35,     1] loss: 931.318
[36,     1] loss: 868.032
[37,     1] loss: 898.075
[38,     1] loss: 877.501
[39,     1] loss: 845.374
[40,     1] loss: 849.891
[41,     1] loss: 878.127
[42,     1] loss: 836.215
[43,     1] loss: 885.159
[44,     1] loss: 799.022
[45,     1] loss: 873.199
[46,     1] loss: 810.173
[47,     1] loss: 826.329
[48,     1] loss: 844.926
[49,     1] loss: 793.936
[50,     1] loss: 831.069
[51,     1] loss: 762.873
[52,     1] loss: 778.140
[53,     1] loss: 844.935
[54,     1] loss: 769.575
[55,     1] loss: 761.792
[56,     1] loss: 739.720
[57,     1] loss: 730.189
[58,     1] loss: 756.466
[59,     1] loss: 720.069
[60,     1] loss: 708.318
[61,     1] loss: 706.573
[62,     1] loss: 745.561
[63,     1] loss: 692.782
[64,     1] loss: 761.838
[65,     1] loss: 662.624
[66,     1] loss: 715.553
[67,     1] loss: 717.013
[68,     1] loss: 697.422
[69,     1] loss: 674.034
[70,     1] loss: 664.691
[71,     1] loss: 688.137
Early stopping applied (best metric=0.8409582376480103)
Finished Training
Total time taken: 10.396218538284302
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1226.531
[2,     1] loss: 1232.153
[3,     1] loss: 1226.639
[4,     1] loss: 1229.224
[5,     1] loss: 1224.064
[6,     1] loss: 1220.530
[7,     1] loss: 1208.553
[8,     1] loss: 1191.404
[9,     1] loss: 1175.189
[10,     1] loss: 1127.354
[11,     1] loss: 1117.896
[12,     1] loss: 1039.596
[13,     1] loss: 1070.477
[14,     1] loss: 1028.951
[15,     1] loss: 1082.839
[16,     1] loss: 1004.249
[17,     1] loss: 1010.549
[18,     1] loss: 1064.668
[19,     1] loss: 1010.699
[20,     1] loss: 1009.583
[21,     1] loss: 996.956
[22,     1] loss: 979.508
[23,     1] loss: 997.115
[24,     1] loss: 978.583
[25,     1] loss: 981.307
[26,     1] loss: 955.445
[27,     1] loss: 982.144
[28,     1] loss: 944.416
[29,     1] loss: 954.236
[30,     1] loss: 931.937
[31,     1] loss: 923.876
[32,     1] loss: 921.289
[33,     1] loss: 897.289
[34,     1] loss: 889.916
[35,     1] loss: 902.819
[36,     1] loss: 908.016
[37,     1] loss: 916.406
[38,     1] loss: 871.842
[39,     1] loss: 849.462
[40,     1] loss: 833.149
[41,     1] loss: 845.198
[42,     1] loss: 865.597
[43,     1] loss: 855.094
[44,     1] loss: 881.918
[45,     1] loss: 849.667
[46,     1] loss: 841.399
[47,     1] loss: 879.949
[48,     1] loss: 795.028
[49,     1] loss: 829.763
[50,     1] loss: 830.432
[51,     1] loss: 783.853
[52,     1] loss: 803.656
[53,     1] loss: 811.735
[54,     1] loss: 804.437
[55,     1] loss: 771.762
[56,     1] loss: 801.375
[57,     1] loss: 753.312
[58,     1] loss: 727.579
[59,     1] loss: 741.149
[60,     1] loss: 742.267
[61,     1] loss: 729.499
[62,     1] loss: 771.047
[63,     1] loss: 695.368
[64,     1] loss: 753.725
[65,     1] loss: 774.938
Early stopping applied (best metric=0.7489726543426514)
Finished Training
Total time taken: 9.785206317901611
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1228.814
[2,     1] loss: 1229.588
[3,     1] loss: 1224.320
[4,     1] loss: 1224.262
[5,     1] loss: 1220.595
[6,     1] loss: 1209.584
[7,     1] loss: 1189.888
[8,     1] loss: 1149.832
[9,     1] loss: 1132.953
[10,     1] loss: 1086.525
[11,     1] loss: 1068.887
[12,     1] loss: 1041.108
[13,     1] loss: 1037.280
[14,     1] loss: 1042.435
[15,     1] loss: 963.791
[16,     1] loss: 993.727
[17,     1] loss: 1038.009
[18,     1] loss: 1000.919
[19,     1] loss: 1046.936
[20,     1] loss: 986.206
[21,     1] loss: 1046.588
[22,     1] loss: 986.432
[23,     1] loss: 986.537
[24,     1] loss: 1006.998
[25,     1] loss: 935.791
[26,     1] loss: 941.977
[27,     1] loss: 926.375
[28,     1] loss: 965.355
[29,     1] loss: 937.735
[30,     1] loss: 923.217
[31,     1] loss: 900.141
[32,     1] loss: 920.457
[33,     1] loss: 862.244
[34,     1] loss: 877.418
[35,     1] loss: 881.960
[36,     1] loss: 853.758
[37,     1] loss: 881.599
[38,     1] loss: 853.839
[39,     1] loss: 894.740
[40,     1] loss: 878.522
[41,     1] loss: 855.279
[42,     1] loss: 816.074
[43,     1] loss: 846.144
[44,     1] loss: 795.885
[45,     1] loss: 802.187
[46,     1] loss: 747.464
[47,     1] loss: 763.479
[48,     1] loss: 754.457
[49,     1] loss: 753.408
[50,     1] loss: 726.628
[51,     1] loss: 771.030
[52,     1] loss: 762.521
[53,     1] loss: 716.903
[54,     1] loss: 693.612
Early stopping applied (best metric=0.8125404119491577)
Finished Training
Total time taken: 8.256176948547363
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1230.765
[2,     1] loss: 1227.857
[3,     1] loss: 1230.802
[4,     1] loss: 1227.086
[5,     1] loss: 1226.414
[6,     1] loss: 1223.350
[7,     1] loss: 1216.400
[8,     1] loss: 1200.176
[9,     1] loss: 1176.333
[10,     1] loss: 1134.058
[11,     1] loss: 1112.572
[12,     1] loss: 1066.516
[13,     1] loss: 1033.914
[14,     1] loss: 1082.946
[15,     1] loss: 1067.622
[16,     1] loss: 1036.601
[17,     1] loss: 1033.148
[18,     1] loss: 1033.779
[19,     1] loss: 1024.301
[20,     1] loss: 982.657
[21,     1] loss: 982.122
[22,     1] loss: 1003.209
[23,     1] loss: 992.465
[24,     1] loss: 994.605
[25,     1] loss: 973.618
[26,     1] loss: 958.727
[27,     1] loss: 952.455
[28,     1] loss: 940.464
[29,     1] loss: 957.035
[30,     1] loss: 931.266
[31,     1] loss: 950.098
[32,     1] loss: 947.297
[33,     1] loss: 977.093
[34,     1] loss: 940.360
[35,     1] loss: 903.160
[36,     1] loss: 902.796
[37,     1] loss: 889.898
[38,     1] loss: 883.360
[39,     1] loss: 912.557
[40,     1] loss: 897.985
[41,     1] loss: 866.579
[42,     1] loss: 875.415
[43,     1] loss: 866.545
[44,     1] loss: 879.027
[45,     1] loss: 849.600
[46,     1] loss: 839.511
[47,     1] loss: 845.914
[48,     1] loss: 867.444
[49,     1] loss: 816.897
[50,     1] loss: 829.812
[51,     1] loss: 834.326
[52,     1] loss: 852.342
[53,     1] loss: 773.417
[54,     1] loss: 859.211
[55,     1] loss: 784.764
[56,     1] loss: 834.585
[57,     1] loss: 820.334
[58,     1] loss: 765.776
[59,     1] loss: 759.901
[60,     1] loss: 747.272
[61,     1] loss: 765.278
[62,     1] loss: 725.153
[63,     1] loss: 790.480
[64,     1] loss: 721.759
[65,     1] loss: 759.208
[66,     1] loss: 690.693
[67,     1] loss: 671.823
[68,     1] loss: 697.652
Early stopping applied (best metric=0.8639470338821411)
Finished Training
Total time taken: 10.726225137710571
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1232.735
[2,     1] loss: 1230.907
[3,     1] loss: 1235.553
[4,     1] loss: 1229.096
[5,     1] loss: 1229.091
[6,     1] loss: 1227.164
[7,     1] loss: 1224.726
[8,     1] loss: 1215.723
[9,     1] loss: 1215.255
[10,     1] loss: 1192.139
[11,     1] loss: 1178.113
[12,     1] loss: 1145.530
[13,     1] loss: 1119.544
[14,     1] loss: 1092.311
[15,     1] loss: 1106.516
[16,     1] loss: 1032.982
[17,     1] loss: 1016.976
[18,     1] loss: 1010.773
[19,     1] loss: 1009.478
[20,     1] loss: 1044.292
[21,     1] loss: 1036.287
[22,     1] loss: 1002.996
[23,     1] loss: 984.511
[24,     1] loss: 985.703
[25,     1] loss: 1004.984
[26,     1] loss: 1003.118
[27,     1] loss: 947.818
[28,     1] loss: 968.379
[29,     1] loss: 954.636
[30,     1] loss: 930.863
[31,     1] loss: 950.819
[32,     1] loss: 944.230
[33,     1] loss: 914.388
[34,     1] loss: 963.842
[35,     1] loss: 901.448
[36,     1] loss: 881.895
[37,     1] loss: 915.833
[38,     1] loss: 920.347
[39,     1] loss: 921.197
[40,     1] loss: 892.105
[41,     1] loss: 914.166
[42,     1] loss: 901.967
[43,     1] loss: 892.149
[44,     1] loss: 904.385
[45,     1] loss: 841.687
[46,     1] loss: 879.764
[47,     1] loss: 852.983
[48,     1] loss: 837.633
[49,     1] loss: 837.363
[50,     1] loss: 841.144
[51,     1] loss: 828.319
[52,     1] loss: 839.056
[53,     1] loss: 792.116
[54,     1] loss: 837.232
[55,     1] loss: 867.783
[56,     1] loss: 822.078
[57,     1] loss: 830.095
[58,     1] loss: 772.455
[59,     1] loss: 800.284
[60,     1] loss: 803.565
[61,     1] loss: 802.566
[62,     1] loss: 806.834
[63,     1] loss: 738.778
[64,     1] loss: 774.304
[65,     1] loss: 722.067
[66,     1] loss: 790.290
[67,     1] loss: 695.869
Early stopping applied (best metric=0.639620840549469)
Finished Training
Total time taken: 10.460221290588379
{'Hydroxylation-K Validation Accuracy': 0.7771572104018912, 'Hydroxylation-K Validation Sensitivity': 0.6733333333333333, 'Hydroxylation-K Validation Specificity': 0.8035087719298245, 'Hydroxylation-K Validation Precision': 0.47832378405907816, 'Hydroxylation-K AUC ROC': 0.7882066276803119, 'Hydroxylation-K AUC PR': 0.5530746435828295, 'Hydroxylation-K MCC': 0.42774903164676303, 'Hydroxylation-K F1': 0.555100166607413, 'Validation Loss (Hydroxylation-K)': 0.43709434270858766, 'Hydroxylation-P Validation Accuracy': 0.7969694093362435, 'Hydroxylation-P Validation Sensitivity': 0.7576719576719577, 'Hydroxylation-P Validation Specificity': 0.8054541373634595, 'Hydroxylation-P Validation Precision': 0.45800161707904, 'Hydroxylation-P AUC ROC': 0.8491839418029004, 'Hydroxylation-P AUC PR': 0.5782531930632684, 'Hydroxylation-P MCC': 0.4728930959278101, 'Hydroxylation-P F1': 0.5692054070960455, 'Validation Loss (Hydroxylation-P)': 0.37632527351379397, 'Validation Loss (total)': 0.8134196043014527, 'TimeToTrain': 9.096858676274618}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004439477061850168,
 'learning_rate_Hydroxylation-K': 0.0004710280279627745,
 'learning_rate_Hydroxylation-P': 0.008969838965334835,
 'log_base': 2.467422990101255,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2113696522,
 'sample_weights': [1.5228153490399232, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7711174957572218,
 'weight_decay_Hydroxylation-K': 0.11886992350853642,
 'weight_decay_Hydroxylation-P': 0.5155968904192327}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1303.042
[2,     1] loss: 1298.046
[3,     1] loss: 1298.074
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008193490416781139,
 'learning_rate_Hydroxylation-K': 0.008307018222161526,
 'learning_rate_Hydroxylation-P': 0.0013088151855869892,
 'log_base': 1.161109352494999,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1056437956,
 'sample_weights': [1.8484174986071573, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.9174829875334916,
 'weight_decay_Hydroxylation-K': 8.041422362060773,
 'weight_decay_Hydroxylation-P': 3.0190866916997736}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3683.789
[2,     1] loss: 3791.584
[3,     1] loss: 3627.480
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022817689740548004,
 'learning_rate_Hydroxylation-K': 0.0011466688687734481,
 'learning_rate_Hydroxylation-P': 0.0035766739097156724,
 'log_base': 2.9680095754860956,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4216382930,
 'sample_weights': [11.176122109197532, 1.3970690822875422],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9869671610674389,
 'weight_decay_Hydroxylation-K': 2.0476948996059123,
 'weight_decay_Hydroxylation-P': 0.11617400843660242}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.713
[2,     1] loss: 1233.903
[3,     1] loss: 1235.565
[4,     1] loss: 1229.887
[5,     1] loss: 1228.293
[6,     1] loss: 1219.883
[7,     1] loss: 1215.395
[8,     1] loss: 1197.923
[9,     1] loss: 1173.147
[10,     1] loss: 1147.414
[11,     1] loss: 1121.946
[12,     1] loss: 1096.617
[13,     1] loss: 1074.205
[14,     1] loss: 1054.198
[15,     1] loss: 1055.592
[16,     1] loss: 1017.860
[17,     1] loss: 1024.479
[18,     1] loss: 1044.973
[19,     1] loss: 993.407
[20,     1] loss: 1037.292
[21,     1] loss: 1023.336
[22,     1] loss: 1018.351
[23,     1] loss: 1011.548
[24,     1] loss: 987.535
[25,     1] loss: 1010.921
[26,     1] loss: 980.059
[27,     1] loss: 944.556
[28,     1] loss: 955.023
[29,     1] loss: 961.537
[30,     1] loss: 947.294
[31,     1] loss: 924.147
[32,     1] loss: 854.511
[33,     1] loss: 882.524
[34,     1] loss: 875.964
[35,     1] loss: 879.609
[36,     1] loss: 893.125
[37,     1] loss: 854.710
[38,     1] loss: 905.527
[39,     1] loss: 900.161
[40,     1] loss: 840.031
[41,     1] loss: 818.962
[42,     1] loss: 815.068
[43,     1] loss: 830.904
[44,     1] loss: 806.562
[45,     1] loss: 821.600
[46,     1] loss: 786.921
[47,     1] loss: 783.340
[48,     1] loss: 739.634
[49,     1] loss: 772.973
[50,     1] loss: 739.232
[51,     1] loss: 840.222
[52,     1] loss: 847.082
[53,     1] loss: 737.682
[54,     1] loss: 795.518
[55,     1] loss: 716.579
[56,     1] loss: 721.695
[57,     1] loss: 715.286
[58,     1] loss: 653.523
[59,     1] loss: 632.076
[60,     1] loss: 584.625
[61,     1] loss: 675.358
Early stopping applied (best metric=0.8759927153587341)
Finished Training
Total time taken: 9.919211864471436
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.928
[2,     1] loss: 1230.695
[3,     1] loss: 1231.990
[4,     1] loss: 1228.062
[5,     1] loss: 1233.769
[6,     1] loss: 1227.281
[7,     1] loss: 1206.238
[8,     1] loss: 1194.432
[9,     1] loss: 1149.789
[10,     1] loss: 1119.991
[11,     1] loss: 1095.564
[12,     1] loss: 1088.993
[13,     1] loss: 1098.871
[14,     1] loss: 1040.504
[15,     1] loss: 1088.506
[16,     1] loss: 1034.434
[17,     1] loss: 1006.199
[18,     1] loss: 985.990
[19,     1] loss: 1026.099
[20,     1] loss: 1026.856
[21,     1] loss: 969.229
[22,     1] loss: 1008.722
[23,     1] loss: 1012.622
[24,     1] loss: 945.872
[25,     1] loss: 977.943
[26,     1] loss: 998.829
[27,     1] loss: 946.876
[28,     1] loss: 992.945
[29,     1] loss: 910.459
[30,     1] loss: 942.259
[31,     1] loss: 945.406
[32,     1] loss: 921.950
[33,     1] loss: 982.154
[34,     1] loss: 895.088
[35,     1] loss: 950.485
[36,     1] loss: 892.027
[37,     1] loss: 880.361
[38,     1] loss: 927.705
[39,     1] loss: 911.818
[40,     1] loss: 919.129
[41,     1] loss: 865.164
[42,     1] loss: 888.988
[43,     1] loss: 870.001
[44,     1] loss: 837.361
[45,     1] loss: 854.973
[46,     1] loss: 864.189
[47,     1] loss: 823.938
[48,     1] loss: 863.663
[49,     1] loss: 809.581
[50,     1] loss: 777.145
[51,     1] loss: 792.308
[52,     1] loss: 784.749
[53,     1] loss: 761.810
[54,     1] loss: 744.608
[55,     1] loss: 753.595
[56,     1] loss: 723.238
[57,     1] loss: 688.059
[58,     1] loss: 730.001
[59,     1] loss: 701.248
[60,     1] loss: 758.121
[61,     1] loss: 701.700
[62,     1] loss: 695.121
[63,     1] loss: 665.753
[64,     1] loss: 638.325
[65,     1] loss: 723.849
[66,     1] loss: 686.905
[67,     1] loss: 674.317
[68,     1] loss: 682.003
[69,     1] loss: 697.971
[70,     1] loss: 658.222
[71,     1] loss: 621.192
[72,     1] loss: 606.622
[73,     1] loss: 613.312
[74,     1] loss: 662.374
[75,     1] loss: 652.808
[76,     1] loss: 603.394
[77,     1] loss: 671.524
[78,     1] loss: 606.768
[79,     1] loss: 610.526
[80,     1] loss: 619.280
[81,     1] loss: 599.392
[82,     1] loss: 584.652
[83,     1] loss: 593.654
[84,     1] loss: 565.963
[85,     1] loss: 536.334
[86,     1] loss: 537.562
Early stopping applied (best metric=0.7187431454658508)
Finished Training
Total time taken: 12.780269384384155
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1230.754
[2,     1] loss: 1235.816
[3,     1] loss: 1233.220
[4,     1] loss: 1231.123
[5,     1] loss: 1227.923
[6,     1] loss: 1222.538
[7,     1] loss: 1208.804
[8,     1] loss: 1187.215
[9,     1] loss: 1152.905
[10,     1] loss: 1109.027
[11,     1] loss: 1085.099
[12,     1] loss: 1062.401
[13,     1] loss: 1020.654
[14,     1] loss: 1042.261
[15,     1] loss: 1017.770
[16,     1] loss: 1078.072
[17,     1] loss: 1007.470
[18,     1] loss: 1009.042
[19,     1] loss: 974.119
[20,     1] loss: 992.989
[21,     1] loss: 970.007
[22,     1] loss: 988.074
[23,     1] loss: 971.975
[24,     1] loss: 970.414
[25,     1] loss: 947.785
[26,     1] loss: 914.521
[27,     1] loss: 915.932
[28,     1] loss: 930.635
[29,     1] loss: 962.321
[30,     1] loss: 954.082
[31,     1] loss: 933.851
[32,     1] loss: 934.839
[33,     1] loss: 886.664
[34,     1] loss: 894.370
[35,     1] loss: 878.598
[36,     1] loss: 872.339
[37,     1] loss: 828.062
[38,     1] loss: 836.258
[39,     1] loss: 877.198
[40,     1] loss: 814.146
[41,     1] loss: 867.340
[42,     1] loss: 877.806
[43,     1] loss: 825.420
Early stopping applied (best metric=0.9462895393371582)
Finished Training
Total time taken: 6.959146976470947
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.313
[2,     1] loss: 1234.378
[3,     1] loss: 1237.304
[4,     1] loss: 1227.980
[5,     1] loss: 1231.950
[6,     1] loss: 1232.087
[7,     1] loss: 1226.395
[8,     1] loss: 1221.655
[9,     1] loss: 1220.470
[10,     1] loss: 1204.683
[11,     1] loss: 1188.003
[12,     1] loss: 1157.426
[13,     1] loss: 1137.300
[14,     1] loss: 1113.719
[15,     1] loss: 1093.653
[16,     1] loss: 1066.598
[17,     1] loss: 1050.818
[18,     1] loss: 1046.308
[19,     1] loss: 1029.680
[20,     1] loss: 991.222
[21,     1] loss: 985.668
[22,     1] loss: 1007.628
[23,     1] loss: 1001.758
[24,     1] loss: 958.163
[25,     1] loss: 997.347
[26,     1] loss: 977.816
[27,     1] loss: 1022.320
[28,     1] loss: 960.094
[29,     1] loss: 1001.609
[30,     1] loss: 926.035
[31,     1] loss: 933.196
[32,     1] loss: 946.260
[33,     1] loss: 951.260
[34,     1] loss: 949.016
[35,     1] loss: 887.501
[36,     1] loss: 884.094
[37,     1] loss: 891.174
[38,     1] loss: 866.205
[39,     1] loss: 862.104
[40,     1] loss: 843.804
[41,     1] loss: 834.436
[42,     1] loss: 833.116
[43,     1] loss: 778.103
[44,     1] loss: 846.498
[45,     1] loss: 795.254
[46,     1] loss: 821.482
[47,     1] loss: 831.940
[48,     1] loss: 749.931
[49,     1] loss: 804.138
[50,     1] loss: 740.671
[51,     1] loss: 742.491
[52,     1] loss: 710.310
[53,     1] loss: 743.791
[54,     1] loss: 719.831
[55,     1] loss: 754.469
Early stopping applied (best metric=0.710564136505127)
Finished Training
Total time taken: 7.429156541824341
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1240.172
[2,     1] loss: 1233.670
[3,     1] loss: 1238.081
[4,     1] loss: 1234.966
[5,     1] loss: 1230.893
[6,     1] loss: 1231.318
[7,     1] loss: 1223.011
[8,     1] loss: 1219.745
[9,     1] loss: 1201.340
[10,     1] loss: 1177.070
[11,     1] loss: 1152.579
[12,     1] loss: 1114.319
[13,     1] loss: 1067.175
[14,     1] loss: 1024.062
[15,     1] loss: 1020.200
[16,     1] loss: 1016.820
[17,     1] loss: 1043.920
[18,     1] loss: 1105.535
[19,     1] loss: 1026.302
[20,     1] loss: 978.913
[21,     1] loss: 968.837
[22,     1] loss: 1022.060
[23,     1] loss: 926.284
[24,     1] loss: 959.577
[25,     1] loss: 974.059
[26,     1] loss: 947.637
[27,     1] loss: 913.516
[28,     1] loss: 938.553
[29,     1] loss: 945.335
[30,     1] loss: 960.659
[31,     1] loss: 916.420
[32,     1] loss: 960.447
[33,     1] loss: 880.104
[34,     1] loss: 897.621
[35,     1] loss: 926.955
[36,     1] loss: 944.807
[37,     1] loss: 887.705
[38,     1] loss: 876.527
[39,     1] loss: 899.715
[40,     1] loss: 921.386
[41,     1] loss: 895.421
[42,     1] loss: 857.479
[43,     1] loss: 845.482
[44,     1] loss: 860.543
[45,     1] loss: 844.782
[46,     1] loss: 817.211
[47,     1] loss: 849.346
[48,     1] loss: 806.941
[49,     1] loss: 813.344
[50,     1] loss: 846.434
[51,     1] loss: 822.707
[52,     1] loss: 865.291
[53,     1] loss: 831.881
[54,     1] loss: 847.855
[55,     1] loss: 779.345
[56,     1] loss: 788.544
[57,     1] loss: 802.613
[58,     1] loss: 747.180
[59,     1] loss: 751.172
[60,     1] loss: 745.607
[61,     1] loss: 741.850
[62,     1] loss: 686.942
[63,     1] loss: 763.903
[64,     1] loss: 752.466
[65,     1] loss: 729.115
[66,     1] loss: 737.494
[67,     1] loss: 683.266
[68,     1] loss: 733.023
[69,     1] loss: 680.370
[70,     1] loss: 732.937
[71,     1] loss: 670.888
[72,     1] loss: 683.718
[73,     1] loss: 653.907
[74,     1] loss: 675.558
[75,     1] loss: 641.728
[76,     1] loss: 602.849
[77,     1] loss: 635.754
[78,     1] loss: 633.346
[79,     1] loss: 634.815
[80,     1] loss: 687.743
[81,     1] loss: 617.990
[82,     1] loss: 599.933
[83,     1] loss: 606.541
[84,     1] loss: 560.186
[85,     1] loss: 550.953
[86,     1] loss: 604.494
[87,     1] loss: 625.693
[88,     1] loss: 567.536
[89,     1] loss: 585.871
[90,     1] loss: 529.306
[91,     1] loss: 552.869
[92,     1] loss: 524.108
Early stopping applied (best metric=0.7451565861701965)
Finished Training
Total time taken: 13.352281332015991
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.995
[2,     1] loss: 1230.648
[3,     1] loss: 1234.170
[4,     1] loss: 1230.816
[5,     1] loss: 1229.804
[6,     1] loss: 1227.427
[7,     1] loss: 1224.264
[8,     1] loss: 1215.827
[9,     1] loss: 1191.717
[10,     1] loss: 1168.523
[11,     1] loss: 1140.610
[12,     1] loss: 1107.864
[13,     1] loss: 1069.208
[14,     1] loss: 1034.298
[15,     1] loss: 1056.857
[16,     1] loss: 1074.474
[17,     1] loss: 1034.460
[18,     1] loss: 1020.526
[19,     1] loss: 1021.162
[20,     1] loss: 1006.853
[21,     1] loss: 1023.500
[22,     1] loss: 1024.008
[23,     1] loss: 1038.256
[24,     1] loss: 991.441
[25,     1] loss: 974.266
[26,     1] loss: 986.520
[27,     1] loss: 971.805
[28,     1] loss: 950.628
[29,     1] loss: 942.571
[30,     1] loss: 944.954
[31,     1] loss: 898.696
[32,     1] loss: 937.806
[33,     1] loss: 942.451
[34,     1] loss: 922.059
[35,     1] loss: 919.852
[36,     1] loss: 899.540
[37,     1] loss: 889.423
[38,     1] loss: 873.865
[39,     1] loss: 901.927
[40,     1] loss: 884.320
[41,     1] loss: 892.437
[42,     1] loss: 819.578
[43,     1] loss: 853.339
[44,     1] loss: 843.405
[45,     1] loss: 825.609
[46,     1] loss: 805.892
[47,     1] loss: 929.251
[48,     1] loss: 785.418
[49,     1] loss: 850.336
[50,     1] loss: 831.176
[51,     1] loss: 780.181
[52,     1] loss: 764.652
[53,     1] loss: 749.857
[54,     1] loss: 828.972
[55,     1] loss: 754.701
[56,     1] loss: 767.300
[57,     1] loss: 800.346
[58,     1] loss: 725.708
[59,     1] loss: 743.230
[60,     1] loss: 772.924
[61,     1] loss: 683.543
[62,     1] loss: 682.896
[63,     1] loss: 665.699
[64,     1] loss: 734.111
[65,     1] loss: 681.412
[66,     1] loss: 642.099
[67,     1] loss: 642.391
[68,     1] loss: 616.103
[69,     1] loss: 650.526
[70,     1] loss: 690.211
[71,     1] loss: 609.094
Early stopping applied (best metric=0.7207937240600586)
Finished Training
Total time taken: 10.81522798538208
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.346
[2,     1] loss: 1233.656
[3,     1] loss: 1231.358
[4,     1] loss: 1230.041
[5,     1] loss: 1227.886
[6,     1] loss: 1215.185
[7,     1] loss: 1198.656
[8,     1] loss: 1173.098
[9,     1] loss: 1124.869
[10,     1] loss: 1121.807
[11,     1] loss: 1088.741
[12,     1] loss: 1049.939
[13,     1] loss: 1018.772
[14,     1] loss: 1029.835
[15,     1] loss: 1049.847
[16,     1] loss: 998.256
[17,     1] loss: 1025.023
[18,     1] loss: 1016.231
[19,     1] loss: 1022.958
[20,     1] loss: 1010.644
[21,     1] loss: 995.001
[22,     1] loss: 953.313
[23,     1] loss: 959.869
[24,     1] loss: 914.101
[25,     1] loss: 925.727
[26,     1] loss: 950.650
[27,     1] loss: 942.926
[28,     1] loss: 942.758
[29,     1] loss: 886.433
[30,     1] loss: 887.791
[31,     1] loss: 888.255
[32,     1] loss: 875.900
[33,     1] loss: 850.109
[34,     1] loss: 843.406
[35,     1] loss: 850.096
[36,     1] loss: 866.409
[37,     1] loss: 864.480
[38,     1] loss: 873.372
[39,     1] loss: 815.839
[40,     1] loss: 846.254
[41,     1] loss: 778.971
[42,     1] loss: 806.576
[43,     1] loss: 763.816
[44,     1] loss: 805.444
[45,     1] loss: 795.159
[46,     1] loss: 815.304
[47,     1] loss: 780.261
[48,     1] loss: 735.233
[49,     1] loss: 770.211
[50,     1] loss: 728.522
[51,     1] loss: 744.428
[52,     1] loss: 748.577
[53,     1] loss: 729.582
[54,     1] loss: 717.294
[55,     1] loss: 756.263
[56,     1] loss: 696.703
[57,     1] loss: 658.225
[58,     1] loss: 704.723
[59,     1] loss: 713.285
[60,     1] loss: 655.595
[61,     1] loss: 683.167
Early stopping applied (best metric=0.8140280842781067)
Finished Training
Total time taken: 9.185193538665771
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1230.434
[2,     1] loss: 1237.844
[3,     1] loss: 1232.378
[4,     1] loss: 1232.454
[5,     1] loss: 1228.129
[6,     1] loss: 1227.558
[7,     1] loss: 1232.777
[8,     1] loss: 1227.136
[9,     1] loss: 1215.631
[10,     1] loss: 1206.114
[11,     1] loss: 1186.984
[12,     1] loss: 1163.521
[13,     1] loss: 1136.202
[14,     1] loss: 1104.751
[15,     1] loss: 1090.927
[16,     1] loss: 1066.486
[17,     1] loss: 1055.820
[18,     1] loss: 1012.252
[19,     1] loss: 1066.805
[20,     1] loss: 1051.566
[21,     1] loss: 1097.267
[22,     1] loss: 972.350
[23,     1] loss: 1022.661
[24,     1] loss: 1040.712
[25,     1] loss: 1002.645
[26,     1] loss: 992.750
[27,     1] loss: 1001.048
[28,     1] loss: 979.185
[29,     1] loss: 979.611
[30,     1] loss: 936.409
[31,     1] loss: 925.075
[32,     1] loss: 996.369
[33,     1] loss: 903.502
[34,     1] loss: 914.633
[35,     1] loss: 909.072
[36,     1] loss: 944.384
[37,     1] loss: 902.601
[38,     1] loss: 884.913
[39,     1] loss: 918.378
[40,     1] loss: 870.536
[41,     1] loss: 884.369
[42,     1] loss: 897.788
[43,     1] loss: 840.377
[44,     1] loss: 827.526
[45,     1] loss: 832.317
[46,     1] loss: 800.090
[47,     1] loss: 804.756
[48,     1] loss: 797.901
[49,     1] loss: 748.955
[50,     1] loss: 776.322
[51,     1] loss: 780.307
[52,     1] loss: 772.714
[53,     1] loss: 768.863
[54,     1] loss: 811.818
[55,     1] loss: 719.082
[56,     1] loss: 700.436
[57,     1] loss: 718.625
[58,     1] loss: 698.293
Early stopping applied (best metric=0.7848647832870483)
Finished Training
Total time taken: 8.607182025909424
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1238.923
[2,     1] loss: 1234.777
[3,     1] loss: 1230.412
[4,     1] loss: 1227.576
[5,     1] loss: 1227.798
[6,     1] loss: 1217.897
[7,     1] loss: 1217.836
[8,     1] loss: 1193.967
[9,     1] loss: 1157.836
[10,     1] loss: 1114.309
[11,     1] loss: 1082.529
[12,     1] loss: 1067.260
[13,     1] loss: 1046.888
[14,     1] loss: 1020.300
[15,     1] loss: 1011.478
[16,     1] loss: 1001.015
[17,     1] loss: 1012.390
[18,     1] loss: 1037.285
[19,     1] loss: 992.091
[20,     1] loss: 966.667
[21,     1] loss: 958.892
[22,     1] loss: 1007.393
[23,     1] loss: 943.821
[24,     1] loss: 940.349
[25,     1] loss: 925.435
[26,     1] loss: 929.499
[27,     1] loss: 910.078
[28,     1] loss: 947.203
[29,     1] loss: 919.724
[30,     1] loss: 881.421
[31,     1] loss: 887.416
[32,     1] loss: 871.573
[33,     1] loss: 882.676
[34,     1] loss: 881.911
[35,     1] loss: 827.772
[36,     1] loss: 846.999
[37,     1] loss: 906.975
[38,     1] loss: 856.366
[39,     1] loss: 832.440
Early stopping applied (best metric=0.9721405506134033)
Finished Training
Total time taken: 5.375112533569336
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1239.249
[2,     1] loss: 1234.326
[3,     1] loss: 1231.618
[4,     1] loss: 1232.129
[5,     1] loss: 1230.514
[6,     1] loss: 1226.071
[7,     1] loss: 1217.628
[8,     1] loss: 1213.172
[9,     1] loss: 1193.016
[10,     1] loss: 1161.659
[11,     1] loss: 1127.003
[12,     1] loss: 1089.722
[13,     1] loss: 1114.665
[14,     1] loss: 1094.986
[15,     1] loss: 1057.692
[16,     1] loss: 1047.359
[17,     1] loss: 1020.231
[18,     1] loss: 1005.402
[19,     1] loss: 1001.824
[20,     1] loss: 995.874
[21,     1] loss: 983.715
[22,     1] loss: 991.024
[23,     1] loss: 986.408
[24,     1] loss: 963.239
[25,     1] loss: 949.437
[26,     1] loss: 931.619
[27,     1] loss: 951.536
[28,     1] loss: 922.934
[29,     1] loss: 910.983
[30,     1] loss: 927.417
[31,     1] loss: 942.334
[32,     1] loss: 900.336
[33,     1] loss: 917.359
[34,     1] loss: 918.410
[35,     1] loss: 912.894
[36,     1] loss: 876.513
[37,     1] loss: 904.758
[38,     1] loss: 825.632
Early stopping applied (best metric=0.922225832939148)
Finished Training
Total time taken: 5.175109624862671
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.440
[2,     1] loss: 1236.343
[3,     1] loss: 1235.446
[4,     1] loss: 1231.488
[5,     1] loss: 1229.912
[6,     1] loss: 1223.071
[7,     1] loss: 1215.934
[8,     1] loss: 1193.305
[9,     1] loss: 1178.908
[10,     1] loss: 1137.041
[11,     1] loss: 1130.233
[12,     1] loss: 1063.860
[13,     1] loss: 1066.106
[14,     1] loss: 1031.670
[15,     1] loss: 1048.601
[16,     1] loss: 1036.100
[17,     1] loss: 1021.373
[18,     1] loss: 1009.532
[19,     1] loss: 1001.658
[20,     1] loss: 996.080
[21,     1] loss: 961.947
[22,     1] loss: 996.896
[23,     1] loss: 967.889
[24,     1] loss: 964.670
[25,     1] loss: 967.107
[26,     1] loss: 968.087
[27,     1] loss: 922.365
[28,     1] loss: 954.390
[29,     1] loss: 882.374
[30,     1] loss: 913.791
[31,     1] loss: 890.021
[32,     1] loss: 945.740
[33,     1] loss: 878.776
[34,     1] loss: 884.326
[35,     1] loss: 873.037
[36,     1] loss: 889.626
[37,     1] loss: 875.112
[38,     1] loss: 854.785
[39,     1] loss: 851.809
[40,     1] loss: 824.378
[41,     1] loss: 832.623
[42,     1] loss: 864.554
[43,     1] loss: 812.163
[44,     1] loss: 814.947
[45,     1] loss: 767.685
[46,     1] loss: 762.345
[47,     1] loss: 758.517
[48,     1] loss: 780.991
[49,     1] loss: 722.856
[50,     1] loss: 764.811
[51,     1] loss: 763.246
[52,     1] loss: 788.773
[53,     1] loss: 738.801
Early stopping applied (best metric=0.8877029418945312)
Finished Training
Total time taken: 8.29717469215393
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.203
[2,     1] loss: 1229.323
[3,     1] loss: 1235.176
[4,     1] loss: 1225.242
[5,     1] loss: 1228.759
[6,     1] loss: 1213.493
[7,     1] loss: 1205.358
[8,     1] loss: 1190.305
[9,     1] loss: 1161.097
[10,     1] loss: 1125.829
[11,     1] loss: 1085.272
[12,     1] loss: 1081.037
[13,     1] loss: 1070.717
[14,     1] loss: 1058.598
[15,     1] loss: 1051.963
[16,     1] loss: 991.804
[17,     1] loss: 1046.532
[18,     1] loss: 996.278
[19,     1] loss: 1013.548
[20,     1] loss: 997.636
[21,     1] loss: 1009.736
[22,     1] loss: 1014.843
[23,     1] loss: 974.239
[24,     1] loss: 987.122
[25,     1] loss: 946.755
[26,     1] loss: 943.544
[27,     1] loss: 982.849
[28,     1] loss: 937.689
[29,     1] loss: 979.033
[30,     1] loss: 909.717
[31,     1] loss: 915.536
[32,     1] loss: 897.706
[33,     1] loss: 907.975
[34,     1] loss: 916.298
[35,     1] loss: 877.504
[36,     1] loss: 903.583
[37,     1] loss: 859.848
[38,     1] loss: 894.881
[39,     1] loss: 865.119
[40,     1] loss: 839.647
[41,     1] loss: 868.106
[42,     1] loss: 866.961
[43,     1] loss: 816.599
[44,     1] loss: 849.249
Early stopping applied (best metric=0.8061119318008423)
Finished Training
Total time taken: 7.534160375595093
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1235.564
[2,     1] loss: 1231.542
[3,     1] loss: 1230.849
[4,     1] loss: 1230.557
[5,     1] loss: 1227.917
[6,     1] loss: 1221.924
[7,     1] loss: 1215.519
[8,     1] loss: 1193.720
[9,     1] loss: 1187.928
[10,     1] loss: 1152.718
[11,     1] loss: 1115.487
[12,     1] loss: 1085.236
[13,     1] loss: 1021.716
[14,     1] loss: 1089.119
[15,     1] loss: 1006.825
[16,     1] loss: 984.300
[17,     1] loss: 1028.276
[18,     1] loss: 965.773
[19,     1] loss: 1004.539
[20,     1] loss: 1018.314
[21,     1] loss: 992.390
[22,     1] loss: 981.948
[23,     1] loss: 969.279
[24,     1] loss: 986.931
[25,     1] loss: 976.425
[26,     1] loss: 909.256
[27,     1] loss: 936.665
[28,     1] loss: 920.821
[29,     1] loss: 935.114
[30,     1] loss: 898.011
[31,     1] loss: 906.419
[32,     1] loss: 874.812
[33,     1] loss: 887.619
[34,     1] loss: 919.877
[35,     1] loss: 847.216
[36,     1] loss: 834.498
[37,     1] loss: 837.682
[38,     1] loss: 879.864
[39,     1] loss: 817.027
[40,     1] loss: 832.196
[41,     1] loss: 859.862
[42,     1] loss: 833.582
[43,     1] loss: 784.272
[44,     1] loss: 794.677
[45,     1] loss: 807.667
[46,     1] loss: 748.722
[47,     1] loss: 793.808
[48,     1] loss: 805.609
[49,     1] loss: 759.876
[50,     1] loss: 739.570
Early stopping applied (best metric=0.8640362620353699)
Finished Training
Total time taken: 7.738164186477661
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.248
[2,     1] loss: 1235.022
[3,     1] loss: 1234.107
[4,     1] loss: 1231.921
[5,     1] loss: 1231.218
[6,     1] loss: 1229.651
[7,     1] loss: 1229.316
[8,     1] loss: 1223.998
[9,     1] loss: 1217.970
[10,     1] loss: 1206.014
[11,     1] loss: 1184.305
[12,     1] loss: 1154.594
[13,     1] loss: 1119.403
[14,     1] loss: 1079.945
[15,     1] loss: 1069.699
[16,     1] loss: 1049.074
[17,     1] loss: 1054.135
[18,     1] loss: 1051.676
[19,     1] loss: 1005.203
[20,     1] loss: 1098.609
[21,     1] loss: 994.965
[22,     1] loss: 1019.210
[23,     1] loss: 1006.924
[24,     1] loss: 991.541
[25,     1] loss: 968.567
[26,     1] loss: 973.612
[27,     1] loss: 977.746
[28,     1] loss: 999.354
[29,     1] loss: 983.459
[30,     1] loss: 935.210
[31,     1] loss: 929.442
[32,     1] loss: 920.297
[33,     1] loss: 897.752
[34,     1] loss: 948.529
[35,     1] loss: 912.968
[36,     1] loss: 904.794
[37,     1] loss: 909.874
[38,     1] loss: 876.562
[39,     1] loss: 863.590
[40,     1] loss: 882.530
[41,     1] loss: 840.986
[42,     1] loss: 854.701
[43,     1] loss: 828.861
[44,     1] loss: 853.398
[45,     1] loss: 822.263
[46,     1] loss: 877.456
[47,     1] loss: 800.055
[48,     1] loss: 814.200
[49,     1] loss: 815.840
[50,     1] loss: 891.521
[51,     1] loss: 782.364
[52,     1] loss: 897.406
[53,     1] loss: 799.865
[54,     1] loss: 826.227
[55,     1] loss: 824.597
[56,     1] loss: 754.361
[57,     1] loss: 857.068
[58,     1] loss: 751.912
[59,     1] loss: 744.713
[60,     1] loss: 797.887
[61,     1] loss: 766.540
[62,     1] loss: 762.470
[63,     1] loss: 748.762
[64,     1] loss: 754.806
[65,     1] loss: 780.774
[66,     1] loss: 757.880
[67,     1] loss: 715.225
[68,     1] loss: 713.388
[69,     1] loss: 703.486
[70,     1] loss: 731.558
[71,     1] loss: 692.108
[72,     1] loss: 701.045
[73,     1] loss: 627.480
[74,     1] loss: 679.352
[75,     1] loss: 701.061
[76,     1] loss: 661.055
[77,     1] loss: 619.221
[78,     1] loss: 610.376
[79,     1] loss: 606.354
[80,     1] loss: 597.865
[81,     1] loss: 599.378
[82,     1] loss: 593.361
[83,     1] loss: 562.254
[84,     1] loss: 632.788
[85,     1] loss: 533.717
Early stopping applied (best metric=0.7247037887573242)
Finished Training
Total time taken: 13.128278017044067
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1236.408
[2,     1] loss: 1241.206
[3,     1] loss: 1234.430
[4,     1] loss: 1230.701
[5,     1] loss: 1226.234
[6,     1] loss: 1218.985
[7,     1] loss: 1199.894
[8,     1] loss: 1169.555
[9,     1] loss: 1136.771
[10,     1] loss: 1078.317
[11,     1] loss: 1046.778
[12,     1] loss: 1026.749
[13,     1] loss: 1026.155
[14,     1] loss: 1014.572
[15,     1] loss: 1054.508
[16,     1] loss: 978.465
[17,     1] loss: 1006.181
[18,     1] loss: 947.012
[19,     1] loss: 989.676
[20,     1] loss: 1005.542
[21,     1] loss: 998.539
[22,     1] loss: 973.105
[23,     1] loss: 929.200
[24,     1] loss: 966.374
[25,     1] loss: 992.594
[26,     1] loss: 917.889
[27,     1] loss: 925.954
[28,     1] loss: 932.659
[29,     1] loss: 920.883
[30,     1] loss: 904.630
[31,     1] loss: 953.871
[32,     1] loss: 874.996
[33,     1] loss: 916.693
[34,     1] loss: 857.299
[35,     1] loss: 843.095
[36,     1] loss: 851.992
[37,     1] loss: 894.986
[38,     1] loss: 890.017
[39,     1] loss: 839.665
[40,     1] loss: 869.571
[41,     1] loss: 830.829
[42,     1] loss: 837.888
[43,     1] loss: 860.326
[44,     1] loss: 797.952
[45,     1] loss: 826.868
[46,     1] loss: 759.612
[47,     1] loss: 792.626
[48,     1] loss: 821.032
[49,     1] loss: 838.328
[50,     1] loss: 704.520
[51,     1] loss: 734.199
[52,     1] loss: 754.490
[53,     1] loss: 747.856
[54,     1] loss: 745.076
[55,     1] loss: 730.434
[56,     1] loss: 698.573
[57,     1] loss: 792.665
[58,     1] loss: 706.082
[59,     1] loss: 781.622
[60,     1] loss: 725.848
[61,     1] loss: 698.747
Early stopping applied (best metric=0.7661360502243042)
Finished Training
Total time taken: 9.415197849273682
{'Hydroxylation-K Validation Accuracy': 0.7732269503546099, 'Hydroxylation-K Validation Sensitivity': 0.6733333333333333, 'Hydroxylation-K Validation Specificity': 0.7982456140350878, 'Hydroxylation-K Validation Precision': 0.4706986294292796, 'Hydroxylation-K AUC ROC': 0.7909551656920079, 'Hydroxylation-K AUC PR': 0.5790774051256025, 'Hydroxylation-K MCC': 0.4210671022915933, 'Hydroxylation-K F1': 0.5504372961762688, 'Validation Loss (Hydroxylation-K)': 0.43989386955897014, 'Hydroxylation-P Validation Accuracy': 0.7859074327868297, 'Hydroxylation-P Validation Sensitivity': 0.7496825396825397, 'Hydroxylation-P Validation Specificity': 0.793675495037159, 'Hydroxylation-P Validation Precision': 0.44885979369449386, 'Hydroxylation-P AUC ROC': 0.8481234724923936, 'Hydroxylation-P AUC PR': 0.5816947475501583, 'Hydroxylation-P MCC': 0.4575093496284093, 'Hydroxylation-P F1': 0.5560086202278721, 'Validation Loss (Hydroxylation-P)': 0.3774054686228434, 'Validation Loss (total)': 0.8172993381818136, 'TimeToTrain': 9.047391128540038}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035821941597717908,
 'learning_rate_Hydroxylation-K': 0.00108977165703082,
 'learning_rate_Hydroxylation-P': 0.001910404140154923,
 'log_base': 2.933742080086153,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1697100433,
 'sample_weights': [1.5357059582887203, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7525423803843494,
 'weight_decay_Hydroxylation-K': 0.0696066231361927,
 'weight_decay_Hydroxylation-P': 1.964217313713989}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.507
[2,     1] loss: 1237.983
[3,     1] loss: 1233.673
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003507760297032995,
 'learning_rate_Hydroxylation-K': 0.006083315034239337,
 'learning_rate_Hydroxylation-P': 0.0012345291058828696,
 'log_base': 2.7788799110823543,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2506157989,
 'sample_weights': [1.5511252253049754, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.342058480669174,
 'weight_decay_Hydroxylation-K': 5.710695396371026,
 'weight_decay_Hydroxylation-P': 5.782051633994625}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1256.264
[2,     1] loss: 1252.310
[3,     1] loss: 1253.900
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011100030476009195,
 'learning_rate_Hydroxylation-K': 0.004315398205686382,
 'learning_rate_Hydroxylation-P': 0.00973473065920269,
 'log_base': 2.9797042053505636,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3911981025,
 'sample_weights': [1.6334293992135083, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2710343521500533,
 'weight_decay_Hydroxylation-K': 0.27743302857341723,
 'weight_decay_Hydroxylation-P': 2.3306211141571342}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.995
[2,     1] loss: 1234.433
[3,     1] loss: 1229.542
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0029455903616623625,
 'learning_rate_Hydroxylation-K': 0.009864203173517565,
 'learning_rate_Hydroxylation-P': 0.0009603710932666019,
 'log_base': 2.9984792569816836,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 514156243,
 'sample_weights': [1.5290404799003952, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.696481329768629,
 'weight_decay_Hydroxylation-K': 4.845164211517064,
 'weight_decay_Hydroxylation-P': 4.295062164892162}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1230.102
[2,     1] loss: 1228.765
[3,     1] loss: 1225.613
[4,     1] loss: 1228.831
[5,     1] loss: 1219.688
[6,     1] loss: 1198.875
[7,     1] loss: 1165.043
[8,     1] loss: 1122.618
[9,     1] loss: 1079.642
[10,     1] loss: 1039.974
[11,     1] loss: 998.837
[12,     1] loss: 999.976
[13,     1] loss: 950.640
[14,     1] loss: 1133.788
[15,     1] loss: 1005.923
[16,     1] loss: 1054.526
[17,     1] loss: 944.693
[18,     1] loss: 1023.368
[19,     1] loss: 996.093
[20,     1] loss: 950.434
[21,     1] loss: 970.315
[22,     1] loss: 954.875
[23,     1] loss: 983.276
[24,     1] loss: 952.881
[25,     1] loss: 948.535
[26,     1] loss: 953.093
[27,     1] loss: 926.223
[28,     1] loss: 895.109
[29,     1] loss: 959.536
[30,     1] loss: 911.844
[31,     1] loss: 912.693
[32,     1] loss: 888.423
[33,     1] loss: 896.904
[34,     1] loss: 917.493
[35,     1] loss: 849.043
[36,     1] loss: 860.757
[37,     1] loss: 886.806
[38,     1] loss: 835.728
[39,     1] loss: 873.116
[40,     1] loss: 855.385
[41,     1] loss: 838.561
[42,     1] loss: 792.297
[43,     1] loss: 804.641
[44,     1] loss: 845.482
[45,     1] loss: 851.923
[46,     1] loss: 771.807
[47,     1] loss: 807.581
[48,     1] loss: 781.000
[49,     1] loss: 744.024
[50,     1] loss: 767.601
[51,     1] loss: 757.271
[52,     1] loss: 765.784
[53,     1] loss: 746.547
[54,     1] loss: 741.056
[55,     1] loss: 895.288
[56,     1] loss: 1116.177
[57,     1] loss: 788.699
[58,     1] loss: 872.999
[59,     1] loss: 921.773
[60,     1] loss: 879.333
[61,     1] loss: 827.660
[62,     1] loss: 886.649
[63,     1] loss: 895.220
[64,     1] loss: 843.543
[65,     1] loss: 773.535
[66,     1] loss: 809.405
[67,     1] loss: 858.611
[68,     1] loss: 722.994
[69,     1] loss: 758.473
[70,     1] loss: 773.913
[71,     1] loss: 727.102
[72,     1] loss: 737.296
[73,     1] loss: 734.097
Early stopping applied (best metric=0.7708628177642822)
Finished Training
Total time taken: 12.192255735397339
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1231.393
[2,     1] loss: 1227.339
[3,     1] loss: 1234.024
[4,     1] loss: 1224.265
[5,     1] loss: 1210.641
[6,     1] loss: 1180.430
[7,     1] loss: 1129.397
[8,     1] loss: 1101.231
[9,     1] loss: 1080.069
[10,     1] loss: 1017.809
[11,     1] loss: 1113.557
[12,     1] loss: 1006.883
[13,     1] loss: 1033.755
[14,     1] loss: 997.458
[15,     1] loss: 968.770
[16,     1] loss: 984.006
[17,     1] loss: 978.433
[18,     1] loss: 965.167
[19,     1] loss: 967.680
[20,     1] loss: 936.019
[21,     1] loss: 955.595
[22,     1] loss: 952.351
[23,     1] loss: 952.825
[24,     1] loss: 916.160
[25,     1] loss: 903.538
[26,     1] loss: 919.873
[27,     1] loss: 886.401
[28,     1] loss: 852.882
[29,     1] loss: 879.005
[30,     1] loss: 893.978
[31,     1] loss: 882.955
[32,     1] loss: 885.775
[33,     1] loss: 881.783
[34,     1] loss: 844.128
[35,     1] loss: 847.351
[36,     1] loss: 845.889
[37,     1] loss: 832.718
[38,     1] loss: 790.504
[39,     1] loss: 781.837
[40,     1] loss: 788.062
[41,     1] loss: 808.922
[42,     1] loss: 768.735
[43,     1] loss: 774.082
[44,     1] loss: 746.274
[45,     1] loss: 682.044
[46,     1] loss: 731.335
[47,     1] loss: 786.150
[48,     1] loss: 1037.513
[49,     1] loss: 915.793
[50,     1] loss: 762.551
[51,     1] loss: 825.177
[52,     1] loss: 846.581
[53,     1] loss: 747.867
[54,     1] loss: 791.362
[55,     1] loss: 767.412
[56,     1] loss: 754.195
[57,     1] loss: 742.652
[58,     1] loss: 738.808
Early stopping applied (best metric=0.8824079036712646)
Finished Training
Total time taken: 7.938167333602905
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.801
[2,     1] loss: 1227.951
[3,     1] loss: 1229.517
[4,     1] loss: 1230.974
[5,     1] loss: 1224.133
[6,     1] loss: 1225.672
[7,     1] loss: 1216.961
[8,     1] loss: 1204.346
[9,     1] loss: 1171.966
[10,     1] loss: 1155.368
[11,     1] loss: 1104.741
[12,     1] loss: 1079.892
[13,     1] loss: 1051.717
[14,     1] loss: 1046.570
[15,     1] loss: 1035.073
[16,     1] loss: 994.553
[17,     1] loss: 1037.714
[18,     1] loss: 993.126
[19,     1] loss: 968.766
[20,     1] loss: 949.289
[21,     1] loss: 963.005
[22,     1] loss: 961.113
[23,     1] loss: 930.555
[24,     1] loss: 954.711
[25,     1] loss: 934.105
[26,     1] loss: 898.781
[27,     1] loss: 892.131
[28,     1] loss: 889.914
[29,     1] loss: 849.638
[30,     1] loss: 900.770
[31,     1] loss: 926.259
[32,     1] loss: 928.977
[33,     1] loss: 839.263
[34,     1] loss: 883.787
[35,     1] loss: 822.993
[36,     1] loss: 862.906
[37,     1] loss: 855.500
[38,     1] loss: 816.904
[39,     1] loss: 773.710
[40,     1] loss: 821.912
[41,     1] loss: 891.691
[42,     1] loss: 778.580
[43,     1] loss: 808.397
[44,     1] loss: 858.048
[45,     1] loss: 771.075
[46,     1] loss: 805.799
[47,     1] loss: 744.932
[48,     1] loss: 791.946
[49,     1] loss: 793.442
[50,     1] loss: 731.847
[51,     1] loss: 708.083
[52,     1] loss: 676.945
[53,     1] loss: 683.341
[54,     1] loss: 773.163
[55,     1] loss: 728.878
[56,     1] loss: 667.602
[57,     1] loss: 753.074
Early stopping applied (best metric=0.8139669895172119)
Finished Training
Total time taken: 9.818208456039429
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.663
[2,     1] loss: 1230.701
[3,     1] loss: 1226.510
[4,     1] loss: 1230.325
[5,     1] loss: 1225.448
[6,     1] loss: 1216.047
[7,     1] loss: 1197.847
[8,     1] loss: 1172.379
[9,     1] loss: 1129.747
[10,     1] loss: 1090.162
[11,     1] loss: 1029.455
[12,     1] loss: 1011.556
[13,     1] loss: 1006.311
[14,     1] loss: 989.753
[15,     1] loss: 1001.260
[16,     1] loss: 945.112
[17,     1] loss: 955.652
[18,     1] loss: 939.962
[19,     1] loss: 975.644
[20,     1] loss: 1008.494
[21,     1] loss: 921.005
[22,     1] loss: 944.102
[23,     1] loss: 917.655
[24,     1] loss: 932.713
[25,     1] loss: 926.872
[26,     1] loss: 840.093
[27,     1] loss: 851.992
[28,     1] loss: 876.146
[29,     1] loss: 828.168
[30,     1] loss: 857.788
[31,     1] loss: 855.571
[32,     1] loss: 840.032
[33,     1] loss: 850.284
[34,     1] loss: 806.443
[35,     1] loss: 849.379
[36,     1] loss: 836.732
[37,     1] loss: 790.606
[38,     1] loss: 774.509
[39,     1] loss: 812.625
[40,     1] loss: 780.346
[41,     1] loss: 837.169
[42,     1] loss: 779.391
[43,     1] loss: 766.732
[44,     1] loss: 803.813
[45,     1] loss: 717.163
[46,     1] loss: 708.232
[47,     1] loss: 690.252
[48,     1] loss: 728.053
[49,     1] loss: 734.564
[50,     1] loss: 780.308
[51,     1] loss: 722.137
[52,     1] loss: 698.471
[53,     1] loss: 686.096
[54,     1] loss: 655.224
[55,     1] loss: 661.858
[56,     1] loss: 700.544
[57,     1] loss: 627.839
[58,     1] loss: 643.144
[59,     1] loss: 705.476
[60,     1] loss: 853.842
[61,     1] loss: 981.228
[62,     1] loss: 670.679
[63,     1] loss: 783.904
[64,     1] loss: 782.526
[65,     1] loss: 759.954
[66,     1] loss: 778.367
[67,     1] loss: 802.860
[68,     1] loss: 745.155
[69,     1] loss: 685.195
[70,     1] loss: 717.727
[71,     1] loss: 788.042
Early stopping applied (best metric=0.8804457783699036)
Finished Training
Total time taken: 10.304214477539062
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1232.449
[2,     1] loss: 1229.011
[3,     1] loss: 1226.765
[4,     1] loss: 1220.761
[5,     1] loss: 1214.679
[6,     1] loss: 1186.526
[7,     1] loss: 1137.248
[8,     1] loss: 1136.628
[9,     1] loss: 1090.415
[10,     1] loss: 1023.998
[11,     1] loss: 1027.001
[12,     1] loss: 1021.701
[13,     1] loss: 1010.317
[14,     1] loss: 1036.964
[15,     1] loss: 990.269
[16,     1] loss: 1001.365
[17,     1] loss: 960.985
[18,     1] loss: 989.011
[19,     1] loss: 991.154
[20,     1] loss: 1003.740
[21,     1] loss: 979.491
[22,     1] loss: 955.624
[23,     1] loss: 947.690
[24,     1] loss: 935.808
[25,     1] loss: 913.903
[26,     1] loss: 915.714
[27,     1] loss: 897.784
[28,     1] loss: 930.066
[29,     1] loss: 866.714
[30,     1] loss: 856.573
[31,     1] loss: 915.483
[32,     1] loss: 894.803
[33,     1] loss: 883.813
[34,     1] loss: 899.503
[35,     1] loss: 846.109
[36,     1] loss: 870.874
[37,     1] loss: 807.181
[38,     1] loss: 845.729
[39,     1] loss: 805.193
[40,     1] loss: 810.364
[41,     1] loss: 835.637
[42,     1] loss: 795.788
[43,     1] loss: 862.265
[44,     1] loss: 812.310
[45,     1] loss: 794.300
[46,     1] loss: 800.708
[47,     1] loss: 812.549
[48,     1] loss: 791.026
[49,     1] loss: 733.390
[50,     1] loss: 724.627
[51,     1] loss: 721.414
[52,     1] loss: 698.199
[53,     1] loss: 780.644
[54,     1] loss: 914.804
[55,     1] loss: 690.127
[56,     1] loss: 859.198
[57,     1] loss: 746.983
[58,     1] loss: 777.067
[59,     1] loss: 768.307
[60,     1] loss: 711.139
[61,     1] loss: 805.900
[62,     1] loss: 689.941
[63,     1] loss: 691.816
[64,     1] loss: 640.977
[65,     1] loss: 691.365
[66,     1] loss: 589.420
[67,     1] loss: 676.786
[68,     1] loss: 739.044
[69,     1] loss: 724.809
[70,     1] loss: 652.515
[71,     1] loss: 762.947
[72,     1] loss: 623.100
[73,     1] loss: 680.047
[74,     1] loss: 648.520
[75,     1] loss: 692.775
[76,     1] loss: 614.273
[77,     1] loss: 567.781
[78,     1] loss: 589.952
[79,     1] loss: 555.906
[80,     1] loss: 536.613
[81,     1] loss: 564.590
[82,     1] loss: 603.364
[83,     1] loss: 516.995
[84,     1] loss: 490.519
[85,     1] loss: 525.615
[86,     1] loss: 535.387
Early stopping applied (best metric=0.7853552103042603)
Finished Training
Total time taken: 12.565263748168945
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1228.062
[2,     1] loss: 1230.709
[3,     1] loss: 1227.829
[4,     1] loss: 1223.101
[5,     1] loss: 1229.645
[6,     1] loss: 1220.036
[7,     1] loss: 1206.813
[8,     1] loss: 1184.018
[9,     1] loss: 1153.622
[10,     1] loss: 1097.126
[11,     1] loss: 1068.263
[12,     1] loss: 1059.495
[13,     1] loss: 1070.191
[14,     1] loss: 1053.586
[15,     1] loss: 1022.834
[16,     1] loss: 1024.442
[17,     1] loss: 996.916
[18,     1] loss: 1033.936
[19,     1] loss: 981.583
[20,     1] loss: 1015.013
[21,     1] loss: 1002.894
[22,     1] loss: 1000.500
[23,     1] loss: 940.018
[24,     1] loss: 963.433
[25,     1] loss: 956.038
[26,     1] loss: 892.769
[27,     1] loss: 925.231
[28,     1] loss: 926.164
[29,     1] loss: 912.300
[30,     1] loss: 911.848
[31,     1] loss: 867.710
[32,     1] loss: 913.031
[33,     1] loss: 875.847
[34,     1] loss: 888.738
[35,     1] loss: 885.854
[36,     1] loss: 863.369
[37,     1] loss: 807.661
[38,     1] loss: 848.798
[39,     1] loss: 951.053
[40,     1] loss: 799.805
[41,     1] loss: 803.729
[42,     1] loss: 833.144
[43,     1] loss: 776.365
[44,     1] loss: 884.508
[45,     1] loss: 760.203
[46,     1] loss: 826.707
[47,     1] loss: 827.083
[48,     1] loss: 760.897
[49,     1] loss: 759.529
[50,     1] loss: 772.968
[51,     1] loss: 828.382
[52,     1] loss: 722.049
[53,     1] loss: 852.482
[54,     1] loss: 684.748
[55,     1] loss: 835.167
[56,     1] loss: 712.116
[57,     1] loss: 783.459
[58,     1] loss: 732.317
[59,     1] loss: 778.443
[60,     1] loss: 695.166
[61,     1] loss: 708.402
[62,     1] loss: 674.449
[63,     1] loss: 705.536
[64,     1] loss: 679.751
[65,     1] loss: 659.042
[66,     1] loss: 658.616
[67,     1] loss: 620.935
[68,     1] loss: 612.260
[69,     1] loss: 643.379
[70,     1] loss: 623.577
[71,     1] loss: 629.364
[72,     1] loss: 628.424
[73,     1] loss: 629.327
[74,     1] loss: 731.389
[75,     1] loss: 851.432
[76,     1] loss: 636.526
[77,     1] loss: 812.898
[78,     1] loss: 655.200
[79,     1] loss: 785.009
[80,     1] loss: 706.043
[81,     1] loss: 666.089
[82,     1] loss: 698.217
[83,     1] loss: 646.505
[84,     1] loss: 727.703
[85,     1] loss: 647.429
[86,     1] loss: 699.887
[87,     1] loss: 606.981
[88,     1] loss: 698.435
[89,     1] loss: 587.248
[90,     1] loss: 623.842
[91,     1] loss: 574.637
[92,     1] loss: 574.464
[93,     1] loss: 571.646
[94,     1] loss: 603.316
[95,     1] loss: 536.999
[96,     1] loss: 507.941
[97,     1] loss: 472.112
[98,     1] loss: 475.863
[99,     1] loss: 501.780
[100,     1] loss: 498.969
[101,     1] loss: 548.893
[102,     1] loss: 665.819
Early stopping applied (best metric=0.7452886700630188)
Finished Training
Total time taken: 15.99333930015564
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1237.480
[2,     1] loss: 1239.710
[3,     1] loss: 1228.717
[4,     1] loss: 1229.436
[5,     1] loss: 1228.573
[6,     1] loss: 1229.339
[7,     1] loss: 1227.426
[8,     1] loss: 1225.691
[9,     1] loss: 1224.580
[10,     1] loss: 1224.272
[11,     1] loss: 1217.999
[12,     1] loss: 1208.571
[13,     1] loss: 1187.170
[14,     1] loss: 1167.471
[15,     1] loss: 1152.146
[16,     1] loss: 1110.910
[17,     1] loss: 1112.328
[18,     1] loss: 1078.989
[19,     1] loss: 1113.003
[20,     1] loss: 1124.349
[21,     1] loss: 1086.968
[22,     1] loss: 1061.411
[23,     1] loss: 1025.436
[24,     1] loss: 1045.270
[25,     1] loss: 1036.599
[26,     1] loss: 984.953
[27,     1] loss: 1003.537
[28,     1] loss: 1052.584
[29,     1] loss: 981.750
[30,     1] loss: 984.710
[31,     1] loss: 934.617
[32,     1] loss: 942.090
[33,     1] loss: 919.271
[34,     1] loss: 957.661
[35,     1] loss: 945.108
[36,     1] loss: 864.508
[37,     1] loss: 875.187
[38,     1] loss: 890.131
[39,     1] loss: 785.601
[40,     1] loss: 833.581
[41,     1] loss: 834.243
[42,     1] loss: 809.723
[43,     1] loss: 997.797
[44,     1] loss: 1097.264
[45,     1] loss: 811.018
[46,     1] loss: 899.337
[47,     1] loss: 866.561
[48,     1] loss: 821.551
[49,     1] loss: 826.388
[50,     1] loss: 866.355
[51,     1] loss: 806.858
[52,     1] loss: 836.604
[53,     1] loss: 821.425
[54,     1] loss: 784.724
[55,     1] loss: 793.654
[56,     1] loss: 736.540
[57,     1] loss: 764.289
[58,     1] loss: 750.163
[59,     1] loss: 794.091
[60,     1] loss: 709.817
Early stopping applied (best metric=0.7612267732620239)
Finished Training
Total time taken: 9.410199642181396
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.092
[2,     1] loss: 1229.003
[3,     1] loss: 1227.119
[4,     1] loss: 1226.166
[5,     1] loss: 1227.305
[6,     1] loss: 1209.143
[7,     1] loss: 1190.885
[8,     1] loss: 1156.574
[9,     1] loss: 1153.447
[10,     1] loss: 1082.682
[11,     1] loss: 1120.429
[12,     1] loss: 1094.124
[13,     1] loss: 1068.377
[14,     1] loss: 1046.187
[15,     1] loss: 1002.305
[16,     1] loss: 980.456
[17,     1] loss: 988.088
[18,     1] loss: 961.436
[19,     1] loss: 998.732
[20,     1] loss: 937.133
[21,     1] loss: 932.936
[22,     1] loss: 950.777
[23,     1] loss: 992.588
[24,     1] loss: 923.781
[25,     1] loss: 1004.920
[26,     1] loss: 907.447
[27,     1] loss: 977.855
[28,     1] loss: 908.143
[29,     1] loss: 922.186
[30,     1] loss: 938.721
[31,     1] loss: 848.755
[32,     1] loss: 915.418
[33,     1] loss: 874.556
[34,     1] loss: 874.244
[35,     1] loss: 871.211
[36,     1] loss: 876.469
[37,     1] loss: 826.773
[38,     1] loss: 868.401
[39,     1] loss: 790.899
[40,     1] loss: 844.915
[41,     1] loss: 788.310
[42,     1] loss: 762.151
[43,     1] loss: 771.143
[44,     1] loss: 794.168
[45,     1] loss: 754.147
[46,     1] loss: 811.484
[47,     1] loss: 942.332
[48,     1] loss: 981.552
[49,     1] loss: 808.727
[50,     1] loss: 835.697
[51,     1] loss: 881.976
[52,     1] loss: 836.198
[53,     1] loss: 821.104
[54,     1] loss: 818.776
[55,     1] loss: 734.640
[56,     1] loss: 769.544
[57,     1] loss: 783.458
[58,     1] loss: 755.274
[59,     1] loss: 732.290
[60,     1] loss: 694.607
[61,     1] loss: 724.378
[62,     1] loss: 667.744
[63,     1] loss: 673.913
[64,     1] loss: 645.091
Early stopping applied (best metric=0.8659079074859619)
Finished Training
Total time taken: 10.615224838256836
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1231.225
[2,     1] loss: 1230.152
[3,     1] loss: 1229.734
[4,     1] loss: 1228.689
[5,     1] loss: 1221.963
[6,     1] loss: 1220.879
[7,     1] loss: 1209.275
[8,     1] loss: 1202.643
[9,     1] loss: 1182.698
[10,     1] loss: 1150.690
[11,     1] loss: 1121.801
[12,     1] loss: 1085.072
[13,     1] loss: 1061.411
[14,     1] loss: 1057.583
[15,     1] loss: 1064.042
[16,     1] loss: 996.900
[17,     1] loss: 1100.786
[18,     1] loss: 996.681
[19,     1] loss: 1011.366
[20,     1] loss: 1026.946
[21,     1] loss: 981.017
[22,     1] loss: 1007.291
[23,     1] loss: 950.040
[24,     1] loss: 983.445
[25,     1] loss: 960.425
[26,     1] loss: 958.121
[27,     1] loss: 937.656
[28,     1] loss: 930.455
[29,     1] loss: 922.456
[30,     1] loss: 941.347
[31,     1] loss: 903.205
[32,     1] loss: 933.976
[33,     1] loss: 889.091
[34,     1] loss: 886.314
[35,     1] loss: 872.540
[36,     1] loss: 865.668
[37,     1] loss: 845.855
[38,     1] loss: 833.044
[39,     1] loss: 757.822
[40,     1] loss: 810.007
[41,     1] loss: 802.588
[42,     1] loss: 809.207
[43,     1] loss: 766.933
[44,     1] loss: 842.207
[45,     1] loss: 779.501
[46,     1] loss: 748.493
[47,     1] loss: 761.597
[48,     1] loss: 723.840
[49,     1] loss: 727.759
[50,     1] loss: 720.374
[51,     1] loss: 693.301
[52,     1] loss: 675.930
[53,     1] loss: 690.734
[54,     1] loss: 669.308
[55,     1] loss: 710.619
[56,     1] loss: 881.850
[57,     1] loss: 1115.028
[58,     1] loss: 726.469
[59,     1] loss: 848.209
[60,     1] loss: 834.941
[61,     1] loss: 803.689
[62,     1] loss: 772.609
[63,     1] loss: 808.779
Early stopping applied (best metric=0.7725598812103271)
Finished Training
Total time taken: 9.635202169418335
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1228.752
[2,     1] loss: 1265.537
[3,     1] loss: 1231.949
[4,     1] loss: 1229.888
[5,     1] loss: 1231.600
[6,     1] loss: 1229.567
[7,     1] loss: 1226.759
[8,     1] loss: 1224.434
[9,     1] loss: 1226.419
[10,     1] loss: 1213.565
[11,     1] loss: 1198.459
[12,     1] loss: 1177.432
[13,     1] loss: 1149.496
[14,     1] loss: 1128.119
[15,     1] loss: 1106.525
[16,     1] loss: 1103.663
[17,     1] loss: 1052.371
[18,     1] loss: 1098.095
[19,     1] loss: 1048.005
[20,     1] loss: 1069.509
[21,     1] loss: 996.098
[22,     1] loss: 1049.239
[23,     1] loss: 973.316
[24,     1] loss: 985.969
[25,     1] loss: 948.143
[26,     1] loss: 953.401
[27,     1] loss: 986.735
[28,     1] loss: 943.973
[29,     1] loss: 1019.588
[30,     1] loss: 905.571
[31,     1] loss: 907.089
[32,     1] loss: 903.691
[33,     1] loss: 861.019
[34,     1] loss: 874.624
[35,     1] loss: 894.352
[36,     1] loss: 874.122
[37,     1] loss: 863.982
[38,     1] loss: 939.284
[39,     1] loss: 902.924
[40,     1] loss: 872.988
[41,     1] loss: 935.223
[42,     1] loss: 888.130
[43,     1] loss: 856.901
[44,     1] loss: 799.524
[45,     1] loss: 834.257
[46,     1] loss: 868.706
[47,     1] loss: 868.948
[48,     1] loss: 784.383
[49,     1] loss: 853.698
[50,     1] loss: 775.621
[51,     1] loss: 788.144
[52,     1] loss: 814.544
[53,     1] loss: 763.841
[54,     1] loss: 803.375
[55,     1] loss: 797.677
[56,     1] loss: 745.701
[57,     1] loss: 806.875
[58,     1] loss: 760.440
[59,     1] loss: 720.771
[60,     1] loss: 788.908
[61,     1] loss: 818.793
[62,     1] loss: 790.589
[63,     1] loss: 777.264
[64,     1] loss: 751.466
[65,     1] loss: 712.095
[66,     1] loss: 773.373
[67,     1] loss: 636.646
[68,     1] loss: 712.120
[69,     1] loss: 666.432
[70,     1] loss: 761.641
[71,     1] loss: 761.395
[72,     1] loss: 657.169
[73,     1] loss: 722.664
[74,     1] loss: 671.499
[75,     1] loss: 659.173
[76,     1] loss: 671.164
[77,     1] loss: 616.248
[78,     1] loss: 640.586
[79,     1] loss: 571.301
[80,     1] loss: 601.601
[81,     1] loss: 695.696
[82,     1] loss: 864.511
[83,     1] loss: 840.263
[84,     1] loss: 635.947
[85,     1] loss: 748.978
[86,     1] loss: 657.202
[87,     1] loss: 700.115
[88,     1] loss: 656.184
[89,     1] loss: 636.184
[90,     1] loss: 613.918
[91,     1] loss: 643.849
[92,     1] loss: 569.864
[93,     1] loss: 587.145
[94,     1] loss: 599.655
[95,     1] loss: 603.953
[96,     1] loss: 567.257
[97,     1] loss: 590.347
[98,     1] loss: 572.596
[99,     1] loss: 507.858
[100,     1] loss: 547.618
[101,     1] loss: 581.668
[102,     1] loss: 509.210
[103,     1] loss: 538.204
[104,     1] loss: 589.201
[105,     1] loss: 544.754
[106,     1] loss: 504.983
[107,     1] loss: 501.975
[108,     1] loss: 490.669
[109,     1] loss: 530.815
[110,     1] loss: 513.735
[111,     1] loss: 495.384
[112,     1] loss: 548.630
[113,     1] loss: 852.956
Early stopping applied (best metric=0.7807331085205078)
Finished Training
Total time taken: 16.01333713531494
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.755
[2,     1] loss: 1228.700
[3,     1] loss: 1227.717
[4,     1] loss: 1228.194
[5,     1] loss: 1230.757
[6,     1] loss: 1229.968
[7,     1] loss: 1226.051
[8,     1] loss: 1221.947
[9,     1] loss: 1206.320
[10,     1] loss: 1180.798
[11,     1] loss: 1156.182
[12,     1] loss: 1118.711
[13,     1] loss: 1100.228
[14,     1] loss: 1081.323
[15,     1] loss: 1064.480
[16,     1] loss: 1037.118
[17,     1] loss: 1032.178
[18,     1] loss: 1016.719
[19,     1] loss: 1030.808
[20,     1] loss: 1008.026
[21,     1] loss: 985.886
[22,     1] loss: 1016.577
[23,     1] loss: 981.420
[24,     1] loss: 975.747
[25,     1] loss: 966.218
[26,     1] loss: 965.280
[27,     1] loss: 941.282
[28,     1] loss: 925.039
[29,     1] loss: 917.249
[30,     1] loss: 901.338
[31,     1] loss: 930.744
[32,     1] loss: 889.974
[33,     1] loss: 866.139
[34,     1] loss: 880.506
[35,     1] loss: 906.404
[36,     1] loss: 858.694
[37,     1] loss: 840.458
[38,     1] loss: 860.396
[39,     1] loss: 852.720
[40,     1] loss: 824.102
[41,     1] loss: 872.086
[42,     1] loss: 845.004
[43,     1] loss: 827.840
[44,     1] loss: 817.065
[45,     1] loss: 799.754
[46,     1] loss: 767.142
[47,     1] loss: 816.639
[48,     1] loss: 906.500
[49,     1] loss: 1040.140
[50,     1] loss: 771.290
[51,     1] loss: 928.884
[52,     1] loss: 839.098
[53,     1] loss: 839.308
[54,     1] loss: 903.248
[55,     1] loss: 820.997
[56,     1] loss: 795.725
[57,     1] loss: 829.065
[58,     1] loss: 825.415
[59,     1] loss: 752.672
[60,     1] loss: 835.578
[61,     1] loss: 756.818
[62,     1] loss: 738.867
[63,     1] loss: 809.369
[64,     1] loss: 733.681
[65,     1] loss: 772.389
[66,     1] loss: 759.544
[67,     1] loss: 715.052
[68,     1] loss: 772.480
[69,     1] loss: 700.384
[70,     1] loss: 750.418
[71,     1] loss: 690.684
[72,     1] loss: 694.067
[73,     1] loss: 708.746
[74,     1] loss: 658.113
[75,     1] loss: 636.784
[76,     1] loss: 690.659
[77,     1] loss: 611.817
[78,     1] loss: 585.863
[79,     1] loss: 630.737
[80,     1] loss: 641.837
[81,     1] loss: 560.473
[82,     1] loss: 577.390
[83,     1] loss: 747.687
Early stopping applied (best metric=0.8432793021202087)
Finished Training
Total time taken: 14.299300909042358
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.628
[2,     1] loss: 1230.964
[3,     1] loss: 1228.723
[4,     1] loss: 1225.840
[5,     1] loss: 1225.525
[6,     1] loss: 1221.268
[7,     1] loss: 1206.193
[8,     1] loss: 1181.337
[9,     1] loss: 1142.479
[10,     1] loss: 1094.297
[11,     1] loss: 1033.509
[12,     1] loss: 1010.505
[13,     1] loss: 985.894
[14,     1] loss: 1007.724
[15,     1] loss: 1031.987
[16,     1] loss: 1045.205
[17,     1] loss: 1019.765
[18,     1] loss: 999.311
[19,     1] loss: 1057.907
[20,     1] loss: 999.936
[21,     1] loss: 987.171
[22,     1] loss: 1036.190
[23,     1] loss: 987.011
[24,     1] loss: 956.594
[25,     1] loss: 990.532
[26,     1] loss: 947.304
[27,     1] loss: 982.001
[28,     1] loss: 921.365
[29,     1] loss: 926.302
[30,     1] loss: 952.595
[31,     1] loss: 927.810
[32,     1] loss: 919.626
[33,     1] loss: 892.241
[34,     1] loss: 881.653
[35,     1] loss: 858.272
[36,     1] loss: 922.229
[37,     1] loss: 865.621
[38,     1] loss: 865.422
[39,     1] loss: 836.609
[40,     1] loss: 822.475
[41,     1] loss: 846.046
[42,     1] loss: 810.758
[43,     1] loss: 854.473
[44,     1] loss: 800.957
[45,     1] loss: 849.707
[46,     1] loss: 813.764
[47,     1] loss: 846.682
[48,     1] loss: 783.149
[49,     1] loss: 777.472
[50,     1] loss: 804.620
[51,     1] loss: 951.559
[52,     1] loss: 819.338
[53,     1] loss: 779.879
[54,     1] loss: 797.381
[55,     1] loss: 790.126
[56,     1] loss: 723.628
[57,     1] loss: 746.696
[58,     1] loss: 671.191
[59,     1] loss: 757.256
[60,     1] loss: 734.493
[61,     1] loss: 771.323
[62,     1] loss: 701.172
[63,     1] loss: 685.901
[64,     1] loss: 801.577
[65,     1] loss: 702.565
[66,     1] loss: 787.884
[67,     1] loss: 676.409
[68,     1] loss: 664.805
[69,     1] loss: 622.278
[70,     1] loss: 692.905
[71,     1] loss: 603.257
[72,     1] loss: 578.392
[73,     1] loss: 631.769
[74,     1] loss: 658.552
[75,     1] loss: 571.897
[76,     1] loss: 550.597
[77,     1] loss: 570.671
[78,     1] loss: 572.546
[79,     1] loss: 554.373
[80,     1] loss: 522.462
[81,     1] loss: 552.908
[82,     1] loss: 491.499
[83,     1] loss: 487.398
[84,     1] loss: 516.171
Early stopping applied (best metric=0.8314623832702637)
Finished Training
Total time taken: 11.843251943588257
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.895
[2,     1] loss: 1231.107
[3,     1] loss: 1226.947
[4,     1] loss: 1228.258
[5,     1] loss: 1228.162
[6,     1] loss: 1226.591
[7,     1] loss: 1226.640
[8,     1] loss: 1223.627
[9,     1] loss: 1216.845
[10,     1] loss: 1212.341
[11,     1] loss: 1194.340
[12,     1] loss: 1174.475
[13,     1] loss: 1145.227
[14,     1] loss: 1116.655
[15,     1] loss: 1092.675
[16,     1] loss: 1047.257
[17,     1] loss: 1014.201
[18,     1] loss: 1015.486
[19,     1] loss: 1044.947
[20,     1] loss: 973.086
[21,     1] loss: 1070.938
[22,     1] loss: 1031.364
[23,     1] loss: 1017.296
[24,     1] loss: 1018.060
[25,     1] loss: 1014.033
[26,     1] loss: 975.685
[27,     1] loss: 983.033
[28,     1] loss: 1009.763
[29,     1] loss: 980.058
[30,     1] loss: 946.001
[31,     1] loss: 925.510
[32,     1] loss: 948.823
[33,     1] loss: 920.165
[34,     1] loss: 881.529
[35,     1] loss: 852.541
[36,     1] loss: 908.556
[37,     1] loss: 869.972
[38,     1] loss: 855.771
[39,     1] loss: 840.636
[40,     1] loss: 827.152
[41,     1] loss: 849.425
[42,     1] loss: 807.706
[43,     1] loss: 868.763
[44,     1] loss: 865.411
[45,     1] loss: 781.339
[46,     1] loss: 832.871
[47,     1] loss: 779.799
[48,     1] loss: 773.390
[49,     1] loss: 760.336
[50,     1] loss: 746.274
[51,     1] loss: 778.918
[52,     1] loss: 749.767
[53,     1] loss: 734.915
[54,     1] loss: 735.918
[55,     1] loss: 784.004
[56,     1] loss: 938.086
[57,     1] loss: 764.802
[58,     1] loss: 771.068
[59,     1] loss: 738.140
[60,     1] loss: 771.780
[61,     1] loss: 710.173
[62,     1] loss: 710.201
[63,     1] loss: 696.686
[64,     1] loss: 726.417
[65,     1] loss: 677.310
[66,     1] loss: 651.893
[67,     1] loss: 683.479
[68,     1] loss: 640.675
[69,     1] loss: 760.521
[70,     1] loss: 738.440
[71,     1] loss: 676.684
Early stopping applied (best metric=0.8192213773727417)
Finished Training
Total time taken: 11.647246837615967
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.543
[2,     1] loss: 1227.346
[3,     1] loss: 1227.113
[4,     1] loss: 1229.152
[5,     1] loss: 1217.480
[6,     1] loss: 1210.218
[7,     1] loss: 1180.421
[8,     1] loss: 1146.241
[9,     1] loss: 1135.054
[10,     1] loss: 1090.785
[11,     1] loss: 1061.706
[12,     1] loss: 1123.654
[13,     1] loss: 1088.286
[14,     1] loss: 1048.554
[15,     1] loss: 1009.308
[16,     1] loss: 1087.145
[17,     1] loss: 1008.846
[18,     1] loss: 997.860
[19,     1] loss: 999.905
[20,     1] loss: 1027.647
[21,     1] loss: 1002.579
[22,     1] loss: 1023.879
[23,     1] loss: 975.187
[24,     1] loss: 950.023
[25,     1] loss: 973.223
[26,     1] loss: 944.548
[27,     1] loss: 973.989
[28,     1] loss: 927.479
[29,     1] loss: 936.565
[30,     1] loss: 863.219
[31,     1] loss: 884.529
[32,     1] loss: 924.727
[33,     1] loss: 925.266
[34,     1] loss: 866.217
[35,     1] loss: 886.808
[36,     1] loss: 889.600
[37,     1] loss: 915.094
[38,     1] loss: 829.218
[39,     1] loss: 828.165
[40,     1] loss: 812.541
[41,     1] loss: 845.842
[42,     1] loss: 851.389
[43,     1] loss: 807.876
[44,     1] loss: 821.624
[45,     1] loss: 924.534
[46,     1] loss: 955.190
[47,     1] loss: 781.471
[48,     1] loss: 882.335
[49,     1] loss: 833.416
[50,     1] loss: 827.696
[51,     1] loss: 840.751
[52,     1] loss: 821.725
[53,     1] loss: 786.675
[54,     1] loss: 828.419
[55,     1] loss: 763.101
[56,     1] loss: 787.496
[57,     1] loss: 750.283
[58,     1] loss: 766.160
[59,     1] loss: 741.509
[60,     1] loss: 677.369
[61,     1] loss: 687.479
[62,     1] loss: 681.007
[63,     1] loss: 704.425
[64,     1] loss: 735.815
[65,     1] loss: 828.907
[66,     1] loss: 791.353
[67,     1] loss: 731.996
[68,     1] loss: 759.758
[69,     1] loss: 701.886
[70,     1] loss: 710.628
[71,     1] loss: 682.188
[72,     1] loss: 675.398
[73,     1] loss: 647.268
[74,     1] loss: 649.500
[75,     1] loss: 640.076
[76,     1] loss: 652.893
[77,     1] loss: 616.558
[78,     1] loss: 600.647
[79,     1] loss: 742.565
Early stopping applied (best metric=0.8526147603988647)
Finished Training
Total time taken: 12.875269412994385
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1242.180
[2,     1] loss: 1230.676
[3,     1] loss: 1234.722
[4,     1] loss: 1230.683
[5,     1] loss: 1225.689
[6,     1] loss: 1222.586
[7,     1] loss: 1213.421
[8,     1] loss: 1202.737
[9,     1] loss: 1171.592
[10,     1] loss: 1127.629
[11,     1] loss: 1109.303
[12,     1] loss: 1087.512
[13,     1] loss: 1077.152
[14,     1] loss: 1021.553
[15,     1] loss: 1026.643
[16,     1] loss: 1035.278
[17,     1] loss: 994.902
[18,     1] loss: 978.232
[19,     1] loss: 950.238
[20,     1] loss: 969.956
[21,     1] loss: 967.772
[22,     1] loss: 949.927
[23,     1] loss: 961.855
[24,     1] loss: 951.534
[25,     1] loss: 937.642
[26,     1] loss: 913.961
[27,     1] loss: 923.724
[28,     1] loss: 831.582
[29,     1] loss: 943.965
[30,     1] loss: 865.404
[31,     1] loss: 858.358
[32,     1] loss: 832.883
[33,     1] loss: 889.312
[34,     1] loss: 852.481
[35,     1] loss: 833.439
[36,     1] loss: 816.898
[37,     1] loss: 816.422
[38,     1] loss: 818.780
[39,     1] loss: 821.264
[40,     1] loss: 783.784
[41,     1] loss: 799.745
[42,     1] loss: 803.655
[43,     1] loss: 745.773
[44,     1] loss: 744.933
[45,     1] loss: 742.847
[46,     1] loss: 725.268
[47,     1] loss: 718.501
[48,     1] loss: 758.262
[49,     1] loss: 741.616
[50,     1] loss: 691.054
[51,     1] loss: 694.249
[52,     1] loss: 840.928
[53,     1] loss: 861.984
[54,     1] loss: 756.558
[55,     1] loss: 836.079
[56,     1] loss: 750.611
[57,     1] loss: 743.716
[58,     1] loss: 791.962
[59,     1] loss: 700.745
Early stopping applied (best metric=0.7975118160247803)
Finished Training
Total time taken: 8.923758268356323
{'Hydroxylation-K Validation Accuracy': 0.7591016548463357, 'Hydroxylation-K Validation Sensitivity': 0.6755555555555556, 'Hydroxylation-K Validation Specificity': 0.7807017543859649, 'Hydroxylation-K Validation Precision': 0.4421015955149082, 'Hydroxylation-K AUC ROC': 0.8001949317738791, 'Hydroxylation-K AUC PR': 0.5941263800444798, 'Hydroxylation-K MCC': 0.3977784617972419, 'Hydroxylation-K F1': 0.5303795807723843, 'Validation Loss (Hydroxylation-K)': 0.43849184513092043, 'Hydroxylation-P Validation Accuracy': 0.7939761095037478, 'Hydroxylation-P Validation Sensitivity': 0.7596825396825397, 'Hydroxylation-P Validation Specificity': 0.8013666517033269, 'Hydroxylation-P Validation Precision': 0.45688964884556715, 'Hydroxylation-P AUC ROC': 0.8492254927807823, 'Hydroxylation-P AUC PR': 0.5954162461283318, 'Hydroxylation-P MCC': 0.47123775311550276, 'Hydroxylation-P F1': 0.5683355401910531, 'Validation Loss (Hydroxylation-P)': 0.3750311295191447, 'Validation Loss (total)': 0.813522978623708, 'TimeToTrain': 11.604949347178142}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006053027183493629,
 'learning_rate_Hydroxylation-K': 0.007318791715283104,
 'learning_rate_Hydroxylation-P': 0.00296494559899093,
 'log_base': 1.956225624091279,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 207191479,
 'sample_weights': [1.5214220531761053, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.4399052102015877,
 'weight_decay_Hydroxylation-K': 2.283807160949789,
 'weight_decay_Hydroxylation-P': 8.403706018030189}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1435.272
[2,     1] loss: 1446.302
[3,     1] loss: 1442.154
[4,     1] loss: 1439.812
[5,     1] loss: 1429.280
[6,     1] loss: 1427.018
[7,     1] loss: 1429.104
[8,     1] loss: 1421.293
[9,     1] loss: 1407.139
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016427247548956596,
 'learning_rate_Hydroxylation-K': 0.006529515998481285,
 'learning_rate_Hydroxylation-P': 0.0009856729679152017,
 'log_base': 1.6783551940749422,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3425417520,
 'sample_weights': [2.48793005191139, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.65002824200966,
 'weight_decay_Hydroxylation-K': 5.922262358384836,
 'weight_decay_Hydroxylation-P': 2.461524368343121}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1587.802
[2,     1] loss: 1588.810
[3,     1] loss: 1584.533
[4,     1] loss: 1587.114
[5,     1] loss: 1590.911
[6,     1] loss: 1587.102
[7,     1] loss: 1586.630
[8,     1] loss: 1579.468
[9,     1] loss: 1577.907
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00555415976021717,
 'learning_rate_Hydroxylation-K': 0.007448024027082076,
 'learning_rate_Hydroxylation-P': 0.0006499440361282107,
 'log_base': 1.6761171015253362,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1950627650,
 'sample_weights': [3.224019243434894, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.905603983963113,
 'weight_decay_Hydroxylation-K': 8.099345654998515,
 'weight_decay_Hydroxylation-P': 5.232389738692643}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1596.417
[2,     1] loss: 1607.446
[3,     1] loss: 1592.902
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008347560951907319,
 'learning_rate_Hydroxylation-K': 0.004358678620555888,
 'learning_rate_Hydroxylation-P': 0.006061893188623355,
 'log_base': 1.4098716078853224,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1070086376,
 'sample_weights': [3.2323489196232935, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.971523723766446,
 'weight_decay_Hydroxylation-K': 1.9476926066811449,
 'weight_decay_Hydroxylation-P': 1.312610928102803}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1938.043
[2,     1] loss: 1934.642
[3,     1] loss: 1929.238
[4,     1] loss: 1932.585
[5,     1] loss: 1928.922
[6,     1] loss: 1929.588
[7,     1] loss: 1925.738
[8,     1] loss: 1930.541
[9,     1] loss: 1921.964
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003626433809028676,
 'learning_rate_Hydroxylation-K': 0.00020512057007354668,
 'learning_rate_Hydroxylation-P': 0.00372428405670047,
 'log_base': 2.4169878730273204,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3607766855,
 'sample_weights': [4.860115713037622, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.822997786930542,
 'weight_decay_Hydroxylation-K': 3.469303248206793,
 'weight_decay_Hydroxylation-P': 0.35933578029544705}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1304.947
[2,     1] loss: 1310.856
[3,     1] loss: 1311.787
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002291095885535861,
 'learning_rate_Hydroxylation-K': 0.0005344144979197857,
 'learning_rate_Hydroxylation-P': 0.0009559377880983509,
 'log_base': 2.7048935722533205,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 219788042,
 'sample_weights': [1.8916729417215887, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7517119446613447,
 'weight_decay_Hydroxylation-K': 7.681485609013116,
 'weight_decay_Hydroxylation-P': 2.846700696009721}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1263.059
[2,     1] loss: 1262.539
[3,     1] loss: 1262.443
[4,     1] loss: 1260.681
[5,     1] loss: 1258.320
[6,     1] loss: 1254.998
[7,     1] loss: 1244.767
[8,     1] loss: 1225.981
[9,     1] loss: 1199.124
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010706452694953963,
 'learning_rate_Hydroxylation-K': 0.009128318415373586,
 'learning_rate_Hydroxylation-P': 0.00675350318514085,
 'log_base': 1.3442398462717273,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2253488630,
 'sample_weights': [1.6777268116497253, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.018384948280566027,
 'weight_decay_Hydroxylation-K': 4.166281873903511,
 'weight_decay_Hydroxylation-P': 2.6359819656327317}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2095.445
[2,     1] loss: 2101.917
[3,     1] loss: 2099.579
[4,     1] loss: 2104.666
[5,     1] loss: 2094.107
[6,     1] loss: 2107.465
[7,     1] loss: 2097.879
[8,     1] loss: 2095.266
[9,     1] loss: 2092.745
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0054881926932411635,
 'learning_rate_Hydroxylation-K': 0.0038522870462415963,
 'learning_rate_Hydroxylation-P': 0.0033759815251590427,
 'log_base': 2.9187216398392337,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1740818283,
 'sample_weights': [5.6432768087728835, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.5713883499414263,
 'weight_decay_Hydroxylation-K': 3.996172875519977,
 'weight_decay_Hydroxylation-P': 0.3153186493927589}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.583
[2,     1] loss: 1236.877
[3,     1] loss: 1241.400
[4,     1] loss: 1230.813
[5,     1] loss: 1231.366
[6,     1] loss: 1197.480
[7,     1] loss: 1157.585
[8,     1] loss: 1099.464
[9,     1] loss: 1042.050
[10,     1] loss: 1066.606
[11,     1] loss: 1099.116
[12,     1] loss: 1028.487
[13,     1] loss: 1037.692
[14,     1] loss: 1034.134
[15,     1] loss: 991.349
[16,     1] loss: 1004.599
[17,     1] loss: 1023.181
[18,     1] loss: 1018.451
[19,     1] loss: 972.837
[20,     1] loss: 969.664
[21,     1] loss: 974.997
[22,     1] loss: 957.723
[23,     1] loss: 961.093
[24,     1] loss: 942.993
[25,     1] loss: 934.871
[26,     1] loss: 963.269
[27,     1] loss: 985.446
[28,     1] loss: 915.625
[29,     1] loss: 909.604
[30,     1] loss: 973.882
[31,     1] loss: 898.525
[32,     1] loss: 909.337
[33,     1] loss: 902.785
[34,     1] loss: 897.509
[35,     1] loss: 874.332
[36,     1] loss: 840.406
[37,     1] loss: 847.308
[38,     1] loss: 836.914
[39,     1] loss: 836.353
[40,     1] loss: 805.171
[41,     1] loss: 808.739
[42,     1] loss: 825.563
[43,     1] loss: 815.196
[44,     1] loss: 768.674
[45,     1] loss: 790.629
[46,     1] loss: 837.089
[47,     1] loss: 754.679
[48,     1] loss: 750.249
[49,     1] loss: 757.822
[50,     1] loss: 738.522
[51,     1] loss: 717.871
[52,     1] loss: 763.042
[53,     1] loss: 717.273
[54,     1] loss: 687.697
[55,     1] loss: 680.328
[56,     1] loss: 767.911
[57,     1] loss: 812.715
[58,     1] loss: 639.528
[59,     1] loss: 765.586
Early stopping applied (best metric=0.8159746527671814)
Finished Training
Total time taken: 9.709228754043579
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1238.280
[2,     1] loss: 1239.543
[3,     1] loss: 1237.816
[4,     1] loss: 1238.831
[5,     1] loss: 1233.189
[6,     1] loss: 1227.651
[7,     1] loss: 1215.826
[8,     1] loss: 1190.090
[9,     1] loss: 1150.792
[10,     1] loss: 1094.429
[11,     1] loss: 1109.579
[12,     1] loss: 1166.866
[13,     1] loss: 1058.032
[14,     1] loss: 1075.671
[15,     1] loss: 1009.307
[16,     1] loss: 1028.555
[17,     1] loss: 1047.136
[18,     1] loss: 1012.952
[19,     1] loss: 1021.505
[20,     1] loss: 986.322
[21,     1] loss: 1006.175
[22,     1] loss: 984.553
[23,     1] loss: 921.625
[24,     1] loss: 982.730
[25,     1] loss: 974.102
[26,     1] loss: 965.309
[27,     1] loss: 901.650
[28,     1] loss: 950.423
[29,     1] loss: 931.461
[30,     1] loss: 917.508
[31,     1] loss: 945.124
[32,     1] loss: 899.667
[33,     1] loss: 950.893
[34,     1] loss: 913.681
[35,     1] loss: 843.772
[36,     1] loss: 861.301
[37,     1] loss: 874.052
[38,     1] loss: 822.874
[39,     1] loss: 863.146
[40,     1] loss: 826.219
[41,     1] loss: 851.122
[42,     1] loss: 865.278
[43,     1] loss: 819.084
[44,     1] loss: 839.792
[45,     1] loss: 850.233
[46,     1] loss: 828.174
[47,     1] loss: 809.061
[48,     1] loss: 792.032
[49,     1] loss: 762.479
[50,     1] loss: 746.460
[51,     1] loss: 788.428
[52,     1] loss: 853.338
[53,     1] loss: 948.000
[54,     1] loss: 707.981
[55,     1] loss: 852.053
[56,     1] loss: 734.788
[57,     1] loss: 820.747
[58,     1] loss: 787.033
[59,     1] loss: 710.038
[60,     1] loss: 735.031
[61,     1] loss: 664.226
[62,     1] loss: 655.570
[63,     1] loss: 622.996
[64,     1] loss: 671.509
[65,     1] loss: 579.025
[66,     1] loss: 670.468
Early stopping applied (best metric=0.7910270690917969)
Finished Training
Total time taken: 8.920190572738647
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.061
[2,     1] loss: 1280.874
[3,     1] loss: 1238.888
[4,     1] loss: 1241.922
[5,     1] loss: 1238.974
[6,     1] loss: 1236.706
[7,     1] loss: 1239.095
[8,     1] loss: 1237.141
[9,     1] loss: 1239.157
[10,     1] loss: 1236.851
[11,     1] loss: 1235.378
[12,     1] loss: 1232.660
[13,     1] loss: 1232.688
[14,     1] loss: 1232.808
[15,     1] loss: 1231.246
[16,     1] loss: 1227.473
[17,     1] loss: 1218.277
[18,     1] loss: 1198.043
[19,     1] loss: 1181.429
[20,     1] loss: 1155.581
[21,     1] loss: 1112.699
[22,     1] loss: 1105.277
[23,     1] loss: 1065.801
[24,     1] loss: 1056.817
[25,     1] loss: 1056.451
[26,     1] loss: 1068.078
[27,     1] loss: 994.766
[28,     1] loss: 1034.581
[29,     1] loss: 995.450
[30,     1] loss: 987.513
[31,     1] loss: 984.568
[32,     1] loss: 1004.600
[33,     1] loss: 981.399
[34,     1] loss: 977.370
[35,     1] loss: 897.881
[36,     1] loss: 918.027
[37,     1] loss: 925.496
[38,     1] loss: 944.516
[39,     1] loss: 918.445
[40,     1] loss: 901.178
[41,     1] loss: 879.376
[42,     1] loss: 839.058
[43,     1] loss: 906.980
[44,     1] loss: 841.711
[45,     1] loss: 872.233
[46,     1] loss: 807.906
[47,     1] loss: 799.970
[48,     1] loss: 775.174
[49,     1] loss: 777.324
[50,     1] loss: 791.335
[51,     1] loss: 788.198
[52,     1] loss: 813.759
[53,     1] loss: 909.455
[54,     1] loss: 795.390
[55,     1] loss: 759.543
[56,     1] loss: 724.474
[57,     1] loss: 759.071
[58,     1] loss: 826.221
[59,     1] loss: 786.139
[60,     1] loss: 673.309
Early stopping applied (best metric=0.8320256471633911)
Finished Training
Total time taken: 9.440197706222534
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1235.363
[2,     1] loss: 1243.581
[3,     1] loss: 1238.320
[4,     1] loss: 1243.186
[5,     1] loss: 1237.160
[6,     1] loss: 1233.904
[7,     1] loss: 1235.291
[8,     1] loss: 1231.529
[9,     1] loss: 1223.647
[10,     1] loss: 1216.251
[11,     1] loss: 1202.421
[12,     1] loss: 1179.296
[13,     1] loss: 1160.218
[14,     1] loss: 1104.309
[15,     1] loss: 1099.774
[16,     1] loss: 1049.407
[17,     1] loss: 1077.298
[18,     1] loss: 1038.829
[19,     1] loss: 1028.334
[20,     1] loss: 995.873
[21,     1] loss: 1028.519
[22,     1] loss: 1075.846
[23,     1] loss: 996.936
[24,     1] loss: 1001.178
[25,     1] loss: 996.779
[26,     1] loss: 1004.606
[27,     1] loss: 980.694
[28,     1] loss: 985.222
[29,     1] loss: 961.625
[30,     1] loss: 989.948
[31,     1] loss: 982.571
[32,     1] loss: 956.326
[33,     1] loss: 915.730
[34,     1] loss: 921.530
[35,     1] loss: 911.234
[36,     1] loss: 966.488
[37,     1] loss: 865.619
[38,     1] loss: 885.236
[39,     1] loss: 897.075
[40,     1] loss: 872.359
[41,     1] loss: 852.860
[42,     1] loss: 829.017
[43,     1] loss: 820.251
[44,     1] loss: 867.962
[45,     1] loss: 915.587
[46,     1] loss: 824.770
[47,     1] loss: 817.595
[48,     1] loss: 814.571
[49,     1] loss: 795.367
[50,     1] loss: 820.959
[51,     1] loss: 801.595
[52,     1] loss: 814.040
[53,     1] loss: 750.040
[54,     1] loss: 780.069
[55,     1] loss: 754.417
[56,     1] loss: 737.435
[57,     1] loss: 709.152
[58,     1] loss: 694.408
[59,     1] loss: 714.505
[60,     1] loss: 716.598
Early stopping applied (best metric=0.8369792103767395)
Finished Training
Total time taken: 9.24019455909729
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1240.020
[2,     1] loss: 1245.128
[3,     1] loss: 1250.716
[4,     1] loss: 1238.828
[5,     1] loss: 1235.371
[6,     1] loss: 1237.046
[7,     1] loss: 1234.672
[8,     1] loss: 1220.707
[9,     1] loss: 1213.749
[10,     1] loss: 1171.220
[11,     1] loss: 1138.485
[12,     1] loss: 1098.117
[13,     1] loss: 1087.345
[14,     1] loss: 1049.896
[15,     1] loss: 1099.590
[16,     1] loss: 1060.817
[17,     1] loss: 1003.380
[18,     1] loss: 989.046
[19,     1] loss: 1018.285
[20,     1] loss: 994.424
[21,     1] loss: 990.415
[22,     1] loss: 976.497
[23,     1] loss: 1005.188
[24,     1] loss: 996.461
[25,     1] loss: 940.201
[26,     1] loss: 995.611
[27,     1] loss: 928.910
[28,     1] loss: 921.750
[29,     1] loss: 924.265
[30,     1] loss: 928.474
[31,     1] loss: 905.424
[32,     1] loss: 896.136
[33,     1] loss: 887.716
[34,     1] loss: 822.769
[35,     1] loss: 900.030
[36,     1] loss: 837.591
[37,     1] loss: 795.881
[38,     1] loss: 824.324
[39,     1] loss: 793.397
[40,     1] loss: 859.313
[41,     1] loss: 783.633
[42,     1] loss: 817.612
[43,     1] loss: 827.811
[44,     1] loss: 808.512
[45,     1] loss: 924.678
[46,     1] loss: 750.829
[47,     1] loss: 901.573
[48,     1] loss: 767.440
[49,     1] loss: 864.510
[50,     1] loss: 753.923
[51,     1] loss: 769.958
[52,     1] loss: 730.504
[53,     1] loss: 725.985
[54,     1] loss: 724.501
[55,     1] loss: 741.381
[56,     1] loss: 640.617
[57,     1] loss: 726.770
[58,     1] loss: 716.099
[59,     1] loss: 686.424
[60,     1] loss: 642.920
[61,     1] loss: 703.724
[62,     1] loss: 734.565
[63,     1] loss: 625.079
[64,     1] loss: 674.669
[65,     1] loss: 646.936
[66,     1] loss: 652.019
[67,     1] loss: 626.534
[68,     1] loss: 624.289
[69,     1] loss: 636.453
[70,     1] loss: 587.150
[71,     1] loss: 616.117
Early stopping applied (best metric=0.7429381608963013)
Finished Training
Total time taken: 10.683227777481079
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.991
[2,     1] loss: 1241.259
[3,     1] loss: 1241.590
[4,     1] loss: 1239.853
[5,     1] loss: 1237.247
[6,     1] loss: 1230.078
[7,     1] loss: 1229.416
[8,     1] loss: 1213.750
[9,     1] loss: 1175.153
[10,     1] loss: 1167.441
[11,     1] loss: 1119.706
[12,     1] loss: 1079.679
[13,     1] loss: 1124.461
[14,     1] loss: 1046.016
[15,     1] loss: 1059.250
[16,     1] loss: 1028.028
[17,     1] loss: 1056.821
[18,     1] loss: 1042.718
[19,     1] loss: 1021.333
[20,     1] loss: 1038.176
[21,     1] loss: 997.149
[22,     1] loss: 1013.460
[23,     1] loss: 1061.382
[24,     1] loss: 996.661
[25,     1] loss: 1028.499
[26,     1] loss: 952.890
[27,     1] loss: 965.912
[28,     1] loss: 944.150
[29,     1] loss: 936.636
[30,     1] loss: 945.405
[31,     1] loss: 924.467
[32,     1] loss: 898.963
[33,     1] loss: 876.202
[34,     1] loss: 890.986
[35,     1] loss: 873.495
[36,     1] loss: 845.072
[37,     1] loss: 837.296
[38,     1] loss: 838.554
[39,     1] loss: 869.573
[40,     1] loss: 864.205
[41,     1] loss: 807.454
[42,     1] loss: 822.392
[43,     1] loss: 834.811
[44,     1] loss: 929.680
[45,     1] loss: 868.418
[46,     1] loss: 793.438
[47,     1] loss: 813.801
[48,     1] loss: 772.984
[49,     1] loss: 778.819
[50,     1] loss: 750.140
[51,     1] loss: 743.206
[52,     1] loss: 728.245
[53,     1] loss: 730.923
[54,     1] loss: 706.589
[55,     1] loss: 659.776
[56,     1] loss: 700.785
[57,     1] loss: 644.877
[58,     1] loss: 695.343
[59,     1] loss: 696.128
[60,     1] loss: 658.939
[61,     1] loss: 659.741
[62,     1] loss: 713.740
[63,     1] loss: 678.091
[64,     1] loss: 609.030
[65,     1] loss: 659.492
[66,     1] loss: 584.617
[67,     1] loss: 610.158
[68,     1] loss: 610.289
[69,     1] loss: 578.144
[70,     1] loss: 601.044
[71,     1] loss: 597.322
[72,     1] loss: 611.739
[73,     1] loss: 612.838
[74,     1] loss: 576.321
[75,     1] loss: 538.367
[76,     1] loss: 615.309
[77,     1] loss: 568.705
[78,     1] loss: 540.443
[79,     1] loss: 619.050
Early stopping applied (best metric=0.6656835675239563)
Finished Training
Total time taken: 12.145257234573364
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1246.689
[2,     1] loss: 1252.193
[3,     1] loss: 1247.883
[4,     1] loss: 1242.531
[5,     1] loss: 1237.319
[6,     1] loss: 1235.033
[7,     1] loss: 1234.756
[8,     1] loss: 1235.275
[9,     1] loss: 1236.508
[10,     1] loss: 1245.190
[11,     1] loss: 1235.887
[12,     1] loss: 1234.519
[13,     1] loss: 1233.884
[14,     1] loss: 1231.614
[15,     1] loss: 1226.762
[16,     1] loss: 1220.806
[17,     1] loss: 1212.686
[18,     1] loss: 1195.732
[19,     1] loss: 1171.542
[20,     1] loss: 1133.775
[21,     1] loss: 1108.664
[22,     1] loss: 1092.373
[23,     1] loss: 1030.296
[24,     1] loss: 1042.840
[25,     1] loss: 1025.050
[26,     1] loss: 1032.835
[27,     1] loss: 1056.344
[28,     1] loss: 962.142
[29,     1] loss: 1016.145
[30,     1] loss: 970.707
[31,     1] loss: 1032.277
[32,     1] loss: 987.160
[33,     1] loss: 999.895
[34,     1] loss: 935.471
[35,     1] loss: 1006.065
[36,     1] loss: 906.346
[37,     1] loss: 955.624
[38,     1] loss: 898.921
[39,     1] loss: 923.060
[40,     1] loss: 911.592
[41,     1] loss: 875.092
[42,     1] loss: 912.047
[43,     1] loss: 865.657
[44,     1] loss: 828.041
[45,     1] loss: 875.012
[46,     1] loss: 953.305
[47,     1] loss: 860.926
[48,     1] loss: 907.062
[49,     1] loss: 877.310
[50,     1] loss: 874.040
[51,     1] loss: 845.111
[52,     1] loss: 858.969
[53,     1] loss: 794.781
[54,     1] loss: 778.734
[55,     1] loss: 796.499
[56,     1] loss: 809.205
[57,     1] loss: 757.671
[58,     1] loss: 746.798
[59,     1] loss: 769.231
[60,     1] loss: 717.425
[61,     1] loss: 709.886
[62,     1] loss: 689.660
[63,     1] loss: 692.246
[64,     1] loss: 671.436
[65,     1] loss: 702.410
[66,     1] loss: 756.740
[67,     1] loss: 676.460
[68,     1] loss: 814.590
[69,     1] loss: 755.629
[70,     1] loss: 697.238
[71,     1] loss: 761.835
[72,     1] loss: 678.884
[73,     1] loss: 689.573
[74,     1] loss: 677.053
[75,     1] loss: 628.185
[76,     1] loss: 624.521
[77,     1] loss: 602.078
[78,     1] loss: 694.070
[79,     1] loss: 658.010
Early stopping applied (best metric=0.9505205154418945)
Finished Training
Total time taken: 11.331238269805908
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1244.680
[2,     1] loss: 1239.137
[3,     1] loss: 1239.813
[4,     1] loss: 1236.388
[5,     1] loss: 1236.123
[6,     1] loss: 1235.116
[7,     1] loss: 1233.956
[8,     1] loss: 1237.548
[9,     1] loss: 1228.783
[10,     1] loss: 1223.922
[11,     1] loss: 1204.635
[12,     1] loss: 1199.675
[13,     1] loss: 1158.737
[14,     1] loss: 1133.700
[15,     1] loss: 1094.810
[16,     1] loss: 1072.576
[17,     1] loss: 1009.753
[18,     1] loss: 1049.975
[19,     1] loss: 1038.848
[20,     1] loss: 999.741
[21,     1] loss: 940.429
[22,     1] loss: 979.693
[23,     1] loss: 1044.188
[24,     1] loss: 999.740
[25,     1] loss: 981.894
[26,     1] loss: 966.766
[27,     1] loss: 930.159
[28,     1] loss: 1027.987
[29,     1] loss: 923.070
[30,     1] loss: 972.635
[31,     1] loss: 880.289
[32,     1] loss: 878.322
[33,     1] loss: 916.901
[34,     1] loss: 912.742
[35,     1] loss: 846.357
[36,     1] loss: 874.355
[37,     1] loss: 829.901
[38,     1] loss: 796.941
[39,     1] loss: 826.270
[40,     1] loss: 849.479
[41,     1] loss: 855.793
[42,     1] loss: 810.593
[43,     1] loss: 758.858
[44,     1] loss: 796.996
[45,     1] loss: 770.420
[46,     1] loss: 783.776
[47,     1] loss: 742.745
[48,     1] loss: 780.626
[49,     1] loss: 730.118
[50,     1] loss: 818.282
[51,     1] loss: 789.275
[52,     1] loss: 660.109
[53,     1] loss: 833.058
[54,     1] loss: 695.765
Early stopping applied (best metric=0.7845700979232788)
Finished Training
Total time taken: 8.881187200546265
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1235.470
[2,     1] loss: 1237.603
[3,     1] loss: 1235.049
[4,     1] loss: 1234.631
[5,     1] loss: 1227.043
[6,     1] loss: 1199.252
[7,     1] loss: 1155.963
[8,     1] loss: 1111.291
[9,     1] loss: 1095.943
[10,     1] loss: 1066.694
[11,     1] loss: 1091.798
[12,     1] loss: 1046.744
[13,     1] loss: 1007.207
[14,     1] loss: 1027.057
[15,     1] loss: 1007.075
[16,     1] loss: 1033.669
[17,     1] loss: 1009.890
[18,     1] loss: 981.230
[19,     1] loss: 974.052
[20,     1] loss: 983.787
[21,     1] loss: 985.828
[22,     1] loss: 928.145
[23,     1] loss: 974.563
[24,     1] loss: 942.169
[25,     1] loss: 940.974
[26,     1] loss: 936.807
[27,     1] loss: 909.211
[28,     1] loss: 859.287
[29,     1] loss: 925.607
[30,     1] loss: 906.312
[31,     1] loss: 890.511
[32,     1] loss: 900.399
[33,     1] loss: 869.587
[34,     1] loss: 862.104
[35,     1] loss: 915.810
[36,     1] loss: 866.996
[37,     1] loss: 842.172
[38,     1] loss: 857.061
[39,     1] loss: 826.933
[40,     1] loss: 846.575
[41,     1] loss: 834.403
[42,     1] loss: 763.116
[43,     1] loss: 823.266
[44,     1] loss: 770.910
[45,     1] loss: 728.164
[46,     1] loss: 782.746
[47,     1] loss: 775.375
[48,     1] loss: 718.810
[49,     1] loss: 753.962
[50,     1] loss: 721.141
[51,     1] loss: 719.423
[52,     1] loss: 670.874
[53,     1] loss: 663.329
[54,     1] loss: 589.777
[55,     1] loss: 677.948
[56,     1] loss: 879.519
[57,     1] loss: 1232.141
[58,     1] loss: 723.533
[59,     1] loss: 950.227
[60,     1] loss: 822.622
[61,     1] loss: 809.631
[62,     1] loss: 831.236
[63,     1] loss: 796.858
[64,     1] loss: 762.286
[65,     1] loss: 795.997
[66,     1] loss: 814.637
[67,     1] loss: 751.287
[68,     1] loss: 663.722
Early stopping applied (best metric=0.7691029906272888)
Finished Training
Total time taken: 10.994232177734375
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1240.138
[2,     1] loss: 1238.678
[3,     1] loss: 1240.155
[4,     1] loss: 1240.217
[5,     1] loss: 1235.164
[6,     1] loss: 1237.137
[7,     1] loss: 1229.530
[8,     1] loss: 1225.057
[9,     1] loss: 1202.378
[10,     1] loss: 1163.240
[11,     1] loss: 1134.677
[12,     1] loss: 1070.593
[13,     1] loss: 1097.597
[14,     1] loss: 1114.400
[15,     1] loss: 1057.369
[16,     1] loss: 1061.469
[17,     1] loss: 1046.889
[18,     1] loss: 1045.762
[19,     1] loss: 1008.643
[20,     1] loss: 997.335
[21,     1] loss: 997.923
[22,     1] loss: 1000.218
[23,     1] loss: 999.642
[24,     1] loss: 929.915
[25,     1] loss: 938.365
[26,     1] loss: 925.681
[27,     1] loss: 931.369
[28,     1] loss: 939.965
[29,     1] loss: 937.255
[30,     1] loss: 881.397
[31,     1] loss: 913.125
[32,     1] loss: 865.073
[33,     1] loss: 910.746
[34,     1] loss: 865.533
[35,     1] loss: 854.382
[36,     1] loss: 879.777
[37,     1] loss: 868.819
[38,     1] loss: 814.984
[39,     1] loss: 860.470
[40,     1] loss: 836.019
[41,     1] loss: 871.082
[42,     1] loss: 814.627
[43,     1] loss: 873.574
[44,     1] loss: 791.593
[45,     1] loss: 825.876
[46,     1] loss: 767.169
[47,     1] loss: 795.136
[48,     1] loss: 775.706
[49,     1] loss: 793.306
[50,     1] loss: 754.041
Early stopping applied (best metric=0.851530909538269)
Finished Training
Total time taken: 6.99114727973938
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1235.466
[2,     1] loss: 1240.026
[3,     1] loss: 1242.228
[4,     1] loss: 1240.705
[5,     1] loss: 1230.875
[6,     1] loss: 1218.435
[7,     1] loss: 1199.253
[8,     1] loss: 1144.509
[9,     1] loss: 1093.345
[10,     1] loss: 1075.384
[11,     1] loss: 1117.443
[12,     1] loss: 1029.745
[13,     1] loss: 1032.072
[14,     1] loss: 1079.188
[15,     1] loss: 1023.423
[16,     1] loss: 1046.283
[17,     1] loss: 1030.492
[18,     1] loss: 1026.911
[19,     1] loss: 1012.399
[20,     1] loss: 965.500
[21,     1] loss: 986.711
[22,     1] loss: 934.146
[23,     1] loss: 961.476
[24,     1] loss: 956.837
[25,     1] loss: 921.677
[26,     1] loss: 982.522
[27,     1] loss: 933.935
[28,     1] loss: 919.665
[29,     1] loss: 920.155
[30,     1] loss: 880.104
[31,     1] loss: 912.198
[32,     1] loss: 891.963
[33,     1] loss: 914.339
[34,     1] loss: 901.561
[35,     1] loss: 949.179
[36,     1] loss: 874.438
[37,     1] loss: 881.738
[38,     1] loss: 880.365
[39,     1] loss: 853.302
[40,     1] loss: 839.255
[41,     1] loss: 816.441
[42,     1] loss: 832.099
[43,     1] loss: 741.798
[44,     1] loss: 760.545
[45,     1] loss: 799.354
[46,     1] loss: 741.250
[47,     1] loss: 736.279
[48,     1] loss: 749.063
[49,     1] loss: 763.751
[50,     1] loss: 713.535
[51,     1] loss: 762.253
[52,     1] loss: 827.010
[53,     1] loss: 812.532
[54,     1] loss: 659.296
[55,     1] loss: 763.471
[56,     1] loss: 681.110
[57,     1] loss: 735.617
[58,     1] loss: 698.437
[59,     1] loss: 676.614
[60,     1] loss: 628.913
[61,     1] loss: 611.140
[62,     1] loss: 579.546
[63,     1] loss: 574.308
[64,     1] loss: 634.009
[65,     1] loss: 633.198
[66,     1] loss: 633.276
[67,     1] loss: 634.286
[68,     1] loss: 636.204
[69,     1] loss: 616.445
[70,     1] loss: 585.038
[71,     1] loss: 603.664
[72,     1] loss: 591.631
[73,     1] loss: 539.793
[74,     1] loss: 504.090
[75,     1] loss: 564.968
[76,     1] loss: 525.505
[77,     1] loss: 537.736
[78,     1] loss: 510.306
[79,     1] loss: 477.321
[80,     1] loss: 518.206
[81,     1] loss: 530.941
[82,     1] loss: 542.763
[83,     1] loss: 595.195
[84,     1] loss: 594.548
[85,     1] loss: 502.029
[86,     1] loss: 538.107
Early stopping applied (best metric=0.7436938285827637)
Finished Training
Total time taken: 12.553263187408447
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.286
[2,     1] loss: 1263.728
[3,     1] loss: 1241.710
[4,     1] loss: 1244.362
[5,     1] loss: 1237.646
[6,     1] loss: 1238.183
[7,     1] loss: 1238.690
[8,     1] loss: 1237.234
[9,     1] loss: 1239.871
[10,     1] loss: 1236.418
[11,     1] loss: 1237.520
[12,     1] loss: 1231.821
[13,     1] loss: 1239.346
[14,     1] loss: 1237.412
[15,     1] loss: 1235.445
[16,     1] loss: 1233.264
[17,     1] loss: 1236.227
[18,     1] loss: 1231.598
[19,     1] loss: 1229.803
[20,     1] loss: 1228.521
[21,     1] loss: 1222.248
[22,     1] loss: 1218.850
[23,     1] loss: 1207.445
[24,     1] loss: 1197.762
[25,     1] loss: 1182.935
[26,     1] loss: 1184.280
[27,     1] loss: 1132.154
[28,     1] loss: 1124.292
[29,     1] loss: 1111.106
[30,     1] loss: 1097.402
[31,     1] loss: 1101.836
[32,     1] loss: 1062.936
[33,     1] loss: 1053.781
[34,     1] loss: 1058.790
[35,     1] loss: 1016.286
[36,     1] loss: 1017.138
[37,     1] loss: 1002.859
[38,     1] loss: 965.620
[39,     1] loss: 1017.152
[40,     1] loss: 1007.402
[41,     1] loss: 947.310
[42,     1] loss: 955.151
[43,     1] loss: 929.145
[44,     1] loss: 973.339
[45,     1] loss: 937.413
[46,     1] loss: 893.550
[47,     1] loss: 899.087
[48,     1] loss: 893.422
[49,     1] loss: 857.314
[50,     1] loss: 901.725
[51,     1] loss: 923.384
[52,     1] loss: 850.186
[53,     1] loss: 833.818
[54,     1] loss: 842.989
[55,     1] loss: 850.499
[56,     1] loss: 846.281
[57,     1] loss: 794.172
[58,     1] loss: 791.307
[59,     1] loss: 776.086
[60,     1] loss: 855.241
[61,     1] loss: 757.197
[62,     1] loss: 736.991
[63,     1] loss: 759.928
[64,     1] loss: 696.780
[65,     1] loss: 702.106
[66,     1] loss: 750.452
[67,     1] loss: 962.676
[68,     1] loss: 701.261
[69,     1] loss: 920.872
[70,     1] loss: 825.624
[71,     1] loss: 884.808
[72,     1] loss: 751.285
[73,     1] loss: 764.239
Early stopping applied (best metric=0.8233699798583984)
Finished Training
Total time taken: 10.77122688293457
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.066
[2,     1] loss: 1239.131
[3,     1] loss: 1243.931
[4,     1] loss: 1234.627
[5,     1] loss: 1235.398
[6,     1] loss: 1225.215
[7,     1] loss: 1208.052
[8,     1] loss: 1172.578
[9,     1] loss: 1106.139
[10,     1] loss: 1051.294
[11,     1] loss: 1063.563
[12,     1] loss: 1019.862
[13,     1] loss: 1047.249
[14,     1] loss: 1043.327
[15,     1] loss: 1042.273
[16,     1] loss: 967.647
[17,     1] loss: 1019.607
[18,     1] loss: 965.489
[19,     1] loss: 1014.584
[20,     1] loss: 1004.203
[21,     1] loss: 962.248
[22,     1] loss: 976.470
[23,     1] loss: 937.069
[24,     1] loss: 898.555
[25,     1] loss: 919.543
[26,     1] loss: 871.461
[27,     1] loss: 911.538
[28,     1] loss: 933.474
[29,     1] loss: 871.182
[30,     1] loss: 899.823
[31,     1] loss: 862.313
[32,     1] loss: 837.131
[33,     1] loss: 880.611
[34,     1] loss: 823.862
[35,     1] loss: 844.358
[36,     1] loss: 851.275
[37,     1] loss: 843.907
[38,     1] loss: 820.826
[39,     1] loss: 815.524
[40,     1] loss: 818.161
[41,     1] loss: 811.203
[42,     1] loss: 782.016
[43,     1] loss: 768.960
[44,     1] loss: 773.805
[45,     1] loss: 765.210
[46,     1] loss: 810.907
[47,     1] loss: 716.131
[48,     1] loss: 814.602
[49,     1] loss: 722.915
[50,     1] loss: 700.384
[51,     1] loss: 726.699
Early stopping applied (best metric=0.9560627937316895)
Finished Training
Total time taken: 8.328174591064453
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.775
[2,     1] loss: 1255.225
[3,     1] loss: 1238.138
[4,     1] loss: 1238.230
[5,     1] loss: 1237.364
[6,     1] loss: 1236.572
[7,     1] loss: 1239.206
[8,     1] loss: 1238.917
[9,     1] loss: 1237.963
[10,     1] loss: 1236.756
[11,     1] loss: 1236.275
[12,     1] loss: 1235.400
[13,     1] loss: 1236.578
[14,     1] loss: 1236.828
[15,     1] loss: 1236.622
[16,     1] loss: 1237.100
[17,     1] loss: 1235.295
[18,     1] loss: 1233.661
[19,     1] loss: 1232.739
[20,     1] loss: 1229.046
[21,     1] loss: 1224.977
[22,     1] loss: 1220.408
[23,     1] loss: 1207.013
[24,     1] loss: 1180.352
[25,     1] loss: 1166.202
[26,     1] loss: 1135.498
[27,     1] loss: 1113.513
[28,     1] loss: 1102.756
[29,     1] loss: 1029.020
[30,     1] loss: 1053.364
[31,     1] loss: 1047.615
[32,     1] loss: 1057.510
[33,     1] loss: 1041.659
[34,     1] loss: 1007.526
[35,     1] loss: 1029.854
[36,     1] loss: 1002.562
[37,     1] loss: 1008.237
[38,     1] loss: 1004.838
[39,     1] loss: 947.877
[40,     1] loss: 911.254
[41,     1] loss: 926.983
[42,     1] loss: 955.719
[43,     1] loss: 987.871
[44,     1] loss: 929.944
[45,     1] loss: 951.286
[46,     1] loss: 898.870
[47,     1] loss: 912.762
[48,     1] loss: 936.044
[49,     1] loss: 884.196
[50,     1] loss: 876.696
[51,     1] loss: 858.780
[52,     1] loss: 831.664
[53,     1] loss: 878.049
[54,     1] loss: 874.275
[55,     1] loss: 793.288
[56,     1] loss: 903.277
[57,     1] loss: 839.053
[58,     1] loss: 791.677
[59,     1] loss: 763.825
[60,     1] loss: 759.466
[61,     1] loss: 752.637
[62,     1] loss: 774.898
[63,     1] loss: 731.301
[64,     1] loss: 732.809
[65,     1] loss: 715.627
[66,     1] loss: 712.921
[67,     1] loss: 703.355
[68,     1] loss: 712.315
[69,     1] loss: 738.849
[70,     1] loss: 714.237
[71,     1] loss: 686.808
[72,     1] loss: 668.471
[73,     1] loss: 634.783
[74,     1] loss: 677.216
[75,     1] loss: 668.176
[76,     1] loss: 639.028
[77,     1] loss: 558.152
Early stopping applied (best metric=0.7633113861083984)
Finished Training
Total time taken: 11.291238069534302
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1239.879
[2,     1] loss: 1250.246
[3,     1] loss: 1248.158
[4,     1] loss: 1241.697
[5,     1] loss: 1240.476
[6,     1] loss: 1238.127
[7,     1] loss: 1238.469
[8,     1] loss: 1240.451
[9,     1] loss: 1235.730
[10,     1] loss: 1238.673
[11,     1] loss: 1241.068
[12,     1] loss: 1240.411
[13,     1] loss: 1236.461
[14,     1] loss: 1233.415
[15,     1] loss: 1234.691
[16,     1] loss: 1232.489
[17,     1] loss: 1229.663
[18,     1] loss: 1232.198
[19,     1] loss: 1217.769
[20,     1] loss: 1203.482
[21,     1] loss: 1186.568
[22,     1] loss: 1174.041
[23,     1] loss: 1163.568
[24,     1] loss: 1127.516
[25,     1] loss: 1112.916
[26,     1] loss: 1127.628
[27,     1] loss: 1143.294
[28,     1] loss: 1106.442
[29,     1] loss: 1110.319
[30,     1] loss: 1128.227
[31,     1] loss: 1066.048
[32,     1] loss: 1077.036
[33,     1] loss: 1060.591
[34,     1] loss: 1015.899
[35,     1] loss: 1045.286
[36,     1] loss: 1056.813
[37,     1] loss: 1014.774
[38,     1] loss: 1013.803
[39,     1] loss: 976.788
[40,     1] loss: 974.123
[41,     1] loss: 932.063
[42,     1] loss: 985.553
[43,     1] loss: 909.265
[44,     1] loss: 934.101
[45,     1] loss: 911.728
[46,     1] loss: 956.575
[47,     1] loss: 920.398
[48,     1] loss: 885.672
[49,     1] loss: 912.518
[50,     1] loss: 856.380
[51,     1] loss: 851.665
[52,     1] loss: 904.751
[53,     1] loss: 872.416
[54,     1] loss: 900.645
[55,     1] loss: 860.039
[56,     1] loss: 867.421
[57,     1] loss: 826.917
[58,     1] loss: 842.381
[59,     1] loss: 877.350
[60,     1] loss: 820.097
[61,     1] loss: 783.005
[62,     1] loss: 800.093
[63,     1] loss: 723.170
[64,     1] loss: 712.674
[65,     1] loss: 745.077
[66,     1] loss: 717.720
[67,     1] loss: 785.458
[68,     1] loss: 883.490
[69,     1] loss: 804.233
[70,     1] loss: 714.066
[71,     1] loss: 753.143
[72,     1] loss: 740.168
[73,     1] loss: 712.355
[74,     1] loss: 698.198
[75,     1] loss: 684.381
[76,     1] loss: 718.969
[77,     1] loss: 657.311
Early stopping applied (best metric=0.7806606292724609)
Finished Training
Total time taken: 12.585265159606934
{'Hydroxylation-K Validation Accuracy': 0.7645094562647754, 'Hydroxylation-K Validation Sensitivity': 0.6814814814814815, 'Hydroxylation-K Validation Specificity': 0.7859649122807018, 'Hydroxylation-K Validation Precision': 0.45121155074715447, 'Hydroxylation-K AUC ROC': 0.8106627680311891, 'Hydroxylation-K AUC PR': 0.6161235753436942, 'Hydroxylation-K MCC': 0.4090740878354118, 'Hydroxylation-K F1': 0.5388719074806032, 'Validation Loss (Hydroxylation-K)': 0.433905158440272, 'Hydroxylation-P Validation Accuracy': 0.798373415901054, 'Hydroxylation-P Validation Sensitivity': 0.7728571428571429, 'Hydroxylation-P Validation Specificity': 0.803863035562871, 'Hydroxylation-P Validation Precision': 0.4655703015515387, 'Hydroxylation-P AUC ROC': 0.8478368691151124, 'Hydroxylation-P AUC PR': 0.5955329244241975, 'Hydroxylation-P MCC': 0.48519798354764776, 'Hydroxylation-P F1': 0.577493151306178, 'Validation Loss (Hydroxylation-P)': 0.37325825889905295, 'Validation Loss (total)': 0.8071634292602539, 'TimeToTrain': 10.257684628168741}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006991674610102895,
 'learning_rate_Hydroxylation-K': 0.0019225003845919375,
 'learning_rate_Hydroxylation-P': 0.005096830415305273,
 'log_base': 1.1615737743368784,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 947713502,
 'sample_weights': [1.5597145163022, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.839582775104995,
 'weight_decay_Hydroxylation-K': 1.8334498336686447,
 'weight_decay_Hydroxylation-P': 7.360271103493158}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3623.765
[2,     1] loss: 3632.152
[3,     1] loss: 3644.499
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0029309729450027453,
 'learning_rate_Hydroxylation-K': 0.00471539809024704,
 'learning_rate_Hydroxylation-P': 0.001240765148885884,
 'log_base': 2.7529317730240033,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 834671641,
 'sample_weights': [11.146281876944787, 1.3933389095602524],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8262909733024597,
 'weight_decay_Hydroxylation-K': 5.221309870507981,
 'weight_decay_Hydroxylation-P': 0.09629574679922337}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1253.728
[2,     1] loss: 1254.263
[3,     1] loss: 1260.072
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003113842732325944,
 'learning_rate_Hydroxylation-K': 0.001651108292289908,
 'learning_rate_Hydroxylation-P': 0.003700929585493834,
 'log_base': 2.8682162875026944,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3208732758,
 'sample_weights': [1.6485617340559273, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.3153947707011637,
 'weight_decay_Hydroxylation-K': 3.778039671534235,
 'weight_decay_Hydroxylation-P': 1.1305196116720158}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1246.103
[2,     1] loss: 1247.647
[3,     1] loss: 1242.934
[4,     1] loss: 1239.125
[5,     1] loss: 1236.901
[6,     1] loss: 1231.142
[7,     1] loss: 1220.153
[8,     1] loss: 1188.149
[9,     1] loss: 1150.475
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0056721767508982855,
 'learning_rate_Hydroxylation-K': 0.0038306265201597106,
 'learning_rate_Hydroxylation-P': 0.004024355948736078,
 'log_base': 2.806721077398641,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 602595930,
 'sample_weights': [1.5843773959385703, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.505647089726377,
 'weight_decay_Hydroxylation-K': 3.541861567193834,
 'weight_decay_Hydroxylation-P': 1.5327921275826264}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1252.506
[2,     1] loss: 1310.033
[3,     1] loss: 1248.792
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001030759049599444,
 'learning_rate_Hydroxylation-K': 0.004824028288846144,
 'learning_rate_Hydroxylation-P': 0.0034462223629119107,
 'log_base': 1.1330526947140895,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3474432294,
 'sample_weights': [1.6176509376342578, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9311182335165287,
 'weight_decay_Hydroxylation-K': 0.7805335743676554,
 'weight_decay_Hydroxylation-P': 0.5038900380058179}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 4360.998
[2,     1] loss: 4343.671
[3,     1] loss: 4332.346
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00890641834219122,
 'learning_rate_Hydroxylation-K': 0.006136991416637827,
 'learning_rate_Hydroxylation-P': 0.0005752669321288763,
 'log_base': 2.1302892532720454,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3572039572,
 'sample_weights': [13.364580707311973, 1.670636945578502],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.273691877197225,
 'weight_decay_Hydroxylation-K': 5.519844155551324,
 'weight_decay_Hydroxylation-P': 6.911060933524514}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1380.141
[2,     1] loss: 1410.382
[3,     1] loss: 1388.133
[4,     1] loss: 1369.101
[5,     1] loss: 1380.671
[6,     1] loss: 1380.858
[7,     1] loss: 1373.650
[8,     1] loss: 1371.965
[9,     1] loss: 1374.092
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007541175129696648,
 'learning_rate_Hydroxylation-K': 0.004483875777093917,
 'learning_rate_Hydroxylation-P': 0.001269869477760055,
 'log_base': 2.901822615212691,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3791679213,
 'sample_weights': [2.2075054476085363, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9084660985617206,
 'weight_decay_Hydroxylation-K': 4.469912303074142,
 'weight_decay_Hydroxylation-P': 3.6935715559929347}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.668
[2,     1] loss: 1280.422
[3,     1] loss: 1243.193
[4,     1] loss: 1241.939
[5,     1] loss: 1233.473
[6,     1] loss: 1246.148
[7,     1] loss: 1239.548
[8,     1] loss: 1240.651
[9,     1] loss: 1240.864
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008638421505641307,
 'learning_rate_Hydroxylation-K': 0.0043074016832964634,
 'learning_rate_Hydroxylation-P': 0.002545361073113645,
 'log_base': 2.7179751710810707,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 24825501,
 'sample_weights': [1.5670534019714684, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.02102873933214,
 'weight_decay_Hydroxylation-K': 1.0329837148026515,
 'weight_decay_Hydroxylation-P': 1.912306253337384}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1255.945
[2,     1] loss: 1262.194
[3,     1] loss: 1258.735
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007922462134076602,
 'learning_rate_Hydroxylation-K': 5.147341669178211e-05,
 'learning_rate_Hydroxylation-P': 0.004906491522243741,
 'log_base': 2.8662450419236274,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 198505018,
 'sample_weights': [1.6696315140968752, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1743756922553024,
 'weight_decay_Hydroxylation-K': 2.7601128149380916,
 'weight_decay_Hydroxylation-P': 0.7835798785778565}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.278
[2,     1] loss: 1243.581
[3,     1] loss: 1243.190
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004719462387011545,
 'learning_rate_Hydroxylation-K': 0.007758124701952575,
 'learning_rate_Hydroxylation-P': 0.006245968398330724,
 'log_base': 1.1817681173206172,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 38571158,
 'sample_weights': [1.5854118404936886, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.196814668761924,
 'weight_decay_Hydroxylation-K': 5.442759989140451,
 'weight_decay_Hydroxylation-P': 6.43203983417153}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3272.915
[2,     1] loss: 3291.732
[3,     1] loss: 3244.722
[4,     1] loss: 3244.788
[5,     1] loss: 3254.783
[6,     1] loss: 3247.649
[7,     1] loss: 3243.887
[8,     1] loss: 3245.603
[9,     1] loss: 3248.141
[10,     1] loss: 3238.189
[11,     1] loss: 3240.366
[12,     1] loss: 3250.784
[13,     1] loss: 3237.424
[14,     1] loss: 3251.608
[15,     1] loss: 3250.080
[16,     1] loss: 3236.938
[17,     1] loss: 3241.616
[18,     1] loss: 3230.991
[19,     1] loss: 3242.343
[20,     1] loss: 3249.886
[21,     1] loss: 3238.528
[22,     1] loss: 3246.689
[23,     1] loss: 3247.344
[24,     1] loss: 3254.856
[25,     1] loss: 3246.628
[26,     1] loss: 3242.004
[27,     1] loss: 3247.196
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0059635214178410615,
 'learning_rate_Hydroxylation-K': 0.005953054014480867,
 'learning_rate_Hydroxylation-P': 0.0034612217620587048,
 'log_base': 2.3419294008935796,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2230202064,
 'sample_weights': [9.995963950570788, 1.2495436294052809],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5489823821482136,
 'weight_decay_Hydroxylation-K': 0.014460029047772327,
 'weight_decay_Hydroxylation-P': 1.5142840250172769}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1321.100
[2,     1] loss: 1336.555
[3,     1] loss: 1336.372
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0055712136318250395,
 'learning_rate_Hydroxylation-K': 3.728166404505905e-05,
 'learning_rate_Hydroxylation-P': 0.0008332181512549211,
 'log_base': 1.381737047568768,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3374128252,
 'sample_weights': [1.9618001846700537, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.547182885171263,
 'weight_decay_Hydroxylation-K': 2.4715742153465508,
 'weight_decay_Hydroxylation-P': 9.867987844054515}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2013.189
[2,     1] loss: 2012.577
[3,     1] loss: 1996.949
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006156869149604224,
 'learning_rate_Hydroxylation-K': 0.0016429409154810788,
 'learning_rate_Hydroxylation-P': 0.008723547225278084,
 'log_base': 1.1604923368885114,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 911511773,
 'sample_weights': [5.163096814982513, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.971048617813384,
 'weight_decay_Hydroxylation-K': 2.848876810988159,
 'weight_decay_Hydroxylation-P': 9.537433117354974}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3646.999
[2,     1] loss: 3636.123
[3,     1] loss: 3654.165
[4,     1] loss: 3650.172
[5,     1] loss: 3667.880
[6,     1] loss: 3616.608
[7,     1] loss: 3655.388
[8,     1] loss: 3625.549
[9,     1] loss: 3624.237
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002083260540899631,
 'learning_rate_Hydroxylation-K': 0.001437056681442566,
 'learning_rate_Hydroxylation-P': 0.004254941256207145,
 'log_base': 1.0887488134704397,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 874350591,
 'sample_weights': [11.216033535405309, 1.4020582027570654],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.328159240013541,
 'weight_decay_Hydroxylation-K': 0.4654841793491391,
 'weight_decay_Hydroxylation-P': 8.896033771674102}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 6359.106
[2,     1] loss: 6359.364
[3,     1] loss: 6367.087
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006779940926500122,
 'learning_rate_Hydroxylation-K': 0.0025201681329606465,
 'learning_rate_Hydroxylation-P': 0.005812079799365873,
 'log_base': 2.495093224167076,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2915285093,
 'sample_weights': [19.633772222321706, 2.454316074258707],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1593991508908363,
 'weight_decay_Hydroxylation-K': 5.255306774791743,
 'weight_decay_Hydroxylation-P': 0.9730662086599275}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1296.195
[2,     1] loss: 1306.797
[3,     1] loss: 1297.114
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007463723327195844,
 'learning_rate_Hydroxylation-K': 0.00434521309149002,
 'learning_rate_Hydroxylation-P': 0.0030425004605085385,
 'log_base': 2.9507039510327955,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 421220093,
 'sample_weights': [1.8258728044462607, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.0651918544358514,
 'weight_decay_Hydroxylation-K': 3.666795224135737,
 'weight_decay_Hydroxylation-P': 1.0666857610557918}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.524
[2,     1] loss: 1311.719
[3,     1] loss: 1248.533
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008234076937610565,
 'learning_rate_Hydroxylation-K': 0.007309025317578852,
 'learning_rate_Hydroxylation-P': 0.007500570872244767,
 'log_base': 1.2306973398892351,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1205272492,
 'sample_weights': [1.5428610142279024, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.154273055987405,
 'weight_decay_Hydroxylation-K': 3.2197217331809265,
 'weight_decay_Hydroxylation-P': 2.9250823649640783}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2613.021
[2,     1] loss: 2628.266
[3,     1] loss: 2613.516
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006386527993512158,
 'learning_rate_Hydroxylation-K': 0.008397906377120547,
 'learning_rate_Hydroxylation-P': 0.003772266428474065,
 'log_base': 1.5191165059838665,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3843656110,
 'sample_weights': [8.04237158319374, 1.005335175955288],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.8249570471097685,
 'weight_decay_Hydroxylation-K': 2.9855741432350533,
 'weight_decay_Hydroxylation-P': 2.4418310228896543}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1748.683
[2,     1] loss: 1757.105
[3,     1] loss: 1760.460
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006549908299823382,
 'learning_rate_Hydroxylation-K': 0.008083009383584226,
 'learning_rate_Hydroxylation-P': 0.003649803983860607,
 'log_base': 1.973200174861579,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2144026839,
 'sample_weights': [3.992651711817506, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6553188431107806,
 'weight_decay_Hydroxylation-K': 9.072550653918356,
 'weight_decay_Hydroxylation-P': 6.744179486092476}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1423.965
[2,     1] loss: 1423.810
[3,     1] loss: 1452.168
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007007007589580763,
 'learning_rate_Hydroxylation-K': 0.00813213614495013,
 'learning_rate_Hydroxylation-P': 0.0009852997507342992,
 'log_base': 1.7004509840006417,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 288786022,
 'sample_weights': [2.456303600062457, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.9716982011374036,
 'weight_decay_Hydroxylation-K': 4.003578854078577,
 'weight_decay_Hydroxylation-P': 8.394529742690331}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1575.423
[2,     1] loss: 1589.000
[3,     1] loss: 1578.846
[4,     1] loss: 1574.801
[5,     1] loss: 1577.541
[6,     1] loss: 1567.725
[7,     1] loss: 1567.135
[8,     1] loss: 1574.446
[9,     1] loss: 1568.802
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007794720369175923,
 'learning_rate_Hydroxylation-K': 0.009769259858718607,
 'learning_rate_Hydroxylation-P': 0.002144490938271271,
 'log_base': 1.219661479547563,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2985459471,
 'sample_weights': [3.144591421026726, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4185659414152756,
 'weight_decay_Hydroxylation-K': 5.704852521882018,
 'weight_decay_Hydroxylation-P': 7.478865917495135}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2730.594
[2,     1] loss: 2837.365
[3,     1] loss: 2725.863
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019203361082703995,
 'learning_rate_Hydroxylation-K': 0.0020252029555042758,
 'learning_rate_Hydroxylation-P': 0.005924610457258671,
 'log_base': 2.9221506222327474,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2603768571,
 'sample_weights': [8.407186533296041, 1.0509388014851808],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.234061055273255,
 'weight_decay_Hydroxylation-K': 1.2278135832857593,
 'weight_decay_Hydroxylation-P': 3.8008026575354474}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1237.063
[2,     1] loss: 1238.329
[3,     1] loss: 1236.080
[4,     1] loss: 1235.324
[5,     1] loss: 1231.719
[6,     1] loss: 1230.511
[7,     1] loss: 1221.664
[8,     1] loss: 1211.759
[9,     1] loss: 1183.901
[10,     1] loss: 1159.272
[11,     1] loss: 1110.989
[12,     1] loss: 1070.205
[13,     1] loss: 1059.100
[14,     1] loss: 1008.649
[15,     1] loss: 1017.651
[16,     1] loss: 1004.732
[17,     1] loss: 1055.996
[18,     1] loss: 1026.870
[19,     1] loss: 975.795
[20,     1] loss: 1017.003
[21,     1] loss: 998.037
[22,     1] loss: 1023.115
[23,     1] loss: 987.876
[24,     1] loss: 982.518
[25,     1] loss: 971.482
[26,     1] loss: 990.514
[27,     1] loss: 968.979
[28,     1] loss: 937.424
[29,     1] loss: 952.654
[30,     1] loss: 949.696
[31,     1] loss: 966.647
[32,     1] loss: 927.353
[33,     1] loss: 927.541
[34,     1] loss: 909.398
[35,     1] loss: 905.762
[36,     1] loss: 876.498
[37,     1] loss: 908.330
[38,     1] loss: 888.098
[39,     1] loss: 833.366
[40,     1] loss: 854.379
[41,     1] loss: 890.712
[42,     1] loss: 892.398
[43,     1] loss: 855.147
[44,     1] loss: 822.980
[45,     1] loss: 830.081
[46,     1] loss: 819.659
[47,     1] loss: 841.358
[48,     1] loss: 791.014
[49,     1] loss: 831.392
[50,     1] loss: 854.348
[51,     1] loss: 736.995
[52,     1] loss: 774.423
[53,     1] loss: 708.335
[54,     1] loss: 806.788
[55,     1] loss: 754.721
[56,     1] loss: 758.632
[57,     1] loss: 725.274
[58,     1] loss: 678.355
[59,     1] loss: 721.799
[60,     1] loss: 752.547
[61,     1] loss: 711.162
[62,     1] loss: 667.988
[63,     1] loss: 689.872
[64,     1] loss: 669.052
[65,     1] loss: 685.231
[66,     1] loss: 652.943
[67,     1] loss: 727.912
[68,     1] loss: 628.490
[69,     1] loss: 617.986
[70,     1] loss: 637.177
[71,     1] loss: 589.992
[72,     1] loss: 650.059
[73,     1] loss: 622.419
[74,     1] loss: 588.017
[75,     1] loss: 627.648
[76,     1] loss: 575.991
[77,     1] loss: 556.830
[78,     1] loss: 600.468
[79,     1] loss: 571.759
[80,     1] loss: 557.793
[81,     1] loss: 598.895
[82,     1] loss: 541.140
[83,     1] loss: 517.147
Early stopping applied (best metric=0.6983535289764404)
Finished Training
Total time taken: 13.581286430358887
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.829
[2,     1] loss: 1237.658
[3,     1] loss: 1232.400
[4,     1] loss: 1234.100
[5,     1] loss: 1230.906
[6,     1] loss: 1225.175
[7,     1] loss: 1213.896
[8,     1] loss: 1194.085
[9,     1] loss: 1172.412
[10,     1] loss: 1138.692
[11,     1] loss: 1113.566
[12,     1] loss: 1093.242
[13,     1] loss: 1086.382
[14,     1] loss: 1069.054
[15,     1] loss: 1010.011
[16,     1] loss: 989.875
[17,     1] loss: 1026.879
[18,     1] loss: 1027.223
[19,     1] loss: 992.184
[20,     1] loss: 1022.969
[21,     1] loss: 987.970
[22,     1] loss: 982.483
[23,     1] loss: 980.774
[24,     1] loss: 1008.825
[25,     1] loss: 973.775
[26,     1] loss: 1009.090
[27,     1] loss: 990.025
[28,     1] loss: 943.000
[29,     1] loss: 960.173
[30,     1] loss: 987.532
[31,     1] loss: 971.604
[32,     1] loss: 897.864
[33,     1] loss: 937.660
[34,     1] loss: 929.670
[35,     1] loss: 901.622
[36,     1] loss: 904.824
[37,     1] loss: 864.319
[38,     1] loss: 916.344
[39,     1] loss: 883.124
[40,     1] loss: 866.103
[41,     1] loss: 831.047
[42,     1] loss: 867.183
[43,     1] loss: 868.639
[44,     1] loss: 877.569
[45,     1] loss: 834.732
[46,     1] loss: 867.491
[47,     1] loss: 812.764
[48,     1] loss: 863.702
[49,     1] loss: 839.018
[50,     1] loss: 839.922
[51,     1] loss: 802.448
[52,     1] loss: 782.272
[53,     1] loss: 752.452
[54,     1] loss: 741.878
[55,     1] loss: 705.885
[56,     1] loss: 726.003
[57,     1] loss: 767.305
[58,     1] loss: 815.924
[59,     1] loss: 672.424
[60,     1] loss: 714.077
[61,     1] loss: 768.254
[62,     1] loss: 714.218
Early stopping applied (best metric=0.9294530749320984)
Finished Training
Total time taken: 9.334196329116821
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.917
[2,     1] loss: 1236.753
[3,     1] loss: 1238.302
[4,     1] loss: 1235.732
[5,     1] loss: 1236.302
[6,     1] loss: 1235.222
[7,     1] loss: 1233.792
[8,     1] loss: 1232.535
[9,     1] loss: 1232.715
[10,     1] loss: 1220.778
[11,     1] loss: 1212.590
[12,     1] loss: 1190.631
[13,     1] loss: 1174.302
[14,     1] loss: 1147.776
[15,     1] loss: 1125.460
[16,     1] loss: 1113.155
[17,     1] loss: 1073.062
[18,     1] loss: 1099.295
[19,     1] loss: 1059.158
[20,     1] loss: 1092.084
[21,     1] loss: 1045.750
[22,     1] loss: 1024.460
[23,     1] loss: 1039.498
[24,     1] loss: 1029.147
[25,     1] loss: 1035.479
[26,     1] loss: 1002.831
[27,     1] loss: 1012.075
[28,     1] loss: 1015.939
[29,     1] loss: 996.082
[30,     1] loss: 958.537
[31,     1] loss: 994.760
[32,     1] loss: 973.059
[33,     1] loss: 946.066
[34,     1] loss: 948.990
[35,     1] loss: 911.939
[36,     1] loss: 963.417
[37,     1] loss: 967.159
[38,     1] loss: 927.220
[39,     1] loss: 931.850
[40,     1] loss: 928.105
[41,     1] loss: 912.839
[42,     1] loss: 905.101
[43,     1] loss: 843.273
[44,     1] loss: 853.270
[45,     1] loss: 871.884
[46,     1] loss: 858.769
[47,     1] loss: 867.100
[48,     1] loss: 836.995
[49,     1] loss: 857.060
[50,     1] loss: 815.217
[51,     1] loss: 813.465
[52,     1] loss: 811.710
[53,     1] loss: 787.041
[54,     1] loss: 784.729
[55,     1] loss: 770.063
[56,     1] loss: 784.541
[57,     1] loss: 773.897
[58,     1] loss: 782.278
[59,     1] loss: 859.641
[60,     1] loss: 880.262
[61,     1] loss: 740.806
[62,     1] loss: 814.980
[63,     1] loss: 717.841
[64,     1] loss: 779.271
[65,     1] loss: 735.343
[66,     1] loss: 735.583
[67,     1] loss: 729.006
[68,     1] loss: 740.816
[69,     1] loss: 714.704
[70,     1] loss: 665.377
[71,     1] loss: 686.792
[72,     1] loss: 671.863
[73,     1] loss: 671.348
[74,     1] loss: 607.882
[75,     1] loss: 612.170
[76,     1] loss: 560.915
Early stopping applied (best metric=0.6909106373786926)
Finished Training
Total time taken: 10.631223678588867
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.732
[2,     1] loss: 1241.437
[3,     1] loss: 1232.592
[4,     1] loss: 1236.921
[5,     1] loss: 1233.168
[6,     1] loss: 1227.947
[7,     1] loss: 1219.596
[8,     1] loss: 1196.370
[9,     1] loss: 1171.821
[10,     1] loss: 1149.169
[11,     1] loss: 1113.923
[12,     1] loss: 1105.816
[13,     1] loss: 1111.455
[14,     1] loss: 1060.797
[15,     1] loss: 1042.425
[16,     1] loss: 1023.830
[17,     1] loss: 1008.844
[18,     1] loss: 1013.837
[19,     1] loss: 1029.539
[20,     1] loss: 990.691
[21,     1] loss: 990.984
[22,     1] loss: 1003.733
[23,     1] loss: 962.107
[24,     1] loss: 995.583
[25,     1] loss: 978.101
[26,     1] loss: 999.365
[27,     1] loss: 958.545
[28,     1] loss: 966.970
[29,     1] loss: 967.721
[30,     1] loss: 959.728
[31,     1] loss: 954.295
[32,     1] loss: 950.296
[33,     1] loss: 942.509
[34,     1] loss: 895.509
[35,     1] loss: 903.217
[36,     1] loss: 889.037
[37,     1] loss: 899.667
[38,     1] loss: 899.739
[39,     1] loss: 900.341
[40,     1] loss: 882.771
[41,     1] loss: 855.828
[42,     1] loss: 857.429
[43,     1] loss: 861.635
[44,     1] loss: 817.263
[45,     1] loss: 836.744
[46,     1] loss: 846.010
[47,     1] loss: 822.790
[48,     1] loss: 772.250
[49,     1] loss: 798.490
[50,     1] loss: 791.813
[51,     1] loss: 795.118
[52,     1] loss: 776.774
[53,     1] loss: 772.689
[54,     1] loss: 767.465
[55,     1] loss: 702.901
[56,     1] loss: 742.573
Early stopping applied (best metric=0.8321444392204285)
Finished Training
Total time taken: 9.204195261001587
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1253.064
[2,     1] loss: 1240.989
[3,     1] loss: 1238.139
[4,     1] loss: 1231.327
[5,     1] loss: 1238.370
[6,     1] loss: 1237.630
[7,     1] loss: 1225.938
[8,     1] loss: 1223.883
[9,     1] loss: 1213.282
[10,     1] loss: 1192.538
[11,     1] loss: 1175.157
[12,     1] loss: 1140.048
[13,     1] loss: 1118.598
[14,     1] loss: 1109.660
[15,     1] loss: 1090.118
[16,     1] loss: 1061.296
[17,     1] loss: 1022.841
[18,     1] loss: 1033.014
[19,     1] loss: 1023.950
[20,     1] loss: 1032.959
[21,     1] loss: 1041.399
[22,     1] loss: 1030.425
[23,     1] loss: 1024.021
[24,     1] loss: 995.592
[25,     1] loss: 1016.874
[26,     1] loss: 969.911
[27,     1] loss: 958.803
[28,     1] loss: 970.085
[29,     1] loss: 963.255
[30,     1] loss: 967.878
[31,     1] loss: 951.401
[32,     1] loss: 914.500
[33,     1] loss: 903.925
[34,     1] loss: 935.338
[35,     1] loss: 892.809
[36,     1] loss: 896.771
[37,     1] loss: 900.798
[38,     1] loss: 882.681
[39,     1] loss: 901.918
[40,     1] loss: 887.261
[41,     1] loss: 845.135
[42,     1] loss: 873.360
[43,     1] loss: 869.325
[44,     1] loss: 895.256
[45,     1] loss: 865.310
[46,     1] loss: 823.109
[47,     1] loss: 816.540
[48,     1] loss: 845.141
[49,     1] loss: 810.276
[50,     1] loss: 849.406
[51,     1] loss: 850.899
[52,     1] loss: 801.646
[53,     1] loss: 824.213
[54,     1] loss: 776.687
[55,     1] loss: 852.590
[56,     1] loss: 782.758
[57,     1] loss: 776.361
[58,     1] loss: 777.068
[59,     1] loss: 749.821
[60,     1] loss: 699.388
[61,     1] loss: 690.878
[62,     1] loss: 658.193
[63,     1] loss: 752.717
[64,     1] loss: 692.846
[65,     1] loss: 657.592
[66,     1] loss: 650.155
[67,     1] loss: 705.153
[68,     1] loss: 681.731
[69,     1] loss: 717.159
[70,     1] loss: 638.675
[71,     1] loss: 774.459
[72,     1] loss: 606.381
[73,     1] loss: 714.173
Early stopping applied (best metric=0.6764994263648987)
Finished Training
Total time taken: 11.484241962432861
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.178
[2,     1] loss: 1233.878
[3,     1] loss: 1237.996
[4,     1] loss: 1231.309
[5,     1] loss: 1231.026
[6,     1] loss: 1228.310
[7,     1] loss: 1212.031
[8,     1] loss: 1206.361
[9,     1] loss: 1182.249
[10,     1] loss: 1158.433
[11,     1] loss: 1118.889
[12,     1] loss: 1127.846
[13,     1] loss: 1091.122
[14,     1] loss: 1073.235
[15,     1] loss: 1067.465
[16,     1] loss: 1024.103
[17,     1] loss: 1042.380
[18,     1] loss: 1037.373
[19,     1] loss: 1033.125
[20,     1] loss: 991.863
[21,     1] loss: 1040.771
[22,     1] loss: 967.117
[23,     1] loss: 974.473
[24,     1] loss: 991.891
[25,     1] loss: 954.712
[26,     1] loss: 977.856
[27,     1] loss: 959.778
[28,     1] loss: 962.618
[29,     1] loss: 961.484
[30,     1] loss: 926.083
[31,     1] loss: 952.808
[32,     1] loss: 930.775
[33,     1] loss: 938.852
[34,     1] loss: 871.766
[35,     1] loss: 851.049
[36,     1] loss: 882.515
[37,     1] loss: 840.759
[38,     1] loss: 899.249
[39,     1] loss: 822.929
[40,     1] loss: 838.352
[41,     1] loss: 844.677
[42,     1] loss: 846.459
[43,     1] loss: 835.436
[44,     1] loss: 850.000
[45,     1] loss: 861.590
[46,     1] loss: 845.454
[47,     1] loss: 847.323
[48,     1] loss: 769.015
[49,     1] loss: 800.909
[50,     1] loss: 761.871
Early stopping applied (best metric=0.8538573980331421)
Finished Training
Total time taken: 7.148149728775024
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.950
[2,     1] loss: 1233.339
[3,     1] loss: 1236.189
[4,     1] loss: 1235.656
[5,     1] loss: 1235.857
[6,     1] loss: 1230.018
[7,     1] loss: 1226.250
[8,     1] loss: 1210.819
[9,     1] loss: 1191.686
[10,     1] loss: 1161.567
[11,     1] loss: 1115.844
[12,     1] loss: 1071.119
[13,     1] loss: 1043.402
[14,     1] loss: 1048.808
[15,     1] loss: 1055.896
[16,     1] loss: 1014.301
[17,     1] loss: 975.169
[18,     1] loss: 977.535
[19,     1] loss: 997.838
[20,     1] loss: 949.875
[21,     1] loss: 992.698
[22,     1] loss: 992.540
[23,     1] loss: 970.580
[24,     1] loss: 1000.725
[25,     1] loss: 974.051
[26,     1] loss: 999.819
[27,     1] loss: 1011.654
[28,     1] loss: 940.546
[29,     1] loss: 1008.723
[30,     1] loss: 986.529
[31,     1] loss: 987.829
[32,     1] loss: 991.281
[33,     1] loss: 980.325
[34,     1] loss: 927.124
[35,     1] loss: 917.959
[36,     1] loss: 905.960
[37,     1] loss: 895.227
[38,     1] loss: 916.390
[39,     1] loss: 908.095
[40,     1] loss: 917.520
[41,     1] loss: 940.191
[42,     1] loss: 846.358
[43,     1] loss: 886.400
[44,     1] loss: 820.400
[45,     1] loss: 864.769
[46,     1] loss: 822.097
[47,     1] loss: 896.878
[48,     1] loss: 820.495
[49,     1] loss: 821.592
[50,     1] loss: 823.398
[51,     1] loss: 809.000
[52,     1] loss: 795.205
[53,     1] loss: 791.021
[54,     1] loss: 775.487
[55,     1] loss: 774.406
[56,     1] loss: 782.173
[57,     1] loss: 756.144
[58,     1] loss: 738.596
[59,     1] loss: 728.541
[60,     1] loss: 777.034
[61,     1] loss: 740.742
[62,     1] loss: 699.416
[63,     1] loss: 770.846
[64,     1] loss: 750.837
[65,     1] loss: 731.299
Early stopping applied (best metric=0.8040198087692261)
Finished Training
Total time taken: 10.011211156845093
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1238.680
[2,     1] loss: 1237.016
[3,     1] loss: 1234.203
[4,     1] loss: 1236.696
[5,     1] loss: 1229.173
[6,     1] loss: 1224.656
[7,     1] loss: 1208.822
[8,     1] loss: 1186.999
[9,     1] loss: 1160.271
[10,     1] loss: 1133.348
[11,     1] loss: 1115.447
[12,     1] loss: 1057.554
[13,     1] loss: 1055.686
[14,     1] loss: 1071.985
[15,     1] loss: 1009.579
[16,     1] loss: 1066.107
[17,     1] loss: 974.583
[18,     1] loss: 1025.124
[19,     1] loss: 1010.432
[20,     1] loss: 978.523
[21,     1] loss: 985.445
[22,     1] loss: 1029.107
[23,     1] loss: 957.243
[24,     1] loss: 1030.299
[25,     1] loss: 981.469
[26,     1] loss: 976.388
[27,     1] loss: 973.202
[28,     1] loss: 935.619
[29,     1] loss: 982.342
[30,     1] loss: 947.189
[31,     1] loss: 894.053
[32,     1] loss: 915.053
[33,     1] loss: 931.218
[34,     1] loss: 886.559
[35,     1] loss: 869.903
[36,     1] loss: 843.006
[37,     1] loss: 867.568
[38,     1] loss: 869.557
[39,     1] loss: 846.005
[40,     1] loss: 825.644
[41,     1] loss: 816.035
[42,     1] loss: 828.050
[43,     1] loss: 801.898
[44,     1] loss: 813.747
[45,     1] loss: 855.398
[46,     1] loss: 829.124
[47,     1] loss: 781.071
[48,     1] loss: 763.243
[49,     1] loss: 745.984
[50,     1] loss: 779.196
[51,     1] loss: 753.213
[52,     1] loss: 748.709
[53,     1] loss: 715.365
[54,     1] loss: 763.888
[55,     1] loss: 756.562
[56,     1] loss: 669.433
[57,     1] loss: 758.082
Early stopping applied (best metric=0.8221144676208496)
Finished Training
Total time taken: 9.16219449043274
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.574
[2,     1] loss: 1241.250
[3,     1] loss: 1240.764
[4,     1] loss: 1237.452
[5,     1] loss: 1236.040
[6,     1] loss: 1233.761
[7,     1] loss: 1229.794
[8,     1] loss: 1223.828
[9,     1] loss: 1218.584
[10,     1] loss: 1208.563
[11,     1] loss: 1182.691
[12,     1] loss: 1152.932
[13,     1] loss: 1113.862
[14,     1] loss: 1086.807
[15,     1] loss: 1050.476
[16,     1] loss: 1049.452
[17,     1] loss: 1032.756
[18,     1] loss: 1051.238
[19,     1] loss: 1078.171
[20,     1] loss: 972.631
[21,     1] loss: 1061.856
[22,     1] loss: 969.330
[23,     1] loss: 1009.215
[24,     1] loss: 995.033
[25,     1] loss: 968.459
[26,     1] loss: 1025.073
[27,     1] loss: 1005.154
[28,     1] loss: 990.624
[29,     1] loss: 1025.465
[30,     1] loss: 967.051
[31,     1] loss: 968.864
[32,     1] loss: 972.136
[33,     1] loss: 942.950
[34,     1] loss: 945.352
[35,     1] loss: 954.486
[36,     1] loss: 942.292
[37,     1] loss: 893.868
[38,     1] loss: 937.626
[39,     1] loss: 855.827
[40,     1] loss: 880.497
[41,     1] loss: 884.685
[42,     1] loss: 851.965
[43,     1] loss: 864.204
[44,     1] loss: 841.618
[45,     1] loss: 867.336
[46,     1] loss: 875.326
[47,     1] loss: 815.921
[48,     1] loss: 849.791
[49,     1] loss: 855.887
[50,     1] loss: 830.867
[51,     1] loss: 871.784
[52,     1] loss: 807.118
[53,     1] loss: 755.238
[54,     1] loss: 818.662
[55,     1] loss: 766.011
[56,     1] loss: 780.956
[57,     1] loss: 751.797
[58,     1] loss: 785.958
[59,     1] loss: 727.131
[60,     1] loss: 768.808
[61,     1] loss: 686.881
[62,     1] loss: 750.383
[63,     1] loss: 721.625
[64,     1] loss: 752.917
[65,     1] loss: 721.071
[66,     1] loss: 655.190
[67,     1] loss: 652.624
[68,     1] loss: 662.887
[69,     1] loss: 633.962
[70,     1] loss: 662.083
[71,     1] loss: 615.388
[72,     1] loss: 615.331
[73,     1] loss: 633.981
[74,     1] loss: 620.859
[75,     1] loss: 580.550
[76,     1] loss: 593.226
[77,     1] loss: 600.011
[78,     1] loss: 599.214
[79,     1] loss: 642.402
Early stopping applied (best metric=0.7725855708122253)
Finished Training
Total time taken: 12.860272407531738
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1239.238
[2,     1] loss: 1239.713
[3,     1] loss: 1234.809
[4,     1] loss: 1242.529
[5,     1] loss: 1240.422
[6,     1] loss: 1232.743
[7,     1] loss: 1227.386
[8,     1] loss: 1225.132
[9,     1] loss: 1204.134
[10,     1] loss: 1189.072
[11,     1] loss: 1143.875
[12,     1] loss: 1118.816
[13,     1] loss: 1090.494
[14,     1] loss: 1067.904
[15,     1] loss: 1056.710
[16,     1] loss: 1000.200
[17,     1] loss: 1027.848
[18,     1] loss: 1042.116
[19,     1] loss: 1015.854
[20,     1] loss: 1042.520
[21,     1] loss: 1010.102
[22,     1] loss: 1024.690
[23,     1] loss: 967.840
[24,     1] loss: 1012.335
[25,     1] loss: 971.378
[26,     1] loss: 963.123
[27,     1] loss: 991.972
[28,     1] loss: 1007.778
[29,     1] loss: 976.084
[30,     1] loss: 962.424
[31,     1] loss: 924.032
[32,     1] loss: 893.235
[33,     1] loss: 932.613
[34,     1] loss: 956.115
[35,     1] loss: 914.664
[36,     1] loss: 872.945
[37,     1] loss: 915.780
[38,     1] loss: 876.397
[39,     1] loss: 880.399
[40,     1] loss: 876.652
[41,     1] loss: 882.374
[42,     1] loss: 834.643
[43,     1] loss: 816.814
[44,     1] loss: 888.158
[45,     1] loss: 808.180
[46,     1] loss: 829.514
[47,     1] loss: 832.183
[48,     1] loss: 847.467
[49,     1] loss: 813.392
[50,     1] loss: 855.575
[51,     1] loss: 770.392
[52,     1] loss: 806.030
[53,     1] loss: 742.905
[54,     1] loss: 778.713
[55,     1] loss: 699.972
[56,     1] loss: 745.882
[57,     1] loss: 725.507
[58,     1] loss: 720.331
[59,     1] loss: 763.576
[60,     1] loss: 686.848
[61,     1] loss: 678.952
[62,     1] loss: 776.820
[63,     1] loss: 667.828
[64,     1] loss: 716.278
[65,     1] loss: 686.418
[66,     1] loss: 764.063
[67,     1] loss: 683.244
[68,     1] loss: 722.698
[69,     1] loss: 661.082
[70,     1] loss: 631.575
[71,     1] loss: 662.476
[72,     1] loss: 640.155
[73,     1] loss: 652.026
[74,     1] loss: 578.863
[75,     1] loss: 652.926
[76,     1] loss: 593.546
[77,     1] loss: 584.794
[78,     1] loss: 552.389
[79,     1] loss: 640.351
[80,     1] loss: 589.891
[81,     1] loss: 561.755
Early stopping applied (best metric=0.8136332035064697)
Finished Training
Total time taken: 13.061275243759155
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.194
[2,     1] loss: 1236.620
[3,     1] loss: 1233.506
[4,     1] loss: 1234.262
[5,     1] loss: 1232.442
[6,     1] loss: 1225.984
[7,     1] loss: 1213.360
[8,     1] loss: 1192.751
[9,     1] loss: 1161.066
[10,     1] loss: 1119.770
[11,     1] loss: 1082.859
[12,     1] loss: 1041.167
[13,     1] loss: 1012.937
[14,     1] loss: 984.436
[15,     1] loss: 1046.822
[16,     1] loss: 1021.980
[17,     1] loss: 1010.236
[18,     1] loss: 1019.182
[19,     1] loss: 961.677
[20,     1] loss: 945.076
[21,     1] loss: 955.167
[22,     1] loss: 982.215
[23,     1] loss: 968.288
[24,     1] loss: 960.978
[25,     1] loss: 910.581
[26,     1] loss: 922.831
[27,     1] loss: 918.206
[28,     1] loss: 976.734
[29,     1] loss: 838.756
[30,     1] loss: 945.091
[31,     1] loss: 879.400
[32,     1] loss: 903.652
[33,     1] loss: 904.629
[34,     1] loss: 857.029
[35,     1] loss: 898.714
[36,     1] loss: 865.270
[37,     1] loss: 802.952
[38,     1] loss: 928.408
[39,     1] loss: 872.477
[40,     1] loss: 887.354
[41,     1] loss: 882.699
[42,     1] loss: 852.481
[43,     1] loss: 812.079
[44,     1] loss: 845.817
[45,     1] loss: 809.155
[46,     1] loss: 839.816
[47,     1] loss: 825.604
[48,     1] loss: 859.372
[49,     1] loss: 814.781
[50,     1] loss: 839.802
[51,     1] loss: 817.620
[52,     1] loss: 761.166
[53,     1] loss: 843.097
[54,     1] loss: 734.124
[55,     1] loss: 780.317
[56,     1] loss: 763.534
[57,     1] loss: 700.728
[58,     1] loss: 762.750
[59,     1] loss: 696.339
[60,     1] loss: 701.008
[61,     1] loss: 661.834
[62,     1] loss: 696.867
[63,     1] loss: 639.910
[64,     1] loss: 639.022
[65,     1] loss: 690.953
[66,     1] loss: 652.184
[67,     1] loss: 656.528
[68,     1] loss: 639.455
[69,     1] loss: 596.757
[70,     1] loss: 637.204
[71,     1] loss: 597.358
[72,     1] loss: 626.246
[73,     1] loss: 715.968
[74,     1] loss: 669.251
[75,     1] loss: 629.315
[76,     1] loss: 652.873
[77,     1] loss: 622.580
[78,     1] loss: 600.567
[79,     1] loss: 589.902
[80,     1] loss: 611.495
[81,     1] loss: 679.393
[82,     1] loss: 514.099
[83,     1] loss: 566.982
[84,     1] loss: 537.505
[85,     1] loss: 665.113
[86,     1] loss: 507.651
[87,     1] loss: 663.247
[88,     1] loss: 533.441
[89,     1] loss: 579.856
[90,     1] loss: 506.250
[91,     1] loss: 576.454
[92,     1] loss: 550.719
[93,     1] loss: 616.097
[94,     1] loss: 468.526
[95,     1] loss: 554.160
[96,     1] loss: 530.496
[97,     1] loss: 482.189
[98,     1] loss: 476.456
[99,     1] loss: 488.985
[100,     1] loss: 476.623
[101,     1] loss: 469.934
[102,     1] loss: 460.378
[103,     1] loss: 449.842
[104,     1] loss: 403.040
[105,     1] loss: 486.265
[106,     1] loss: 426.332
[107,     1] loss: 493.761
[108,     1] loss: 477.717
[109,     1] loss: 403.612
[110,     1] loss: 462.648
[111,     1] loss: 434.428
[112,     1] loss: 498.320
[113,     1] loss: 453.884
[114,     1] loss: 457.310
[115,     1] loss: 412.467
[116,     1] loss: 438.252
[117,     1] loss: 419.507
[118,     1] loss: 404.781
[119,     1] loss: 359.481
[120,     1] loss: 376.219
Early stopping applied (best metric=0.8032026290893555)
Finished Training
Total time taken: 18.15338444709778
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.521
[2,     1] loss: 1239.948
[3,     1] loss: 1234.722
[4,     1] loss: 1238.076
[5,     1] loss: 1236.310
[6,     1] loss: 1235.125
[7,     1] loss: 1232.527
[8,     1] loss: 1227.314
[9,     1] loss: 1221.416
[10,     1] loss: 1208.012
[11,     1] loss: 1183.455
[12,     1] loss: 1152.264
[13,     1] loss: 1140.976
[14,     1] loss: 1093.422
[15,     1] loss: 1072.125
[16,     1] loss: 1108.892
[17,     1] loss: 1055.916
[18,     1] loss: 1057.919
[19,     1] loss: 1025.117
[20,     1] loss: 1032.711
[21,     1] loss: 1000.308
[22,     1] loss: 1027.159
[23,     1] loss: 1019.627
[24,     1] loss: 978.913
[25,     1] loss: 988.278
[26,     1] loss: 1021.135
[27,     1] loss: 991.231
[28,     1] loss: 992.212
[29,     1] loss: 982.452
[30,     1] loss: 948.490
[31,     1] loss: 960.903
[32,     1] loss: 932.241
[33,     1] loss: 890.626
[34,     1] loss: 960.484
[35,     1] loss: 933.297
[36,     1] loss: 896.613
[37,     1] loss: 920.791
[38,     1] loss: 869.526
[39,     1] loss: 860.287
Early stopping applied (best metric=0.8626730442047119)
Finished Training
Total time taken: 6.4781341552734375
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1245.635
[2,     1] loss: 1235.767
[3,     1] loss: 1235.649
[4,     1] loss: 1234.110
[5,     1] loss: 1239.584
[6,     1] loss: 1230.563
[7,     1] loss: 1229.719
[8,     1] loss: 1221.248
[9,     1] loss: 1205.948
[10,     1] loss: 1181.874
[11,     1] loss: 1157.306
[12,     1] loss: 1134.910
[13,     1] loss: 1094.563
[14,     1] loss: 1078.607
[15,     1] loss: 1087.245
[16,     1] loss: 1039.985
[17,     1] loss: 1053.698
[18,     1] loss: 1043.160
[19,     1] loss: 1065.787
[20,     1] loss: 1074.244
[21,     1] loss: 1034.441
[22,     1] loss: 995.869
[23,     1] loss: 1038.509
[24,     1] loss: 990.880
[25,     1] loss: 1003.378
[26,     1] loss: 1036.727
[27,     1] loss: 971.507
[28,     1] loss: 960.510
[29,     1] loss: 962.740
[30,     1] loss: 978.471
[31,     1] loss: 922.999
[32,     1] loss: 926.876
[33,     1] loss: 970.481
[34,     1] loss: 944.768
[35,     1] loss: 921.883
[36,     1] loss: 906.867
[37,     1] loss: 943.598
[38,     1] loss: 904.930
[39,     1] loss: 924.500
[40,     1] loss: 891.773
[41,     1] loss: 880.012
[42,     1] loss: 847.608
[43,     1] loss: 845.793
[44,     1] loss: 865.878
[45,     1] loss: 826.643
[46,     1] loss: 845.712
[47,     1] loss: 800.698
[48,     1] loss: 812.290
[49,     1] loss: 774.789
[50,     1] loss: 786.622
[51,     1] loss: 790.379
[52,     1] loss: 756.104
[53,     1] loss: 741.325
[54,     1] loss: 775.339
[55,     1] loss: 795.538
[56,     1] loss: 789.496
[57,     1] loss: 735.884
[58,     1] loss: 704.993
[59,     1] loss: 688.724
[60,     1] loss: 690.052
[61,     1] loss: 690.605
[62,     1] loss: 715.447
[63,     1] loss: 751.373
[64,     1] loss: 741.818
[65,     1] loss: 693.661
Early stopping applied (best metric=0.736119270324707)
Finished Training
Total time taken: 10.655227422714233
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1249.953
[2,     1] loss: 1239.004
[3,     1] loss: 1239.448
[4,     1] loss: 1237.832
[5,     1] loss: 1237.080
[6,     1] loss: 1233.435
[7,     1] loss: 1231.762
[8,     1] loss: 1225.753
[9,     1] loss: 1218.923
[10,     1] loss: 1209.261
[11,     1] loss: 1200.837
[12,     1] loss: 1167.582
[13,     1] loss: 1140.718
[14,     1] loss: 1132.249
[15,     1] loss: 1101.637
[16,     1] loss: 1056.637
[17,     1] loss: 1040.743
[18,     1] loss: 1084.709
[19,     1] loss: 1047.510
[20,     1] loss: 1023.564
[21,     1] loss: 1066.031
[22,     1] loss: 1031.746
[23,     1] loss: 982.431
[24,     1] loss: 1025.474
[25,     1] loss: 1006.652
[26,     1] loss: 980.322
[27,     1] loss: 995.151
[28,     1] loss: 961.787
[29,     1] loss: 942.317
[30,     1] loss: 922.778
[31,     1] loss: 925.211
[32,     1] loss: 954.790
[33,     1] loss: 947.422
[34,     1] loss: 905.701
[35,     1] loss: 909.270
[36,     1] loss: 891.616
[37,     1] loss: 886.558
[38,     1] loss: 895.964
[39,     1] loss: 888.470
[40,     1] loss: 860.767
[41,     1] loss: 867.111
[42,     1] loss: 870.738
[43,     1] loss: 855.846
[44,     1] loss: 833.842
[45,     1] loss: 795.818
[46,     1] loss: 805.370
[47,     1] loss: 769.245
[48,     1] loss: 778.864
Early stopping applied (best metric=0.8622840642929077)
Finished Training
Total time taken: 7.768162488937378
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1243.554
[2,     1] loss: 1236.961
[3,     1] loss: 1239.065
[4,     1] loss: 1237.739
[5,     1] loss: 1233.961
[6,     1] loss: 1226.649
[7,     1] loss: 1215.678
[8,     1] loss: 1203.643
[9,     1] loss: 1175.350
[10,     1] loss: 1146.155
[11,     1] loss: 1114.529
[12,     1] loss: 1107.181
[13,     1] loss: 1096.437
[14,     1] loss: 1081.964
[15,     1] loss: 1043.772
[16,     1] loss: 1068.150
[17,     1] loss: 1031.519
[18,     1] loss: 1023.417
[19,     1] loss: 1026.054
[20,     1] loss: 990.296
[21,     1] loss: 1034.001
[22,     1] loss: 991.811
[23,     1] loss: 971.734
[24,     1] loss: 1006.816
[25,     1] loss: 992.481
[26,     1] loss: 976.412
[27,     1] loss: 1010.041
[28,     1] loss: 953.141
[29,     1] loss: 932.683
[30,     1] loss: 958.688
[31,     1] loss: 947.404
[32,     1] loss: 930.702
[33,     1] loss: 928.933
[34,     1] loss: 939.673
[35,     1] loss: 907.723
[36,     1] loss: 889.870
[37,     1] loss: 895.193
[38,     1] loss: 913.872
[39,     1] loss: 909.909
[40,     1] loss: 886.710
[41,     1] loss: 851.905
[42,     1] loss: 889.977
[43,     1] loss: 800.329
[44,     1] loss: 871.067
[45,     1] loss: 864.995
[46,     1] loss: 877.185
[47,     1] loss: 829.534
[48,     1] loss: 819.239
[49,     1] loss: 843.456
[50,     1] loss: 820.807
[51,     1] loss: 805.057
[52,     1] loss: 833.460
[53,     1] loss: 802.793
[54,     1] loss: 774.118
[55,     1] loss: 741.150
[56,     1] loss: 751.399
[57,     1] loss: 730.254
[58,     1] loss: 767.709
[59,     1] loss: 692.782
[60,     1] loss: 762.084
[61,     1] loss: 696.958
[62,     1] loss: 690.677
Early stopping applied (best metric=0.7994612455368042)
Finished Training
Total time taken: 8.815184354782104
{'Hydroxylation-K Validation Accuracy': 0.7799940898345153, 'Hydroxylation-K Validation Sensitivity': 0.6644444444444445, 'Hydroxylation-K Validation Specificity': 0.8087719298245614, 'Hydroxylation-K Validation Precision': 0.46695036989154637, 'Hydroxylation-K AUC ROC': 0.8081676413255361, 'Hydroxylation-K AUC PR': 0.6102432609148402, 'Hydroxylation-K MCC': 0.4203648771875934, 'Hydroxylation-K F1': 0.5451752163422644, 'Validation Loss (Hydroxylation-K)': 0.4252151628335317, 'Hydroxylation-P Validation Accuracy': 0.7856177520599631, 'Hydroxylation-P Validation Sensitivity': 0.7994708994708994, 'Hydroxylation-P Validation Specificity': 0.782672452491396, 'Hydroxylation-P Validation Precision': 0.44709090127358897, 'Hydroxylation-P AUC ROC': 0.8580423102288283, 'Hydroxylation-P AUC PR': 0.599815706009122, 'Hydroxylation-P MCC': 0.4794078581009972, 'Hydroxylation-P F1': 0.5706468390132616, 'Validation Loss (Hydroxylation-P)': 0.371938955783844, 'Validation Loss (total)': 0.7971541206041972, 'TimeToTrain': 10.556555970509846}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007771178936896513,
 'learning_rate_Hydroxylation-K': 0.00036858735551100526,
 'learning_rate_Hydroxylation-P': 0.0069933791570922985,
 'log_base': 2.5515361454495498,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1233696860,
 'sample_weights': [1.5580067110017504, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.597671248054143,
 'weight_decay_Hydroxylation-K': 0.8261899737168179,
 'weight_decay_Hydroxylation-P': 5.336934256890433}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1286.886
[2,     1] loss: 1283.653
[3,     1] loss: 1285.132
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001220124034015386,
 'learning_rate_Hydroxylation-K': 0.004111067744042622,
 'learning_rate_Hydroxylation-P': 0.0001200114290475264,
 'log_base': 1.5129004173565632,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3489293286,
 'sample_weights': [1.7822686144920545, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7500892670006083,
 'weight_decay_Hydroxylation-K': 3.1216598113509226,
 'weight_decay_Hydroxylation-P': 4.1892692461283865}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1763.803
[2,     1] loss: 1756.429
[3,     1] loss: 1759.506
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004607103020387047,
 'learning_rate_Hydroxylation-K': 0.003227804841306571,
 'learning_rate_Hydroxylation-P': 0.00805403431914527,
 'log_base': 1.0890755025103322,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3066418675,
 'sample_weights': [4.032192675619611, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8833111694718246,
 'weight_decay_Hydroxylation-K': 1.101479067350573,
 'weight_decay_Hydroxylation-P': 1.2466123349142144}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 6354.791
[2,     1] loss: 6362.522
[3,     1] loss: 6362.904
[4,     1] loss: 6348.094
[5,     1] loss: 6351.265
[6,     1] loss: 6338.068
[7,     1] loss: 6302.149
[8,     1] loss: 6313.920
[9,     1] loss: 6315.151
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00412243072434803,
 'learning_rate_Hydroxylation-K': 0.0003403514966053931,
 'learning_rate_Hydroxylation-P': 0.008568502781767028,
 'log_base': 1.045562651676395,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 771315603,
 'sample_weights': [19.564740623810103, 2.4456867920229595],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.0655871874977,
 'weight_decay_Hydroxylation-K': 1.1469725995343953,
 'weight_decay_Hydroxylation-P': 3.7815362218142328}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 12177.490
[2,     1] loss: 12160.485
[3,     1] loss: 12215.882
[4,     1] loss: 12178.078
[5,     1] loss: 12159.259
[6,     1] loss: 12097.664
[7,     1] loss: 12036.994
[8,     1] loss: 12224.926
[9,     1] loss: 12016.639
[10,     1] loss: 11926.558
[11,     1] loss: 11543.065
[12,     1] loss: 11685.873
[13,     1] loss: 11013.488
[14,     1] loss: 10892.797
[15,     1] loss: 10688.954
[16,     1] loss: 10601.904
[17,     1] loss: 10494.407
[18,     1] loss: 10826.865
[19,     1] loss: 9979.265
[20,     1] loss: 9770.294
[21,     1] loss: 9665.452
[22,     1] loss: 9653.165
[23,     1] loss: 9913.948
[24,     1] loss: 9281.402
[25,     1] loss: 9782.897
[26,     1] loss: 9460.967
[27,     1] loss: 9468.189
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008274898590431045,
 'learning_rate_Hydroxylation-K': 0.0008070354639310583,
 'learning_rate_Hydroxylation-P': 0.00017724301487298725,
 'log_base': 2.2845544973184815,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1947429761,
 'sample_weights': [37.46912879263424, 4.683821531742182],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.225726463881683,
 'weight_decay_Hydroxylation-K': 2.3507192458504456,
 'weight_decay_Hydroxylation-P': 0.5410973250675921}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1335.668
[2,     1] loss: 1335.672
[3,     1] loss: 1334.120
[4,     1] loss: 1350.107
[5,     1] loss: 1331.047
[6,     1] loss: 1342.949
[7,     1] loss: 1324.888
[8,     1] loss: 1317.833
[9,     1] loss: 1317.453
[10,     1] loss: 1296.334
[11,     1] loss: 1262.208
[12,     1] loss: 1228.515
[13,     1] loss: 1129.501
[14,     1] loss: 1113.233
[15,     1] loss: 1142.037
[16,     1] loss: 1092.845
[17,     1] loss: 1072.395
[18,     1] loss: 1051.696
[19,     1] loss: 1072.462
[20,     1] loss: 1040.766
[21,     1] loss: 1037.111
[22,     1] loss: 1029.622
[23,     1] loss: 1114.879
[24,     1] loss: 1051.974
[25,     1] loss: 1018.986
[26,     1] loss: 1085.612
[27,     1] loss: 988.331
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009946922141828013,
 'learning_rate_Hydroxylation-K': 0.007720171600852054,
 'learning_rate_Hydroxylation-P': 0.0022233623143804926,
 'log_base': 2.207121817724022,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1142566149,
 'sample_weights': [2.0206991926427955, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.435966653657524,
 'weight_decay_Hydroxylation-K': 4.767141288187746,
 'weight_decay_Hydroxylation-P': 5.911898439011529}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1363.312
[2,     1] loss: 1375.336
[3,     1] loss: 1392.957
[4,     1] loss: 1353.659
[5,     1] loss: 1351.992
[6,     1] loss: 1355.192
[7,     1] loss: 1351.561
[8,     1] loss: 1354.134
[9,     1] loss: 1359.495
[10,     1] loss: 1350.234
[11,     1] loss: 1352.680
[12,     1] loss: 1352.134
[13,     1] loss: 1354.689
[14,     1] loss: 1351.078
[15,     1] loss: 1352.411
[16,     1] loss: 1352.803
[17,     1] loss: 1352.198
[18,     1] loss: 1353.677
[19,     1] loss: 1354.968
[20,     1] loss: 1350.729
[21,     1] loss: 1352.555
[22,     1] loss: 1352.197
[23,     1] loss: 1352.385
[24,     1] loss: 1352.733
[25,     1] loss: 1352.186
[26,     1] loss: 1352.102
[27,     1] loss: 1351.335
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005162643802602026,
 'learning_rate_Hydroxylation-K': 0.0012808130733465667,
 'learning_rate_Hydroxylation-P': 0.008547390923158295,
 'log_base': 1.4731545953919218,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2519494870,
 'sample_weights': [2.1087099464539025, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.6301609514033855,
 'weight_decay_Hydroxylation-K': 1.5359572481991688,
 'weight_decay_Hydroxylation-P': 3.450085322595858}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1822.553
[2,     1] loss: 1823.971
[3,     1] loss: 1815.608
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 6.585389173847109e-05,
 'learning_rate_Hydroxylation-K': 0.0025848512563057917,
 'learning_rate_Hydroxylation-P': 0.0089718392687682,
 'log_base': 2.598489906401091,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3883493710,
 'sample_weights': [4.309284787412952, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.490622251762759,
 'weight_decay_Hydroxylation-K': 0.9328396187856691,
 'weight_decay_Hydroxylation-P': 3.8133768914521555}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1276.016
[2,     1] loss: 1276.121
[3,     1] loss: 1276.055
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007081932247484761,
 'learning_rate_Hydroxylation-K': 0.0008516832046746535,
 'learning_rate_Hydroxylation-P': 0.007567906315237986,
 'log_base': 1.678825307079121,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1512728985,
 'sample_weights': [1.7482352883376577, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.896766574469584,
 'weight_decay_Hydroxylation-K': 0.7146418772099367,
 'weight_decay_Hydroxylation-P': 4.184526978413148}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1592.727
[2,     1] loss: 1588.416
[3,     1] loss: 1590.893
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00413545373648086,
 'learning_rate_Hydroxylation-K': 0.0057185553561919025,
 'learning_rate_Hydroxylation-P': 0.009259366993110281,
 'log_base': 1.2219984804262596,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4281318974,
 'sample_weights': [3.2222764482163098, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.709484188610986,
 'weight_decay_Hydroxylation-K': 0.6143203352027865,
 'weight_decay_Hydroxylation-P': 6.609780231767442}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2716.046
[2,     1] loss: 2743.573
[3,     1] loss: 2710.033
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0044207060357459105,
 'learning_rate_Hydroxylation-K': 0.004517587305930689,
 'learning_rate_Hydroxylation-P': 0.007773551167187652,
 'log_base': 1.1964445414108735,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3156372082,
 'sample_weights': [8.326914003209586, 1.0409043486718486],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.70661208815916,
 'weight_decay_Hydroxylation-K': 5.7341904043163785,
 'weight_decay_Hydroxylation-P': 6.913337689279732}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3033.270
[2,     1] loss: 3039.625
[3,     1] loss: 3023.618
[4,     1] loss: 3020.286
[5,     1] loss: 3015.804
[6,     1] loss: 3003.388
[7,     1] loss: 2992.514
[8,     1] loss: 2970.923
[9,     1] loss: 2886.899
[10,     1] loss: 2846.584
[11,     1] loss: 2748.017
[12,     1] loss: 2608.764
[13,     1] loss: 2529.492
[14,     1] loss: 2543.742
[15,     1] loss: 2570.253
[16,     1] loss: 2309.520
[17,     1] loss: 2532.681
[18,     1] loss: 2556.553
[19,     1] loss: 2422.229
[20,     1] loss: 2313.067
[21,     1] loss: 2259.700
[22,     1] loss: 2144.924
[23,     1] loss: 2314.116
[24,     1] loss: 2039.415
[25,     1] loss: 2435.508
[26,     1] loss: 2090.042
[27,     1] loss: 2087.528
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019011053906562432,
 'learning_rate_Hydroxylation-K': 0.00296394454791332,
 'learning_rate_Hydroxylation-P': 0.0038649963827845726,
 'log_base': 2.6210098750398543,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1811001056,
 'sample_weights': [9.308075497070755, 1.163554260189585],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.772770180976186,
 'weight_decay_Hydroxylation-K': 6.2787530019865025,
 'weight_decay_Hydroxylation-P': 6.737475655185493}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1275.347
[2,     1] loss: 1275.311
[3,     1] loss: 1280.968
[4,     1] loss: 1273.061
[5,     1] loss: 1276.730
[6,     1] loss: 1274.009
[7,     1] loss: 1271.807
[8,     1] loss: 1270.559
[9,     1] loss: 1269.888
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012848806561354615,
 'learning_rate_Hydroxylation-K': 0.00033937660518408477,
 'learning_rate_Hydroxylation-P': 0.00820384194484953,
 'log_base': 1.1195522885134472,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3681802632,
 'sample_weights': [1.732578854524968, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.6634847174365195,
 'weight_decay_Hydroxylation-K': 2.8407841881764178,
 'weight_decay_Hydroxylation-P': 7.16570491750013}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 4828.469
[2,     1] loss: 4781.633
[3,     1] loss: 4799.745
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007419396153353444,
 'learning_rate_Hydroxylation-K': 0.003487239924950958,
 'learning_rate_Hydroxylation-P': 0.005475698740858977,
 'log_base': 2.934524009663903,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3468537372,
 'sample_weights': [14.783139608617528, 1.847963639314857],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.898259774912162,
 'weight_decay_Hydroxylation-K': 0.5620474975469625,
 'weight_decay_Hydroxylation-P': 3.6932884143576397}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.435
[2,     1] loss: 1236.351
[3,     1] loss: 1234.049
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004561737696270237,
 'learning_rate_Hydroxylation-K': 0.0018067181297863994,
 'learning_rate_Hydroxylation-P': 0.0075552107418595405,
 'log_base': 2.9761202996465013,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2281197253,
 'sample_weights': [1.5507412507835572, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5667361715101664,
 'weight_decay_Hydroxylation-K': 3.81249496757858,
 'weight_decay_Hydroxylation-P': 0.6621673069816398}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.946
[2,     1] loss: 1233.968
[3,     1] loss: 1228.906
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00230526496178472,
 'learning_rate_Hydroxylation-K': 5.941940227110256e-05,
 'learning_rate_Hydroxylation-P': 0.007213634505361263,
 'log_base': 1.0974884469553938,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1107592957,
 'sample_weights': [1.5307277710982659, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3983651734357827,
 'weight_decay_Hydroxylation-K': 0.842494176812687,
 'weight_decay_Hydroxylation-P': 2.6577095918350393}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 5826.592
[2,     1] loss: 5823.637
[3,     1] loss: 5830.670
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028897098999149454,
 'learning_rate_Hydroxylation-K': 0.0018837258202651995,
 'learning_rate_Hydroxylation-P': 0.0072302367756286335,
 'log_base': 1.0341565894953453,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 216696375,
 'sample_weights': [17.94630482116729, 2.2433745231118376],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.33032840570536,
 'weight_decay_Hydroxylation-K': 3.262931998936019,
 'weight_decay_Hydroxylation-P': 2.9693576410296902}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16067.297
Exploding loss, terminate run (best metric=1.1078232526779175)
Finished Training
Total time taken: 0.2360091209411621
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16111.344
Exploding loss, terminate run (best metric=1.105212688446045)
Finished Training
Total time taken: 0.23700428009033203
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16167.170
Exploding loss, terminate run (best metric=1.0946705341339111)
Finished Training
Total time taken: 0.23200726509094238
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16202.119
Exploding loss, terminate run (best metric=1.0728362798690796)
Finished Training
Total time taken: 0.2290041446685791
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 16206.318
Exploding loss, terminate run (best metric=1.0753614902496338)
Finished Training
Total time taken: 0.21500468254089355
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16186.153
Exploding loss, terminate run (best metric=1.1002987623214722)
Finished Training
Total time taken: 0.1990044116973877
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16159.164
Exploding loss, terminate run (best metric=1.0916365385055542)
Finished Training
Total time taken: 0.2180042266845703
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16118.521
Exploding loss, terminate run (best metric=1.0933690071105957)
Finished Training
Total time taken: 0.21900439262390137
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16139.567
Exploding loss, terminate run (best metric=1.0782344341278076)
Finished Training
Total time taken: 0.2140061855316162
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 16110.096
Exploding loss, terminate run (best metric=1.0818092823028564)
Finished Training
Total time taken: 0.20200276374816895
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16141.570
Exploding loss, terminate run (best metric=1.0976154804229736)
Finished Training
Total time taken: 0.2160046100616455
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16087.562
Exploding loss, terminate run (best metric=1.0970265865325928)
Finished Training
Total time taken: 0.2140045166015625
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16056.859
Exploding loss, terminate run (best metric=1.090933084487915)
Finished Training
Total time taken: 0.23000645637512207
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16140.584
Exploding loss, terminate run (best metric=1.0867317914962769)
Finished Training
Total time taken: 0.2160031795501709
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 16213.590
Exploding loss, terminate run (best metric=1.0749841928482056)
Finished Training
Total time taken: 0.20400404930114746
{'Hydroxylation-K Validation Accuracy': 0.6065602836879432, 'Hydroxylation-K Validation Sensitivity': 0.35555555555555557, 'Hydroxylation-K Validation Specificity': 0.6701754385964912, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.6840740740740741, 'Hydroxylation-K AUC PR': 0.41400816168491195, 'Hydroxylation-K MCC': 0.03733336135393236, 'Hydroxylation-K F1': 0.14380482887314378, 'Validation Loss (Hydroxylation-K)': 0.5572097500165304, 'Hydroxylation-P Validation Accuracy': 0.5975697341928498, 'Hydroxylation-P Validation Sensitivity': 0.3580952380952381, 'Hydroxylation-P Validation Specificity': 0.6490248890218964, 'Hydroxylation-P Validation Precision': nan, 'Hydroxylation-P AUC ROC': 0.6127877800579058, 'Hydroxylation-P AUC PR': 0.2853181741793283, 'Hydroxylation-P MCC': 0.008444902352833728, 'Hydroxylation-P F1': 0.11811289634713157, 'Validation Loss (Hydroxylation-P)': 0.5326931556065877, 'Validation Loss (total)': 1.089902893702189, 'TimeToTrain': 0.21873828570048015}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007943280882309263,
 'learning_rate_Hydroxylation-K': 0.009337398939602988,
 'learning_rate_Hydroxylation-P': 0.0052975982748722054,
 'log_base': 2.210234402018247,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1249340703,
 'sample_weights': [49.74308740178259, 6.204966256848178],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.595576338180795,
 'weight_decay_Hydroxylation-K': 1.982602651818025,
 'weight_decay_Hydroxylation-P': 0.8515642754443975}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1364.331
[2,     1] loss: 1376.842
[3,     1] loss: 1354.849
[4,     1] loss: 1355.006
[5,     1] loss: 1351.990
[6,     1] loss: 1351.213
[7,     1] loss: 1355.347
[8,     1] loss: 1351.823
[9,     1] loss: 1353.586
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004902849840559611,
 'learning_rate_Hydroxylation-K': 0.0016931427002510962,
 'learning_rate_Hydroxylation-P': 0.006080688457424108,
 'log_base': 2.7501569681145415,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2356322566,
 'sample_weights': [2.104962991740751, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.738469393338825,
 'weight_decay_Hydroxylation-K': 1.2549681597937572,
 'weight_decay_Hydroxylation-P': 4.166540123456371}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1260.322
[2,     1] loss: 1255.689
[3,     1] loss: 1257.351
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019453863599893163,
 'learning_rate_Hydroxylation-K': 0.0007056792796468047,
 'learning_rate_Hydroxylation-P': 0.005948367817326082,
 'log_base': 1.039875168973225,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1176622863,
 'sample_weights': [1.6502050742201655, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.752868082145572,
 'weight_decay_Hydroxylation-K': 3.8380215904533825,
 'weight_decay_Hydroxylation-P': 4.140526039439289}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 13853.100
[2,     1] loss: 13860.012
[3,     1] loss: 13892.111
[4,     1] loss: 13874.844
[5,     1] loss: 13807.931
[6,     1] loss: 13793.842
[7,     1] loss: 13793.775
[8,     1] loss: 13772.518
[9,     1] loss: 13688.151
[10,     1] loss: 13605.731
[11,     1] loss: 13508.834
[12,     1] loss: 13274.762
[13,     1] loss: 13109.203
[14,     1] loss: 12590.486
[15,     1] loss: 12655.375
[16,     1] loss: 12451.949
[17,     1] loss: 11671.069
[18,     1] loss: 11872.736
[19,     1] loss: 11128.313
[20,     1] loss: 11149.701
[21,     1] loss: 10879.084
[22,     1] loss: 10830.791
[23,     1] loss: 11070.334
[24,     1] loss: 10772.636
[25,     1] loss: 10838.943
[26,     1] loss: 10850.398
[27,     1] loss: 10800.015
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005320649683517856,
 'learning_rate_Hydroxylation-K': 0.00021195336390398244,
 'learning_rate_Hydroxylation-P': 0.005171159889821629,
 'log_base': 1.5926393925272107,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1525177100,
 'sample_weights': [42.69601739070448, 5.3372077765932175],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.895818122938829,
 'weight_decay_Hydroxylation-K': 3.250763618752391,
 'weight_decay_Hydroxylation-P': 0.2385998568479275}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1662.837
[2,     1] loss: 1665.327
[3,     1] loss: 1667.958
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002531446629466185,
 'learning_rate_Hydroxylation-K': 0.003995489758050822,
 'learning_rate_Hydroxylation-P': 0.003777712030908447,
 'log_base': 2.6088905840022494,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1936564063,
 'sample_weights': [3.5871713923459354, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.663180802628403,
 'weight_decay_Hydroxylation-K': 2.914149538650792,
 'weight_decay_Hydroxylation-P': 5.343624155231423}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1280.483
[2,     1] loss: 1278.009
[3,     1] loss: 1278.646
[4,     1] loss: 1273.630
[5,     1] loss: 1273.616
[6,     1] loss: 1269.872
[7,     1] loss: 1256.685
[8,     1] loss: 1237.335
[9,     1] loss: 1201.945
[10,     1] loss: 1176.438
[11,     1] loss: 1159.250
[12,     1] loss: 1095.978
[13,     1] loss: 1076.318
[14,     1] loss: 1073.702
[15,     1] loss: 1063.871
[16,     1] loss: 1053.062
[17,     1] loss: 1037.902
[18,     1] loss: 1026.715
[19,     1] loss: 1032.144
[20,     1] loss: 1017.864
[21,     1] loss: 1039.665
[22,     1] loss: 1011.930
[23,     1] loss: 986.495
[24,     1] loss: 983.381
[25,     1] loss: 986.615
[26,     1] loss: 956.743
[27,     1] loss: 902.024
[28,     1] loss: 932.582
[29,     1] loss: 909.194
[30,     1] loss: 900.515
[31,     1] loss: 943.717
[32,     1] loss: 1003.253
[33,     1] loss: 936.073
[34,     1] loss: 973.960
[35,     1] loss: 943.961
[36,     1] loss: 928.316
[37,     1] loss: 881.198
[38,     1] loss: 917.377
[39,     1] loss: 840.987
[40,     1] loss: 904.594
[41,     1] loss: 841.362
[42,     1] loss: 896.845
[43,     1] loss: 845.154
[44,     1] loss: 855.186
[45,     1] loss: 828.830
[46,     1] loss: 818.291
[47,     1] loss: 807.756
[48,     1] loss: 895.433
[49,     1] loss: 827.469
[50,     1] loss: 806.221
[51,     1] loss: 836.521
[52,     1] loss: 792.791
[53,     1] loss: 849.291
[54,     1] loss: 814.689
[55,     1] loss: 746.863
[56,     1] loss: 739.408
[57,     1] loss: 717.675
[58,     1] loss: 778.889
[59,     1] loss: 660.725
[60,     1] loss: 708.601
Early stopping applied (best metric=0.7816275358200073)
Finished Training
Total time taken: 9.112195491790771
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1289.099
[2,     1] loss: 1276.950
[3,     1] loss: 1284.938
[4,     1] loss: 1276.999
[5,     1] loss: 1274.647
[6,     1] loss: 1275.100
[7,     1] loss: 1274.953
[8,     1] loss: 1271.307
[9,     1] loss: 1268.220
[10,     1] loss: 1266.467
[11,     1] loss: 1255.688
[12,     1] loss: 1242.120
[13,     1] loss: 1223.693
[14,     1] loss: 1199.336
[15,     1] loss: 1182.851
[16,     1] loss: 1148.174
[17,     1] loss: 1152.653
[18,     1] loss: 1114.050
[19,     1] loss: 1094.599
[20,     1] loss: 1049.148
[21,     1] loss: 1033.261
[22,     1] loss: 1033.533
[23,     1] loss: 1007.314
[24,     1] loss: 1051.946
[25,     1] loss: 983.177
[26,     1] loss: 1038.816
[27,     1] loss: 985.122
[28,     1] loss: 969.087
[29,     1] loss: 956.489
[30,     1] loss: 960.667
[31,     1] loss: 954.285
[32,     1] loss: 974.704
[33,     1] loss: 921.734
[34,     1] loss: 908.757
[35,     1] loss: 912.848
[36,     1] loss: 946.122
[37,     1] loss: 867.466
[38,     1] loss: 899.118
[39,     1] loss: 967.228
[40,     1] loss: 885.474
[41,     1] loss: 943.332
[42,     1] loss: 873.272
[43,     1] loss: 947.053
[44,     1] loss: 845.462
[45,     1] loss: 848.024
[46,     1] loss: 865.676
[47,     1] loss: 874.608
[48,     1] loss: 828.244
[49,     1] loss: 831.975
[50,     1] loss: 804.781
[51,     1] loss: 816.566
[52,     1] loss: 769.753
[53,     1] loss: 801.385
[54,     1] loss: 785.197
[55,     1] loss: 739.651
[56,     1] loss: 745.305
[57,     1] loss: 748.432
[58,     1] loss: 704.259
[59,     1] loss: 723.715
[60,     1] loss: 730.085
[61,     1] loss: 863.776
[62,     1] loss: 928.051
[63,     1] loss: 709.601
[64,     1] loss: 812.255
[65,     1] loss: 743.013
[66,     1] loss: 780.151
[67,     1] loss: 745.389
[68,     1] loss: 790.488
[69,     1] loss: 742.047
[70,     1] loss: 715.197
[71,     1] loss: 799.156
[72,     1] loss: 725.390
[73,     1] loss: 701.072
Early stopping applied (best metric=0.8075383305549622)
Finished Training
Total time taken: 10.814228773117065
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1271.408
[2,     1] loss: 1274.541
[3,     1] loss: 1277.541
[4,     1] loss: 1277.681
[5,     1] loss: 1268.097
[6,     1] loss: 1274.398
[7,     1] loss: 1265.795
[8,     1] loss: 1251.216
[9,     1] loss: 1234.022
[10,     1] loss: 1215.583
[11,     1] loss: 1173.329
[12,     1] loss: 1144.982
[13,     1] loss: 1128.326
[14,     1] loss: 1115.362
[15,     1] loss: 1094.581
[16,     1] loss: 1081.176
[17,     1] loss: 1102.842
[18,     1] loss: 1060.772
[19,     1] loss: 1082.082
[20,     1] loss: 1072.025
[21,     1] loss: 1060.768
[22,     1] loss: 1045.917
[23,     1] loss: 1022.577
[24,     1] loss: 1038.947
[25,     1] loss: 1012.399
[26,     1] loss: 1015.064
[27,     1] loss: 986.279
[28,     1] loss: 957.303
[29,     1] loss: 980.611
[30,     1] loss: 933.861
[31,     1] loss: 948.900
[32,     1] loss: 918.167
[33,     1] loss: 925.452
[34,     1] loss: 873.228
[35,     1] loss: 883.850
[36,     1] loss: 895.614
[37,     1] loss: 986.205
[38,     1] loss: 972.247
[39,     1] loss: 832.040
[40,     1] loss: 876.814
[41,     1] loss: 827.829
[42,     1] loss: 884.780
[43,     1] loss: 822.731
[44,     1] loss: 864.884
[45,     1] loss: 799.223
[46,     1] loss: 757.415
[47,     1] loss: 774.349
[48,     1] loss: 812.975
[49,     1] loss: 801.620
[50,     1] loss: 839.085
[51,     1] loss: 912.359
[52,     1] loss: 887.422
[53,     1] loss: 784.244
[54,     1] loss: 857.861
[55,     1] loss: 760.263
[56,     1] loss: 777.561
[57,     1] loss: 749.742
[58,     1] loss: 777.627
[59,     1] loss: 763.530
[60,     1] loss: 774.547
[61,     1] loss: 728.310
[62,     1] loss: 696.858
[63,     1] loss: 682.971
[64,     1] loss: 688.556
[65,     1] loss: 674.073
[66,     1] loss: 665.284
[67,     1] loss: 673.589
[68,     1] loss: 700.624
[69,     1] loss: 680.350
[70,     1] loss: 626.105
[71,     1] loss: 626.292
[72,     1] loss: 664.179
[73,     1] loss: 672.593
[74,     1] loss: 695.484
[75,     1] loss: 621.095
[76,     1] loss: 561.810
[77,     1] loss: 638.619
[78,     1] loss: 683.266
[79,     1] loss: 596.750
[80,     1] loss: 625.963
[81,     1] loss: 654.648
[82,     1] loss: 626.370
[83,     1] loss: 665.822
[84,     1] loss: 579.068
[85,     1] loss: 600.759
[86,     1] loss: 568.499
[87,     1] loss: 529.687
[88,     1] loss: 660.853
[89,     1] loss: 587.827
[90,     1] loss: 485.562
[91,     1] loss: 615.147
[92,     1] loss: 652.394
[93,     1] loss: 549.591
[94,     1] loss: 547.464
[95,     1] loss: 752.105
Early stopping applied (best metric=0.7303927540779114)
Finished Training
Total time taken: 14.020293951034546
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1286.476
[2,     1] loss: 1273.587
[3,     1] loss: 1285.125
[4,     1] loss: 1274.464
[5,     1] loss: 1280.999
[6,     1] loss: 1274.226
[7,     1] loss: 1273.827
[8,     1] loss: 1271.494
[9,     1] loss: 1271.156
[10,     1] loss: 1274.283
[11,     1] loss: 1268.797
[12,     1] loss: 1260.220
[13,     1] loss: 1251.119
[14,     1] loss: 1235.397
[15,     1] loss: 1216.396
[16,     1] loss: 1195.361
[17,     1] loss: 1159.992
[18,     1] loss: 1151.146
[19,     1] loss: 1146.636
[20,     1] loss: 1092.679
[21,     1] loss: 1096.059
[22,     1] loss: 1066.458
[23,     1] loss: 1074.929
[24,     1] loss: 1106.899
[25,     1] loss: 1077.458
[26,     1] loss: 1143.207
[27,     1] loss: 1066.568
[28,     1] loss: 1085.301
[29,     1] loss: 1059.679
[30,     1] loss: 1023.250
[31,     1] loss: 1051.737
[32,     1] loss: 1036.902
[33,     1] loss: 1030.759
[34,     1] loss: 1052.968
[35,     1] loss: 1019.234
[36,     1] loss: 997.366
[37,     1] loss: 1017.898
[38,     1] loss: 989.042
[39,     1] loss: 948.406
[40,     1] loss: 945.900
[41,     1] loss: 944.395
[42,     1] loss: 968.299
[43,     1] loss: 953.412
[44,     1] loss: 929.888
[45,     1] loss: 914.710
[46,     1] loss: 980.089
[47,     1] loss: 943.940
[48,     1] loss: 928.409
[49,     1] loss: 887.266
[50,     1] loss: 915.004
[51,     1] loss: 887.195
[52,     1] loss: 873.090
[53,     1] loss: 957.742
[54,     1] loss: 959.241
[55,     1] loss: 876.197
[56,     1] loss: 890.314
[57,     1] loss: 931.548
[58,     1] loss: 883.463
[59,     1] loss: 890.773
[60,     1] loss: 819.714
[61,     1] loss: 900.903
[62,     1] loss: 795.653
[63,     1] loss: 844.449
[64,     1] loss: 771.773
[65,     1] loss: 838.388
[66,     1] loss: 826.239
[67,     1] loss: 794.295
[68,     1] loss: 756.106
[69,     1] loss: 749.683
[70,     1] loss: 738.590
[71,     1] loss: 730.123
[72,     1] loss: 741.931
[73,     1] loss: 810.869
[74,     1] loss: 852.381
[75,     1] loss: 739.011
[76,     1] loss: 737.903
[77,     1] loss: 748.988
[78,     1] loss: 734.768
[79,     1] loss: 709.142
[80,     1] loss: 664.784
[81,     1] loss: 683.724
[82,     1] loss: 657.016
[83,     1] loss: 777.853
[84,     1] loss: 966.800
[85,     1] loss: 823.926
[86,     1] loss: 707.617
[87,     1] loss: 787.094
[88,     1] loss: 744.389
[89,     1] loss: 707.636
[90,     1] loss: 768.383
[91,     1] loss: 710.248
[92,     1] loss: 690.551
[93,     1] loss: 744.941
[94,     1] loss: 689.739
[95,     1] loss: 664.295
[96,     1] loss: 668.574
[97,     1] loss: 670.189
[98,     1] loss: 690.202
[99,     1] loss: 656.427
[100,     1] loss: 607.374
[101,     1] loss: 636.420
[102,     1] loss: 603.329
[103,     1] loss: 609.266
[104,     1] loss: 575.474
[105,     1] loss: 566.327
[106,     1] loss: 536.090
[107,     1] loss: 595.651
[108,     1] loss: 622.645
[109,     1] loss: 544.321
[110,     1] loss: 658.386
[111,     1] loss: 553.359
[112,     1] loss: 528.207
[113,     1] loss: 524.206
[114,     1] loss: 529.187
Early stopping applied (best metric=0.6615955829620361)
Finished Training
Total time taken: 16.53134846687317
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1278.182
[2,     1] loss: 1276.832
[3,     1] loss: 1275.610
[4,     1] loss: 1266.290
[5,     1] loss: 1259.271
[6,     1] loss: 1226.850
[7,     1] loss: 1188.117
[8,     1] loss: 1157.399
[9,     1] loss: 1114.684
[10,     1] loss: 1116.164
[11,     1] loss: 1127.673
[12,     1] loss: 1099.110
[13,     1] loss: 1090.650
[14,     1] loss: 1057.987
[15,     1] loss: 1067.618
[16,     1] loss: 1024.079
[17,     1] loss: 1052.513
[18,     1] loss: 1039.769
[19,     1] loss: 1032.493
[20,     1] loss: 1044.375
[21,     1] loss: 966.745
[22,     1] loss: 1014.140
[23,     1] loss: 992.680
[24,     1] loss: 996.296
[25,     1] loss: 978.860
[26,     1] loss: 1012.817
[27,     1] loss: 948.110
[28,     1] loss: 934.912
[29,     1] loss: 953.533
[30,     1] loss: 925.604
[31,     1] loss: 922.882
[32,     1] loss: 944.550
[33,     1] loss: 906.342
[34,     1] loss: 862.176
[35,     1] loss: 958.735
[36,     1] loss: 900.285
[37,     1] loss: 933.870
[38,     1] loss: 919.481
[39,     1] loss: 912.046
[40,     1] loss: 952.278
[41,     1] loss: 861.166
[42,     1] loss: 881.766
[43,     1] loss: 881.752
[44,     1] loss: 780.911
[45,     1] loss: 821.293
[46,     1] loss: 818.123
[47,     1] loss: 804.188
[48,     1] loss: 843.513
[49,     1] loss: 810.019
[50,     1] loss: 770.030
[51,     1] loss: 795.634
[52,     1] loss: 759.909
[53,     1] loss: 827.881
[54,     1] loss: 815.504
[55,     1] loss: 713.406
[56,     1] loss: 770.915
[57,     1] loss: 736.637
[58,     1] loss: 742.254
[59,     1] loss: 725.373
[60,     1] loss: 691.197
[61,     1] loss: 665.603
[62,     1] loss: 681.779
[63,     1] loss: 810.719
[64,     1] loss: 815.919
[65,     1] loss: 699.882
[66,     1] loss: 653.324
[67,     1] loss: 647.446
[68,     1] loss: 737.816
[69,     1] loss: 689.359
[70,     1] loss: 692.328
[71,     1] loss: 713.409
[72,     1] loss: 610.653
[73,     1] loss: 649.272
[74,     1] loss: 635.698
[75,     1] loss: 628.187
[76,     1] loss: 657.774
[77,     1] loss: 601.257
[78,     1] loss: 549.512
[79,     1] loss: 712.876
[80,     1] loss: 680.096
[81,     1] loss: 642.131
[82,     1] loss: 573.326
[83,     1] loss: 603.308
[84,     1] loss: 545.989
[85,     1] loss: 712.567
Early stopping applied (best metric=0.7904459238052368)
Finished Training
Total time taken: 12.37026071548462
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1272.193
[2,     1] loss: 1288.286
[3,     1] loss: 1276.339
[4,     1] loss: 1274.585
[5,     1] loss: 1274.419
[6,     1] loss: 1271.985
[7,     1] loss: 1269.361
[8,     1] loss: 1258.969
[9,     1] loss: 1248.984
[10,     1] loss: 1230.040
[11,     1] loss: 1197.862
[12,     1] loss: 1162.982
[13,     1] loss: 1130.746
[14,     1] loss: 1104.670
[15,     1] loss: 1075.109
[16,     1] loss: 1148.374
[17,     1] loss: 1060.629
[18,     1] loss: 1052.915
[19,     1] loss: 1044.615
[20,     1] loss: 1043.803
[21,     1] loss: 1022.287
[22,     1] loss: 991.879
[23,     1] loss: 1026.686
[24,     1] loss: 1017.051
[25,     1] loss: 1024.642
[26,     1] loss: 984.063
[27,     1] loss: 964.148
[28,     1] loss: 1000.110
[29,     1] loss: 1019.530
[30,     1] loss: 949.865
[31,     1] loss: 943.412
[32,     1] loss: 959.084
[33,     1] loss: 905.639
[34,     1] loss: 900.633
[35,     1] loss: 904.042
[36,     1] loss: 857.437
[37,     1] loss: 888.283
[38,     1] loss: 922.081
[39,     1] loss: 880.318
[40,     1] loss: 885.810
[41,     1] loss: 867.505
[42,     1] loss: 858.491
[43,     1] loss: 875.884
[44,     1] loss: 856.945
[45,     1] loss: 830.845
[46,     1] loss: 791.600
[47,     1] loss: 784.883
[48,     1] loss: 793.503
[49,     1] loss: 839.928
[50,     1] loss: 950.599
[51,     1] loss: 768.887
[52,     1] loss: 795.541
[53,     1] loss: 770.429
[54,     1] loss: 780.094
[55,     1] loss: 737.875
[56,     1] loss: 745.573
[57,     1] loss: 760.338
[58,     1] loss: 690.314
[59,     1] loss: 646.629
Early stopping applied (best metric=0.8506650924682617)
Finished Training
Total time taken: 9.74020528793335
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1279.614
[2,     1] loss: 1271.814
[3,     1] loss: 1285.905
[4,     1] loss: 1275.839
[5,     1] loss: 1276.805
[6,     1] loss: 1272.757
[7,     1] loss: 1270.042
[8,     1] loss: 1265.187
[9,     1] loss: 1263.269
[10,     1] loss: 1247.992
[11,     1] loss: 1219.658
[12,     1] loss: 1196.584
[13,     1] loss: 1172.723
[14,     1] loss: 1136.744
[15,     1] loss: 1114.374
[16,     1] loss: 1109.142
[17,     1] loss: 1086.070
[18,     1] loss: 1068.916
[19,     1] loss: 1079.763
[20,     1] loss: 1061.897
[21,     1] loss: 1097.138
[22,     1] loss: 1063.677
[23,     1] loss: 1045.792
[24,     1] loss: 1045.426
[25,     1] loss: 1035.926
[26,     1] loss: 1011.995
[27,     1] loss: 1023.912
[28,     1] loss: 991.648
[29,     1] loss: 976.888
[30,     1] loss: 978.204
[31,     1] loss: 971.559
[32,     1] loss: 933.803
[33,     1] loss: 924.412
[34,     1] loss: 934.105
[35,     1] loss: 940.830
[36,     1] loss: 918.416
[37,     1] loss: 936.718
[38,     1] loss: 868.973
[39,     1] loss: 881.231
[40,     1] loss: 880.713
[41,     1] loss: 926.552
[42,     1] loss: 877.675
[43,     1] loss: 882.933
[44,     1] loss: 812.549
[45,     1] loss: 846.845
[46,     1] loss: 1003.941
[47,     1] loss: 878.784
[48,     1] loss: 889.197
[49,     1] loss: 855.200
[50,     1] loss: 879.286
[51,     1] loss: 821.935
[52,     1] loss: 874.623
[53,     1] loss: 825.275
[54,     1] loss: 871.387
[55,     1] loss: 792.916
[56,     1] loss: 841.729
[57,     1] loss: 739.877
[58,     1] loss: 765.008
[59,     1] loss: 708.807
[60,     1] loss: 763.150
[61,     1] loss: 757.501
[62,     1] loss: 761.637
[63,     1] loss: 827.672
[64,     1] loss: 757.826
Early stopping applied (best metric=0.8110538721084595)
Finished Training
Total time taken: 10.610223770141602
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.620
[2,     1] loss: 1275.942
[3,     1] loss: 1275.496
[4,     1] loss: 1271.178
[5,     1] loss: 1271.718
[6,     1] loss: 1269.764
[7,     1] loss: 1260.299
[8,     1] loss: 1246.577
[9,     1] loss: 1217.013
[10,     1] loss: 1187.320
[11,     1] loss: 1162.958
[12,     1] loss: 1144.722
[13,     1] loss: 1104.663
[14,     1] loss: 1068.803
[15,     1] loss: 1087.557
[16,     1] loss: 1041.908
[17,     1] loss: 1026.251
[18,     1] loss: 1022.427
[19,     1] loss: 948.645
[20,     1] loss: 978.269
[21,     1] loss: 992.698
[22,     1] loss: 979.431
[23,     1] loss: 988.109
[24,     1] loss: 944.073
[25,     1] loss: 950.919
[26,     1] loss: 971.932
[27,     1] loss: 915.679
[28,     1] loss: 951.188
[29,     1] loss: 992.117
[30,     1] loss: 906.908
[31,     1] loss: 907.223
[32,     1] loss: 929.258
[33,     1] loss: 923.825
[34,     1] loss: 839.259
[35,     1] loss: 894.029
[36,     1] loss: 850.290
[37,     1] loss: 873.253
[38,     1] loss: 861.003
[39,     1] loss: 787.256
[40,     1] loss: 833.701
[41,     1] loss: 800.231
[42,     1] loss: 810.977
[43,     1] loss: 786.582
[44,     1] loss: 780.123
[45,     1] loss: 788.925
[46,     1] loss: 834.912
[47,     1] loss: 843.242
[48,     1] loss: 799.432
[49,     1] loss: 767.781
[50,     1] loss: 802.628
[51,     1] loss: 827.388
[52,     1] loss: 794.451
[53,     1] loss: 733.316
[54,     1] loss: 738.482
[55,     1] loss: 721.314
[56,     1] loss: 668.448
[57,     1] loss: 722.645
[58,     1] loss: 856.922
[59,     1] loss: 763.634
[60,     1] loss: 689.970
[61,     1] loss: 735.490
[62,     1] loss: 689.772
[63,     1] loss: 744.211
[64,     1] loss: 672.670
[65,     1] loss: 652.051
Early stopping applied (best metric=0.8704146146774292)
Finished Training
Total time taken: 9.155195713043213
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1277.801
[2,     1] loss: 1273.330
[3,     1] loss: 1278.246
[4,     1] loss: 1272.892
[5,     1] loss: 1278.345
[6,     1] loss: 1272.150
[7,     1] loss: 1263.251
[8,     1] loss: 1248.615
[9,     1] loss: 1221.954
[10,     1] loss: 1181.086
[11,     1] loss: 1155.044
[12,     1] loss: 1119.411
[13,     1] loss: 1089.668
[14,     1] loss: 1073.363
[15,     1] loss: 1048.954
[16,     1] loss: 1033.063
[17,     1] loss: 1039.355
[18,     1] loss: 1017.583
[19,     1] loss: 981.161
[20,     1] loss: 997.214
[21,     1] loss: 989.041
[22,     1] loss: 1013.556
[23,     1] loss: 1017.645
[24,     1] loss: 955.312
[25,     1] loss: 966.907
[26,     1] loss: 926.413
[27,     1] loss: 971.061
[28,     1] loss: 882.597
[29,     1] loss: 918.732
[30,     1] loss: 910.444
[31,     1] loss: 920.409
[32,     1] loss: 868.084
[33,     1] loss: 864.566
[34,     1] loss: 866.381
[35,     1] loss: 996.019
[36,     1] loss: 884.544
[37,     1] loss: 918.547
[38,     1] loss: 853.178
[39,     1] loss: 876.264
[40,     1] loss: 804.665
[41,     1] loss: 832.135
[42,     1] loss: 839.075
[43,     1] loss: 914.248
[44,     1] loss: 822.585
[45,     1] loss: 867.807
Early stopping applied (best metric=0.9590867757797241)
Finished Training
Total time taken: 7.1301493644714355
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1274.432
[2,     1] loss: 1276.452
[3,     1] loss: 1274.836
[4,     1] loss: 1274.480
[5,     1] loss: 1271.901
[6,     1] loss: 1260.524
[7,     1] loss: 1253.785
[8,     1] loss: 1225.374
[9,     1] loss: 1191.758
[10,     1] loss: 1140.856
[11,     1] loss: 1132.982
[12,     1] loss: 1089.259
[13,     1] loss: 1116.443
[14,     1] loss: 1047.896
[15,     1] loss: 1032.308
[16,     1] loss: 1047.021
[17,     1] loss: 1042.351
[18,     1] loss: 1026.541
[19,     1] loss: 1021.338
[20,     1] loss: 1014.265
[21,     1] loss: 983.475
[22,     1] loss: 1002.180
[23,     1] loss: 984.713
[24,     1] loss: 989.711
[25,     1] loss: 973.473
[26,     1] loss: 943.697
[27,     1] loss: 952.543
[28,     1] loss: 983.451
[29,     1] loss: 953.204
[30,     1] loss: 921.679
[31,     1] loss: 928.217
[32,     1] loss: 897.055
[33,     1] loss: 917.322
[34,     1] loss: 870.175
[35,     1] loss: 891.000
[36,     1] loss: 836.589
[37,     1] loss: 869.289
[38,     1] loss: 841.045
[39,     1] loss: 801.345
[40,     1] loss: 856.431
[41,     1] loss: 829.617
[42,     1] loss: 811.552
[43,     1] loss: 781.313
[44,     1] loss: 791.101
[45,     1] loss: 810.428
[46,     1] loss: 749.552
[47,     1] loss: 802.547
[48,     1] loss: 700.091
[49,     1] loss: 726.453
[50,     1] loss: 749.698
[51,     1] loss: 1082.619
[52,     1] loss: 1162.628
[53,     1] loss: 840.867
[54,     1] loss: 824.511
[55,     1] loss: 996.219
Early stopping applied (best metric=0.8494856953620911)
Finished Training
Total time taken: 7.867165565490723
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1274.952
[2,     1] loss: 1274.714
[3,     1] loss: 1274.352
[4,     1] loss: 1276.352
[5,     1] loss: 1269.978
[6,     1] loss: 1257.807
[7,     1] loss: 1239.973
[8,     1] loss: 1197.615
[9,     1] loss: 1137.956
[10,     1] loss: 1125.179
[11,     1] loss: 1085.124
[12,     1] loss: 1070.607
[13,     1] loss: 1021.163
[14,     1] loss: 1065.923
[15,     1] loss: 1056.123
[16,     1] loss: 1026.209
[17,     1] loss: 1012.883
[18,     1] loss: 989.261
[19,     1] loss: 1013.474
[20,     1] loss: 1031.874
[21,     1] loss: 973.354
[22,     1] loss: 982.043
[23,     1] loss: 945.877
[24,     1] loss: 963.346
[25,     1] loss: 938.120
[26,     1] loss: 941.776
[27,     1] loss: 974.061
[28,     1] loss: 946.722
[29,     1] loss: 899.609
[30,     1] loss: 965.958
[31,     1] loss: 899.570
[32,     1] loss: 854.599
[33,     1] loss: 919.828
[34,     1] loss: 856.407
[35,     1] loss: 890.432
[36,     1] loss: 883.328
[37,     1] loss: 887.259
[38,     1] loss: 900.275
[39,     1] loss: 860.973
[40,     1] loss: 844.369
[41,     1] loss: 812.606
[42,     1] loss: 828.359
[43,     1] loss: 832.084
[44,     1] loss: 983.989
[45,     1] loss: 946.791
[46,     1] loss: 795.845
[47,     1] loss: 882.706
[48,     1] loss: 826.037
[49,     1] loss: 897.818
[50,     1] loss: 828.176
[51,     1] loss: 848.205
[52,     1] loss: 817.481
[53,     1] loss: 801.990
[54,     1] loss: 778.917
[55,     1] loss: 810.220
[56,     1] loss: 798.573
[57,     1] loss: 806.948
[58,     1] loss: 737.761
[59,     1] loss: 785.924
[60,     1] loss: 712.491
[61,     1] loss: 757.005
[62,     1] loss: 819.413
[63,     1] loss: 666.284
[64,     1] loss: 816.960
[65,     1] loss: 716.292
[66,     1] loss: 745.887
[67,     1] loss: 761.989
[68,     1] loss: 670.659
[69,     1] loss: 716.049
[70,     1] loss: 694.169
[71,     1] loss: 660.042
[72,     1] loss: 815.220
[73,     1] loss: 642.017
[74,     1] loss: 642.530
[75,     1] loss: 728.844
[76,     1] loss: 660.999
[77,     1] loss: 710.269
[78,     1] loss: 612.106
[79,     1] loss: 620.816
[80,     1] loss: 625.520
[81,     1] loss: 599.753
[82,     1] loss: 603.880
[83,     1] loss: 619.768
[84,     1] loss: 667.602
[85,     1] loss: 553.003
[86,     1] loss: 586.422
[87,     1] loss: 558.444
[88,     1] loss: 532.086
[89,     1] loss: 559.567
[90,     1] loss: 571.466
[91,     1] loss: 547.701
[92,     1] loss: 562.350
[93,     1] loss: 505.654
[94,     1] loss: 496.387
[95,     1] loss: 538.176
[96,     1] loss: 769.681
[97,     1] loss: 1182.291
[98,     1] loss: 623.521
Early stopping applied (best metric=0.8101462125778198)
Finished Training
Total time taken: 14.689309358596802
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1278.191
[2,     1] loss: 1287.134
[3,     1] loss: 1276.582
[4,     1] loss: 1276.906
[5,     1] loss: 1273.515
[6,     1] loss: 1276.700
[7,     1] loss: 1272.345
[8,     1] loss: 1272.451
[9,     1] loss: 1271.020
[10,     1] loss: 1265.801
[11,     1] loss: 1259.679
[12,     1] loss: 1251.513
[13,     1] loss: 1236.023
[14,     1] loss: 1212.586
[15,     1] loss: 1201.885
[16,     1] loss: 1163.991
[17,     1] loss: 1135.550
[18,     1] loss: 1142.429
[19,     1] loss: 1106.082
[20,     1] loss: 1084.946
[21,     1] loss: 1075.821
[22,     1] loss: 1111.925
[23,     1] loss: 1101.928
[24,     1] loss: 1069.305
[25,     1] loss: 1045.939
[26,     1] loss: 1041.451
[27,     1] loss: 999.488
[28,     1] loss: 984.478
[29,     1] loss: 994.963
[30,     1] loss: 1014.100
[31,     1] loss: 990.696
[32,     1] loss: 1006.487
[33,     1] loss: 940.940
[34,     1] loss: 969.799
[35,     1] loss: 979.315
[36,     1] loss: 962.779
[37,     1] loss: 955.455
[38,     1] loss: 953.724
[39,     1] loss: 902.528
[40,     1] loss: 985.463
[41,     1] loss: 926.231
[42,     1] loss: 937.554
[43,     1] loss: 887.983
[44,     1] loss: 916.200
[45,     1] loss: 893.946
[46,     1] loss: 915.510
[47,     1] loss: 856.008
[48,     1] loss: 896.578
[49,     1] loss: 862.225
[50,     1] loss: 867.587
[51,     1] loss: 870.864
[52,     1] loss: 896.279
[53,     1] loss: 851.161
[54,     1] loss: 863.378
[55,     1] loss: 800.687
[56,     1] loss: 865.925
[57,     1] loss: 805.182
[58,     1] loss: 752.761
[59,     1] loss: 758.113
[60,     1] loss: 761.413
[61,     1] loss: 773.464
[62,     1] loss: 770.100
[63,     1] loss: 760.695
[64,     1] loss: 736.132
[65,     1] loss: 794.599
[66,     1] loss: 704.879
[67,     1] loss: 710.700
[68,     1] loss: 774.631
[69,     1] loss: 739.400
[70,     1] loss: 702.339
[71,     1] loss: 680.366
[72,     1] loss: 639.994
[73,     1] loss: 689.956
[74,     1] loss: 684.002
[75,     1] loss: 703.588
[76,     1] loss: 682.389
[77,     1] loss: 764.442
[78,     1] loss: 676.970
[79,     1] loss: 650.257
[80,     1] loss: 744.564
[81,     1] loss: 659.334
[82,     1] loss: 746.018
Early stopping applied (best metric=0.7970805168151855)
Finished Training
Total time taken: 12.074254751205444
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1275.755
[2,     1] loss: 1274.200
[3,     1] loss: 1277.946
[4,     1] loss: 1274.218
[5,     1] loss: 1271.771
[6,     1] loss: 1268.350
[7,     1] loss: 1258.795
[8,     1] loss: 1247.029
[9,     1] loss: 1215.520
[10,     1] loss: 1176.217
[11,     1] loss: 1139.111
[12,     1] loss: 1115.078
[13,     1] loss: 1092.763
[14,     1] loss: 1051.808
[15,     1] loss: 1057.780
[16,     1] loss: 1061.633
[17,     1] loss: 1053.743
[18,     1] loss: 1006.770
[19,     1] loss: 983.479
[20,     1] loss: 1005.167
[21,     1] loss: 1014.530
[22,     1] loss: 982.248
[23,     1] loss: 1013.975
[24,     1] loss: 961.487
[25,     1] loss: 970.940
[26,     1] loss: 989.638
[27,     1] loss: 968.071
[28,     1] loss: 926.330
[29,     1] loss: 981.283
[30,     1] loss: 897.179
[31,     1] loss: 926.611
[32,     1] loss: 896.414
[33,     1] loss: 926.860
[34,     1] loss: 827.861
[35,     1] loss: 860.193
[36,     1] loss: 827.612
[37,     1] loss: 843.653
[38,     1] loss: 877.211
[39,     1] loss: 833.773
[40,     1] loss: 824.262
[41,     1] loss: 885.781
[42,     1] loss: 803.619
[43,     1] loss: 810.245
[44,     1] loss: 822.211
[45,     1] loss: 809.444
[46,     1] loss: 752.737
[47,     1] loss: 783.787
[48,     1] loss: 826.161
[49,     1] loss: 703.200
[50,     1] loss: 742.875
[51,     1] loss: 796.338
[52,     1] loss: 741.858
[53,     1] loss: 672.456
[54,     1] loss: 784.247
[55,     1] loss: 700.261
[56,     1] loss: 749.797
[57,     1] loss: 709.117
[58,     1] loss: 671.494
[59,     1] loss: 691.901
[60,     1] loss: 712.974
[61,     1] loss: 632.196
[62,     1] loss: 820.846
[63,     1] loss: 817.244
[64,     1] loss: 624.806
[65,     1] loss: 720.343
[66,     1] loss: 672.589
[67,     1] loss: 687.656
[68,     1] loss: 621.229
[69,     1] loss: 686.593
[70,     1] loss: 577.369
[71,     1] loss: 632.243
[72,     1] loss: 656.442
[73,     1] loss: 611.196
Early stopping applied (best metric=0.8876919746398926)
Finished Training
Total time taken: 11.497242212295532
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1278.004
[2,     1] loss: 1277.039
[3,     1] loss: 1272.208
[4,     1] loss: 1270.283
[5,     1] loss: 1270.981
[6,     1] loss: 1258.812
[7,     1] loss: 1232.676
[8,     1] loss: 1207.859
[9,     1] loss: 1170.063
[10,     1] loss: 1138.973
[11,     1] loss: 1106.858
[12,     1] loss: 1063.151
[13,     1] loss: 1049.164
[14,     1] loss: 1046.829
[15,     1] loss: 1066.319
[16,     1] loss: 1003.730
[17,     1] loss: 1024.523
[18,     1] loss: 1050.060
[19,     1] loss: 1017.655
[20,     1] loss: 1043.783
[21,     1] loss: 998.621
[22,     1] loss: 1029.002
[23,     1] loss: 992.749
[24,     1] loss: 989.245
[25,     1] loss: 962.429
[26,     1] loss: 968.466
[27,     1] loss: 937.345
[28,     1] loss: 925.738
[29,     1] loss: 956.894
[30,     1] loss: 931.505
[31,     1] loss: 950.787
[32,     1] loss: 879.171
[33,     1] loss: 893.901
[34,     1] loss: 859.299
[35,     1] loss: 857.083
[36,     1] loss: 887.288
[37,     1] loss: 789.540
[38,     1] loss: 850.715
[39,     1] loss: 803.131
[40,     1] loss: 839.378
[41,     1] loss: 879.041
[42,     1] loss: 860.936
[43,     1] loss: 848.207
[44,     1] loss: 897.531
[45,     1] loss: 824.883
[46,     1] loss: 900.615
[47,     1] loss: 759.926
[48,     1] loss: 831.848
[49,     1] loss: 824.380
[50,     1] loss: 803.000
[51,     1] loss: 770.242
[52,     1] loss: 789.681
[53,     1] loss: 729.243
[54,     1] loss: 759.401
[55,     1] loss: 724.293
[56,     1] loss: 765.167
[57,     1] loss: 696.801
[58,     1] loss: 710.291
[59,     1] loss: 713.821
[60,     1] loss: 705.217
[61,     1] loss: 719.434
[62,     1] loss: 651.286
[63,     1] loss: 703.676
[64,     1] loss: 654.536
[65,     1] loss: 640.610
[66,     1] loss: 648.406
[67,     1] loss: 594.640
[68,     1] loss: 551.636
[69,     1] loss: 617.629
[70,     1] loss: 732.702
[71,     1] loss: 1237.616
[72,     1] loss: 602.950
[73,     1] loss: 878.602
[74,     1] loss: 720.355
[75,     1] loss: 830.666
Early stopping applied (best metric=0.8077735900878906)
Finished Training
Total time taken: 11.514241695404053
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1280.716
[2,     1] loss: 1287.641
[3,     1] loss: 1274.901
[4,     1] loss: 1278.817
[5,     1] loss: 1277.450
[6,     1] loss: 1276.006
[7,     1] loss: 1275.609
[8,     1] loss: 1275.745
[9,     1] loss: 1272.297
[10,     1] loss: 1269.316
[11,     1] loss: 1265.317
[12,     1] loss: 1257.052
[13,     1] loss: 1241.104
[14,     1] loss: 1220.275
[15,     1] loss: 1200.556
[16,     1] loss: 1166.413
[17,     1] loss: 1132.976
[18,     1] loss: 1103.567
[19,     1] loss: 1077.942
[20,     1] loss: 1069.053
[21,     1] loss: 1028.507
[22,     1] loss: 1035.053
[23,     1] loss: 1024.441
[24,     1] loss: 1067.682
[25,     1] loss: 1009.269
[26,     1] loss: 1024.567
[27,     1] loss: 1005.388
[28,     1] loss: 985.179
[29,     1] loss: 1006.233
[30,     1] loss: 961.603
[31,     1] loss: 990.714
[32,     1] loss: 969.378
[33,     1] loss: 976.441
[34,     1] loss: 976.227
[35,     1] loss: 893.041
[36,     1] loss: 976.105
[37,     1] loss: 924.070
[38,     1] loss: 900.806
[39,     1] loss: 943.311
[40,     1] loss: 899.597
[41,     1] loss: 892.994
[42,     1] loss: 883.689
[43,     1] loss: 842.520
[44,     1] loss: 878.738
[45,     1] loss: 926.313
[46,     1] loss: 885.074
[47,     1] loss: 824.501
[48,     1] loss: 817.752
[49,     1] loss: 839.877
[50,     1] loss: 842.912
[51,     1] loss: 786.812
[52,     1] loss: 876.332
[53,     1] loss: 800.412
[54,     1] loss: 798.737
[55,     1] loss: 727.654
[56,     1] loss: 758.080
[57,     1] loss: 774.993
[58,     1] loss: 708.004
[59,     1] loss: 743.762
[60,     1] loss: 823.920
[61,     1] loss: 713.470
[62,     1] loss: 697.236
[63,     1] loss: 758.347
[64,     1] loss: 713.409
[65,     1] loss: 700.588
[66,     1] loss: 718.108
[67,     1] loss: 656.080
Early stopping applied (best metric=0.8420215845108032)
Finished Training
Total time taken: 11.053235530853271
{'Hydroxylation-K Validation Accuracy': 0.7238179669030733, 'Hydroxylation-K Validation Sensitivity': 0.6718518518518518, 'Hydroxylation-K Validation Specificity': 0.7368421052631579, 'Hydroxylation-K Validation Precision': 0.39845814259126955, 'Hydroxylation-K AUC ROC': 0.7909161793372319, 'Hydroxylation-K AUC PR': 0.5488073341693368, 'Hydroxylation-K MCC': 0.34844595605844525, 'Hydroxylation-K F1': 0.4978776149350862, 'Validation Loss (Hydroxylation-K)': 0.4520264983177185, 'Hydroxylation-P Validation Accuracy': 0.7842238295856386, 'Hydroxylation-P Validation Sensitivity': 0.7974074074074075, 'Hydroxylation-P Validation Specificity': 0.7814255075066088, 'Hydroxylation-P Validation Precision': 0.44617210467953144, 'Hydroxylation-P AUC ROC': 0.8561909393414705, 'Hydroxylation-P AUC PR': 0.6266943603579785, 'Hydroxylation-P MCC': 0.477175214918453, 'Hydroxylation-P F1': 0.569189124530591, 'Validation Loss (Hydroxylation-P)': 0.365108182032903, 'Validation Loss (total)': 0.8171346704165141, 'TimeToTrain': 11.211970043182372}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000559495647322307,
 'learning_rate_Hydroxylation-K': 0.0051710013270027085,
 'learning_rate_Hydroxylation-P': 0.006478045074854329,
 'log_base': 1.8073566127406686,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 615971495,
 'sample_weights': [1.7422440965684918, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3554776696509112,
 'weight_decay_Hydroxylation-K': 3.7264654125555605,
 'weight_decay_Hydroxylation-P': 2.877628363722508}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1504.503
[2,     1] loss: 1505.351
[3,     1] loss: 1502.546
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00014839751612229332,
 'learning_rate_Hydroxylation-K': 0.00761212323602749,
 'learning_rate_Hydroxylation-P': 0.004871544915572137,
 'log_base': 1.8453685541083358,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1512477185,
 'sample_weights': [2.8206469048781084, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6595178444955582,
 'weight_decay_Hydroxylation-K': 0.02633248625591733,
 'weight_decay_Hydroxylation-P': 2.9999947205663857}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1479.991
[2,     1] loss: 1484.561
[3,     1] loss: 1483.296
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002552078221236609,
 'learning_rate_Hydroxylation-K': 5.1361314930130895e-05,
 'learning_rate_Hydroxylation-P': 0.004358351083708601,
 'log_base': 2.9807325093448833,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 887671172,
 'sample_weights': [2.7248250783637396, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.287378027173993,
 'weight_decay_Hydroxylation-K': 1.7292533054882115,
 'weight_decay_Hydroxylation-P': 3.1470408377295382}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1228.800
[2,     1] loss: 1230.316
[3,     1] loss: 1229.136
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001597838420821567,
 'learning_rate_Hydroxylation-K': 0.0025923887792994784,
 'learning_rate_Hydroxylation-P': 0.0013256240237303528,
 'log_base': 2.72483917097298,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1353469535,
 'sample_weights': [1.5285574182643538, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.090081455562724,
 'weight_decay_Hydroxylation-K': 0.8658150930637798,
 'weight_decay_Hydroxylation-P': 0.08139734348736728}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1256.351
[2,     1] loss: 1265.831
[3,     1] loss: 1260.510
[4,     1] loss: 1260.870
[5,     1] loss: 1257.555
[6,     1] loss: 1252.138
[7,     1] loss: 1249.013
[8,     1] loss: 1239.417
[9,     1] loss: 1238.808
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017744366907561967,
 'learning_rate_Hydroxylation-K': 0.005201159808007028,
 'learning_rate_Hydroxylation-P': 0.00820534017565499,
 'log_base': 1.1437345252423154,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3807572277,
 'sample_weights': [1.665430448397664, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.443093780663496,
 'weight_decay_Hydroxylation-K': 6.286242859005897,
 'weight_decay_Hydroxylation-P': 2.0040118738994255}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 4042.729
[2,     1] loss: 4030.667
[3,     1] loss: 4028.316
[4,     1] loss: 4016.824
[5,     1] loss: 4031.368
[6,     1] loss: 4042.230
[7,     1] loss: 4040.673
[8,     1] loss: 4018.609
[9,     1] loss: 4029.990
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0085332615274044,
 'learning_rate_Hydroxylation-K': 0.00879794765986432,
 'learning_rate_Hydroxylation-P': 0.003181897491005704,
 'log_base': 1.8505615133167888,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3703347776,
 'sample_weights': [12.43081138505012, 1.5539112837277749],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.649358928330752,
 'weight_decay_Hydroxylation-K': 8.097848712869327,
 'weight_decay_Hydroxylation-P': 6.0429725500524185}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1496.164
[2,     1] loss: 1487.693
[3,     1] loss: 1489.238
[4,     1] loss: 1486.593
[5,     1] loss: 1485.286
[6,     1] loss: 1493.552
[7,     1] loss: 1482.213
[8,     1] loss: 1479.198
[9,     1] loss: 1482.819
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005290190170666203,
 'learning_rate_Hydroxylation-K': 0.008953874033855154,
 'learning_rate_Hydroxylation-P': 0.009157386121202014,
 'log_base': 2.6858169667759926,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1555064895,
 'sample_weights': [2.712384524975859, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.694091049787044,
 'weight_decay_Hydroxylation-K': 3.2284697308153767,
 'weight_decay_Hydroxylation-P': 8.15697408905015}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1265.841
[2,     1] loss: 1271.984
[3,     1] loss: 1268.582
[4,     1] loss: 1260.534
[5,     1] loss: 1258.966
[6,     1] loss: 1244.570
[7,     1] loss: 1226.007
[8,     1] loss: 1184.411
[9,     1] loss: 1132.993
[10,     1] loss: 1100.448
[11,     1] loss: 1115.727
[12,     1] loss: 1081.395
[13,     1] loss: 1041.704
[14,     1] loss: 1025.317
[15,     1] loss: 1022.665
[16,     1] loss: 1055.094
[17,     1] loss: 1012.503
[18,     1] loss: 1021.673
[19,     1] loss: 975.384
[20,     1] loss: 994.410
[21,     1] loss: 944.008
[22,     1] loss: 973.049
[23,     1] loss: 891.887
[24,     1] loss: 918.501
[25,     1] loss: 922.117
[26,     1] loss: 868.523
[27,     1] loss: 933.597
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008135862915735577,
 'learning_rate_Hydroxylation-K': 0.00885608014528113,
 'learning_rate_Hydroxylation-P': 0.005057901305365936,
 'log_base': 1.6167787839664056,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1186886755,
 'sample_weights': [1.6897455203502176, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1643325031653209,
 'weight_decay_Hydroxylation-K': 6.325986437931681,
 'weight_decay_Hydroxylation-P': 6.725182727997279}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1639.905
[2,     1] loss: 1661.614
[3,     1] loss: 1644.201
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005168820029214302,
 'learning_rate_Hydroxylation-K': 0.007973484969706766,
 'learning_rate_Hydroxylation-P': 0.00912444234411898,
 'log_base': 1.4584773784969653,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1687663776,
 'sample_weights': [3.4748519360863415, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.7768419467166,
 'weight_decay_Hydroxylation-K': 9.443729311003018,
 'weight_decay_Hydroxylation-P': 0.6426826290210066}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1844.020
[2,     1] loss: 1846.111
[3,     1] loss: 1844.807
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007085396850972472,
 'learning_rate_Hydroxylation-K': 0.000980136049327799,
 'learning_rate_Hydroxylation-P': 0.0071178330886763775,
 'log_base': 2.886370773373475,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2806321339,
 'sample_weights': [4.423619799585322, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.724574438751319,
 'weight_decay_Hydroxylation-K': 0.7261022698467028,
 'weight_decay_Hydroxylation-P': 2.0430943229245013}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.145
[2,     1] loss: 1242.155
[3,     1] loss: 1242.917
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005672364634538209,
 'learning_rate_Hydroxylation-K': 0.0003021388676486456,
 'learning_rate_Hydroxylation-P': 0.0014486357411820615,
 'log_base': 2.999421350204482,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3527187557,
 'sample_weights': [1.5749464766286443, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.3734867852084887,
 'weight_decay_Hydroxylation-K': 5.818172385561725,
 'weight_decay_Hydroxylation-P': 0.12967626187878004}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.105
[2,     1] loss: 1240.059
[3,     1] loss: 1228.426
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012852447354572993,
 'learning_rate_Hydroxylation-K': 0.0032160041572179246,
 'learning_rate_Hydroxylation-P': 0.008328727097640019,
 'log_base': 2.481505524440149,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2432552541,
 'sample_weights': [1.519859506749421, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.752878619947914,
 'weight_decay_Hydroxylation-K': 5.567194950793214,
 'weight_decay_Hydroxylation-P': 6.642205279414577}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1301.315
[2,     1] loss: 1291.098
[3,     1] loss: 1293.355
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002276751801667537,
 'learning_rate_Hydroxylation-K': 0.006958965981886131,
 'learning_rate_Hydroxylation-P': 0.002480983019657302,
 'log_base': 2.5782259469214766,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3266460675,
 'sample_weights': [1.8368430239920206, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2561642921684815,
 'weight_decay_Hydroxylation-K': 9.86605579471815,
 'weight_decay_Hydroxylation-P': 5.677527604046606}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1280.519
[2,     1] loss: 1278.979
[3,     1] loss: 1284.247
[4,     1] loss: 1278.698
[5,     1] loss: 1276.577
[6,     1] loss: 1277.514
[7,     1] loss: 1270.896
[8,     1] loss: 1259.344
[9,     1] loss: 1239.295
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004122272940226771,
 'learning_rate_Hydroxylation-K': 0.0034911488092353987,
 'learning_rate_Hydroxylation-P': 0.006999345799935736,
 'log_base': 1.3398560652845046,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1611033258,
 'sample_weights': [1.7626865422572464, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.89770623247227,
 'weight_decay_Hydroxylation-K': 2.3827352795233816,
 'weight_decay_Hydroxylation-P': 1.6083089762210747}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2114.354
[2,     1] loss: 2106.844
[3,     1] loss: 2123.096
[4,     1] loss: 2100.466
[5,     1] loss: 2123.768
[6,     1] loss: 2152.887
[7,     1] loss: 2105.616
[8,     1] loss: 2116.135
[9,     1] loss: 2101.742
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005566773626117954,
 'learning_rate_Hydroxylation-K': 0.00029811562850435636,
 'learning_rate_Hydroxylation-P': 0.007521523038462185,
 'log_base': 1.3780530074022186,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1580465152,
 'sample_weights': [5.706284613554116, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.991266236254314,
 'weight_decay_Hydroxylation-K': 3.1661402038360587,
 'weight_decay_Hydroxylation-P': 8.974228289920662}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2002.724
[2,     1] loss: 2043.085
[3,     1] loss: 2016.288
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007759859805401297,
 'learning_rate_Hydroxylation-K': 0.0008409160124436595,
 'learning_rate_Hydroxylation-P': 0.007694325281649263,
 'log_base': 1.1605074945089071,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 632461607,
 'sample_weights': [5.206082938515567, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.8116932094843525,
 'weight_decay_Hydroxylation-K': 5.421179656855222,
 'weight_decay_Hydroxylation-P': 6.235175766231111}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3616.179
[2,     1] loss: 3801.990
[3,     1] loss: 3652.283
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011499243384386025,
 'learning_rate_Hydroxylation-K': 0.006983644369774987,
 'learning_rate_Hydroxylation-P': 0.0035270998875250635,
 'log_base': 1.6835150456850507,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1991479693,
 'sample_weights': [11.215049400196724, 1.4019351811168872],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.178262451310103,
 'weight_decay_Hydroxylation-K': 3.168638752440918,
 'weight_decay_Hydroxylation-P': 0.3171275548024688}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1584.438
[2,     1] loss: 1583.480
[3,     1] loss: 1582.736
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031422749286596076,
 'learning_rate_Hydroxylation-K': 0.0037680771697767065,
 'learning_rate_Hydroxylation-P': 0.007364277458328792,
 'log_base': 2.9555188553838145,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3807560978,
 'sample_weights': [3.2050196942550726, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.07078753290717,
 'weight_decay_Hydroxylation-K': 2.9793328629628473,
 'weight_decay_Hydroxylation-P': 4.906303060458931}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.353
[2,     1] loss: 1237.142
[3,     1] loss: 1243.904
[4,     1] loss: 1229.568
[5,     1] loss: 1233.236
[6,     1] loss: 1222.456
[7,     1] loss: 1217.986
[8,     1] loss: 1210.379
[9,     1] loss: 1180.679
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017144665731095954,
 'learning_rate_Hydroxylation-K': 0.0027550400248487045,
 'learning_rate_Hydroxylation-P': 0.0013195464191867994,
 'log_base': 2.897206218099648,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 468502680,
 'sample_weights': [1.540539688992237, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.05335303220068,
 'weight_decay_Hydroxylation-K': 6.781306191928342,
 'weight_decay_Hydroxylation-P': 3.132777029401761}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.577
[2,     1] loss: 1240.682
[3,     1] loss: 1238.653
[4,     1] loss: 1239.154
[5,     1] loss: 1236.525
[6,     1] loss: 1233.239
[7,     1] loss: 1226.528
[8,     1] loss: 1214.399
[9,     1] loss: 1187.698
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00252010150019173,
 'learning_rate_Hydroxylation-K': 0.0010700090347899626,
 'learning_rate_Hydroxylation-P': 0.00016735098822345004,
 'log_base': 2.6960102584963854,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 557891430,
 'sample_weights': [1.5693988373370056, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2975855782154926,
 'weight_decay_Hydroxylation-K': 8.482509772562915,
 'weight_decay_Hydroxylation-P': 2.8227670082337584}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1264.083
[2,     1] loss: 1261.876
[3,     1] loss: 1261.754
[4,     1] loss: 1258.167
[5,     1] loss: 1248.073
[6,     1] loss: 1226.507
[7,     1] loss: 1195.930
[8,     1] loss: 1170.410
[9,     1] loss: 1105.590
[10,     1] loss: 1108.545
[11,     1] loss: 1047.075
[12,     1] loss: 1030.765
[13,     1] loss: 1052.860
[14,     1] loss: 1101.893
[15,     1] loss: 1082.560
[16,     1] loss: 1065.313
[17,     1] loss: 1025.487
[18,     1] loss: 1016.382
[19,     1] loss: 1001.263
[20,     1] loss: 1053.249
[21,     1] loss: 997.229
[22,     1] loss: 984.095
[23,     1] loss: 963.119
[24,     1] loss: 1020.587
[25,     1] loss: 1007.138
[26,     1] loss: 972.148
[27,     1] loss: 944.774
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0026252693569153145,
 'learning_rate_Hydroxylation-K': 0.008872867405174756,
 'learning_rate_Hydroxylation-P': 0.002172977918282119,
 'log_base': 2.921745803402434,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1978137548,
 'sample_weights': [1.683291590498099, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.000964174586207,
 'weight_decay_Hydroxylation-K': 5.800153840994519,
 'weight_decay_Hydroxylation-P': 4.652914564715715}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.236
[2,     1] loss: 1236.315
[3,     1] loss: 1238.876
[4,     1] loss: 1230.192
[5,     1] loss: 1232.014
[6,     1] loss: 1218.952
[7,     1] loss: 1220.428
[8,     1] loss: 1176.389
[9,     1] loss: 1144.039
[10,     1] loss: 1115.165
[11,     1] loss: 1067.045
[12,     1] loss: 1060.119
[13,     1] loss: 1011.397
[14,     1] loss: 1044.642
[15,     1] loss: 1038.740
[16,     1] loss: 1022.666
[17,     1] loss: 1020.328
[18,     1] loss: 990.081
[19,     1] loss: 980.509
[20,     1] loss: 992.329
[21,     1] loss: 961.160
[22,     1] loss: 985.140
[23,     1] loss: 950.960
[24,     1] loss: 950.519
[25,     1] loss: 940.404
[26,     1] loss: 966.535
[27,     1] loss: 908.418
[28,     1] loss: 920.724
[29,     1] loss: 968.990
[30,     1] loss: 867.246
[31,     1] loss: 903.115
[32,     1] loss: 904.252
[33,     1] loss: 868.129
[34,     1] loss: 864.808
[35,     1] loss: 825.027
[36,     1] loss: 814.584
[37,     1] loss: 818.834
[38,     1] loss: 844.616
[39,     1] loss: 819.726
[40,     1] loss: 810.737
[41,     1] loss: 804.898
[42,     1] loss: 816.820
[43,     1] loss: 855.281
[44,     1] loss: 773.400
[45,     1] loss: 864.447
[46,     1] loss: 811.248
[47,     1] loss: 827.995
[48,     1] loss: 787.623
[49,     1] loss: 803.630
[50,     1] loss: 765.578
[51,     1] loss: 717.796
[52,     1] loss: 757.730
[53,     1] loss: 779.946
[54,     1] loss: 670.658
[55,     1] loss: 679.125
[56,     1] loss: 765.941
[57,     1] loss: 889.509
[58,     1] loss: 630.935
[59,     1] loss: 901.547
[60,     1] loss: 728.015
Early stopping applied (best metric=0.851438045501709)
Finished Training
Total time taken: 9.491198301315308
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.721
[2,     1] loss: 1245.941
[3,     1] loss: 1236.192
[4,     1] loss: 1237.548
[5,     1] loss: 1238.984
[6,     1] loss: 1235.816
[7,     1] loss: 1224.259
[8,     1] loss: 1218.809
[9,     1] loss: 1204.860
[10,     1] loss: 1180.555
[11,     1] loss: 1149.236
[12,     1] loss: 1121.533
[13,     1] loss: 1079.196
[14,     1] loss: 1083.633
[15,     1] loss: 1044.838
[16,     1] loss: 1039.190
[17,     1] loss: 1042.991
[18,     1] loss: 1052.569
[19,     1] loss: 976.115
[20,     1] loss: 1024.420
[21,     1] loss: 974.124
[22,     1] loss: 970.328
[23,     1] loss: 956.984
[24,     1] loss: 965.457
[25,     1] loss: 950.293
[26,     1] loss: 961.273
[27,     1] loss: 935.770
[28,     1] loss: 987.590
[29,     1] loss: 916.954
[30,     1] loss: 916.241
[31,     1] loss: 893.949
[32,     1] loss: 974.328
[33,     1] loss: 901.889
[34,     1] loss: 924.662
[35,     1] loss: 921.955
[36,     1] loss: 888.599
[37,     1] loss: 958.526
[38,     1] loss: 885.650
[39,     1] loss: 882.313
[40,     1] loss: 831.447
[41,     1] loss: 806.725
[42,     1] loss: 783.564
[43,     1] loss: 835.920
[44,     1] loss: 820.077
[45,     1] loss: 758.712
[46,     1] loss: 764.686
[47,     1] loss: 788.892
[48,     1] loss: 742.299
[49,     1] loss: 783.415
[50,     1] loss: 922.789
[51,     1] loss: 977.303
[52,     1] loss: 785.033
[53,     1] loss: 883.488
[54,     1] loss: 924.265
[55,     1] loss: 796.651
[56,     1] loss: 839.217
[57,     1] loss: 845.055
Early stopping applied (best metric=0.8771539926528931)
Finished Training
Total time taken: 7.8121631145477295
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1237.493
[2,     1] loss: 1238.816
[3,     1] loss: 1238.828
[4,     1] loss: 1236.392
[5,     1] loss: 1235.041
[6,     1] loss: 1226.676
[7,     1] loss: 1223.766
[8,     1] loss: 1205.507
[9,     1] loss: 1189.085
[10,     1] loss: 1153.003
[11,     1] loss: 1143.976
[12,     1] loss: 1106.391
[13,     1] loss: 1098.675
[14,     1] loss: 1050.229
[15,     1] loss: 1034.017
[16,     1] loss: 1053.528
[17,     1] loss: 1049.362
[18,     1] loss: 995.050
[19,     1] loss: 1000.870
[20,     1] loss: 1022.420
[21,     1] loss: 1029.142
[22,     1] loss: 991.662
[23,     1] loss: 1015.944
[24,     1] loss: 991.303
[25,     1] loss: 961.762
[26,     1] loss: 957.085
[27,     1] loss: 967.627
[28,     1] loss: 917.200
[29,     1] loss: 997.858
[30,     1] loss: 885.508
[31,     1] loss: 875.953
[32,     1] loss: 923.972
[33,     1] loss: 880.077
[34,     1] loss: 878.701
[35,     1] loss: 880.827
[36,     1] loss: 903.870
[37,     1] loss: 866.045
[38,     1] loss: 886.750
[39,     1] loss: 814.954
[40,     1] loss: 842.853
[41,     1] loss: 845.017
[42,     1] loss: 851.058
[43,     1] loss: 836.867
[44,     1] loss: 786.746
[45,     1] loss: 783.147
[46,     1] loss: 781.170
[47,     1] loss: 803.380
[48,     1] loss: 802.619
[49,     1] loss: 722.767
[50,     1] loss: 758.625
[51,     1] loss: 909.911
[52,     1] loss: 735.967
[53,     1] loss: 790.327
[54,     1] loss: 760.996
[55,     1] loss: 811.137
[56,     1] loss: 701.592
[57,     1] loss: 771.824
[58,     1] loss: 705.813
[59,     1] loss: 702.981
[60,     1] loss: 690.214
[61,     1] loss: 702.287
[62,     1] loss: 689.327
[63,     1] loss: 660.325
[64,     1] loss: 631.038
[65,     1] loss: 617.456
[66,     1] loss: 637.571
[67,     1] loss: 594.368
[68,     1] loss: 675.093
[69,     1] loss: 707.736
[70,     1] loss: 947.281
[71,     1] loss: 640.188
[72,     1] loss: 730.061
[73,     1] loss: 733.700
[74,     1] loss: 728.546
[75,     1] loss: 654.135
[76,     1] loss: 758.863
[77,     1] loss: 638.991
Early stopping applied (best metric=0.7917077541351318)
Finished Training
Total time taken: 11.836249113082886
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1237.964
[2,     1] loss: 1242.899
[3,     1] loss: 1236.619
[4,     1] loss: 1234.413
[5,     1] loss: 1232.979
[6,     1] loss: 1230.466
[7,     1] loss: 1225.657
[8,     1] loss: 1210.346
[9,     1] loss: 1183.765
[10,     1] loss: 1147.726
[11,     1] loss: 1125.945
[12,     1] loss: 1069.463
[13,     1] loss: 1071.045
[14,     1] loss: 1065.693
[15,     1] loss: 1034.769
[16,     1] loss: 1050.943
[17,     1] loss: 1056.538
[18,     1] loss: 987.960
[19,     1] loss: 1029.489
[20,     1] loss: 976.975
[21,     1] loss: 973.479
[22,     1] loss: 1018.713
[23,     1] loss: 1007.605
[24,     1] loss: 974.527
[25,     1] loss: 967.651
[26,     1] loss: 903.845
[27,     1] loss: 943.456
[28,     1] loss: 935.089
[29,     1] loss: 938.224
[30,     1] loss: 928.216
[31,     1] loss: 942.026
[32,     1] loss: 931.125
[33,     1] loss: 910.915
[34,     1] loss: 909.501
[35,     1] loss: 894.379
[36,     1] loss: 884.729
[37,     1] loss: 876.249
[38,     1] loss: 877.864
[39,     1] loss: 852.344
[40,     1] loss: 877.039
[41,     1] loss: 842.956
[42,     1] loss: 873.480
[43,     1] loss: 930.246
[44,     1] loss: 793.685
[45,     1] loss: 888.900
[46,     1] loss: 832.643
[47,     1] loss: 827.691
[48,     1] loss: 803.005
[49,     1] loss: 850.193
[50,     1] loss: 750.985
[51,     1] loss: 801.208
[52,     1] loss: 772.998
[53,     1] loss: 773.350
[54,     1] loss: 799.268
Early stopping applied (best metric=0.8191640377044678)
Finished Training
Total time taken: 8.19717264175415
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1240.524
[2,     1] loss: 1234.806
[3,     1] loss: 1239.362
[4,     1] loss: 1238.486
[5,     1] loss: 1234.674
[6,     1] loss: 1235.875
[7,     1] loss: 1221.348
[8,     1] loss: 1205.999
[9,     1] loss: 1173.664
[10,     1] loss: 1153.451
[11,     1] loss: 1092.948
[12,     1] loss: 1061.388
[13,     1] loss: 1091.707
[14,     1] loss: 1057.167
[15,     1] loss: 1053.198
[16,     1] loss: 1011.559
[17,     1] loss: 1023.380
[18,     1] loss: 993.497
[19,     1] loss: 1041.323
[20,     1] loss: 1020.602
[21,     1] loss: 1015.272
[22,     1] loss: 961.322
[23,     1] loss: 1011.502
[24,     1] loss: 958.219
[25,     1] loss: 923.694
[26,     1] loss: 947.147
[27,     1] loss: 942.477
[28,     1] loss: 913.042
[29,     1] loss: 946.203
[30,     1] loss: 878.981
[31,     1] loss: 884.471
[32,     1] loss: 831.550
[33,     1] loss: 852.666
[34,     1] loss: 866.464
[35,     1] loss: 908.827
[36,     1] loss: 870.716
[37,     1] loss: 843.007
[38,     1] loss: 840.185
[39,     1] loss: 807.278
[40,     1] loss: 840.066
[41,     1] loss: 811.436
[42,     1] loss: 791.748
[43,     1] loss: 742.834
[44,     1] loss: 797.647
[45,     1] loss: 772.052
[46,     1] loss: 767.460
[47,     1] loss: 828.349
[48,     1] loss: 762.968
[49,     1] loss: 786.095
[50,     1] loss: 748.822
[51,     1] loss: 741.746
[52,     1] loss: 761.263
[53,     1] loss: 851.030
[54,     1] loss: 748.851
[55,     1] loss: 750.348
[56,     1] loss: 779.327
[57,     1] loss: 682.632
[58,     1] loss: 806.992
[59,     1] loss: 683.663
[60,     1] loss: 741.244
[61,     1] loss: 687.922
[62,     1] loss: 699.098
[63,     1] loss: 687.375
Early stopping applied (best metric=0.7985027432441711)
Finished Training
Total time taken: 10.299217224121094
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.035
[2,     1] loss: 1241.442
[3,     1] loss: 1237.226
[4,     1] loss: 1238.058
[5,     1] loss: 1232.120
[6,     1] loss: 1224.870
[7,     1] loss: 1212.078
[8,     1] loss: 1180.410
[9,     1] loss: 1156.296
[10,     1] loss: 1123.734
[11,     1] loss: 1083.493
[12,     1] loss: 1082.781
[13,     1] loss: 1011.516
[14,     1] loss: 1051.278
[15,     1] loss: 962.642
[16,     1] loss: 948.901
[17,     1] loss: 1001.137
[18,     1] loss: 960.749
[19,     1] loss: 981.352
[20,     1] loss: 954.405
[21,     1] loss: 899.820
[22,     1] loss: 913.185
[23,     1] loss: 921.888
[24,     1] loss: 913.734
[25,     1] loss: 894.391
[26,     1] loss: 918.405
[27,     1] loss: 926.395
[28,     1] loss: 896.120
[29,     1] loss: 887.735
[30,     1] loss: 821.561
[31,     1] loss: 868.266
Early stopping applied (best metric=1.0044965744018555)
Finished Training
Total time taken: 5.139107942581177
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.345
[2,     1] loss: 1239.117
[3,     1] loss: 1235.649
[4,     1] loss: 1236.583
[5,     1] loss: 1237.562
[6,     1] loss: 1234.392
[7,     1] loss: 1231.984
[8,     1] loss: 1230.269
[9,     1] loss: 1221.914
[10,     1] loss: 1208.579
[11,     1] loss: 1194.950
[12,     1] loss: 1172.964
[13,     1] loss: 1155.303
[14,     1] loss: 1118.251
[15,     1] loss: 1093.842
[16,     1] loss: 1096.074
[17,     1] loss: 1043.968
[18,     1] loss: 1074.394
[19,     1] loss: 1008.290
[20,     1] loss: 1038.984
[21,     1] loss: 1040.968
[22,     1] loss: 1021.494
[23,     1] loss: 1012.024
[24,     1] loss: 1006.555
[25,     1] loss: 1017.154
[26,     1] loss: 1007.381
[27,     1] loss: 1000.174
[28,     1] loss: 988.968
[29,     1] loss: 996.498
[30,     1] loss: 986.632
[31,     1] loss: 941.383
[32,     1] loss: 971.667
[33,     1] loss: 900.326
[34,     1] loss: 942.688
[35,     1] loss: 944.567
[36,     1] loss: 907.910
[37,     1] loss: 905.240
[38,     1] loss: 945.352
[39,     1] loss: 914.057
[40,     1] loss: 872.119
[41,     1] loss: 852.057
[42,     1] loss: 883.104
[43,     1] loss: 935.668
[44,     1] loss: 944.845
[45,     1] loss: 828.286
[46,     1] loss: 876.774
[47,     1] loss: 843.078
[48,     1] loss: 843.932
[49,     1] loss: 835.257
[50,     1] loss: 825.489
[51,     1] loss: 822.653
[52,     1] loss: 807.407
[53,     1] loss: 756.958
[54,     1] loss: 776.328
[55,     1] loss: 763.344
[56,     1] loss: 846.815
[57,     1] loss: 788.997
[58,     1] loss: 749.497
[59,     1] loss: 763.593
[60,     1] loss: 752.441
[61,     1] loss: 734.495
[62,     1] loss: 738.692
[63,     1] loss: 719.300
[64,     1] loss: 686.588
[65,     1] loss: 686.834
[66,     1] loss: 652.502
[67,     1] loss: 729.108
[68,     1] loss: 877.292
[69,     1] loss: 793.787
[70,     1] loss: 700.255
[71,     1] loss: 772.294
[72,     1] loss: 702.656
[73,     1] loss: 763.720
[74,     1] loss: 698.867
Early stopping applied (best metric=0.8234438896179199)
Finished Training
Total time taken: 10.999231815338135
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.023
[2,     1] loss: 1236.743
[3,     1] loss: 1237.157
[4,     1] loss: 1233.163
[5,     1] loss: 1238.636
[6,     1] loss: 1234.317
[7,     1] loss: 1232.468
[8,     1] loss: 1231.148
[9,     1] loss: 1217.978
[10,     1] loss: 1205.937
[11,     1] loss: 1184.968
[12,     1] loss: 1151.409
[13,     1] loss: 1117.500
[14,     1] loss: 1086.577
[15,     1] loss: 1057.172
[16,     1] loss: 1085.758
[17,     1] loss: 1037.965
[18,     1] loss: 1035.785
[19,     1] loss: 1004.169
[20,     1] loss: 1005.596
[21,     1] loss: 1018.466
[22,     1] loss: 1033.975
[23,     1] loss: 992.965
[24,     1] loss: 968.947
[25,     1] loss: 976.865
[26,     1] loss: 968.429
[27,     1] loss: 931.282
[28,     1] loss: 924.489
[29,     1] loss: 926.927
[30,     1] loss: 906.462
[31,     1] loss: 913.807
[32,     1] loss: 837.507
[33,     1] loss: 894.563
[34,     1] loss: 908.559
[35,     1] loss: 901.411
[36,     1] loss: 884.419
[37,     1] loss: 828.208
[38,     1] loss: 881.241
[39,     1] loss: 841.644
[40,     1] loss: 865.746
[41,     1] loss: 841.818
[42,     1] loss: 830.950
[43,     1] loss: 848.744
[44,     1] loss: 794.275
[45,     1] loss: 755.409
[46,     1] loss: 769.575
[47,     1] loss: 752.409
[48,     1] loss: 724.740
[49,     1] loss: 798.537
[50,     1] loss: 1089.259
[51,     1] loss: 1032.856
[52,     1] loss: 851.916
[53,     1] loss: 828.449
[54,     1] loss: 914.095
[55,     1] loss: 914.087
[56,     1] loss: 867.382
[57,     1] loss: 842.837
[58,     1] loss: 873.815
[59,     1] loss: 849.493
[60,     1] loss: 807.483
[61,     1] loss: 800.644
[62,     1] loss: 802.444
[63,     1] loss: 783.063
[64,     1] loss: 740.792
[65,     1] loss: 816.577
[66,     1] loss: 690.911
[67,     1] loss: 771.633
Early stopping applied (best metric=0.8760521411895752)
Finished Training
Total time taken: 10.09821343421936
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.207
[2,     1] loss: 1235.088
[3,     1] loss: 1235.259
[4,     1] loss: 1233.050
[5,     1] loss: 1229.889
[6,     1] loss: 1215.743
[7,     1] loss: 1204.228
[8,     1] loss: 1177.660
[9,     1] loss: 1122.547
[10,     1] loss: 1075.194
[11,     1] loss: 1074.873
[12,     1] loss: 1038.366
[13,     1] loss: 1012.753
[14,     1] loss: 1049.670
[15,     1] loss: 1031.888
[16,     1] loss: 1015.304
[17,     1] loss: 976.268
[18,     1] loss: 988.405
[19,     1] loss: 981.369
[20,     1] loss: 1001.958
[21,     1] loss: 992.361
[22,     1] loss: 991.591
[23,     1] loss: 948.319
[24,     1] loss: 956.051
[25,     1] loss: 939.328
[26,     1] loss: 923.281
[27,     1] loss: 950.709
[28,     1] loss: 947.838
[29,     1] loss: 888.610
[30,     1] loss: 911.621
[31,     1] loss: 888.697
[32,     1] loss: 879.292
[33,     1] loss: 862.050
[34,     1] loss: 844.316
[35,     1] loss: 813.364
[36,     1] loss: 880.769
[37,     1] loss: 870.042
[38,     1] loss: 807.264
[39,     1] loss: 847.813
[40,     1] loss: 827.971
[41,     1] loss: 810.680
[42,     1] loss: 808.709
[43,     1] loss: 803.819
[44,     1] loss: 776.114
[45,     1] loss: 748.791
[46,     1] loss: 731.301
[47,     1] loss: 718.966
[48,     1] loss: 703.645
[49,     1] loss: 820.188
[50,     1] loss: 1005.696
[51,     1] loss: 925.319
[52,     1] loss: 790.649
[53,     1] loss: 873.461
[54,     1] loss: 886.473
[55,     1] loss: 821.295
[56,     1] loss: 818.831
[57,     1] loss: 823.403
Early stopping applied (best metric=0.8073743581771851)
Finished Training
Total time taken: 9.424201488494873
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1239.049
[2,     1] loss: 1241.816
[3,     1] loss: 1235.149
[4,     1] loss: 1234.544
[5,     1] loss: 1232.269
[6,     1] loss: 1233.520
[7,     1] loss: 1202.574
[8,     1] loss: 1171.820
[9,     1] loss: 1127.744
[10,     1] loss: 1085.309
[11,     1] loss: 1058.577
[12,     1] loss: 1051.474
[13,     1] loss: 1049.081
[14,     1] loss: 1018.980
[15,     1] loss: 1001.991
[16,     1] loss: 1006.897
[17,     1] loss: 1037.411
[18,     1] loss: 994.174
[19,     1] loss: 1048.368
[20,     1] loss: 956.798
[21,     1] loss: 968.866
[22,     1] loss: 943.008
[23,     1] loss: 983.665
[24,     1] loss: 955.828
[25,     1] loss: 931.997
[26,     1] loss: 969.455
[27,     1] loss: 903.567
[28,     1] loss: 941.594
[29,     1] loss: 873.099
[30,     1] loss: 905.333
[31,     1] loss: 877.417
[32,     1] loss: 874.684
[33,     1] loss: 847.298
[34,     1] loss: 837.168
[35,     1] loss: 886.669
[36,     1] loss: 877.084
[37,     1] loss: 824.975
[38,     1] loss: 820.048
[39,     1] loss: 862.571
[40,     1] loss: 825.480
[41,     1] loss: 823.794
[42,     1] loss: 785.080
[43,     1] loss: 732.053
[44,     1] loss: 740.034
[45,     1] loss: 877.959
[46,     1] loss: 1066.118
[47,     1] loss: 860.689
[48,     1] loss: 851.205
[49,     1] loss: 795.438
[50,     1] loss: 892.944
[51,     1] loss: 857.952
Early stopping applied (best metric=0.8371599912643433)
Finished Training
Total time taken: 6.940146207809448
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.103
[2,     1] loss: 1237.729
[3,     1] loss: 1240.898
[4,     1] loss: 1233.964
[5,     1] loss: 1239.193
[6,     1] loss: 1238.632
[7,     1] loss: 1234.829
[8,     1] loss: 1230.717
[9,     1] loss: 1229.467
[10,     1] loss: 1219.582
[11,     1] loss: 1207.262
[12,     1] loss: 1183.418
[13,     1] loss: 1155.851
[14,     1] loss: 1132.887
[15,     1] loss: 1104.786
[16,     1] loss: 1082.390
[17,     1] loss: 1056.627
[18,     1] loss: 1023.898
[19,     1] loss: 1022.131
[20,     1] loss: 1022.135
[21,     1] loss: 966.437
[22,     1] loss: 1034.989
[23,     1] loss: 986.033
[24,     1] loss: 996.682
[25,     1] loss: 992.467
[26,     1] loss: 997.867
[27,     1] loss: 984.898
[28,     1] loss: 994.096
[29,     1] loss: 977.644
[30,     1] loss: 980.876
[31,     1] loss: 947.003
[32,     1] loss: 930.774
[33,     1] loss: 903.810
[34,     1] loss: 892.360
[35,     1] loss: 893.422
[36,     1] loss: 920.985
[37,     1] loss: 893.509
[38,     1] loss: 905.754
[39,     1] loss: 934.952
[40,     1] loss: 873.243
[41,     1] loss: 893.016
[42,     1] loss: 908.004
[43,     1] loss: 857.956
[44,     1] loss: 874.090
[45,     1] loss: 866.777
[46,     1] loss: 858.994
[47,     1] loss: 883.947
[48,     1] loss: 813.597
[49,     1] loss: 799.099
[50,     1] loss: 764.417
[51,     1] loss: 818.016
[52,     1] loss: 807.532
[53,     1] loss: 851.380
[54,     1] loss: 840.818
[55,     1] loss: 793.893
[56,     1] loss: 801.118
[57,     1] loss: 755.881
[58,     1] loss: 802.395
[59,     1] loss: 717.024
[60,     1] loss: 725.759
[61,     1] loss: 707.797
[62,     1] loss: 666.945
[63,     1] loss: 684.180
[64,     1] loss: 604.865
[65,     1] loss: 697.897
[66,     1] loss: 822.966
[67,     1] loss: 1085.088
[68,     1] loss: 716.102
[69,     1] loss: 860.792
[70,     1] loss: 726.952
[71,     1] loss: 779.552
[72,     1] loss: 835.384
[73,     1] loss: 804.089
[74,     1] loss: 752.678
[75,     1] loss: 790.941
[76,     1] loss: 748.629
[77,     1] loss: 681.433
[78,     1] loss: 730.255
[79,     1] loss: 670.789
[80,     1] loss: 679.251
[81,     1] loss: 571.987
[82,     1] loss: 621.562
[83,     1] loss: 616.140
[84,     1] loss: 548.589
[85,     1] loss: 609.548
[86,     1] loss: 570.804
[87,     1] loss: 566.958
[88,     1] loss: 622.145
[89,     1] loss: 601.998
[90,     1] loss: 605.183
[91,     1] loss: 581.988
[92,     1] loss: 511.512
[93,     1] loss: 555.740
[94,     1] loss: 551.898
[95,     1] loss: 500.646
[96,     1] loss: 463.585
[97,     1] loss: 483.474
[98,     1] loss: 498.810
[99,     1] loss: 546.873
[100,     1] loss: 791.724
[101,     1] loss: 1454.398
Early stopping applied (best metric=0.7120153903961182)
Finished Training
Total time taken: 16.05733847618103
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1238.755
[2,     1] loss: 1236.915
[3,     1] loss: 1235.303
[4,     1] loss: 1232.356
[5,     1] loss: 1228.819
[6,     1] loss: 1228.298
[7,     1] loss: 1209.028
[8,     1] loss: 1173.307
[9,     1] loss: 1139.521
[10,     1] loss: 1101.746
[11,     1] loss: 1075.706
[12,     1] loss: 1104.711
[13,     1] loss: 1103.512
[14,     1] loss: 1053.236
[15,     1] loss: 1018.699
[16,     1] loss: 1052.595
[17,     1] loss: 1025.322
[18,     1] loss: 1005.877
[19,     1] loss: 1006.602
[20,     1] loss: 1033.395
[21,     1] loss: 988.612
[22,     1] loss: 1006.417
[23,     1] loss: 983.493
[24,     1] loss: 958.383
[25,     1] loss: 971.392
[26,     1] loss: 936.862
[27,     1] loss: 937.531
[28,     1] loss: 954.370
[29,     1] loss: 918.670
[30,     1] loss: 976.192
[31,     1] loss: 982.383
[32,     1] loss: 929.391
[33,     1] loss: 935.830
[34,     1] loss: 907.227
[35,     1] loss: 928.511
[36,     1] loss: 889.558
[37,     1] loss: 961.902
[38,     1] loss: 856.367
[39,     1] loss: 873.470
[40,     1] loss: 831.599
[41,     1] loss: 885.513
[42,     1] loss: 857.633
[43,     1] loss: 935.237
[44,     1] loss: 813.607
[45,     1] loss: 873.384
[46,     1] loss: 805.096
[47,     1] loss: 896.061
[48,     1] loss: 806.230
[49,     1] loss: 912.834
[50,     1] loss: 790.272
[51,     1] loss: 873.275
[52,     1] loss: 760.041
[53,     1] loss: 816.525
[54,     1] loss: 776.500
[55,     1] loss: 815.660
[56,     1] loss: 771.175
[57,     1] loss: 854.339
[58,     1] loss: 783.751
[59,     1] loss: 822.670
[60,     1] loss: 765.761
[61,     1] loss: 747.152
[62,     1] loss: 781.406
[63,     1] loss: 675.653
[64,     1] loss: 767.563
[65,     1] loss: 760.433
[66,     1] loss: 736.317
[67,     1] loss: 663.346
[68,     1] loss: 692.217
[69,     1] loss: 767.738
Early stopping applied (best metric=0.6964766979217529)
Finished Training
Total time taken: 10.458220481872559
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.831
[2,     1] loss: 1235.477
[3,     1] loss: 1237.005
[4,     1] loss: 1237.417
[5,     1] loss: 1231.933
[6,     1] loss: 1230.681
[7,     1] loss: 1224.443
[8,     1] loss: 1207.393
[9,     1] loss: 1177.886
[10,     1] loss: 1143.623
[11,     1] loss: 1101.292
[12,     1] loss: 1085.674
[13,     1] loss: 1073.953
[14,     1] loss: 1018.988
[15,     1] loss: 1040.961
[16,     1] loss: 995.645
[17,     1] loss: 1033.073
[18,     1] loss: 1005.410
[19,     1] loss: 1028.160
[20,     1] loss: 987.604
[21,     1] loss: 992.761
[22,     1] loss: 970.035
[23,     1] loss: 941.710
[24,     1] loss: 961.345
[25,     1] loss: 922.838
[26,     1] loss: 966.144
[27,     1] loss: 905.731
[28,     1] loss: 954.647
[29,     1] loss: 855.718
[30,     1] loss: 872.832
[31,     1] loss: 885.333
[32,     1] loss: 857.133
[33,     1] loss: 846.504
[34,     1] loss: 878.188
[35,     1] loss: 871.817
[36,     1] loss: 860.926
[37,     1] loss: 787.534
[38,     1] loss: 794.998
[39,     1] loss: 868.126
[40,     1] loss: 826.687
[41,     1] loss: 818.205
[42,     1] loss: 767.531
[43,     1] loss: 824.753
[44,     1] loss: 847.247
[45,     1] loss: 771.380
[46,     1] loss: 761.217
[47,     1] loss: 823.984
[48,     1] loss: 723.276
[49,     1] loss: 797.475
[50,     1] loss: 803.545
[51,     1] loss: 697.704
[52,     1] loss: 774.487
[53,     1] loss: 731.255
[54,     1] loss: 707.278
[55,     1] loss: 723.167
[56,     1] loss: 674.305
[57,     1] loss: 657.626
[58,     1] loss: 678.400
[59,     1] loss: 610.232
[60,     1] loss: 729.102
[61,     1] loss: 930.466
[62,     1] loss: 722.868
[63,     1] loss: 772.238
[64,     1] loss: 681.275
[65,     1] loss: 777.091
[66,     1] loss: 708.446
[67,     1] loss: 695.045
[68,     1] loss: 707.087
[69,     1] loss: 640.760
[70,     1] loss: 612.318
[71,     1] loss: 603.361
[72,     1] loss: 644.123
Early stopping applied (best metric=0.8735922574996948)
Finished Training
Total time taken: 11.23823881149292
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1237.692
[2,     1] loss: 1239.082
[3,     1] loss: 1239.503
[4,     1] loss: 1236.966
[5,     1] loss: 1232.729
[6,     1] loss: 1233.339
[7,     1] loss: 1225.768
[8,     1] loss: 1215.691
[9,     1] loss: 1203.678
[10,     1] loss: 1169.896
[11,     1] loss: 1138.983
[12,     1] loss: 1081.540
[13,     1] loss: 1062.788
[14,     1] loss: 1055.595
[15,     1] loss: 1055.870
[16,     1] loss: 1027.486
[17,     1] loss: 980.965
[18,     1] loss: 1037.064
[19,     1] loss: 1024.433
[20,     1] loss: 985.188
[21,     1] loss: 980.605
[22,     1] loss: 958.385
[23,     1] loss: 993.908
[24,     1] loss: 955.208
[25,     1] loss: 948.224
[26,     1] loss: 931.850
[27,     1] loss: 918.536
[28,     1] loss: 980.451
[29,     1] loss: 909.688
[30,     1] loss: 922.749
[31,     1] loss: 888.165
[32,     1] loss: 870.893
[33,     1] loss: 874.423
[34,     1] loss: 917.783
[35,     1] loss: 900.787
[36,     1] loss: 863.496
[37,     1] loss: 871.448
[38,     1] loss: 843.026
[39,     1] loss: 893.383
[40,     1] loss: 845.195
[41,     1] loss: 832.589
[42,     1] loss: 832.521
[43,     1] loss: 793.122
[44,     1] loss: 814.863
[45,     1] loss: 752.612
[46,     1] loss: 804.021
[47,     1] loss: 883.068
[48,     1] loss: 975.108
[49,     1] loss: 741.410
[50,     1] loss: 906.532
[51,     1] loss: 820.406
[52,     1] loss: 847.579
[53,     1] loss: 883.574
[54,     1] loss: 804.761
[55,     1] loss: 777.309
[56,     1] loss: 864.499
[57,     1] loss: 762.364
[58,     1] loss: 835.286
[59,     1] loss: 779.605
[60,     1] loss: 732.024
[61,     1] loss: 740.115
[62,     1] loss: 693.655
[63,     1] loss: 728.186
[64,     1] loss: 753.711
[65,     1] loss: 739.779
[66,     1] loss: 725.838
[67,     1] loss: 666.611
[68,     1] loss: 688.728
[69,     1] loss: 672.490
[70,     1] loss: 670.972
[71,     1] loss: 673.727
[72,     1] loss: 693.288
[73,     1] loss: 747.870
[74,     1] loss: 754.748
[75,     1] loss: 639.771
[76,     1] loss: 655.171
[77,     1] loss: 650.893
[78,     1] loss: 623.566
[79,     1] loss: 634.003
[80,     1] loss: 625.271
[81,     1] loss: 645.467
[82,     1] loss: 847.938
[83,     1] loss: 600.275
[84,     1] loss: 595.448
[85,     1] loss: 629.553
[86,     1] loss: 605.802
Early stopping applied (best metric=0.7684834599494934)
Finished Training
Total time taken: 11.882251024246216
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1240.604
[2,     1] loss: 1238.224
[3,     1] loss: 1238.178
[4,     1] loss: 1239.999
[5,     1] loss: 1228.906
[6,     1] loss: 1216.235
[7,     1] loss: 1195.151
[8,     1] loss: 1152.813
[9,     1] loss: 1111.256
[10,     1] loss: 1094.301
[11,     1] loss: 1044.671
[12,     1] loss: 1029.111
[13,     1] loss: 1031.639
[14,     1] loss: 1008.098
[15,     1] loss: 999.476
[16,     1] loss: 1025.257
[17,     1] loss: 987.478
[18,     1] loss: 968.141
[19,     1] loss: 968.613
[20,     1] loss: 980.634
[21,     1] loss: 972.750
[22,     1] loss: 945.230
[23,     1] loss: 896.621
[24,     1] loss: 984.030
[25,     1] loss: 892.055
[26,     1] loss: 880.936
[27,     1] loss: 882.719
[28,     1] loss: 863.171
[29,     1] loss: 910.280
[30,     1] loss: 875.641
[31,     1] loss: 807.315
[32,     1] loss: 848.819
[33,     1] loss: 869.032
[34,     1] loss: 822.463
[35,     1] loss: 866.102
[36,     1] loss: 857.576
[37,     1] loss: 777.278
[38,     1] loss: 808.939
[39,     1] loss: 775.465
[40,     1] loss: 799.322
[41,     1] loss: 837.854
[42,     1] loss: 738.147
[43,     1] loss: 776.391
[44,     1] loss: 766.949
[45,     1] loss: 738.573
[46,     1] loss: 741.256
[47,     1] loss: 679.185
[48,     1] loss: 769.686
[49,     1] loss: 742.640
[50,     1] loss: 695.885
[51,     1] loss: 651.288
[52,     1] loss: 697.091
[53,     1] loss: 644.966
[54,     1] loss: 660.103
[55,     1] loss: 633.126
[56,     1] loss: 659.153
[57,     1] loss: 609.772
[58,     1] loss: 549.335
[59,     1] loss: 799.214
[60,     1] loss: 1356.159
[61,     1] loss: 653.749
[62,     1] loss: 1054.130
[63,     1] loss: 814.699
[64,     1] loss: 835.977
Early stopping applied (best metric=0.9101532697677612)
Finished Training
Total time taken: 10.220214605331421
{'Hydroxylation-K Validation Accuracy': 0.736790780141844, 'Hydroxylation-K Validation Sensitivity': 0.64, 'Hydroxylation-K Validation Specificity': 0.7614035087719299, 'Hydroxylation-K Validation Precision': 0.4188654047477577, 'Hydroxylation-K AUC ROC': 0.7609356725146199, 'Hydroxylation-K AUC PR': 0.5063224320047099, 'Hydroxylation-K MCC': 0.3526810957554573, 'Hydroxylation-K F1': 0.5009751572974304, 'Validation Loss (Hydroxylation-K)': 0.469015888373057, 'Hydroxylation-P Validation Accuracy': 0.78724881985686, 'Hydroxylation-P Validation Sensitivity': 0.8165608465608466, 'Hydroxylation-P Validation Specificity': 0.7809990523218115, 'Hydroxylation-P Validation Precision': 0.45139732979536734, 'Hydroxylation-P AUC ROC': 0.8664766995464287, 'Hydroxylation-P AUC PR': 0.63021633140548, 'Hydroxylation-P MCC': 0.4907317325540327, 'Hydroxylation-P F1': 0.5781940885732814, 'Validation Loss (Hydroxylation-P)': 0.3607984165350596, 'Validation Loss (total)': 0.8298143068949382, 'TimeToTrain': 10.006210978825887}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004106112984816619,
 'learning_rate_Hydroxylation-K': 0.0007194405129521699,
 'learning_rate_Hydroxylation-P': 0.00487976001768925,
 'log_base': 2.8680202900919585,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4045751093,
 'sample_weights': [1.5582080320955507, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.788043794912788,
 'weight_decay_Hydroxylation-K': 0.22928266659223384,
 'weight_decay_Hydroxylation-P': 8.11551601706505}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1247.459
[2,     1] loss: 1244.551
[3,     1] loss: 1242.588
[4,     1] loss: 1244.812
[5,     1] loss: 1239.661
[6,     1] loss: 1239.014
[7,     1] loss: 1235.894
[8,     1] loss: 1221.041
[9,     1] loss: 1196.731
[10,     1] loss: 1165.939
[11,     1] loss: 1133.734
[12,     1] loss: 1115.103
[13,     1] loss: 1048.821
[14,     1] loss: 1064.582
[15,     1] loss: 1060.785
[16,     1] loss: 1121.853
[17,     1] loss: 1062.025
[18,     1] loss: 986.719
[19,     1] loss: 1037.682
[20,     1] loss: 1014.680
[21,     1] loss: 1000.590
[22,     1] loss: 968.693
[23,     1] loss: 959.140
[24,     1] loss: 1002.516
[25,     1] loss: 958.369
[26,     1] loss: 918.037
[27,     1] loss: 923.522
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0065525284425142,
 'learning_rate_Hydroxylation-K': 0.00030419336863215753,
 'learning_rate_Hydroxylation-P': 0.005990906910873609,
 'log_base': 1.1135293246120708,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 957426878,
 'sample_weights': [1.5844801566456679, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.887179419461162,
 'weight_decay_Hydroxylation-K': 2.2007810399807592,
 'weight_decay_Hydroxylation-P': 8.827643502944165}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 5044.134
[2,     1] loss: 5061.144
[3,     1] loss: 5071.043
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004383909627553848,
 'learning_rate_Hydroxylation-K': 0.00040239389915140385,
 'learning_rate_Hydroxylation-P': 0.00145971248902428,
 'log_base': 2.706632794732576,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 924553849,
 'sample_weights': [15.524715151366767, 1.9406641532169868],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.57598989524643,
 'weight_decay_Hydroxylation-K': 8.984523451782472,
 'weight_decay_Hydroxylation-P': 5.514887756864656}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1267.137
[2,     1] loss: 1258.512
[3,     1] loss: 1270.028
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018687431801983681,
 'learning_rate_Hydroxylation-K': 0.001774556787578172,
 'learning_rate_Hydroxylation-P': 0.0003994397859040011,
 'log_base': 2.232083539501255,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 234923253,
 'sample_weights': [1.6766437435221428, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.5212139514670096,
 'weight_decay_Hydroxylation-K': 7.763511445466676,
 'weight_decay_Hydroxylation-P': 1.9238885461406414}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1349.115
[2,     1] loss: 1345.503
[3,     1] loss: 1345.449
[4,     1] loss: 1342.898
[5,     1] loss: 1339.331
[6,     1] loss: 1327.067
[7,     1] loss: 1310.161
[8,     1] loss: 1281.041
[9,     1] loss: 1235.128
[10,     1] loss: 1207.235
[11,     1] loss: 1157.189
[12,     1] loss: 1143.003
[13,     1] loss: 1148.887
[14,     1] loss: 1188.269
[15,     1] loss: 1118.475
[16,     1] loss: 1074.550
[17,     1] loss: 1063.472
[18,     1] loss: 1033.269
[19,     1] loss: 1038.138
[20,     1] loss: 1057.903
[21,     1] loss: 1047.349
[22,     1] loss: 1022.231
[23,     1] loss: 1016.036
[24,     1] loss: 1064.997
[25,     1] loss: 1004.254
[26,     1] loss: 999.432
[27,     1] loss: 999.799
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0004384845924331575,
 'learning_rate_Hydroxylation-K': 0.007625146124356998,
 'learning_rate_Hydroxylation-P': 0.0020268178687734666,
 'log_base': 2.8585477949481173,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3262615794,
 'sample_weights': [2.0791747354879937, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.351640212431933,
 'weight_decay_Hydroxylation-K': 1.3189070947841817,
 'weight_decay_Hydroxylation-P': 2.9949048995359613}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1247.531
[2,     1] loss: 1242.357
[3,     1] loss: 1243.555
[4,     1] loss: 1244.456
[5,     1] loss: 1244.560
[6,     1] loss: 1243.797
[7,     1] loss: 1241.428
[8,     1] loss: 1241.234
[9,     1] loss: 1242.361
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008968842705332497,
 'learning_rate_Hydroxylation-K': 0.008063234570287606,
 'learning_rate_Hydroxylation-P': 0.0008494261616728812,
 'log_base': 1.8531548160722326,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3188163114,
 'sample_weights': [1.5894709330787145, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.0305098067410094,
 'weight_decay_Hydroxylation-K': 6.138033827718678,
 'weight_decay_Hydroxylation-P': 3.4397716569326175}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1479.056
[2,     1] loss: 1485.300
[3,     1] loss: 1479.440
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008901880360176917,
 'learning_rate_Hydroxylation-K': 0.0087589032240356,
 'learning_rate_Hydroxylation-P': 0.003845245948417001,
 'log_base': 1.294575751005117,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2928944724,
 'sample_weights': [2.7062272371324583, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.175090049258454,
 'weight_decay_Hydroxylation-K': 5.214706567330934,
 'weight_decay_Hydroxylation-P': 4.0638509646344785}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2274.639
[2,     1] loss: 2281.156
[3,     1] loss: 2344.530
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004713880587083422,
 'learning_rate_Hydroxylation-K': 0.00035125585380433005,
 'learning_rate_Hydroxylation-P': 1.0143810557194255e-05,
 'log_base': 2.3914868984955886,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2768021680,
 'sample_weights': [6.466122533838171, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7432571222400473,
 'weight_decay_Hydroxylation-K': 9.929390606968795,
 'weight_decay_Hydroxylation-P': 1.3716740544762007}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1313.318
[2,     1] loss: 1320.119
[3,     1] loss: 1311.011
[4,     1] loss: 1311.822
[5,     1] loss: 1309.301
[6,     1] loss: 1308.866
[7,     1] loss: 1304.550
[8,     1] loss: 1295.313
[9,     1] loss: 1296.231
[10,     1] loss: 1270.037
[11,     1] loss: 1257.181
[12,     1] loss: 1219.804
[13,     1] loss: 1222.703
[14,     1] loss: 1173.994
[15,     1] loss: 1163.586
[16,     1] loss: 1119.492
[17,     1] loss: 1138.639
[18,     1] loss: 1156.626
[19,     1] loss: 1105.771
[20,     1] loss: 1119.013
[21,     1] loss: 1087.566
[22,     1] loss: 1081.948
[23,     1] loss: 1062.509
[24,     1] loss: 1074.028
[25,     1] loss: 1040.011
[26,     1] loss: 1018.392
[27,     1] loss: 1032.050
[28,     1] loss: 1057.219
[29,     1] loss: 1046.543
[30,     1] loss: 981.278
[31,     1] loss: 939.013
[32,     1] loss: 926.456
[33,     1] loss: 960.723
[34,     1] loss: 949.324
[35,     1] loss: 1036.970
[36,     1] loss: 966.138
[37,     1] loss: 914.313
[38,     1] loss: 920.259
[39,     1] loss: 919.719
[40,     1] loss: 900.270
[41,     1] loss: 886.446
[42,     1] loss: 897.868
[43,     1] loss: 871.346
[44,     1] loss: 846.592
[45,     1] loss: 886.297
[46,     1] loss: 826.935
[47,     1] loss: 880.509
[48,     1] loss: 822.923
Early stopping applied (best metric=0.8053051233291626)
Finished Training
Total time taken: 7.400158166885376
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1316.418
[2,     1] loss: 1320.189
[3,     1] loss: 1312.882
[4,     1] loss: 1313.537
[5,     1] loss: 1320.116
[6,     1] loss: 1315.965
[7,     1] loss: 1307.185
[8,     1] loss: 1310.736
[9,     1] loss: 1310.844
[10,     1] loss: 1301.880
[11,     1] loss: 1296.141
[12,     1] loss: 1286.652
[13,     1] loss: 1268.856
[14,     1] loss: 1245.200
[15,     1] loss: 1239.065
[16,     1] loss: 1210.932
[17,     1] loss: 1189.751
[18,     1] loss: 1169.538
[19,     1] loss: 1140.689
[20,     1] loss: 1101.170
[21,     1] loss: 1077.238
[22,     1] loss: 1082.572
[23,     1] loss: 1066.507
[24,     1] loss: 1054.958
[25,     1] loss: 1025.118
[26,     1] loss: 1047.040
[27,     1] loss: 1016.999
[28,     1] loss: 1020.174
[29,     1] loss: 1018.363
[30,     1] loss: 1021.693
[31,     1] loss: 1050.688
[32,     1] loss: 994.095
[33,     1] loss: 998.310
[34,     1] loss: 970.517
[35,     1] loss: 962.378
[36,     1] loss: 963.154
Early stopping applied (best metric=0.9375051259994507)
Finished Training
Total time taken: 6.249134302139282
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1311.749
[2,     1] loss: 1310.151
[3,     1] loss: 1312.971
[4,     1] loss: 1310.994
[5,     1] loss: 1310.749
[6,     1] loss: 1301.448
[7,     1] loss: 1294.920
[8,     1] loss: 1264.516
[9,     1] loss: 1242.317
[10,     1] loss: 1208.165
[11,     1] loss: 1189.748
[12,     1] loss: 1153.902
[13,     1] loss: 1109.911
[14,     1] loss: 1152.182
[15,     1] loss: 1138.548
[16,     1] loss: 1044.947
[17,     1] loss: 1114.923
[18,     1] loss: 1094.910
[19,     1] loss: 1074.312
[20,     1] loss: 1063.316
[21,     1] loss: 1080.119
[22,     1] loss: 1079.623
[23,     1] loss: 1064.989
[24,     1] loss: 1019.721
[25,     1] loss: 1075.969
[26,     1] loss: 1033.847
[27,     1] loss: 1011.508
[28,     1] loss: 1024.826
[29,     1] loss: 985.951
[30,     1] loss: 1003.342
[31,     1] loss: 1028.239
[32,     1] loss: 1033.449
[33,     1] loss: 936.413
[34,     1] loss: 977.508
[35,     1] loss: 968.081
[36,     1] loss: 951.495
[37,     1] loss: 908.925
[38,     1] loss: 900.594
[39,     1] loss: 931.511
[40,     1] loss: 885.119
[41,     1] loss: 930.845
[42,     1] loss: 935.811
[43,     1] loss: 895.755
[44,     1] loss: 847.083
[45,     1] loss: 889.679
[46,     1] loss: 903.094
Early stopping applied (best metric=0.7838423848152161)
Finished Training
Total time taken: 7.960168838500977
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1317.760
[2,     1] loss: 1312.751
[3,     1] loss: 1315.208
[4,     1] loss: 1315.017
[5,     1] loss: 1315.511
[6,     1] loss: 1309.901
[7,     1] loss: 1310.083
[8,     1] loss: 1309.307
[9,     1] loss: 1300.565
[10,     1] loss: 1289.346
[11,     1] loss: 1274.462
[12,     1] loss: 1247.051
[13,     1] loss: 1194.686
[14,     1] loss: 1172.485
[15,     1] loss: 1134.607
[16,     1] loss: 1100.490
[17,     1] loss: 1085.993
[18,     1] loss: 1126.404
[19,     1] loss: 1136.509
[20,     1] loss: 1079.386
[21,     1] loss: 1085.389
[22,     1] loss: 1000.072
[23,     1] loss: 1087.753
[24,     1] loss: 1046.234
[25,     1] loss: 1067.286
[26,     1] loss: 1042.594
[27,     1] loss: 997.412
[28,     1] loss: 1017.829
[29,     1] loss: 1037.189
[30,     1] loss: 974.178
[31,     1] loss: 1039.187
[32,     1] loss: 963.936
[33,     1] loss: 1009.372
[34,     1] loss: 950.042
[35,     1] loss: 964.668
[36,     1] loss: 965.823
[37,     1] loss: 968.127
[38,     1] loss: 964.896
[39,     1] loss: 974.045
[40,     1] loss: 954.897
[41,     1] loss: 982.420
[42,     1] loss: 944.279
[43,     1] loss: 917.538
[44,     1] loss: 983.622
[45,     1] loss: 906.434
[46,     1] loss: 904.277
[47,     1] loss: 932.829
[48,     1] loss: 948.311
[49,     1] loss: 897.672
[50,     1] loss: 899.875
[51,     1] loss: 864.735
[52,     1] loss: 841.760
[53,     1] loss: 892.276
[54,     1] loss: 842.011
[55,     1] loss: 881.433
[56,     1] loss: 840.158
[57,     1] loss: 840.967
[58,     1] loss: 824.549
[59,     1] loss: 778.705
[60,     1] loss: 813.118
[61,     1] loss: 793.110
[62,     1] loss: 760.416
Early stopping applied (best metric=0.8766851425170898)
Finished Training
Total time taken: 9.241194725036621
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1314.246
[2,     1] loss: 1325.861
[3,     1] loss: 1314.050
[4,     1] loss: 1316.610
[5,     1] loss: 1312.112
[6,     1] loss: 1312.053
[7,     1] loss: 1313.797
[8,     1] loss: 1309.928
[9,     1] loss: 1311.779
[10,     1] loss: 1311.526
[11,     1] loss: 1302.061
[12,     1] loss: 1295.427
[13,     1] loss: 1289.904
[14,     1] loss: 1277.649
[15,     1] loss: 1250.571
[16,     1] loss: 1219.145
[17,     1] loss: 1189.113
[18,     1] loss: 1160.838
[19,     1] loss: 1143.913
[20,     1] loss: 1119.852
[21,     1] loss: 1128.443
[22,     1] loss: 1079.568
[23,     1] loss: 1129.761
[24,     1] loss: 1085.475
[25,     1] loss: 1065.619
[26,     1] loss: 1115.829
[27,     1] loss: 1102.106
[28,     1] loss: 1082.155
[29,     1] loss: 1071.749
[30,     1] loss: 1031.745
[31,     1] loss: 1042.280
[32,     1] loss: 1033.165
[33,     1] loss: 1012.025
[34,     1] loss: 1010.479
[35,     1] loss: 988.635
[36,     1] loss: 1010.478
[37,     1] loss: 1016.633
[38,     1] loss: 964.786
[39,     1] loss: 962.480
[40,     1] loss: 997.607
[41,     1] loss: 962.438
[42,     1] loss: 937.579
[43,     1] loss: 929.447
[44,     1] loss: 965.557
[45,     1] loss: 950.707
[46,     1] loss: 890.035
[47,     1] loss: 927.062
[48,     1] loss: 908.218
[49,     1] loss: 912.322
[50,     1] loss: 917.520
[51,     1] loss: 915.008
[52,     1] loss: 909.170
[53,     1] loss: 866.641
[54,     1] loss: 895.706
[55,     1] loss: 785.382
[56,     1] loss: 850.383
[57,     1] loss: 853.953
[58,     1] loss: 857.232
[59,     1] loss: 807.014
[60,     1] loss: 816.321
[61,     1] loss: 845.319
[62,     1] loss: 822.727
[63,     1] loss: 827.303
[64,     1] loss: 811.420
[65,     1] loss: 832.474
[66,     1] loss: 822.981
[67,     1] loss: 776.271
[68,     1] loss: 768.617
[69,     1] loss: 797.386
[70,     1] loss: 714.101
[71,     1] loss: 835.041
[72,     1] loss: 737.162
[73,     1] loss: 780.035
[74,     1] loss: 793.874
Early stopping applied (best metric=0.8463902473449707)
Finished Training
Total time taken: 11.636248588562012
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1314.554
[2,     1] loss: 1335.358
[3,     1] loss: 1321.937
[4,     1] loss: 1313.392
[5,     1] loss: 1310.997
[6,     1] loss: 1311.230
[7,     1] loss: 1307.769
[8,     1] loss: 1307.113
[9,     1] loss: 1303.323
[10,     1] loss: 1301.001
[11,     1] loss: 1290.868
[12,     1] loss: 1271.539
[13,     1] loss: 1232.627
[14,     1] loss: 1207.059
[15,     1] loss: 1169.112
[16,     1] loss: 1139.013
[17,     1] loss: 1119.911
[18,     1] loss: 1091.605
[19,     1] loss: 1076.283
[20,     1] loss: 1111.645
[21,     1] loss: 1053.571
[22,     1] loss: 1087.209
[23,     1] loss: 1092.921
[24,     1] loss: 1075.065
[25,     1] loss: 1026.144
[26,     1] loss: 1032.914
[27,     1] loss: 1033.035
[28,     1] loss: 1064.971
[29,     1] loss: 993.389
[30,     1] loss: 989.235
[31,     1] loss: 984.872
[32,     1] loss: 983.033
[33,     1] loss: 952.315
[34,     1] loss: 967.532
[35,     1] loss: 978.216
[36,     1] loss: 947.475
[37,     1] loss: 939.886
[38,     1] loss: 986.827
[39,     1] loss: 967.466
[40,     1] loss: 942.615
[41,     1] loss: 956.280
[42,     1] loss: 981.235
[43,     1] loss: 895.162
[44,     1] loss: 971.958
[45,     1] loss: 911.421
[46,     1] loss: 883.473
[47,     1] loss: 884.128
[48,     1] loss: 894.794
[49,     1] loss: 850.778
[50,     1] loss: 839.569
[51,     1] loss: 857.445
[52,     1] loss: 890.809
[53,     1] loss: 840.652
[54,     1] loss: 840.535
[55,     1] loss: 796.102
[56,     1] loss: 799.744
[57,     1] loss: 819.743
[58,     1] loss: 784.374
[59,     1] loss: 790.453
[60,     1] loss: 747.197
[61,     1] loss: 769.842
[62,     1] loss: 783.911
[63,     1] loss: 748.563
[64,     1] loss: 704.455
[65,     1] loss: 728.950
[66,     1] loss: 726.661
[67,     1] loss: 714.466
[68,     1] loss: 719.493
[69,     1] loss: 784.144
[70,     1] loss: 701.663
[71,     1] loss: 746.570
[72,     1] loss: 713.900
[73,     1] loss: 704.873
Early stopping applied (best metric=0.851671576499939)
Finished Training
Total time taken: 10.65522575378418
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1313.928
[2,     1] loss: 1312.448
[3,     1] loss: 1306.925
[4,     1] loss: 1305.590
[5,     1] loss: 1277.814
[6,     1] loss: 1234.594
[7,     1] loss: 1232.567
[8,     1] loss: 1162.713
[9,     1] loss: 1137.263
[10,     1] loss: 1140.170
[11,     1] loss: 1112.090
[12,     1] loss: 1086.670
[13,     1] loss: 1081.296
[14,     1] loss: 1056.466
[15,     1] loss: 1064.523
[16,     1] loss: 1063.566
[17,     1] loss: 1040.222
[18,     1] loss: 1046.229
[19,     1] loss: 1029.530
[20,     1] loss: 991.157
[21,     1] loss: 1055.423
[22,     1] loss: 1002.175
[23,     1] loss: 996.594
[24,     1] loss: 1001.155
[25,     1] loss: 976.334
[26,     1] loss: 973.148
[27,     1] loss: 939.994
[28,     1] loss: 1006.881
[29,     1] loss: 941.473
[30,     1] loss: 969.553
[31,     1] loss: 883.815
[32,     1] loss: 952.666
[33,     1] loss: 939.219
[34,     1] loss: 973.164
[35,     1] loss: 914.890
[36,     1] loss: 910.804
[37,     1] loss: 891.603
[38,     1] loss: 928.302
[39,     1] loss: 869.969
[40,     1] loss: 863.049
[41,     1] loss: 886.111
[42,     1] loss: 839.738
[43,     1] loss: 822.454
[44,     1] loss: 812.690
[45,     1] loss: 814.002
[46,     1] loss: 812.452
[47,     1] loss: 829.925
[48,     1] loss: 799.527
[49,     1] loss: 819.910
[50,     1] loss: 767.788
[51,     1] loss: 836.641
[52,     1] loss: 834.057
[53,     1] loss: 778.661
[54,     1] loss: 851.065
[55,     1] loss: 797.199
[56,     1] loss: 796.983
Early stopping applied (best metric=0.8340795040130615)
Finished Training
Total time taken: 7.778163433074951
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1317.644
[2,     1] loss: 1313.554
[3,     1] loss: 1311.948
[4,     1] loss: 1321.751
[5,     1] loss: 1309.695
[6,     1] loss: 1309.753
[7,     1] loss: 1303.405
[8,     1] loss: 1296.245
[9,     1] loss: 1291.775
[10,     1] loss: 1278.892
[11,     1] loss: 1233.787
[12,     1] loss: 1204.327
[13,     1] loss: 1158.780
[14,     1] loss: 1115.847
[15,     1] loss: 1119.429
[16,     1] loss: 1140.067
[17,     1] loss: 1119.825
[18,     1] loss: 1142.004
[19,     1] loss: 1054.732
[20,     1] loss: 1067.907
[21,     1] loss: 1137.862
[22,     1] loss: 1088.822
[23,     1] loss: 1106.182
[24,     1] loss: 1094.467
[25,     1] loss: 1031.409
[26,     1] loss: 1055.292
[27,     1] loss: 1006.677
[28,     1] loss: 1045.594
[29,     1] loss: 1030.985
[30,     1] loss: 1020.365
[31,     1] loss: 1028.902
[32,     1] loss: 993.531
[33,     1] loss: 1005.748
[34,     1] loss: 975.625
[35,     1] loss: 971.690
[36,     1] loss: 921.220
[37,     1] loss: 933.462
[38,     1] loss: 924.823
[39,     1] loss: 919.921
[40,     1] loss: 871.851
[41,     1] loss: 896.097
[42,     1] loss: 895.039
[43,     1] loss: 878.036
[44,     1] loss: 904.645
[45,     1] loss: 864.855
[46,     1] loss: 937.360
[47,     1] loss: 819.870
[48,     1] loss: 835.774
[49,     1] loss: 846.029
[50,     1] loss: 807.987
[51,     1] loss: 831.108
Early stopping applied (best metric=0.7958543300628662)
Finished Training
Total time taken: 7.242151260375977
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1314.691
[2,     1] loss: 1321.258
[3,     1] loss: 1315.128
[4,     1] loss: 1312.225
[5,     1] loss: 1311.349
[6,     1] loss: 1313.885
[7,     1] loss: 1309.206
[8,     1] loss: 1306.521
[9,     1] loss: 1306.500
[10,     1] loss: 1299.283
[11,     1] loss: 1289.873
[12,     1] loss: 1281.871
[13,     1] loss: 1254.156
[14,     1] loss: 1228.328
[15,     1] loss: 1199.705
[16,     1] loss: 1170.044
[17,     1] loss: 1115.759
[18,     1] loss: 1138.741
[19,     1] loss: 1145.693
[20,     1] loss: 1123.800
[21,     1] loss: 1083.661
[22,     1] loss: 1113.160
[23,     1] loss: 1044.205
[24,     1] loss: 1065.808
[25,     1] loss: 1043.103
[26,     1] loss: 1066.966
[27,     1] loss: 1049.532
[28,     1] loss: 1060.895
[29,     1] loss: 1037.671
[30,     1] loss: 1085.635
[31,     1] loss: 996.376
[32,     1] loss: 1007.720
[33,     1] loss: 1008.023
[34,     1] loss: 1001.833
[35,     1] loss: 960.965
[36,     1] loss: 979.172
[37,     1] loss: 974.579
[38,     1] loss: 977.228
[39,     1] loss: 988.653
[40,     1] loss: 955.768
[41,     1] loss: 960.464
[42,     1] loss: 907.257
[43,     1] loss: 887.505
[44,     1] loss: 932.691
[45,     1] loss: 953.311
[46,     1] loss: 885.818
[47,     1] loss: 887.199
[48,     1] loss: 864.583
[49,     1] loss: 854.994
[50,     1] loss: 860.684
[51,     1] loss: 849.223
[52,     1] loss: 830.210
[53,     1] loss: 821.378
[54,     1] loss: 806.927
[55,     1] loss: 773.857
[56,     1] loss: 790.096
[57,     1] loss: 804.766
[58,     1] loss: 799.193
[59,     1] loss: 733.216
[60,     1] loss: 745.661
[61,     1] loss: 769.423
Early stopping applied (best metric=0.7845189571380615)
Finished Training
Total time taken: 9.226221561431885
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1314.963
[2,     1] loss: 1323.755
[3,     1] loss: 1326.934
[4,     1] loss: 1322.144
[5,     1] loss: 1312.869
[6,     1] loss: 1310.194
[7,     1] loss: 1304.980
[8,     1] loss: 1303.583
[9,     1] loss: 1291.126
[10,     1] loss: 1271.019
[11,     1] loss: 1239.318
[12,     1] loss: 1196.200
[13,     1] loss: 1182.984
[14,     1] loss: 1153.917
[15,     1] loss: 1151.122
[16,     1] loss: 1137.615
[17,     1] loss: 1107.273
[18,     1] loss: 1068.410
[19,     1] loss: 1058.150
[20,     1] loss: 1062.499
[21,     1] loss: 1076.784
[22,     1] loss: 1074.150
[23,     1] loss: 1078.632
[24,     1] loss: 1095.665
[25,     1] loss: 1032.359
[26,     1] loss: 1049.163
[27,     1] loss: 1027.532
[28,     1] loss: 1031.079
[29,     1] loss: 1035.811
[30,     1] loss: 998.317
[31,     1] loss: 1014.542
[32,     1] loss: 993.156
[33,     1] loss: 981.754
[34,     1] loss: 1015.895
[35,     1] loss: 981.260
[36,     1] loss: 936.718
[37,     1] loss: 938.925
[38,     1] loss: 948.348
[39,     1] loss: 949.322
[40,     1] loss: 847.486
[41,     1] loss: 895.048
[42,     1] loss: 932.657
[43,     1] loss: 884.029
[44,     1] loss: 899.111
[45,     1] loss: 892.229
[46,     1] loss: 854.918
[47,     1] loss: 864.845
[48,     1] loss: 843.014
[49,     1] loss: 819.085
[50,     1] loss: 737.758
[51,     1] loss: 822.663
[52,     1] loss: 846.902
[53,     1] loss: 775.178
[54,     1] loss: 797.519
Early stopping applied (best metric=0.8521002531051636)
Finished Training
Total time taken: 8.419287919998169
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1310.208
[2,     1] loss: 1315.696
[3,     1] loss: 1314.894
[4,     1] loss: 1309.488
[5,     1] loss: 1310.864
[6,     1] loss: 1301.977
[7,     1] loss: 1285.271
[8,     1] loss: 1267.458
[9,     1] loss: 1213.619
[10,     1] loss: 1171.772
[11,     1] loss: 1158.578
[12,     1] loss: 1123.014
[13,     1] loss: 1079.739
[14,     1] loss: 1060.397
[15,     1] loss: 1078.660
[16,     1] loss: 1046.355
[17,     1] loss: 1038.704
[18,     1] loss: 1059.831
[19,     1] loss: 1072.287
[20,     1] loss: 1044.352
[21,     1] loss: 1034.718
[22,     1] loss: 980.599
[23,     1] loss: 971.666
[24,     1] loss: 955.185
[25,     1] loss: 967.681
[26,     1] loss: 970.778
[27,     1] loss: 944.990
[28,     1] loss: 974.079
[29,     1] loss: 943.354
[30,     1] loss: 988.478
[31,     1] loss: 961.713
[32,     1] loss: 918.073
[33,     1] loss: 970.701
[34,     1] loss: 947.537
[35,     1] loss: 924.705
[36,     1] loss: 855.913
[37,     1] loss: 939.243
[38,     1] loss: 883.543
[39,     1] loss: 902.719
[40,     1] loss: 876.916
[41,     1] loss: 830.198
[42,     1] loss: 957.720
[43,     1] loss: 824.024
[44,     1] loss: 884.948
[45,     1] loss: 814.375
[46,     1] loss: 888.349
[47,     1] loss: 791.964
[48,     1] loss: 819.929
[49,     1] loss: 808.745
Early stopping applied (best metric=0.9413663148880005)
Finished Training
Total time taken: 7.703480243682861
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1311.797
[2,     1] loss: 1316.374
[3,     1] loss: 1316.672
[4,     1] loss: 1309.925
[5,     1] loss: 1305.995
[6,     1] loss: 1303.832
[7,     1] loss: 1304.775
[8,     1] loss: 1296.615
[9,     1] loss: 1270.936
[10,     1] loss: 1257.627
[11,     1] loss: 1226.416
[12,     1] loss: 1166.555
[13,     1] loss: 1140.150
[14,     1] loss: 1155.338
[15,     1] loss: 1158.114
[16,     1] loss: 1104.685
[17,     1] loss: 1126.568
[18,     1] loss: 1073.393
[19,     1] loss: 1071.305
[20,     1] loss: 1089.822
[21,     1] loss: 1071.222
[22,     1] loss: 1065.008
[23,     1] loss: 1077.515
[24,     1] loss: 1068.040
[25,     1] loss: 1086.423
[26,     1] loss: 1023.464
[27,     1] loss: 1002.757
[28,     1] loss: 999.097
[29,     1] loss: 987.788
[30,     1] loss: 1039.004
[31,     1] loss: 947.271
[32,     1] loss: 997.759
[33,     1] loss: 951.793
[34,     1] loss: 967.792
[35,     1] loss: 937.678
[36,     1] loss: 987.866
[37,     1] loss: 916.349
[38,     1] loss: 959.005
[39,     1] loss: 958.619
[40,     1] loss: 884.858
[41,     1] loss: 938.138
[42,     1] loss: 923.354
Early stopping applied (best metric=0.9237281084060669)
Finished Training
Total time taken: 7.3142499923706055
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1319.688
[2,     1] loss: 1314.006
[3,     1] loss: 1314.053
[4,     1] loss: 1320.027
[5,     1] loss: 1310.965
[6,     1] loss: 1313.691
[7,     1] loss: 1310.481
[8,     1] loss: 1314.488
[9,     1] loss: 1311.535
[10,     1] loss: 1307.082
[11,     1] loss: 1308.326
[12,     1] loss: 1304.996
[13,     1] loss: 1308.018
[14,     1] loss: 1290.772
[15,     1] loss: 1278.154
[16,     1] loss: 1256.193
[17,     1] loss: 1242.494
[18,     1] loss: 1231.611
[19,     1] loss: 1180.793
[20,     1] loss: 1154.614
[21,     1] loss: 1135.279
[22,     1] loss: 1179.207
[23,     1] loss: 1146.996
[24,     1] loss: 1135.509
[25,     1] loss: 1047.854
[26,     1] loss: 1090.078
[27,     1] loss: 1079.555
[28,     1] loss: 1101.542
[29,     1] loss: 1069.115
[30,     1] loss: 1065.503
[31,     1] loss: 1033.244
[32,     1] loss: 1015.534
[33,     1] loss: 1111.036
[34,     1] loss: 1033.839
[35,     1] loss: 1024.183
[36,     1] loss: 1013.561
[37,     1] loss: 1004.905
[38,     1] loss: 990.458
[39,     1] loss: 981.831
[40,     1] loss: 964.166
[41,     1] loss: 944.318
[42,     1] loss: 947.932
[43,     1] loss: 990.991
[44,     1] loss: 955.941
[45,     1] loss: 958.175
[46,     1] loss: 979.685
[47,     1] loss: 962.238
[48,     1] loss: 895.276
[49,     1] loss: 920.396
[50,     1] loss: 878.938
[51,     1] loss: 898.515
[52,     1] loss: 911.081
Early stopping applied (best metric=0.908988356590271)
Finished Training
Total time taken: 9.588716268539429
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1314.430
[2,     1] loss: 1309.685
[3,     1] loss: 1307.485
[4,     1] loss: 1321.964
[5,     1] loss: 1301.373
[6,     1] loss: 1298.769
[7,     1] loss: 1273.471
[8,     1] loss: 1241.394
[9,     1] loss: 1189.533
[10,     1] loss: 1170.596
[11,     1] loss: 1194.220
[12,     1] loss: 1130.222
[13,     1] loss: 1138.526
[14,     1] loss: 1126.448
[15,     1] loss: 1067.736
[16,     1] loss: 1075.165
[17,     1] loss: 1023.259
[18,     1] loss: 1037.432
[19,     1] loss: 1014.847
[20,     1] loss: 1007.686
[21,     1] loss: 1019.730
[22,     1] loss: 993.294
[23,     1] loss: 1020.359
[24,     1] loss: 1050.344
[25,     1] loss: 1037.795
[26,     1] loss: 994.250
[27,     1] loss: 968.024
[28,     1] loss: 983.544
[29,     1] loss: 1002.780
[30,     1] loss: 942.755
[31,     1] loss: 964.973
[32,     1] loss: 971.583
[33,     1] loss: 998.638
[34,     1] loss: 992.863
[35,     1] loss: 949.167
[36,     1] loss: 967.110
[37,     1] loss: 956.368
[38,     1] loss: 935.234
[39,     1] loss: 916.862
[40,     1] loss: 896.303
[41,     1] loss: 900.594
[42,     1] loss: 907.123
[43,     1] loss: 877.918
[44,     1] loss: 866.538
[45,     1] loss: 912.675
[46,     1] loss: 973.864
[47,     1] loss: 884.899
[48,     1] loss: 867.700
[49,     1] loss: 883.543
[50,     1] loss: 836.754
[51,     1] loss: 883.597
[52,     1] loss: 801.785
[53,     1] loss: 889.735
[54,     1] loss: 718.528
[55,     1] loss: 876.031
[56,     1] loss: 814.839
[57,     1] loss: 885.730
[58,     1] loss: 775.803
Early stopping applied (best metric=0.7679367065429688)
Finished Training
Total time taken: 9.886791706085205
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1316.212
[2,     1] loss: 1312.809
[3,     1] loss: 1312.964
[4,     1] loss: 1316.589
[5,     1] loss: 1306.216
[6,     1] loss: 1299.168
[7,     1] loss: 1278.280
[8,     1] loss: 1242.272
[9,     1] loss: 1203.329
[10,     1] loss: 1229.261
[11,     1] loss: 1180.641
[12,     1] loss: 1120.625
[13,     1] loss: 1087.629
[14,     1] loss: 1116.117
[15,     1] loss: 1046.035
[16,     1] loss: 1090.780
[17,     1] loss: 1059.881
[18,     1] loss: 1075.713
[19,     1] loss: 1081.926
[20,     1] loss: 988.633
[21,     1] loss: 1015.919
[22,     1] loss: 1040.177
[23,     1] loss: 978.275
[24,     1] loss: 990.672
[25,     1] loss: 993.983
[26,     1] loss: 958.177
[27,     1] loss: 967.741
[28,     1] loss: 980.854
[29,     1] loss: 903.088
[30,     1] loss: 910.124
[31,     1] loss: 924.152
[32,     1] loss: 873.660
[33,     1] loss: 976.578
[34,     1] loss: 925.155
[35,     1] loss: 900.482
[36,     1] loss: 917.214
[37,     1] loss: 908.442
[38,     1] loss: 903.566
[39,     1] loss: 895.598
[40,     1] loss: 866.367
[41,     1] loss: 843.237
[42,     1] loss: 843.582
[43,     1] loss: 888.428
Early stopping applied (best metric=0.9208702445030212)
Finished Training
Total time taken: 6.532167911529541
{'Hydroxylation-K Validation Accuracy': 0.778871158392435, 'Hydroxylation-K Validation Sensitivity': 0.6259259259259259, 'Hydroxylation-K Validation Specificity': 0.8175438596491228, 'Hydroxylation-K Validation Precision': 0.471152066887361, 'Hydroxylation-K AUC ROC': 0.764990253411306, 'Hydroxylation-K AUC PR': 0.543740784019116, 'Hydroxylation-K MCC': 0.4032348749002185, 'Hydroxylation-K F1': 0.5346420618960664, 'Validation Loss (Hydroxylation-K)': 0.47033791144688925, 'Hydroxylation-P Validation Accuracy': 0.783575689897298, 'Hydroxylation-P Validation Sensitivity': 0.7557671957671958, 'Hydroxylation-P Validation Specificity': 0.7895880093770263, 'Hydroxylation-P Validation Precision': 0.43756781065300265, 'Hydroxylation-P AUC ROC': 0.8369884140997413, 'Hydroxylation-P AUC PR': 0.5622293066591618, 'Hydroxylation-P MCC': 0.4523358116798188, 'Hydroxylation-P F1': 0.5531072444014961, 'Validation Loss (Hydroxylation-P)': 0.3850515842437744, 'Validation Loss (total)': 0.8553894917170207, 'TimeToTrain': 8.455557378133138}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007297711590622394,
 'learning_rate_Hydroxylation-K': 0.0022032362729611037,
 'learning_rate_Hydroxylation-P': 0.00023008897608289597,
 'log_base': 2.1212038543956977,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1803068886,
 'sample_weights': [1.9161052990320162, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8495062371853754,
 'weight_decay_Hydroxylation-K': 9.444311606677209,
 'weight_decay_Hydroxylation-P': 3.6765893153322997}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1375.674
[2,     1] loss: 1430.882
[3,     1] loss: 1386.354
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005266325553151042,
 'learning_rate_Hydroxylation-K': 3.785474629668312e-05,
 'learning_rate_Hydroxylation-P': 0.0005387640725372899,
 'log_base': 2.2343771673322586,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 353683958,
 'sample_weights': [2.2200520601125726, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.48328343728798,
 'weight_decay_Hydroxylation-K': 9.82005844130634,
 'weight_decay_Hydroxylation-P': 1.6803404139139118}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1350.791
[2,     1] loss: 1350.216
[3,     1] loss: 1349.941
[4,     1] loss: 1344.199
[5,     1] loss: 1351.465
[6,     1] loss: 1349.080
[7,     1] loss: 1346.252
[8,     1] loss: 1346.375
[9,     1] loss: 1340.453
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028985393695959653,
 'learning_rate_Hydroxylation-K': 0.001380510314751946,
 'learning_rate_Hydroxylation-P': 0.004315816291302923,
 'log_base': 2.1929961152487794,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1405646484,
 'sample_weights': [2.0765186340677273, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4597182172919103,
 'weight_decay_Hydroxylation-K': 1.7452575178016398,
 'weight_decay_Hydroxylation-P': 0.523150390698595}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1355.639
[2,     1] loss: 1357.742
[3,     1] loss: 1358.605
[4,     1] loss: 1356.780
[5,     1] loss: 1349.008
[6,     1] loss: 1325.857
[7,     1] loss: 1320.740
[8,     1] loss: 1297.497
[9,     1] loss: 1237.340
[10,     1] loss: 1256.004
[11,     1] loss: 1163.532
[12,     1] loss: 1240.986
[13,     1] loss: 1167.576
[14,     1] loss: 1079.393
[15,     1] loss: 1125.483
[16,     1] loss: 1136.978
[17,     1] loss: 1132.808
[18,     1] loss: 1097.528
[19,     1] loss: 1113.933
[20,     1] loss: 1095.578
[21,     1] loss: 1094.423
[22,     1] loss: 1043.561
[23,     1] loss: 1078.501
[24,     1] loss: 1040.808
[25,     1] loss: 1024.604
[26,     1] loss: 994.722
[27,     1] loss: 1011.506
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001677033089222887,
 'learning_rate_Hydroxylation-K': 0.00028285000219086383,
 'learning_rate_Hydroxylation-P': 0.00045624338090134644,
 'log_base': 2.7369844271866057,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 918828667,
 'sample_weights': [2.1259514758091784, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8602582628323994,
 'weight_decay_Hydroxylation-K': 9.529809385848694,
 'weight_decay_Hydroxylation-P': 2.8717330878569536}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1259.763
[2,     1] loss: 1257.802
[3,     1] loss: 1258.504
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005692816720394584,
 'learning_rate_Hydroxylation-K': 0.0048844921521856615,
 'learning_rate_Hydroxylation-P': 0.005948824328881554,
 'log_base': 2.8670432444578116,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 980350172,
 'sample_weights': [1.658074163479627, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.5356108914181714,
 'weight_decay_Hydroxylation-K': 3.1747708866956192,
 'weight_decay_Hydroxylation-P': 0.28932070792081593}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.542
[2,     1] loss: 1248.415
[3,     1] loss: 1250.547
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005525039293938334,
 'learning_rate_Hydroxylation-K': 3.715405561045891e-05,
 'learning_rate_Hydroxylation-P': 0.008862642309036037,
 'log_base': 1.1108209594284246,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2930623862,
 'sample_weights': [1.5849927217760373, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.295048809121724,
 'weight_decay_Hydroxylation-K': 2.2973612947917132,
 'weight_decay_Hydroxylation-P': 3.081160753258319}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 5156.420
[2,     1] loss: 5166.108
[3,     1] loss: 5148.332
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00925225873006101,
 'learning_rate_Hydroxylation-K': 0.001170360197588949,
 'learning_rate_Hydroxylation-P': 0.006537161986625068,
 'log_base': 1.655758661825014,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1306996814,
 'sample_weights': [15.884429601032611, 1.9856301916308525],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.7651069663397205,
 'weight_decay_Hydroxylation-K': 9.74410297997027,
 'weight_decay_Hydroxylation-P': 0.1782394999292891}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1609.576
[2,     1] loss: 1631.266
[3,     1] loss: 1617.750
[4,     1] loss: 1613.545
[5,     1] loss: 1606.728
[6,     1] loss: 1605.812
[7,     1] loss: 1607.878
[8,     1] loss: 1607.209
[9,     1] loss: 1603.848
[10,     1] loss: 1603.010
[11,     1] loss: 1609.769
[12,     1] loss: 1601.187
[13,     1] loss: 1599.172
[14,     1] loss: 1598.651
[15,     1] loss: 1590.591
[16,     1] loss: 1572.309
[17,     1] loss: 1558.140
[18,     1] loss: 1525.901
[19,     1] loss: 1487.166
[20,     1] loss: 1447.287
[21,     1] loss: 1430.743
[22,     1] loss: 1360.302
[23,     1] loss: 1552.063
[24,     1] loss: 1430.672
[25,     1] loss: 1386.997
[26,     1] loss: 1422.299
[27,     1] loss: 1407.367
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004075279823362192,
 'learning_rate_Hydroxylation-K': 0.0012444448541461305,
 'learning_rate_Hydroxylation-P': 0.0046738696686025975,
 'log_base': 1.152989194963019,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 330352198,
 'sample_weights': [3.310683839071989, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.164070559721317,
 'weight_decay_Hydroxylation-K': 0.45902460133775014,
 'weight_decay_Hydroxylation-P': 0.5823357092825177}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3809.154
[2,     1] loss: 3795.492
[3,     1] loss: 3827.000
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006087951047817564,
 'learning_rate_Hydroxylation-K': 0.001496789625138524,
 'learning_rate_Hydroxylation-P': 0.002170924398679191,
 'log_base': 2.5075757972719375,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 792722840,
 'sample_weights': [11.727087145659706, 1.4659423650185235],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.13154077723229107,
 'weight_decay_Hydroxylation-K': 8.482468545918262,
 'weight_decay_Hydroxylation-P': 0.9603480294902829}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1298.031
[2,     1] loss: 1326.704
[3,     1] loss: 1295.248
[4,     1] loss: 1293.201
[5,     1] loss: 1289.449
[6,     1] loss: 1293.291
[7,     1] loss: 1293.249
[8,     1] loss: 1291.737
[9,     1] loss: 1288.568
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002867269023254148,
 'learning_rate_Hydroxylation-K': 0.0043556539986882815,
 'learning_rate_Hydroxylation-P': 0.006880684077409509,
 'log_base': 1.0329189626113686,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2702693654,
 'sample_weights': [1.8159613195307305, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.91282950692188,
 'weight_decay_Hydroxylation-K': 1.38741021339309,
 'weight_decay_Hydroxylation-P': 3.9623664485586607}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16744.332
Exploding loss, terminate run (best metric=1.0994257926940918)
Finished Training
Total time taken: 0.26300621032714844
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16762.732
Exploding loss, terminate run (best metric=1.0897331237792969)
Finished Training
Total time taken: 0.23451972007751465
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16719.512
Exploding loss, terminate run (best metric=1.091618299484253)
Finished Training
Total time taken: 0.2660055160522461
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16782.986
Exploding loss, terminate run (best metric=1.070826768875122)
Finished Training
Total time taken: 0.2400054931640625
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 16739.527
Exploding loss, terminate run (best metric=1.0797415971755981)
Finished Training
Total time taken: 0.2505195140838623
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16780.748
Exploding loss, terminate run (best metric=1.1011905670166016)
Finished Training
Total time taken: 0.2610037326812744
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16828.225
Exploding loss, terminate run (best metric=1.0945156812667847)
Finished Training
Total time taken: 0.2510068416595459
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16768.330
Exploding loss, terminate run (best metric=1.0935269594192505)
Finished Training
Total time taken: 0.24400639533996582
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16712.480
Exploding loss, terminate run (best metric=1.0727105140686035)
Finished Training
Total time taken: 0.23500728607177734
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 16773.031
Exploding loss, terminate run (best metric=1.0725284814834595)
Finished Training
Total time taken: 0.2510049343109131
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16770.992
Exploding loss, terminate run (best metric=1.0954406261444092)
Finished Training
Total time taken: 0.24500751495361328
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16677.367
Exploding loss, terminate run (best metric=1.0950511693954468)
Finished Training
Total time taken: 0.24800562858581543
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16760.586
Exploding loss, terminate run (best metric=1.0910842418670654)
Finished Training
Total time taken: 0.25000572204589844
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 16785.297
Exploding loss, terminate run (best metric=1.071284532546997)
Finished Training
Total time taken: 0.33800792694091797
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 16715.830
Exploding loss, terminate run (best metric=1.0736873149871826)
Finished Training
Total time taken: 0.29500603675842285
{'Hydroxylation-K Validation Accuracy': 0.4385933806146572, 'Hydroxylation-K Validation Sensitivity': 0.6, 'Hydroxylation-K Validation Specificity': 0.4017543859649123, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.68729044834308, 'Hydroxylation-K AUC PR': 0.41089955094738506, 'Hydroxylation-K MCC': 0.004783648732349399, 'Hydroxylation-K F1': 0.19948649052097328, 'Validation Loss (Hydroxylation-K)': 0.5559590816497803, 'Hydroxylation-P Validation Accuracy': 0.44062705784816336, 'Hydroxylation-P Validation Sensitivity': 0.5981481481481481, 'Hydroxylation-P Validation Specificity': 0.4073170731707317, 'Hydroxylation-P Validation Precision': nan, 'Hydroxylation-P AUC ROC': 0.6202651816541537, 'Hydroxylation-P AUC PR': 0.3252079730628084, 'Hydroxylation-P MCC': 0.0071608543482842395, 'Hydroxylation-P F1': 0.18122072060878652, 'Validation Loss (Hydroxylation-P)': 0.5301986336708069, 'Validation Loss (total)': 1.0861577113469443, 'TimeToTrain': 0.25814123153686525}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002356435508931377,
 'learning_rate_Hydroxylation-K': 0.0045484537388592065,
 'learning_rate_Hydroxylation-P': 0.0001818558040297285,
 'log_base': 2.086913897371523,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2582537054,
 'sample_weights': [51.582173815375995, 6.4343743964677165],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.210419928126208,
 'weight_decay_Hydroxylation-K': 7.545174398864988,
 'weight_decay_Hydroxylation-P': 2.073164461765476}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1392.315
[2,     1] loss: 1387.494
[3,     1] loss: 1390.403
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025665283543551453,
 'learning_rate_Hydroxylation-K': 0.004456584136349847,
 'learning_rate_Hydroxylation-P': 0.006877634773087596,
 'log_base': 1.1995397110280532,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2461305285,
 'sample_weights': [2.269232126831035, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.333638320868624,
 'weight_decay_Hydroxylation-K': 0.01936910179756901,
 'weight_decay_Hydroxylation-P': 5.259234604675385}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2973.652
[2,     1] loss: 2977.596
[3,     1] loss: 2981.259
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004675201918764112,
 'learning_rate_Hydroxylation-K': 0.008302689043997637,
 'learning_rate_Hydroxylation-P': 0.007998639461855372,
 'log_base': 1.6475166573331388,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 659450259,
 'sample_weights': [9.175894985174612, 1.1470310596870539],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5425780382464067,
 'weight_decay_Hydroxylation-K': 1.089362652038719,
 'weight_decay_Hydroxylation-P': 0.3094693340225433}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1610.673
[2,     1] loss: 1622.166
[3,     1] loss: 1608.267
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003279452653313479,
 'learning_rate_Hydroxylation-K': 0.0028004092419100196,
 'learning_rate_Hydroxylation-P': 0.0042595879762642895,
 'log_base': 2.8808759944184885,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4094142980,
 'sample_weights': [3.343774237295311, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7105691175225717,
 'weight_decay_Hydroxylation-K': 0.28647534253588836,
 'weight_decay_Hydroxylation-P': 0.03295451137380355}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1252.653
[2,     1] loss: 1240.698
[3,     1] loss: 1239.761
[4,     1] loss: 1242.858
[5,     1] loss: 1239.764
[6,     1] loss: 1241.108
[7,     1] loss: 1240.803
[8,     1] loss: 1241.028
[9,     1] loss: 1228.735
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025733402029992007,
 'learning_rate_Hydroxylation-K': 0.006304695158450808,
 'learning_rate_Hydroxylation-P': 0.006641282762734492,
 'log_base': 1.3483910859311137,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1560435207,
 'sample_weights': [1.5777827833695874, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6763579533540955,
 'weight_decay_Hydroxylation-K': 1.554381763710174,
 'weight_decay_Hydroxylation-P': 2.854415660194636}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2103.307
[2,     1] loss: 2092.214
[3,     1] loss: 2100.837
[4,     1] loss: 2083.570
[5,     1] loss: 2069.822
[6,     1] loss: 2091.415
[7,     1] loss: 2089.409
[8,     1] loss: 2088.727
[9,     1] loss: 2072.021
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009506905682712359,
 'learning_rate_Hydroxylation-K': 0.002019827642722045,
 'learning_rate_Hydroxylation-P': 0.008596429274401175,
 'log_base': 2.669957304279655,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2400928142,
 'sample_weights': [5.585063915740945, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3288842280141557,
 'weight_decay_Hydroxylation-K': 6.70438931792232,
 'weight_decay_Hydroxylation-P': 0.4371738436552658}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1272.378
[2,     1] loss: 1268.026
[3,     1] loss: 1266.660
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006993413406787348,
 'learning_rate_Hydroxylation-K': 0.002107806206075099,
 'learning_rate_Hydroxylation-P': 0.0058180951933721236,
 'log_base': 1.0484661563727466,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2439447586,
 'sample_weights': [1.6999357770816077, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.342983418085394,
 'weight_decay_Hydroxylation-K': 4.1850502641353104,
 'weight_decay_Hydroxylation-P': 4.114280313815879}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 11416.251
[2,     1] loss: 11441.731
[3,     1] loss: 11360.141
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002246068795253736,
 'learning_rate_Hydroxylation-K': 0.002691432077265328,
 'learning_rate_Hydroxylation-P': 0.004480661075994554,
 'log_base': 1.872351795240795,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1100628499,
 'sample_weights': [35.27368202271077, 4.409380113323539],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.8008274100777597,
 'weight_decay_Hydroxylation-K': 3.7545447142166335,
 'weight_decay_Hydroxylation-P': 1.5951870941367785}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1467.877
[2,     1] loss: 1475.563
[3,     1] loss: 1464.714
[4,     1] loss: 1466.789
[5,     1] loss: 1471.347
[6,     1] loss: 1463.743
[7,     1] loss: 1462.003
[8,     1] loss: 1451.009
[9,     1] loss: 1438.371
[10,     1] loss: 1400.923
[11,     1] loss: 1377.291
[12,     1] loss: 1326.710
[13,     1] loss: 1272.296
[14,     1] loss: 1234.665
[15,     1] loss: 1245.192
[16,     1] loss: 1231.457
[17,     1] loss: 1255.469
[18,     1] loss: 1238.846
[19,     1] loss: 1189.805
[20,     1] loss: 1203.345
[21,     1] loss: 1219.209
[22,     1] loss: 1184.762
[23,     1] loss: 1181.058
[24,     1] loss: 1184.468
[25,     1] loss: 1179.395
[26,     1] loss: 1148.267
[27,     1] loss: 1163.377
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004459165020912821,
 'learning_rate_Hydroxylation-K': 0.0013872773543374868,
 'learning_rate_Hydroxylation-P': 0.00031118193111621235,
 'log_base': 2.3323532307565933,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3005989382,
 'sample_weights': [2.661759721089728, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.23954032041694862,
 'weight_decay_Hydroxylation-K': 9.572967964499368,
 'weight_decay_Hydroxylation-P': 1.6675727871303159}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1328.531
[2,     1] loss: 1329.093
[3,     1] loss: 1327.837
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002333080687878293,
 'learning_rate_Hydroxylation-K': 0.00027345469480876864,
 'learning_rate_Hydroxylation-P': 0.008382830587458048,
 'log_base': 2.4169838606360616,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2073434570,
 'sample_weights': [1.9712918310018175, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.721848095237327,
 'weight_decay_Hydroxylation-K': 3.4621885000606674,
 'weight_decay_Hydroxylation-P': 0.2098279237753996}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1311.154
[2,     1] loss: 1307.885
[3,     1] loss: 1307.839
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004440374698653764,
 'learning_rate_Hydroxylation-K': 0.002057861044670909,
 'learning_rate_Hydroxylation-P': 0.004182648380806531,
 'log_base': 2.9618726281175234,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1697830022,
 'sample_weights': [1.8916765000862406, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.21289728989696455,
 'weight_decay_Hydroxylation-K': 2.5199313983582825,
 'weight_decay_Hydroxylation-P': 1.6873340101690522}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.969
[2,     1] loss: 1230.976
[3,     1] loss: 1239.356
[4,     1] loss: 1235.007
[5,     1] loss: 1229.983
[6,     1] loss: 1227.957
[7,     1] loss: 1224.225
[8,     1] loss: 1210.158
[9,     1] loss: 1200.090
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009584277893734284,
 'learning_rate_Hydroxylation-K': 0.006550486518692559,
 'learning_rate_Hydroxylation-P': 0.005810388550693303,
 'log_base': 2.896282450077408,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 87663663,
 'sample_weights': [1.5374928752447854, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.36159218469785936,
 'weight_decay_Hydroxylation-K': 9.784239199428454,
 'weight_decay_Hydroxylation-P': 4.504399484845539}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1249.873
[2,     1] loss: 1242.297
[3,     1] loss: 1238.821
[4,     1] loss: 1237.418
[5,     1] loss: 1239.684
[6,     1] loss: 1234.452
[7,     1] loss: 1232.556
[8,     1] loss: 1233.884
[9,     1] loss: 1235.004
[10,     1] loss: 1227.710
[11,     1] loss: 1215.850
[12,     1] loss: 1203.203
[13,     1] loss: 1191.272
[14,     1] loss: 1169.123
[15,     1] loss: 1146.823
[16,     1] loss: 1132.376
[17,     1] loss: 1097.073
[18,     1] loss: 1068.916
[19,     1] loss: 1055.912
[20,     1] loss: 1070.599
[21,     1] loss: 1029.979
[22,     1] loss: 1088.537
[23,     1] loss: 1034.027
[24,     1] loss: 1017.881
[25,     1] loss: 1046.486
[26,     1] loss: 1048.265
[27,     1] loss: 1031.538
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005009816531142577,
 'learning_rate_Hydroxylation-K': 0.0005311485901978007,
 'learning_rate_Hydroxylation-P': 0.0012791369876709556,
 'log_base': 2.9302183570292604,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 654072981,
 'sample_weights': [1.5698694655916714, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.1008070575413752,
 'weight_decay_Hydroxylation-K': 9.319893156533922,
 'weight_decay_Hydroxylation-P': 2.7843281671235327}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1237.061
[2,     1] loss: 1236.437
[3,     1] loss: 1235.839
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001959504460723958,
 'learning_rate_Hydroxylation-K': 0.001587384614396014,
 'learning_rate_Hydroxylation-P': 0.002282998746104392,
 'log_base': 1.92597581767214,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 684544845,
 'sample_weights': [1.5528592213267889, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9804076869345993,
 'weight_decay_Hydroxylation-K': 1.9151671963031482,
 'weight_decay_Hydroxylation-P': 0.6841129860461342}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1460.726
[2,     1] loss: 1448.247
[3,     1] loss: 1444.670
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017476404526375101,
 'learning_rate_Hydroxylation-K': 0.0018258585291660262,
 'learning_rate_Hydroxylation-P': 0.005812363973749081,
 'log_base': 2.095421117381167,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1464547394,
 'sample_weights': [2.5470853083536933, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8178068240453098,
 'weight_decay_Hydroxylation-K': 4.481330391613701,
 'weight_decay_Hydroxylation-P': 2.0385394965173247}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1384.632
[2,     1] loss: 1384.327
[3,     1] loss: 1386.033
[4,     1] loss: 1383.477
[5,     1] loss: 1382.497
[6,     1] loss: 1384.250
[7,     1] loss: 1385.986
[8,     1] loss: 1366.676
[9,     1] loss: 1371.766
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004072554686383219,
 'learning_rate_Hydroxylation-K': 0.005126009179976839,
 'learning_rate_Hydroxylation-P': 0.004088399130705575,
 'log_base': 2.1302712117207134,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2623067063,
 'sample_weights': [2.2567528125190157, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.088808638749624,
 'weight_decay_Hydroxylation-K': 2.021472434878903,
 'weight_decay_Hydroxylation-P': 3.8839174268021686}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1373.799
[2,     1] loss: 1375.763
[3,     1] loss: 1370.231
[4,     1] loss: 1373.016
[5,     1] loss: 1375.629
[6,     1] loss: 1369.354
[7,     1] loss: 1356.402
[8,     1] loss: 1334.078
[9,     1] loss: 1285.132
[10,     1] loss: 1260.014
[11,     1] loss: 1225.362
[12,     1] loss: 1194.518
[13,     1] loss: 1172.247
[14,     1] loss: 1168.709
[15,     1] loss: 1130.952
[16,     1] loss: 1090.214
[17,     1] loss: 1171.199
[18,     1] loss: 1145.028
[19,     1] loss: 1157.590
[20,     1] loss: 1090.953
[21,     1] loss: 1106.993
[22,     1] loss: 1071.748
[23,     1] loss: 1069.016
[24,     1] loss: 1072.013
[25,     1] loss: 1065.043
[26,     1] loss: 1115.122
[27,     1] loss: 1005.486
[28,     1] loss: 1053.844
[29,     1] loss: 1035.463
[30,     1] loss: 1005.610
[31,     1] loss: 991.872
[32,     1] loss: 1019.898
[33,     1] loss: 983.618
[34,     1] loss: 909.437
[35,     1] loss: 958.245
[36,     1] loss: 945.710
[37,     1] loss: 937.664
[38,     1] loss: 1031.125
[39,     1] loss: 989.604
[40,     1] loss: 913.883
[41,     1] loss: 915.113
[42,     1] loss: 918.381
[43,     1] loss: 908.743
[44,     1] loss: 879.962
[45,     1] loss: 839.013
[46,     1] loss: 814.876
[47,     1] loss: 806.224
[48,     1] loss: 829.954
[49,     1] loss: 813.579
[50,     1] loss: 831.042
Early stopping applied (best metric=0.7901971340179443)
Finished Training
Total time taken: 9.236251831054688
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1376.046
[2,     1] loss: 1375.970
[3,     1] loss: 1376.027
[4,     1] loss: 1374.578
[5,     1] loss: 1372.736
[6,     1] loss: 1364.171
[7,     1] loss: 1352.070
[8,     1] loss: 1336.749
[9,     1] loss: 1286.594
[10,     1] loss: 1248.119
[11,     1] loss: 1210.673
[12,     1] loss: 1210.627
[13,     1] loss: 1180.929
[14,     1] loss: 1224.914
[15,     1] loss: 1119.580
[16,     1] loss: 1185.464
[17,     1] loss: 1128.193
[18,     1] loss: 1147.638
[19,     1] loss: 1112.825
[20,     1] loss: 1122.365
[21,     1] loss: 1097.542
[22,     1] loss: 1058.129
[23,     1] loss: 1051.126
[24,     1] loss: 1048.260
[25,     1] loss: 1018.189
[26,     1] loss: 1008.921
[27,     1] loss: 1020.277
[28,     1] loss: 981.720
[29,     1] loss: 1016.698
[30,     1] loss: 989.197
[31,     1] loss: 967.007
[32,     1] loss: 942.029
[33,     1] loss: 937.758
[34,     1] loss: 935.048
[35,     1] loss: 1038.615
[36,     1] loss: 1243.212
[37,     1] loss: 910.734
[38,     1] loss: 1106.343
[39,     1] loss: 1049.675
[40,     1] loss: 1013.498
[41,     1] loss: 1003.099
[42,     1] loss: 999.027
[43,     1] loss: 890.834
[44,     1] loss: 983.697
[45,     1] loss: 970.018
[46,     1] loss: 905.597
[47,     1] loss: 963.108
[48,     1] loss: 925.996
[49,     1] loss: 893.047
[50,     1] loss: 838.802
[51,     1] loss: 883.428
[52,     1] loss: 865.300
[53,     1] loss: 892.875
[54,     1] loss: 920.331
[55,     1] loss: 779.116
[56,     1] loss: 861.137
[57,     1] loss: 779.615
[58,     1] loss: 832.684
[59,     1] loss: 878.125
[60,     1] loss: 773.046
[61,     1] loss: 842.876
[62,     1] loss: 796.648
Early stopping applied (best metric=0.8243216872215271)
Finished Training
Total time taken: 11.339844465255737
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1372.318
[2,     1] loss: 1376.052
[3,     1] loss: 1377.458
[4,     1] loss: 1372.922
[5,     1] loss: 1365.791
[6,     1] loss: 1365.450
[7,     1] loss: 1334.904
[8,     1] loss: 1302.615
[9,     1] loss: 1258.097
[10,     1] loss: 1214.193
[11,     1] loss: 1152.612
[12,     1] loss: 1156.144
[13,     1] loss: 1184.975
[14,     1] loss: 1146.875
[15,     1] loss: 1198.705
[16,     1] loss: 1117.490
[17,     1] loss: 1180.489
[18,     1] loss: 1082.904
[19,     1] loss: 1116.281
[20,     1] loss: 1117.069
[21,     1] loss: 1092.036
[22,     1] loss: 1077.057
[23,     1] loss: 1083.320
[24,     1] loss: 1026.792
[25,     1] loss: 1107.097
[26,     1] loss: 1025.261
[27,     1] loss: 978.876
[28,     1] loss: 992.498
[29,     1] loss: 969.841
[30,     1] loss: 983.769
[31,     1] loss: 1027.534
[32,     1] loss: 987.996
[33,     1] loss: 972.285
[34,     1] loss: 948.050
[35,     1] loss: 933.525
[36,     1] loss: 974.818
[37,     1] loss: 919.039
[38,     1] loss: 896.954
[39,     1] loss: 881.296
[40,     1] loss: 899.844
[41,     1] loss: 846.298
[42,     1] loss: 799.705
[43,     1] loss: 758.493
[44,     1] loss: 781.191
[45,     1] loss: 814.205
[46,     1] loss: 855.287
[47,     1] loss: 1476.126
[48,     1] loss: 942.741
[49,     1] loss: 1086.269
[50,     1] loss: 1041.143
[51,     1] loss: 1072.930
[52,     1] loss: 1057.606
[53,     1] loss: 1052.893
[54,     1] loss: 1064.750
[55,     1] loss: 1003.755
[56,     1] loss: 944.031
[57,     1] loss: 907.011
[58,     1] loss: 977.494
Early stopping applied (best metric=0.8592737317085266)
Finished Training
Total time taken: 10.629250526428223
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1373.174
[2,     1] loss: 1382.002
[3,     1] loss: 1375.060
[4,     1] loss: 1381.295
[5,     1] loss: 1372.315
[6,     1] loss: 1377.083
[7,     1] loss: 1361.348
[8,     1] loss: 1351.367
[9,     1] loss: 1319.057
[10,     1] loss: 1291.801
[11,     1] loss: 1246.807
[12,     1] loss: 1216.075
[13,     1] loss: 1243.014
[14,     1] loss: 1173.176
[15,     1] loss: 1257.001
[16,     1] loss: 1129.025
[17,     1] loss: 1155.826
[18,     1] loss: 1162.753
[19,     1] loss: 1131.371
[20,     1] loss: 1189.655
[21,     1] loss: 1125.732
[22,     1] loss: 1105.711
[23,     1] loss: 1107.614
[24,     1] loss: 1073.200
[25,     1] loss: 1058.112
[26,     1] loss: 1073.367
[27,     1] loss: 1032.825
[28,     1] loss: 1003.359
[29,     1] loss: 992.470
[30,     1] loss: 990.221
[31,     1] loss: 983.766
[32,     1] loss: 992.161
[33,     1] loss: 1020.415
[34,     1] loss: 948.287
[35,     1] loss: 1001.797
[36,     1] loss: 939.815
[37,     1] loss: 914.756
[38,     1] loss: 932.632
[39,     1] loss: 887.750
[40,     1] loss: 889.649
[41,     1] loss: 905.455
[42,     1] loss: 953.717
[43,     1] loss: 912.368
[44,     1] loss: 939.972
[45,     1] loss: 925.040
[46,     1] loss: 848.929
[47,     1] loss: 927.615
[48,     1] loss: 827.356
[49,     1] loss: 837.284
[50,     1] loss: 962.507
[51,     1] loss: 815.458
[52,     1] loss: 901.162
[53,     1] loss: 869.623
[54,     1] loss: 877.559
[55,     1] loss: 843.292
[56,     1] loss: 820.956
[57,     1] loss: 854.916
[58,     1] loss: 747.167
[59,     1] loss: 822.299
[60,     1] loss: 808.237
[61,     1] loss: 743.040
[62,     1] loss: 680.195
[63,     1] loss: 694.248
[64,     1] loss: 697.562
[65,     1] loss: 770.265
[66,     1] loss: 918.880
[67,     1] loss: 757.906
[68,     1] loss: 694.947
[69,     1] loss: 795.294
[70,     1] loss: 678.493
Early stopping applied (best metric=0.8700159788131714)
Finished Training
Total time taken: 10.952168941497803
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1378.457
[2,     1] loss: 1379.712
[3,     1] loss: 1378.286
[4,     1] loss: 1374.160
[5,     1] loss: 1373.809
[6,     1] loss: 1373.196
[7,     1] loss: 1375.016
[8,     1] loss: 1358.696
[9,     1] loss: 1360.597
[10,     1] loss: 1334.686
[11,     1] loss: 1286.404
[12,     1] loss: 1263.016
[13,     1] loss: 1230.679
[14,     1] loss: 1190.249
[15,     1] loss: 1203.755
[16,     1] loss: 1182.825
[17,     1] loss: 1155.833
[18,     1] loss: 1147.326
[19,     1] loss: 1171.430
[20,     1] loss: 1111.821
[21,     1] loss: 1090.252
[22,     1] loss: 1078.939
[23,     1] loss: 1070.408
[24,     1] loss: 1069.716
[25,     1] loss: 1082.400
[26,     1] loss: 1055.595
[27,     1] loss: 1011.920
[28,     1] loss: 1026.614
[29,     1] loss: 972.188
[30,     1] loss: 1017.565
[31,     1] loss: 989.147
[32,     1] loss: 912.945
[33,     1] loss: 943.857
[34,     1] loss: 889.712
[35,     1] loss: 861.516
[36,     1] loss: 826.971
Early stopping applied (best metric=0.8596713542938232)
Finished Training
Total time taken: 6.017381906509399
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1374.776
[2,     1] loss: 1375.397
[3,     1] loss: 1374.099
[4,     1] loss: 1373.053
[5,     1] loss: 1370.284
[6,     1] loss: 1372.723
[7,     1] loss: 1356.899
[8,     1] loss: 1341.009
[9,     1] loss: 1328.933
[10,     1] loss: 1273.564
[11,     1] loss: 1282.703
[12,     1] loss: 1237.349
[13,     1] loss: 1196.944
[14,     1] loss: 1177.797
[15,     1] loss: 1186.840
[16,     1] loss: 1155.826
[17,     1] loss: 1173.125
[18,     1] loss: 1155.793
[19,     1] loss: 1154.163
[20,     1] loss: 1162.806
[21,     1] loss: 1129.047
[22,     1] loss: 1112.958
[23,     1] loss: 1119.162
[24,     1] loss: 1076.404
[25,     1] loss: 1112.469
[26,     1] loss: 1091.339
[27,     1] loss: 1072.993
[28,     1] loss: 1059.927
[29,     1] loss: 1049.011
[30,     1] loss: 1057.401
[31,     1] loss: 1013.444
[32,     1] loss: 1082.449
[33,     1] loss: 955.757
[34,     1] loss: 986.002
[35,     1] loss: 1023.776
[36,     1] loss: 965.501
[37,     1] loss: 998.390
[38,     1] loss: 956.028
[39,     1] loss: 929.225
[40,     1] loss: 987.574
[41,     1] loss: 910.099
[42,     1] loss: 951.482
[43,     1] loss: 856.243
[44,     1] loss: 915.848
[45,     1] loss: 922.246
[46,     1] loss: 1134.363
[47,     1] loss: 948.578
[48,     1] loss: 972.842
[49,     1] loss: 906.574
[50,     1] loss: 967.259
[51,     1] loss: 871.812
[52,     1] loss: 949.818
[53,     1] loss: 855.079
[54,     1] loss: 867.037
[55,     1] loss: 857.077
[56,     1] loss: 949.828
[57,     1] loss: 833.351
[58,     1] loss: 893.796
[59,     1] loss: 924.612
[60,     1] loss: 813.995
[61,     1] loss: 870.566
[62,     1] loss: 791.607
Early stopping applied (best metric=0.7990276217460632)
Finished Training
Total time taken: 11.191068172454834
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1373.715
[2,     1] loss: 1385.193
[3,     1] loss: 1372.878
[4,     1] loss: 1373.653
[5,     1] loss: 1372.609
[6,     1] loss: 1367.770
[7,     1] loss: 1362.075
[8,     1] loss: 1342.357
[9,     1] loss: 1312.715
[10,     1] loss: 1265.827
[11,     1] loss: 1247.056
[12,     1] loss: 1214.204
[13,     1] loss: 1186.084
[14,     1] loss: 1169.337
[15,     1] loss: 1103.185
[16,     1] loss: 1151.366
[17,     1] loss: 1161.136
[18,     1] loss: 1163.738
[19,     1] loss: 1164.597
[20,     1] loss: 1169.857
[21,     1] loss: 1100.373
[22,     1] loss: 1106.329
[23,     1] loss: 1135.612
[24,     1] loss: 1089.051
[25,     1] loss: 1069.983
[26,     1] loss: 1021.886
[27,     1] loss: 1041.073
[28,     1] loss: 1052.504
[29,     1] loss: 1041.630
[30,     1] loss: 1038.070
[31,     1] loss: 1006.655
[32,     1] loss: 999.551
[33,     1] loss: 1040.220
[34,     1] loss: 885.128
[35,     1] loss: 998.461
[36,     1] loss: 930.999
[37,     1] loss: 933.308
[38,     1] loss: 901.424
[39,     1] loss: 919.401
[40,     1] loss: 879.354
[41,     1] loss: 927.154
[42,     1] loss: 903.591
[43,     1] loss: 1090.188
[44,     1] loss: 1036.047
[45,     1] loss: 1013.750
[46,     1] loss: 946.333
[47,     1] loss: 1050.094
[48,     1] loss: 963.565
[49,     1] loss: 917.008
[50,     1] loss: 927.329
[51,     1] loss: 897.201
[52,     1] loss: 866.908
[53,     1] loss: 894.514
[54,     1] loss: 849.912
[55,     1] loss: 792.319
Early stopping applied (best metric=0.7827916145324707)
Finished Training
Total time taken: 10.49080753326416
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1379.040
[2,     1] loss: 1373.043
[3,     1] loss: 1373.187
[4,     1] loss: 1372.372
[5,     1] loss: 1371.086
[6,     1] loss: 1366.442
[7,     1] loss: 1353.322
[8,     1] loss: 1313.711
[9,     1] loss: 1276.712
[10,     1] loss: 1264.790
[11,     1] loss: 1212.938
[12,     1] loss: 1182.853
[13,     1] loss: 1196.745
[14,     1] loss: 1135.189
[15,     1] loss: 1171.224
[16,     1] loss: 1115.578
[17,     1] loss: 1152.515
[18,     1] loss: 1118.316
[19,     1] loss: 1113.002
[20,     1] loss: 1098.764
[21,     1] loss: 1094.015
[22,     1] loss: 1090.179
[23,     1] loss: 1110.834
[24,     1] loss: 1055.542
[25,     1] loss: 1086.826
[26,     1] loss: 1004.004
[27,     1] loss: 1005.812
[28,     1] loss: 1002.960
[29,     1] loss: 998.824
[30,     1] loss: 959.023
[31,     1] loss: 913.883
[32,     1] loss: 937.190
[33,     1] loss: 942.307
[34,     1] loss: 957.391
[35,     1] loss: 874.783
[36,     1] loss: 872.874
[37,     1] loss: 900.375
[38,     1] loss: 896.877
[39,     1] loss: 841.951
[40,     1] loss: 834.017
[41,     1] loss: 920.181
[42,     1] loss: 1144.151
[43,     1] loss: 868.320
[44,     1] loss: 1019.264
[45,     1] loss: 963.190
[46,     1] loss: 929.692
[47,     1] loss: 1006.459
[48,     1] loss: 921.845
[49,     1] loss: 846.743
[50,     1] loss: 869.788
[51,     1] loss: 879.132
[52,     1] loss: 872.113
[53,     1] loss: 772.844
[54,     1] loss: 830.791
[55,     1] loss: 788.541
[56,     1] loss: 819.818
[57,     1] loss: 723.854
[58,     1] loss: 716.651
[59,     1] loss: 706.132
[60,     1] loss: 798.437
[61,     1] loss: 739.146
[62,     1] loss: 672.645
[63,     1] loss: 833.332
[64,     1] loss: 753.738
[65,     1] loss: 681.951
[66,     1] loss: 712.594
Early stopping applied (best metric=0.9548555016517639)
Finished Training
Total time taken: 12.358530759811401
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1380.100
[2,     1] loss: 1374.872
[3,     1] loss: 1379.262
[4,     1] loss: 1374.584
[5,     1] loss: 1369.416
[6,     1] loss: 1366.377
[7,     1] loss: 1359.203
[8,     1] loss: 1332.647
[9,     1] loss: 1298.736
[10,     1] loss: 1258.181
[11,     1] loss: 1209.388
[12,     1] loss: 1152.030
[13,     1] loss: 1154.698
[14,     1] loss: 1177.344
[15,     1] loss: 1179.593
[16,     1] loss: 1094.014
[17,     1] loss: 1090.465
[18,     1] loss: 1117.511
[19,     1] loss: 1139.473
[20,     1] loss: 1082.531
[21,     1] loss: 1058.991
[22,     1] loss: 1079.922
[23,     1] loss: 1063.210
[24,     1] loss: 1009.724
[25,     1] loss: 979.822
[26,     1] loss: 1017.617
[27,     1] loss: 1015.041
[28,     1] loss: 963.234
[29,     1] loss: 952.319
[30,     1] loss: 955.610
[31,     1] loss: 945.966
[32,     1] loss: 931.802
[33,     1] loss: 929.592
[34,     1] loss: 921.982
[35,     1] loss: 1002.937
[36,     1] loss: 978.776
[37,     1] loss: 890.538
[38,     1] loss: 953.062
[39,     1] loss: 887.761
[40,     1] loss: 864.346
[41,     1] loss: 835.124
[42,     1] loss: 859.760
[43,     1] loss: 911.520
[44,     1] loss: 794.411
[45,     1] loss: 816.704
[46,     1] loss: 825.897
[47,     1] loss: 825.937
[48,     1] loss: 741.605
[49,     1] loss: 839.443
[50,     1] loss: 797.478
[51,     1] loss: 758.928
[52,     1] loss: 724.351
[53,     1] loss: 769.941
[54,     1] loss: 795.448
[55,     1] loss: 807.210
[56,     1] loss: 769.107
[57,     1] loss: 639.630
[58,     1] loss: 838.158
[59,     1] loss: 777.834
[60,     1] loss: 703.930
[61,     1] loss: 670.445
[62,     1] loss: 761.018
[63,     1] loss: 668.319
[64,     1] loss: 640.530
[65,     1] loss: 755.704
[66,     1] loss: 959.057
Early stopping applied (best metric=0.8904749751091003)
Finished Training
Total time taken: 10.119318723678589
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1374.795
[2,     1] loss: 1387.440
[3,     1] loss: 1373.627
[4,     1] loss: 1375.678
[5,     1] loss: 1375.162
[6,     1] loss: 1370.237
[7,     1] loss: 1358.984
[8,     1] loss: 1352.581
[9,     1] loss: 1323.582
[10,     1] loss: 1284.553
[11,     1] loss: 1274.920
[12,     1] loss: 1227.037
[13,     1] loss: 1170.448
[14,     1] loss: 1167.306
[15,     1] loss: 1108.182
[16,     1] loss: 1167.896
[17,     1] loss: 1106.139
[18,     1] loss: 1182.864
[19,     1] loss: 1120.378
[20,     1] loss: 1123.479
[21,     1] loss: 1089.513
[22,     1] loss: 1130.324
[23,     1] loss: 1065.073
[24,     1] loss: 1111.105
[25,     1] loss: 1062.198
[26,     1] loss: 1064.587
[27,     1] loss: 1060.082
[28,     1] loss: 1036.916
[29,     1] loss: 1000.753
[30,     1] loss: 1015.742
[31,     1] loss: 1022.537
[32,     1] loss: 961.373
[33,     1] loss: 960.479
[34,     1] loss: 1042.250
[35,     1] loss: 1135.233
[36,     1] loss: 945.775
[37,     1] loss: 981.697
[38,     1] loss: 943.613
[39,     1] loss: 996.692
[40,     1] loss: 957.750
[41,     1] loss: 929.886
[42,     1] loss: 908.902
[43,     1] loss: 854.823
[44,     1] loss: 844.916
[45,     1] loss: 825.263
[46,     1] loss: 864.447
[47,     1] loss: 869.132
[48,     1] loss: 1115.279
[49,     1] loss: 1497.680
[50,     1] loss: 999.979
[51,     1] loss: 974.207
Early stopping applied (best metric=0.8075250387191772)
Finished Training
Total time taken: 8.612327575683594
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1379.032
[2,     1] loss: 1383.997
[3,     1] loss: 1380.880
[4,     1] loss: 1373.522
[5,     1] loss: 1375.519
[6,     1] loss: 1373.545
[7,     1] loss: 1372.575
[8,     1] loss: 1367.268
[9,     1] loss: 1368.800
[10,     1] loss: 1367.609
[11,     1] loss: 1367.258
[12,     1] loss: 1353.030
[13,     1] loss: 1347.663
[14,     1] loss: 1321.532
[15,     1] loss: 1310.154
[16,     1] loss: 1286.854
[17,     1] loss: 1251.772
[18,     1] loss: 1211.924
[19,     1] loss: 1220.710
[20,     1] loss: 1176.330
[21,     1] loss: 1180.092
[22,     1] loss: 1154.948
[23,     1] loss: 1125.063
[24,     1] loss: 1149.445
[25,     1] loss: 1149.049
[26,     1] loss: 1125.170
[27,     1] loss: 1116.322
[28,     1] loss: 1147.154
[29,     1] loss: 1174.855
[30,     1] loss: 1142.426
[31,     1] loss: 1155.638
[32,     1] loss: 1091.349
[33,     1] loss: 1050.434
[34,     1] loss: 1052.116
[35,     1] loss: 1061.866
[36,     1] loss: 1021.684
[37,     1] loss: 1039.042
[38,     1] loss: 1010.201
[39,     1] loss: 1062.780
[40,     1] loss: 982.210
[41,     1] loss: 1057.701
[42,     1] loss: 990.524
[43,     1] loss: 1034.107
[44,     1] loss: 990.790
[45,     1] loss: 1022.834
[46,     1] loss: 954.383
[47,     1] loss: 991.590
[48,     1] loss: 930.108
[49,     1] loss: 931.406
[50,     1] loss: 897.070
[51,     1] loss: 933.336
[52,     1] loss: 897.259
[53,     1] loss: 913.686
[54,     1] loss: 904.447
[55,     1] loss: 1116.669
[56,     1] loss: 1216.378
[57,     1] loss: 989.062
[58,     1] loss: 1011.256
[59,     1] loss: 1100.195
[60,     1] loss: 1066.027
[61,     1] loss: 1042.938
[62,     1] loss: 997.739
[63,     1] loss: 1048.159
[64,     1] loss: 967.996
[65,     1] loss: 918.055
[66,     1] loss: 944.435
[67,     1] loss: 987.471
[68,     1] loss: 851.895
[69,     1] loss: 883.347
[70,     1] loss: 862.981
[71,     1] loss: 922.244
[72,     1] loss: 859.542
[73,     1] loss: 870.179
[74,     1] loss: 842.188
[75,     1] loss: 879.063
[76,     1] loss: 815.716
[77,     1] loss: 776.813
[78,     1] loss: 767.730
[79,     1] loss: 828.038
[80,     1] loss: 783.727
[81,     1] loss: 850.389
[82,     1] loss: 1057.407
[83,     1] loss: 750.185
[84,     1] loss: 871.293
[85,     1] loss: 800.949
[86,     1] loss: 906.447
[87,     1] loss: 721.848
[88,     1] loss: 930.509
[89,     1] loss: 868.848
[90,     1] loss: 747.172
[91,     1] loss: 815.546
Early stopping applied (best metric=0.8104214072227478)
Finished Training
Total time taken: 14.825828075408936
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1372.401
[2,     1] loss: 1374.713
[3,     1] loss: 1373.739
[4,     1] loss: 1374.190
[5,     1] loss: 1367.909
[6,     1] loss: 1369.498
[7,     1] loss: 1350.369
[8,     1] loss: 1336.217
[9,     1] loss: 1284.205
[10,     1] loss: 1250.862
[11,     1] loss: 1223.050
[12,     1] loss: 1159.176
[13,     1] loss: 1178.628
[14,     1] loss: 1179.262
[15,     1] loss: 1148.661
[16,     1] loss: 1138.347
[17,     1] loss: 1128.602
[18,     1] loss: 1163.801
[19,     1] loss: 1118.841
[20,     1] loss: 1118.361
[21,     1] loss: 1108.855
[22,     1] loss: 1082.326
[23,     1] loss: 1060.096
[24,     1] loss: 1061.956
[25,     1] loss: 1052.630
[26,     1] loss: 1067.380
[27,     1] loss: 1031.435
[28,     1] loss: 1042.091
[29,     1] loss: 1015.110
[30,     1] loss: 1022.447
[31,     1] loss: 1019.810
[32,     1] loss: 966.712
[33,     1] loss: 1002.502
[34,     1] loss: 1107.309
[35,     1] loss: 907.772
[36,     1] loss: 961.814
[37,     1] loss: 891.491
[38,     1] loss: 888.827
[39,     1] loss: 967.938
[40,     1] loss: 951.160
[41,     1] loss: 935.792
[42,     1] loss: 938.559
[43,     1] loss: 883.755
[44,     1] loss: 862.225
[45,     1] loss: 902.692
[46,     1] loss: 943.975
[47,     1] loss: 869.684
[48,     1] loss: 814.015
[49,     1] loss: 899.809
[50,     1] loss: 908.920
[51,     1] loss: 825.732
[52,     1] loss: 869.055
[53,     1] loss: 837.166
[54,     1] loss: 987.168
[55,     1] loss: 776.151
[56,     1] loss: 934.581
[57,     1] loss: 789.758
[58,     1] loss: 765.157
[59,     1] loss: 742.201
[60,     1] loss: 761.411
[61,     1] loss: 792.239
[62,     1] loss: 960.248
[63,     1] loss: 747.278
Early stopping applied (best metric=0.8618157505989075)
Finished Training
Total time taken: 10.6312894821167
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1370.240
[2,     1] loss: 1380.422
[3,     1] loss: 1383.994
[4,     1] loss: 1372.621
[5,     1] loss: 1377.608
[6,     1] loss: 1373.467
[7,     1] loss: 1367.221
[8,     1] loss: 1358.454
[9,     1] loss: 1335.706
[10,     1] loss: 1309.519
[11,     1] loss: 1277.021
[12,     1] loss: 1230.724
[13,     1] loss: 1195.228
[14,     1] loss: 1144.581
[15,     1] loss: 1141.786
[16,     1] loss: 1207.285
[17,     1] loss: 1144.426
[18,     1] loss: 1135.971
[19,     1] loss: 1138.372
[20,     1] loss: 1085.086
[21,     1] loss: 1072.472
[22,     1] loss: 1074.439
[23,     1] loss: 1052.806
[24,     1] loss: 1046.684
[25,     1] loss: 1028.532
[26,     1] loss: 1080.569
[27,     1] loss: 1010.606
[28,     1] loss: 976.565
[29,     1] loss: 1055.967
[30,     1] loss: 1037.821
[31,     1] loss: 1004.346
[32,     1] loss: 941.743
[33,     1] loss: 1012.108
[34,     1] loss: 933.159
[35,     1] loss: 888.196
[36,     1] loss: 923.763
[37,     1] loss: 949.744
[38,     1] loss: 968.662
[39,     1] loss: 862.364
[40,     1] loss: 955.867
[41,     1] loss: 951.584
[42,     1] loss: 866.424
[43,     1] loss: 900.688
[44,     1] loss: 903.488
[45,     1] loss: 807.670
[46,     1] loss: 976.551
[47,     1] loss: 909.453
Early stopping applied (best metric=0.8039979934692383)
Finished Training
Total time taken: 7.635700225830078
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1376.867
[2,     1] loss: 1380.680
[3,     1] loss: 1373.681
[4,     1] loss: 1375.257
[5,     1] loss: 1373.929
[6,     1] loss: 1369.728
[7,     1] loss: 1377.289
[8,     1] loss: 1369.843
[9,     1] loss: 1370.299
[10,     1] loss: 1363.973
[11,     1] loss: 1357.652
[12,     1] loss: 1343.373
[13,     1] loss: 1320.255
[14,     1] loss: 1281.645
[15,     1] loss: 1274.909
[16,     1] loss: 1226.176
[17,     1] loss: 1149.683
[18,     1] loss: 1232.647
[19,     1] loss: 1169.094
[20,     1] loss: 1148.372
[21,     1] loss: 1171.833
[22,     1] loss: 1153.095
[23,     1] loss: 1144.145
[24,     1] loss: 1150.053
[25,     1] loss: 1134.921
[26,     1] loss: 1111.321
[27,     1] loss: 1106.035
[28,     1] loss: 1113.743
[29,     1] loss: 1080.940
[30,     1] loss: 1091.677
[31,     1] loss: 1065.203
[32,     1] loss: 1024.225
[33,     1] loss: 1045.855
[34,     1] loss: 1017.238
[35,     1] loss: 1006.953
[36,     1] loss: 1053.622
[37,     1] loss: 984.969
[38,     1] loss: 959.928
[39,     1] loss: 998.144
[40,     1] loss: 952.924
[41,     1] loss: 1079.636
[42,     1] loss: 983.881
[43,     1] loss: 1000.722
[44,     1] loss: 966.450
[45,     1] loss: 988.030
[46,     1] loss: 950.835
[47,     1] loss: 1016.907
[48,     1] loss: 892.392
[49,     1] loss: 983.491
[50,     1] loss: 869.848
[51,     1] loss: 881.145
[52,     1] loss: 851.039
[53,     1] loss: 858.632
[54,     1] loss: 870.056
[55,     1] loss: 1067.717
[56,     1] loss: 901.731
[57,     1] loss: 856.426
[58,     1] loss: 886.094
[59,     1] loss: 905.891
[60,     1] loss: 848.430
[61,     1] loss: 895.629
[62,     1] loss: 776.941
[63,     1] loss: 766.012
[64,     1] loss: 782.962
[65,     1] loss: 781.388
[66,     1] loss: 929.793
[67,     1] loss: 895.647
[68,     1] loss: 750.080
[69,     1] loss: 850.426
[70,     1] loss: 768.540
[71,     1] loss: 791.682
[72,     1] loss: 772.320
[73,     1] loss: 768.177
[74,     1] loss: 992.773
[75,     1] loss: 957.832
[76,     1] loss: 853.578
[77,     1] loss: 855.870
[78,     1] loss: 894.326
[79,     1] loss: 779.371
[80,     1] loss: 825.686
[81,     1] loss: 700.543
[82,     1] loss: 868.153
Early stopping applied (best metric=0.6383280754089355)
Finished Training
Total time taken: 13.6168692111969
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1376.150
[2,     1] loss: 1375.728
[3,     1] loss: 1371.078
[4,     1] loss: 1373.250
[5,     1] loss: 1371.163
[6,     1] loss: 1365.139
[7,     1] loss: 1343.010
[8,     1] loss: 1319.319
[9,     1] loss: 1288.153
[10,     1] loss: 1225.685
[11,     1] loss: 1212.640
[12,     1] loss: 1218.191
[13,     1] loss: 1208.426
[14,     1] loss: 1189.656
[15,     1] loss: 1138.644
[16,     1] loss: 1141.063
[17,     1] loss: 1131.464
[18,     1] loss: 1121.257
[19,     1] loss: 1070.636
[20,     1] loss: 1127.214
[21,     1] loss: 1075.510
[22,     1] loss: 1105.772
[23,     1] loss: 1057.526
[24,     1] loss: 1150.223
[25,     1] loss: 1034.573
[26,     1] loss: 1102.045
[27,     1] loss: 981.444
[28,     1] loss: 1017.695
[29,     1] loss: 992.835
[30,     1] loss: 996.547
[31,     1] loss: 1035.721
[32,     1] loss: 934.668
[33,     1] loss: 932.625
[34,     1] loss: 986.019
[35,     1] loss: 970.377
[36,     1] loss: 976.026
[37,     1] loss: 971.818
[38,     1] loss: 969.060
[39,     1] loss: 939.772
[40,     1] loss: 918.203
[41,     1] loss: 965.891
[42,     1] loss: 940.435
[43,     1] loss: 895.130
[44,     1] loss: 889.148
[45,     1] loss: 866.858
[46,     1] loss: 850.399
[47,     1] loss: 849.805
[48,     1] loss: 874.930
[49,     1] loss: 1505.959
[50,     1] loss: 1319.775
[51,     1] loss: 1065.462
[52,     1] loss: 1105.570
[53,     1] loss: 1157.492
[54,     1] loss: 1169.818
[55,     1] loss: 1139.226
[56,     1] loss: 1092.031
[57,     1] loss: 1080.791
[58,     1] loss: 1060.563
[59,     1] loss: 1008.190
[60,     1] loss: 1017.924
[61,     1] loss: 1030.483
Early stopping applied (best metric=0.8128923177719116)
Finished Training
Total time taken: 9.071842432022095
{'Hydroxylation-K Validation Accuracy': 0.7592789598108747, 'Hydroxylation-K Validation Sensitivity': 0.6466666666666666, 'Hydroxylation-K Validation Specificity': 0.787719298245614, 'Hydroxylation-K Validation Precision': 0.45459152932837144, 'Hydroxylation-K AUC ROC': 0.7823001949317739, 'Hydroxylation-K AUC PR': 0.6129804470722137, 'Hydroxylation-K MCC': 0.3890722121649188, 'Hydroxylation-K F1': 0.5206256921489305, 'Validation Loss (Hydroxylation-K)': 0.4484681109587351, 'Hydroxylation-P Validation Accuracy': 0.7697627024008934, 'Hydroxylation-P Validation Sensitivity': 0.7956084656084657, 'Hydroxylation-P Validation Specificity': 0.7642600628460272, 'Hydroxylation-P Validation Precision': 0.4293457111672192, 'Hydroxylation-P AUC ROC': 0.8488753625047206, 'Hydroxylation-P AUC PR': 0.578054443430945, 'Hydroxylation-P MCC': 0.45813174676772483, 'Hydroxylation-P F1': 0.5542257093097384, 'Validation Loss (Hydroxylation-P)': 0.3759058972199758, 'Validation Loss (total)': 0.824374012152354, 'TimeToTrain': 10.448565324147543}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003010726632389955,
 'learning_rate_Hydroxylation-K': 0.0030748065295715496,
 'learning_rate_Hydroxylation-P': 0.005855903976202873,
 'log_base': 1.1927023985529541,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3785503255,
 'sample_weights': [2.2091677113998576, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.066523373241262,
 'weight_decay_Hydroxylation-K': 1.1649169732849467,
 'weight_decay_Hydroxylation-P': 4.556724217526021}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3082.907
[2,     1] loss: 3078.071
[3,     1] loss: 3065.931
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035509799366590443,
 'learning_rate_Hydroxylation-K': 0.0006058622343948779,
 'learning_rate_Hydroxylation-P': 0.007669781057811752,
 'log_base': 2.8713913862126765,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3869813278,
 'sample_weights': [9.47354138440599, 1.1842382929077933],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.873494379705269,
 'weight_decay_Hydroxylation-K': 5.470604511512802,
 'weight_decay_Hydroxylation-P': 4.972224837120511}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.377
[2,     1] loss: 1243.991
[3,     1] loss: 1233.963
[4,     1] loss: 1248.402
[5,     1] loss: 1238.074
[6,     1] loss: 1237.061
[7,     1] loss: 1233.771
[8,     1] loss: 1212.752
[9,     1] loss: 1195.550
[10,     1] loss: 1160.811
[11,     1] loss: 1117.603
[12,     1] loss: 1073.142
[13,     1] loss: 1063.389
[14,     1] loss: 1030.947
[15,     1] loss: 1047.409
[16,     1] loss: 1049.779
[17,     1] loss: 989.789
[18,     1] loss: 949.774
[19,     1] loss: 981.493
[20,     1] loss: 1022.593
[21,     1] loss: 969.332
[22,     1] loss: 1004.153
[23,     1] loss: 934.747
[24,     1] loss: 941.882
[25,     1] loss: 894.451
[26,     1] loss: 937.371
[27,     1] loss: 876.045
[28,     1] loss: 869.328
[29,     1] loss: 913.789
[30,     1] loss: 928.669
[31,     1] loss: 889.604
[32,     1] loss: 841.732
[33,     1] loss: 857.087
[34,     1] loss: 855.411
[35,     1] loss: 835.831
[36,     1] loss: 820.773
[37,     1] loss: 804.973
[38,     1] loss: 863.411
[39,     1] loss: 792.656
[40,     1] loss: 836.086
[41,     1] loss: 768.458
[42,     1] loss: 774.875
[43,     1] loss: 760.071
[44,     1] loss: 755.006
[45,     1] loss: 919.294
[46,     1] loss: 963.959
[47,     1] loss: 754.681
[48,     1] loss: 852.965
[49,     1] loss: 769.417
[50,     1] loss: 802.984
[51,     1] loss: 805.109
[52,     1] loss: 766.983
[53,     1] loss: 795.918
[54,     1] loss: 722.890
[55,     1] loss: 767.255
[56,     1] loss: 655.987
[57,     1] loss: 687.500
[58,     1] loss: 663.934
[59,     1] loss: 698.931
[60,     1] loss: 647.460
Early stopping applied (best metric=0.8200640082359314)
Finished Training
Total time taken: 11.780631065368652
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.025
[2,     1] loss: 1244.271
[3,     1] loss: 1249.793
[4,     1] loss: 1240.152
[5,     1] loss: 1232.947
[6,     1] loss: 1215.385
[7,     1] loss: 1177.250
[8,     1] loss: 1153.913
[9,     1] loss: 1084.133
[10,     1] loss: 1084.599
[11,     1] loss: 1040.847
[12,     1] loss: 1011.158
[13,     1] loss: 995.808
[14,     1] loss: 994.953
[15,     1] loss: 1026.905
[16,     1] loss: 1010.047
[17,     1] loss: 923.345
[18,     1] loss: 976.382
[19,     1] loss: 979.094
[20,     1] loss: 979.730
[21,     1] loss: 977.579
[22,     1] loss: 947.126
[23,     1] loss: 895.584
[24,     1] loss: 911.679
[25,     1] loss: 932.638
[26,     1] loss: 904.252
[27,     1] loss: 903.645
[28,     1] loss: 836.030
[29,     1] loss: 863.709
[30,     1] loss: 885.129
[31,     1] loss: 820.446
[32,     1] loss: 816.898
[33,     1] loss: 820.900
[34,     1] loss: 794.319
[35,     1] loss: 750.403
[36,     1] loss: 797.851
[37,     1] loss: 758.137
[38,     1] loss: 760.519
[39,     1] loss: 735.603
[40,     1] loss: 730.423
[41,     1] loss: 712.912
[42,     1] loss: 787.050
[43,     1] loss: 1214.179
[44,     1] loss: 917.210
[45,     1] loss: 923.159
[46,     1] loss: 912.256
[47,     1] loss: 904.382
[48,     1] loss: 929.940
[49,     1] loss: 925.119
[50,     1] loss: 848.534
[51,     1] loss: 791.327
[52,     1] loss: 850.177
[53,     1] loss: 857.426
[54,     1] loss: 807.117
Early stopping applied (best metric=0.919191837310791)
Finished Training
Total time taken: 9.503746747970581
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1244.401
[2,     1] loss: 1241.851
[3,     1] loss: 1240.691
[4,     1] loss: 1244.193
[5,     1] loss: 1244.047
[6,     1] loss: 1241.906
[7,     1] loss: 1235.210
[8,     1] loss: 1231.140
[9,     1] loss: 1217.682
[10,     1] loss: 1198.866
[11,     1] loss: 1162.093
[12,     1] loss: 1121.461
[13,     1] loss: 1101.354
[14,     1] loss: 1061.677
[15,     1] loss: 1029.411
[16,     1] loss: 1077.233
[17,     1] loss: 1030.392
[18,     1] loss: 1027.160
[19,     1] loss: 1023.321
[20,     1] loss: 1015.425
[21,     1] loss: 1057.879
[22,     1] loss: 1010.920
[23,     1] loss: 1016.170
[24,     1] loss: 946.375
[25,     1] loss: 973.554
[26,     1] loss: 964.128
[27,     1] loss: 949.739
[28,     1] loss: 974.882
[29,     1] loss: 909.400
[30,     1] loss: 881.151
[31,     1] loss: 887.090
[32,     1] loss: 887.161
[33,     1] loss: 879.254
[34,     1] loss: 928.681
[35,     1] loss: 869.368
[36,     1] loss: 873.791
[37,     1] loss: 902.714
[38,     1] loss: 870.019
[39,     1] loss: 852.026
[40,     1] loss: 930.568
[41,     1] loss: 801.610
[42,     1] loss: 839.817
[43,     1] loss: 798.754
[44,     1] loss: 820.829
[45,     1] loss: 788.135
[46,     1] loss: 817.806
[47,     1] loss: 849.632
[48,     1] loss: 742.138
[49,     1] loss: 875.100
[50,     1] loss: 825.897
[51,     1] loss: 718.979
[52,     1] loss: 740.206
[53,     1] loss: 776.669
[54,     1] loss: 721.669
[55,     1] loss: 707.269
[56,     1] loss: 816.781
[57,     1] loss: 688.634
[58,     1] loss: 761.171
[59,     1] loss: 839.074
[60,     1] loss: 655.522
[61,     1] loss: 826.974
[62,     1] loss: 683.226
[63,     1] loss: 685.058
[64,     1] loss: 681.315
[65,     1] loss: 621.856
[66,     1] loss: 673.310
[67,     1] loss: 602.398
[68,     1] loss: 667.368
[69,     1] loss: 596.128
[70,     1] loss: 539.408
[71,     1] loss: 632.366
[72,     1] loss: 691.662
[73,     1] loss: 566.793
[74,     1] loss: 715.320
[75,     1] loss: 642.101
[76,     1] loss: 595.996
[77,     1] loss: 615.498
[78,     1] loss: 583.098
[79,     1] loss: 661.032
[80,     1] loss: 551.378
[81,     1] loss: 709.602
Early stopping applied (best metric=0.7819559574127197)
Finished Training
Total time taken: 13.344795942306519
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1250.437
[2,     1] loss: 1249.736
[3,     1] loss: 1241.345
[4,     1] loss: 1238.586
[5,     1] loss: 1239.479
[6,     1] loss: 1237.708
[7,     1] loss: 1237.116
[8,     1] loss: 1218.035
[9,     1] loss: 1197.976
[10,     1] loss: 1171.305
[11,     1] loss: 1126.269
[12,     1] loss: 1108.563
[13,     1] loss: 1058.878
[14,     1] loss: 1065.165
[15,     1] loss: 1046.338
[16,     1] loss: 1031.219
[17,     1] loss: 1031.331
[18,     1] loss: 1009.033
[19,     1] loss: 985.489
[20,     1] loss: 1048.064
[21,     1] loss: 943.342
[22,     1] loss: 960.333
[23,     1] loss: 959.280
[24,     1] loss: 937.244
[25,     1] loss: 928.468
[26,     1] loss: 914.064
[27,     1] loss: 911.085
[28,     1] loss: 873.248
[29,     1] loss: 884.283
[30,     1] loss: 872.227
[31,     1] loss: 911.201
[32,     1] loss: 859.208
[33,     1] loss: 876.510
[34,     1] loss: 830.272
[35,     1] loss: 882.228
[36,     1] loss: 861.825
[37,     1] loss: 845.859
[38,     1] loss: 850.396
[39,     1] loss: 790.308
[40,     1] loss: 859.351
[41,     1] loss: 777.901
[42,     1] loss: 830.349
[43,     1] loss: 806.018
[44,     1] loss: 757.882
[45,     1] loss: 768.547
[46,     1] loss: 742.230
[47,     1] loss: 773.094
[48,     1] loss: 721.006
[49,     1] loss: 725.125
[50,     1] loss: 774.828
[51,     1] loss: 666.619
[52,     1] loss: 733.540
[53,     1] loss: 745.156
[54,     1] loss: 652.470
[55,     1] loss: 660.786
[56,     1] loss: 698.000
[57,     1] loss: 609.646
[58,     1] loss: 596.588
[59,     1] loss: 596.045
[60,     1] loss: 729.531
[61,     1] loss: 1108.241
[62,     1] loss: 900.601
[63,     1] loss: 850.150
[64,     1] loss: 701.931
[65,     1] loss: 842.143
[66,     1] loss: 854.280
[67,     1] loss: 792.912
[68,     1] loss: 773.759
[69,     1] loss: 783.174
[70,     1] loss: 799.572
[71,     1] loss: 764.356
[72,     1] loss: 749.345
[73,     1] loss: 736.390
[74,     1] loss: 669.775
[75,     1] loss: 641.313
[76,     1] loss: 724.370
[77,     1] loss: 636.391
Early stopping applied (best metric=0.7688455581665039)
Finished Training
Total time taken: 13.186827898025513
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1246.097
[2,     1] loss: 1241.083
[3,     1] loss: 1243.296
[4,     1] loss: 1245.452
[5,     1] loss: 1239.140
[6,     1] loss: 1231.871
[7,     1] loss: 1212.166
[8,     1] loss: 1173.900
[9,     1] loss: 1105.281
[10,     1] loss: 1092.166
[11,     1] loss: 1068.452
[12,     1] loss: 1053.515
[13,     1] loss: 1069.826
[14,     1] loss: 1022.184
[15,     1] loss: 1041.212
[16,     1] loss: 1025.528
[17,     1] loss: 982.437
[18,     1] loss: 987.051
[19,     1] loss: 971.554
[20,     1] loss: 963.950
[21,     1] loss: 959.514
[22,     1] loss: 957.516
[23,     1] loss: 971.608
[24,     1] loss: 930.206
[25,     1] loss: 906.216
[26,     1] loss: 930.878
[27,     1] loss: 957.741
[28,     1] loss: 912.952
[29,     1] loss: 935.896
[30,     1] loss: 850.102
[31,     1] loss: 884.535
[32,     1] loss: 885.391
[33,     1] loss: 877.124
[34,     1] loss: 880.789
[35,     1] loss: 863.435
[36,     1] loss: 851.002
[37,     1] loss: 782.727
[38,     1] loss: 907.314
[39,     1] loss: 800.848
[40,     1] loss: 817.220
[41,     1] loss: 833.571
[42,     1] loss: 815.526
[43,     1] loss: 757.790
[44,     1] loss: 778.099
[45,     1] loss: 776.102
[46,     1] loss: 680.687
[47,     1] loss: 725.981
[48,     1] loss: 955.720
[49,     1] loss: 1421.503
[50,     1] loss: 820.037
[51,     1] loss: 881.714
[52,     1] loss: 989.132
[53,     1] loss: 965.335
[54,     1] loss: 940.171
[55,     1] loss: 918.400
[56,     1] loss: 917.747
[57,     1] loss: 927.447
[58,     1] loss: 879.179
[59,     1] loss: 841.848
[60,     1] loss: 845.867
[61,     1] loss: 877.757
[62,     1] loss: 850.867
[63,     1] loss: 876.002
[64,     1] loss: 786.034
[65,     1] loss: 800.503
[66,     1] loss: 784.324
Early stopping applied (best metric=0.7319197654724121)
Finished Training
Total time taken: 12.37781286239624
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.604
[2,     1] loss: 1243.669
[3,     1] loss: 1243.148
[4,     1] loss: 1239.902
[5,     1] loss: 1233.279
[6,     1] loss: 1228.351
[7,     1] loss: 1189.649
[8,     1] loss: 1158.678
[9,     1] loss: 1114.060
[10,     1] loss: 1096.059
[11,     1] loss: 1025.417
[12,     1] loss: 1061.734
[13,     1] loss: 1035.996
[14,     1] loss: 1015.540
[15,     1] loss: 1014.730
[16,     1] loss: 994.749
[17,     1] loss: 1021.918
[18,     1] loss: 993.811
[19,     1] loss: 997.551
[20,     1] loss: 1026.305
[21,     1] loss: 926.559
[22,     1] loss: 981.964
[23,     1] loss: 1003.093
[24,     1] loss: 941.435
[25,     1] loss: 961.660
[26,     1] loss: 937.089
[27,     1] loss: 943.510
[28,     1] loss: 929.350
[29,     1] loss: 893.857
[30,     1] loss: 885.071
[31,     1] loss: 879.931
[32,     1] loss: 856.861
[33,     1] loss: 881.932
[34,     1] loss: 886.765
[35,     1] loss: 839.739
[36,     1] loss: 843.028
[37,     1] loss: 870.415
[38,     1] loss: 776.115
[39,     1] loss: 923.769
[40,     1] loss: 786.186
[41,     1] loss: 807.031
[42,     1] loss: 793.709
[43,     1] loss: 795.963
[44,     1] loss: 787.393
[45,     1] loss: 784.129
[46,     1] loss: 741.712
[47,     1] loss: 785.670
[48,     1] loss: 717.733
[49,     1] loss: 705.938
[50,     1] loss: 719.215
[51,     1] loss: 743.960
[52,     1] loss: 741.196
[53,     1] loss: 738.121
[54,     1] loss: 695.566
[55,     1] loss: 731.309
[56,     1] loss: 778.957
[57,     1] loss: 719.915
[58,     1] loss: 662.290
[59,     1] loss: 754.975
[60,     1] loss: 698.958
[61,     1] loss: 687.889
[62,     1] loss: 744.806
[63,     1] loss: 613.497
[64,     1] loss: 674.867
[65,     1] loss: 599.553
[66,     1] loss: 652.279
[67,     1] loss: 670.725
Early stopping applied (best metric=0.9312283396720886)
Finished Training
Total time taken: 11.185234546661377
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.637
[2,     1] loss: 1244.962
[3,     1] loss: 1239.993
[4,     1] loss: 1239.839
[5,     1] loss: 1228.051
[6,     1] loss: 1210.125
[7,     1] loss: 1182.302
[8,     1] loss: 1145.585
[9,     1] loss: 1106.571
[10,     1] loss: 1080.030
[11,     1] loss: 983.739
[12,     1] loss: 1038.487
[13,     1] loss: 997.492
[14,     1] loss: 981.463
[15,     1] loss: 1038.385
[16,     1] loss: 985.448
[17,     1] loss: 960.994
[18,     1] loss: 1033.259
[19,     1] loss: 976.365
[20,     1] loss: 955.869
[21,     1] loss: 962.707
[22,     1] loss: 966.600
[23,     1] loss: 906.521
[24,     1] loss: 923.526
[25,     1] loss: 921.617
[26,     1] loss: 905.120
[27,     1] loss: 916.894
[28,     1] loss: 921.858
[29,     1] loss: 869.574
[30,     1] loss: 900.559
[31,     1] loss: 858.143
[32,     1] loss: 841.044
[33,     1] loss: 856.059
[34,     1] loss: 911.571
[35,     1] loss: 909.700
[36,     1] loss: 847.944
[37,     1] loss: 854.266
[38,     1] loss: 814.370
[39,     1] loss: 806.068
[40,     1] loss: 803.221
[41,     1] loss: 783.512
[42,     1] loss: 774.890
[43,     1] loss: 800.158
[44,     1] loss: 771.645
[45,     1] loss: 747.387
[46,     1] loss: 783.341
[47,     1] loss: 683.388
[48,     1] loss: 729.836
[49,     1] loss: 723.066
[50,     1] loss: 641.214
[51,     1] loss: 743.961
[52,     1] loss: 696.393
[53,     1] loss: 635.701
[54,     1] loss: 706.666
[55,     1] loss: 733.246
[56,     1] loss: 651.225
[57,     1] loss: 626.892
[58,     1] loss: 747.269
[59,     1] loss: 642.306
[60,     1] loss: 581.135
[61,     1] loss: 620.685
[62,     1] loss: 551.069
[63,     1] loss: 575.734
[64,     1] loss: 554.906
Early stopping applied (best metric=0.8582731485366821)
Finished Training
Total time taken: 9.650329351425171
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.392
[2,     1] loss: 1237.371
[3,     1] loss: 1237.577
[4,     1] loss: 1246.665
[5,     1] loss: 1222.223
[6,     1] loss: 1199.798
[7,     1] loss: 1158.316
[8,     1] loss: 1119.012
[9,     1] loss: 1141.792
[10,     1] loss: 1037.154
[11,     1] loss: 1104.365
[12,     1] loss: 1047.530
[13,     1] loss: 1068.845
[14,     1] loss: 1040.777
[15,     1] loss: 998.883
[16,     1] loss: 1018.048
[17,     1] loss: 997.727
[18,     1] loss: 993.586
[19,     1] loss: 993.360
[20,     1] loss: 977.414
[21,     1] loss: 986.974
[22,     1] loss: 934.591
[23,     1] loss: 947.502
[24,     1] loss: 956.044
[25,     1] loss: 900.325
[26,     1] loss: 895.004
[27,     1] loss: 924.989
[28,     1] loss: 886.783
[29,     1] loss: 886.039
[30,     1] loss: 832.645
[31,     1] loss: 830.688
[32,     1] loss: 788.740
[33,     1] loss: 877.028
[34,     1] loss: 801.345
[35,     1] loss: 789.904
[36,     1] loss: 764.239
[37,     1] loss: 788.232
[38,     1] loss: 767.239
[39,     1] loss: 821.434
[40,     1] loss: 943.787
[41,     1] loss: 773.801
[42,     1] loss: 801.447
[43,     1] loss: 799.085
[44,     1] loss: 780.680
[45,     1] loss: 750.043
Early stopping applied (best metric=0.9637123346328735)
Finished Training
Total time taken: 8.149970054626465
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1244.216
[2,     1] loss: 1248.305
[3,     1] loss: 1241.461
[4,     1] loss: 1240.543
[5,     1] loss: 1233.760
[6,     1] loss: 1227.026
[7,     1] loss: 1209.596
[8,     1] loss: 1195.256
[9,     1] loss: 1150.021
[10,     1] loss: 1115.673
[11,     1] loss: 1108.225
[12,     1] loss: 1061.596
[13,     1] loss: 1029.243
[14,     1] loss: 1051.277
[15,     1] loss: 1020.258
[16,     1] loss: 1001.842
[17,     1] loss: 964.277
[18,     1] loss: 1007.046
[19,     1] loss: 1009.437
[20,     1] loss: 966.920
[21,     1] loss: 935.293
[22,     1] loss: 974.990
[23,     1] loss: 926.807
[24,     1] loss: 952.738
[25,     1] loss: 914.688
[26,     1] loss: 907.225
[27,     1] loss: 885.015
[28,     1] loss: 910.117
[29,     1] loss: 900.361
[30,     1] loss: 927.516
[31,     1] loss: 871.272
[32,     1] loss: 860.959
[33,     1] loss: 862.812
[34,     1] loss: 849.386
[35,     1] loss: 810.106
[36,     1] loss: 833.790
[37,     1] loss: 843.732
[38,     1] loss: 770.318
[39,     1] loss: 817.944
[40,     1] loss: 790.034
[41,     1] loss: 764.381
[42,     1] loss: 760.474
[43,     1] loss: 860.686
[44,     1] loss: 763.585
[45,     1] loss: 712.821
[46,     1] loss: 760.271
[47,     1] loss: 692.262
[48,     1] loss: 714.210
[49,     1] loss: 682.552
[50,     1] loss: 737.543
[51,     1] loss: 709.540
[52,     1] loss: 621.353
[53,     1] loss: 757.080
[54,     1] loss: 846.013
[55,     1] loss: 658.433
[56,     1] loss: 717.686
[57,     1] loss: 710.282
[58,     1] loss: 697.752
[59,     1] loss: 690.756
[60,     1] loss: 640.282
[61,     1] loss: 612.873
[62,     1] loss: 674.418
[63,     1] loss: 722.337
[64,     1] loss: 617.225
[65,     1] loss: 594.997
[66,     1] loss: 581.726
[67,     1] loss: 595.560
[68,     1] loss: 552.183
[69,     1] loss: 617.643
[70,     1] loss: 790.799
[71,     1] loss: 855.547
[72,     1] loss: 624.653
[73,     1] loss: 739.514
[74,     1] loss: 640.898
[75,     1] loss: 718.556
[76,     1] loss: 688.279
[77,     1] loss: 602.212
[78,     1] loss: 636.441
[79,     1] loss: 582.880
[80,     1] loss: 634.440
[81,     1] loss: 606.717
[82,     1] loss: 629.466
[83,     1] loss: 545.451
[84,     1] loss: 648.765
[85,     1] loss: 481.949
[86,     1] loss: 668.969
[87,     1] loss: 518.629
[88,     1] loss: 511.042
[89,     1] loss: 513.203
[90,     1] loss: 493.814
[91,     1] loss: 464.823
[92,     1] loss: 534.590
[93,     1] loss: 435.491
[94,     1] loss: 496.477
[95,     1] loss: 577.048
[96,     1] loss: 476.696
[97,     1] loss: 422.482
[98,     1] loss: 417.766
[99,     1] loss: 438.598
[100,     1] loss: 446.091
[101,     1] loss: 430.803
[102,     1] loss: 420.344
[103,     1] loss: 394.893
[104,     1] loss: 424.133
[105,     1] loss: 459.539
[106,     1] loss: 549.369
[107,     1] loss: 1178.782
Early stopping applied (best metric=0.6825979948043823)
Finished Training
Total time taken: 19.100501775741577
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1248.080
[2,     1] loss: 1244.492
[3,     1] loss: 1247.953
[4,     1] loss: 1244.157
[5,     1] loss: 1240.089
[6,     1] loss: 1242.940
[7,     1] loss: 1244.866
[8,     1] loss: 1233.798
[9,     1] loss: 1226.308
[10,     1] loss: 1219.239
[11,     1] loss: 1196.337
[12,     1] loss: 1176.652
[13,     1] loss: 1140.728
[14,     1] loss: 1150.532
[15,     1] loss: 1084.903
[16,     1] loss: 1093.420
[17,     1] loss: 1042.221
[18,     1] loss: 1073.620
[19,     1] loss: 1002.942
[20,     1] loss: 1001.776
[21,     1] loss: 1063.291
[22,     1] loss: 1007.129
[23,     1] loss: 998.217
[24,     1] loss: 1005.963
[25,     1] loss: 988.156
[26,     1] loss: 979.780
[27,     1] loss: 978.734
[28,     1] loss: 947.317
[29,     1] loss: 923.037
[30,     1] loss: 917.098
[31,     1] loss: 928.939
[32,     1] loss: 952.835
[33,     1] loss: 894.392
[34,     1] loss: 873.108
[35,     1] loss: 963.800
[36,     1] loss: 940.507
[37,     1] loss: 875.447
[38,     1] loss: 893.928
[39,     1] loss: 814.852
[40,     1] loss: 834.860
[41,     1] loss: 797.299
[42,     1] loss: 828.258
[43,     1] loss: 892.502
[44,     1] loss: 775.095
[45,     1] loss: 851.417
[46,     1] loss: 788.021
[47,     1] loss: 791.226
[48,     1] loss: 758.691
[49,     1] loss: 773.376
[50,     1] loss: 740.740
[51,     1] loss: 872.978
[52,     1] loss: 904.796
[53,     1] loss: 842.617
[54,     1] loss: 737.339
[55,     1] loss: 773.226
[56,     1] loss: 767.191
[57,     1] loss: 723.969
[58,     1] loss: 746.959
[59,     1] loss: 742.885
[60,     1] loss: 699.317
[61,     1] loss: 747.604
[62,     1] loss: 788.910
[63,     1] loss: 681.205
Early stopping applied (best metric=0.7623398303985596)
Finished Training
Total time taken: 11.071321725845337
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.538
[2,     1] loss: 1243.076
[3,     1] loss: 1238.332
[4,     1] loss: 1244.815
[5,     1] loss: 1237.470
[6,     1] loss: 1218.172
[7,     1] loss: 1196.254
[8,     1] loss: 1146.433
[9,     1] loss: 1118.115
[10,     1] loss: 1101.123
[11,     1] loss: 1052.235
[12,     1] loss: 1015.279
[13,     1] loss: 1109.546
[14,     1] loss: 1000.925
[15,     1] loss: 1120.710
[16,     1] loss: 997.982
[17,     1] loss: 1035.625
[18,     1] loss: 1033.251
[19,     1] loss: 999.902
[20,     1] loss: 992.401
[21,     1] loss: 1003.026
[22,     1] loss: 967.245
[23,     1] loss: 980.522
[24,     1] loss: 945.542
[25,     1] loss: 962.491
[26,     1] loss: 955.150
[27,     1] loss: 928.854
[28,     1] loss: 887.236
[29,     1] loss: 866.398
[30,     1] loss: 885.046
[31,     1] loss: 876.276
[32,     1] loss: 914.709
[33,     1] loss: 907.446
[34,     1] loss: 874.787
[35,     1] loss: 857.902
[36,     1] loss: 877.373
[37,     1] loss: 832.331
[38,     1] loss: 856.325
[39,     1] loss: 855.379
[40,     1] loss: 822.198
[41,     1] loss: 815.571
[42,     1] loss: 825.734
[43,     1] loss: 780.235
[44,     1] loss: 815.679
[45,     1] loss: 796.832
[46,     1] loss: 785.152
[47,     1] loss: 813.378
[48,     1] loss: 747.869
[49,     1] loss: 724.277
[50,     1] loss: 684.566
[51,     1] loss: 675.784
[52,     1] loss: 689.327
[53,     1] loss: 683.938
[54,     1] loss: 735.818
[55,     1] loss: 1017.137
[56,     1] loss: 1034.456
Early stopping applied (best metric=0.8597646951675415)
Finished Training
Total time taken: 10.641872644424438
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.672
[2,     1] loss: 1244.978
[3,     1] loss: 1244.137
[4,     1] loss: 1241.142
[5,     1] loss: 1241.583
[6,     1] loss: 1234.649
[7,     1] loss: 1219.960
[8,     1] loss: 1201.457
[9,     1] loss: 1160.707
[10,     1] loss: 1179.314
[11,     1] loss: 1128.212
[12,     1] loss: 1118.343
[13,     1] loss: 1058.698
[14,     1] loss: 1097.022
[15,     1] loss: 1027.042
[16,     1] loss: 1031.983
[17,     1] loss: 1022.185
[18,     1] loss: 1034.123
[19,     1] loss: 1014.313
[20,     1] loss: 979.980
[21,     1] loss: 969.862
[22,     1] loss: 976.777
[23,     1] loss: 937.102
[24,     1] loss: 953.673
[25,     1] loss: 985.696
[26,     1] loss: 944.134
[27,     1] loss: 947.443
[28,     1] loss: 915.247
[29,     1] loss: 881.733
[30,     1] loss: 873.401
[31,     1] loss: 849.610
[32,     1] loss: 868.478
[33,     1] loss: 857.312
[34,     1] loss: 848.053
[35,     1] loss: 865.875
[36,     1] loss: 810.433
[37,     1] loss: 825.357
[38,     1] loss: 837.038
[39,     1] loss: 832.877
[40,     1] loss: 900.764
[41,     1] loss: 871.856
[42,     1] loss: 806.241
[43,     1] loss: 857.223
[44,     1] loss: 791.473
[45,     1] loss: 814.261
[46,     1] loss: 767.690
[47,     1] loss: 777.273
[48,     1] loss: 771.437
[49,     1] loss: 739.414
[50,     1] loss: 726.441
[51,     1] loss: 760.806
[52,     1] loss: 729.217
[53,     1] loss: 640.308
[54,     1] loss: 737.711
[55,     1] loss: 703.226
[56,     1] loss: 688.010
[57,     1] loss: 630.951
[58,     1] loss: 661.567
[59,     1] loss: 661.228
[60,     1] loss: 621.235
[61,     1] loss: 817.439
[62,     1] loss: 933.417
[63,     1] loss: 648.743
[64,     1] loss: 859.878
[65,     1] loss: 684.488
[66,     1] loss: 736.775
[67,     1] loss: 712.563
[68,     1] loss: 669.673
[69,     1] loss: 706.404
[70,     1] loss: 633.877
[71,     1] loss: 637.325
[72,     1] loss: 588.242
[73,     1] loss: 660.222
[74,     1] loss: 635.776
[75,     1] loss: 556.130
[76,     1] loss: 598.732
[77,     1] loss: 527.941
[78,     1] loss: 579.565
[79,     1] loss: 594.391
[80,     1] loss: 502.640
[81,     1] loss: 554.091
[82,     1] loss: 658.985
[83,     1] loss: 732.969
[84,     1] loss: 552.664
[85,     1] loss: 763.719
[86,     1] loss: 558.166
[87,     1] loss: 716.876
[88,     1] loss: 569.693
[89,     1] loss: 638.960
[90,     1] loss: 498.978
[91,     1] loss: 554.625
[92,     1] loss: 517.019
[93,     1] loss: 449.958
[94,     1] loss: 454.579
[95,     1] loss: 486.109
[96,     1] loss: 467.800
[97,     1] loss: 407.478
[98,     1] loss: 431.938
[99,     1] loss: 430.105
[100,     1] loss: 383.190
[101,     1] loss: 435.585
[102,     1] loss: 434.631
[103,     1] loss: 367.451
[104,     1] loss: 406.769
[105,     1] loss: 519.055
Early stopping applied (best metric=0.8423235416412354)
Finished Training
Total time taken: 19.50306010246277
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.426
[2,     1] loss: 1241.344
[3,     1] loss: 1244.475
[4,     1] loss: 1239.734
[5,     1] loss: 1240.226
[6,     1] loss: 1237.124
[7,     1] loss: 1223.001
[8,     1] loss: 1211.561
[9,     1] loss: 1175.646
[10,     1] loss: 1141.200
[11,     1] loss: 1111.055
[12,     1] loss: 1070.007
[13,     1] loss: 1045.895
[14,     1] loss: 1032.164
[15,     1] loss: 1035.171
[16,     1] loss: 1030.028
[17,     1] loss: 1031.795
[18,     1] loss: 1014.841
[19,     1] loss: 1010.803
[20,     1] loss: 1001.594
[21,     1] loss: 1014.427
[22,     1] loss: 980.614
[23,     1] loss: 1000.147
[24,     1] loss: 951.428
[25,     1] loss: 953.334
[26,     1] loss: 959.572
[27,     1] loss: 912.487
[28,     1] loss: 912.608
[29,     1] loss: 910.776
[30,     1] loss: 915.698
[31,     1] loss: 848.411
[32,     1] loss: 963.439
[33,     1] loss: 905.376
[34,     1] loss: 886.673
[35,     1] loss: 841.538
[36,     1] loss: 845.240
[37,     1] loss: 844.545
[38,     1] loss: 848.609
[39,     1] loss: 788.554
[40,     1] loss: 815.715
[41,     1] loss: 792.601
[42,     1] loss: 824.820
[43,     1] loss: 783.782
[44,     1] loss: 780.373
[45,     1] loss: 737.236
[46,     1] loss: 758.328
[47,     1] loss: 755.029
[48,     1] loss: 749.425
[49,     1] loss: 684.181
[50,     1] loss: 732.513
[51,     1] loss: 845.920
[52,     1] loss: 690.278
[53,     1] loss: 772.679
[54,     1] loss: 729.833
[55,     1] loss: 723.561
[56,     1] loss: 673.895
[57,     1] loss: 690.521
[58,     1] loss: 638.709
[59,     1] loss: 692.110
[60,     1] loss: 779.527
[61,     1] loss: 606.201
[62,     1] loss: 714.249
[63,     1] loss: 710.122
[64,     1] loss: 639.087
[65,     1] loss: 642.044
Early stopping applied (best metric=0.8304010629653931)
Finished Training
Total time taken: 10.167263507843018
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1245.734
[2,     1] loss: 1241.223
[3,     1] loss: 1246.157
[4,     1] loss: 1240.672
[5,     1] loss: 1241.306
[6,     1] loss: 1237.433
[7,     1] loss: 1234.717
[8,     1] loss: 1220.732
[9,     1] loss: 1205.759
[10,     1] loss: 1173.303
[11,     1] loss: 1134.202
[12,     1] loss: 1107.163
[13,     1] loss: 1070.987
[14,     1] loss: 1063.974
[15,     1] loss: 1026.659
[16,     1] loss: 1017.886
[17,     1] loss: 1015.501
[18,     1] loss: 1003.480
[19,     1] loss: 1013.591
[20,     1] loss: 1014.080
[21,     1] loss: 990.776
[22,     1] loss: 968.976
[23,     1] loss: 941.635
[24,     1] loss: 951.390
[25,     1] loss: 894.570
[26,     1] loss: 961.322
[27,     1] loss: 938.741
[28,     1] loss: 925.214
[29,     1] loss: 908.590
[30,     1] loss: 959.725
[31,     1] loss: 908.513
[32,     1] loss: 885.848
[33,     1] loss: 883.375
[34,     1] loss: 933.716
[35,     1] loss: 864.156
[36,     1] loss: 865.323
[37,     1] loss: 904.925
[38,     1] loss: 876.450
[39,     1] loss: 817.502
[40,     1] loss: 836.206
[41,     1] loss: 847.215
[42,     1] loss: 815.611
[43,     1] loss: 819.601
[44,     1] loss: 836.299
[45,     1] loss: 772.521
[46,     1] loss: 871.260
[47,     1] loss: 851.309
[48,     1] loss: 734.161
[49,     1] loss: 843.910
[50,     1] loss: 742.198
[51,     1] loss: 872.399
[52,     1] loss: 708.896
[53,     1] loss: 795.754
[54,     1] loss: 684.792
[55,     1] loss: 760.515
[56,     1] loss: 703.643
[57,     1] loss: 765.649
[58,     1] loss: 679.464
[59,     1] loss: 719.601
[60,     1] loss: 689.137
[61,     1] loss: 645.053
[62,     1] loss: 712.882
[63,     1] loss: 646.123
[64,     1] loss: 615.720
[65,     1] loss: 644.978
[66,     1] loss: 649.991
[67,     1] loss: 617.503
[68,     1] loss: 717.984
[69,     1] loss: 686.356
[70,     1] loss: 584.312
[71,     1] loss: 626.363
[72,     1] loss: 556.274
[73,     1] loss: 590.029
[74,     1] loss: 643.514
[75,     1] loss: 589.312
[76,     1] loss: 516.218
[77,     1] loss: 541.660
[78,     1] loss: 547.986
[79,     1] loss: 508.924
[80,     1] loss: 541.763
[81,     1] loss: 536.417
[82,     1] loss: 504.631
[83,     1] loss: 750.001
[84,     1] loss: 663.106
[85,     1] loss: 480.831
[86,     1] loss: 572.725
[87,     1] loss: 533.238
[88,     1] loss: 526.676
[89,     1] loss: 503.675
[90,     1] loss: 483.922
[91,     1] loss: 492.012
[92,     1] loss: 561.009
[93,     1] loss: 439.191
[94,     1] loss: 457.644
[95,     1] loss: 508.308
[96,     1] loss: 520.446
[97,     1] loss: 563.151
Early stopping applied (best metric=0.7759088277816772)
Finished Training
Total time taken: 15.642879009246826
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1251.673
[2,     1] loss: 1256.215
[3,     1] loss: 1243.293
[4,     1] loss: 1243.506
[5,     1] loss: 1242.900
[6,     1] loss: 1248.439
[7,     1] loss: 1244.893
[8,     1] loss: 1242.533
[9,     1] loss: 1240.845
[10,     1] loss: 1236.239
[11,     1] loss: 1229.269
[12,     1] loss: 1223.292
[13,     1] loss: 1198.858
[14,     1] loss: 1156.895
[15,     1] loss: 1147.811
[16,     1] loss: 1120.746
[17,     1] loss: 1087.304
[18,     1] loss: 1063.636
[19,     1] loss: 1028.336
[20,     1] loss: 1060.320
[21,     1] loss: 1004.986
[22,     1] loss: 1000.640
[23,     1] loss: 974.631
[24,     1] loss: 980.764
[25,     1] loss: 1002.733
[26,     1] loss: 963.189
[27,     1] loss: 968.631
[28,     1] loss: 1024.968
[29,     1] loss: 980.953
[30,     1] loss: 927.161
[31,     1] loss: 937.083
[32,     1] loss: 938.898
[33,     1] loss: 918.080
[34,     1] loss: 948.775
[35,     1] loss: 888.737
[36,     1] loss: 880.062
[37,     1] loss: 861.142
[38,     1] loss: 888.901
[39,     1] loss: 844.982
[40,     1] loss: 846.898
[41,     1] loss: 843.493
[42,     1] loss: 866.051
[43,     1] loss: 791.284
[44,     1] loss: 816.480
[45,     1] loss: 806.794
[46,     1] loss: 771.186
[47,     1] loss: 751.368
[48,     1] loss: 796.490
[49,     1] loss: 900.653
[50,     1] loss: 913.722
[51,     1] loss: 750.098
[52,     1] loss: 867.594
[53,     1] loss: 816.582
[54,     1] loss: 827.587
[55,     1] loss: 860.287
[56,     1] loss: 753.919
[57,     1] loss: 799.303
[58,     1] loss: 776.130
[59,     1] loss: 736.257
[60,     1] loss: 746.205
Early stopping applied (best metric=0.842180609703064)
Finished Training
Total time taken: 10.468390703201294
{'Hydroxylation-K Validation Accuracy': 0.7564716312056737, 'Hydroxylation-K Validation Sensitivity': 0.682962962962963, 'Hydroxylation-K Validation Specificity': 0.775438596491228, 'Hydroxylation-K Validation Precision': 0.43570985659220957, 'Hydroxylation-K AUC ROC': 0.7929044834307992, 'Hydroxylation-K AUC PR': 0.5899559044178291, 'Hydroxylation-K MCC': 0.39581126569226227, 'Hydroxylation-K F1': 0.5301113025460852, 'Validation Loss (Hydroxylation-K)': 0.44045455058415733, 'Hydroxylation-P Validation Accuracy': 0.7701686885606484, 'Hydroxylation-P Validation Sensitivity': 0.7617460317460317, 'Hydroxylation-P Validation Specificity': 0.7720883834605217, 'Hydroxylation-P Validation Precision': 0.42813489710374525, 'Hydroxylation-P AUC ROC': 0.8397507238218745, 'Hydroxylation-P AUC PR': 0.5947936494160478, 'Hydroxylation-P MCC': 0.4416618139483701, 'Hydroxylation-P F1': 0.5428800256464508, 'Validation Loss (Hydroxylation-P)': 0.384259295463562, 'Validation Loss (total)': 0.8247138341267903, 'TimeToTrain': 12.384975862503051}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005490405784009155,
 'learning_rate_Hydroxylation-K': 0.0051395130727127135,
 'learning_rate_Hydroxylation-P': 0.007161050972820857,
 'log_base': 2.722848546295447,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4062823504,
 'sample_weights': [1.5838895898793552, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.342029085842453,
 'weight_decay_Hydroxylation-K': 0.404317623055233,
 'weight_decay_Hydroxylation-P': 5.174124471296024}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1262.668
[2,     1] loss: 1259.556
[3,     1] loss: 1258.597
[4,     1] loss: 1256.865
[5,     1] loss: 1259.765
[6,     1] loss: 1255.356
[7,     1] loss: 1257.157
[8,     1] loss: 1255.931
[9,     1] loss: 1256.935
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027182959316599795,
 'learning_rate_Hydroxylation-K': 0.0003623399740025641,
 'learning_rate_Hydroxylation-P': 0.0005339562696221878,
 'log_base': 2.8545040926746803,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3800343923,
 'sample_weights': [1.6666455296016711, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.77000329724546,
 'weight_decay_Hydroxylation-K': 0.8807280187479791,
 'weight_decay_Hydroxylation-P': 2.10928719488211}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1246.911
[2,     1] loss: 1248.005
[3,     1] loss: 1241.137
[4,     1] loss: 1247.144
[5,     1] loss: 1238.470
[6,     1] loss: 1244.329
[7,     1] loss: 1232.025
[8,     1] loss: 1223.620
[9,     1] loss: 1202.861
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007095344015510282,
 'learning_rate_Hydroxylation-K': 0.002367503711759516,
 'learning_rate_Hydroxylation-P': 0.005147694138227331,
 'log_base': 1.7027610969309048,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3350967724,
 'sample_weights': [1.5916160963425336, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.129674048559979,
 'weight_decay_Hydroxylation-K': 0.7189789924075489,
 'weight_decay_Hydroxylation-P': 2.052066482003191}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1574.568
[2,     1] loss: 1593.212
[3,     1] loss: 1573.375
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00404157347364247,
 'learning_rate_Hydroxylation-K': 0.0061932479833529865,
 'learning_rate_Hydroxylation-P': 0.005477495681940394,
 'log_base': 1.7427245240547296,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 602630377,
 'sample_weights': [3.136570543038335, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.5795755256131283,
 'weight_decay_Hydroxylation-K': 1.680472716937098,
 'weight_decay_Hydroxylation-P': 8.988732582150384}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1549.384
[2,     1] loss: 1546.299
[3,     1] loss: 1538.289
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0038535886325737024,
 'learning_rate_Hydroxylation-K': 0.0029280943267432132,
 'learning_rate_Hydroxylation-P': 0.0038033305838962588,
 'log_base': 2.509949653684514,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 448829387,
 'sample_weights': [3.005570308679352, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.867949298769223,
 'weight_decay_Hydroxylation-K': 3.410079382706985,
 'weight_decay_Hydroxylation-P': 1.5599709698714204}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1288.665
[2,     1] loss: 1287.898
[3,     1] loss: 1298.978
[4,     1] loss: 1295.872
[5,     1] loss: 1284.237
[6,     1] loss: 1279.017
[7,     1] loss: 1248.013
[8,     1] loss: 1207.216
[9,     1] loss: 1177.470
[10,     1] loss: 1122.533
[11,     1] loss: 1114.881
[12,     1] loss: 1068.447
[13,     1] loss: 1202.341
[14,     1] loss: 1055.701
[15,     1] loss: 1120.181
[16,     1] loss: 1070.249
[17,     1] loss: 1071.054
[18,     1] loss: 1075.563
[19,     1] loss: 1068.180
[20,     1] loss: 1046.093
[21,     1] loss: 1058.578
[22,     1] loss: 1016.584
[23,     1] loss: 1049.904
[24,     1] loss: 1003.678
[25,     1] loss: 985.168
[26,     1] loss: 1019.705
[27,     1] loss: 994.178
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005078744654576164,
 'learning_rate_Hydroxylation-K': 0.004203153106392076,
 'learning_rate_Hydroxylation-P': 0.004127827353178291,
 'log_base': 2.489377062359803,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1207774082,
 'sample_weights': [1.814094124568977, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1104412041687983,
 'weight_decay_Hydroxylation-K': 3.938429584040602,
 'weight_decay_Hydroxylation-P': 5.092675562872067}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1296.857
[2,     1] loss: 1323.071
[3,     1] loss: 1292.442
[4,     1] loss: 1293.114
[5,     1] loss: 1297.496
[6,     1] loss: 1294.851
[7,     1] loss: 1299.439
[8,     1] loss: 1297.179
[9,     1] loss: 1293.081
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005382981287701063,
 'learning_rate_Hydroxylation-K': 0.0028609162791570974,
 'learning_rate_Hydroxylation-P': 0.00252615360924235,
 'log_base': 2.364200720898136,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3420326707,
 'sample_weights': [1.8304645296812876, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.0189473798412014,
 'weight_decay_Hydroxylation-K': 2.8887391852832276,
 'weight_decay_Hydroxylation-P': 1.0065559780609874}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1325.413
[2,     1] loss: 1326.320
[3,     1] loss: 1317.058
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005417071939477315,
 'learning_rate_Hydroxylation-K': 0.004523405257995371,
 'learning_rate_Hydroxylation-P': 0.0013054538153478728,
 'log_base': 2.8964631576593165,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1130877177,
 'sample_weights': [1.940220283930161, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.356991375419067,
 'weight_decay_Hydroxylation-K': 5.076241336736965,
 'weight_decay_Hydroxylation-P': 0.8700141286763171}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.260
[2,     1] loss: 1278.352
[3,     1] loss: 1239.905
[4,     1] loss: 1245.630
[5,     1] loss: 1238.857
[6,     1] loss: 1239.135
[7,     1] loss: 1241.300
[8,     1] loss: 1236.436
[9,     1] loss: 1237.812
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00696834083494203,
 'learning_rate_Hydroxylation-K': 0.004324947116213408,
 'learning_rate_Hydroxylation-P': 0.0026240587497301905,
 'log_base': 2.987329570885353,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3206476474,
 'sample_weights': [1.5697773672340516, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.970456261803545,
 'weight_decay_Hydroxylation-K': 6.386845646228341,
 'weight_decay_Hydroxylation-P': 3.3096832720042317}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.514
[2,     1] loss: 1249.222
[3,     1] loss: 1231.641
[4,     1] loss: 1230.508
[5,     1] loss: 1229.037
[6,     1] loss: 1227.755
[7,     1] loss: 1222.401
[8,     1] loss: 1212.168
[9,     1] loss: 1210.244
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012286725634293586,
 'learning_rate_Hydroxylation-K': 0.00194151348139151,
 'learning_rate_Hydroxylation-P': 0.004753437713263148,
 'log_base': 2.963234061454065,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3772571456,
 'sample_weights': [1.525469533834579, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.919499608362382,
 'weight_decay_Hydroxylation-K': 6.4870332579118575,
 'weight_decay_Hydroxylation-P': 8.234417206278106}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.341
[2,     1] loss: 1231.013
[3,     1] loss: 1231.523
[4,     1] loss: 1229.320
[5,     1] loss: 1232.195
[6,     1] loss: 1230.826
[7,     1] loss: 1227.269
[8,     1] loss: 1225.196
[9,     1] loss: 1219.482
[10,     1] loss: 1209.986
[11,     1] loss: 1206.141
[12,     1] loss: 1182.660
[13,     1] loss: 1165.801
[14,     1] loss: 1130.792
[15,     1] loss: 1107.408
[16,     1] loss: 1103.056
[17,     1] loss: 1064.026
[18,     1] loss: 1030.555
[19,     1] loss: 1021.167
[20,     1] loss: 1037.078
[21,     1] loss: 979.065
[22,     1] loss: 997.082
[23,     1] loss: 993.153
[24,     1] loss: 1007.254
[25,     1] loss: 985.951
[26,     1] loss: 960.437
[27,     1] loss: 1001.661
[28,     1] loss: 984.599
[29,     1] loss: 954.238
[30,     1] loss: 944.713
[31,     1] loss: 911.462
[32,     1] loss: 935.323
[33,     1] loss: 928.411
[34,     1] loss: 919.359
[35,     1] loss: 930.421
[36,     1] loss: 899.288
[37,     1] loss: 892.649
[38,     1] loss: 935.614
[39,     1] loss: 931.247
[40,     1] loss: 895.035
[41,     1] loss: 893.768
[42,     1] loss: 844.388
[43,     1] loss: 926.642
[44,     1] loss: 894.373
[45,     1] loss: 852.317
[46,     1] loss: 843.474
[47,     1] loss: 885.150
[48,     1] loss: 834.780
[49,     1] loss: 863.143
[50,     1] loss: 833.999
[51,     1] loss: 813.947
[52,     1] loss: 791.055
[53,     1] loss: 806.650
[54,     1] loss: 785.283
[55,     1] loss: 828.053
[56,     1] loss: 779.271
[57,     1] loss: 832.859
[58,     1] loss: 790.311
[59,     1] loss: 725.934
[60,     1] loss: 756.021
Early stopping applied (best metric=0.8081889152526855)
Finished Training
Total time taken: 11.016325950622559
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1231.664
[2,     1] loss: 1237.750
[3,     1] loss: 1230.978
[4,     1] loss: 1231.864
[5,     1] loss: 1233.179
[6,     1] loss: 1230.601
[7,     1] loss: 1233.384
[8,     1] loss: 1232.939
[9,     1] loss: 1226.819
[10,     1] loss: 1228.340
[11,     1] loss: 1224.604
[12,     1] loss: 1220.164
[13,     1] loss: 1214.628
[14,     1] loss: 1205.486
[15,     1] loss: 1191.066
[16,     1] loss: 1180.635
[17,     1] loss: 1155.089
[18,     1] loss: 1118.626
[19,     1] loss: 1097.396
[20,     1] loss: 1072.895
[21,     1] loss: 1059.079
[22,     1] loss: 1038.682
[23,     1] loss: 1015.347
[24,     1] loss: 1011.861
[25,     1] loss: 974.742
[26,     1] loss: 1004.280
[27,     1] loss: 1034.669
[28,     1] loss: 1020.483
[29,     1] loss: 970.759
[30,     1] loss: 975.313
[31,     1] loss: 935.346
[32,     1] loss: 938.019
[33,     1] loss: 936.905
[34,     1] loss: 937.715
[35,     1] loss: 953.919
[36,     1] loss: 919.455
[37,     1] loss: 943.132
[38,     1] loss: 892.245
[39,     1] loss: 921.571
[40,     1] loss: 915.035
[41,     1] loss: 948.366
[42,     1] loss: 861.637
[43,     1] loss: 893.331
[44,     1] loss: 907.236
[45,     1] loss: 813.971
[46,     1] loss: 898.273
[47,     1] loss: 939.228
[48,     1] loss: 832.852
[49,     1] loss: 828.380
[50,     1] loss: 877.851
Early stopping applied (best metric=0.9919443130493164)
Finished Training
Total time taken: 8.022291421890259
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.766
[2,     1] loss: 1237.000
[3,     1] loss: 1237.792
[4,     1] loss: 1233.644
[5,     1] loss: 1231.810
[6,     1] loss: 1229.124
[7,     1] loss: 1226.653
[8,     1] loss: 1220.397
[9,     1] loss: 1218.798
[10,     1] loss: 1205.148
[11,     1] loss: 1194.705
[12,     1] loss: 1174.789
[13,     1] loss: 1152.467
[14,     1] loss: 1102.717
[15,     1] loss: 1091.295
[16,     1] loss: 1050.833
[17,     1] loss: 1077.861
[18,     1] loss: 1034.298
[19,     1] loss: 1051.281
[20,     1] loss: 1046.236
[21,     1] loss: 1075.493
[22,     1] loss: 983.679
[23,     1] loss: 1005.432
[24,     1] loss: 984.151
[25,     1] loss: 1037.270
[26,     1] loss: 970.065
[27,     1] loss: 998.570
[28,     1] loss: 1006.691
[29,     1] loss: 986.956
[30,     1] loss: 973.691
[31,     1] loss: 976.198
[32,     1] loss: 973.691
[33,     1] loss: 984.168
[34,     1] loss: 963.661
[35,     1] loss: 939.997
[36,     1] loss: 913.830
[37,     1] loss: 939.824
[38,     1] loss: 918.763
[39,     1] loss: 883.268
[40,     1] loss: 893.594
[41,     1] loss: 933.764
[42,     1] loss: 918.694
[43,     1] loss: 878.164
[44,     1] loss: 893.536
[45,     1] loss: 895.596
[46,     1] loss: 874.339
[47,     1] loss: 895.164
[48,     1] loss: 829.492
[49,     1] loss: 866.200
[50,     1] loss: 869.490
[51,     1] loss: 840.311
[52,     1] loss: 855.002
[53,     1] loss: 816.171
[54,     1] loss: 810.880
[55,     1] loss: 814.148
[56,     1] loss: 858.527
[57,     1] loss: 881.092
[58,     1] loss: 807.229
[59,     1] loss: 776.041
[60,     1] loss: 801.139
[61,     1] loss: 788.471
[62,     1] loss: 774.614
[63,     1] loss: 726.815
[64,     1] loss: 742.279
[65,     1] loss: 759.916
[66,     1] loss: 764.698
[67,     1] loss: 767.807
[68,     1] loss: 736.024
[69,     1] loss: 691.848
[70,     1] loss: 737.889
[71,     1] loss: 721.072
[72,     1] loss: 719.686
[73,     1] loss: 728.514
Early stopping applied (best metric=0.8758037090301514)
Finished Training
Total time taken: 13.322395324707031
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.346
[2,     1] loss: 1227.998
[3,     1] loss: 1231.570
[4,     1] loss: 1230.559
[5,     1] loss: 1229.127
[6,     1] loss: 1230.454
[7,     1] loss: 1225.697
[8,     1] loss: 1221.669
[9,     1] loss: 1215.583
[10,     1] loss: 1206.975
[11,     1] loss: 1192.655
[12,     1] loss: 1158.704
[13,     1] loss: 1155.838
[14,     1] loss: 1113.800
[15,     1] loss: 1108.520
[16,     1] loss: 1071.286
[17,     1] loss: 1052.217
[18,     1] loss: 1040.256
[19,     1] loss: 1036.440
[20,     1] loss: 1026.082
[21,     1] loss: 1029.718
[22,     1] loss: 1016.215
[23,     1] loss: 1040.543
[24,     1] loss: 1008.244
[25,     1] loss: 1029.286
[26,     1] loss: 1013.643
[27,     1] loss: 965.435
[28,     1] loss: 1007.147
[29,     1] loss: 1001.160
[30,     1] loss: 971.585
[31,     1] loss: 966.865
[32,     1] loss: 944.122
[33,     1] loss: 958.585
[34,     1] loss: 960.563
[35,     1] loss: 975.732
[36,     1] loss: 908.987
[37,     1] loss: 930.893
[38,     1] loss: 917.816
[39,     1] loss: 884.179
[40,     1] loss: 882.584
[41,     1] loss: 878.697
[42,     1] loss: 858.422
[43,     1] loss: 879.031
[44,     1] loss: 887.694
[45,     1] loss: 879.361
[46,     1] loss: 821.774
[47,     1] loss: 872.601
[48,     1] loss: 826.161
[49,     1] loss: 816.608
[50,     1] loss: 818.059
[51,     1] loss: 812.332
[52,     1] loss: 834.533
[53,     1] loss: 803.562
[54,     1] loss: 809.705
[55,     1] loss: 798.454
Early stopping applied (best metric=0.8549273014068604)
Finished Training
Total time taken: 9.851978063583374
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1228.134
[2,     1] loss: 1236.053
[3,     1] loss: 1235.773
[4,     1] loss: 1239.713
[5,     1] loss: 1231.386
[6,     1] loss: 1231.414
[7,     1] loss: 1229.832
[8,     1] loss: 1229.016
[9,     1] loss: 1225.358
[10,     1] loss: 1216.012
[11,     1] loss: 1204.364
[12,     1] loss: 1193.616
[13,     1] loss: 1175.356
[14,     1] loss: 1144.944
[15,     1] loss: 1121.239
[16,     1] loss: 1086.257
[17,     1] loss: 1073.317
[18,     1] loss: 1071.364
[19,     1] loss: 1075.454
[20,     1] loss: 1070.426
[21,     1] loss: 1071.215
[22,     1] loss: 1051.249
[23,     1] loss: 1087.483
[24,     1] loss: 1088.456
[25,     1] loss: 1038.286
[26,     1] loss: 997.273
[27,     1] loss: 1034.166
[28,     1] loss: 999.928
[29,     1] loss: 1021.996
[30,     1] loss: 1008.909
[31,     1] loss: 1021.888
[32,     1] loss: 1005.402
[33,     1] loss: 1018.533
[34,     1] loss: 991.431
[35,     1] loss: 975.535
[36,     1] loss: 964.150
[37,     1] loss: 1003.922
[38,     1] loss: 955.462
[39,     1] loss: 1018.655
[40,     1] loss: 977.305
[41,     1] loss: 980.709
[42,     1] loss: 985.000
[43,     1] loss: 978.456
[44,     1] loss: 961.263
[45,     1] loss: 960.467
[46,     1] loss: 949.526
[47,     1] loss: 942.392
[48,     1] loss: 909.637
[49,     1] loss: 915.378
[50,     1] loss: 950.835
[51,     1] loss: 953.133
[52,     1] loss: 923.956
[53,     1] loss: 918.951
[54,     1] loss: 922.888
[55,     1] loss: 901.984
[56,     1] loss: 923.505
[57,     1] loss: 889.684
[58,     1] loss: 863.167
[59,     1] loss: 879.453
[60,     1] loss: 913.420
[61,     1] loss: 881.842
[62,     1] loss: 865.151
[63,     1] loss: 837.866
[64,     1] loss: 884.668
[65,     1] loss: 834.277
[66,     1] loss: 865.647
[67,     1] loss: 838.152
[68,     1] loss: 811.770
[69,     1] loss: 805.282
[70,     1] loss: 841.298
[71,     1] loss: 803.006
[72,     1] loss: 768.919
[73,     1] loss: 786.969
[74,     1] loss: 786.780
[75,     1] loss: 790.760
[76,     1] loss: 760.722
[77,     1] loss: 764.730
[78,     1] loss: 772.635
[79,     1] loss: 799.884
[80,     1] loss: 777.986
[81,     1] loss: 745.863
Early stopping applied (best metric=0.6754770874977112)
Finished Training
Total time taken: 14.419999837875366
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.826
[2,     1] loss: 1231.197
[3,     1] loss: 1232.150
[4,     1] loss: 1235.526
[5,     1] loss: 1228.761
[6,     1] loss: 1228.153
[7,     1] loss: 1230.584
[8,     1] loss: 1235.707
[9,     1] loss: 1224.913
[10,     1] loss: 1219.533
[11,     1] loss: 1217.352
[12,     1] loss: 1207.188
[13,     1] loss: 1197.000
[14,     1] loss: 1177.276
[15,     1] loss: 1151.173
[16,     1] loss: 1131.628
[17,     1] loss: 1095.460
[18,     1] loss: 1087.281
[19,     1] loss: 1074.138
[20,     1] loss: 1065.313
[21,     1] loss: 1046.148
[22,     1] loss: 1012.322
[23,     1] loss: 1013.821
[24,     1] loss: 987.019
[25,     1] loss: 1011.846
[26,     1] loss: 1012.241
[27,     1] loss: 993.569
[28,     1] loss: 949.622
[29,     1] loss: 1002.108
[30,     1] loss: 983.121
[31,     1] loss: 993.298
[32,     1] loss: 995.031
[33,     1] loss: 990.703
[34,     1] loss: 962.478
[35,     1] loss: 997.323
[36,     1] loss: 930.950
[37,     1] loss: 942.112
[38,     1] loss: 961.950
[39,     1] loss: 976.129
[40,     1] loss: 913.676
[41,     1] loss: 920.719
[42,     1] loss: 913.401
[43,     1] loss: 914.300
[44,     1] loss: 917.280
[45,     1] loss: 871.319
[46,     1] loss: 868.374
[47,     1] loss: 915.963
[48,     1] loss: 920.598
[49,     1] loss: 864.674
[50,     1] loss: 844.148
[51,     1] loss: 897.432
[52,     1] loss: 881.374
[53,     1] loss: 823.265
[54,     1] loss: 841.533
[55,     1] loss: 853.662
[56,     1] loss: 864.887
[57,     1] loss: 841.596
[58,     1] loss: 781.015
[59,     1] loss: 851.181
[60,     1] loss: 795.165
[61,     1] loss: 781.453
[62,     1] loss: 813.138
[63,     1] loss: 782.512
[64,     1] loss: 727.242
[65,     1] loss: 718.778
Early stopping applied (best metric=0.8707758188247681)
Finished Training
Total time taken: 11.539309024810791
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.713
[2,     1] loss: 1232.031
[3,     1] loss: 1237.795
[4,     1] loss: 1232.871
[5,     1] loss: 1229.553
[6,     1] loss: 1225.797
[7,     1] loss: 1227.365
[8,     1] loss: 1216.629
[9,     1] loss: 1205.896
[10,     1] loss: 1192.870
[11,     1] loss: 1176.594
[12,     1] loss: 1159.297
[13,     1] loss: 1132.837
[14,     1] loss: 1102.184
[15,     1] loss: 1071.753
[16,     1] loss: 1060.357
[17,     1] loss: 1051.250
[18,     1] loss: 1006.059
[19,     1] loss: 1073.585
[20,     1] loss: 1057.205
[21,     1] loss: 1023.242
[22,     1] loss: 975.383
[23,     1] loss: 1012.543
[24,     1] loss: 1028.916
[25,     1] loss: 1000.885
[26,     1] loss: 984.943
[27,     1] loss: 1004.629
[28,     1] loss: 949.644
[29,     1] loss: 994.088
[30,     1] loss: 933.594
[31,     1] loss: 953.933
[32,     1] loss: 955.145
[33,     1] loss: 948.529
[34,     1] loss: 920.703
[35,     1] loss: 983.437
[36,     1] loss: 965.594
[37,     1] loss: 984.812
[38,     1] loss: 937.719
[39,     1] loss: 916.059
[40,     1] loss: 913.781
[41,     1] loss: 887.746
[42,     1] loss: 926.257
[43,     1] loss: 868.017
[44,     1] loss: 912.495
[45,     1] loss: 859.218
[46,     1] loss: 905.321
[47,     1] loss: 881.260
[48,     1] loss: 845.043
[49,     1] loss: 839.572
[50,     1] loss: 850.443
[51,     1] loss: 888.432
[52,     1] loss: 844.285
[53,     1] loss: 861.895
[54,     1] loss: 798.082
[55,     1] loss: 872.513
[56,     1] loss: 827.617
[57,     1] loss: 855.539
[58,     1] loss: 830.576
[59,     1] loss: 811.302
[60,     1] loss: 818.066
[61,     1] loss: 796.131
[62,     1] loss: 810.429
[63,     1] loss: 796.834
[64,     1] loss: 775.397
[65,     1] loss: 794.506
Early stopping applied (best metric=0.8454370498657227)
Finished Training
Total time taken: 9.803807020187378
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1238.901
[2,     1] loss: 1231.972
[3,     1] loss: 1234.773
[4,     1] loss: 1231.744
[5,     1] loss: 1230.092
[6,     1] loss: 1230.521
[7,     1] loss: 1229.051
[8,     1] loss: 1230.672
[9,     1] loss: 1230.719
[10,     1] loss: 1225.458
[11,     1] loss: 1224.380
[12,     1] loss: 1222.410
[13,     1] loss: 1215.976
[14,     1] loss: 1209.430
[15,     1] loss: 1205.855
[16,     1] loss: 1182.691
[17,     1] loss: 1174.375
[18,     1] loss: 1153.536
[19,     1] loss: 1138.759
[20,     1] loss: 1123.837
[21,     1] loss: 1087.553
[22,     1] loss: 1080.701
[23,     1] loss: 1056.531
[24,     1] loss: 1033.000
[25,     1] loss: 1044.114
[26,     1] loss: 1069.908
[27,     1] loss: 1006.411
[28,     1] loss: 1029.059
[29,     1] loss: 1018.914
[30,     1] loss: 962.933
[31,     1] loss: 1027.297
[32,     1] loss: 1016.458
[33,     1] loss: 981.196
[34,     1] loss: 984.586
[35,     1] loss: 1016.252
[36,     1] loss: 993.001
[37,     1] loss: 1004.782
[38,     1] loss: 977.391
[39,     1] loss: 989.969
[40,     1] loss: 965.724
[41,     1] loss: 966.072
[42,     1] loss: 949.425
[43,     1] loss: 913.956
[44,     1] loss: 900.655
[45,     1] loss: 908.986
[46,     1] loss: 898.281
[47,     1] loss: 919.849
[48,     1] loss: 888.458
[49,     1] loss: 901.622
[50,     1] loss: 834.999
[51,     1] loss: 875.483
[52,     1] loss: 906.618
[53,     1] loss: 852.516
[54,     1] loss: 826.280
[55,     1] loss: 832.740
[56,     1] loss: 881.510
[57,     1] loss: 795.227
[58,     1] loss: 820.591
[59,     1] loss: 778.680
Early stopping applied (best metric=0.847892701625824)
Finished Training
Total time taken: 10.07135558128357
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1230.782
[2,     1] loss: 1236.694
[3,     1] loss: 1232.785
[4,     1] loss: 1230.653
[5,     1] loss: 1229.874
[6,     1] loss: 1225.222
[7,     1] loss: 1228.444
[8,     1] loss: 1222.249
[9,     1] loss: 1216.361
[10,     1] loss: 1200.727
[11,     1] loss: 1182.884
[12,     1] loss: 1155.641
[13,     1] loss: 1129.428
[14,     1] loss: 1079.694
[15,     1] loss: 1055.664
[16,     1] loss: 1058.998
[17,     1] loss: 989.196
[18,     1] loss: 1028.989
[19,     1] loss: 996.865
[20,     1] loss: 1015.166
[21,     1] loss: 996.135
[22,     1] loss: 990.836
[23,     1] loss: 990.032
[24,     1] loss: 972.635
[25,     1] loss: 938.943
[26,     1] loss: 934.372
[27,     1] loss: 990.552
[28,     1] loss: 941.174
[29,     1] loss: 911.326
[30,     1] loss: 954.279
[31,     1] loss: 901.198
[32,     1] loss: 911.812
[33,     1] loss: 953.220
[34,     1] loss: 951.146
[35,     1] loss: 888.820
[36,     1] loss: 932.054
[37,     1] loss: 909.225
[38,     1] loss: 881.436
[39,     1] loss: 884.414
[40,     1] loss: 910.560
[41,     1] loss: 861.454
[42,     1] loss: 827.053
[43,     1] loss: 826.135
[44,     1] loss: 880.093
[45,     1] loss: 830.034
[46,     1] loss: 848.642
[47,     1] loss: 814.083
[48,     1] loss: 835.832
[49,     1] loss: 839.254
[50,     1] loss: 826.592
[51,     1] loss: 820.320
[52,     1] loss: 818.189
[53,     1] loss: 842.354
[54,     1] loss: 820.503
[55,     1] loss: 799.810
[56,     1] loss: 845.195
[57,     1] loss: 779.176
[58,     1] loss: 799.025
[59,     1] loss: 841.874
[60,     1] loss: 749.687
Early stopping applied (best metric=0.9260948896408081)
Finished Training
Total time taken: 8.61420726776123
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1235.635
[2,     1] loss: 1235.144
[3,     1] loss: 1231.564
[4,     1] loss: 1235.051
[5,     1] loss: 1231.833
[6,     1] loss: 1235.235
[7,     1] loss: 1232.736
[8,     1] loss: 1228.208
[9,     1] loss: 1222.480
[10,     1] loss: 1213.484
[11,     1] loss: 1205.816
[12,     1] loss: 1186.920
[13,     1] loss: 1163.851
[14,     1] loss: 1138.808
[15,     1] loss: 1127.534
[16,     1] loss: 1099.072
[17,     1] loss: 1075.790
[18,     1] loss: 1079.396
[19,     1] loss: 1028.244
[20,     1] loss: 1028.308
[21,     1] loss: 1023.401
[22,     1] loss: 1023.287
[23,     1] loss: 1041.620
[24,     1] loss: 994.966
[25,     1] loss: 986.319
[26,     1] loss: 1034.104
[27,     1] loss: 1057.572
[28,     1] loss: 984.138
[29,     1] loss: 951.336
[30,     1] loss: 990.737
[31,     1] loss: 981.645
[32,     1] loss: 958.364
[33,     1] loss: 950.810
[34,     1] loss: 943.569
[35,     1] loss: 915.240
[36,     1] loss: 931.523
[37,     1] loss: 926.098
[38,     1] loss: 941.057
[39,     1] loss: 920.003
[40,     1] loss: 902.360
[41,     1] loss: 899.485
Early stopping applied (best metric=0.9533742666244507)
Finished Training
Total time taken: 5.69326114654541
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.147
[2,     1] loss: 1235.372
[3,     1] loss: 1228.904
[4,     1] loss: 1230.088
[5,     1] loss: 1232.099
[6,     1] loss: 1229.767
[7,     1] loss: 1227.630
[8,     1] loss: 1219.754
[9,     1] loss: 1218.192
[10,     1] loss: 1205.760
[11,     1] loss: 1191.202
[12,     1] loss: 1175.982
[13,     1] loss: 1158.694
[14,     1] loss: 1125.838
[15,     1] loss: 1091.289
[16,     1] loss: 1118.426
[17,     1] loss: 1067.359
[18,     1] loss: 1083.874
[19,     1] loss: 1057.892
[20,     1] loss: 1074.215
[21,     1] loss: 1069.626
[22,     1] loss: 1014.799
[23,     1] loss: 1092.413
[24,     1] loss: 1036.836
[25,     1] loss: 1025.948
[26,     1] loss: 1012.118
[27,     1] loss: 1019.650
[28,     1] loss: 1034.373
[29,     1] loss: 1010.359
[30,     1] loss: 1013.322
[31,     1] loss: 1029.647
[32,     1] loss: 964.125
[33,     1] loss: 972.340
[34,     1] loss: 994.708
[35,     1] loss: 1015.353
[36,     1] loss: 994.271
[37,     1] loss: 970.299
[38,     1] loss: 930.868
[39,     1] loss: 979.614
[40,     1] loss: 947.477
[41,     1] loss: 937.257
[42,     1] loss: 989.961
[43,     1] loss: 913.027
[44,     1] loss: 929.334
[45,     1] loss: 970.063
[46,     1] loss: 945.127
[47,     1] loss: 908.921
[48,     1] loss: 909.192
[49,     1] loss: 889.580
[50,     1] loss: 897.214
[51,     1] loss: 913.082
[52,     1] loss: 859.506
[53,     1] loss: 871.700
[54,     1] loss: 833.055
[55,     1] loss: 859.209
[56,     1] loss: 837.149
[57,     1] loss: 843.430
[58,     1] loss: 801.311
[59,     1] loss: 835.834
[60,     1] loss: 826.107
[61,     1] loss: 813.406
[62,     1] loss: 812.833
[63,     1] loss: 783.904
[64,     1] loss: 781.850
[65,     1] loss: 800.054
[66,     1] loss: 732.966
[67,     1] loss: 763.652
[68,     1] loss: 753.728
[69,     1] loss: 745.461
Early stopping applied (best metric=0.7519195079803467)
Finished Training
Total time taken: 11.448273658752441
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.154
[2,     1] loss: 1230.317
[3,     1] loss: 1237.723
[4,     1] loss: 1230.935
[5,     1] loss: 1228.540
[6,     1] loss: 1228.679
[7,     1] loss: 1222.885
[8,     1] loss: 1208.406
[9,     1] loss: 1202.793
[10,     1] loss: 1181.450
[11,     1] loss: 1163.449
[12,     1] loss: 1148.232
[13,     1] loss: 1123.157
[14,     1] loss: 1095.431
[15,     1] loss: 1081.525
[16,     1] loss: 1065.242
[17,     1] loss: 1041.367
[18,     1] loss: 1029.219
[19,     1] loss: 1034.689
[20,     1] loss: 1064.162
[21,     1] loss: 1060.848
[22,     1] loss: 1019.695
[23,     1] loss: 1041.892
[24,     1] loss: 996.763
[25,     1] loss: 1016.544
[26,     1] loss: 1026.586
[27,     1] loss: 993.927
[28,     1] loss: 1003.571
[29,     1] loss: 988.089
[30,     1] loss: 1005.932
[31,     1] loss: 955.812
[32,     1] loss: 965.949
[33,     1] loss: 995.461
[34,     1] loss: 1008.807
[35,     1] loss: 925.999
[36,     1] loss: 913.179
[37,     1] loss: 919.898
[38,     1] loss: 959.891
[39,     1] loss: 895.471
[40,     1] loss: 924.736
[41,     1] loss: 922.967
[42,     1] loss: 884.075
[43,     1] loss: 900.505
[44,     1] loss: 857.574
[45,     1] loss: 880.925
[46,     1] loss: 870.910
[47,     1] loss: 872.092
[48,     1] loss: 892.323
[49,     1] loss: 840.918
[50,     1] loss: 849.901
[51,     1] loss: 819.175
[52,     1] loss: 826.927
[53,     1] loss: 824.496
[54,     1] loss: 829.863
[55,     1] loss: 821.934
[56,     1] loss: 820.465
[57,     1] loss: 820.797
[58,     1] loss: 786.713
[59,     1] loss: 814.198
[60,     1] loss: 811.107
[61,     1] loss: 806.960
[62,     1] loss: 773.829
[63,     1] loss: 786.407
[64,     1] loss: 748.598
[65,     1] loss: 844.740
[66,     1] loss: 811.599
[67,     1] loss: 779.370
[68,     1] loss: 761.503
[69,     1] loss: 749.290
[70,     1] loss: 746.325
[71,     1] loss: 793.706
[72,     1] loss: 705.111
[73,     1] loss: 695.980
[74,     1] loss: 702.812
[75,     1] loss: 690.139
[76,     1] loss: 693.860
[77,     1] loss: 693.325
[78,     1] loss: 736.495
[79,     1] loss: 697.057
[80,     1] loss: 691.137
[81,     1] loss: 702.595
[82,     1] loss: 703.053
[83,     1] loss: 684.202
[84,     1] loss: 689.182
[85,     1] loss: 666.019
[86,     1] loss: 629.240
[87,     1] loss: 629.519
[88,     1] loss: 613.661
[89,     1] loss: 621.889
[90,     1] loss: 568.952
[91,     1] loss: 613.077
[92,     1] loss: 621.179
[93,     1] loss: 636.763
[94,     1] loss: 548.507
[95,     1] loss: 602.310
[96,     1] loss: 618.200
[97,     1] loss: 599.328
[98,     1] loss: 586.823
[99,     1] loss: 547.809
[100,     1] loss: 568.163
[101,     1] loss: 588.998
[102,     1] loss: 528.526
[103,     1] loss: 551.468
Early stopping applied (best metric=0.7100722789764404)
Finished Training
Total time taken: 16.612956285476685
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1235.507
[2,     1] loss: 1234.158
[3,     1] loss: 1231.971
[4,     1] loss: 1230.908
[5,     1] loss: 1230.285
[6,     1] loss: 1231.616
[7,     1] loss: 1226.368
[8,     1] loss: 1227.449
[9,     1] loss: 1227.739
[10,     1] loss: 1221.924
[11,     1] loss: 1218.061
[12,     1] loss: 1207.630
[13,     1] loss: 1190.230
[14,     1] loss: 1168.157
[15,     1] loss: 1146.109
[16,     1] loss: 1129.289
[17,     1] loss: 1087.479
[18,     1] loss: 1071.252
[19,     1] loss: 1030.932
[20,     1] loss: 1045.912
[21,     1] loss: 1004.201
[22,     1] loss: 1026.773
[23,     1] loss: 1012.061
[24,     1] loss: 1000.286
[25,     1] loss: 1014.799
[26,     1] loss: 988.519
[27,     1] loss: 972.597
[28,     1] loss: 999.786
[29,     1] loss: 968.992
[30,     1] loss: 986.282
[31,     1] loss: 971.291
[32,     1] loss: 974.068
[33,     1] loss: 948.941
[34,     1] loss: 975.396
[35,     1] loss: 958.972
[36,     1] loss: 948.599
[37,     1] loss: 898.459
[38,     1] loss: 959.846
[39,     1] loss: 964.515
[40,     1] loss: 953.782
[41,     1] loss: 994.506
[42,     1] loss: 925.271
[43,     1] loss: 886.200
[44,     1] loss: 923.162
[45,     1] loss: 892.329
[46,     1] loss: 927.682
[47,     1] loss: 869.818
[48,     1] loss: 891.645
[49,     1] loss: 852.691
[50,     1] loss: 934.466
[51,     1] loss: 865.452
[52,     1] loss: 843.953
[53,     1] loss: 834.967
[54,     1] loss: 801.869
[55,     1] loss: 847.850
[56,     1] loss: 822.485
[57,     1] loss: 849.676
[58,     1] loss: 788.451
[59,     1] loss: 777.727
[60,     1] loss: 838.224
[61,     1] loss: 884.717
[62,     1] loss: 831.733
[63,     1] loss: 843.514
[64,     1] loss: 814.080
[65,     1] loss: 808.191
[66,     1] loss: 788.150
[67,     1] loss: 764.957
[68,     1] loss: 796.493
[69,     1] loss: 803.359
[70,     1] loss: 782.712
[71,     1] loss: 756.185
[72,     1] loss: 697.138
[73,     1] loss: 717.685
[74,     1] loss: 701.484
[75,     1] loss: 686.636
[76,     1] loss: 715.430
[77,     1] loss: 719.126
[78,     1] loss: 672.250
[79,     1] loss: 695.181
[80,     1] loss: 728.379
[81,     1] loss: 722.741
[82,     1] loss: 699.968
[83,     1] loss: 727.249
[84,     1] loss: 660.294
Early stopping applied (best metric=0.8374444246292114)
Finished Training
Total time taken: 14.607452154159546
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1238.139
[2,     1] loss: 1230.565
[3,     1] loss: 1232.971
[4,     1] loss: 1238.146
[5,     1] loss: 1235.935
[6,     1] loss: 1232.421
[7,     1] loss: 1228.856
[8,     1] loss: 1229.298
[9,     1] loss: 1231.076
[10,     1] loss: 1226.758
[11,     1] loss: 1222.795
[12,     1] loss: 1215.410
[13,     1] loss: 1205.938
[14,     1] loss: 1191.794
[15,     1] loss: 1182.165
[16,     1] loss: 1151.910
[17,     1] loss: 1131.966
[18,     1] loss: 1106.550
[19,     1] loss: 1071.913
[20,     1] loss: 1083.011
[21,     1] loss: 1038.079
[22,     1] loss: 1042.399
[23,     1] loss: 1021.884
[24,     1] loss: 1038.443
[25,     1] loss: 1002.936
[26,     1] loss: 1004.508
[27,     1] loss: 1012.041
[28,     1] loss: 1004.189
[29,     1] loss: 992.452
[30,     1] loss: 998.978
[31,     1] loss: 942.319
[32,     1] loss: 1019.266
[33,     1] loss: 994.493
[34,     1] loss: 1001.957
[35,     1] loss: 949.531
[36,     1] loss: 944.085
[37,     1] loss: 938.466
[38,     1] loss: 968.280
[39,     1] loss: 935.375
[40,     1] loss: 999.273
[41,     1] loss: 933.074
[42,     1] loss: 936.621
[43,     1] loss: 914.630
[44,     1] loss: 965.850
[45,     1] loss: 930.848
[46,     1] loss: 890.495
[47,     1] loss: 889.106
[48,     1] loss: 901.983
[49,     1] loss: 924.933
[50,     1] loss: 903.418
[51,     1] loss: 899.982
[52,     1] loss: 915.802
[53,     1] loss: 887.660
[54,     1] loss: 853.998
[55,     1] loss: 919.662
[56,     1] loss: 838.419
[57,     1] loss: 840.113
[58,     1] loss: 836.836
[59,     1] loss: 831.283
[60,     1] loss: 845.787
[61,     1] loss: 791.600
[62,     1] loss: 877.095
[63,     1] loss: 856.471
[64,     1] loss: 851.420
[65,     1] loss: 833.503
[66,     1] loss: 823.804
[67,     1] loss: 816.290
[68,     1] loss: 862.998
[69,     1] loss: 795.178
[70,     1] loss: 829.003
[71,     1] loss: 794.234
[72,     1] loss: 789.933
[73,     1] loss: 804.030
[74,     1] loss: 724.782
[75,     1] loss: 825.172
[76,     1] loss: 748.644
[77,     1] loss: 697.753
[78,     1] loss: 796.839
[79,     1] loss: 728.254
[80,     1] loss: 766.109
[81,     1] loss: 762.474
[82,     1] loss: 754.221
[83,     1] loss: 713.964
[84,     1] loss: 690.065
[85,     1] loss: 691.054
[86,     1] loss: 687.931
[87,     1] loss: 718.110
[88,     1] loss: 661.997
[89,     1] loss: 650.289
[90,     1] loss: 658.280
[91,     1] loss: 628.729
[92,     1] loss: 696.113
[93,     1] loss: 630.093
[94,     1] loss: 679.829
[95,     1] loss: 640.491
[96,     1] loss: 606.385
[97,     1] loss: 617.935
[98,     1] loss: 617.968
[99,     1] loss: 621.646
[100,     1] loss: 594.023
[101,     1] loss: 659.365
[102,     1] loss: 558.648
[103,     1] loss: 585.108
[104,     1] loss: 532.659
[105,     1] loss: 558.792
[106,     1] loss: 556.633
[107,     1] loss: 588.991
Early stopping applied (best metric=0.6406054496765137)
Finished Training
Total time taken: 17.18293046951294
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1240.973
[2,     1] loss: 1238.308
[3,     1] loss: 1231.745
[4,     1] loss: 1232.947
[5,     1] loss: 1233.820
[6,     1] loss: 1228.831
[7,     1] loss: 1228.208
[8,     1] loss: 1227.186
[9,     1] loss: 1219.981
[10,     1] loss: 1216.515
[11,     1] loss: 1205.391
[12,     1] loss: 1186.278
[13,     1] loss: 1172.229
[14,     1] loss: 1138.500
[15,     1] loss: 1120.344
[16,     1] loss: 1128.868
[17,     1] loss: 1103.091
[18,     1] loss: 1077.792
[19,     1] loss: 1053.907
[20,     1] loss: 1037.414
[21,     1] loss: 1008.885
[22,     1] loss: 1049.209
[23,     1] loss: 1015.233
[24,     1] loss: 1052.517
[25,     1] loss: 1027.872
[26,     1] loss: 995.669
[27,     1] loss: 1006.299
[28,     1] loss: 1038.443
[29,     1] loss: 986.051
[30,     1] loss: 1017.529
[31,     1] loss: 980.923
[32,     1] loss: 1006.540
[33,     1] loss: 977.212
[34,     1] loss: 963.206
[35,     1] loss: 951.358
[36,     1] loss: 975.129
[37,     1] loss: 932.473
[38,     1] loss: 976.997
[39,     1] loss: 944.004
[40,     1] loss: 941.216
[41,     1] loss: 955.901
[42,     1] loss: 957.046
[43,     1] loss: 923.255
[44,     1] loss: 904.684
[45,     1] loss: 913.225
[46,     1] loss: 961.077
[47,     1] loss: 900.983
[48,     1] loss: 917.618
[49,     1] loss: 949.018
[50,     1] loss: 908.162
[51,     1] loss: 938.893
[52,     1] loss: 939.383
[53,     1] loss: 943.159
[54,     1] loss: 895.089
[55,     1] loss: 856.829
[56,     1] loss: 856.833
[57,     1] loss: 882.758
[58,     1] loss: 833.974
[59,     1] loss: 854.309
[60,     1] loss: 841.106
[61,     1] loss: 870.007
[62,     1] loss: 828.021
[63,     1] loss: 855.593
[64,     1] loss: 788.555
[65,     1] loss: 787.085
[66,     1] loss: 791.427
[67,     1] loss: 833.242
[68,     1] loss: 808.347
[69,     1] loss: 804.155
[70,     1] loss: 826.958
[71,     1] loss: 813.614
[72,     1] loss: 793.383
[73,     1] loss: 767.363
[74,     1] loss: 742.881
[75,     1] loss: 762.529
[76,     1] loss: 754.636
[77,     1] loss: 766.277
[78,     1] loss: 776.000
[79,     1] loss: 728.996
[80,     1] loss: 707.204
[81,     1] loss: 763.180
[82,     1] loss: 739.996
[83,     1] loss: 667.827
[84,     1] loss: 673.334
[85,     1] loss: 708.682
[86,     1] loss: 762.282
[87,     1] loss: 732.960
[88,     1] loss: 689.749
[89,     1] loss: 674.113
[90,     1] loss: 679.491
[91,     1] loss: 669.025
[92,     1] loss: 674.212
[93,     1] loss: 679.472
[94,     1] loss: 673.011
[95,     1] loss: 623.967
[96,     1] loss: 660.549
[97,     1] loss: 653.960
[98,     1] loss: 654.883
[99,     1] loss: 614.614
[100,     1] loss: 643.036
[101,     1] loss: 646.311
Early stopping applied (best metric=0.699639081954956)
Finished Training
Total time taken: 15.243447542190552
{'Hydroxylation-K Validation Accuracy': 0.7645390070921986, 'Hydroxylation-K Validation Sensitivity': 0.6733333333333333, 'Hydroxylation-K Validation Specificity': 0.787719298245614, 'Hydroxylation-K Validation Precision': 0.44296602434373333, 'Hydroxylation-K AUC ROC': 0.7928654970760234, 'Hydroxylation-K AUC PR': 0.5719081490682228, 'Hydroxylation-K MCC': 0.40139378683967025, 'Hydroxylation-K F1': 0.531214638287102, 'Validation Loss (Hydroxylation-K)': 0.4381253699461619, 'Hydroxylation-P Validation Accuracy': 0.7709010710116238, 'Hydroxylation-P Validation Sensitivity': 0.7785185185185185, 'Hydroxylation-P Validation Specificity': 0.7692977205845678, 'Hydroxylation-P Validation Precision': 0.4285689656138738, 'Hydroxylation-P AUC ROC': 0.8403260127766338, 'Hydroxylation-P AUC PR': 0.5621781801480814, 'Hydroxylation-P MCC': 0.45001577186974734, 'Hydroxylation-P F1': 0.5497335083179354, 'Validation Loss (Hydroxylation-P)': 0.3811810870965322, 'Validation Loss (total)': 0.8193064530690511, 'TimeToTrain': 11.829999383290609}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016115760030116634,
 'learning_rate_Hydroxylation-K': 0.004542251397902262,
 'learning_rate_Hydroxylation-P': 0.00532849379830515,
 'log_base': 2.1214705575789865,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4114602655,
 'sample_weights': [1.537982471803896, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.265490074423405,
 'weight_decay_Hydroxylation-K': 8.114904097712593,
 'weight_decay_Hydroxylation-P': 9.325206106121183}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1376.018
[2,     1] loss: 1375.779
[3,     1] loss: 1373.652
[4,     1] loss: 1373.469
[5,     1] loss: 1369.654
[6,     1] loss: 1370.021
[7,     1] loss: 1360.906
[8,     1] loss: 1345.009
[9,     1] loss: 1333.222
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007978493238663833,
 'learning_rate_Hydroxylation-K': 0.009383057832201017,
 'learning_rate_Hydroxylation-P': 0.008417229769224745,
 'log_base': 1.8881556398753023,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2754801931,
 'sample_weights': [2.219680951895228, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1398718900276794,
 'weight_decay_Hydroxylation-K': 9.023412703138463,
 'weight_decay_Hydroxylation-P': 0.6882015907432857}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1462.116
[2,     1] loss: 1471.574
[3,     1] loss: 1475.919
[4,     1] loss: 1456.214
[5,     1] loss: 1461.097
[6,     1] loss: 1453.252
[7,     1] loss: 1459.692
[8,     1] loss: 1447.188
[9,     1] loss: 1454.751
[10,     1] loss: 1421.012
[11,     1] loss: 1433.811
[12,     1] loss: 1385.074
[13,     1] loss: 1385.915
[14,     1] loss: 1368.009
[15,     1] loss: 1341.036
[16,     1] loss: 1284.219
[17,     1] loss: 1294.722
[18,     1] loss: 1300.774
[19,     1] loss: 1279.652
[20,     1] loss: 1299.353
[21,     1] loss: 1272.917
[22,     1] loss: 1267.252
[23,     1] loss: 1273.223
[24,     1] loss: 1186.955
[25,     1] loss: 1222.193
[26,     1] loss: 1199.584
[27,     1] loss: 1127.198
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008523455291323781,
 'learning_rate_Hydroxylation-K': 0.008034558696133584,
 'learning_rate_Hydroxylation-P': 0.005965991624273421,
 'log_base': 1.107412855540023,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 84987867,
 'sample_weights': [2.6265604661802944, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.347954920324784,
 'weight_decay_Hydroxylation-K': 0.661834673058249,
 'weight_decay_Hydroxylation-P': 6.411722692080305}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 5322.540
[2,     1] loss: 5302.360
[3,     1] loss: 5294.219
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003226699446906249,
 'learning_rate_Hydroxylation-K': 0.0015955516909948715,
 'learning_rate_Hydroxylation-P': 0.004691042149721835,
 'log_base': 2.720220856255392,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 713329145,
 'sample_weights': [16.362833082322336, 2.0454329305449668],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.980735980007767,
 'weight_decay_Hydroxylation-K': 4.2065659275566425,
 'weight_decay_Hydroxylation-P': 3.219853658396909}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1260.945
[2,     1] loss: 1260.095
[3,     1] loss: 1271.580
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00223637598012954,
 'learning_rate_Hydroxylation-K': 0.0015116703120077381,
 'learning_rate_Hydroxylation-P': 0.005089806142400447,
 'log_base': 1.994515500057567,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 434888614,
 'sample_weights': [1.6682535589112895, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3529900873856195,
 'weight_decay_Hydroxylation-K': 0.2849084470000036,
 'weight_decay_Hydroxylation-P': 0.4916246260328595}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1419.394
[2,     1] loss: 1417.956
[3,     1] loss: 1415.929
[4,     1] loss: 1412.971
[5,     1] loss: 1415.046
[6,     1] loss: 1401.654
[7,     1] loss: 1401.469
[8,     1] loss: 1400.524
[9,     1] loss: 1371.064
[10,     1] loss: 1339.370
[11,     1] loss: 1291.201
[12,     1] loss: 1241.188
[13,     1] loss: 1264.252
[14,     1] loss: 1235.909
[15,     1] loss: 1194.749
[16,     1] loss: 1242.647
[17,     1] loss: 1206.344
[18,     1] loss: 1190.917
[19,     1] loss: 1161.822
[20,     1] loss: 1204.382
[21,     1] loss: 1168.480
[22,     1] loss: 1160.778
[23,     1] loss: 1129.151
[24,     1] loss: 1106.345
[25,     1] loss: 1191.342
[26,     1] loss: 1090.812
[27,     1] loss: 1111.231
[28,     1] loss: 1096.650
[29,     1] loss: 1051.634
[30,     1] loss: 1106.982
[31,     1] loss: 1038.258
[32,     1] loss: 1045.801
[33,     1] loss: 1055.724
[34,     1] loss: 1048.160
[35,     1] loss: 1069.211
[36,     1] loss: 1068.176
[37,     1] loss: 1028.789
[38,     1] loss: 1041.644
[39,     1] loss: 982.269
[40,     1] loss: 996.397
[41,     1] loss: 977.670
[42,     1] loss: 962.849
[43,     1] loss: 962.379
[44,     1] loss: 892.112
[45,     1] loss: 940.058
[46,     1] loss: 896.929
[47,     1] loss: 917.373
[48,     1] loss: 918.764
[49,     1] loss: 964.538
[50,     1] loss: 938.638
[51,     1] loss: 861.384
[52,     1] loss: 897.010
[53,     1] loss: 850.946
[54,     1] loss: 863.684
Early stopping applied (best metric=0.7397010326385498)
Finished Training
Total time taken: 10.379313945770264
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1414.038
[2,     1] loss: 1417.026
[3,     1] loss: 1416.168
[4,     1] loss: 1426.553
[5,     1] loss: 1411.900
[6,     1] loss: 1405.397
[7,     1] loss: 1395.179
[8,     1] loss: 1382.660
[9,     1] loss: 1334.325
[10,     1] loss: 1303.073
[11,     1] loss: 1292.457
[12,     1] loss: 1220.990
[13,     1] loss: 1221.049
[14,     1] loss: 1190.727
[15,     1] loss: 1201.563
[16,     1] loss: 1161.378
[17,     1] loss: 1214.873
[18,     1] loss: 1238.367
[19,     1] loss: 1132.055
[20,     1] loss: 1202.735
[21,     1] loss: 1165.236
[22,     1] loss: 1168.381
[23,     1] loss: 1152.516
[24,     1] loss: 1115.710
[25,     1] loss: 1163.113
[26,     1] loss: 1107.405
[27,     1] loss: 1124.701
[28,     1] loss: 1065.951
[29,     1] loss: 1076.301
[30,     1] loss: 1138.192
[31,     1] loss: 1035.756
[32,     1] loss: 1053.453
Early stopping applied (best metric=0.927160382270813)
Finished Training
Total time taken: 6.22115683555603
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1421.871
[2,     1] loss: 1416.987
[3,     1] loss: 1422.468
[4,     1] loss: 1417.083
[5,     1] loss: 1413.679
[6,     1] loss: 1410.148
[7,     1] loss: 1406.441
[8,     1] loss: 1397.158
[9,     1] loss: 1378.219
[10,     1] loss: 1365.545
[11,     1] loss: 1326.139
[12,     1] loss: 1282.634
[13,     1] loss: 1268.100
[14,     1] loss: 1213.960
[15,     1] loss: 1218.016
[16,     1] loss: 1218.478
[17,     1] loss: 1195.161
[18,     1] loss: 1179.651
[19,     1] loss: 1208.259
[20,     1] loss: 1171.069
[21,     1] loss: 1100.317
[22,     1] loss: 1184.138
[23,     1] loss: 1122.569
[24,     1] loss: 1135.316
[25,     1] loss: 1146.068
[26,     1] loss: 1068.044
[27,     1] loss: 1091.043
[28,     1] loss: 1046.421
[29,     1] loss: 1067.915
[30,     1] loss: 1051.509
[31,     1] loss: 1089.018
[32,     1] loss: 1009.933
[33,     1] loss: 1065.592
[34,     1] loss: 1058.133
[35,     1] loss: 1022.949
[36,     1] loss: 972.491
[37,     1] loss: 989.395
[38,     1] loss: 1037.517
[39,     1] loss: 939.314
[40,     1] loss: 987.279
[41,     1] loss: 984.674
[42,     1] loss: 947.888
[43,     1] loss: 960.833
[44,     1] loss: 952.930
[45,     1] loss: 927.000
[46,     1] loss: 935.650
[47,     1] loss: 924.199
[48,     1] loss: 936.643
[49,     1] loss: 949.002
[50,     1] loss: 929.889
[51,     1] loss: 942.372
[52,     1] loss: 899.700
[53,     1] loss: 903.611
[54,     1] loss: 843.222
[55,     1] loss: 901.757
[56,     1] loss: 832.224
Early stopping applied (best metric=0.892651379108429)
Finished Training
Total time taken: 10.192337036132812
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1421.246
[2,     1] loss: 1418.000
[3,     1] loss: 1415.289
[4,     1] loss: 1415.901
[5,     1] loss: 1407.385
[6,     1] loss: 1407.472
[7,     1] loss: 1386.996
[8,     1] loss: 1367.357
[9,     1] loss: 1318.689
[10,     1] loss: 1282.189
[11,     1] loss: 1236.323
[12,     1] loss: 1222.626
[13,     1] loss: 1195.708
[14,     1] loss: 1193.580
[15,     1] loss: 1207.759
[16,     1] loss: 1133.167
[17,     1] loss: 1173.003
[18,     1] loss: 1106.052
[19,     1] loss: 1147.249
[20,     1] loss: 1114.088
[21,     1] loss: 1130.475
[22,     1] loss: 1124.383
[23,     1] loss: 1119.119
[24,     1] loss: 1086.076
[25,     1] loss: 1115.548
[26,     1] loss: 1116.240
[27,     1] loss: 1087.273
[28,     1] loss: 1050.573
[29,     1] loss: 1051.503
[30,     1] loss: 1039.089
[31,     1] loss: 1048.659
[32,     1] loss: 1048.872
[33,     1] loss: 1065.822
[34,     1] loss: 1062.613
[35,     1] loss: 1050.860
[36,     1] loss: 1004.639
[37,     1] loss: 1046.592
[38,     1] loss: 1031.902
[39,     1] loss: 1015.572
[40,     1] loss: 972.797
[41,     1] loss: 897.286
Early stopping applied (best metric=0.948575496673584)
Finished Training
Total time taken: 6.284168481826782
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1423.750
[2,     1] loss: 1423.261
[3,     1] loss: 1417.661
[4,     1] loss: 1422.160
[5,     1] loss: 1420.711
[6,     1] loss: 1412.008
[7,     1] loss: 1407.936
[8,     1] loss: 1403.109
[9,     1] loss: 1383.689
[10,     1] loss: 1352.440
[11,     1] loss: 1314.050
[12,     1] loss: 1298.602
[13,     1] loss: 1255.910
[14,     1] loss: 1236.729
[15,     1] loss: 1214.429
[16,     1] loss: 1162.587
[17,     1] loss: 1285.415
[18,     1] loss: 1236.952
[19,     1] loss: 1198.829
[20,     1] loss: 1128.896
[21,     1] loss: 1168.174
[22,     1] loss: 1179.217
[23,     1] loss: 1157.466
[24,     1] loss: 1220.974
[25,     1] loss: 1099.934
[26,     1] loss: 1124.480
[27,     1] loss: 1072.477
[28,     1] loss: 1075.002
[29,     1] loss: 1107.243
[30,     1] loss: 1167.881
[31,     1] loss: 1083.775
[32,     1] loss: 1046.884
[33,     1] loss: 1112.494
[34,     1] loss: 1069.279
[35,     1] loss: 1070.592
[36,     1] loss: 1066.642
[37,     1] loss: 1055.195
[38,     1] loss: 1145.231
[39,     1] loss: 1103.944
[40,     1] loss: 1072.715
[41,     1] loss: 1034.318
[42,     1] loss: 1038.379
[43,     1] loss: 1011.425
[44,     1] loss: 1045.935
[45,     1] loss: 995.313
[46,     1] loss: 991.127
[47,     1] loss: 1023.740
[48,     1] loss: 970.108
[49,     1] loss: 974.126
[50,     1] loss: 933.251
[51,     1] loss: 937.429
[52,     1] loss: 947.575
[53,     1] loss: 866.323
[54,     1] loss: 936.343
[55,     1] loss: 884.989
[56,     1] loss: 892.985
[57,     1] loss: 872.112
[58,     1] loss: 849.801
[59,     1] loss: 890.550
[60,     1] loss: 859.711
[61,     1] loss: 849.821
[62,     1] loss: 847.633
[63,     1] loss: 820.287
[64,     1] loss: 864.678
[65,     1] loss: 789.661
[66,     1] loss: 823.342
Early stopping applied (best metric=0.7125835418701172)
Finished Training
Total time taken: 12.192848205566406
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1420.817
[2,     1] loss: 1418.695
[3,     1] loss: 1419.823
[4,     1] loss: 1412.498
[5,     1] loss: 1414.979
[6,     1] loss: 1414.025
[7,     1] loss: 1402.477
[8,     1] loss: 1393.385
[9,     1] loss: 1370.065
[10,     1] loss: 1354.245
[11,     1] loss: 1306.365
[12,     1] loss: 1269.070
[13,     1] loss: 1273.787
[14,     1] loss: 1248.163
[15,     1] loss: 1243.784
[16,     1] loss: 1216.928
[17,     1] loss: 1241.729
[18,     1] loss: 1155.132
[19,     1] loss: 1197.245
[20,     1] loss: 1199.271
[21,     1] loss: 1148.265
[22,     1] loss: 1145.374
[23,     1] loss: 1178.655
[24,     1] loss: 1193.228
[25,     1] loss: 1124.442
[26,     1] loss: 1129.196
[27,     1] loss: 1118.478
[28,     1] loss: 1151.175
[29,     1] loss: 1128.389
[30,     1] loss: 1070.103
[31,     1] loss: 1057.703
[32,     1] loss: 1033.338
[33,     1] loss: 1018.734
[34,     1] loss: 1030.467
[35,     1] loss: 1023.783
[36,     1] loss: 1077.718
[37,     1] loss: 1048.923
[38,     1] loss: 1007.176
[39,     1] loss: 1009.263
[40,     1] loss: 958.258
[41,     1] loss: 946.281
[42,     1] loss: 967.103
[43,     1] loss: 946.658
[44,     1] loss: 948.135
[45,     1] loss: 906.411
[46,     1] loss: 958.322
[47,     1] loss: 960.119
[48,     1] loss: 874.339
[49,     1] loss: 888.006
[50,     1] loss: 867.494
[51,     1] loss: 883.835
[52,     1] loss: 854.161
[53,     1] loss: 880.959
[54,     1] loss: 869.592
[55,     1] loss: 880.878
Early stopping applied (best metric=0.8051385879516602)
Finished Training
Total time taken: 10.502286434173584
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1420.124
[2,     1] loss: 1419.631
[3,     1] loss: 1417.412
[4,     1] loss: 1412.244
[5,     1] loss: 1412.985
[6,     1] loss: 1414.565
[7,     1] loss: 1409.556
[8,     1] loss: 1399.466
[9,     1] loss: 1392.618
[10,     1] loss: 1375.734
[11,     1] loss: 1347.653
[12,     1] loss: 1324.546
[13,     1] loss: 1280.746
[14,     1] loss: 1263.253
[15,     1] loss: 1252.127
[16,     1] loss: 1234.077
[17,     1] loss: 1226.585
[18,     1] loss: 1192.927
[19,     1] loss: 1194.611
[20,     1] loss: 1174.482
[21,     1] loss: 1099.998
[22,     1] loss: 1149.269
[23,     1] loss: 1168.411
[24,     1] loss: 1135.219
[25,     1] loss: 1156.882
[26,     1] loss: 1106.035
[27,     1] loss: 1067.304
[28,     1] loss: 1103.031
[29,     1] loss: 1068.317
[30,     1] loss: 1069.806
[31,     1] loss: 1062.577
[32,     1] loss: 1039.853
[33,     1] loss: 1077.905
[34,     1] loss: 995.530
[35,     1] loss: 1028.568
[36,     1] loss: 1013.599
[37,     1] loss: 960.086
[38,     1] loss: 1019.347
[39,     1] loss: 972.652
[40,     1] loss: 940.949
[41,     1] loss: 995.754
[42,     1] loss: 928.572
[43,     1] loss: 948.355
[44,     1] loss: 968.302
Early stopping applied (best metric=0.772072434425354)
Finished Training
Total time taken: 7.334245681762695
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1419.554
[2,     1] loss: 1416.357
[3,     1] loss: 1422.584
[4,     1] loss: 1419.530
[5,     1] loss: 1422.959
[6,     1] loss: 1413.999
[7,     1] loss: 1418.604
[8,     1] loss: 1417.353
[9,     1] loss: 1417.160
[10,     1] loss: 1411.234
[11,     1] loss: 1413.062
[12,     1] loss: 1410.200
[13,     1] loss: 1407.246
[14,     1] loss: 1395.550
[15,     1] loss: 1380.489
[16,     1] loss: 1369.481
[17,     1] loss: 1336.768
[18,     1] loss: 1314.935
[19,     1] loss: 1279.688
[20,     1] loss: 1276.897
[21,     1] loss: 1220.478
[22,     1] loss: 1269.131
[23,     1] loss: 1207.680
[24,     1] loss: 1219.916
[25,     1] loss: 1203.149
[26,     1] loss: 1216.282
[27,     1] loss: 1180.915
[28,     1] loss: 1159.932
[29,     1] loss: 1169.112
[30,     1] loss: 1162.165
[31,     1] loss: 1165.557
[32,     1] loss: 1188.201
[33,     1] loss: 1177.729
[34,     1] loss: 1186.993
[35,     1] loss: 1122.586
[36,     1] loss: 1141.251
[37,     1] loss: 1111.969
[38,     1] loss: 1114.423
[39,     1] loss: 1059.916
[40,     1] loss: 1129.970
[41,     1] loss: 1089.984
[42,     1] loss: 1098.932
[43,     1] loss: 1141.214
[44,     1] loss: 1113.173
[45,     1] loss: 1117.170
[46,     1] loss: 1078.099
[47,     1] loss: 1118.074
[48,     1] loss: 1068.723
[49,     1] loss: 998.983
[50,     1] loss: 1062.392
[51,     1] loss: 997.826
[52,     1] loss: 1047.358
[53,     1] loss: 1004.188
[54,     1] loss: 976.372
[55,     1] loss: 1019.017
[56,     1] loss: 993.584
[57,     1] loss: 989.272
[58,     1] loss: 989.623
[59,     1] loss: 995.921
[60,     1] loss: 953.354
[61,     1] loss: 918.482
[62,     1] loss: 994.702
[63,     1] loss: 887.488
[64,     1] loss: 928.860
[65,     1] loss: 903.956
[66,     1] loss: 855.650
[67,     1] loss: 903.052
[68,     1] loss: 849.304
[69,     1] loss: 785.200
[70,     1] loss: 820.377
[71,     1] loss: 792.589
[72,     1] loss: 782.281
[73,     1] loss: 835.150
[74,     1] loss: 771.625
[75,     1] loss: 774.499
[76,     1] loss: 716.843
[77,     1] loss: 779.842
[78,     1] loss: 742.045
[79,     1] loss: 733.276
[80,     1] loss: 733.446
Early stopping applied (best metric=0.630028486251831)
Finished Training
Total time taken: 12.868438482284546
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1420.479
[2,     1] loss: 1418.223
[3,     1] loss: 1413.677
[4,     1] loss: 1420.358
[5,     1] loss: 1422.299
[6,     1] loss: 1422.294
[7,     1] loss: 1418.360
[8,     1] loss: 1409.707
[9,     1] loss: 1398.178
[10,     1] loss: 1385.859
[11,     1] loss: 1360.900
[12,     1] loss: 1337.811
[13,     1] loss: 1292.208
[14,     1] loss: 1266.145
[15,     1] loss: 1245.868
[16,     1] loss: 1241.416
[17,     1] loss: 1284.163
[18,     1] loss: 1201.767
[19,     1] loss: 1245.461
[20,     1] loss: 1219.663
[21,     1] loss: 1220.984
[22,     1] loss: 1232.227
[23,     1] loss: 1174.273
[24,     1] loss: 1110.058
[25,     1] loss: 1146.823
[26,     1] loss: 1160.698
[27,     1] loss: 1138.334
[28,     1] loss: 1138.449
[29,     1] loss: 1137.710
[30,     1] loss: 1145.754
[31,     1] loss: 1129.073
[32,     1] loss: 1118.267
[33,     1] loss: 1076.861
[34,     1] loss: 1066.943
[35,     1] loss: 1068.264
[36,     1] loss: 1046.939
[37,     1] loss: 1007.052
[38,     1] loss: 1068.627
[39,     1] loss: 1002.446
[40,     1] loss: 984.329
[41,     1] loss: 1027.569
[42,     1] loss: 1033.439
[43,     1] loss: 991.228
[44,     1] loss: 994.450
[45,     1] loss: 944.267
[46,     1] loss: 984.639
[47,     1] loss: 935.021
[48,     1] loss: 977.097
[49,     1] loss: 941.587
[50,     1] loss: 924.067
[51,     1] loss: 925.091
[52,     1] loss: 915.259
[53,     1] loss: 897.310
Early stopping applied (best metric=0.7621093988418579)
Finished Training
Total time taken: 10.156245470046997
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1422.120
[2,     1] loss: 1419.959
[3,     1] loss: 1415.576
[4,     1] loss: 1417.848
[5,     1] loss: 1416.633
[6,     1] loss: 1409.583
[7,     1] loss: 1399.982
[8,     1] loss: 1382.429
[9,     1] loss: 1348.865
[10,     1] loss: 1318.219
[11,     1] loss: 1282.002
[12,     1] loss: 1225.118
[13,     1] loss: 1188.821
[14,     1] loss: 1192.096
[15,     1] loss: 1151.694
[16,     1] loss: 1141.929
[17,     1] loss: 1196.147
[18,     1] loss: 1165.786
[19,     1] loss: 1208.907
[20,     1] loss: 1167.025
[21,     1] loss: 1124.918
[22,     1] loss: 1142.603
[23,     1] loss: 1163.226
[24,     1] loss: 1142.990
[25,     1] loss: 1115.766
[26,     1] loss: 1065.553
[27,     1] loss: 1073.272
[28,     1] loss: 1056.258
[29,     1] loss: 1086.831
[30,     1] loss: 1101.314
[31,     1] loss: 1077.329
[32,     1] loss: 1076.914
[33,     1] loss: 1025.640
[34,     1] loss: 1052.488
[35,     1] loss: 1051.630
[36,     1] loss: 1068.061
[37,     1] loss: 1015.635
[38,     1] loss: 986.813
[39,     1] loss: 1025.277
[40,     1] loss: 1034.880
[41,     1] loss: 1030.888
[42,     1] loss: 963.689
[43,     1] loss: 969.338
[44,     1] loss: 1004.263
[45,     1] loss: 1021.311
[46,     1] loss: 1011.479
[47,     1] loss: 981.789
[48,     1] loss: 951.681
[49,     1] loss: 956.651
[50,     1] loss: 934.464
[51,     1] loss: 899.170
[52,     1] loss: 920.089
[53,     1] loss: 970.177
[54,     1] loss: 870.672
[55,     1] loss: 857.500
[56,     1] loss: 855.700
[57,     1] loss: 867.866
[58,     1] loss: 840.392
[59,     1] loss: 857.189
[60,     1] loss: 771.854
[61,     1] loss: 823.560
[62,     1] loss: 826.461
[63,     1] loss: 855.248
[64,     1] loss: 784.071
[65,     1] loss: 809.445
[66,     1] loss: 862.645
[67,     1] loss: 761.210
[68,     1] loss: 877.707
Early stopping applied (best metric=0.6475174427032471)
Finished Training
Total time taken: 12.82587456703186
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1418.461
[2,     1] loss: 1435.921
[3,     1] loss: 1417.871
[4,     1] loss: 1413.245
[5,     1] loss: 1414.175
[6,     1] loss: 1414.794
[7,     1] loss: 1416.515
[8,     1] loss: 1413.515
[9,     1] loss: 1412.463
[10,     1] loss: 1398.749
[11,     1] loss: 1397.618
[12,     1] loss: 1364.391
[13,     1] loss: 1334.063
[14,     1] loss: 1323.005
[15,     1] loss: 1296.770
[16,     1] loss: 1249.638
[17,     1] loss: 1216.841
[18,     1] loss: 1175.430
[19,     1] loss: 1187.651
[20,     1] loss: 1184.556
[21,     1] loss: 1205.031
[22,     1] loss: 1138.988
[23,     1] loss: 1136.667
[24,     1] loss: 1127.023
[25,     1] loss: 1104.669
[26,     1] loss: 1087.073
[27,     1] loss: 1132.958
[28,     1] loss: 1108.072
[29,     1] loss: 1079.542
[30,     1] loss: 1085.856
[31,     1] loss: 1105.369
[32,     1] loss: 1018.235
[33,     1] loss: 1060.412
[34,     1] loss: 1014.670
[35,     1] loss: 994.226
[36,     1] loss: 1007.425
[37,     1] loss: 1055.295
[38,     1] loss: 1007.784
[39,     1] loss: 1006.675
[40,     1] loss: 959.164
[41,     1] loss: 950.118
[42,     1] loss: 955.727
[43,     1] loss: 940.307
[44,     1] loss: 997.772
[45,     1] loss: 862.177
[46,     1] loss: 908.305
[47,     1] loss: 894.856
[48,     1] loss: 892.793
[49,     1] loss: 943.410
Early stopping applied (best metric=1.0373036861419678)
Finished Training
Total time taken: 9.279743432998657
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1423.493
[2,     1] loss: 1419.426
[3,     1] loss: 1420.144
[4,     1] loss: 1430.723
[5,     1] loss: 1417.546
[6,     1] loss: 1413.323
[7,     1] loss: 1414.632
[8,     1] loss: 1415.979
[9,     1] loss: 1408.156
[10,     1] loss: 1396.323
[11,     1] loss: 1386.051
[12,     1] loss: 1352.376
[13,     1] loss: 1336.959
[14,     1] loss: 1284.373
[15,     1] loss: 1251.601
[16,     1] loss: 1203.579
[17,     1] loss: 1257.123
[18,     1] loss: 1182.403
[19,     1] loss: 1214.000
[20,     1] loss: 1134.234
[21,     1] loss: 1170.551
[22,     1] loss: 1181.863
[23,     1] loss: 1163.913
[24,     1] loss: 1159.497
[25,     1] loss: 1134.956
[26,     1] loss: 1132.379
[27,     1] loss: 1119.813
[28,     1] loss: 1101.632
[29,     1] loss: 1090.242
[30,     1] loss: 1068.083
[31,     1] loss: 1017.773
[32,     1] loss: 1069.724
[33,     1] loss: 1065.108
[34,     1] loss: 1028.525
[35,     1] loss: 1049.535
Early stopping applied (best metric=0.9158481359481812)
Finished Training
Total time taken: 5.767122268676758
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1419.093
[2,     1] loss: 1416.901
[3,     1] loss: 1418.177
[4,     1] loss: 1413.225
[5,     1] loss: 1414.003
[6,     1] loss: 1416.986
[7,     1] loss: 1407.377
[8,     1] loss: 1403.278
[9,     1] loss: 1396.286
[10,     1] loss: 1363.443
[11,     1] loss: 1341.361
[12,     1] loss: 1310.994
[13,     1] loss: 1288.657
[14,     1] loss: 1269.566
[15,     1] loss: 1277.640
[16,     1] loss: 1221.723
[17,     1] loss: 1169.680
[18,     1] loss: 1204.545
[19,     1] loss: 1180.986
[20,     1] loss: 1181.123
[21,     1] loss: 1155.012
[22,     1] loss: 1190.045
[23,     1] loss: 1181.335
[24,     1] loss: 1177.130
[25,     1] loss: 1130.857
[26,     1] loss: 1092.764
[27,     1] loss: 1123.682
[28,     1] loss: 1144.717
[29,     1] loss: 1101.841
[30,     1] loss: 1093.661
[31,     1] loss: 1082.768
[32,     1] loss: 1049.076
[33,     1] loss: 1046.239
[34,     1] loss: 1002.329
[35,     1] loss: 1002.948
[36,     1] loss: 1035.022
[37,     1] loss: 985.559
[38,     1] loss: 988.062
[39,     1] loss: 999.362
Early stopping applied (best metric=0.8816231489181519)
Finished Training
Total time taken: 6.543694734573364
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1421.513
[2,     1] loss: 1413.214
[3,     1] loss: 1421.746
[4,     1] loss: 1424.153
[5,     1] loss: 1414.661
[6,     1] loss: 1401.319
[7,     1] loss: 1389.411
[8,     1] loss: 1360.160
[9,     1] loss: 1328.740
[10,     1] loss: 1306.072
[11,     1] loss: 1278.502
[12,     1] loss: 1246.920
[13,     1] loss: 1252.890
[14,     1] loss: 1197.553
[15,     1] loss: 1249.568
[16,     1] loss: 1264.460
[17,     1] loss: 1184.455
[18,     1] loss: 1218.630
[19,     1] loss: 1187.517
[20,     1] loss: 1175.212
[21,     1] loss: 1209.237
[22,     1] loss: 1208.864
[23,     1] loss: 1155.730
[24,     1] loss: 1171.150
[25,     1] loss: 1177.525
[26,     1] loss: 1136.542
[27,     1] loss: 1169.803
[28,     1] loss: 1116.071
[29,     1] loss: 1119.785
[30,     1] loss: 1103.688
[31,     1] loss: 1086.001
[32,     1] loss: 1058.315
[33,     1] loss: 1055.657
[34,     1] loss: 1110.202
[35,     1] loss: 1013.437
[36,     1] loss: 1020.619
[37,     1] loss: 1074.964
[38,     1] loss: 1013.700
[39,     1] loss: 1047.692
[40,     1] loss: 1007.669
[41,     1] loss: 1013.470
[42,     1] loss: 997.192
[43,     1] loss: 999.286
[44,     1] loss: 964.712
[45,     1] loss: 994.436
[46,     1] loss: 948.398
[47,     1] loss: 921.018
[48,     1] loss: 943.709
[49,     1] loss: 902.868
[50,     1] loss: 879.190
[51,     1] loss: 956.021
[52,     1] loss: 880.510
[53,     1] loss: 876.836
[54,     1] loss: 872.187
[55,     1] loss: 902.830
[56,     1] loss: 854.191
[57,     1] loss: 917.718
[58,     1] loss: 879.393
Early stopping applied (best metric=0.7758920192718506)
Finished Training
Total time taken: 10.095287084579468
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1432.698
[2,     1] loss: 1420.901
[3,     1] loss: 1417.464
[4,     1] loss: 1419.636
[5,     1] loss: 1428.195
[6,     1] loss: 1425.075
[7,     1] loss: 1413.398
[8,     1] loss: 1412.487
[9,     1] loss: 1411.144
[10,     1] loss: 1377.145
[11,     1] loss: 1357.567
[12,     1] loss: 1315.157
[13,     1] loss: 1289.138
[14,     1] loss: 1250.019
[15,     1] loss: 1218.631
[16,     1] loss: 1233.020
[17,     1] loss: 1197.496
[18,     1] loss: 1205.784
[19,     1] loss: 1191.476
[20,     1] loss: 1162.258
[21,     1] loss: 1154.221
[22,     1] loss: 1164.366
[23,     1] loss: 1131.940
[24,     1] loss: 1172.741
[25,     1] loss: 1138.174
[26,     1] loss: 1074.191
[27,     1] loss: 1083.818
[28,     1] loss: 1096.457
[29,     1] loss: 1064.434
[30,     1] loss: 1066.439
[31,     1] loss: 1082.088
[32,     1] loss: 1045.684
[33,     1] loss: 1058.761
[34,     1] loss: 984.180
[35,     1] loss: 967.618
[36,     1] loss: 1005.726
[37,     1] loss: 986.995
[38,     1] loss: 996.031
[39,     1] loss: 958.642
[40,     1] loss: 981.249
[41,     1] loss: 993.814
[42,     1] loss: 977.167
[43,     1] loss: 934.093
[44,     1] loss: 939.105
[45,     1] loss: 922.477
[46,     1] loss: 940.075
Early stopping applied (best metric=0.9092221856117249)
Finished Training
Total time taken: 9.117953062057495
{'Hydroxylation-K Validation Accuracy': 0.7703014184397163, 'Hydroxylation-K Validation Sensitivity': 0.6733333333333333, 'Hydroxylation-K Validation Specificity': 0.7947368421052632, 'Hydroxylation-K Validation Precision': 0.45735144485144485, 'Hydroxylation-K AUC ROC': 0.7984990253411306, 'Hydroxylation-K AUC PR': 0.5556646210179292, 'Hydroxylation-K MCC': 0.41227084562868926, 'Hydroxylation-K F1': 0.5411952542753459, 'Validation Loss (Hydroxylation-K)': 0.4400818347930908, 'Hydroxylation-P Validation Accuracy': 0.7745354212138131, 'Hydroxylation-P Validation Sensitivity': 0.7637037037037037, 'Hydroxylation-P Validation Specificity': 0.7769589505711008, 'Hydroxylation-P Validation Precision': 0.43272942698150013, 'Hydroxylation-P AUC ROC': 0.8353591735961181, 'Hydroxylation-P AUC PR': 0.5587035953165573, 'Hydroxylation-P MCC': 0.44785214734841805, 'Hydroxylation-P F1': 0.5482269519771699, 'Validation Loss (Hydroxylation-P)': 0.3837466518084208, 'Validation Loss (total)': 0.8238284905751546, 'TimeToTrain': 9.317381048202515}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005077390549291285,
 'learning_rate_Hydroxylation-K': 0.003349567166005393,
 'learning_rate_Hydroxylation-P': 0.0076786037343469695,
 'log_base': 1.0490726642926247,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2730354515,
 'sample_weights': [2.4198706859658383, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.934551941718458,
 'weight_decay_Hydroxylation-K': 2.498901532808966,
 'weight_decay_Hydroxylation-P': 3.131002975364385}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 11323.467
[2,     1] loss: 11412.830
[3,     1] loss: 11306.924
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016844368310179522,
 'learning_rate_Hydroxylation-K': 0.0006271767810582547,
 'learning_rate_Hydroxylation-P': 0.008422436272004544,
 'log_base': 1.0800140876130255,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2279259631,
 'sample_weights': [34.84787585344582, 4.35615229169498],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.083350432219389,
 'weight_decay_Hydroxylation-K': 4.012516345024631,
 'weight_decay_Hydroxylation-P': 1.6824282161544013}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 7097.467
[2,     1] loss: 7028.742
[3,     1] loss: 7015.630
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016706345427164291,
 'learning_rate_Hydroxylation-K': 0.0013699815844313793,
 'learning_rate_Hydroxylation-P': 0.005810943330475295,
 'log_base': 2.23989936676999,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 634794166,
 'sample_weights': [21.688379205134424, 2.711151841074236],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.820151903827392,
 'weight_decay_Hydroxylation-K': 0.1938845263360438,
 'weight_decay_Hydroxylation-P': 2.27490503617492}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1348.889
[2,     1] loss: 1343.977
[3,     1] loss: 1346.489
[4,     1] loss: 1345.099
[5,     1] loss: 1340.261
[6,     1] loss: 1343.778
[7,     1] loss: 1337.479
[8,     1] loss: 1333.393
[9,     1] loss: 1326.175
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007131257510977981,
 'learning_rate_Hydroxylation-K': 0.005497740737677174,
 'learning_rate_Hydroxylation-P': 0.00418856305259992,
 'log_base': 2.1189941103533543,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3342658434,
 'sample_weights': [2.0701625719554744, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.1979719572692311,
 'weight_decay_Hydroxylation-K': 0.17882143021746166,
 'weight_decay_Hydroxylation-P': 0.13969014228050958}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1378.108
[2,     1] loss: 1378.260
[3,     1] loss: 1378.219
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005581703771287772,
 'learning_rate_Hydroxylation-K': 0.007710850857011978,
 'learning_rate_Hydroxylation-P': 0.007518015093656262,
 'log_base': 1.485930661833158,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 205494100,
 'sample_weights': [2.223133423559892, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.098447424458834,
 'weight_decay_Hydroxylation-K': 0.25537365911141996,
 'weight_decay_Hydroxylation-P': 1.8397592171423427}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1799.118
[2,     1] loss: 1803.969
[3,     1] loss: 1800.298
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003384601482465638,
 'learning_rate_Hydroxylation-K': 0.00438792291766459,
 'learning_rate_Hydroxylation-P': 0.005484552088283312,
 'log_base': 1.8412996752126425,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 183939504,
 'sample_weights': [4.215326062640797, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3416121935340155,
 'weight_decay_Hydroxylation-K': 1.222344643045235,
 'weight_decay_Hydroxylation-P': 0.019338112881783887}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1485.964
[2,     1] loss: 1487.417
[3,     1] loss: 1486.160
[4,     1] loss: 1482.128
[5,     1] loss: 1482.047
[6,     1] loss: 1481.324
[7,     1] loss: 1487.174
[8,     1] loss: 1476.814
[9,     1] loss: 1476.219
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009212121206361957,
 'learning_rate_Hydroxylation-K': 0.009013458806826477,
 'learning_rate_Hydroxylation-P': 0.004933033477761123,
 'log_base': 1.462000886580043,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 693749105,
 'sample_weights': [2.7346775228050157, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9135469904722555,
 'weight_decay_Hydroxylation-K': 9.671573167044667,
 'weight_decay_Hydroxylation-P': 5.087423232975818}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1835.785
[2,     1] loss: 1854.762
[3,     1] loss: 1895.231
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005320663209571187,
 'learning_rate_Hydroxylation-K': 0.0015079041130111061,
 'learning_rate_Hydroxylation-P': 0.008812691061083539,
 'log_base': 1.035447143033545,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4076802900,
 'sample_weights': [4.39551584021449, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.631741111230076,
 'weight_decay_Hydroxylation-K': 1.632086184930817,
 'weight_decay_Hydroxylation-P': 4.666127902933739}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15550.562
Exploding loss, terminate run (best metric=1.097625732421875)
Finished Training
Total time taken: 0.2740058898925781
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15566.658
Exploding loss, terminate run (best metric=1.092989444732666)
Finished Training
Total time taken: 0.26100826263427734
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15747.753
Exploding loss, terminate run (best metric=1.091494083404541)
Finished Training
Total time taken: 0.2550067901611328
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15563.997
Exploding loss, terminate run (best metric=1.0836222171783447)
Finished Training
Total time taken: 0.22800517082214355
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 15580.852
Exploding loss, terminate run (best metric=1.082926630973816)
Finished Training
Total time taken: 0.25000452995300293
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15687.785
Exploding loss, terminate run (best metric=1.117236614227295)
Finished Training
Total time taken: 0.27800488471984863
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15505.866
Exploding loss, terminate run (best metric=1.1044840812683105)
Finished Training
Total time taken: 0.24600648880004883
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15604.236
Exploding loss, terminate run (best metric=1.092854619026184)
Finished Training
Total time taken: 0.2730071544647217
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15528.744
Exploding loss, terminate run (best metric=1.104483962059021)
Finished Training
Total time taken: 0.2555198669433594
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 15542.744
Exploding loss, terminate run (best metric=1.0948231220245361)
Finished Training
Total time taken: 0.23500514030456543
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15647.238
Exploding loss, terminate run (best metric=1.0949870347976685)
Finished Training
Total time taken: 0.2590055465698242
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15512.462
Exploding loss, terminate run (best metric=1.100511074066162)
Finished Training
Total time taken: 0.25400638580322266
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15595.436
Exploding loss, terminate run (best metric=1.091917634010315)
Finished Training
Total time taken: 0.23100495338439941
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15567.918
Exploding loss, terminate run (best metric=1.076636552810669)
Finished Training
Total time taken: 0.2680041790008545
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 15609.914
Exploding loss, terminate run (best metric=1.1248371601104736)
Finished Training
Total time taken: 0.2790052890777588
{'Hydroxylation-K Validation Accuracy': 0.6017139479905437, 'Hydroxylation-K Validation Sensitivity': 0.3333333333333333, 'Hydroxylation-K Validation Specificity': 0.6666666666666666, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.7097076023391813, 'Hydroxylation-K AUC PR': 0.44953982751872706, 'Hydroxylation-K MCC': 0.0, 'Hydroxylation-K F1': 0.11338259441707718, 'Validation Loss (Hydroxylation-K)': 0.5614681204160055, 'Hydroxylation-P Validation Accuracy': 0.6082556892205133, 'Hydroxylation-P Validation Sensitivity': 0.3333333333333333, 'Hydroxylation-P Validation Specificity': 0.6666666666666666, 'Hydroxylation-P Validation Precision': nan, 'Hydroxylation-P AUC ROC': 0.6239824612239695, 'Hydroxylation-P AUC PR': 0.3153258293543668, 'Hydroxylation-P MCC': 0.0, 'Hydroxylation-P F1': 0.10059261829102523, 'Validation Loss (Hydroxylation-P)': 0.5352938850720723, 'Validation Loss (total)': 1.0967619975407918, 'TimeToTrain': 0.25644003550211586}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037147937956948677,
 'learning_rate_Hydroxylation-K': 0.006243696648663078,
 'learning_rate_Hydroxylation-P': 0.003038916251910005,
 'log_base': 2.636577144862714,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3309388889,
 'sample_weights': [47.9621186415692, 5.982807729124208],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.1373015635268104,
 'weight_decay_Hydroxylation-K': 4.679363040873916,
 'weight_decay_Hydroxylation-P': 1.4422967080317781}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1269.266
[2,     1] loss: 1275.264
[3,     1] loss: 1265.775
[4,     1] loss: 1257.430
[5,     1] loss: 1239.309
[6,     1] loss: 1238.329
[7,     1] loss: 1138.929
[8,     1] loss: 1128.577
[9,     1] loss: 1101.603
[10,     1] loss: 1061.669
[11,     1] loss: 1087.799
[12,     1] loss: 1018.707
[13,     1] loss: 1057.477
[14,     1] loss: 1094.170
[15,     1] loss: 1001.503
[16,     1] loss: 992.002
[17,     1] loss: 1030.961
[18,     1] loss: 1045.803
[19,     1] loss: 1019.750
[20,     1] loss: 1034.384
[21,     1] loss: 992.443
[22,     1] loss: 969.996
[23,     1] loss: 980.061
[24,     1] loss: 983.740
[25,     1] loss: 934.062
[26,     1] loss: 959.307
[27,     1] loss: 951.472
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001045728919200349,
 'learning_rate_Hydroxylation-K': 0.00319026979309253,
 'learning_rate_Hydroxylation-P': 0.0063264049171705555,
 'log_base': 1.8000941008804687,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1517230148,
 'sample_weights': [1.7219958077910498, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.1469563381222052,
 'weight_decay_Hydroxylation-K': 0.8175826269592728,
 'weight_decay_Hydroxylation-P': 0.11597326872653946}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1508.711
[2,     1] loss: 1505.262
[3,     1] loss: 1506.500
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00518679197907617,
 'learning_rate_Hydroxylation-K': 0.00019124682263759504,
 'learning_rate_Hydroxylation-P': 0.001944382944893669,
 'log_base': 1.0877560367119306,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3405155473,
 'sample_weights': [2.8399669173062785, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.256111502317262,
 'weight_decay_Hydroxylation-K': 1.7467781600790693,
 'weight_decay_Hydroxylation-P': 7.891694568567767}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 6436.370
[2,     1] loss: 6498.914
[3,     1] loss: 6394.780
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013995200623310544,
 'learning_rate_Hydroxylation-K': 0.0016054868971841208,
 'learning_rate_Hydroxylation-P': 0.005518592947238941,
 'log_base': 2.837667393506619,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 954203735,
 'sample_weights': [19.84670499874362, 2.4809336966896467],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3837824037007316,
 'weight_decay_Hydroxylation-K': 3.240306352640427,
 'weight_decay_Hydroxylation-P': 1.2605912896232474}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.946
[2,     1] loss: 1248.286
[3,     1] loss: 1244.164
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0050291679871544035,
 'learning_rate_Hydroxylation-K': 0.0062861560281082494,
 'learning_rate_Hydroxylation-P': 0.0023829549066076627,
 'log_base': 2.975163129521153,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3653350686,
 'sample_weights': [1.6006436814677951, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7145735852750663,
 'weight_decay_Hydroxylation-K': 3.199928395361318,
 'weight_decay_Hydroxylation-P': 0.5382197996249376}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.589
[2,     1] loss: 1232.802
[3,     1] loss: 1232.471
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0038504164886749995,
 'learning_rate_Hydroxylation-K': 0.00012195557506756039,
 'learning_rate_Hydroxylation-P': 0.00817062094939871,
 'log_base': 2.5483711937744786,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3599375242,
 'sample_weights': [1.5311793783423606, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.697026846968454,
 'weight_decay_Hydroxylation-K': 6.541603888477334,
 'weight_decay_Hydroxylation-P': 1.0744642819113692}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1283.302
[2,     1] loss: 1287.310
[3,     1] loss: 1286.564
[4,     1] loss: 1286.719
[5,     1] loss: 1277.829
[6,     1] loss: 1275.806
[7,     1] loss: 1253.966
[8,     1] loss: 1220.646
[9,     1] loss: 1181.742
[10,     1] loss: 1130.766
[11,     1] loss: 1136.526
[12,     1] loss: 1123.035
[13,     1] loss: 1098.599
[14,     1] loss: 1077.389
[15,     1] loss: 1065.394
[16,     1] loss: 1054.026
[17,     1] loss: 1079.675
[18,     1] loss: 1009.124
[19,     1] loss: 1049.556
[20,     1] loss: 1007.425
[21,     1] loss: 996.974
[22,     1] loss: 980.022
[23,     1] loss: 982.249
[24,     1] loss: 970.722
[25,     1] loss: 959.204
[26,     1] loss: 944.582
[27,     1] loss: 1000.021
[28,     1] loss: 1033.516
[29,     1] loss: 934.556
[30,     1] loss: 1020.834
[31,     1] loss: 901.907
[32,     1] loss: 962.330
[33,     1] loss: 934.391
[34,     1] loss: 918.974
[35,     1] loss: 878.725
[36,     1] loss: 839.693
[37,     1] loss: 835.227
[38,     1] loss: 876.402
[39,     1] loss: 869.222
[40,     1] loss: 850.610
[41,     1] loss: 878.018
[42,     1] loss: 887.452
[43,     1] loss: 803.512
[44,     1] loss: 863.398
[45,     1] loss: 823.573
[46,     1] loss: 832.569
[47,     1] loss: 822.005
[48,     1] loss: 819.944
[49,     1] loss: 776.811
[50,     1] loss: 773.499
[51,     1] loss: 850.436
[52,     1] loss: 694.100
[53,     1] loss: 743.995
[54,     1] loss: 825.486
[55,     1] loss: 732.798
[56,     1] loss: 799.760
[57,     1] loss: 734.788
[58,     1] loss: 757.339
[59,     1] loss: 681.823
[60,     1] loss: 776.402
[61,     1] loss: 834.479
[62,     1] loss: 664.158
[63,     1] loss: 837.904
[64,     1] loss: 684.784
[65,     1] loss: 689.299
[66,     1] loss: 611.307
[67,     1] loss: 675.151
[68,     1] loss: 671.862
[69,     1] loss: 567.128
[70,     1] loss: 660.794
[71,     1] loss: 621.932
[72,     1] loss: 566.761
[73,     1] loss: 684.227
[74,     1] loss: 716.808
[75,     1] loss: 553.276
[76,     1] loss: 661.439
[77,     1] loss: 550.199
[78,     1] loss: 491.252
[79,     1] loss: 573.351
[80,     1] loss: 536.321
[81,     1] loss: 479.439
Early stopping applied (best metric=0.6661831140518188)
Finished Training
Total time taken: 14.46488356590271
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1291.174
[2,     1] loss: 1282.955
[3,     1] loss: 1297.609
[4,     1] loss: 1279.850
[5,     1] loss: 1289.029
[6,     1] loss: 1278.373
[7,     1] loss: 1269.524
[8,     1] loss: 1255.213
[9,     1] loss: 1217.474
[10,     1] loss: 1172.305
[11,     1] loss: 1131.501
[12,     1] loss: 1103.352
[13,     1] loss: 1040.669
[14,     1] loss: 1085.801
[15,     1] loss: 1062.437
[16,     1] loss: 1056.581
[17,     1] loss: 1050.814
[18,     1] loss: 1029.062
[19,     1] loss: 1007.004
[20,     1] loss: 1052.830
[21,     1] loss: 1002.881
[22,     1] loss: 1059.465
[23,     1] loss: 977.758
[24,     1] loss: 1008.032
[25,     1] loss: 984.003
[26,     1] loss: 960.818
[27,     1] loss: 982.800
[28,     1] loss: 960.955
[29,     1] loss: 946.524
[30,     1] loss: 893.194
[31,     1] loss: 935.495
[32,     1] loss: 907.803
[33,     1] loss: 934.329
[34,     1] loss: 948.700
[35,     1] loss: 885.571
[36,     1] loss: 887.025
[37,     1] loss: 854.895
[38,     1] loss: 843.875
[39,     1] loss: 851.150
[40,     1] loss: 828.164
[41,     1] loss: 819.344
[42,     1] loss: 800.831
[43,     1] loss: 830.214
[44,     1] loss: 799.764
[45,     1] loss: 780.747
[46,     1] loss: 784.495
[47,     1] loss: 755.737
[48,     1] loss: 756.500
[49,     1] loss: 854.693
[50,     1] loss: 890.283
[51,     1] loss: 781.464
[52,     1] loss: 862.147
[53,     1] loss: 756.693
[54,     1] loss: 870.984
[55,     1] loss: 731.868
[56,     1] loss: 765.219
[57,     1] loss: 739.052
[58,     1] loss: 731.571
[59,     1] loss: 679.475
[60,     1] loss: 791.889
[61,     1] loss: 646.844
[62,     1] loss: 625.098
[63,     1] loss: 733.745
[64,     1] loss: 796.940
[65,     1] loss: 734.694
[66,     1] loss: 593.362
Early stopping applied (best metric=0.9697232246398926)
Finished Training
Total time taken: 11.596243381500244
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1289.186
[2,     1] loss: 1283.614
[3,     1] loss: 1286.063
[4,     1] loss: 1280.959
[5,     1] loss: 1285.002
[6,     1] loss: 1277.320
[7,     1] loss: 1269.516
[8,     1] loss: 1250.531
[9,     1] loss: 1220.480
[10,     1] loss: 1192.362
[11,     1] loss: 1129.351
[12,     1] loss: 1112.938
[13,     1] loss: 1121.167
[14,     1] loss: 1134.785
[15,     1] loss: 1137.510
[16,     1] loss: 1082.245
[17,     1] loss: 1060.016
[18,     1] loss: 1032.954
[19,     1] loss: 993.203
[20,     1] loss: 1035.819
[21,     1] loss: 1021.547
[22,     1] loss: 1049.087
[23,     1] loss: 961.149
[24,     1] loss: 982.149
[25,     1] loss: 919.943
[26,     1] loss: 1013.250
[27,     1] loss: 907.351
[28,     1] loss: 916.651
[29,     1] loss: 910.971
[30,     1] loss: 954.354
[31,     1] loss: 878.202
[32,     1] loss: 863.401
[33,     1] loss: 898.593
[34,     1] loss: 844.660
[35,     1] loss: 906.736
[36,     1] loss: 810.141
[37,     1] loss: 812.869
[38,     1] loss: 818.357
[39,     1] loss: 826.277
[40,     1] loss: 931.345
[41,     1] loss: 812.774
[42,     1] loss: 803.022
[43,     1] loss: 810.169
[44,     1] loss: 781.260
[45,     1] loss: 745.877
[46,     1] loss: 733.104
[47,     1] loss: 727.069
[48,     1] loss: 715.285
[49,     1] loss: 794.047
[50,     1] loss: 1046.822
[51,     1] loss: 764.244
[52,     1] loss: 887.221
[53,     1] loss: 800.168
[54,     1] loss: 865.907
[55,     1] loss: 870.148
[56,     1] loss: 763.550
[57,     1] loss: 799.576
[58,     1] loss: 856.409
[59,     1] loss: 727.083
[60,     1] loss: 768.373
[61,     1] loss: 671.413
Early stopping applied (best metric=0.9187712669372559)
Finished Training
Total time taken: 10.824228525161743
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1286.105
[2,     1] loss: 1287.479
[3,     1] loss: 1291.372
[4,     1] loss: 1284.174
[5,     1] loss: 1279.963
[6,     1] loss: 1285.824
[7,     1] loss: 1280.797
[8,     1] loss: 1268.063
[9,     1] loss: 1256.051
[10,     1] loss: 1234.273
[11,     1] loss: 1203.399
[12,     1] loss: 1177.550
[13,     1] loss: 1148.395
[14,     1] loss: 1148.895
[15,     1] loss: 1130.442
[16,     1] loss: 1117.534
[17,     1] loss: 1072.503
[18,     1] loss: 1177.256
[19,     1] loss: 1079.556
[20,     1] loss: 1121.527
[21,     1] loss: 1043.425
[22,     1] loss: 1052.343
[23,     1] loss: 1076.989
[24,     1] loss: 1031.075
[25,     1] loss: 1025.089
[26,     1] loss: 1025.520
[27,     1] loss: 1030.211
[28,     1] loss: 1005.879
[29,     1] loss: 1019.019
[30,     1] loss: 960.938
[31,     1] loss: 968.983
[32,     1] loss: 951.278
[33,     1] loss: 938.092
[34,     1] loss: 940.661
[35,     1] loss: 924.925
[36,     1] loss: 889.746
[37,     1] loss: 885.062
[38,     1] loss: 878.462
[39,     1] loss: 818.840
[40,     1] loss: 831.027
[41,     1] loss: 871.901
[42,     1] loss: 1065.403
[43,     1] loss: 1225.403
[44,     1] loss: 845.645
[45,     1] loss: 908.385
[46,     1] loss: 1052.610
[47,     1] loss: 982.543
[48,     1] loss: 911.926
[49,     1] loss: 938.941
[50,     1] loss: 973.666
[51,     1] loss: 983.402
[52,     1] loss: 906.512
[53,     1] loss: 895.367
[54,     1] loss: 876.604
[55,     1] loss: 918.689
[56,     1] loss: 811.413
Early stopping applied (best metric=0.7682408094406128)
Finished Training
Total time taken: 8.92025351524353
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1292.726
[2,     1] loss: 1289.850
[3,     1] loss: 1286.910
[4,     1] loss: 1289.130
[5,     1] loss: 1283.695
[6,     1] loss: 1279.108
[7,     1] loss: 1276.652
[8,     1] loss: 1262.890
[9,     1] loss: 1231.285
[10,     1] loss: 1197.164
[11,     1] loss: 1171.104
[12,     1] loss: 1160.539
[13,     1] loss: 1171.207
[14,     1] loss: 1117.166
[15,     1] loss: 1167.532
[16,     1] loss: 1075.398
[17,     1] loss: 1115.926
[18,     1] loss: 1081.213
[19,     1] loss: 1044.188
[20,     1] loss: 1061.153
[21,     1] loss: 1081.981
[22,     1] loss: 1066.779
[23,     1] loss: 1054.261
[24,     1] loss: 1016.674
[25,     1] loss: 1063.269
[26,     1] loss: 997.941
[27,     1] loss: 969.483
[28,     1] loss: 1025.985
[29,     1] loss: 1016.663
[30,     1] loss: 975.033
[31,     1] loss: 950.830
[32,     1] loss: 936.950
[33,     1] loss: 921.140
[34,     1] loss: 940.247
[35,     1] loss: 937.207
[36,     1] loss: 891.835
[37,     1] loss: 844.587
[38,     1] loss: 923.965
[39,     1] loss: 903.120
[40,     1] loss: 845.193
[41,     1] loss: 888.870
[42,     1] loss: 856.430
[43,     1] loss: 823.915
[44,     1] loss: 872.837
[45,     1] loss: 781.882
[46,     1] loss: 823.111
[47,     1] loss: 850.047
[48,     1] loss: 779.969
[49,     1] loss: 835.109
[50,     1] loss: 802.787
[51,     1] loss: 728.959
[52,     1] loss: 762.327
[53,     1] loss: 775.670
[54,     1] loss: 738.595
[55,     1] loss: 669.419
[56,     1] loss: 658.519
[57,     1] loss: 624.175
[58,     1] loss: 649.641
Early stopping applied (best metric=0.8062161207199097)
Finished Training
Total time taken: 9.178217887878418
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1294.314
[2,     1] loss: 1285.925
[3,     1] loss: 1286.906
[4,     1] loss: 1283.663
[5,     1] loss: 1285.942
[6,     1] loss: 1284.618
[7,     1] loss: 1282.914
[8,     1] loss: 1282.271
[9,     1] loss: 1283.222
[10,     1] loss: 1277.727
[11,     1] loss: 1275.958
[12,     1] loss: 1263.886
[13,     1] loss: 1251.710
[14,     1] loss: 1233.051
[15,     1] loss: 1200.071
[16,     1] loss: 1180.718
[17,     1] loss: 1163.977
[18,     1] loss: 1155.261
[19,     1] loss: 1132.237
[20,     1] loss: 1058.148
[21,     1] loss: 1079.421
[22,     1] loss: 1067.698
[23,     1] loss: 1078.400
[24,     1] loss: 1046.743
[25,     1] loss: 1016.639
[26,     1] loss: 1038.760
[27,     1] loss: 1006.993
[28,     1] loss: 1028.783
[29,     1] loss: 1020.507
[30,     1] loss: 962.062
[31,     1] loss: 933.900
[32,     1] loss: 896.880
[33,     1] loss: 1005.009
[34,     1] loss: 988.395
[35,     1] loss: 910.980
[36,     1] loss: 990.228
[37,     1] loss: 884.837
[38,     1] loss: 931.670
[39,     1] loss: 889.148
[40,     1] loss: 912.094
[41,     1] loss: 813.092
[42,     1] loss: 920.084
[43,     1] loss: 822.962
[44,     1] loss: 873.111
[45,     1] loss: 832.681
[46,     1] loss: 810.141
[47,     1] loss: 839.160
[48,     1] loss: 852.777
[49,     1] loss: 858.351
[50,     1] loss: 742.328
[51,     1] loss: 823.257
[52,     1] loss: 738.402
[53,     1] loss: 795.085
[54,     1] loss: 678.054
[55,     1] loss: 770.951
[56,     1] loss: 687.130
[57,     1] loss: 653.827
[58,     1] loss: 681.792
[59,     1] loss: 660.795
[60,     1] loss: 661.820
[61,     1] loss: 613.050
[62,     1] loss: 599.383
Early stopping applied (best metric=0.7621839642524719)
Finished Training
Total time taken: 10.747226476669312
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1285.609
[2,     1] loss: 1282.008
[3,     1] loss: 1280.870
[4,     1] loss: 1289.602
[5,     1] loss: 1274.739
[6,     1] loss: 1260.992
[7,     1] loss: 1251.879
[8,     1] loss: 1195.296
[9,     1] loss: 1154.816
[10,     1] loss: 1129.655
[11,     1] loss: 1085.268
[12,     1] loss: 1067.907
[13,     1] loss: 1140.178
[14,     1] loss: 1079.550
[15,     1] loss: 1058.125
[16,     1] loss: 1064.923
[17,     1] loss: 1019.444
[18,     1] loss: 1046.585
[19,     1] loss: 1027.649
[20,     1] loss: 1009.590
[21,     1] loss: 997.384
[22,     1] loss: 960.862
[23,     1] loss: 964.004
[24,     1] loss: 958.502
[25,     1] loss: 983.730
[26,     1] loss: 1001.742
[27,     1] loss: 915.722
[28,     1] loss: 970.021
[29,     1] loss: 905.823
[30,     1] loss: 940.400
[31,     1] loss: 921.875
[32,     1] loss: 868.942
[33,     1] loss: 955.283
[34,     1] loss: 870.660
[35,     1] loss: 862.977
[36,     1] loss: 897.195
[37,     1] loss: 963.597
[38,     1] loss: 909.763
[39,     1] loss: 827.851
[40,     1] loss: 857.830
[41,     1] loss: 824.712
[42,     1] loss: 802.980
[43,     1] loss: 900.383
[44,     1] loss: 835.343
[45,     1] loss: 772.803
[46,     1] loss: 853.366
[47,     1] loss: 804.026
[48,     1] loss: 787.910
[49,     1] loss: 774.381
[50,     1] loss: 807.047
[51,     1] loss: 695.172
[52,     1] loss: 733.642
[53,     1] loss: 798.589
[54,     1] loss: 752.416
[55,     1] loss: 684.216
[56,     1] loss: 694.738
[57,     1] loss: 813.910
[58,     1] loss: 792.372
Early stopping applied (best metric=0.8779383897781372)
Finished Training
Total time taken: 8.382176399230957
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1290.778
[2,     1] loss: 1284.532
[3,     1] loss: 1286.538
[4,     1] loss: 1282.565
[5,     1] loss: 1277.048
[6,     1] loss: 1263.022
[7,     1] loss: 1236.373
[8,     1] loss: 1191.690
[9,     1] loss: 1180.055
[10,     1] loss: 1155.620
[11,     1] loss: 1133.156
[12,     1] loss: 1110.551
[13,     1] loss: 1079.216
[14,     1] loss: 1055.358
[15,     1] loss: 1072.714
[16,     1] loss: 1020.089
[17,     1] loss: 1019.827
[18,     1] loss: 1018.871
[19,     1] loss: 1038.855
[20,     1] loss: 1010.896
[21,     1] loss: 981.772
[22,     1] loss: 1011.634
[23,     1] loss: 974.059
[24,     1] loss: 952.575
[25,     1] loss: 919.906
[26,     1] loss: 963.404
[27,     1] loss: 963.196
[28,     1] loss: 983.436
[29,     1] loss: 909.242
[30,     1] loss: 916.366
[31,     1] loss: 882.818
[32,     1] loss: 929.022
[33,     1] loss: 904.087
[34,     1] loss: 861.121
[35,     1] loss: 893.795
[36,     1] loss: 874.134
[37,     1] loss: 830.590
[38,     1] loss: 794.125
[39,     1] loss: 815.612
[40,     1] loss: 822.718
[41,     1] loss: 900.340
[42,     1] loss: 952.624
[43,     1] loss: 825.362
[44,     1] loss: 854.802
[45,     1] loss: 842.365
[46,     1] loss: 814.574
[47,     1] loss: 778.624
[48,     1] loss: 779.134
[49,     1] loss: 790.713
[50,     1] loss: 741.195
[51,     1] loss: 706.683
[52,     1] loss: 720.949
[53,     1] loss: 728.194
[54,     1] loss: 700.424
[55,     1] loss: 778.813
[56,     1] loss: 835.935
[57,     1] loss: 657.658
[58,     1] loss: 793.224
[59,     1] loss: 727.229
[60,     1] loss: 705.309
[61,     1] loss: 696.711
[62,     1] loss: 627.107
[63,     1] loss: 737.012
[64,     1] loss: 621.453
[65,     1] loss: 656.281
[66,     1] loss: 704.910
[67,     1] loss: 612.128
[68,     1] loss: 624.132
[69,     1] loss: 756.741
Early stopping applied (best metric=0.8271937370300293)
Finished Training
Total time taken: 9.49120020866394
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1283.635
[2,     1] loss: 1282.777
[3,     1] loss: 1281.163
[4,     1] loss: 1279.748
[5,     1] loss: 1270.781
[6,     1] loss: 1257.219
[7,     1] loss: 1228.053
[8,     1] loss: 1209.462
[9,     1] loss: 1112.683
[10,     1] loss: 1147.615
[11,     1] loss: 1104.755
[12,     1] loss: 1079.536
[13,     1] loss: 1055.953
[14,     1] loss: 1044.664
[15,     1] loss: 1018.899
[16,     1] loss: 1058.484
[17,     1] loss: 1007.469
[18,     1] loss: 1005.563
[19,     1] loss: 1029.461
[20,     1] loss: 994.792
[21,     1] loss: 1011.906
[22,     1] loss: 962.293
[23,     1] loss: 997.954
[24,     1] loss: 977.079
[25,     1] loss: 973.335
[26,     1] loss: 956.337
[27,     1] loss: 933.507
[28,     1] loss: 895.676
[29,     1] loss: 878.368
[30,     1] loss: 902.215
[31,     1] loss: 890.195
[32,     1] loss: 960.166
[33,     1] loss: 881.828
[34,     1] loss: 925.200
[35,     1] loss: 914.411
[36,     1] loss: 954.011
[37,     1] loss: 913.350
[38,     1] loss: 840.053
[39,     1] loss: 885.721
[40,     1] loss: 825.859
[41,     1] loss: 893.128
[42,     1] loss: 879.715
[43,     1] loss: 987.294
[44,     1] loss: 796.701
[45,     1] loss: 875.047
[46,     1] loss: 797.889
[47,     1] loss: 817.544
[48,     1] loss: 842.641
[49,     1] loss: 829.186
[50,     1] loss: 792.998
[51,     1] loss: 797.992
[52,     1] loss: 777.337
[53,     1] loss: 803.369
[54,     1] loss: 767.207
[55,     1] loss: 728.903
[56,     1] loss: 755.210
[57,     1] loss: 688.286
[58,     1] loss: 762.484
[59,     1] loss: 720.693
[60,     1] loss: 750.890
[61,     1] loss: 614.135
[62,     1] loss: 674.353
[63,     1] loss: 662.847
[64,     1] loss: 750.397
[65,     1] loss: 1126.483
[66,     1] loss: 750.797
[67,     1] loss: 863.391
[68,     1] loss: 744.001
[69,     1] loss: 833.821
[70,     1] loss: 867.189
[71,     1] loss: 758.313
[72,     1] loss: 807.098
[73,     1] loss: 812.973
[74,     1] loss: 730.813
[75,     1] loss: 739.135
[76,     1] loss: 681.077
[77,     1] loss: 696.213
[78,     1] loss: 724.224
[79,     1] loss: 683.812
[80,     1] loss: 652.036
Early stopping applied (best metric=0.8278213739395142)
Finished Training
Total time taken: 12.831273078918457
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1293.053
[2,     1] loss: 1299.306
[3,     1] loss: 1290.845
[4,     1] loss: 1288.003
[5,     1] loss: 1283.808
[6,     1] loss: 1284.903
[7,     1] loss: 1284.058
[8,     1] loss: 1285.640
[9,     1] loss: 1282.438
[10,     1] loss: 1280.109
[11,     1] loss: 1276.231
[12,     1] loss: 1273.000
[13,     1] loss: 1254.226
[14,     1] loss: 1233.486
[15,     1] loss: 1200.791
[16,     1] loss: 1176.774
[17,     1] loss: 1149.229
[18,     1] loss: 1134.244
[19,     1] loss: 1148.226
[20,     1] loss: 1070.739
[21,     1] loss: 1111.522
[22,     1] loss: 1105.681
[23,     1] loss: 1048.433
[24,     1] loss: 1073.427
[25,     1] loss: 1064.527
[26,     1] loss: 1055.944
[27,     1] loss: 1002.203
[28,     1] loss: 1020.099
[29,     1] loss: 1032.588
[30,     1] loss: 1013.617
[31,     1] loss: 969.125
[32,     1] loss: 970.204
[33,     1] loss: 950.661
[34,     1] loss: 1012.910
[35,     1] loss: 983.226
[36,     1] loss: 928.602
[37,     1] loss: 947.747
[38,     1] loss: 925.936
[39,     1] loss: 945.291
[40,     1] loss: 937.644
[41,     1] loss: 903.859
[42,     1] loss: 948.303
[43,     1] loss: 856.637
[44,     1] loss: 882.423
[45,     1] loss: 839.445
[46,     1] loss: 948.157
[47,     1] loss: 885.612
[48,     1] loss: 885.118
[49,     1] loss: 874.148
[50,     1] loss: 827.301
[51,     1] loss: 817.071
[52,     1] loss: 788.079
[53,     1] loss: 777.293
[54,     1] loss: 800.710
[55,     1] loss: 724.461
[56,     1] loss: 795.729
[57,     1] loss: 854.854
[58,     1] loss: 739.033
[59,     1] loss: 829.676
[60,     1] loss: 728.545
[61,     1] loss: 728.988
[62,     1] loss: 700.180
[63,     1] loss: 625.722
[64,     1] loss: 681.422
[65,     1] loss: 635.206
[66,     1] loss: 906.008
[67,     1] loss: 943.462
[68,     1] loss: 734.689
[69,     1] loss: 771.208
[70,     1] loss: 732.508
[71,     1] loss: 764.570
[72,     1] loss: 719.670
[73,     1] loss: 715.417
[74,     1] loss: 719.423
[75,     1] loss: 651.873
[76,     1] loss: 650.259
[77,     1] loss: 610.035
[78,     1] loss: 617.189
[79,     1] loss: 589.414
[80,     1] loss: 607.324
[81,     1] loss: 568.740
[82,     1] loss: 550.464
[83,     1] loss: 514.060
[84,     1] loss: 527.682
[85,     1] loss: 512.152
[86,     1] loss: 672.277
[87,     1] loss: 698.225
[88,     1] loss: 648.107
[89,     1] loss: 556.419
[90,     1] loss: 626.863
[91,     1] loss: 509.381
[92,     1] loss: 635.264
[93,     1] loss: 587.619
[94,     1] loss: 520.474
Early stopping applied (best metric=0.7031306624412537)
Finished Training
Total time taken: 14.192519426345825
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1288.208
[2,     1] loss: 1286.631
[3,     1] loss: 1293.880
[4,     1] loss: 1278.622
[5,     1] loss: 1282.660
[6,     1] loss: 1273.982
[7,     1] loss: 1253.293
[8,     1] loss: 1216.988
[9,     1] loss: 1206.537
[10,     1] loss: 1183.977
[11,     1] loss: 1120.095
[12,     1] loss: 1132.806
[13,     1] loss: 1123.848
[14,     1] loss: 1098.898
[15,     1] loss: 1064.647
[16,     1] loss: 1070.562
[17,     1] loss: 1052.012
[18,     1] loss: 1047.001
[19,     1] loss: 1023.795
[20,     1] loss: 1050.930
[21,     1] loss: 1066.886
[22,     1] loss: 1050.668
[23,     1] loss: 1056.434
[24,     1] loss: 1016.588
[25,     1] loss: 979.806
[26,     1] loss: 1024.053
[27,     1] loss: 984.878
[28,     1] loss: 974.741
[29,     1] loss: 998.761
[30,     1] loss: 955.742
[31,     1] loss: 943.446
[32,     1] loss: 920.108
[33,     1] loss: 947.782
[34,     1] loss: 961.537
[35,     1] loss: 890.383
[36,     1] loss: 933.236
[37,     1] loss: 887.031
[38,     1] loss: 879.748
[39,     1] loss: 943.245
[40,     1] loss: 990.612
[41,     1] loss: 861.943
[42,     1] loss: 934.050
[43,     1] loss: 837.686
[44,     1] loss: 905.400
[45,     1] loss: 832.527
[46,     1] loss: 846.274
[47,     1] loss: 867.610
[48,     1] loss: 825.562
[49,     1] loss: 770.754
[50,     1] loss: 817.660
[51,     1] loss: 727.805
[52,     1] loss: 769.580
[53,     1] loss: 795.729
[54,     1] loss: 719.375
[55,     1] loss: 723.780
[56,     1] loss: 777.712
[57,     1] loss: 797.945
[58,     1] loss: 734.718
[59,     1] loss: 734.419
[60,     1] loss: 739.961
[61,     1] loss: 676.068
[62,     1] loss: 704.112
[63,     1] loss: 836.860
[64,     1] loss: 614.040
[65,     1] loss: 742.378
[66,     1] loss: 701.343
[67,     1] loss: 595.833
[68,     1] loss: 687.438
[69,     1] loss: 597.803
[70,     1] loss: 730.736
[71,     1] loss: 616.729
[72,     1] loss: 542.031
[73,     1] loss: 531.898
[74,     1] loss: 599.378
[75,     1] loss: 541.332
[76,     1] loss: 532.553
[77,     1] loss: 642.216
[78,     1] loss: 762.323
[79,     1] loss: 1010.983
[80,     1] loss: 609.330
[81,     1] loss: 871.913
[82,     1] loss: 719.330
[83,     1] loss: 711.624
[84,     1] loss: 725.977
[85,     1] loss: 613.341
[86,     1] loss: 651.109
[87,     1] loss: 555.890
[88,     1] loss: 685.653
[89,     1] loss: 533.073
[90,     1] loss: 671.751
[91,     1] loss: 566.528
[92,     1] loss: 588.476
[93,     1] loss: 635.441
[94,     1] loss: 597.890
[95,     1] loss: 698.262
[96,     1] loss: 501.781
Early stopping applied (best metric=0.6590743064880371)
Finished Training
Total time taken: 15.36032485961914
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1288.331
[2,     1] loss: 1293.801
[3,     1] loss: 1288.945
[4,     1] loss: 1280.116
[5,     1] loss: 1288.930
[6,     1] loss: 1283.358
[7,     1] loss: 1277.401
[8,     1] loss: 1269.589
[9,     1] loss: 1260.586
[10,     1] loss: 1238.392
[11,     1] loss: 1200.112
[12,     1] loss: 1178.960
[13,     1] loss: 1167.723
[14,     1] loss: 1141.793
[15,     1] loss: 1094.332
[16,     1] loss: 1107.848
[17,     1] loss: 1038.213
[18,     1] loss: 1040.365
[19,     1] loss: 1061.256
[20,     1] loss: 1004.217
[21,     1] loss: 1040.232
[22,     1] loss: 1028.436
[23,     1] loss: 971.536
[24,     1] loss: 971.263
[25,     1] loss: 958.380
[26,     1] loss: 959.617
[27,     1] loss: 1004.653
[28,     1] loss: 1003.119
[29,     1] loss: 969.518
[30,     1] loss: 938.135
[31,     1] loss: 928.890
[32,     1] loss: 862.771
[33,     1] loss: 848.951
[34,     1] loss: 851.086
[35,     1] loss: 877.117
[36,     1] loss: 789.526
[37,     1] loss: 841.033
[38,     1] loss: 857.027
[39,     1] loss: 886.503
[40,     1] loss: 834.319
[41,     1] loss: 840.590
[42,     1] loss: 836.172
[43,     1] loss: 823.207
[44,     1] loss: 786.026
[45,     1] loss: 731.178
[46,     1] loss: 821.760
[47,     1] loss: 913.801
[48,     1] loss: 791.982
[49,     1] loss: 698.458
[50,     1] loss: 821.465
[51,     1] loss: 740.385
[52,     1] loss: 779.471
[53,     1] loss: 701.312
[54,     1] loss: 730.784
[55,     1] loss: 682.078
[56,     1] loss: 672.378
[57,     1] loss: 708.893
[58,     1] loss: 647.160
[59,     1] loss: 637.996
[60,     1] loss: 642.231
[61,     1] loss: 636.563
[62,     1] loss: 682.115
Early stopping applied (best metric=0.884351372718811)
Finished Training
Total time taken: 9.4961998462677
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1284.863
[2,     1] loss: 1284.186
[3,     1] loss: 1290.010
[4,     1] loss: 1286.856
[5,     1] loss: 1272.953
[6,     1] loss: 1265.011
[7,     1] loss: 1229.806
[8,     1] loss: 1179.638
[9,     1] loss: 1138.682
[10,     1] loss: 1141.370
[11,     1] loss: 1096.940
[12,     1] loss: 1044.042
[13,     1] loss: 1030.171
[14,     1] loss: 1036.322
[15,     1] loss: 1049.253
[16,     1] loss: 1008.270
[17,     1] loss: 1001.995
[18,     1] loss: 989.399
[19,     1] loss: 1035.852
[20,     1] loss: 980.804
[21,     1] loss: 996.641
[22,     1] loss: 971.231
[23,     1] loss: 924.548
[24,     1] loss: 914.534
[25,     1] loss: 887.367
[26,     1] loss: 878.225
[27,     1] loss: 902.371
[28,     1] loss: 829.072
[29,     1] loss: 919.886
[30,     1] loss: 857.633
[31,     1] loss: 912.602
[32,     1] loss: 811.156
[33,     1] loss: 876.286
[34,     1] loss: 814.218
[35,     1] loss: 869.190
[36,     1] loss: 829.560
[37,     1] loss: 845.842
[38,     1] loss: 800.803
[39,     1] loss: 830.526
[40,     1] loss: 733.424
[41,     1] loss: 773.940
[42,     1] loss: 728.579
[43,     1] loss: 734.091
[44,     1] loss: 686.125
[45,     1] loss: 709.336
[46,     1] loss: 758.104
[47,     1] loss: 678.034
[48,     1] loss: 731.327
[49,     1] loss: 661.624
[50,     1] loss: 706.275
[51,     1] loss: 691.343
[52,     1] loss: 656.138
[53,     1] loss: 658.169
[54,     1] loss: 601.717
[55,     1] loss: 588.548
[56,     1] loss: 630.001
[57,     1] loss: 734.411
[58,     1] loss: 749.082
[59,     1] loss: 577.198
[60,     1] loss: 645.581
Early stopping applied (best metric=0.8943410515785217)
Finished Training
Total time taken: 8.156171798706055
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1284.502
[2,     1] loss: 1282.428
[3,     1] loss: 1283.068
[4,     1] loss: 1282.495
[5,     1] loss: 1296.051
[6,     1] loss: 1273.553
[7,     1] loss: 1264.670
[8,     1] loss: 1240.433
[9,     1] loss: 1184.086
[10,     1] loss: 1153.068
[11,     1] loss: 1162.913
[12,     1] loss: 1075.730
[13,     1] loss: 1138.074
[14,     1] loss: 1035.648
[15,     1] loss: 1050.129
[16,     1] loss: 1078.971
[17,     1] loss: 1040.118
[18,     1] loss: 1028.393
[19,     1] loss: 1002.369
[20,     1] loss: 1040.837
[21,     1] loss: 988.130
[22,     1] loss: 1001.653
[23,     1] loss: 930.805
[24,     1] loss: 952.935
[25,     1] loss: 980.953
[26,     1] loss: 918.151
[27,     1] loss: 920.781
[28,     1] loss: 949.174
[29,     1] loss: 950.099
[30,     1] loss: 845.529
[31,     1] loss: 904.880
[32,     1] loss: 874.600
[33,     1] loss: 890.469
[34,     1] loss: 865.700
[35,     1] loss: 918.811
[36,     1] loss: 837.328
[37,     1] loss: 837.658
[38,     1] loss: 800.382
[39,     1] loss: 824.818
[40,     1] loss: 773.851
[41,     1] loss: 790.818
[42,     1] loss: 802.496
[43,     1] loss: 873.715
[44,     1] loss: 1129.064
[45,     1] loss: 894.671
[46,     1] loss: 1023.009
[47,     1] loss: 914.847
[48,     1] loss: 909.996
[49,     1] loss: 958.597
[50,     1] loss: 913.113
[51,     1] loss: 864.833
[52,     1] loss: 888.691
[53,     1] loss: 923.563
[54,     1] loss: 808.115
[55,     1] loss: 852.484
[56,     1] loss: 759.615
[57,     1] loss: 790.132
Early stopping applied (best metric=0.9072855710983276)
Finished Training
Total time taken: 8.957190752029419
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1285.712
[2,     1] loss: 1290.573
[3,     1] loss: 1288.732
[4,     1] loss: 1290.829
[5,     1] loss: 1282.302
[6,     1] loss: 1280.195
[7,     1] loss: 1273.962
[8,     1] loss: 1260.851
[9,     1] loss: 1225.089
[10,     1] loss: 1202.091
[11,     1] loss: 1161.976
[12,     1] loss: 1126.892
[13,     1] loss: 1079.581
[14,     1] loss: 1196.380
[15,     1] loss: 1063.628
[16,     1] loss: 1154.017
[17,     1] loss: 1116.939
[18,     1] loss: 1090.195
[19,     1] loss: 1082.058
[20,     1] loss: 1053.454
[21,     1] loss: 1089.991
[22,     1] loss: 1020.920
[23,     1] loss: 1025.273
[24,     1] loss: 1055.017
[25,     1] loss: 1028.285
[26,     1] loss: 996.053
[27,     1] loss: 1011.795
[28,     1] loss: 987.696
[29,     1] loss: 1014.323
[30,     1] loss: 966.914
[31,     1] loss: 932.531
[32,     1] loss: 944.625
[33,     1] loss: 925.599
[34,     1] loss: 907.107
[35,     1] loss: 911.326
[36,     1] loss: 954.707
[37,     1] loss: 880.515
[38,     1] loss: 894.516
[39,     1] loss: 878.195
[40,     1] loss: 958.989
[41,     1] loss: 926.226
[42,     1] loss: 868.647
[43,     1] loss: 870.885
[44,     1] loss: 844.201
[45,     1] loss: 872.239
[46,     1] loss: 905.412
[47,     1] loss: 804.032
[48,     1] loss: 822.289
[49,     1] loss: 808.416
[50,     1] loss: 735.488
[51,     1] loss: 783.308
[52,     1] loss: 908.514
[53,     1] loss: 1059.920
[54,     1] loss: 736.628
[55,     1] loss: 911.479
[56,     1] loss: 864.781
[57,     1] loss: 830.108
[58,     1] loss: 865.285
[59,     1] loss: 824.100
[60,     1] loss: 748.000
[61,     1] loss: 786.020
[62,     1] loss: 716.990
[63,     1] loss: 787.584
[64,     1] loss: 742.016
[65,     1] loss: 728.051
[66,     1] loss: 691.447
[67,     1] loss: 702.340
[68,     1] loss: 671.289
[69,     1] loss: 640.299
[70,     1] loss: 589.392
[71,     1] loss: 627.960
[72,     1] loss: 711.711
[73,     1] loss: 730.491
[74,     1] loss: 517.476
[75,     1] loss: 706.382
[76,     1] loss: 703.381
[77,     1] loss: 654.190
[78,     1] loss: 835.118
[79,     1] loss: 617.795
[80,     1] loss: 671.477
[81,     1] loss: 537.557
[82,     1] loss: 678.141
Early stopping applied (best metric=0.7144176959991455)
Finished Training
Total time taken: 12.550263404846191
{'Hydroxylation-K Validation Accuracy': 0.7479314420803782, 'Hydroxylation-K Validation Sensitivity': 0.6666666666666666, 'Hydroxylation-K Validation Specificity': 0.7684210526315789, 'Hydroxylation-K Validation Precision': 0.4265382338679552, 'Hydroxylation-K AUC ROC': 0.7983430799220274, 'Hydroxylation-K AUC PR': 0.5741041893319527, 'Hydroxylation-K MCC': 0.3777943216324209, 'Hydroxylation-K F1': 0.5163701572027731, 'Validation Loss (Hydroxylation-K)': 0.43865920305252076, 'Hydroxylation-P Validation Accuracy': 0.801676513882544, 'Hydroxylation-P Validation Sensitivity': 0.7556084656084656, 'Hydroxylation-P Validation Specificity': 0.8115541922290388, 'Hydroxylation-P Validation Precision': 0.4645438681259245, 'Hydroxylation-P AUC ROC': 0.8458518712487738, 'Hydroxylation-P AUC PR': 0.5860724805415911, 'Hydroxylation-P MCC': 0.4785354238063247, 'Hydroxylation-P F1': 0.5743931228592966, 'Validation Loss (Hydroxylation-P)': 0.37379897038141885, 'Validation Loss (total)': 0.8124581774075826, 'TimeToTrain': 11.00989154179891}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003974621333186314,
 'learning_rate_Hydroxylation-K': 0.0013025710985469859,
 'learning_rate_Hydroxylation-P': 0.008643894495758302,
 'log_base': 2.978076313148061,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3343734830,
 'sample_weights': [1.7859572034726006, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.439797306414233,
 'weight_decay_Hydroxylation-K': 6.658455070783766,
 'weight_decay_Hydroxylation-P': 0.45899280130511955}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1230.831
[2,     1] loss: 1233.161
[3,     1] loss: 1233.832
[4,     1] loss: 1230.205
[5,     1] loss: 1227.341
[6,     1] loss: 1232.727
[7,     1] loss: 1221.441
[8,     1] loss: 1215.108
[9,     1] loss: 1195.938
[10,     1] loss: 1173.631
[11,     1] loss: 1142.297
[12,     1] loss: 1089.177
[13,     1] loss: 1047.102
[14,     1] loss: 1043.078
[15,     1] loss: 1019.583
[16,     1] loss: 1054.532
[17,     1] loss: 1089.487
[18,     1] loss: 998.658
[19,     1] loss: 991.422
[20,     1] loss: 1028.339
[21,     1] loss: 1002.774
[22,     1] loss: 1004.771
[23,     1] loss: 964.527
[24,     1] loss: 1026.495
[25,     1] loss: 965.216
[26,     1] loss: 933.889
[27,     1] loss: 983.460
[28,     1] loss: 920.110
[29,     1] loss: 955.891
[30,     1] loss: 886.445
[31,     1] loss: 920.571
[32,     1] loss: 924.354
[33,     1] loss: 959.478
[34,     1] loss: 901.493
[35,     1] loss: 909.757
[36,     1] loss: 884.156
[37,     1] loss: 872.888
[38,     1] loss: 855.964
[39,     1] loss: 813.743
[40,     1] loss: 842.158
[41,     1] loss: 821.441
[42,     1] loss: 787.182
[43,     1] loss: 867.240
[44,     1] loss: 832.903
[45,     1] loss: 770.812
[46,     1] loss: 849.580
[47,     1] loss: 766.493
[48,     1] loss: 706.990
[49,     1] loss: 763.101
[50,     1] loss: 750.193
[51,     1] loss: 763.743
[52,     1] loss: 735.443
[53,     1] loss: 752.548
[54,     1] loss: 703.771
[55,     1] loss: 685.721
[56,     1] loss: 724.013
[57,     1] loss: 718.968
[58,     1] loss: 650.741
[59,     1] loss: 632.166
[60,     1] loss: 627.337
[61,     1] loss: 975.095
Early stopping applied (best metric=0.7686203718185425)
Finished Training
Total time taken: 9.085191488265991
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1235.632
[2,     1] loss: 1231.910
[3,     1] loss: 1245.426
[4,     1] loss: 1230.555
[5,     1] loss: 1232.123
[6,     1] loss: 1223.139
[7,     1] loss: 1220.056
[8,     1] loss: 1202.213
[9,     1] loss: 1170.255
[10,     1] loss: 1127.585
[11,     1] loss: 1095.937
[12,     1] loss: 1074.872
[13,     1] loss: 1073.157
[14,     1] loss: 1037.140
[15,     1] loss: 1006.549
[16,     1] loss: 1015.997
[17,     1] loss: 1021.370
[18,     1] loss: 962.850
[19,     1] loss: 952.552
[20,     1] loss: 941.198
[21,     1] loss: 973.246
[22,     1] loss: 932.577
[23,     1] loss: 915.889
[24,     1] loss: 917.481
[25,     1] loss: 892.868
[26,     1] loss: 955.987
[27,     1] loss: 926.766
[28,     1] loss: 933.464
[29,     1] loss: 870.948
[30,     1] loss: 875.487
[31,     1] loss: 859.745
[32,     1] loss: 855.830
[33,     1] loss: 881.805
[34,     1] loss: 828.623
[35,     1] loss: 798.150
[36,     1] loss: 839.665
[37,     1] loss: 815.749
[38,     1] loss: 829.285
[39,     1] loss: 841.236
[40,     1] loss: 832.727
[41,     1] loss: 787.879
[42,     1] loss: 844.593
[43,     1] loss: 816.755
[44,     1] loss: 792.029
[45,     1] loss: 812.316
[46,     1] loss: 797.411
[47,     1] loss: 741.454
Early stopping applied (best metric=0.9446556568145752)
Finished Training
Total time taken: 6.72014045715332
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1235.309
[2,     1] loss: 1230.156
[3,     1] loss: 1229.359
[4,     1] loss: 1232.051
[5,     1] loss: 1224.439
[6,     1] loss: 1222.236
[7,     1] loss: 1210.567
[8,     1] loss: 1190.147
[9,     1] loss: 1145.431
[10,     1] loss: 1076.645
[11,     1] loss: 1064.836
[12,     1] loss: 1057.642
[13,     1] loss: 1016.191
[14,     1] loss: 980.353
[15,     1] loss: 1003.135
[16,     1] loss: 987.901
[17,     1] loss: 969.844
[18,     1] loss: 969.962
[19,     1] loss: 922.794
[20,     1] loss: 956.847
[21,     1] loss: 941.577
[22,     1] loss: 896.551
[23,     1] loss: 927.537
[24,     1] loss: 855.684
[25,     1] loss: 898.175
[26,     1] loss: 882.005
[27,     1] loss: 941.117
[28,     1] loss: 869.008
[29,     1] loss: 889.198
[30,     1] loss: 836.092
[31,     1] loss: 826.627
[32,     1] loss: 768.716
[33,     1] loss: 848.670
[34,     1] loss: 784.548
[35,     1] loss: 842.829
[36,     1] loss: 825.402
[37,     1] loss: 729.932
[38,     1] loss: 788.092
[39,     1] loss: 751.181
[40,     1] loss: 724.901
[41,     1] loss: 808.119
[42,     1] loss: 729.824
[43,     1] loss: 693.199
[44,     1] loss: 680.053
[45,     1] loss: 673.867
[46,     1] loss: 635.614
[47,     1] loss: 716.820
[48,     1] loss: 1142.341
Early stopping applied (best metric=0.945627748966217)
Finished Training
Total time taken: 7.816164493560791
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.459
[2,     1] loss: 1231.890
[3,     1] loss: 1231.194
[4,     1] loss: 1230.939
[5,     1] loss: 1228.334
[6,     1] loss: 1225.577
[7,     1] loss: 1226.141
[8,     1] loss: 1215.397
[9,     1] loss: 1197.096
[10,     1] loss: 1178.085
[11,     1] loss: 1133.431
[12,     1] loss: 1121.103
[13,     1] loss: 1091.910
[14,     1] loss: 1075.892
[15,     1] loss: 1021.343
[16,     1] loss: 1015.427
[17,     1] loss: 1024.948
[18,     1] loss: 983.844
[19,     1] loss: 1020.982
[20,     1] loss: 1024.244
[21,     1] loss: 967.486
[22,     1] loss: 983.829
[23,     1] loss: 964.034
[24,     1] loss: 987.004
[25,     1] loss: 977.376
[26,     1] loss: 921.223
[27,     1] loss: 926.753
[28,     1] loss: 970.999
[29,     1] loss: 933.748
[30,     1] loss: 929.116
[31,     1] loss: 958.134
[32,     1] loss: 920.992
[33,     1] loss: 933.773
[34,     1] loss: 875.158
[35,     1] loss: 880.934
[36,     1] loss: 880.714
[37,     1] loss: 892.608
[38,     1] loss: 925.294
[39,     1] loss: 814.220
[40,     1] loss: 854.792
[41,     1] loss: 865.339
[42,     1] loss: 850.581
[43,     1] loss: 867.669
[44,     1] loss: 830.515
[45,     1] loss: 827.825
[46,     1] loss: 813.590
[47,     1] loss: 873.530
[48,     1] loss: 826.419
[49,     1] loss: 785.461
[50,     1] loss: 754.053
[51,     1] loss: 786.530
[52,     1] loss: 810.196
[53,     1] loss: 909.274
[54,     1] loss: 916.017
[55,     1] loss: 766.350
[56,     1] loss: 844.266
[57,     1] loss: 809.629
[58,     1] loss: 763.188
[59,     1] loss: 785.985
[60,     1] loss: 750.386
[61,     1] loss: 751.645
[62,     1] loss: 696.772
[63,     1] loss: 720.724
[64,     1] loss: 690.799
[65,     1] loss: 681.487
[66,     1] loss: 651.359
[67,     1] loss: 618.213
[68,     1] loss: 655.627
[69,     1] loss: 946.462
[70,     1] loss: 1613.849
[71,     1] loss: 779.396
[72,     1] loss: 863.871
[73,     1] loss: 1030.500
[74,     1] loss: 1008.068
[75,     1] loss: 1007.784
[76,     1] loss: 1024.188
[77,     1] loss: 1006.173
[78,     1] loss: 987.592
[79,     1] loss: 936.921
[80,     1] loss: 963.815
[81,     1] loss: 915.557
Early stopping applied (best metric=0.7508615851402283)
Finished Training
Total time taken: 11.050232410430908
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1232.290
[2,     1] loss: 1233.160
[3,     1] loss: 1232.746
[4,     1] loss: 1230.329
[5,     1] loss: 1218.442
[6,     1] loss: 1211.753
[7,     1] loss: 1207.850
[8,     1] loss: 1160.616
[9,     1] loss: 1126.554
[10,     1] loss: 1118.804
[11,     1] loss: 1054.017
[12,     1] loss: 1104.348
[13,     1] loss: 1025.126
[14,     1] loss: 1025.847
[15,     1] loss: 1022.594
[16,     1] loss: 1070.625
[17,     1] loss: 981.720
[18,     1] loss: 1061.397
[19,     1] loss: 986.016
[20,     1] loss: 1014.627
[21,     1] loss: 993.907
[22,     1] loss: 966.849
[23,     1] loss: 942.247
[24,     1] loss: 959.702
[25,     1] loss: 950.624
[26,     1] loss: 942.415
[27,     1] loss: 918.231
[28,     1] loss: 900.670
[29,     1] loss: 909.667
[30,     1] loss: 850.070
[31,     1] loss: 879.458
[32,     1] loss: 875.218
[33,     1] loss: 899.471
[34,     1] loss: 905.189
[35,     1] loss: 899.849
[36,     1] loss: 851.718
[37,     1] loss: 953.671
[38,     1] loss: 837.102
[39,     1] loss: 887.199
[40,     1] loss: 883.428
[41,     1] loss: 779.051
[42,     1] loss: 855.517
[43,     1] loss: 812.246
[44,     1] loss: 795.117
[45,     1] loss: 799.123
[46,     1] loss: 780.385
[47,     1] loss: 768.698
[48,     1] loss: 758.982
[49,     1] loss: 760.139
[50,     1] loss: 879.218
[51,     1] loss: 919.353
[52,     1] loss: 752.959
[53,     1] loss: 817.256
[54,     1] loss: 736.469
[55,     1] loss: 792.556
[56,     1] loss: 735.279
[57,     1] loss: 778.004
[58,     1] loss: 776.880
[59,     1] loss: 720.893
[60,     1] loss: 751.369
[61,     1] loss: 673.076
[62,     1] loss: 670.007
[63,     1] loss: 724.671
[64,     1] loss: 665.141
[65,     1] loss: 668.162
[66,     1] loss: 715.146
[67,     1] loss: 576.477
[68,     1] loss: 605.041
[69,     1] loss: 683.378
[70,     1] loss: 802.556
[71,     1] loss: 796.844
[72,     1] loss: 654.887
[73,     1] loss: 733.278
[74,     1] loss: 628.321
[75,     1] loss: 716.928
[76,     1] loss: 648.964
[77,     1] loss: 690.393
[78,     1] loss: 579.101
[79,     1] loss: 578.337
[80,     1] loss: 601.229
[81,     1] loss: 539.358
[82,     1] loss: 500.149
[83,     1] loss: 542.285
[84,     1] loss: 481.456
[85,     1] loss: 472.399
[86,     1] loss: 527.111
[87,     1] loss: 748.989
[88,     1] loss: 1414.863
[89,     1] loss: 571.611
[90,     1] loss: 1023.972
[91,     1] loss: 776.185
[92,     1] loss: 837.969
[93,     1] loss: 920.741
[94,     1] loss: 848.453
[95,     1] loss: 778.880
[96,     1] loss: 792.413
[97,     1] loss: 841.613
Early stopping applied (best metric=0.7160810232162476)
Finished Training
Total time taken: 14.236300468444824
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.794
[2,     1] loss: 1233.866
[3,     1] loss: 1227.963
[4,     1] loss: 1226.815
[5,     1] loss: 1229.214
[6,     1] loss: 1221.119
[7,     1] loss: 1215.026
[8,     1] loss: 1198.121
[9,     1] loss: 1160.262
[10,     1] loss: 1127.318
[11,     1] loss: 1076.560
[12,     1] loss: 1076.957
[13,     1] loss: 1034.445
[14,     1] loss: 1021.772
[15,     1] loss: 1029.940
[16,     1] loss: 997.145
[17,     1] loss: 987.987
[18,     1] loss: 966.323
[19,     1] loss: 1007.042
[20,     1] loss: 948.816
[21,     1] loss: 996.985
[22,     1] loss: 935.831
[23,     1] loss: 968.962
[24,     1] loss: 901.126
[25,     1] loss: 971.977
[26,     1] loss: 895.615
[27,     1] loss: 961.611
[28,     1] loss: 877.038
[29,     1] loss: 897.698
[30,     1] loss: 902.387
[31,     1] loss: 825.052
[32,     1] loss: 953.011
[33,     1] loss: 861.886
[34,     1] loss: 864.343
[35,     1] loss: 883.034
[36,     1] loss: 838.093
[37,     1] loss: 865.258
[38,     1] loss: 840.673
[39,     1] loss: 822.983
[40,     1] loss: 818.616
[41,     1] loss: 770.657
[42,     1] loss: 816.222
[43,     1] loss: 811.079
[44,     1] loss: 836.170
[45,     1] loss: 900.906
[46,     1] loss: 816.722
[47,     1] loss: 843.573
[48,     1] loss: 772.507
[49,     1] loss: 762.081
[50,     1] loss: 782.307
[51,     1] loss: 748.035
[52,     1] loss: 754.891
[53,     1] loss: 758.537
[54,     1] loss: 700.475
[55,     1] loss: 750.969
[56,     1] loss: 674.659
[57,     1] loss: 776.226
[58,     1] loss: 893.597
[59,     1] loss: 689.147
[60,     1] loss: 824.638
[61,     1] loss: 741.827
Early stopping applied (best metric=0.7710336446762085)
Finished Training
Total time taken: 8.82118844985962
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1231.463
[2,     1] loss: 1233.543
[3,     1] loss: 1235.937
[4,     1] loss: 1232.164
[5,     1] loss: 1229.322
[6,     1] loss: 1226.042
[7,     1] loss: 1227.398
[8,     1] loss: 1217.213
[9,     1] loss: 1201.997
[10,     1] loss: 1173.491
[11,     1] loss: 1136.942
[12,     1] loss: 1104.756
[13,     1] loss: 1053.314
[14,     1] loss: 1020.222
[15,     1] loss: 1180.370
[16,     1] loss: 1038.964
[17,     1] loss: 1156.099
[18,     1] loss: 1018.338
[19,     1] loss: 1051.508
[20,     1] loss: 1040.664
[21,     1] loss: 1014.749
[22,     1] loss: 1015.602
[23,     1] loss: 1020.072
[24,     1] loss: 1007.465
[25,     1] loss: 1004.533
[26,     1] loss: 999.363
[27,     1] loss: 993.422
[28,     1] loss: 962.678
[29,     1] loss: 935.908
[30,     1] loss: 910.631
[31,     1] loss: 895.950
[32,     1] loss: 879.919
[33,     1] loss: 887.153
[34,     1] loss: 891.370
[35,     1] loss: 928.325
[36,     1] loss: 900.223
[37,     1] loss: 885.890
[38,     1] loss: 811.074
[39,     1] loss: 825.138
[40,     1] loss: 874.607
[41,     1] loss: 854.832
[42,     1] loss: 818.912
[43,     1] loss: 865.288
[44,     1] loss: 841.614
[45,     1] loss: 767.140
[46,     1] loss: 802.209
[47,     1] loss: 763.571
[48,     1] loss: 789.167
[49,     1] loss: 749.317
[50,     1] loss: 731.184
[51,     1] loss: 764.681
[52,     1] loss: 727.537
[53,     1] loss: 828.717
[54,     1] loss: 1257.487
[55,     1] loss: 759.679
[56,     1] loss: 1038.111
[57,     1] loss: 877.041
[58,     1] loss: 916.551
[59,     1] loss: 929.400
[60,     1] loss: 906.303
[61,     1] loss: 864.986
[62,     1] loss: 806.554
[63,     1] loss: 827.498
[64,     1] loss: 776.597
[65,     1] loss: 793.529
[66,     1] loss: 811.097
[67,     1] loss: 755.786
[68,     1] loss: 772.749
[69,     1] loss: 753.957
[70,     1] loss: 759.692
[71,     1] loss: 747.638
[72,     1] loss: 726.026
[73,     1] loss: 684.810
[74,     1] loss: 701.522
[75,     1] loss: 695.487
[76,     1] loss: 699.725
[77,     1] loss: 655.980
[78,     1] loss: 692.716
[79,     1] loss: 638.229
[80,     1] loss: 836.142
[81,     1] loss: 867.487
[82,     1] loss: 659.139
[83,     1] loss: 735.094
[84,     1] loss: 707.905
[85,     1] loss: 742.014
[86,     1] loss: 636.498
[87,     1] loss: 701.917
[88,     1] loss: 663.236
Early stopping applied (best metric=0.7735769748687744)
Finished Training
Total time taken: 13.111276388168335
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1230.539
[2,     1] loss: 1232.969
[3,     1] loss: 1236.462
[4,     1] loss: 1226.040
[5,     1] loss: 1231.580
[6,     1] loss: 1226.023
[7,     1] loss: 1214.886
[8,     1] loss: 1194.353
[9,     1] loss: 1158.173
[10,     1] loss: 1138.087
[11,     1] loss: 1106.910
[12,     1] loss: 1040.650
[13,     1] loss: 1002.934
[14,     1] loss: 1030.725
[15,     1] loss: 1019.858
[16,     1] loss: 1019.335
[17,     1] loss: 1045.742
[18,     1] loss: 1001.789
[19,     1] loss: 990.546
[20,     1] loss: 974.424
[21,     1] loss: 1003.212
[22,     1] loss: 959.012
[23,     1] loss: 912.161
[24,     1] loss: 979.845
[25,     1] loss: 954.720
[26,     1] loss: 977.510
[27,     1] loss: 927.905
[28,     1] loss: 949.550
[29,     1] loss: 898.778
[30,     1] loss: 901.507
[31,     1] loss: 943.809
[32,     1] loss: 875.211
[33,     1] loss: 889.554
[34,     1] loss: 901.007
[35,     1] loss: 837.898
[36,     1] loss: 867.184
[37,     1] loss: 836.410
[38,     1] loss: 850.590
[39,     1] loss: 788.709
[40,     1] loss: 875.792
[41,     1] loss: 862.870
[42,     1] loss: 807.419
[43,     1] loss: 801.683
[44,     1] loss: 809.267
[45,     1] loss: 837.477
[46,     1] loss: 714.733
[47,     1] loss: 752.746
[48,     1] loss: 909.386
[49,     1] loss: 909.710
[50,     1] loss: 735.972
[51,     1] loss: 817.208
[52,     1] loss: 746.575
[53,     1] loss: 820.916
[54,     1] loss: 756.530
[55,     1] loss: 733.298
Early stopping applied (best metric=0.7979066371917725)
Finished Training
Total time taken: 8.69518232345581
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.133
[2,     1] loss: 1234.129
[3,     1] loss: 1230.508
[4,     1] loss: 1235.784
[5,     1] loss: 1229.246
[6,     1] loss: 1226.905
[7,     1] loss: 1225.636
[8,     1] loss: 1223.515
[9,     1] loss: 1209.176
[10,     1] loss: 1184.089
[11,     1] loss: 1172.666
[12,     1] loss: 1148.885
[13,     1] loss: 1105.210
[14,     1] loss: 1096.206
[15,     1] loss: 1047.861
[16,     1] loss: 1048.202
[17,     1] loss: 1005.393
[18,     1] loss: 994.112
[19,     1] loss: 962.834
[20,     1] loss: 1012.771
[21,     1] loss: 1048.589
[22,     1] loss: 982.790
[23,     1] loss: 1011.078
[24,     1] loss: 988.465
[25,     1] loss: 975.874
[26,     1] loss: 956.149
[27,     1] loss: 950.162
[28,     1] loss: 933.828
[29,     1] loss: 964.102
[30,     1] loss: 865.506
[31,     1] loss: 913.654
[32,     1] loss: 865.308
[33,     1] loss: 826.673
[34,     1] loss: 844.447
[35,     1] loss: 875.288
[36,     1] loss: 904.289
[37,     1] loss: 863.175
[38,     1] loss: 865.960
[39,     1] loss: 828.878
[40,     1] loss: 853.854
[41,     1] loss: 828.180
[42,     1] loss: 788.651
[43,     1] loss: 730.470
[44,     1] loss: 789.408
[45,     1] loss: 727.300
[46,     1] loss: 864.963
[47,     1] loss: 1160.309
[48,     1] loss: 866.585
[49,     1] loss: 959.776
[50,     1] loss: 935.272
[51,     1] loss: 920.557
[52,     1] loss: 899.432
[53,     1] loss: 920.741
[54,     1] loss: 851.068
[55,     1] loss: 821.628
[56,     1] loss: 869.221
[57,     1] loss: 819.559
Early stopping applied (best metric=0.8787418603897095)
Finished Training
Total time taken: 8.273174524307251
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1237.002
[2,     1] loss: 1238.787
[3,     1] loss: 1228.343
[4,     1] loss: 1231.828
[5,     1] loss: 1231.493
[6,     1] loss: 1231.998
[7,     1] loss: 1230.852
[8,     1] loss: 1229.972
[9,     1] loss: 1224.391
[10,     1] loss: 1224.869
[11,     1] loss: 1206.165
[12,     1] loss: 1196.987
[13,     1] loss: 1158.838
[14,     1] loss: 1135.338
[15,     1] loss: 1105.635
[16,     1] loss: 1070.632
[17,     1] loss: 994.466
[18,     1] loss: 1006.814
[19,     1] loss: 1028.217
[20,     1] loss: 981.396
[21,     1] loss: 959.989
[22,     1] loss: 987.836
[23,     1] loss: 1031.507
[24,     1] loss: 949.448
[25,     1] loss: 965.688
[26,     1] loss: 945.285
[27,     1] loss: 921.183
[28,     1] loss: 898.151
[29,     1] loss: 910.174
[30,     1] loss: 864.761
[31,     1] loss: 885.474
[32,     1] loss: 916.617
[33,     1] loss: 882.004
[34,     1] loss: 860.089
[35,     1] loss: 877.698
[36,     1] loss: 848.202
[37,     1] loss: 867.410
[38,     1] loss: 834.808
[39,     1] loss: 841.221
[40,     1] loss: 814.252
[41,     1] loss: 808.015
[42,     1] loss: 772.651
[43,     1] loss: 789.404
[44,     1] loss: 781.468
[45,     1] loss: 730.088
[46,     1] loss: 710.996
[47,     1] loss: 789.360
[48,     1] loss: 793.387
[49,     1] loss: 961.592
[50,     1] loss: 956.708
[51,     1] loss: 822.410
[52,     1] loss: 868.366
[53,     1] loss: 888.738
[54,     1] loss: 828.136
[55,     1] loss: 814.710
[56,     1] loss: 774.957
[57,     1] loss: 789.343
[58,     1] loss: 748.351
[59,     1] loss: 746.196
[60,     1] loss: 740.036
[61,     1] loss: 705.456
[62,     1] loss: 690.594
[63,     1] loss: 721.517
[64,     1] loss: 736.187
[65,     1] loss: 723.210
[66,     1] loss: 703.466
[67,     1] loss: 697.351
[68,     1] loss: 682.090
[69,     1] loss: 708.510
[70,     1] loss: 607.000
[71,     1] loss: 650.655
[72,     1] loss: 595.213
[73,     1] loss: 586.915
[74,     1] loss: 591.944
[75,     1] loss: 670.151
[76,     1] loss: 837.237
[77,     1] loss: 684.225
[78,     1] loss: 637.466
[79,     1] loss: 762.797
[80,     1] loss: 598.645
[81,     1] loss: 715.846
[82,     1] loss: 567.059
[83,     1] loss: 592.708
[84,     1] loss: 560.951
Early stopping applied (best metric=0.8332526683807373)
Finished Training
Total time taken: 12.257261037826538
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.905
[2,     1] loss: 1234.855
[3,     1] loss: 1237.854
[4,     1] loss: 1224.180
[5,     1] loss: 1225.663
[6,     1] loss: 1207.994
[7,     1] loss: 1167.064
[8,     1] loss: 1131.295
[9,     1] loss: 1081.976
[10,     1] loss: 1053.508
[11,     1] loss: 1109.637
[12,     1] loss: 1023.761
[13,     1] loss: 1078.978
[14,     1] loss: 1004.980
[15,     1] loss: 1023.339
[16,     1] loss: 986.023
[17,     1] loss: 1032.622
[18,     1] loss: 1006.065
[19,     1] loss: 997.243
[20,     1] loss: 988.138
[21,     1] loss: 940.180
[22,     1] loss: 968.321
[23,     1] loss: 955.205
[24,     1] loss: 926.434
[25,     1] loss: 945.852
[26,     1] loss: 911.632
[27,     1] loss: 911.557
[28,     1] loss: 872.865
[29,     1] loss: 906.360
[30,     1] loss: 858.504
[31,     1] loss: 834.010
[32,     1] loss: 852.091
[33,     1] loss: 777.435
[34,     1] loss: 814.672
[35,     1] loss: 1042.140
[36,     1] loss: 850.742
[37,     1] loss: 871.113
[38,     1] loss: 855.050
[39,     1] loss: 870.489
[40,     1] loss: 842.771
[41,     1] loss: 860.666
[42,     1] loss: 813.916
[43,     1] loss: 830.963
[44,     1] loss: 802.278
[45,     1] loss: 735.482
[46,     1] loss: 786.719
[47,     1] loss: 748.543
[48,     1] loss: 777.247
[49,     1] loss: 766.482
[50,     1] loss: 733.141
[51,     1] loss: 676.778
[52,     1] loss: 720.027
[53,     1] loss: 728.473
[54,     1] loss: 827.474
[55,     1] loss: 982.114
[56,     1] loss: 735.266
[57,     1] loss: 842.013
[58,     1] loss: 827.993
[59,     1] loss: 782.294
[60,     1] loss: 811.113
[61,     1] loss: 805.440
[62,     1] loss: 704.932
[63,     1] loss: 875.402
[64,     1] loss: 704.476
[65,     1] loss: 713.962
[66,     1] loss: 671.885
[67,     1] loss: 674.992
[68,     1] loss: 642.068
[69,     1] loss: 673.800
[70,     1] loss: 612.918
[71,     1] loss: 593.933
[72,     1] loss: 642.020
[73,     1] loss: 727.973
[74,     1] loss: 783.557
[75,     1] loss: 580.605
[76,     1] loss: 809.964
[77,     1] loss: 620.317
[78,     1] loss: 723.919
[79,     1] loss: 600.043
[80,     1] loss: 673.573
[81,     1] loss: 552.645
[82,     1] loss: 602.193
[83,     1] loss: 537.196
[84,     1] loss: 539.697
[85,     1] loss: 506.452
[86,     1] loss: 536.771
[87,     1] loss: 554.365
[88,     1] loss: 548.323
[89,     1] loss: 600.214
[90,     1] loss: 485.950
[91,     1] loss: 473.468
[92,     1] loss: 578.625
[93,     1] loss: 541.508
[94,     1] loss: 513.784
[95,     1] loss: 418.186
[96,     1] loss: 574.900
[97,     1] loss: 688.984
[98,     1] loss: 496.948
[99,     1] loss: 484.034
[100,     1] loss: 566.103
[101,     1] loss: 437.197
Early stopping applied (best metric=0.826870322227478)
Finished Training
Total time taken: 15.717331171035767
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.362
[2,     1] loss: 1232.052
[3,     1] loss: 1225.130
[4,     1] loss: 1234.227
[5,     1] loss: 1223.153
[6,     1] loss: 1219.063
[7,     1] loss: 1202.022
[8,     1] loss: 1174.107
[9,     1] loss: 1127.602
[10,     1] loss: 1142.107
[11,     1] loss: 1074.377
[12,     1] loss: 1123.914
[13,     1] loss: 1035.933
[14,     1] loss: 1044.505
[15,     1] loss: 1067.688
[16,     1] loss: 1061.531
[17,     1] loss: 1037.547
[18,     1] loss: 986.897
[19,     1] loss: 1037.683
[20,     1] loss: 1004.907
[21,     1] loss: 970.476
[22,     1] loss: 978.416
[23,     1] loss: 994.306
[24,     1] loss: 965.017
[25,     1] loss: 971.488
[26,     1] loss: 912.987
[27,     1] loss: 961.993
[28,     1] loss: 891.655
[29,     1] loss: 864.971
[30,     1] loss: 889.167
[31,     1] loss: 912.854
[32,     1] loss: 926.528
[33,     1] loss: 875.756
[34,     1] loss: 828.007
[35,     1] loss: 835.150
[36,     1] loss: 820.100
[37,     1] loss: 850.352
[38,     1] loss: 872.673
[39,     1] loss: 925.353
[40,     1] loss: 818.421
[41,     1] loss: 809.443
[42,     1] loss: 823.960
[43,     1] loss: 802.274
[44,     1] loss: 824.186
[45,     1] loss: 774.270
[46,     1] loss: 792.048
[47,     1] loss: 753.378
[48,     1] loss: 752.695
[49,     1] loss: 829.552
[50,     1] loss: 794.934
[51,     1] loss: 755.310
[52,     1] loss: 788.290
[53,     1] loss: 705.859
[54,     1] loss: 745.113
[55,     1] loss: 714.980
[56,     1] loss: 671.224
[57,     1] loss: 752.929
[58,     1] loss: 744.625
[59,     1] loss: 662.152
[60,     1] loss: 651.205
[61,     1] loss: 708.557
[62,     1] loss: 776.834
[63,     1] loss: 810.571
[64,     1] loss: 666.326
[65,     1] loss: 707.108
[66,     1] loss: 633.790
[67,     1] loss: 704.953
[68,     1] loss: 648.764
[69,     1] loss: 604.084
[70,     1] loss: 629.084
[71,     1] loss: 557.331
[72,     1] loss: 591.896
[73,     1] loss: 798.458
[74,     1] loss: 1230.967
[75,     1] loss: 639.273
[76,     1] loss: 809.259
[77,     1] loss: 741.727
[78,     1] loss: 771.637
[79,     1] loss: 801.131
Early stopping applied (best metric=0.8274941444396973)
Finished Training
Total time taken: 11.625248193740845
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1235.624
[2,     1] loss: 1244.345
[3,     1] loss: 1228.133
[4,     1] loss: 1232.478
[5,     1] loss: 1233.189
[6,     1] loss: 1228.088
[7,     1] loss: 1226.251
[8,     1] loss: 1224.394
[9,     1] loss: 1209.452
[10,     1] loss: 1196.342
[11,     1] loss: 1164.121
[12,     1] loss: 1114.186
[13,     1] loss: 1094.969
[14,     1] loss: 1065.844
[15,     1] loss: 1056.800
[16,     1] loss: 1042.524
[17,     1] loss: 1078.176
[18,     1] loss: 1015.451
[19,     1] loss: 1038.441
[20,     1] loss: 1019.006
[21,     1] loss: 1049.974
[22,     1] loss: 991.532
[23,     1] loss: 992.648
[24,     1] loss: 971.724
[25,     1] loss: 974.714
[26,     1] loss: 951.190
[27,     1] loss: 966.853
[28,     1] loss: 937.513
[29,     1] loss: 940.367
[30,     1] loss: 917.205
[31,     1] loss: 884.949
[32,     1] loss: 890.167
[33,     1] loss: 879.843
[34,     1] loss: 863.322
[35,     1] loss: 898.633
[36,     1] loss: 854.832
[37,     1] loss: 833.198
[38,     1] loss: 981.781
[39,     1] loss: 1277.938
[40,     1] loss: 882.908
[41,     1] loss: 988.519
[42,     1] loss: 1006.625
[43,     1] loss: 943.027
[44,     1] loss: 941.970
[45,     1] loss: 930.398
[46,     1] loss: 903.732
[47,     1] loss: 908.846
[48,     1] loss: 873.479
[49,     1] loss: 866.180
[50,     1] loss: 917.674
[51,     1] loss: 852.048
[52,     1] loss: 865.896
[53,     1] loss: 825.541
[54,     1] loss: 815.515
[55,     1] loss: 841.034
[56,     1] loss: 796.413
[57,     1] loss: 783.103
[58,     1] loss: 790.275
[59,     1] loss: 754.910
[60,     1] loss: 794.059
[61,     1] loss: 775.058
[62,     1] loss: 735.543
[63,     1] loss: 703.360
[64,     1] loss: 722.943
[65,     1] loss: 681.170
[66,     1] loss: 654.725
[67,     1] loss: 711.934
[68,     1] loss: 841.433
[69,     1] loss: 924.692
[70,     1] loss: 673.999
Early stopping applied (best metric=0.8352693915367126)
Finished Training
Total time taken: 9.892207384109497
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1231.723
[2,     1] loss: 1233.059
[3,     1] loss: 1227.142
[4,     1] loss: 1226.535
[5,     1] loss: 1214.091
[6,     1] loss: 1181.608
[7,     1] loss: 1142.343
[8,     1] loss: 1100.092
[9,     1] loss: 1047.032
[10,     1] loss: 1053.453
[11,     1] loss: 1099.035
[12,     1] loss: 1034.903
[13,     1] loss: 1006.677
[14,     1] loss: 1012.812
[15,     1] loss: 1016.774
[16,     1] loss: 966.309
[17,     1] loss: 975.836
[18,     1] loss: 965.508
[19,     1] loss: 969.483
[20,     1] loss: 909.677
[21,     1] loss: 946.491
[22,     1] loss: 916.739
[23,     1] loss: 998.041
[24,     1] loss: 865.787
[25,     1] loss: 925.999
[26,     1] loss: 881.746
[27,     1] loss: 926.669
[28,     1] loss: 869.585
[29,     1] loss: 849.189
[30,     1] loss: 833.279
[31,     1] loss: 843.025
[32,     1] loss: 813.742
[33,     1] loss: 845.290
[34,     1] loss: 812.416
[35,     1] loss: 877.335
[36,     1] loss: 800.867
[37,     1] loss: 764.505
[38,     1] loss: 871.654
[39,     1] loss: 931.655
[40,     1] loss: 770.750
[41,     1] loss: 857.559
[42,     1] loss: 770.176
[43,     1] loss: 852.852
[44,     1] loss: 745.902
[45,     1] loss: 808.087
[46,     1] loss: 729.914
[47,     1] loss: 758.525
[48,     1] loss: 707.138
[49,     1] loss: 733.102
[50,     1] loss: 772.691
[51,     1] loss: 684.457
Early stopping applied (best metric=0.8360098600387573)
Finished Training
Total time taken: 7.892165422439575
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1233.293
[2,     1] loss: 1251.984
[3,     1] loss: 1231.611
[4,     1] loss: 1232.005
[5,     1] loss: 1234.009
[6,     1] loss: 1230.027
[7,     1] loss: 1230.037
[8,     1] loss: 1229.606
[9,     1] loss: 1230.507
[10,     1] loss: 1232.320
[11,     1] loss: 1227.915
[12,     1] loss: 1225.381
[13,     1] loss: 1217.889
[14,     1] loss: 1212.502
[15,     1] loss: 1189.026
[16,     1] loss: 1169.608
[17,     1] loss: 1135.170
[18,     1] loss: 1118.583
[19,     1] loss: 1081.049
[20,     1] loss: 1072.394
[21,     1] loss: 1061.861
[22,     1] loss: 1048.700
[23,     1] loss: 1044.075
[24,     1] loss: 1052.621
[25,     1] loss: 1021.766
[26,     1] loss: 1039.037
[27,     1] loss: 994.666
[28,     1] loss: 974.270
[29,     1] loss: 1026.219
[30,     1] loss: 957.395
[31,     1] loss: 945.994
[32,     1] loss: 903.076
[33,     1] loss: 954.568
[34,     1] loss: 862.495
[35,     1] loss: 928.947
[36,     1] loss: 882.922
[37,     1] loss: 933.349
[38,     1] loss: 887.589
[39,     1] loss: 896.626
[40,     1] loss: 861.559
[41,     1] loss: 870.333
[42,     1] loss: 830.397
[43,     1] loss: 798.996
[44,     1] loss: 858.328
[45,     1] loss: 866.357
[46,     1] loss: 761.667
[47,     1] loss: 879.437
[48,     1] loss: 859.652
[49,     1] loss: 767.438
[50,     1] loss: 776.363
[51,     1] loss: 745.077
[52,     1] loss: 707.255
[53,     1] loss: 715.637
[54,     1] loss: 746.267
[55,     1] loss: 968.306
[56,     1] loss: 978.475
[57,     1] loss: 681.647
[58,     1] loss: 893.799
[59,     1] loss: 776.536
[60,     1] loss: 788.643
[61,     1] loss: 819.226
[62,     1] loss: 748.320
[63,     1] loss: 832.450
[64,     1] loss: 714.589
[65,     1] loss: 746.539
[66,     1] loss: 707.479
[67,     1] loss: 699.357
[68,     1] loss: 721.922
[69,     1] loss: 698.209
[70,     1] loss: 629.263
[71,     1] loss: 633.832
[72,     1] loss: 725.188
Early stopping applied (best metric=0.7490110993385315)
Finished Training
Total time taken: 11.00123119354248
{'Hydroxylation-K Validation Accuracy': 0.7884456264775414, 'Hydroxylation-K Validation Sensitivity': 0.6125925925925926, 'Hydroxylation-K Validation Specificity': 0.8333333333333334, 'Hydroxylation-K Validation Precision': 0.4921116894801105, 'Hydroxylation-K AUC ROC': 0.7863157894736842, 'Hydroxylation-K AUC PR': 0.593694348250889, 'Hydroxylation-K MCC': 0.4147643192122811, 'Hydroxylation-K F1': 0.5370260107371427, 'Validation Loss (Hydroxylation-K)': 0.438946004708608, 'Hydroxylation-P Validation Accuracy': 0.7882573811820043, 'Hydroxylation-P Validation Sensitivity': 0.754021164021164, 'Hydroxylation-P Validation Specificity': 0.7956606314529403, 'Hydroxylation-P Validation Precision': 0.45073266424003244, 'Hydroxylation-P AUC ROC': 0.8450706463608603, 'Hydroxylation-P AUC PR': 0.5701833103774469, 'Hydroxylation-P MCC': 0.46172939143470443, 'Hydroxylation-P F1': 0.5601379150169554, 'Validation Loss (Hydroxylation-P)': 0.3780548632144928, 'Validation Loss (total)': 0.8170008659362793, 'TimeToTrain': 10.412953027089436}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002744111028417961,
 'learning_rate_Hydroxylation-K': 0.00013229381816233575,
 'learning_rate_Hydroxylation-P': 0.008843125607719403,
 'log_base': 2.7228566215163186,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4139958389,
 'sample_weights': [1.5309409810752697, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.379871261439261,
 'weight_decay_Hydroxylation-K': 7.376707582166697,
 'weight_decay_Hydroxylation-P': 0.8395231869029243}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1274.010
[2,     1] loss: 1259.509
[3,     1] loss: 1261.118
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005029644618357231,
 'learning_rate_Hydroxylation-K': 0.0011818959663811549,
 'learning_rate_Hydroxylation-P': 0.007004640788932068,
 'log_base': 2.563197628007145,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3545646836,
 'sample_weights': [1.6666405950938168, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.818338295037469,
 'weight_decay_Hydroxylation-K': 7.342393136360494,
 'weight_decay_Hydroxylation-P': 1.1626524983030573}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1289.427
[2,     1] loss: 1289.410
[3,     1] loss: 1279.128
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002078116007384649,
 'learning_rate_Hydroxylation-K': 0.0010394193465527932,
 'learning_rate_Hydroxylation-P': 0.003418622018420758,
 'log_base': 2.8602074953514443,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2921426798,
 'sample_weights': [1.773634315367329, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7056036149884694,
 'weight_decay_Hydroxylation-K': 4.510757373761373,
 'weight_decay_Hydroxylation-P': 8.493350865227274}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1244.395
[2,     1] loss: 1245.751
[3,     1] loss: 1244.011
[4,     1] loss: 1241.068
[5,     1] loss: 1236.649
[6,     1] loss: 1232.732
[7,     1] loss: 1226.263
[8,     1] loss: 1203.549
[9,     1] loss: 1186.329
[10,     1] loss: 1149.469
[11,     1] loss: 1115.340
[12,     1] loss: 1077.055
[13,     1] loss: 1087.714
[14,     1] loss: 1046.277
[15,     1] loss: 1068.113
[16,     1] loss: 1010.536
[17,     1] loss: 1067.012
[18,     1] loss: 1069.829
[19,     1] loss: 1048.636
[20,     1] loss: 993.907
[21,     1] loss: 1003.814
[22,     1] loss: 1017.643
[23,     1] loss: 1014.341
[24,     1] loss: 992.365
[25,     1] loss: 999.871
[26,     1] loss: 969.040
[27,     1] loss: 951.100
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024975562510441735,
 'learning_rate_Hydroxylation-K': 0.0006042620092048462,
 'learning_rate_Hydroxylation-P': 0.005286725260863982,
 'log_base': 2.0160228129360394,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 7725370,
 'sample_weights': [1.588593019430805, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8863185846031402,
 'weight_decay_Hydroxylation-K': 2.197581865910971,
 'weight_decay_Hydroxylation-P': 1.9168726551693465}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1412.710
[2,     1] loss: 1411.719
[3,     1] loss: 1410.940
[4,     1] loss: 1408.739
[5,     1] loss: 1409.787
[6,     1] loss: 1408.680
[7,     1] loss: 1403.619
[8,     1] loss: 1391.519
[9,     1] loss: 1380.786
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005009113738748154,
 'learning_rate_Hydroxylation-K': 0.0014393624066845268,
 'learning_rate_Hydroxylation-P': 0.007775944734081114,
 'log_base': 1.9838853576301771,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 839760135,
 'sample_weights': [2.3810863688072414, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.36313254506977,
 'weight_decay_Hydroxylation-K': 6.214503301109275,
 'weight_decay_Hydroxylation-P': 2.858839347237673}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1425.785
[2,     1] loss: 1424.953
[3,     1] loss: 1426.123
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0053535008210781,
 'learning_rate_Hydroxylation-K': 0.00024281378617361789,
 'learning_rate_Hydroxylation-P': 0.003170990455175252,
 'log_base': 2.281676437847697,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2790857445,
 'sample_weights': [2.436939703092252, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1443749180603846,
 'weight_decay_Hydroxylation-K': 1.573238216431002,
 'weight_decay_Hydroxylation-P': 0.6408395919967086}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1333.739
[2,     1] loss: 1334.760
[3,     1] loss: 1370.166
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002616201296387848,
 'learning_rate_Hydroxylation-K': 0.0008646214917350861,
 'learning_rate_Hydroxylation-P': 0.0014586839308670277,
 'log_base': 2.282493183888726,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1055282421,
 'sample_weights': [2.023787118088424, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.847262203648952,
 'weight_decay_Hydroxylation-K': 1.8838918941766187,
 'weight_decay_Hydroxylation-P': 8.947783495723968}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1333.823
[2,     1] loss: 1333.097
[3,     1] loss: 1333.758
[4,     1] loss: 1335.044
[5,     1] loss: 1327.527
[6,     1] loss: 1324.614
[7,     1] loss: 1306.810
[8,     1] loss: 1277.045
[9,     1] loss: 1241.768
[10,     1] loss: 1179.937
[11,     1] loss: 1134.883
[12,     1] loss: 1136.177
[13,     1] loss: 1102.444
[14,     1] loss: 1104.566
[15,     1] loss: 1048.387
[16,     1] loss: 1113.659
[17,     1] loss: 1101.746
[18,     1] loss: 1102.859
[19,     1] loss: 999.329
[20,     1] loss: 1047.156
[21,     1] loss: 1052.542
[22,     1] loss: 1061.348
[23,     1] loss: 980.340
[24,     1] loss: 963.068
[25,     1] loss: 984.720
[26,     1] loss: 1005.737
[27,     1] loss: 959.787
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031246287640402043,
 'learning_rate_Hydroxylation-K': 0.00025657304139199916,
 'learning_rate_Hydroxylation-P': 0.006037504368486189,
 'log_base': 1.5307027597025293,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3066208710,
 'sample_weights': [2.0229094609264515, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.0223053256691017,
 'weight_decay_Hydroxylation-K': 1.3032962837631716,
 'weight_decay_Hydroxylation-P': 1.3546405769381984}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1738.807
[2,     1] loss: 1735.300
[3,     1] loss: 1734.429
[4,     1] loss: 1737.928
[5,     1] loss: 1749.756
[6,     1] loss: 1735.792
[7,     1] loss: 1731.975
[8,     1] loss: 1737.396
[9,     1] loss: 1718.291
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023488733642149967,
 'learning_rate_Hydroxylation-K': 0.009042800494089568,
 'learning_rate_Hydroxylation-P': 0.0034750208948713963,
 'log_base': 2.1028751988549037,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 793223221,
 'sample_weights': [3.921394093937918, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.422355145149917,
 'weight_decay_Hydroxylation-K': 1.5814628486965314,
 'weight_decay_Hydroxylation-P': 8.505761035114686}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1387.047
[2,     1] loss: 1385.387
[3,     1] loss: 1377.626
[4,     1] loss: 1378.816
[5,     1] loss: 1376.910
[6,     1] loss: 1377.988
[7,     1] loss: 1368.528
[8,     1] loss: 1349.330
[9,     1] loss: 1300.210
[10,     1] loss: 1286.722
[11,     1] loss: 1263.033
[12,     1] loss: 1208.651
[13,     1] loss: 1191.819
[14,     1] loss: 1188.976
[15,     1] loss: 1170.939
[16,     1] loss: 1152.421
[17,     1] loss: 1167.512
[18,     1] loss: 1160.741
[19,     1] loss: 1134.785
[20,     1] loss: 1154.911
[21,     1] loss: 1056.236
[22,     1] loss: 1101.750
[23,     1] loss: 1128.773
[24,     1] loss: 1079.549
[25,     1] loss: 1032.034
[26,     1] loss: 1060.348
[27,     1] loss: 1080.477
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008614826988230472,
 'learning_rate_Hydroxylation-K': 0.009159083431205032,
 'learning_rate_Hydroxylation-P': 0.008912484060804613,
 'log_base': 2.4529622866261445,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1917016181,
 'sample_weights': [2.245971587364004, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.07890688365697,
 'weight_decay_Hydroxylation-K': 1.5299931157670317,
 'weight_decay_Hydroxylation-P': 8.932019841665966}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1305.016
[2,     1] loss: 1355.275
[3,     1] loss: 1304.522
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0042532135375440835,
 'learning_rate_Hydroxylation-K': 0.00423578895844214,
 'learning_rate_Hydroxylation-P': 0.004636081217923506,
 'log_base': 1.643129154599659,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1065822425,
 'sample_weights': [1.8605258692624738, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.71108718181572,
 'weight_decay_Hydroxylation-K': 1.4187426997125963,
 'weight_decay_Hydroxylation-P': 5.300566115988092}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1623.396
[2,     1] loss: 1633.936
[3,     1] loss: 1631.554
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001378635558498359,
 'learning_rate_Hydroxylation-K': 0.002352062663690247,
 'learning_rate_Hydroxylation-P': 0.007345103976101007,
 'log_base': 2.6000401969242426,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4153242947,
 'sample_weights': [3.361729617568432, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.4521155637695244,
 'weight_decay_Hydroxylation-K': 7.74258334229383,
 'weight_decay_Hydroxylation-P': 7.80265763652322}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1279.907
[2,     1] loss: 1280.240
[3,     1] loss: 1275.937
[4,     1] loss: 1277.189
[5,     1] loss: 1274.663
[6,     1] loss: 1274.708
[7,     1] loss: 1265.586
[8,     1] loss: 1258.810
[9,     1] loss: 1252.161
[10,     1] loss: 1237.406
[11,     1] loss: 1222.003
[12,     1] loss: 1184.109
[13,     1] loss: 1155.239
[14,     1] loss: 1107.583
[15,     1] loss: 1119.684
[16,     1] loss: 1066.774
[17,     1] loss: 1098.488
[18,     1] loss: 1072.541
[19,     1] loss: 1049.559
[20,     1] loss: 1096.825
[21,     1] loss: 1085.809
[22,     1] loss: 1080.355
[23,     1] loss: 1087.615
[24,     1] loss: 1070.670
[25,     1] loss: 1051.119
[26,     1] loss: 1078.090
[27,     1] loss: 1029.653
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008296892773856906,
 'learning_rate_Hydroxylation-K': 0.0099238918221215,
 'learning_rate_Hydroxylation-P': 0.0021284066162913177,
 'log_base': 1.6564735247249267,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3233962702,
 'sample_weights': [1.7471440502907318, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.5258854589265827,
 'weight_decay_Hydroxylation-K': 4.235692139155776,
 'weight_decay_Hydroxylation-P': 5.678296166752415}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1604.421
[2,     1] loss: 1636.334
[3,     1] loss: 1613.780
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004702234969366634,
 'learning_rate_Hydroxylation-K': 0.0002093845931180852,
 'learning_rate_Hydroxylation-P': 0.006697726130718675,
 'log_base': 2.92791495535139,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3997037283,
 'sample_weights': [3.3078522894885665, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.130782407998003,
 'weight_decay_Hydroxylation-K': 5.989166397086597,
 'weight_decay_Hydroxylation-P': 2.6277395748110903}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.528
[2,     1] loss: 1239.284
[3,     1] loss: 1239.648
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005052310799286571,
 'learning_rate_Hydroxylation-K': 0.0017780248163492705,
 'learning_rate_Hydroxylation-P': 0.009650585079434964,
 'log_base': 2.5602356894658342,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 816680869,
 'sample_weights': [1.553995934193835, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.356178268059377,
 'weight_decay_Hydroxylation-K': 5.211206027688523,
 'weight_decay_Hydroxylation-P': 0.8493442412056406}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1286.214
[2,     1] loss: 1292.147
[3,     1] loss: 1281.621
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006750986666632161,
 'learning_rate_Hydroxylation-K': 0.009466318773692993,
 'learning_rate_Hydroxylation-P': 0.0003319883394499152,
 'log_base': 2.468201960480842,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2013868873,
 'sample_weights': [1.7758157155377694, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.7549122415772835,
 'weight_decay_Hydroxylation-K': 6.321510630746485,
 'weight_decay_Hydroxylation-P': 1.0344503337799495}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1297.657
[2,     1] loss: 1293.850
[3,     1] loss: 1318.573
[4,     1] loss: 1315.460
[5,     1] loss: 1301.406
[6,     1] loss: 1298.217
[7,     1] loss: 1296.655
[8,     1] loss: 1295.401
[9,     1] loss: 1293.332
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0038019643546833943,
 'learning_rate_Hydroxylation-K': 0.00020278367253053452,
 'learning_rate_Hydroxylation-P': 0.007449054297804836,
 'log_base': 2.9606032144780787,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 660393181,
 'sample_weights': [1.8477717171882238, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.5542113170632925,
 'weight_decay_Hydroxylation-K': 2.257855411067719,
 'weight_decay_Hydroxylation-P': 1.2886786636251484}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.575
[2,     1] loss: 1235.688
[3,     1] loss: 1232.649
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004943792091614838,
 'learning_rate_Hydroxylation-K': 0.0026272023453835077,
 'learning_rate_Hydroxylation-P': 0.005371192114070547,
 'log_base': 2.218221692795364,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1642845628,
 'sample_weights': [1.538100109056562, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8288964830547867,
 'weight_decay_Hydroxylation-K': 0.3937246752688208,
 'weight_decay_Hydroxylation-P': 0.7884171818638568}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1351.994
[2,     1] loss: 1355.820
[3,     1] loss: 1352.513
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015958334716307293,
 'learning_rate_Hydroxylation-K': 0.0010761913051388805,
 'learning_rate_Hydroxylation-P': 0.0030361155202616296,
 'log_base': 2.9455777715631144,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3122494423,
 'sample_weights': [2.0954323074182444, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.44338830248681926,
 'weight_decay_Hydroxylation-K': 0.5896333590401444,
 'weight_decay_Hydroxylation-P': 0.7342566455174695}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.048
[2,     1] loss: 1234.834
[3,     1] loss: 1230.349
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006136983750630605,
 'learning_rate_Hydroxylation-K': 0.006733686730501234,
 'learning_rate_Hydroxylation-P': 0.0029606721645573297,
 'log_base': 2.8266421489249556,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 982320011,
 'sample_weights': [1.5453442966320419, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.068890504013447,
 'weight_decay_Hydroxylation-K': 6.729630453391092,
 'weight_decay_Hydroxylation-P': 7.336635551620862}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1248.484
[2,     1] loss: 1256.904
[3,     1] loss: 1251.447
[4,     1] loss: 1248.078
[5,     1] loss: 1252.265
[6,     1] loss: 1243.818
[7,     1] loss: 1248.592
[8,     1] loss: 1242.978
[9,     1] loss: 1248.904
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007356985725381943,
 'learning_rate_Hydroxylation-K': 0.008815049199471904,
 'learning_rate_Hydroxylation-P': 0.009587086516914374,
 'log_base': 1.848277077703131,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 754073290,
 'sample_weights': [1.606640397884513, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.543068094210442,
 'weight_decay_Hydroxylation-K': 8.632312756493842,
 'weight_decay_Hydroxylation-P': 1.7697789585826802}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1483.166
[2,     1] loss: 1487.979
[3,     1] loss: 1511.116
[4,     1] loss: 1493.375
[5,     1] loss: 1483.168
[6,     1] loss: 1472.535
[7,     1] loss: 1480.149
[8,     1] loss: 1468.416
[9,     1] loss: 1459.408
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007448295386968658,
 'learning_rate_Hydroxylation-K': 8.275377400190475e-05,
 'learning_rate_Hydroxylation-P': 0.007095995061898074,
 'log_base': 2.8299981028566474,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 159012246,
 'sample_weights': [2.717838924313841, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.16574143048891,
 'weight_decay_Hydroxylation-K': 5.887145765333221,
 'weight_decay_Hydroxylation-P': 3.0100700042275697}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1251.717
[2,     1] loss: 1275.985
[3,     1] loss: 1246.814
[4,     1] loss: 1255.681
[5,     1] loss: 1246.113
[6,     1] loss: 1253.021
[7,     1] loss: 1249.418
[8,     1] loss: 1249.986
[9,     1] loss: 1248.910
[10,     1] loss: 1245.217
[11,     1] loss: 1242.676
[12,     1] loss: 1241.694
[13,     1] loss: 1248.816
[14,     1] loss: 1238.609
[15,     1] loss: 1238.568
[16,     1] loss: 1240.342
[17,     1] loss: 1228.577
[18,     1] loss: 1228.186
[19,     1] loss: 1215.721
[20,     1] loss: 1197.371
[21,     1] loss: 1167.934
[22,     1] loss: 1167.414
[23,     1] loss: 1160.319
[24,     1] loss: 1129.532
[25,     1] loss: 1143.045
[26,     1] loss: 1095.222
[27,     1] loss: 1102.532
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006699767001735597,
 'learning_rate_Hydroxylation-K': 0.0013455391637408726,
 'learning_rate_Hydroxylation-P': 0.006152832860797624,
 'log_base': 1.2374930031537505,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3852146994,
 'sample_weights': [1.6048078405799822, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.839133773672929,
 'weight_decay_Hydroxylation-K': 0.13492631786801912,
 'weight_decay_Hydroxylation-P': 9.425942865604913}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2564.444
[2,     1] loss: 2605.674
[3,     1] loss: 2565.754
[4,     1] loss: 2554.826
[5,     1] loss: 2540.590
[6,     1] loss: 2578.695
[7,     1] loss: 2542.642
[8,     1] loss: 2534.776
[9,     1] loss: 2523.283
[10,     1] loss: 2504.659
[11,     1] loss: 2501.052
[12,     1] loss: 2424.209
[13,     1] loss: 2384.645
[14,     1] loss: 2303.685
[15,     1] loss: 2247.933
[16,     1] loss: 2145.286
[17,     1] loss: 2178.475
[18,     1] loss: 2167.022
[19,     1] loss: 2016.820
[20,     1] loss: 2092.975
[21,     1] loss: 2159.387
[22,     1] loss: 2081.267
[23,     1] loss: 2060.491
[24,     1] loss: 1895.311
[25,     1] loss: 1979.358
[26,     1] loss: 1861.848
[27,     1] loss: 1946.694
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009728548860007338,
 'learning_rate_Hydroxylation-K': 0.008978072226112523,
 'learning_rate_Hydroxylation-P': 0.0031030235147909433,
 'log_base': 1.4343386418500008,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4254559397,
 'sample_weights': [7.834540581531133, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.67221821373926,
 'weight_decay_Hydroxylation-K': 7.35229414146597,
 'weight_decay_Hydroxylation-P': 7.424038601092514}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1879.928
[2,     1] loss: 1896.368
[3,     1] loss: 1904.140
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004064333007880899,
 'learning_rate_Hydroxylation-K': 0.0035906712470220206,
 'learning_rate_Hydroxylation-P': 0.008350747049425353,
 'log_base': 2.9911134992441935,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3988855172,
 'sample_weights': [4.6282929122403775, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.73826928177764,
 'weight_decay_Hydroxylation-K': 3.7317573733736062,
 'weight_decay_Hydroxylation-P': 1.5796450775361186}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1235.302
[2,     1] loss: 1235.660
[3,     1] loss: 1237.925
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005577795007489584,
 'learning_rate_Hydroxylation-K': 0.009322654276839194,
 'learning_rate_Hydroxylation-P': 0.00982864233443637,
 'log_base': 1.1900353259944514,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2248207334,
 'sample_weights': [1.5237070779685722, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.639169581431634,
 'weight_decay_Hydroxylation-K': 7.622936991171553,
 'weight_decay_Hydroxylation-P': 8.44451707903514}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3115.159
[2,     1] loss: 3115.076
[3,     1] loss: 3113.300
[4,     1] loss: 3111.927
[5,     1] loss: 3097.303
[6,     1] loss: 3121.402
[7,     1] loss: 3106.940
[8,     1] loss: 3107.930
[9,     1] loss: 3111.045
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006442768799213978,
 'learning_rate_Hydroxylation-K': 0.004047770314556685,
 'learning_rate_Hydroxylation-P': 0.008345535729667505,
 'log_base': 2.7768396673355658,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 102724304,
 'sample_weights': [9.595438752185336, 1.1994760508772242],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.6112933040055815,
 'weight_decay_Hydroxylation-K': 7.6251195543290855,
 'weight_decay_Hydroxylation-P': 1.0334672787510073}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1253.121
[2,     1] loss: 1260.589
[3,     1] loss: 1262.899
[4,     1] loss: 1250.074
[5,     1] loss: 1250.992
[6,     1] loss: 1249.804
[7,     1] loss: 1244.640
[8,     1] loss: 1234.090
[9,     1] loss: 1209.003
[10,     1] loss: 1192.203
[11,     1] loss: 1145.918
[12,     1] loss: 1104.173
[13,     1] loss: 1094.070
[14,     1] loss: 1065.038
[15,     1] loss: 1086.659
[16,     1] loss: 1040.896
[17,     1] loss: 1011.515
[18,     1] loss: 1023.914
[19,     1] loss: 1022.785
[20,     1] loss: 981.994
[21,     1] loss: 973.281
[22,     1] loss: 946.075
[23,     1] loss: 1024.663
[24,     1] loss: 932.382
[25,     1] loss: 939.568
[26,     1] loss: 957.713
[27,     1] loss: 899.330
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004068135233792907,
 'learning_rate_Hydroxylation-K': 0.001894400860333073,
 'learning_rate_Hydroxylation-P': 0.009591765814097604,
 'log_base': 2.943340480440319,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3622341456,
 'sample_weights': [1.6346040615973876, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.413185751801666,
 'weight_decay_Hydroxylation-K': 8.26893699766988,
 'weight_decay_Hydroxylation-P': 1.5790543440665092}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.401
[2,     1] loss: 1236.979
[3,     1] loss: 1235.266
[4,     1] loss: 1228.555
[5,     1] loss: 1224.242
[6,     1] loss: 1213.056
[7,     1] loss: 1174.449
[8,     1] loss: 1141.074
[9,     1] loss: 1115.546
[10,     1] loss: 1075.421
[11,     1] loss: 1006.962
[12,     1] loss: 1006.672
[13,     1] loss: 1008.829
[14,     1] loss: 983.337
[15,     1] loss: 974.621
[16,     1] loss: 979.446
[17,     1] loss: 1007.625
[18,     1] loss: 950.113
[19,     1] loss: 959.939
[20,     1] loss: 919.646
[21,     1] loss: 970.720
[22,     1] loss: 922.293
[23,     1] loss: 887.699
[24,     1] loss: 917.894
[25,     1] loss: 942.807
[26,     1] loss: 911.223
[27,     1] loss: 878.669
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003009189705263327,
 'learning_rate_Hydroxylation-K': 0.0022449976059339006,
 'learning_rate_Hydroxylation-P': 0.0035355638889910442,
 'log_base': 2.6016478266272043,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1038953836,
 'sample_weights': [1.546431977355319, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.589976734693234,
 'weight_decay_Hydroxylation-K': 3.3150350355274782,
 'weight_decay_Hydroxylation-P': 0.5805776691280133}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1276.048
[2,     1] loss: 1281.364
[3,     1] loss: 1278.181
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004239922957804461,
 'learning_rate_Hydroxylation-K': 0.002810730676726907,
 'learning_rate_Hydroxylation-P': 0.006619311863887224,
 'log_base': 2.382571282014663,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3904321061,
 'sample_weights': [1.7460145751562048, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.117024467792673,
 'weight_decay_Hydroxylation-K': 5.634274657188753,
 'weight_decay_Hydroxylation-P': 0.13587887851090003}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1312.730
[2,     1] loss: 1312.402
[3,     1] loss: 1314.430
[4,     1] loss: 1309.568
[5,     1] loss: 1307.134
[6,     1] loss: 1290.095
[7,     1] loss: 1242.635
[8,     1] loss: 1194.369
[9,     1] loss: 1186.350
[10,     1] loss: 1139.329
[11,     1] loss: 1126.346
[12,     1] loss: 1088.389
[13,     1] loss: 1045.977
[14,     1] loss: 1063.875
[15,     1] loss: 1040.797
[16,     1] loss: 1046.710
[17,     1] loss: 1043.927
[18,     1] loss: 1024.887
[19,     1] loss: 1008.107
[20,     1] loss: 975.367
[21,     1] loss: 949.538
[22,     1] loss: 967.925
[23,     1] loss: 909.896
[24,     1] loss: 998.901
[25,     1] loss: 960.638
[26,     1] loss: 940.162
[27,     1] loss: 959.420
[28,     1] loss: 927.769
[29,     1] loss: 917.171
[30,     1] loss: 907.702
[31,     1] loss: 959.287
[32,     1] loss: 922.520
[33,     1] loss: 938.322
[34,     1] loss: 937.429
[35,     1] loss: 894.774
[36,     1] loss: 905.867
[37,     1] loss: 931.939
[38,     1] loss: 833.036
[39,     1] loss: 887.970
[40,     1] loss: 895.247
[41,     1] loss: 815.755
[42,     1] loss: 895.448
[43,     1] loss: 785.195
[44,     1] loss: 813.092
[45,     1] loss: 802.115
[46,     1] loss: 748.773
[47,     1] loss: 811.325
[48,     1] loss: 984.779
[49,     1] loss: 1007.312
[50,     1] loss: 858.082
[51,     1] loss: 884.988
[52,     1] loss: 943.357
[53,     1] loss: 854.603
[54,     1] loss: 835.630
[55,     1] loss: 879.894
[56,     1] loss: 789.163
[57,     1] loss: 852.991
[58,     1] loss: 748.370
[59,     1] loss: 832.498
[60,     1] loss: 782.941
[61,     1] loss: 837.542
[62,     1] loss: 697.818
[63,     1] loss: 770.294
[64,     1] loss: 673.970
[65,     1] loss: 735.886
Early stopping applied (best metric=0.8067820072174072)
Finished Training
Total time taken: 10.287216901779175
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1318.901
[2,     1] loss: 1324.927
[3,     1] loss: 1315.349
[4,     1] loss: 1315.215
[5,     1] loss: 1314.153
[6,     1] loss: 1314.870
[7,     1] loss: 1318.933
[8,     1] loss: 1309.502
[9,     1] loss: 1315.954
[10,     1] loss: 1312.087
[11,     1] loss: 1310.619
[12,     1] loss: 1309.920
[13,     1] loss: 1306.926
[14,     1] loss: 1300.138
[15,     1] loss: 1290.182
[16,     1] loss: 1274.828
[17,     1] loss: 1254.641
[18,     1] loss: 1215.452
[19,     1] loss: 1186.536
[20,     1] loss: 1155.522
[21,     1] loss: 1124.696
[22,     1] loss: 1144.484
[23,     1] loss: 1136.714
[24,     1] loss: 1133.983
[25,     1] loss: 1131.579
[26,     1] loss: 1095.568
[27,     1] loss: 1076.707
[28,     1] loss: 1095.945
[29,     1] loss: 1073.122
[30,     1] loss: 1045.301
[31,     1] loss: 1080.618
[32,     1] loss: 1040.792
[33,     1] loss: 1031.024
[34,     1] loss: 1025.072
[35,     1] loss: 986.811
[36,     1] loss: 980.388
[37,     1] loss: 981.329
[38,     1] loss: 962.893
[39,     1] loss: 1022.145
[40,     1] loss: 1018.722
[41,     1] loss: 922.317
[42,     1] loss: 918.773
[43,     1] loss: 915.438
[44,     1] loss: 901.410
[45,     1] loss: 892.113
[46,     1] loss: 1009.817
[47,     1] loss: 948.194
[48,     1] loss: 893.849
[49,     1] loss: 864.749
[50,     1] loss: 899.926
[51,     1] loss: 853.128
[52,     1] loss: 939.601
[53,     1] loss: 1016.304
[54,     1] loss: 800.350
[55,     1] loss: 1000.571
[56,     1] loss: 798.701
[57,     1] loss: 963.059
[58,     1] loss: 842.961
[59,     1] loss: 903.061
[60,     1] loss: 844.253
[61,     1] loss: 902.769
[62,     1] loss: 792.062
[63,     1] loss: 816.951
[64,     1] loss: 788.528
[65,     1] loss: 776.455
[66,     1] loss: 744.376
[67,     1] loss: 777.051
[68,     1] loss: 767.813
[69,     1] loss: 991.575
[70,     1] loss: 909.704
[71,     1] loss: 733.236
[72,     1] loss: 859.488
[73,     1] loss: 777.001
[74,     1] loss: 829.689
[75,     1] loss: 759.008
[76,     1] loss: 740.907
[77,     1] loss: 739.283
[78,     1] loss: 707.251
[79,     1] loss: 660.188
[80,     1] loss: 729.096
[81,     1] loss: 782.573
[82,     1] loss: 744.164
[83,     1] loss: 634.439
[84,     1] loss: 766.532
[85,     1] loss: 755.067
[86,     1] loss: 621.137
[87,     1] loss: 715.030
[88,     1] loss: 781.776
[89,     1] loss: 669.654
[90,     1] loss: 568.170
[91,     1] loss: 646.116
[92,     1] loss: 682.016
[93,     1] loss: 763.768
[94,     1] loss: 596.222
[95,     1] loss: 751.687
Early stopping applied (best metric=0.6948785185813904)
Finished Training
Total time taken: 14.737310886383057
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1313.965
[2,     1] loss: 1315.769
[3,     1] loss: 1318.031
[4,     1] loss: 1315.432
[5,     1] loss: 1317.277
[6,     1] loss: 1306.260
[7,     1] loss: 1302.811
[8,     1] loss: 1285.115
[9,     1] loss: 1267.259
[10,     1] loss: 1236.369
[11,     1] loss: 1181.710
[12,     1] loss: 1139.676
[13,     1] loss: 1132.773
[14,     1] loss: 1089.603
[15,     1] loss: 1168.541
[16,     1] loss: 1139.315
[17,     1] loss: 1103.146
[18,     1] loss: 1070.480
[19,     1] loss: 1077.363
[20,     1] loss: 1093.761
[21,     1] loss: 1029.908
[22,     1] loss: 1051.879
[23,     1] loss: 1061.375
[24,     1] loss: 1044.375
[25,     1] loss: 1072.388
[26,     1] loss: 983.056
[27,     1] loss: 984.388
[28,     1] loss: 1032.236
[29,     1] loss: 994.547
[30,     1] loss: 1045.355
[31,     1] loss: 979.073
[32,     1] loss: 997.515
[33,     1] loss: 969.151
[34,     1] loss: 989.882
[35,     1] loss: 933.919
[36,     1] loss: 925.067
[37,     1] loss: 961.249
[38,     1] loss: 909.318
[39,     1] loss: 913.068
[40,     1] loss: 828.713
[41,     1] loss: 832.459
[42,     1] loss: 823.814
[43,     1] loss: 853.903
[44,     1] loss: 809.608
[45,     1] loss: 817.336
[46,     1] loss: 1137.124
[47,     1] loss: 1138.764
[48,     1] loss: 1004.708
[49,     1] loss: 959.906
[50,     1] loss: 1008.169
[51,     1] loss: 1054.406
[52,     1] loss: 1050.733
[53,     1] loss: 1017.185
[54,     1] loss: 968.644
[55,     1] loss: 982.758
Early stopping applied (best metric=0.9309421181678772)
Finished Training
Total time taken: 8.261174201965332
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1315.998
[2,     1] loss: 1314.293
[3,     1] loss: 1312.955
[4,     1] loss: 1315.329
[5,     1] loss: 1311.971
[6,     1] loss: 1311.429
[7,     1] loss: 1301.352
[8,     1] loss: 1297.105
[9,     1] loss: 1270.909
[10,     1] loss: 1255.447
[11,     1] loss: 1209.344
[12,     1] loss: 1165.773
[13,     1] loss: 1166.660
[14,     1] loss: 1115.165
[15,     1] loss: 1122.682
[16,     1] loss: 1161.150
[17,     1] loss: 1109.328
[18,     1] loss: 1096.605
[19,     1] loss: 1057.799
[20,     1] loss: 1097.314
[21,     1] loss: 1087.137
[22,     1] loss: 1050.659
[23,     1] loss: 1067.630
[24,     1] loss: 1020.775
[25,     1] loss: 1032.795
[26,     1] loss: 1010.980
[27,     1] loss: 997.265
[28,     1] loss: 1017.990
[29,     1] loss: 1012.412
[30,     1] loss: 953.225
[31,     1] loss: 988.076
[32,     1] loss: 989.632
[33,     1] loss: 965.981
[34,     1] loss: 972.658
[35,     1] loss: 919.519
[36,     1] loss: 945.404
[37,     1] loss: 986.553
[38,     1] loss: 911.726
[39,     1] loss: 898.977
[40,     1] loss: 925.755
[41,     1] loss: 891.899
[42,     1] loss: 916.296
[43,     1] loss: 910.466
[44,     1] loss: 879.911
[45,     1] loss: 838.119
[46,     1] loss: 860.024
[47,     1] loss: 885.716
[48,     1] loss: 943.556
[49,     1] loss: 839.889
[50,     1] loss: 884.112
[51,     1] loss: 889.698
[52,     1] loss: 814.940
[53,     1] loss: 865.037
[54,     1] loss: 834.531
[55,     1] loss: 818.250
[56,     1] loss: 886.848
[57,     1] loss: 803.880
[58,     1] loss: 779.311
[59,     1] loss: 829.194
[60,     1] loss: 770.734
[61,     1] loss: 798.953
[62,     1] loss: 829.527
[63,     1] loss: 731.522
[64,     1] loss: 737.852
[65,     1] loss: 704.928
[66,     1] loss: 691.509
[67,     1] loss: 661.874
[68,     1] loss: 622.088
[69,     1] loss: 767.533
[70,     1] loss: 1734.593
[71,     1] loss: 729.138
[72,     1] loss: 1133.839
[73,     1] loss: 1017.258
[74,     1] loss: 1049.981
[75,     1] loss: 1078.127
[76,     1] loss: 1057.175
[77,     1] loss: 1041.670
[78,     1] loss: 997.331
[79,     1] loss: 933.692
[80,     1] loss: 1035.973
[81,     1] loss: 993.204
[82,     1] loss: 895.314
[83,     1] loss: 969.221
[84,     1] loss: 972.154
[85,     1] loss: 895.428
[86,     1] loss: 984.076
[87,     1] loss: 931.890
Early stopping applied (best metric=0.7121772170066833)
Finished Training
Total time taken: 13.121279239654541
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1318.713
[2,     1] loss: 1312.167
[3,     1] loss: 1314.226
[4,     1] loss: 1319.483
[5,     1] loss: 1312.085
[6,     1] loss: 1312.238
[7,     1] loss: 1309.218
[8,     1] loss: 1304.287
[9,     1] loss: 1293.953
[10,     1] loss: 1275.590
[11,     1] loss: 1236.035
[12,     1] loss: 1221.904
[13,     1] loss: 1178.526
[14,     1] loss: 1146.184
[15,     1] loss: 1126.511
[16,     1] loss: 1144.287
[17,     1] loss: 1104.602
[18,     1] loss: 1087.785
[19,     1] loss: 1075.895
[20,     1] loss: 1062.023
[21,     1] loss: 1094.732
[22,     1] loss: 1044.051
[23,     1] loss: 1026.376
[24,     1] loss: 1054.458
[25,     1] loss: 1048.204
[26,     1] loss: 1051.302
[27,     1] loss: 1025.999
[28,     1] loss: 1005.746
[29,     1] loss: 964.074
[30,     1] loss: 954.624
[31,     1] loss: 951.834
[32,     1] loss: 981.889
[33,     1] loss: 937.180
[34,     1] loss: 905.627
[35,     1] loss: 911.159
[36,     1] loss: 916.163
[37,     1] loss: 874.065
[38,     1] loss: 967.055
[39,     1] loss: 1302.665
[40,     1] loss: 925.355
[41,     1] loss: 1161.904
[42,     1] loss: 1069.378
[43,     1] loss: 1051.121
[44,     1] loss: 1037.853
[45,     1] loss: 1065.341
[46,     1] loss: 1016.995
[47,     1] loss: 980.991
[48,     1] loss: 940.574
[49,     1] loss: 952.411
[50,     1] loss: 946.608
[51,     1] loss: 949.065
[52,     1] loss: 918.772
[53,     1] loss: 905.786
[54,     1] loss: 871.018
[55,     1] loss: 915.889
[56,     1] loss: 914.353
Early stopping applied (best metric=0.7098045349121094)
Finished Training
Total time taken: 9.298194169998169
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1321.043
[2,     1] loss: 1330.154
[3,     1] loss: 1313.645
[4,     1] loss: 1316.213
[5,     1] loss: 1314.269
[6,     1] loss: 1313.944
[7,     1] loss: 1312.401
[8,     1] loss: 1311.478
[9,     1] loss: 1311.587
[10,     1] loss: 1307.361
[11,     1] loss: 1307.729
[12,     1] loss: 1294.202
[13,     1] loss: 1275.606
[14,     1] loss: 1242.006
[15,     1] loss: 1193.143
[16,     1] loss: 1164.279
[17,     1] loss: 1153.161
[18,     1] loss: 1144.535
[19,     1] loss: 1112.805
[20,     1] loss: 1165.671
[21,     1] loss: 1128.354
[22,     1] loss: 1109.407
[23,     1] loss: 1087.177
[24,     1] loss: 1076.350
[25,     1] loss: 1086.598
[26,     1] loss: 1071.660
[27,     1] loss: 1064.315
[28,     1] loss: 1027.461
[29,     1] loss: 1067.922
[30,     1] loss: 1033.366
[31,     1] loss: 967.577
[32,     1] loss: 1029.807
[33,     1] loss: 993.593
[34,     1] loss: 981.980
[35,     1] loss: 977.488
[36,     1] loss: 999.996
[37,     1] loss: 959.427
[38,     1] loss: 1011.793
[39,     1] loss: 997.777
[40,     1] loss: 947.710
[41,     1] loss: 980.016
[42,     1] loss: 983.782
[43,     1] loss: 957.003
[44,     1] loss: 966.225
[45,     1] loss: 921.943
[46,     1] loss: 1077.285
[47,     1] loss: 1014.057
[48,     1] loss: 961.753
[49,     1] loss: 932.214
[50,     1] loss: 986.738
[51,     1] loss: 924.664
[52,     1] loss: 948.734
[53,     1] loss: 914.734
[54,     1] loss: 914.256
[55,     1] loss: 866.953
[56,     1] loss: 851.909
[57,     1] loss: 808.986
[58,     1] loss: 834.347
[59,     1] loss: 854.156
[60,     1] loss: 1049.410
[61,     1] loss: 1202.958
[62,     1] loss: 877.807
[63,     1] loss: 997.863
[64,     1] loss: 991.302
[65,     1] loss: 908.417
[66,     1] loss: 918.450
[67,     1] loss: 932.270
[68,     1] loss: 859.999
[69,     1] loss: 908.840
[70,     1] loss: 924.158
[71,     1] loss: 850.949
[72,     1] loss: 929.072
[73,     1] loss: 834.046
[74,     1] loss: 878.315
[75,     1] loss: 820.831
[76,     1] loss: 869.241
[77,     1] loss: 776.297
[78,     1] loss: 841.261
[79,     1] loss: 752.217
[80,     1] loss: 826.743
[81,     1] loss: 828.895
[82,     1] loss: 755.709
[83,     1] loss: 741.714
[84,     1] loss: 750.193
[85,     1] loss: 689.601
[86,     1] loss: 720.895
[87,     1] loss: 984.553
[88,     1] loss: 1249.809
[89,     1] loss: 764.824
[90,     1] loss: 974.114
[91,     1] loss: 865.154
[92,     1] loss: 900.962
[93,     1] loss: 905.061
[94,     1] loss: 876.464
[95,     1] loss: 830.563
[96,     1] loss: 861.864
[97,     1] loss: 798.981
[98,     1] loss: 843.237
[99,     1] loss: 772.402
[100,     1] loss: 806.312
[101,     1] loss: 733.246
[102,     1] loss: 710.679
[103,     1] loss: 727.091
[104,     1] loss: 706.928
[105,     1] loss: 729.129
Early stopping applied (best metric=0.7184141874313354)
Finished Training
Total time taken: 15.564329385757446
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1311.454
[2,     1] loss: 1315.541
[3,     1] loss: 1336.567
[4,     1] loss: 1313.740
[5,     1] loss: 1312.009
[6,     1] loss: 1313.864
[7,     1] loss: 1312.665
[8,     1] loss: 1308.248
[9,     1] loss: 1305.977
[10,     1] loss: 1302.492
[11,     1] loss: 1287.923
[12,     1] loss: 1277.795
[13,     1] loss: 1241.587
[14,     1] loss: 1217.897
[15,     1] loss: 1200.602
[16,     1] loss: 1171.728
[17,     1] loss: 1157.693
[18,     1] loss: 1099.532
[19,     1] loss: 1104.107
[20,     1] loss: 1097.647
[21,     1] loss: 1113.621
[22,     1] loss: 1074.562
[23,     1] loss: 1052.005
[24,     1] loss: 1082.799
[25,     1] loss: 1009.561
[26,     1] loss: 1008.140
[27,     1] loss: 1006.094
[28,     1] loss: 1000.802
[29,     1] loss: 1058.740
[30,     1] loss: 1078.984
[31,     1] loss: 982.456
[32,     1] loss: 990.399
[33,     1] loss: 1030.004
[34,     1] loss: 1008.204
[35,     1] loss: 952.074
[36,     1] loss: 987.745
[37,     1] loss: 918.424
[38,     1] loss: 934.830
[39,     1] loss: 938.116
[40,     1] loss: 933.435
[41,     1] loss: 855.187
[42,     1] loss: 852.062
[43,     1] loss: 911.278
[44,     1] loss: 896.844
Early stopping applied (best metric=0.8993182182312012)
Finished Training
Total time taken: 7.163150787353516
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1314.488
[2,     1] loss: 1313.126
[3,     1] loss: 1315.195
[4,     1] loss: 1308.290
[5,     1] loss: 1289.153
[6,     1] loss: 1251.391
[7,     1] loss: 1207.295
[8,     1] loss: 1220.808
[9,     1] loss: 1146.396
[10,     1] loss: 1128.528
[11,     1] loss: 1123.612
[12,     1] loss: 1105.773
[13,     1] loss: 1110.875
[14,     1] loss: 1103.713
[15,     1] loss: 1069.786
[16,     1] loss: 1066.387
[17,     1] loss: 1032.121
[18,     1] loss: 1067.132
[19,     1] loss: 1028.199
[20,     1] loss: 1028.735
[21,     1] loss: 1007.974
[22,     1] loss: 996.218
[23,     1] loss: 956.561
[24,     1] loss: 982.581
[25,     1] loss: 910.265
[26,     1] loss: 950.064
[27,     1] loss: 937.367
[28,     1] loss: 944.211
[29,     1] loss: 886.694
[30,     1] loss: 859.317
[31,     1] loss: 883.345
[32,     1] loss: 836.577
[33,     1] loss: 892.176
[34,     1] loss: 1535.573
[35,     1] loss: 1010.070
[36,     1] loss: 1216.842
[37,     1] loss: 1155.815
[38,     1] loss: 1185.105
[39,     1] loss: 1195.424
[40,     1] loss: 1206.517
[41,     1] loss: 1166.943
[42,     1] loss: 1154.402
[43,     1] loss: 1122.232
[44,     1] loss: 1139.255
[45,     1] loss: 1144.834
[46,     1] loss: 1102.199
[47,     1] loss: 1087.370
[48,     1] loss: 1096.119
[49,     1] loss: 1061.386
[50,     1] loss: 1073.381
[51,     1] loss: 990.317
Early stopping applied (best metric=0.7660266757011414)
Finished Training
Total time taken: 8.070170402526855
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1316.070
[2,     1] loss: 1310.783
[3,     1] loss: 1326.898
[4,     1] loss: 1311.267
[5,     1] loss: 1318.278
[6,     1] loss: 1311.166
[7,     1] loss: 1311.812
[8,     1] loss: 1308.242
[9,     1] loss: 1305.351
[10,     1] loss: 1300.952
[11,     1] loss: 1301.956
[12,     1] loss: 1272.611
[13,     1] loss: 1244.013
[14,     1] loss: 1217.306
[15,     1] loss: 1164.107
[16,     1] loss: 1174.666
[17,     1] loss: 1111.104
[18,     1] loss: 1116.189
[19,     1] loss: 1093.201
[20,     1] loss: 1044.098
[21,     1] loss: 1055.429
[22,     1] loss: 1011.649
[23,     1] loss: 1086.421
[24,     1] loss: 1051.514
[25,     1] loss: 1036.524
[26,     1] loss: 999.918
[27,     1] loss: 1055.647
[28,     1] loss: 997.303
[29,     1] loss: 951.075
[30,     1] loss: 957.475
[31,     1] loss: 1010.372
[32,     1] loss: 903.044
[33,     1] loss: 946.999
[34,     1] loss: 924.375
[35,     1] loss: 946.549
[36,     1] loss: 903.211
[37,     1] loss: 972.223
[38,     1] loss: 881.914
[39,     1] loss: 910.374
[40,     1] loss: 864.515
[41,     1] loss: 890.674
[42,     1] loss: 862.349
[43,     1] loss: 848.402
[44,     1] loss: 815.069
[45,     1] loss: 944.379
[46,     1] loss: 792.848
[47,     1] loss: 797.237
Early stopping applied (best metric=0.8688469529151917)
Finished Training
Total time taken: 6.402134895324707
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1321.031
[2,     1] loss: 1315.362
[3,     1] loss: 1320.960
[4,     1] loss: 1314.794
[5,     1] loss: 1303.453
[6,     1] loss: 1291.098
[7,     1] loss: 1267.778
[8,     1] loss: 1220.016
[9,     1] loss: 1163.756
[10,     1] loss: 1137.988
[11,     1] loss: 1135.684
[12,     1] loss: 1087.864
[13,     1] loss: 1065.907
[14,     1] loss: 1133.289
[15,     1] loss: 1070.753
[16,     1] loss: 1055.911
[17,     1] loss: 1042.836
[18,     1] loss: 1062.282
[19,     1] loss: 1011.482
[20,     1] loss: 1030.932
[21,     1] loss: 1013.001
[22,     1] loss: 977.002
[23,     1] loss: 1013.539
[24,     1] loss: 1017.419
[25,     1] loss: 982.417
[26,     1] loss: 961.649
[27,     1] loss: 987.500
[28,     1] loss: 942.478
[29,     1] loss: 919.588
[30,     1] loss: 945.435
[31,     1] loss: 961.693
[32,     1] loss: 994.557
[33,     1] loss: 889.184
[34,     1] loss: 896.346
[35,     1] loss: 937.243
[36,     1] loss: 900.393
[37,     1] loss: 873.811
[38,     1] loss: 852.547
[39,     1] loss: 877.331
[40,     1] loss: 879.040
[41,     1] loss: 839.833
[42,     1] loss: 823.225
[43,     1] loss: 861.545
[44,     1] loss: 1063.764
[45,     1] loss: 1316.219
[46,     1] loss: 934.945
[47,     1] loss: 1020.606
[48,     1] loss: 1111.437
[49,     1] loss: 1042.149
[50,     1] loss: 1002.085
[51,     1] loss: 965.680
[52,     1] loss: 985.262
[53,     1] loss: 952.735
[54,     1] loss: 950.545
[55,     1] loss: 919.445
[56,     1] loss: 923.766
[57,     1] loss: 914.994
[58,     1] loss: 921.840
[59,     1] loss: 864.635
[60,     1] loss: 879.674
[61,     1] loss: 900.407
[62,     1] loss: 889.752
Early stopping applied (best metric=0.8685443997383118)
Finished Training
Total time taken: 10.104212284088135
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1313.812
[2,     1] loss: 1317.217
[3,     1] loss: 1315.920
[4,     1] loss: 1314.933
[5,     1] loss: 1309.034
[6,     1] loss: 1308.497
[7,     1] loss: 1295.174
[8,     1] loss: 1282.581
[9,     1] loss: 1239.697
[10,     1] loss: 1196.912
[11,     1] loss: 1160.101
[12,     1] loss: 1103.979
[13,     1] loss: 1087.881
[14,     1] loss: 1127.264
[15,     1] loss: 1121.563
[16,     1] loss: 1047.167
[17,     1] loss: 1041.098
[18,     1] loss: 1098.272
[19,     1] loss: 1075.451
[20,     1] loss: 1066.860
[21,     1] loss: 1017.703
[22,     1] loss: 1040.230
[23,     1] loss: 964.307
[24,     1] loss: 1009.790
[25,     1] loss: 1035.583
[26,     1] loss: 972.365
[27,     1] loss: 980.917
[28,     1] loss: 946.324
[29,     1] loss: 973.573
[30,     1] loss: 948.311
[31,     1] loss: 926.069
[32,     1] loss: 981.532
[33,     1] loss: 907.821
[34,     1] loss: 881.948
[35,     1] loss: 930.431
[36,     1] loss: 858.359
[37,     1] loss: 870.517
[38,     1] loss: 899.319
[39,     1] loss: 830.705
[40,     1] loss: 889.575
[41,     1] loss: 823.019
[42,     1] loss: 789.662
[43,     1] loss: 939.594
[44,     1] loss: 1079.369
[45,     1] loss: 917.120
[46,     1] loss: 923.999
[47,     1] loss: 871.333
[48,     1] loss: 914.704
[49,     1] loss: 880.134
[50,     1] loss: 818.277
[51,     1] loss: 931.724
[52,     1] loss: 788.992
[53,     1] loss: 856.820
[54,     1] loss: 779.122
[55,     1] loss: 844.646
[56,     1] loss: 764.817
[57,     1] loss: 777.113
[58,     1] loss: 750.168
[59,     1] loss: 818.393
[60,     1] loss: 696.179
[61,     1] loss: 704.958
Early stopping applied (best metric=0.8964146971702576)
Finished Training
Total time taken: 8.356176137924194
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1313.204
[2,     1] loss: 1313.246
[3,     1] loss: 1309.532
[4,     1] loss: 1312.298
[5,     1] loss: 1310.357
[6,     1] loss: 1290.385
[7,     1] loss: 1278.753
[8,     1] loss: 1227.810
[9,     1] loss: 1196.289
[10,     1] loss: 1186.434
[11,     1] loss: 1135.522
[12,     1] loss: 1105.718
[13,     1] loss: 1138.427
[14,     1] loss: 1114.571
[15,     1] loss: 1050.551
[16,     1] loss: 1053.258
[17,     1] loss: 1087.974
[18,     1] loss: 1082.007
[19,     1] loss: 1031.808
[20,     1] loss: 1055.643
[21,     1] loss: 1022.188
[22,     1] loss: 1024.708
[23,     1] loss: 1014.990
[24,     1] loss: 1084.413
[25,     1] loss: 952.510
[26,     1] loss: 1004.196
[27,     1] loss: 980.551
[28,     1] loss: 948.090
[29,     1] loss: 955.195
[30,     1] loss: 956.917
[31,     1] loss: 883.308
[32,     1] loss: 919.274
[33,     1] loss: 894.574
[34,     1] loss: 945.514
[35,     1] loss: 859.274
[36,     1] loss: 922.694
[37,     1] loss: 981.643
[38,     1] loss: 983.966
[39,     1] loss: 904.615
[40,     1] loss: 829.345
[41,     1] loss: 877.034
[42,     1] loss: 860.987
[43,     1] loss: 834.492
[44,     1] loss: 800.540
[45,     1] loss: 853.435
[46,     1] loss: 813.585
[47,     1] loss: 1003.024
[48,     1] loss: 833.542
[49,     1] loss: 892.414
[50,     1] loss: 823.658
[51,     1] loss: 851.841
[52,     1] loss: 767.509
[53,     1] loss: 760.980
[54,     1] loss: 790.868
[55,     1] loss: 768.839
[56,     1] loss: 752.545
[57,     1] loss: 800.180
[58,     1] loss: 830.716
[59,     1] loss: 812.916
[60,     1] loss: 698.079
[61,     1] loss: 800.642
[62,     1] loss: 720.676
[63,     1] loss: 777.971
[64,     1] loss: 719.799
[65,     1] loss: 663.379
[66,     1] loss: 677.144
[67,     1] loss: 812.859
[68,     1] loss: 1104.668
[69,     1] loss: 682.807
[70,     1] loss: 1026.475
[71,     1] loss: 756.273
[72,     1] loss: 870.143
[73,     1] loss: 936.506
[74,     1] loss: 785.597
Early stopping applied (best metric=0.7706223726272583)
Finished Training
Total time taken: 12.119258403778076
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1312.705
[2,     1] loss: 1314.033
[3,     1] loss: 1318.918
[4,     1] loss: 1311.351
[5,     1] loss: 1308.431
[6,     1] loss: 1301.307
[7,     1] loss: 1297.030
[8,     1] loss: 1248.162
[9,     1] loss: 1205.631
[10,     1] loss: 1203.424
[11,     1] loss: 1132.002
[12,     1] loss: 1161.415
[13,     1] loss: 1101.689
[14,     1] loss: 1080.650
[15,     1] loss: 1108.558
[16,     1] loss: 1090.002
[17,     1] loss: 1054.844
[18,     1] loss: 1061.263
[19,     1] loss: 1050.863
[20,     1] loss: 1008.160
[21,     1] loss: 999.986
[22,     1] loss: 969.544
[23,     1] loss: 968.622
[24,     1] loss: 958.005
[25,     1] loss: 977.300
[26,     1] loss: 959.945
[27,     1] loss: 1024.293
[28,     1] loss: 990.944
[29,     1] loss: 922.890
[30,     1] loss: 909.632
[31,     1] loss: 1039.430
[32,     1] loss: 973.928
[33,     1] loss: 935.173
[34,     1] loss: 977.218
[35,     1] loss: 892.073
[36,     1] loss: 951.360
[37,     1] loss: 902.275
[38,     1] loss: 898.386
[39,     1] loss: 890.604
[40,     1] loss: 870.559
[41,     1] loss: 914.277
[42,     1] loss: 851.125
[43,     1] loss: 853.355
[44,     1] loss: 849.074
[45,     1] loss: 833.160
[46,     1] loss: 808.122
[47,     1] loss: 863.654
[48,     1] loss: 820.917
[49,     1] loss: 846.761
[50,     1] loss: 865.999
[51,     1] loss: 836.154
[52,     1] loss: 766.661
[53,     1] loss: 854.352
[54,     1] loss: 752.307
[55,     1] loss: 785.945
[56,     1] loss: 800.211
[57,     1] loss: 749.525
[58,     1] loss: 684.595
[59,     1] loss: 740.234
[60,     1] loss: 877.881
[61,     1] loss: 836.525
[62,     1] loss: 680.469
[63,     1] loss: 765.022
[64,     1] loss: 704.195
[65,     1] loss: 666.217
[66,     1] loss: 698.958
Early stopping applied (best metric=0.8137813210487366)
Finished Training
Total time taken: 11.014232158660889
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1319.183
[2,     1] loss: 1316.676
[3,     1] loss: 1310.219
[4,     1] loss: 1309.528
[5,     1] loss: 1315.175
[6,     1] loss: 1309.420
[7,     1] loss: 1296.354
[8,     1] loss: 1270.569
[9,     1] loss: 1241.355
[10,     1] loss: 1193.741
[11,     1] loss: 1158.000
[12,     1] loss: 1131.724
[13,     1] loss: 1093.409
[14,     1] loss: 1087.245
[15,     1] loss: 1036.423
[16,     1] loss: 1040.305
[17,     1] loss: 1150.458
[18,     1] loss: 1079.278
[19,     1] loss: 1051.733
[20,     1] loss: 1026.766
[21,     1] loss: 1025.528
[22,     1] loss: 1036.668
[23,     1] loss: 988.120
[24,     1] loss: 1005.993
[25,     1] loss: 1023.860
[26,     1] loss: 959.696
[27,     1] loss: 943.705
[28,     1] loss: 903.345
[29,     1] loss: 956.203
[30,     1] loss: 860.208
[31,     1] loss: 876.833
[32,     1] loss: 924.919
[33,     1] loss: 956.810
[34,     1] loss: 874.229
[35,     1] loss: 1011.230
[36,     1] loss: 869.041
[37,     1] loss: 977.287
[38,     1] loss: 894.733
[39,     1] loss: 918.861
[40,     1] loss: 897.494
[41,     1] loss: 814.849
[42,     1] loss: 879.884
[43,     1] loss: 755.910
[44,     1] loss: 913.571
[45,     1] loss: 803.534
[46,     1] loss: 893.250
[47,     1] loss: 725.912
[48,     1] loss: 807.043
Early stopping applied (best metric=0.9122350811958313)
Finished Training
Total time taken: 7.414156198501587
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1316.859
[2,     1] loss: 1318.704
[3,     1] loss: 1314.644
[4,     1] loss: 1314.518
[5,     1] loss: 1316.844
[6,     1] loss: 1312.562
[7,     1] loss: 1309.126
[8,     1] loss: 1308.538
[9,     1] loss: 1298.581
[10,     1] loss: 1290.194
[11,     1] loss: 1252.597
[12,     1] loss: 1213.174
[13,     1] loss: 1176.633
[14,     1] loss: 1191.375
[15,     1] loss: 1123.701
[16,     1] loss: 1141.639
[17,     1] loss: 1102.746
[18,     1] loss: 1128.564
[19,     1] loss: 1057.005
[20,     1] loss: 1067.020
[21,     1] loss: 1100.870
[22,     1] loss: 1113.745
[23,     1] loss: 1037.993
[24,     1] loss: 1055.133
[25,     1] loss: 972.145
[26,     1] loss: 1027.195
[27,     1] loss: 979.282
[28,     1] loss: 962.362
[29,     1] loss: 946.870
[30,     1] loss: 1001.261
[31,     1] loss: 943.198
[32,     1] loss: 1052.767
[33,     1] loss: 999.988
[34,     1] loss: 918.329
[35,     1] loss: 975.937
[36,     1] loss: 934.163
[37,     1] loss: 994.676
[38,     1] loss: 929.670
[39,     1] loss: 930.822
[40,     1] loss: 853.164
[41,     1] loss: 879.839
[42,     1] loss: 893.816
[43,     1] loss: 971.836
[44,     1] loss: 968.547
[45,     1] loss: 845.875
[46,     1] loss: 877.881
[47,     1] loss: 894.300
[48,     1] loss: 876.479
Early stopping applied (best metric=0.7822853326797485)
Finished Training
Total time taken: 7.926167249679565
{'Hydroxylation-K Validation Accuracy': 0.7534869976359337, 'Hydroxylation-K Validation Sensitivity': 0.6725925925925926, 'Hydroxylation-K Validation Specificity': 0.7736842105263158, 'Hydroxylation-K Validation Precision': 0.446019621895581, 'Hydroxylation-K AUC ROC': 0.7985380116959064, 'Hydroxylation-K AUC PR': 0.5949519276351377, 'Hydroxylation-K MCC': 0.39503363341845443, 'Hydroxylation-K F1': 0.5278951832715274, 'Validation Loss (Hydroxylation-K)': 0.4398753503958384, 'Hydroxylation-P Validation Accuracy': 0.8093565301253743, 'Hydroxylation-P Validation Sensitivity': 0.7730687830687831, 'Hydroxylation-P Validation Specificity': 0.8172602124794254, 'Hydroxylation-P Validation Precision': 0.48459433799684337, 'Hydroxylation-P AUC ROC': 0.8576231546203864, 'Hydroxylation-P AUC PR': 0.5928971587622623, 'Hydroxylation-P MCC': 0.5023623357114089, 'Hydroxylation-P F1': 0.590982628110362, 'Validation Loss (Hydroxylation-P)': 0.3701962192853292, 'Validation Loss (total)': 0.8100715756416321, 'TimeToTrain': 9.989277553558349}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014562064178232834,
 'learning_rate_Hydroxylation-K': 0.00021341449703737208,
 'learning_rate_Hydroxylation-P': 0.004443056923047795,
 'log_base': 2.9800195361372097,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1203625881,
 'sample_weights': [1.924348646929651, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.256466845845897,
 'weight_decay_Hydroxylation-K': 6.958940039560279,
 'weight_decay_Hydroxylation-P': 9.42759001018698}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.048
[2,     1] loss: 1229.822
[3,     1] loss: 1231.942
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005306688984067017,
 'learning_rate_Hydroxylation-K': 0.008108383555526212,
 'learning_rate_Hydroxylation-P': 0.00807983767639524,
 'log_base': 2.3283153658675357,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3814085343,
 'sample_weights': [1.5288922982308306, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.4775325072169903,
 'weight_decay_Hydroxylation-K': 7.521285768018454,
 'weight_decay_Hydroxylation-P': 2.4614724687244296}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1325.701
[2,     1] loss: 1325.847
[3,     1] loss: 1330.449
[4,     1] loss: 1324.154
[5,     1] loss: 1320.636
[6,     1] loss: 1324.497
[7,     1] loss: 1319.427
[8,     1] loss: 1315.051
[9,     1] loss: 1305.321
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019490463555940636,
 'learning_rate_Hydroxylation-K': 0.006731382446718087,
 'learning_rate_Hydroxylation-P': 0.005531831561883183,
 'log_base': 2.803201475525179,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2083734536,
 'sample_weights': [1.9753334313537898, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2640161986226137,
 'weight_decay_Hydroxylation-K': 5.739362440568165,
 'weight_decay_Hydroxylation-P': 9.664710613608058}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1250.596
[2,     1] loss: 1246.243
[3,     1] loss: 1249.894
[4,     1] loss: 1241.982
[5,     1] loss: 1224.374
[6,     1] loss: 1208.323
[7,     1] loss: 1157.710
[8,     1] loss: 1111.032
[9,     1] loss: 1068.898
[10,     1] loss: 1062.310
[11,     1] loss: 1030.426
[12,     1] loss: 1052.715
[13,     1] loss: 1003.235
[14,     1] loss: 1008.616
[15,     1] loss: 1010.488
[16,     1] loss: 1014.197
[17,     1] loss: 1029.443
[18,     1] loss: 1004.163
[19,     1] loss: 1000.318
[20,     1] loss: 967.948
[21,     1] loss: 1026.921
[22,     1] loss: 989.132
[23,     1] loss: 962.616
[24,     1] loss: 966.030
[25,     1] loss: 956.584
[26,     1] loss: 947.632
[27,     1] loss: 951.164
[28,     1] loss: 906.686
[29,     1] loss: 934.592
[30,     1] loss: 924.701
[31,     1] loss: 914.467
[32,     1] loss: 916.880
[33,     1] loss: 855.307
[34,     1] loss: 906.114
[35,     1] loss: 900.438
[36,     1] loss: 864.371
[37,     1] loss: 817.737
[38,     1] loss: 849.143
[39,     1] loss: 826.128
[40,     1] loss: 818.118
[41,     1] loss: 866.438
[42,     1] loss: 822.519
[43,     1] loss: 805.375
[44,     1] loss: 755.681
[45,     1] loss: 770.649
[46,     1] loss: 714.846
[47,     1] loss: 788.549
[48,     1] loss: 749.210
[49,     1] loss: 744.700
[50,     1] loss: 759.810
[51,     1] loss: 730.407
[52,     1] loss: 740.988
[53,     1] loss: 701.448
[54,     1] loss: 644.554
[55,     1] loss: 705.620
[56,     1] loss: 631.005
[57,     1] loss: 666.586
[58,     1] loss: 731.060
[59,     1] loss: 682.424
Early stopping applied (best metric=0.787750244140625)
Finished Training
Total time taken: 8.020170211791992
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1257.435
[2,     1] loss: 1250.323
[3,     1] loss: 1246.438
[4,     1] loss: 1256.369
[5,     1] loss: 1249.968
[6,     1] loss: 1246.914
[7,     1] loss: 1240.629
[8,     1] loss: 1224.136
[9,     1] loss: 1222.329
[10,     1] loss: 1183.493
[11,     1] loss: 1158.985
[12,     1] loss: 1134.808
[13,     1] loss: 1103.377
[14,     1] loss: 1080.585
[15,     1] loss: 1089.647
[16,     1] loss: 1066.726
[17,     1] loss: 1042.382
[18,     1] loss: 1032.769
[19,     1] loss: 1075.281
[20,     1] loss: 1006.474
[21,     1] loss: 1020.608
[22,     1] loss: 1018.966
[23,     1] loss: 1058.679
[24,     1] loss: 1038.553
[25,     1] loss: 1024.226
[26,     1] loss: 995.514
[27,     1] loss: 1021.772
[28,     1] loss: 980.684
[29,     1] loss: 984.929
[30,     1] loss: 926.241
[31,     1] loss: 964.890
[32,     1] loss: 927.393
[33,     1] loss: 931.469
[34,     1] loss: 981.860
[35,     1] loss: 966.924
[36,     1] loss: 937.377
[37,     1] loss: 979.458
[38,     1] loss: 916.144
[39,     1] loss: 924.093
[40,     1] loss: 899.152
[41,     1] loss: 917.031
[42,     1] loss: 901.087
[43,     1] loss: 851.794
[44,     1] loss: 877.522
[45,     1] loss: 912.692
[46,     1] loss: 885.264
[47,     1] loss: 818.684
[48,     1] loss: 899.077
[49,     1] loss: 869.487
[50,     1] loss: 835.290
[51,     1] loss: 796.528
[52,     1] loss: 827.556
[53,     1] loss: 793.968
[54,     1] loss: 824.470
[55,     1] loss: 779.637
[56,     1] loss: 786.104
Early stopping applied (best metric=0.7282378673553467)
Finished Training
Total time taken: 9.249194622039795
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1251.318
[2,     1] loss: 1248.694
[3,     1] loss: 1252.385
[4,     1] loss: 1244.319
[5,     1] loss: 1246.467
[6,     1] loss: 1233.954
[7,     1] loss: 1222.737
[8,     1] loss: 1198.607
[9,     1] loss: 1170.312
[10,     1] loss: 1138.160
[11,     1] loss: 1083.113
[12,     1] loss: 1067.246
[13,     1] loss: 1062.748
[14,     1] loss: 1064.020
[15,     1] loss: 1059.919
[16,     1] loss: 1010.236
[17,     1] loss: 1047.947
[18,     1] loss: 1009.577
[19,     1] loss: 1027.576
[20,     1] loss: 998.785
[21,     1] loss: 985.158
[22,     1] loss: 965.087
[23,     1] loss: 985.410
[24,     1] loss: 952.894
[25,     1] loss: 930.071
[26,     1] loss: 965.470
[27,     1] loss: 930.124
[28,     1] loss: 931.462
[29,     1] loss: 934.827
[30,     1] loss: 893.690
[31,     1] loss: 872.728
[32,     1] loss: 943.830
[33,     1] loss: 909.068
[34,     1] loss: 927.769
[35,     1] loss: 930.581
[36,     1] loss: 878.105
[37,     1] loss: 853.045
[38,     1] loss: 911.195
[39,     1] loss: 879.801
[40,     1] loss: 856.952
[41,     1] loss: 870.379
[42,     1] loss: 845.041
[43,     1] loss: 831.003
[44,     1] loss: 819.931
[45,     1] loss: 828.963
[46,     1] loss: 848.788
[47,     1] loss: 778.383
[48,     1] loss: 737.491
[49,     1] loss: 765.765
[50,     1] loss: 762.351
[51,     1] loss: 750.325
[52,     1] loss: 710.993
[53,     1] loss: 770.466
[54,     1] loss: 726.592
[55,     1] loss: 746.423
[56,     1] loss: 735.804
[57,     1] loss: 717.609
[58,     1] loss: 717.956
[59,     1] loss: 706.574
[60,     1] loss: 708.676
[61,     1] loss: 721.986
[62,     1] loss: 714.004
[63,     1] loss: 694.101
[64,     1] loss: 645.214
[65,     1] loss: 713.789
Early stopping applied (best metric=0.8436479568481445)
Finished Training
Total time taken: 10.903231859207153
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1252.480
[2,     1] loss: 1253.418
[3,     1] loss: 1248.428
[4,     1] loss: 1246.662
[5,     1] loss: 1252.207
[6,     1] loss: 1249.870
[7,     1] loss: 1246.413
[8,     1] loss: 1243.399
[9,     1] loss: 1242.743
[10,     1] loss: 1235.168
[11,     1] loss: 1221.965
[12,     1] loss: 1203.723
[13,     1] loss: 1173.256
[14,     1] loss: 1138.434
[15,     1] loss: 1100.322
[16,     1] loss: 1064.489
[17,     1] loss: 1081.975
[18,     1] loss: 1067.257
[19,     1] loss: 1042.120
[20,     1] loss: 1082.146
[21,     1] loss: 1049.479
[22,     1] loss: 1033.941
[23,     1] loss: 1087.803
[24,     1] loss: 1022.237
[25,     1] loss: 1028.052
[26,     1] loss: 1014.500
[27,     1] loss: 968.832
[28,     1] loss: 984.988
[29,     1] loss: 1032.342
[30,     1] loss: 956.220
[31,     1] loss: 903.306
[32,     1] loss: 996.394
[33,     1] loss: 936.086
[34,     1] loss: 929.178
[35,     1] loss: 991.808
[36,     1] loss: 923.496
[37,     1] loss: 917.305
[38,     1] loss: 950.328
[39,     1] loss: 960.059
[40,     1] loss: 886.981
[41,     1] loss: 924.360
[42,     1] loss: 936.813
[43,     1] loss: 903.375
[44,     1] loss: 892.345
[45,     1] loss: 921.796
[46,     1] loss: 865.372
[47,     1] loss: 904.655
[48,     1] loss: 875.166
[49,     1] loss: 837.046
[50,     1] loss: 876.804
[51,     1] loss: 831.946
[52,     1] loss: 846.992
[53,     1] loss: 818.074
[54,     1] loss: 832.935
[55,     1] loss: 776.210
[56,     1] loss: 800.159
[57,     1] loss: 835.313
[58,     1] loss: 766.659
[59,     1] loss: 817.834
[60,     1] loss: 727.460
[61,     1] loss: 805.407
[62,     1] loss: 758.180
[63,     1] loss: 821.762
[64,     1] loss: 760.860
[65,     1] loss: 743.471
[66,     1] loss: 744.867
[67,     1] loss: 702.802
[68,     1] loss: 724.803
[69,     1] loss: 661.442
[70,     1] loss: 670.077
[71,     1] loss: 667.998
[72,     1] loss: 671.818
[73,     1] loss: 651.286
[74,     1] loss: 675.060
[75,     1] loss: 656.425
[76,     1] loss: 645.197
[77,     1] loss: 691.703
[78,     1] loss: 693.475
[79,     1] loss: 602.787
Early stopping applied (best metric=0.7710116505622864)
Finished Training
Total time taken: 13.247278213500977
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1259.833
[2,     1] loss: 1251.378
[3,     1] loss: 1254.465
[4,     1] loss: 1246.689
[5,     1] loss: 1248.302
[6,     1] loss: 1249.252
[7,     1] loss: 1246.742
[8,     1] loss: 1241.824
[9,     1] loss: 1236.898
[10,     1] loss: 1223.015
[11,     1] loss: 1214.208
[12,     1] loss: 1183.547
[13,     1] loss: 1171.945
[14,     1] loss: 1145.738
[15,     1] loss: 1113.510
[16,     1] loss: 1114.427
[17,     1] loss: 1092.256
[18,     1] loss: 1087.111
[19,     1] loss: 1089.142
[20,     1] loss: 1009.847
[21,     1] loss: 1033.247
[22,     1] loss: 1035.640
[23,     1] loss: 1036.550
[24,     1] loss: 1008.397
[25,     1] loss: 1010.915
[26,     1] loss: 1004.473
[27,     1] loss: 995.025
[28,     1] loss: 1005.021
[29,     1] loss: 996.105
[30,     1] loss: 987.758
[31,     1] loss: 947.410
[32,     1] loss: 970.504
[33,     1] loss: 932.245
[34,     1] loss: 978.615
[35,     1] loss: 939.000
[36,     1] loss: 901.026
[37,     1] loss: 887.799
[38,     1] loss: 865.651
[39,     1] loss: 899.060
[40,     1] loss: 873.339
[41,     1] loss: 899.700
[42,     1] loss: 876.880
[43,     1] loss: 872.520
[44,     1] loss: 831.744
[45,     1] loss: 840.060
[46,     1] loss: 868.552
[47,     1] loss: 827.646
[48,     1] loss: 807.342
[49,     1] loss: 821.735
[50,     1] loss: 859.717
[51,     1] loss: 887.932
[52,     1] loss: 796.606
[53,     1] loss: 877.429
[54,     1] loss: 780.942
[55,     1] loss: 820.797
[56,     1] loss: 817.712
[57,     1] loss: 810.308
[58,     1] loss: 824.782
[59,     1] loss: 762.341
[60,     1] loss: 761.136
[61,     1] loss: 763.678
[62,     1] loss: 737.881
[63,     1] loss: 815.957
[64,     1] loss: 707.818
[65,     1] loss: 710.024
[66,     1] loss: 741.309
[67,     1] loss: 763.303
[68,     1] loss: 666.428
[69,     1] loss: 695.431
[70,     1] loss: 739.009
[71,     1] loss: 751.328
[72,     1] loss: 707.732
[73,     1] loss: 720.035
[74,     1] loss: 609.326
[75,     1] loss: 678.927
[76,     1] loss: 675.390
[77,     1] loss: 676.050
Early stopping applied (best metric=0.9022334814071655)
Finished Training
Total time taken: 11.013232469558716
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1251.816
[2,     1] loss: 1250.154
[3,     1] loss: 1249.980
[4,     1] loss: 1247.006
[5,     1] loss: 1246.842
[6,     1] loss: 1230.394
[7,     1] loss: 1218.117
[8,     1] loss: 1173.911
[9,     1] loss: 1129.866
[10,     1] loss: 1097.056
[11,     1] loss: 1098.272
[12,     1] loss: 1049.400
[13,     1] loss: 1006.109
[14,     1] loss: 1051.003
[15,     1] loss: 1074.843
[16,     1] loss: 1035.868
[17,     1] loss: 975.966
[18,     1] loss: 967.213
[19,     1] loss: 949.714
[20,     1] loss: 996.191
[21,     1] loss: 982.416
[22,     1] loss: 987.398
[23,     1] loss: 967.606
[24,     1] loss: 956.312
[25,     1] loss: 950.738
[26,     1] loss: 971.788
[27,     1] loss: 959.808
[28,     1] loss: 944.625
[29,     1] loss: 923.659
[30,     1] loss: 932.829
[31,     1] loss: 937.214
[32,     1] loss: 893.643
Early stopping applied (best metric=0.9327388405799866)
Finished Training
Total time taken: 5.364112854003906
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1251.750
[2,     1] loss: 1251.629
[3,     1] loss: 1252.870
[4,     1] loss: 1250.799
[5,     1] loss: 1249.504
[6,     1] loss: 1244.672
[7,     1] loss: 1243.055
[8,     1] loss: 1239.095
[9,     1] loss: 1227.770
[10,     1] loss: 1202.905
[11,     1] loss: 1177.496
[12,     1] loss: 1140.228
[13,     1] loss: 1104.417
[14,     1] loss: 1084.979
[15,     1] loss: 1035.585
[16,     1] loss: 1072.289
[17,     1] loss: 1033.746
[18,     1] loss: 1064.471
[19,     1] loss: 1078.735
[20,     1] loss: 1025.398
[21,     1] loss: 1028.255
[22,     1] loss: 981.922
[23,     1] loss: 1008.760
[24,     1] loss: 982.343
[25,     1] loss: 1000.354
[26,     1] loss: 984.611
[27,     1] loss: 978.758
[28,     1] loss: 930.400
[29,     1] loss: 896.517
[30,     1] loss: 946.426
[31,     1] loss: 932.960
[32,     1] loss: 940.837
[33,     1] loss: 900.303
[34,     1] loss: 855.190
[35,     1] loss: 900.751
[36,     1] loss: 869.104
[37,     1] loss: 883.451
[38,     1] loss: 842.075
[39,     1] loss: 869.388
[40,     1] loss: 816.348
[41,     1] loss: 867.805
[42,     1] loss: 834.454
[43,     1] loss: 837.336
[44,     1] loss: 815.678
[45,     1] loss: 834.394
[46,     1] loss: 840.658
[47,     1] loss: 775.372
[48,     1] loss: 839.908
[49,     1] loss: 835.882
[50,     1] loss: 745.691
[51,     1] loss: 744.991
[52,     1] loss: 758.171
[53,     1] loss: 729.500
[54,     1] loss: 742.538
[55,     1] loss: 784.475
[56,     1] loss: 727.891
[57,     1] loss: 702.899
[58,     1] loss: 734.789
[59,     1] loss: 713.407
[60,     1] loss: 683.662
[61,     1] loss: 732.065
[62,     1] loss: 681.537
[63,     1] loss: 701.595
[64,     1] loss: 679.293
[65,     1] loss: 681.959
[66,     1] loss: 629.178
[67,     1] loss: 628.051
[68,     1] loss: 738.454
[69,     1] loss: 596.633
[70,     1] loss: 693.917
[71,     1] loss: 615.054
[72,     1] loss: 597.766
[73,     1] loss: 599.755
[74,     1] loss: 564.473
[75,     1] loss: 595.421
[76,     1] loss: 592.995
Early stopping applied (best metric=0.7925800085067749)
Finished Training
Total time taken: 11.197235822677612
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1254.507
[2,     1] loss: 1251.195
[3,     1] loss: 1251.820
[4,     1] loss: 1248.470
[5,     1] loss: 1249.449
[6,     1] loss: 1245.444
[7,     1] loss: 1246.321
[8,     1] loss: 1244.615
[9,     1] loss: 1227.796
[10,     1] loss: 1217.819
[11,     1] loss: 1194.580
[12,     1] loss: 1162.980
[13,     1] loss: 1137.081
[14,     1] loss: 1129.875
[15,     1] loss: 1062.252
[16,     1] loss: 1065.468
[17,     1] loss: 1079.578
[18,     1] loss: 1047.262
[19,     1] loss: 1011.439
[20,     1] loss: 998.223
[21,     1] loss: 1018.001
[22,     1] loss: 1025.430
[23,     1] loss: 997.202
[24,     1] loss: 967.815
[25,     1] loss: 985.688
[26,     1] loss: 957.865
[27,     1] loss: 981.810
[28,     1] loss: 995.971
[29,     1] loss: 940.816
[30,     1] loss: 991.622
[31,     1] loss: 928.112
[32,     1] loss: 971.690
[33,     1] loss: 949.236
[34,     1] loss: 980.932
[35,     1] loss: 960.056
[36,     1] loss: 917.639
[37,     1] loss: 955.736
[38,     1] loss: 902.550
[39,     1] loss: 904.256
[40,     1] loss: 883.622
[41,     1] loss: 877.768
[42,     1] loss: 899.875
[43,     1] loss: 868.405
[44,     1] loss: 838.856
[45,     1] loss: 853.086
[46,     1] loss: 880.375
[47,     1] loss: 816.768
[48,     1] loss: 854.329
[49,     1] loss: 885.233
[50,     1] loss: 775.747
[51,     1] loss: 808.883
[52,     1] loss: 776.211
[53,     1] loss: 859.430
[54,     1] loss: 746.066
[55,     1] loss: 825.164
[56,     1] loss: 740.919
[57,     1] loss: 775.082
[58,     1] loss: 775.327
[59,     1] loss: 739.745
[60,     1] loss: 769.070
[61,     1] loss: 722.105
[62,     1] loss: 682.486
[63,     1] loss: 692.539
[64,     1] loss: 707.699
[65,     1] loss: 672.746
[66,     1] loss: 631.682
[67,     1] loss: 696.968
[68,     1] loss: 659.363
[69,     1] loss: 660.330
[70,     1] loss: 599.325
[71,     1] loss: 670.218
[72,     1] loss: 668.619
[73,     1] loss: 653.176
[74,     1] loss: 664.930
[75,     1] loss: 611.677
Early stopping applied (best metric=0.7082850933074951)
Finished Training
Total time taken: 12.035253763198853
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1253.531
[2,     1] loss: 1250.030
[3,     1] loss: 1248.049
[4,     1] loss: 1249.447
[5,     1] loss: 1245.597
[6,     1] loss: 1250.846
[7,     1] loss: 1243.110
[8,     1] loss: 1236.936
[9,     1] loss: 1224.767
[10,     1] loss: 1209.410
[11,     1] loss: 1175.529
[12,     1] loss: 1149.212
[13,     1] loss: 1101.726
[14,     1] loss: 1106.536
[15,     1] loss: 1081.939
[16,     1] loss: 1108.921
[17,     1] loss: 1086.975
[18,     1] loss: 1077.509
[19,     1] loss: 1018.073
[20,     1] loss: 1062.227
[21,     1] loss: 1062.130
[22,     1] loss: 1031.531
[23,     1] loss: 1032.352
[24,     1] loss: 991.258
[25,     1] loss: 1019.889
[26,     1] loss: 972.632
[27,     1] loss: 1021.536
[28,     1] loss: 977.842
[29,     1] loss: 995.256
[30,     1] loss: 978.665
[31,     1] loss: 955.482
[32,     1] loss: 935.803
[33,     1] loss: 918.949
[34,     1] loss: 957.148
[35,     1] loss: 943.920
[36,     1] loss: 931.230
[37,     1] loss: 916.427
[38,     1] loss: 962.427
[39,     1] loss: 899.028
[40,     1] loss: 872.232
[41,     1] loss: 880.170
[42,     1] loss: 841.346
[43,     1] loss: 848.985
[44,     1] loss: 861.371
[45,     1] loss: 842.964
[46,     1] loss: 852.866
[47,     1] loss: 791.467
[48,     1] loss: 803.487
[49,     1] loss: 731.370
[50,     1] loss: 835.054
[51,     1] loss: 802.166
[52,     1] loss: 788.735
[53,     1] loss: 781.870
[54,     1] loss: 731.107
[55,     1] loss: 747.265
[56,     1] loss: 721.106
[57,     1] loss: 702.005
[58,     1] loss: 738.698
[59,     1] loss: 713.594
[60,     1] loss: 694.422
Early stopping applied (best metric=0.8556251525878906)
Finished Training
Total time taken: 8.355175733566284
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1255.760
[2,     1] loss: 1253.643
[3,     1] loss: 1249.775
[4,     1] loss: 1249.496
[5,     1] loss: 1245.325
[6,     1] loss: 1245.647
[7,     1] loss: 1234.081
[8,     1] loss: 1228.833
[9,     1] loss: 1203.807
[10,     1] loss: 1171.544
[11,     1] loss: 1135.408
[12,     1] loss: 1111.729
[13,     1] loss: 1095.400
[14,     1] loss: 1078.525
[15,     1] loss: 1073.122
[16,     1] loss: 1042.889
[17,     1] loss: 1104.806
[18,     1] loss: 1038.316
[19,     1] loss: 1033.351
[20,     1] loss: 1043.460
[21,     1] loss: 1010.926
[22,     1] loss: 1011.055
[23,     1] loss: 950.142
[24,     1] loss: 1014.005
[25,     1] loss: 1016.827
[26,     1] loss: 1007.404
[27,     1] loss: 984.818
[28,     1] loss: 1025.233
[29,     1] loss: 984.356
[30,     1] loss: 965.848
[31,     1] loss: 949.149
[32,     1] loss: 944.969
[33,     1] loss: 930.111
[34,     1] loss: 928.243
[35,     1] loss: 907.306
[36,     1] loss: 874.256
[37,     1] loss: 899.147
[38,     1] loss: 871.131
[39,     1] loss: 842.091
[40,     1] loss: 860.800
[41,     1] loss: 829.571
[42,     1] loss: 848.572
[43,     1] loss: 824.020
[44,     1] loss: 822.991
[45,     1] loss: 818.424
[46,     1] loss: 799.281
[47,     1] loss: 807.590
[48,     1] loss: 826.931
[49,     1] loss: 776.159
[50,     1] loss: 812.346
[51,     1] loss: 765.534
[52,     1] loss: 751.871
[53,     1] loss: 756.899
[54,     1] loss: 700.783
[55,     1] loss: 693.684
[56,     1] loss: 769.763
[57,     1] loss: 688.082
Early stopping applied (best metric=0.8011345863342285)
Finished Training
Total time taken: 8.206172227859497
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1256.083
[2,     1] loss: 1250.145
[3,     1] loss: 1249.354
[4,     1] loss: 1246.074
[5,     1] loss: 1247.327
[6,     1] loss: 1244.383
[7,     1] loss: 1241.552
[8,     1] loss: 1240.993
[9,     1] loss: 1230.073
[10,     1] loss: 1207.058
[11,     1] loss: 1177.965
[12,     1] loss: 1159.551
[13,     1] loss: 1117.223
[14,     1] loss: 1089.870
[15,     1] loss: 1074.588
[16,     1] loss: 1063.299
[17,     1] loss: 1060.320
[18,     1] loss: 1086.515
[19,     1] loss: 1000.158
[20,     1] loss: 1020.587
[21,     1] loss: 998.118
[22,     1] loss: 1004.986
[23,     1] loss: 1007.146
[24,     1] loss: 981.606
[25,     1] loss: 1003.069
[26,     1] loss: 974.475
[27,     1] loss: 970.452
[28,     1] loss: 967.361
[29,     1] loss: 995.929
[30,     1] loss: 953.698
[31,     1] loss: 952.082
[32,     1] loss: 956.414
[33,     1] loss: 912.065
[34,     1] loss: 948.052
[35,     1] loss: 900.654
[36,     1] loss: 918.124
[37,     1] loss: 930.886
[38,     1] loss: 860.757
[39,     1] loss: 877.630
[40,     1] loss: 878.118
[41,     1] loss: 863.994
[42,     1] loss: 890.880
[43,     1] loss: 825.462
[44,     1] loss: 836.620
[45,     1] loss: 826.766
[46,     1] loss: 780.867
[47,     1] loss: 784.932
[48,     1] loss: 810.848
[49,     1] loss: 747.608
[50,     1] loss: 781.359
[51,     1] loss: 767.852
[52,     1] loss: 770.213
[53,     1] loss: 765.313
[54,     1] loss: 744.323
[55,     1] loss: 691.612
[56,     1] loss: 773.972
[57,     1] loss: 718.832
[58,     1] loss: 661.057
[59,     1] loss: 676.088
[60,     1] loss: 703.947
[61,     1] loss: 616.819
[62,     1] loss: 637.116
[63,     1] loss: 642.720
Early stopping applied (best metric=0.7811357975006104)
Finished Training
Total time taken: 9.171193599700928
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1250.576
[2,     1] loss: 1255.121
[3,     1] loss: 1250.430
[4,     1] loss: 1246.494
[5,     1] loss: 1245.850
[6,     1] loss: 1247.464
[7,     1] loss: 1238.398
[8,     1] loss: 1227.886
[9,     1] loss: 1207.731
[10,     1] loss: 1171.469
[11,     1] loss: 1153.645
[12,     1] loss: 1124.132
[13,     1] loss: 1096.411
[14,     1] loss: 1044.953
[15,     1] loss: 1010.568
[16,     1] loss: 1046.229
[17,     1] loss: 1013.742
[18,     1] loss: 1027.625
[19,     1] loss: 979.059
[20,     1] loss: 1030.714
[21,     1] loss: 1008.469
[22,     1] loss: 1027.427
[23,     1] loss: 979.124
[24,     1] loss: 972.995
[25,     1] loss: 968.472
[26,     1] loss: 948.873
[27,     1] loss: 981.392
[28,     1] loss: 938.210
[29,     1] loss: 937.145
[30,     1] loss: 949.136
[31,     1] loss: 959.963
[32,     1] loss: 953.812
[33,     1] loss: 929.805
[34,     1] loss: 878.364
[35,     1] loss: 868.965
[36,     1] loss: 856.460
[37,     1] loss: 870.910
[38,     1] loss: 883.180
[39,     1] loss: 850.997
[40,     1] loss: 866.831
[41,     1] loss: 895.577
[42,     1] loss: 881.368
[43,     1] loss: 857.409
[44,     1] loss: 842.275
[45,     1] loss: 863.021
[46,     1] loss: 808.286
[47,     1] loss: 793.210
[48,     1] loss: 774.433
[49,     1] loss: 772.746
[50,     1] loss: 766.871
[51,     1] loss: 776.720
[52,     1] loss: 737.064
[53,     1] loss: 769.507
[54,     1] loss: 757.861
[55,     1] loss: 745.177
[56,     1] loss: 720.044
[57,     1] loss: 716.121
[58,     1] loss: 699.903
[59,     1] loss: 694.930
[60,     1] loss: 658.295
[61,     1] loss: 729.059
[62,     1] loss: 658.433
[63,     1] loss: 647.357
[64,     1] loss: 618.984
[65,     1] loss: 639.143
Early stopping applied (best metric=0.8023855686187744)
Finished Training
Total time taken: 8.902188777923584
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1252.727
[2,     1] loss: 1249.421
[3,     1] loss: 1248.234
[4,     1] loss: 1247.664
[5,     1] loss: 1249.143
[6,     1] loss: 1244.414
[7,     1] loss: 1235.126
[8,     1] loss: 1218.976
[9,     1] loss: 1202.591
[10,     1] loss: 1177.076
[11,     1] loss: 1138.209
[12,     1] loss: 1106.345
[13,     1] loss: 1075.378
[14,     1] loss: 1089.369
[15,     1] loss: 1026.819
[16,     1] loss: 988.819
[17,     1] loss: 1019.776
[18,     1] loss: 1048.514
[19,     1] loss: 1030.908
[20,     1] loss: 1006.518
[21,     1] loss: 1012.889
[22,     1] loss: 1017.578
[23,     1] loss: 1014.702
[24,     1] loss: 975.025
[25,     1] loss: 1062.905
[26,     1] loss: 1000.005
[27,     1] loss: 964.621
[28,     1] loss: 981.329
[29,     1] loss: 970.824
[30,     1] loss: 946.817
[31,     1] loss: 958.492
[32,     1] loss: 943.630
[33,     1] loss: 885.099
[34,     1] loss: 974.416
[35,     1] loss: 888.254
[36,     1] loss: 933.533
[37,     1] loss: 933.079
[38,     1] loss: 893.247
[39,     1] loss: 936.019
[40,     1] loss: 910.758
[41,     1] loss: 868.472
[42,     1] loss: 904.064
[43,     1] loss: 833.825
[44,     1] loss: 854.431
[45,     1] loss: 867.531
[46,     1] loss: 886.147
Early stopping applied (best metric=0.941565752029419)
Finished Training
Total time taken: 7.690163612365723
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1251.414
[2,     1] loss: 1245.115
[3,     1] loss: 1258.876
[4,     1] loss: 1255.303
[5,     1] loss: 1252.625
[6,     1] loss: 1239.729
[7,     1] loss: 1239.306
[8,     1] loss: 1222.694
[9,     1] loss: 1201.516
[10,     1] loss: 1182.738
[11,     1] loss: 1141.581
[12,     1] loss: 1101.674
[13,     1] loss: 1073.690
[14,     1] loss: 1052.917
[15,     1] loss: 1035.176
[16,     1] loss: 1080.072
[17,     1] loss: 1117.392
[18,     1] loss: 1065.216
[19,     1] loss: 998.189
[20,     1] loss: 1002.621
[21,     1] loss: 953.948
[22,     1] loss: 993.344
[23,     1] loss: 1043.477
[24,     1] loss: 983.809
[25,     1] loss: 980.577
[26,     1] loss: 996.357
[27,     1] loss: 954.688
[28,     1] loss: 986.680
[29,     1] loss: 960.180
[30,     1] loss: 955.109
[31,     1] loss: 905.090
[32,     1] loss: 981.759
[33,     1] loss: 898.376
[34,     1] loss: 958.539
[35,     1] loss: 910.111
[36,     1] loss: 901.891
[37,     1] loss: 898.140
[38,     1] loss: 902.758
[39,     1] loss: 909.675
[40,     1] loss: 883.186
[41,     1] loss: 844.655
[42,     1] loss: 887.702
[43,     1] loss: 877.914
[44,     1] loss: 825.210
[45,     1] loss: 860.922
[46,     1] loss: 848.608
[47,     1] loss: 844.791
[48,     1] loss: 795.971
[49,     1] loss: 798.795
[50,     1] loss: 833.143
[51,     1] loss: 808.930
[52,     1] loss: 825.805
[53,     1] loss: 768.484
[54,     1] loss: 791.768
[55,     1] loss: 763.087
[56,     1] loss: 771.346
[57,     1] loss: 770.936
[58,     1] loss: 770.420
[59,     1] loss: 748.568
[60,     1] loss: 704.911
[61,     1] loss: 752.845
[62,     1] loss: 739.184
[63,     1] loss: 690.869
[64,     1] loss: 747.505
[65,     1] loss: 714.586
[66,     1] loss: 733.534
[67,     1] loss: 662.743
[68,     1] loss: 711.295
[69,     1] loss: 692.391
[70,     1] loss: 670.968
[71,     1] loss: 652.342
[72,     1] loss: 622.594
[73,     1] loss: 692.194
[74,     1] loss: 659.511
[75,     1] loss: 625.360
Early stopping applied (best metric=0.771591305732727)
Finished Training
Total time taken: 12.417261600494385
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1256.106
[2,     1] loss: 1250.437
[3,     1] loss: 1253.082
[4,     1] loss: 1250.356
[5,     1] loss: 1248.494
[6,     1] loss: 1246.704
[7,     1] loss: 1239.507
[8,     1] loss: 1230.575
[9,     1] loss: 1211.878
[10,     1] loss: 1184.246
[11,     1] loss: 1152.406
[12,     1] loss: 1106.310
[13,     1] loss: 1099.694
[14,     1] loss: 1062.357
[15,     1] loss: 1082.459
[16,     1] loss: 1069.224
[17,     1] loss: 1074.543
[18,     1] loss: 1011.905
[19,     1] loss: 1042.992
[20,     1] loss: 1020.287
[21,     1] loss: 1071.308
[22,     1] loss: 1062.069
[23,     1] loss: 1003.912
[24,     1] loss: 1038.012
[25,     1] loss: 1041.048
[26,     1] loss: 974.104
[27,     1] loss: 965.861
[28,     1] loss: 985.856
[29,     1] loss: 995.802
[30,     1] loss: 918.281
[31,     1] loss: 949.430
[32,     1] loss: 1019.091
[33,     1] loss: 952.440
[34,     1] loss: 979.892
[35,     1] loss: 959.871
[36,     1] loss: 969.116
[37,     1] loss: 898.152
[38,     1] loss: 944.117
[39,     1] loss: 882.579
[40,     1] loss: 876.590
[41,     1] loss: 915.561
[42,     1] loss: 891.385
[43,     1] loss: 853.738
[44,     1] loss: 877.463
[45,     1] loss: 933.336
[46,     1] loss: 828.050
[47,     1] loss: 860.683
[48,     1] loss: 874.856
[49,     1] loss: 855.805
[50,     1] loss: 887.024
[51,     1] loss: 866.332
[52,     1] loss: 845.193
[53,     1] loss: 803.933
[54,     1] loss: 828.685
[55,     1] loss: 762.167
[56,     1] loss: 829.875
[57,     1] loss: 804.716
[58,     1] loss: 790.518
Early stopping applied (best metric=0.9332983493804932)
Finished Training
Total time taken: 8.568180561065674
{'Hydroxylation-K Validation Accuracy': 0.7870271867612293, 'Hydroxylation-K Validation Sensitivity': 0.7140740740740741, 'Hydroxylation-K Validation Specificity': 0.8052631578947368, 'Hydroxylation-K Validation Precision': 0.4844931710875983, 'Hydroxylation-K AUC ROC': 0.8117543859649122, 'Hydroxylation-K AUC PR': 0.6048494447832633, 'Hydroxylation-K MCC': 0.45705303778967193, 'Hydroxylation-K F1': 0.5752397389568804, 'Validation Loss (Hydroxylation-K)': 0.42499351302782695, 'Hydroxylation-P Validation Accuracy': 0.7742139146913016, 'Hydroxylation-P Validation Sensitivity': 0.7312169312169312, 'Hydroxylation-P Validation Specificity': 0.7834929422913861, 'Hydroxylation-P Validation Precision': 0.42618077393438275, 'Hydroxylation-P AUC ROC': 0.8285264791736436, 'Hydroxylation-P AUC PR': 0.5582451086551798, 'Hydroxylation-P MCC': 0.42886219145670196, 'Hydroxylation-P F1': 0.5354200055722745, 'Validation Loss (Hydroxylation-P)': 0.39855460325876874, 'Validation Loss (total)': 0.8235481103261312, 'TimeToTrain': 9.622669728597005}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0060416844882916765,
 'learning_rate_Hydroxylation-K': 0.009030916704211796,
 'learning_rate_Hydroxylation-P': 0.008955316950766049,
 'log_base': 1.8806280323256654,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2473064175,
 'sample_weights': [1.6208215840126767, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9586893395510128,
 'weight_decay_Hydroxylation-K': 9.197954852973108,
 'weight_decay_Hydroxylation-P': 1.59493665482918}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1464.447
[2,     1] loss: 1464.402
[3,     1] loss: 1465.225
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0039011534341465617,
 'learning_rate_Hydroxylation-K': 0.001772930749225871,
 'learning_rate_Hydroxylation-P': 0.006587333013916455,
 'log_base': 1.8190133419470111,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 34393251,
 'sample_weights': [2.643172684864463, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.9345989969634285,
 'weight_decay_Hydroxylation-K': 6.3000445747419285,
 'weight_decay_Hydroxylation-P': 0.18901077193004445}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1498.377
[2,     1] loss: 1499.194
[3,     1] loss: 1493.668
[4,     1] loss: 1492.855
[5,     1] loss: 1489.007
[6,     1] loss: 1487.737
[7,     1] loss: 1466.903
[8,     1] loss: 1441.481
[9,     1] loss: 1389.839
[10,     1] loss: 1337.709
[11,     1] loss: 1376.075
[12,     1] loss: 1339.671
[13,     1] loss: 1298.705
[14,     1] loss: 1304.471
[15,     1] loss: 1274.253
[16,     1] loss: 1257.158
[17,     1] loss: 1345.464
[18,     1] loss: 1266.401
[19,     1] loss: 1194.562
[20,     1] loss: 1253.946
[21,     1] loss: 1188.363
[22,     1] loss: 1169.289
[23,     1] loss: 1170.499
[24,     1] loss: 1214.922
[25,     1] loss: 1100.529
[26,     1] loss: 1143.726
[27,     1] loss: 1138.075
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027333389982347883,
 'learning_rate_Hydroxylation-K': 0.006139623338720113,
 'learning_rate_Hydroxylation-P': 0.007077750156172735,
 'log_base': 1.025612123677091,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1016468503,
 'sample_weights': [2.7903380172711874, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.632338423722123,
 'weight_decay_Hydroxylation-K': 1.2010501804665743,
 'weight_decay_Hydroxylation-P': 4.017921518720406}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 21516.348
Exploding loss, terminate run (best metric=1.0960137844085693)
Finished Training
Total time taken: 0.20900416374206543
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 21502.852
Exploding loss, terminate run (best metric=1.0914745330810547)
Finished Training
Total time taken: 0.23900485038757324
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 21414.100
Exploding loss, terminate run (best metric=1.0960078239440918)
Finished Training
Total time taken: 0.2290046215057373
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 21489.438
Exploding loss, terminate run (best metric=1.0713846683502197)
Finished Training
Total time taken: 0.20200324058532715
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 21410.115
Exploding loss, terminate run (best metric=1.0813573598861694)
Finished Training
Total time taken: 0.22300434112548828
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 21557.055
Exploding loss, terminate run (best metric=1.0978643894195557)
Finished Training
Total time taken: 0.2230067253112793
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 21428.938
Exploding loss, terminate run (best metric=1.0944185256958008)
Finished Training
Total time taken: 0.21900415420532227
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 21513.824
Exploding loss, terminate run (best metric=1.0917208194732666)
Finished Training
Total time taken: 0.20600438117980957
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 21379.664
Exploding loss, terminate run (best metric=1.0735666751861572)
Finished Training
Total time taken: 0.21900486946105957
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 21459.047
Exploding loss, terminate run (best metric=1.0736169815063477)
Finished Training
Total time taken: 0.21900439262390137
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 21454.062
Exploding loss, terminate run (best metric=1.0952675342559814)
Finished Training
Total time taken: 0.22300410270690918
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 21376.215
Exploding loss, terminate run (best metric=1.0937209129333496)
Finished Training
Total time taken: 0.20500564575195312
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 21590.172
Exploding loss, terminate run (best metric=1.0934419631958008)
Finished Training
Total time taken: 0.2200028896331787
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 21501.160
Exploding loss, terminate run (best metric=1.073054552078247)
Finished Training
Total time taken: 0.2180030345916748
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 21423.676
Exploding loss, terminate run (best metric=1.0729217529296875)
Finished Training
Total time taken: 0.22200465202331543
{'Hydroxylation-K Validation Accuracy': 0.4732860520094562, 'Hydroxylation-K Validation Sensitivity': 0.5333333333333333, 'Hydroxylation-K Validation Specificity': 0.4631578947368421, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.701150097465887, 'Hydroxylation-K AUC PR': 0.39262859922434584, 'Hydroxylation-K MCC': -0.007131042497342636, 'Hydroxylation-K F1': 0.17610837438423646, 'Validation Loss (Hydroxylation-K)': 0.556154469648997, 'Hydroxylation-P Validation Accuracy': 0.47872588531885013, 'Hydroxylation-P Validation Sensitivity': 0.5407407407407407, 'Hydroxylation-P Validation Specificity': 0.46504065040650405, 'Hydroxylation-P Validation Precision': nan, 'Hydroxylation-P AUC ROC': 0.6149733391286586, 'Hydroxylation-P AUC PR': 0.30114636002053846, 'Hydroxylation-P MCC': 0.011334697121126013, 'Hydroxylation-P F1': 0.17262848260156766, 'Validation Loss (Hydroxylation-P)': 0.5302343448003133, 'Validation Loss (total)': 1.0863888184229533, 'TimeToTrain': 0.21840440432230632}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002305107377890393,
 'learning_rate_Hydroxylation-K': 0.0031492613792117267,
 'learning_rate_Hydroxylation-P': 0.0053527779869710175,
 'log_base': 2.3941508706290517,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3452994723,
 'sample_weights': [66.0619257145783, 8.240582588098055],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.092408055129866,
 'weight_decay_Hydroxylation-K': 1.2758146360473044,
 'weight_decay_Hydroxylation-P': 6.945038908038009}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1313.495
[2,     1] loss: 1310.677
[3,     1] loss: 1312.652
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008670630199157,
 'learning_rate_Hydroxylation-K': 0.009639053602168981,
 'learning_rate_Hydroxylation-P': 0.008336457530607692,
 'log_base': 1.5707093139427002,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 950904541,
 'sample_weights': [1.9122433087899693, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3819230166428196,
 'weight_decay_Hydroxylation-K': 7.651835062485434,
 'weight_decay_Hydroxylation-P': 1.862544721367589}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1683.408
[2,     1] loss: 1696.720
[3,     1] loss: 1730.859
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004673603732679767,
 'learning_rate_Hydroxylation-K': 0.0034686801676392545,
 'learning_rate_Hydroxylation-P': 0.0043940933672804595,
 'log_base': 2.886203097104607,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2496699096,
 'sample_weights': [3.6973248610514693, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.335373513590429,
 'weight_decay_Hydroxylation-K': 7.112339588902364,
 'weight_decay_Hydroxylation-P': 0.36706969175594045}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1249.784
[2,     1] loss: 1254.011
[3,     1] loss: 1240.464
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003850876719371661,
 'learning_rate_Hydroxylation-K': 0.004645660759494245,
 'learning_rate_Hydroxylation-P': 0.0032774935895518616,
 'log_base': 2.314292581669694,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2583557253,
 'sample_weights': [1.575032797509843, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.256386314253535,
 'weight_decay_Hydroxylation-K': 6.345357249408104,
 'weight_decay_Hydroxylation-P': 3.127879535211073}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1335.244
[2,     1] loss: 1344.165
[3,     1] loss: 1328.480
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007057687039049075,
 'learning_rate_Hydroxylation-K': 0.00346752493918291,
 'learning_rate_Hydroxylation-P': 0.005211475704244491,
 'log_base': 2.7673484405866304,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4037343705,
 'sample_weights': [1.9895543662320843, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8925761223755653,
 'weight_decay_Hydroxylation-K': 8.930776363272976,
 'weight_decay_Hydroxylation-P': 8.769460119188427}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1256.348
[2,     1] loss: 1253.597
[3,     1] loss: 1252.733
[4,     1] loss: 1247.807
[5,     1] loss: 1240.297
[6,     1] loss: 1235.978
[7,     1] loss: 1186.593
[8,     1] loss: 1128.414
[9,     1] loss: 1086.154
[10,     1] loss: 1226.591
[11,     1] loss: 1181.561
[12,     1] loss: 1063.320
[13,     1] loss: 1065.503
[14,     1] loss: 1098.416
[15,     1] loss: 1082.379
[16,     1] loss: 1041.305
[17,     1] loss: 1045.420
[18,     1] loss: 1024.633
[19,     1] loss: 1028.165
[20,     1] loss: 981.235
[21,     1] loss: 1004.059
[22,     1] loss: 1029.468
[23,     1] loss: 961.630
[24,     1] loss: 999.892
[25,     1] loss: 1024.340
[26,     1] loss: 1015.779
[27,     1] loss: 975.161
[28,     1] loss: 973.185
[29,     1] loss: 972.209
[30,     1] loss: 953.938
[31,     1] loss: 966.838
[32,     1] loss: 942.177
[33,     1] loss: 977.645
[34,     1] loss: 916.181
[35,     1] loss: 910.105
[36,     1] loss: 927.962
[37,     1] loss: 901.743
[38,     1] loss: 941.416
[39,     1] loss: 910.153
[40,     1] loss: 888.204
[41,     1] loss: 904.940
[42,     1] loss: 894.017
[43,     1] loss: 889.525
[44,     1] loss: 832.702
[45,     1] loss: 837.373
[46,     1] loss: 813.496
[47,     1] loss: 837.411
[48,     1] loss: 810.845
[49,     1] loss: 848.960
[50,     1] loss: 798.412
Early stopping applied (best metric=0.8653135299682617)
Finished Training
Total time taken: 7.858163833618164
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1258.111
[2,     1] loss: 1296.408
[3,     1] loss: 1264.684
[4,     1] loss: 1258.933
[5,     1] loss: 1257.966
[6,     1] loss: 1252.394
[7,     1] loss: 1253.852
[8,     1] loss: 1252.214
[9,     1] loss: 1262.224
[10,     1] loss: 1262.664
[11,     1] loss: 1252.962
[12,     1] loss: 1254.479
[13,     1] loss: 1256.479
[14,     1] loss: 1264.500
[15,     1] loss: 1257.431
[16,     1] loss: 1248.663
[17,     1] loss: 1255.975
[18,     1] loss: 1252.943
[19,     1] loss: 1251.959
[20,     1] loss: 1249.763
[21,     1] loss: 1248.883
[22,     1] loss: 1249.965
[23,     1] loss: 1241.833
[24,     1] loss: 1231.829
[25,     1] loss: 1228.158
[26,     1] loss: 1212.833
[27,     1] loss: 1177.720
[28,     1] loss: 1169.184
[29,     1] loss: 1135.978
[30,     1] loss: 1131.489
[31,     1] loss: 1078.403
[32,     1] loss: 1110.452
[33,     1] loss: 1039.156
[34,     1] loss: 1008.815
[35,     1] loss: 1060.410
[36,     1] loss: 999.291
[37,     1] loss: 1023.675
[38,     1] loss: 1051.734
[39,     1] loss: 996.221
[40,     1] loss: 972.767
[41,     1] loss: 1015.922
[42,     1] loss: 1011.190
[43,     1] loss: 978.767
[44,     1] loss: 965.384
[45,     1] loss: 987.797
[46,     1] loss: 1005.151
[47,     1] loss: 967.789
[48,     1] loss: 937.194
[49,     1] loss: 943.089
[50,     1] loss: 965.906
[51,     1] loss: 900.129
[52,     1] loss: 924.778
[53,     1] loss: 914.714
[54,     1] loss: 932.895
[55,     1] loss: 925.331
[56,     1] loss: 897.299
[57,     1] loss: 906.656
[58,     1] loss: 881.175
[59,     1] loss: 873.376
[60,     1] loss: 908.123
[61,     1] loss: 900.725
[62,     1] loss: 909.112
[63,     1] loss: 838.936
[64,     1] loss: 860.598
[65,     1] loss: 847.363
[66,     1] loss: 832.855
[67,     1] loss: 887.238
[68,     1] loss: 882.885
[69,     1] loss: 838.463
[70,     1] loss: 805.261
[71,     1] loss: 800.527
[72,     1] loss: 839.326
[73,     1] loss: 777.180
[74,     1] loss: 817.058
[75,     1] loss: 795.630
[76,     1] loss: 788.524
[77,     1] loss: 759.319
[78,     1] loss: 764.442
[79,     1] loss: 776.749
[80,     1] loss: 754.239
[81,     1] loss: 808.912
[82,     1] loss: 734.277
[83,     1] loss: 712.051
[84,     1] loss: 736.346
[85,     1] loss: 758.455
[86,     1] loss: 771.945
[87,     1] loss: 735.490
[88,     1] loss: 729.215
[89,     1] loss: 724.273
[90,     1] loss: 735.275
[91,     1] loss: 704.287
Early stopping applied (best metric=0.9358822107315063)
Finished Training
Total time taken: 13.764289855957031
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1260.695
[2,     1] loss: 1274.346
[3,     1] loss: 1290.435
[4,     1] loss: 1256.203
[5,     1] loss: 1256.073
[6,     1] loss: 1254.790
[7,     1] loss: 1252.003
[8,     1] loss: 1257.797
[9,     1] loss: 1259.225
[10,     1] loss: 1253.304
[11,     1] loss: 1255.948
[12,     1] loss: 1254.596
[13,     1] loss: 1251.092
[14,     1] loss: 1255.889
[15,     1] loss: 1253.914
[16,     1] loss: 1252.290
[17,     1] loss: 1251.431
[18,     1] loss: 1253.487
[19,     1] loss: 1252.780
[20,     1] loss: 1255.652
[21,     1] loss: 1258.001
[22,     1] loss: 1253.697
[23,     1] loss: 1253.493
[24,     1] loss: 1250.630
[25,     1] loss: 1250.695
[26,     1] loss: 1254.686
[27,     1] loss: 1252.670
[28,     1] loss: 1253.780
Early stopping applied (best metric=1.0916829109191895)
Finished Training
Total time taken: 4.6000964641571045
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1252.913
[2,     1] loss: 1310.476
[3,     1] loss: 1257.180
[4,     1] loss: 1257.351
[5,     1] loss: 1249.638
[6,     1] loss: 1254.436
[7,     1] loss: 1251.621
[8,     1] loss: 1257.735
[9,     1] loss: 1255.775
[10,     1] loss: 1248.599
[11,     1] loss: 1254.570
[12,     1] loss: 1260.036
[13,     1] loss: 1255.335
[14,     1] loss: 1253.033
[15,     1] loss: 1256.711
[16,     1] loss: 1254.863
[17,     1] loss: 1255.491
[18,     1] loss: 1257.133
[19,     1] loss: 1256.598
[20,     1] loss: 1254.458
[21,     1] loss: 1253.925
[22,     1] loss: 1254.283
[23,     1] loss: 1254.415
[24,     1] loss: 1251.941
[25,     1] loss: 1253.997
[26,     1] loss: 1252.628
[27,     1] loss: 1252.921
[28,     1] loss: 1253.271
[29,     1] loss: 1251.939
[30,     1] loss: 1253.356
[31,     1] loss: 1250.300
[32,     1] loss: 1252.172
Early stopping applied (best metric=1.072282075881958)
Finished Training
Total time taken: 5.367113351821899
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1257.560
[2,     1] loss: 1260.421
[3,     1] loss: 1263.562
[4,     1] loss: 1251.126
[5,     1] loss: 1249.102
[6,     1] loss: 1248.825
[7,     1] loss: 1235.288
[8,     1] loss: 1226.040
[9,     1] loss: 1198.528
[10,     1] loss: 1143.889
[11,     1] loss: 1112.841
[12,     1] loss: 1064.919
[13,     1] loss: 1076.867
[14,     1] loss: 1089.964
[15,     1] loss: 1019.727
[16,     1] loss: 1047.267
[17,     1] loss: 1029.622
[18,     1] loss: 1023.475
[19,     1] loss: 1031.425
[20,     1] loss: 1016.612
[21,     1] loss: 1006.222
[22,     1] loss: 1024.479
[23,     1] loss: 1025.313
[24,     1] loss: 970.225
[25,     1] loss: 993.236
[26,     1] loss: 972.176
[27,     1] loss: 971.311
[28,     1] loss: 938.044
[29,     1] loss: 942.321
[30,     1] loss: 922.514
[31,     1] loss: 961.243
[32,     1] loss: 934.170
[33,     1] loss: 865.560
[34,     1] loss: 866.498
[35,     1] loss: 909.988
[36,     1] loss: 919.385
[37,     1] loss: 893.359
[38,     1] loss: 949.056
[39,     1] loss: 894.148
[40,     1] loss: 887.350
[41,     1] loss: 827.242
[42,     1] loss: 875.569
[43,     1] loss: 828.189
[44,     1] loss: 848.392
[45,     1] loss: 777.409
[46,     1] loss: 890.281
[47,     1] loss: 812.041
[48,     1] loss: 798.560
[49,     1] loss: 816.422
[50,     1] loss: 768.801
[51,     1] loss: 807.484
[52,     1] loss: 748.358
[53,     1] loss: 807.288
[54,     1] loss: 730.532
[55,     1] loss: 764.574
[56,     1] loss: 727.719
[57,     1] loss: 726.057
[58,     1] loss: 716.329
[59,     1] loss: 715.381
[60,     1] loss: 690.182
[61,     1] loss: 710.480
[62,     1] loss: 695.302
[63,     1] loss: 670.670
[64,     1] loss: 637.868
[65,     1] loss: 676.721
[66,     1] loss: 639.822
[67,     1] loss: 702.540
[68,     1] loss: 631.920
[69,     1] loss: 715.217
[70,     1] loss: 599.817
[71,     1] loss: 721.716
[72,     1] loss: 811.526
Early stopping applied (best metric=0.7013185024261475)
Finished Training
Total time taken: 10.634224653244019
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1254.292
[2,     1] loss: 1269.110
[3,     1] loss: 1253.479
[4,     1] loss: 1252.087
[5,     1] loss: 1258.155
[6,     1] loss: 1254.168
[7,     1] loss: 1253.438
[8,     1] loss: 1249.869
[9,     1] loss: 1255.688
[10,     1] loss: 1249.646
[11,     1] loss: 1250.415
[12,     1] loss: 1242.069
[13,     1] loss: 1236.666
[14,     1] loss: 1227.139
[15,     1] loss: 1202.700
[16,     1] loss: 1168.639
[17,     1] loss: 1144.300
[18,     1] loss: 1111.452
[19,     1] loss: 1093.592
[20,     1] loss: 1069.778
[21,     1] loss: 1093.318
[22,     1] loss: 1032.263
[23,     1] loss: 1046.385
[24,     1] loss: 1022.308
[25,     1] loss: 1048.173
[26,     1] loss: 996.188
[27,     1] loss: 1001.919
[28,     1] loss: 1006.865
[29,     1] loss: 1020.754
[30,     1] loss: 988.387
[31,     1] loss: 977.250
[32,     1] loss: 910.124
[33,     1] loss: 944.275
[34,     1] loss: 956.739
[35,     1] loss: 1026.079
[36,     1] loss: 921.807
[37,     1] loss: 929.548
[38,     1] loss: 940.652
[39,     1] loss: 971.962
[40,     1] loss: 911.092
[41,     1] loss: 900.394
[42,     1] loss: 924.217
[43,     1] loss: 884.278
[44,     1] loss: 828.121
[45,     1] loss: 914.574
[46,     1] loss: 854.878
[47,     1] loss: 933.458
[48,     1] loss: 885.365
[49,     1] loss: 823.029
[50,     1] loss: 864.950
[51,     1] loss: 844.684
[52,     1] loss: 842.967
[53,     1] loss: 789.681
[54,     1] loss: 897.105
[55,     1] loss: 848.777
[56,     1] loss: 808.906
[57,     1] loss: 801.071
[58,     1] loss: 808.669
[59,     1] loss: 765.711
[60,     1] loss: 758.165
[61,     1] loss: 787.933
[62,     1] loss: 816.479
[63,     1] loss: 779.936
[64,     1] loss: 812.442
[65,     1] loss: 739.285
[66,     1] loss: 756.264
[67,     1] loss: 733.050
[68,     1] loss: 759.810
[69,     1] loss: 762.478
[70,     1] loss: 705.930
[71,     1] loss: 714.831
[72,     1] loss: 684.510
[73,     1] loss: 694.758
[74,     1] loss: 697.148
[75,     1] loss: 612.286
[76,     1] loss: 648.201
Early stopping applied (best metric=0.7819898128509521)
Finished Training
Total time taken: 11.760247468948364
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1253.457
[2,     1] loss: 1258.753
[3,     1] loss: 1263.505
[4,     1] loss: 1257.124
[5,     1] loss: 1248.217
[6,     1] loss: 1238.112
[7,     1] loss: 1225.664
[8,     1] loss: 1157.818
[9,     1] loss: 1203.890
[10,     1] loss: 1201.215
[11,     1] loss: 1223.948
[12,     1] loss: 1138.114
[13,     1] loss: 1079.190
[14,     1] loss: 1145.594
[15,     1] loss: 1076.212
[16,     1] loss: 1056.441
[17,     1] loss: 1039.268
[18,     1] loss: 1060.262
[19,     1] loss: 1011.632
[20,     1] loss: 1010.161
[21,     1] loss: 966.402
[22,     1] loss: 1024.472
[23,     1] loss: 983.902
[24,     1] loss: 942.668
[25,     1] loss: 1009.266
[26,     1] loss: 961.879
[27,     1] loss: 973.014
[28,     1] loss: 975.000
[29,     1] loss: 987.286
[30,     1] loss: 973.812
[31,     1] loss: 948.435
[32,     1] loss: 926.533
[33,     1] loss: 893.637
[34,     1] loss: 903.728
[35,     1] loss: 901.655
[36,     1] loss: 925.910
[37,     1] loss: 859.824
[38,     1] loss: 888.823
[39,     1] loss: 855.757
[40,     1] loss: 891.451
[41,     1] loss: 843.533
[42,     1] loss: 841.625
[43,     1] loss: 813.503
[44,     1] loss: 830.040
[45,     1] loss: 862.858
[46,     1] loss: 805.235
[47,     1] loss: 833.551
[48,     1] loss: 823.295
[49,     1] loss: 807.049
[50,     1] loss: 786.671
[51,     1] loss: 835.541
[52,     1] loss: 778.074
[53,     1] loss: 803.311
[54,     1] loss: 756.570
[55,     1] loss: 748.906
[56,     1] loss: 755.132
[57,     1] loss: 815.318
[58,     1] loss: 748.766
[59,     1] loss: 743.893
[60,     1] loss: 797.562
[61,     1] loss: 710.962
[62,     1] loss: 691.752
Early stopping applied (best metric=0.9512704014778137)
Finished Training
Total time taken: 9.48720097541809
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1260.809
[2,     1] loss: 1284.320
[3,     1] loss: 1254.255
[4,     1] loss: 1263.875
[5,     1] loss: 1252.815
[6,     1] loss: 1255.580
[7,     1] loss: 1254.631
[8,     1] loss: 1252.594
[9,     1] loss: 1257.923
[10,     1] loss: 1254.522
[11,     1] loss: 1251.765
[12,     1] loss: 1251.813
[13,     1] loss: 1253.109
[14,     1] loss: 1249.754
[15,     1] loss: 1254.277
[16,     1] loss: 1248.391
[17,     1] loss: 1250.576
[18,     1] loss: 1248.441
[19,     1] loss: 1244.882
[20,     1] loss: 1240.474
[21,     1] loss: 1234.769
[22,     1] loss: 1216.317
[23,     1] loss: 1194.576
[24,     1] loss: 1182.138
[25,     1] loss: 1159.341
[26,     1] loss: 1148.112
[27,     1] loss: 1107.504
[28,     1] loss: 1123.674
[29,     1] loss: 1096.144
[30,     1] loss: 1048.203
[31,     1] loss: 1092.578
[32,     1] loss: 1091.918
[33,     1] loss: 1033.575
[34,     1] loss: 1040.905
[35,     1] loss: 1058.438
[36,     1] loss: 1046.624
[37,     1] loss: 1040.180
[38,     1] loss: 1039.387
[39,     1] loss: 1022.736
[40,     1] loss: 1001.958
[41,     1] loss: 1006.282
[42,     1] loss: 998.119
[43,     1] loss: 1015.619
[44,     1] loss: 1034.187
[45,     1] loss: 1024.233
[46,     1] loss: 992.577
[47,     1] loss: 947.917
[48,     1] loss: 989.976
[49,     1] loss: 964.303
[50,     1] loss: 1011.735
[51,     1] loss: 942.427
[52,     1] loss: 916.488
[53,     1] loss: 966.275
[54,     1] loss: 947.559
[55,     1] loss: 930.689
[56,     1] loss: 909.460
[57,     1] loss: 926.031
[58,     1] loss: 905.571
[59,     1] loss: 853.615
[60,     1] loss: 884.339
[61,     1] loss: 860.541
[62,     1] loss: 891.539
[63,     1] loss: 915.551
[64,     1] loss: 825.563
[65,     1] loss: 881.843
[66,     1] loss: 865.715
[67,     1] loss: 869.152
[68,     1] loss: 836.111
[69,     1] loss: 854.950
[70,     1] loss: 916.608
[71,     1] loss: 847.594
[72,     1] loss: 869.314
[73,     1] loss: 843.109
[74,     1] loss: 859.872
Early stopping applied (best metric=0.8430691957473755)
Finished Training
Total time taken: 11.942251443862915
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1252.793
[2,     1] loss: 1261.451
[3,     1] loss: 1315.763
[4,     1] loss: 1249.740
[5,     1] loss: 1249.453
[6,     1] loss: 1250.037
[7,     1] loss: 1245.088
[8,     1] loss: 1238.065
[9,     1] loss: 1225.857
[10,     1] loss: 1213.609
[11,     1] loss: 1181.860
[12,     1] loss: 1133.256
[13,     1] loss: 1097.580
[14,     1] loss: 1077.766
[15,     1] loss: 1078.231
[16,     1] loss: 1071.813
[17,     1] loss: 1093.144
[18,     1] loss: 1015.281
[19,     1] loss: 1018.525
[20,     1] loss: 999.660
[21,     1] loss: 1013.728
[22,     1] loss: 1004.148
[23,     1] loss: 1005.620
[24,     1] loss: 989.600
[25,     1] loss: 973.714
[26,     1] loss: 950.099
[27,     1] loss: 921.134
[28,     1] loss: 915.790
[29,     1] loss: 978.987
[30,     1] loss: 947.174
[31,     1] loss: 885.124
[32,     1] loss: 893.036
[33,     1] loss: 893.197
[34,     1] loss: 910.305
[35,     1] loss: 875.128
[36,     1] loss: 847.123
[37,     1] loss: 872.633
[38,     1] loss: 854.750
[39,     1] loss: 806.698
[40,     1] loss: 786.793
[41,     1] loss: 820.548
Early stopping applied (best metric=0.9318592548370361)
Finished Training
Total time taken: 5.599117755889893
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1256.351
[2,     1] loss: 1263.499
[3,     1] loss: 1273.071
[4,     1] loss: 1260.678
[5,     1] loss: 1253.339
[6,     1] loss: 1251.128
[7,     1] loss: 1256.964
[8,     1] loss: 1252.837
[9,     1] loss: 1256.659
[10,     1] loss: 1249.964
[11,     1] loss: 1248.857
[12,     1] loss: 1236.948
[13,     1] loss: 1233.077
[14,     1] loss: 1231.026
[15,     1] loss: 1213.731
[16,     1] loss: 1181.842
[17,     1] loss: 1143.455
[18,     1] loss: 1134.797
[19,     1] loss: 1121.332
[20,     1] loss: 1101.953
[21,     1] loss: 1055.611
[22,     1] loss: 1058.052
[23,     1] loss: 1077.494
[24,     1] loss: 1080.553
[25,     1] loss: 1062.540
[26,     1] loss: 1025.317
[27,     1] loss: 1059.407
[28,     1] loss: 1065.029
[29,     1] loss: 1030.993
[30,     1] loss: 1027.081
[31,     1] loss: 1013.896
[32,     1] loss: 1028.464
[33,     1] loss: 983.652
[34,     1] loss: 1001.198
[35,     1] loss: 925.592
[36,     1] loss: 963.977
[37,     1] loss: 986.392
[38,     1] loss: 947.800
[39,     1] loss: 944.101
[40,     1] loss: 945.749
[41,     1] loss: 944.135
[42,     1] loss: 904.466
[43,     1] loss: 921.134
[44,     1] loss: 941.536
[45,     1] loss: 908.553
[46,     1] loss: 902.882
[47,     1] loss: 920.577
[48,     1] loss: 950.710
[49,     1] loss: 887.867
[50,     1] loss: 815.998
[51,     1] loss: 879.014
[52,     1] loss: 883.975
[53,     1] loss: 862.443
[54,     1] loss: 872.462
[55,     1] loss: 813.544
[56,     1] loss: 824.092
[57,     1] loss: 862.106
[58,     1] loss: 821.394
[59,     1] loss: 820.473
[60,     1] loss: 830.611
[61,     1] loss: 812.385
[62,     1] loss: 769.313
[63,     1] loss: 782.280
[64,     1] loss: 806.051
[65,     1] loss: 768.991
[66,     1] loss: 772.738
[67,     1] loss: 724.079
[68,     1] loss: 744.190
Early stopping applied (best metric=0.8273235559463501)
Finished Training
Total time taken: 10.710227966308594
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1262.845
[2,     1] loss: 1293.086
[3,     1] loss: 1258.615
[4,     1] loss: 1257.949
[5,     1] loss: 1260.497
[6,     1] loss: 1253.771
[7,     1] loss: 1261.504
[8,     1] loss: 1252.671
[9,     1] loss: 1254.789
[10,     1] loss: 1252.894
[11,     1] loss: 1254.988
[12,     1] loss: 1255.712
[13,     1] loss: 1253.573
[14,     1] loss: 1250.803
[15,     1] loss: 1256.201
[16,     1] loss: 1254.491
[17,     1] loss: 1253.382
[18,     1] loss: 1254.225
[19,     1] loss: 1254.970
[20,     1] loss: 1252.448
[21,     1] loss: 1253.914
[22,     1] loss: 1251.966
[23,     1] loss: 1252.058
[24,     1] loss: 1251.289
[25,     1] loss: 1252.456
[26,     1] loss: 1251.023
[27,     1] loss: 1251.121
[28,     1] loss: 1251.979
[29,     1] loss: 1249.403
[30,     1] loss: 1244.408
[31,     1] loss: 1241.734
[32,     1] loss: 1240.218
[33,     1] loss: 1231.942
[34,     1] loss: 1218.753
[35,     1] loss: 1212.028
[36,     1] loss: 1185.314
[37,     1] loss: 1161.882
[38,     1] loss: 1162.981
[39,     1] loss: 1127.437
[40,     1] loss: 1088.449
[41,     1] loss: 1115.662
[42,     1] loss: 1073.646
[43,     1] loss: 1078.797
[44,     1] loss: 1038.943
[45,     1] loss: 1023.570
[46,     1] loss: 1012.784
[47,     1] loss: 1012.224
[48,     1] loss: 990.673
[49,     1] loss: 1048.037
[50,     1] loss: 1011.399
[51,     1] loss: 999.677
[52,     1] loss: 1000.015
[53,     1] loss: 1000.231
[54,     1] loss: 980.311
[55,     1] loss: 933.171
[56,     1] loss: 987.781
[57,     1] loss: 894.299
[58,     1] loss: 975.407
[59,     1] loss: 938.924
[60,     1] loss: 960.803
[61,     1] loss: 879.019
[62,     1] loss: 920.694
[63,     1] loss: 951.113
[64,     1] loss: 952.527
[65,     1] loss: 929.455
[66,     1] loss: 922.587
[67,     1] loss: 897.902
[68,     1] loss: 851.602
[69,     1] loss: 868.417
[70,     1] loss: 831.873
[71,     1] loss: 904.630
[72,     1] loss: 892.764
[73,     1] loss: 901.449
[74,     1] loss: 834.322
[75,     1] loss: 864.119
[76,     1] loss: 832.179
[77,     1] loss: 852.038
[78,     1] loss: 831.863
[79,     1] loss: 872.963
[80,     1] loss: 774.532
[81,     1] loss: 778.837
[82,     1] loss: 842.088
[83,     1] loss: 795.846
[84,     1] loss: 767.694
[85,     1] loss: 806.333
[86,     1] loss: 801.523
[87,     1] loss: 822.355
[88,     1] loss: 799.673
[89,     1] loss: 762.286
[90,     1] loss: 743.343
[91,     1] loss: 742.724
[92,     1] loss: 794.868
[93,     1] loss: 728.926
[94,     1] loss: 739.877
[95,     1] loss: 716.882
Early stopping applied (best metric=0.9003701210021973)
Finished Training
Total time taken: 14.7443106174469
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1254.451
[2,     1] loss: 1262.122
[3,     1] loss: 1264.092
[4,     1] loss: 1258.570
[5,     1] loss: 1252.545
[6,     1] loss: 1252.518
[7,     1] loss: 1261.348
[8,     1] loss: 1250.741
[9,     1] loss: 1243.453
[10,     1] loss: 1249.321
[11,     1] loss: 1230.296
[12,     1] loss: 1217.848
[13,     1] loss: 1197.542
[14,     1] loss: 1160.882
[15,     1] loss: 1104.590
[16,     1] loss: 1070.327
[17,     1] loss: 1059.134
[18,     1] loss: 1068.882
[19,     1] loss: 1093.121
[20,     1] loss: 1030.526
[21,     1] loss: 1043.839
[22,     1] loss: 1029.588
[23,     1] loss: 1023.367
[24,     1] loss: 1070.727
[25,     1] loss: 988.283
[26,     1] loss: 1049.934
[27,     1] loss: 1059.700
[28,     1] loss: 1006.756
[29,     1] loss: 997.869
[30,     1] loss: 1042.413
[31,     1] loss: 965.757
[32,     1] loss: 1041.593
[33,     1] loss: 1030.220
[34,     1] loss: 995.022
[35,     1] loss: 997.187
[36,     1] loss: 958.021
[37,     1] loss: 941.016
[38,     1] loss: 944.578
[39,     1] loss: 945.382
[40,     1] loss: 951.217
[41,     1] loss: 918.474
[42,     1] loss: 957.744
[43,     1] loss: 888.903
[44,     1] loss: 923.546
[45,     1] loss: 953.950
[46,     1] loss: 911.007
[47,     1] loss: 958.986
[48,     1] loss: 890.703
[49,     1] loss: 899.843
[50,     1] loss: 932.351
[51,     1] loss: 901.466
[52,     1] loss: 903.626
[53,     1] loss: 886.051
[54,     1] loss: 853.424
[55,     1] loss: 883.371
[56,     1] loss: 896.980
[57,     1] loss: 882.706
[58,     1] loss: 837.531
[59,     1] loss: 862.460
[60,     1] loss: 876.258
[61,     1] loss: 868.438
[62,     1] loss: 813.317
[63,     1] loss: 842.396
[64,     1] loss: 804.149
Early stopping applied (best metric=0.762152910232544)
Finished Training
Total time taken: 9.266195297241211
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1259.331
[2,     1] loss: 1277.448
[3,     1] loss: 1257.368
[4,     1] loss: 1252.186
[5,     1] loss: 1253.973
[6,     1] loss: 1250.832
[7,     1] loss: 1257.313
[8,     1] loss: 1256.966
[9,     1] loss: 1255.836
[10,     1] loss: 1254.866
[11,     1] loss: 1256.288
[12,     1] loss: 1254.012
[13,     1] loss: 1255.869
[14,     1] loss: 1250.775
[15,     1] loss: 1255.508
[16,     1] loss: 1252.208
[17,     1] loss: 1252.042
[18,     1] loss: 1249.724
[19,     1] loss: 1254.028
[20,     1] loss: 1248.491
[21,     1] loss: 1247.239
[22,     1] loss: 1246.439
[23,     1] loss: 1240.048
[24,     1] loss: 1231.768
[25,     1] loss: 1228.533
[26,     1] loss: 1206.820
[27,     1] loss: 1204.130
[28,     1] loss: 1153.480
[29,     1] loss: 1137.399
[30,     1] loss: 1152.532
[31,     1] loss: 1125.400
[32,     1] loss: 1100.571
[33,     1] loss: 1082.877
[34,     1] loss: 1088.349
[35,     1] loss: 1084.579
[36,     1] loss: 1053.742
[37,     1] loss: 1022.107
[38,     1] loss: 1052.219
[39,     1] loss: 1033.946
[40,     1] loss: 1038.808
[41,     1] loss: 998.251
[42,     1] loss: 1041.869
[43,     1] loss: 987.708
[44,     1] loss: 1024.037
[45,     1] loss: 1013.506
[46,     1] loss: 958.578
[47,     1] loss: 940.965
[48,     1] loss: 956.980
[49,     1] loss: 930.637
[50,     1] loss: 981.505
[51,     1] loss: 954.032
[52,     1] loss: 963.764
[53,     1] loss: 928.855
[54,     1] loss: 936.591
[55,     1] loss: 975.783
[56,     1] loss: 919.559
[57,     1] loss: 905.964
[58,     1] loss: 904.827
[59,     1] loss: 930.354
[60,     1] loss: 930.291
[61,     1] loss: 843.785
[62,     1] loss: 898.876
[63,     1] loss: 852.398
[64,     1] loss: 845.053
[65,     1] loss: 856.196
[66,     1] loss: 825.193
[67,     1] loss: 826.617
[68,     1] loss: 859.015
[69,     1] loss: 838.879
[70,     1] loss: 814.577
[71,     1] loss: 802.744
[72,     1] loss: 822.175
[73,     1] loss: 854.537
[74,     1] loss: 754.606
[75,     1] loss: 809.739
[76,     1] loss: 773.740
[77,     1] loss: 752.634
Early stopping applied (best metric=0.8118786811828613)
Finished Training
Total time taken: 11.702246904373169
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1255.063
[2,     1] loss: 1266.387
[3,     1] loss: 1269.430
[4,     1] loss: 1253.884
[5,     1] loss: 1254.868
[6,     1] loss: 1254.136
[7,     1] loss: 1254.773
[8,     1] loss: 1253.114
[9,     1] loss: 1254.645
[10,     1] loss: 1250.454
[11,     1] loss: 1252.229
[12,     1] loss: 1253.190
[13,     1] loss: 1251.667
[14,     1] loss: 1247.770
[15,     1] loss: 1247.512
[16,     1] loss: 1242.996
[17,     1] loss: 1239.625
[18,     1] loss: 1231.420
[19,     1] loss: 1212.673
[20,     1] loss: 1177.633
[21,     1] loss: 1169.229
[22,     1] loss: 1130.956
[23,     1] loss: 1112.475
[24,     1] loss: 1097.172
[25,     1] loss: 1038.165
[26,     1] loss: 1027.530
[27,     1] loss: 1029.450
[28,     1] loss: 1099.044
[29,     1] loss: 1056.167
[30,     1] loss: 1011.399
[31,     1] loss: 1023.458
[32,     1] loss: 1024.996
[33,     1] loss: 1039.901
[34,     1] loss: 985.567
[35,     1] loss: 1007.092
[36,     1] loss: 999.958
[37,     1] loss: 989.243
[38,     1] loss: 983.224
[39,     1] loss: 933.739
[40,     1] loss: 953.940
[41,     1] loss: 924.645
[42,     1] loss: 943.234
[43,     1] loss: 907.379
[44,     1] loss: 926.094
[45,     1] loss: 914.511
[46,     1] loss: 927.985
[47,     1] loss: 903.172
[48,     1] loss: 903.591
[49,     1] loss: 915.423
[50,     1] loss: 913.885
[51,     1] loss: 892.865
[52,     1] loss: 879.234
[53,     1] loss: 863.559
[54,     1] loss: 862.330
[55,     1] loss: 864.865
[56,     1] loss: 872.762
[57,     1] loss: 871.053
[58,     1] loss: 861.536
[59,     1] loss: 919.536
[60,     1] loss: 839.139
[61,     1] loss: 872.512
[62,     1] loss: 867.237
[63,     1] loss: 859.672
[64,     1] loss: 794.585
[65,     1] loss: 879.341
[66,     1] loss: 861.781
[67,     1] loss: 779.231
[68,     1] loss: 824.945
[69,     1] loss: 766.808
[70,     1] loss: 816.304
[71,     1] loss: 771.487
[72,     1] loss: 782.348
[73,     1] loss: 759.615
[74,     1] loss: 720.959
[75,     1] loss: 719.745
[76,     1] loss: 748.868
[77,     1] loss: 658.154
[78,     1] loss: 717.559
[79,     1] loss: 687.413
[80,     1] loss: 660.576
Early stopping applied (best metric=0.8464617729187012)
Finished Training
Total time taken: 13.402282476425171
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1254.988
[2,     1] loss: 1257.233
[3,     1] loss: 1261.187
[4,     1] loss: 1257.074
[5,     1] loss: 1253.198
[6,     1] loss: 1249.886
[7,     1] loss: 1261.026
[8,     1] loss: 1251.714
[9,     1] loss: 1244.274
[10,     1] loss: 1231.115
[11,     1] loss: 1210.059
[12,     1] loss: 1155.234
[13,     1] loss: 1135.481
[14,     1] loss: 1059.529
[15,     1] loss: 1084.301
[16,     1] loss: 1093.790
[17,     1] loss: 1044.950
[18,     1] loss: 1005.724
[19,     1] loss: 997.822
[20,     1] loss: 1038.925
[21,     1] loss: 965.431
[22,     1] loss: 1013.586
[23,     1] loss: 1012.416
[24,     1] loss: 964.336
[25,     1] loss: 1003.728
[26,     1] loss: 988.396
[27,     1] loss: 948.471
[28,     1] loss: 981.993
[29,     1] loss: 955.477
[30,     1] loss: 932.307
[31,     1] loss: 949.377
[32,     1] loss: 941.979
[33,     1] loss: 925.846
[34,     1] loss: 926.547
[35,     1] loss: 926.284
[36,     1] loss: 944.854
[37,     1] loss: 898.628
[38,     1] loss: 880.526
[39,     1] loss: 898.649
[40,     1] loss: 913.750
[41,     1] loss: 910.785
[42,     1] loss: 865.326
[43,     1] loss: 897.577
[44,     1] loss: 863.739
[45,     1] loss: 886.683
[46,     1] loss: 852.441
[47,     1] loss: 823.894
[48,     1] loss: 874.122
[49,     1] loss: 820.726
[50,     1] loss: 824.901
[51,     1] loss: 854.664
[52,     1] loss: 791.151
[53,     1] loss: 779.635
[54,     1] loss: 814.126
[55,     1] loss: 819.712
[56,     1] loss: 807.950
[57,     1] loss: 800.977
[58,     1] loss: 835.782
[59,     1] loss: 773.888
[60,     1] loss: 835.884
[61,     1] loss: 762.161
[62,     1] loss: 737.843
[63,     1] loss: 743.352
[64,     1] loss: 792.659
[65,     1] loss: 802.507
[66,     1] loss: 739.600
[67,     1] loss: 727.773
[68,     1] loss: 741.188
[69,     1] loss: 700.737
[70,     1] loss: 711.899
[71,     1] loss: 717.106
[72,     1] loss: 738.794
[73,     1] loss: 681.190
[74,     1] loss: 746.626
[75,     1] loss: 657.422
[76,     1] loss: 701.471
[77,     1] loss: 661.625
[78,     1] loss: 682.909
[79,     1] loss: 647.589
[80,     1] loss: 644.836
[81,     1] loss: 630.519
[82,     1] loss: 604.478
[83,     1] loss: 606.330
[84,     1] loss: 711.611
[85,     1] loss: 653.046
[86,     1] loss: 617.313
[87,     1] loss: 627.178
[88,     1] loss: 622.940
[89,     1] loss: 545.291
[90,     1] loss: 722.534
[91,     1] loss: 617.600
[92,     1] loss: 723.807
[93,     1] loss: 585.760
[94,     1] loss: 575.070
[95,     1] loss: 594.398
[96,     1] loss: 622.619
[97,     1] loss: 533.924
[98,     1] loss: 552.115
[99,     1] loss: 576.768
Early stopping applied (best metric=0.6729045510292053)
Finished Training
Total time taken: 14.19529914855957
{'Hydroxylation-K Validation Accuracy': 0.6888888888888889, 'Hydroxylation-K Validation Sensitivity': 0.7037037037037037, 'Hydroxylation-K Validation Specificity': 0.6859649122807018, 'Hydroxylation-K Validation Precision': 0.411363416632503, 'Hydroxylation-K AUC ROC': 0.7860818713450293, 'Hydroxylation-K AUC PR': 0.5674054709004221, 'Hydroxylation-K MCC': 0.34168455388130975, 'Hydroxylation-K F1': 0.5000260050165097, 'Validation Loss (Hydroxylation-K)': 0.4521534353494644, 'Hydroxylation-P Validation Accuracy': 0.7031821565741164, 'Hydroxylation-P Validation Sensitivity': 0.7728042328042328, 'Hydroxylation-P Validation Specificity': 0.6883734849618435, 'Hydroxylation-P Validation Precision': 0.40389988178795233, 'Hydroxylation-P AUC ROC': 0.8097464564990376, 'Hydroxylation-P AUC PR': 0.5147960552380044, 'Hydroxylation-P MCC': 0.3860646130394115, 'Hydroxylation-P F1': 0.5144690126946144, 'Validation Loss (Hydroxylation-P)': 0.41423052350680034, 'Validation Loss (total)': 0.86638396581014, 'TimeToTrain': 10.335551214218139}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024623799978045055,
 'learning_rate_Hydroxylation-K': 0.004371297340502266,
 'learning_rate_Hydroxylation-P': 0.005551003170580661,
 'log_base': 2.500701802740035,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2938899831,
 'sample_weights': [1.641318964952882, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.555794059534877,
 'weight_decay_Hydroxylation-K': 5.609525069614749,
 'weight_decay_Hydroxylation-P': 0.4850279368103533}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1294.065
[2,     1] loss: 1292.113
[3,     1] loss: 1289.404
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006415519259832816,
 'learning_rate_Hydroxylation-K': 0.005019382795336728,
 'learning_rate_Hydroxylation-P': 0.002261756159293516,
 'log_base': 2.506028120709331,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3978031980,
 'sample_weights': [1.8213999724380285, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.5556618659663854,
 'weight_decay_Hydroxylation-K': 4.394821805481854,
 'weight_decay_Hydroxylation-P': 1.8266977943353675}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1291.097
[2,     1] loss: 1290.031
[3,     1] loss: 1292.476
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003022604673918879,
 'learning_rate_Hydroxylation-K': 0.008217388160236256,
 'learning_rate_Hydroxylation-P': 0.008299327407172985,
 'log_base': 1.0982738392344682,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2218603346,
 'sample_weights': [1.8171816951073616, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.865441836050708,
 'weight_decay_Hydroxylation-K': 3.8913914056313033,
 'weight_decay_Hydroxylation-P': 3.3828913485329934}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 5805.104
[2,     1] loss: 5794.334
[3,     1] loss: 5782.172
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003760463324111031,
 'learning_rate_Hydroxylation-K': 0.0016827070646680776,
 'learning_rate_Hydroxylation-P': 0.0001735373313465515,
 'log_base': 2.3551139696701155,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1602505614,
 'sample_weights': [17.80934828808615, 2.2262542969622428],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7464896148916036,
 'weight_decay_Hydroxylation-K': 8.072604695606096,
 'weight_decay_Hydroxylation-P': 3.612830071749368}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1322.238
[2,     1] loss: 1319.205
[3,     1] loss: 1320.248
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004232121347913982,
 'learning_rate_Hydroxylation-K': 0.0028116265487402653,
 'learning_rate_Hydroxylation-P': 0.0025547984974260357,
 'log_base': 1.8831740174564915,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3916043676,
 'sample_weights': [1.9489427385609783, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.635490636607464,
 'weight_decay_Hydroxylation-K': 1.7646165895482058,
 'weight_decay_Hydroxylation-P': 0.463440316623418}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1482.129
[2,     1] loss: 1458.526
[3,     1] loss: 1478.322
[4,     1] loss: 1464.601
[5,     1] loss: 1472.260
[6,     1] loss: 1472.818
[7,     1] loss: 1467.200
[8,     1] loss: 1462.147
[9,     1] loss: 1461.113
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004504027160613962,
 'learning_rate_Hydroxylation-K': 0.00041311832334168597,
 'learning_rate_Hydroxylation-P': 0.004478031516195517,
 'log_base': 1.888475965878787,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2466843441,
 'sample_weights': [2.6375231935990078, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.3938063452213164,
 'weight_decay_Hydroxylation-K': 0.44237046367097577,
 'weight_decay_Hydroxylation-P': 0.5066383711148457}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1461.776
[2,     1] loss: 1468.922
[3,     1] loss: 1454.428
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028280630674741548,
 'learning_rate_Hydroxylation-K': 0.009279131433941799,
 'learning_rate_Hydroxylation-P': 0.002958578760739485,
 'log_base': 2.7162985985863504,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1096937845,
 'sample_weights': [2.6258596488262214, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.74678124634759,
 'weight_decay_Hydroxylation-K': 4.733140607067554,
 'weight_decay_Hydroxylation-P': 3.6661785908277205}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1259.481
[2,     1] loss: 1259.807
[3,     1] loss: 1257.254
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001087964449169808,
 'learning_rate_Hydroxylation-K': 0.00103754300442984,
 'learning_rate_Hydroxylation-P': 0.004733276744777984,
 'log_base': 2.814346950708907,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1187313456,
 'sample_weights': [1.6706624900938578, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.197437421670144,
 'weight_decay_Hydroxylation-K': 1.2794147377006833,
 'weight_decay_Hydroxylation-P': 5.285572637079598}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1249.051
[2,     1] loss: 1248.738
[3,     1] loss: 1252.587
[4,     1] loss: 1247.238
[5,     1] loss: 1245.859
[6,     1] loss: 1247.597
[7,     1] loss: 1241.319
[8,     1] loss: 1236.221
[9,     1] loss: 1232.135
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00861129846168345,
 'learning_rate_Hydroxylation-K': 0.009761268273155974,
 'learning_rate_Hydroxylation-P': 0.009396606531200228,
 'log_base': 1.9763718870354288,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3365710217,
 'sample_weights': [1.6134090547208506, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.582633610606807,
 'weight_decay_Hydroxylation-K': 9.334371813953968,
 'weight_decay_Hydroxylation-P': 0.2576772456081517}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1424.011
[2,     1] loss: 1437.060
[3,     1] loss: 1451.971
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003254306213910489,
 'learning_rate_Hydroxylation-K': 0.0064054699086513464,
 'learning_rate_Hydroxylation-P': 0.00219297462098697,
 'log_base': 2.3550236399361517,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1379957441,
 'sample_weights': [2.4505127649898855, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1948746319494894,
 'weight_decay_Hydroxylation-K': 4.547303682491667,
 'weight_decay_Hydroxylation-P': 2.794649279978481}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1317.175
[2,     1] loss: 1318.610
[3,     1] loss: 1320.684
[4,     1] loss: 1316.751
[5,     1] loss: 1309.833
[6,     1] loss: 1306.501
[7,     1] loss: 1288.580
[8,     1] loss: 1252.536
[9,     1] loss: 1208.347
[10,     1] loss: 1187.178
[11,     1] loss: 1153.220
[12,     1] loss: 1130.943
[13,     1] loss: 1115.592
[14,     1] loss: 1125.071
[15,     1] loss: 1112.577
[16,     1] loss: 1109.123
[17,     1] loss: 1092.632
[18,     1] loss: 1110.785
[19,     1] loss: 1053.199
[20,     1] loss: 1086.532
[21,     1] loss: 1035.594
[22,     1] loss: 1064.408
[23,     1] loss: 1058.862
[24,     1] loss: 1023.297
[25,     1] loss: 1054.864
[26,     1] loss: 976.389
[27,     1] loss: 1029.419
[28,     1] loss: 971.278
[29,     1] loss: 957.498
[30,     1] loss: 951.001
[31,     1] loss: 922.728
[32,     1] loss: 923.724
[33,     1] loss: 944.279
[34,     1] loss: 934.505
[35,     1] loss: 979.662
[36,     1] loss: 901.259
[37,     1] loss: 922.470
[38,     1] loss: 873.669
[39,     1] loss: 896.794
[40,     1] loss: 865.065
[41,     1] loss: 867.100
[42,     1] loss: 876.962
[43,     1] loss: 841.829
[44,     1] loss: 979.047
[45,     1] loss: 830.846
[46,     1] loss: 950.456
[47,     1] loss: 772.759
[48,     1] loss: 833.468
[49,     1] loss: 848.538
Early stopping applied (best metric=0.7553341388702393)
Finished Training
Total time taken: 6.858144283294678
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1319.682
[2,     1] loss: 1318.437
[3,     1] loss: 1327.452
[4,     1] loss: 1325.848
[5,     1] loss: 1315.845
[6,     1] loss: 1311.541
[7,     1] loss: 1307.924
[8,     1] loss: 1290.185
[9,     1] loss: 1264.087
[10,     1] loss: 1210.205
[11,     1] loss: 1182.221
[12,     1] loss: 1157.085
[13,     1] loss: 1148.116
[14,     1] loss: 1131.065
[15,     1] loss: 1136.988
[16,     1] loss: 1135.600
[17,     1] loss: 1092.771
[18,     1] loss: 1098.794
[19,     1] loss: 1044.086
[20,     1] loss: 1088.123
[21,     1] loss: 1057.744
[22,     1] loss: 1089.102
[23,     1] loss: 1035.353
[24,     1] loss: 1050.980
[25,     1] loss: 1026.151
[26,     1] loss: 1035.315
[27,     1] loss: 963.799
[28,     1] loss: 983.220
[29,     1] loss: 1013.740
[30,     1] loss: 997.747
[31,     1] loss: 989.155
[32,     1] loss: 990.967
[33,     1] loss: 966.483
[34,     1] loss: 937.103
[35,     1] loss: 957.112
[36,     1] loss: 933.329
[37,     1] loss: 901.552
[38,     1] loss: 940.099
[39,     1] loss: 934.507
[40,     1] loss: 904.699
[41,     1] loss: 929.122
[42,     1] loss: 941.831
[43,     1] loss: 903.359
[44,     1] loss: 841.893
[45,     1] loss: 871.338
[46,     1] loss: 855.742
[47,     1] loss: 880.869
[48,     1] loss: 809.846
Early stopping applied (best metric=0.863457202911377)
Finished Training
Total time taken: 6.510137319564819
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1320.867
[2,     1] loss: 1324.966
[3,     1] loss: 1316.196
[4,     1] loss: 1318.992
[5,     1] loss: 1318.512
[6,     1] loss: 1315.523
[7,     1] loss: 1307.802
[8,     1] loss: 1312.621
[9,     1] loss: 1289.498
[10,     1] loss: 1266.297
[11,     1] loss: 1249.844
[12,     1] loss: 1198.856
[13,     1] loss: 1169.403
[14,     1] loss: 1148.414
[15,     1] loss: 1124.293
[16,     1] loss: 1114.260
[17,     1] loss: 1084.873
[18,     1] loss: 1017.130
[19,     1] loss: 1054.640
[20,     1] loss: 1018.974
[21,     1] loss: 1039.523
[22,     1] loss: 1053.924
[23,     1] loss: 987.997
[24,     1] loss: 1029.619
[25,     1] loss: 1002.017
[26,     1] loss: 971.476
[27,     1] loss: 1006.186
[28,     1] loss: 922.393
[29,     1] loss: 983.113
Early stopping applied (best metric=1.05438232421875)
Finished Training
Total time taken: 4.53609561920166
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1321.393
[2,     1] loss: 1318.080
[3,     1] loss: 1316.615
[4,     1] loss: 1319.238
[5,     1] loss: 1315.398
[6,     1] loss: 1311.939
[7,     1] loss: 1301.789
[8,     1] loss: 1288.216
[9,     1] loss: 1261.895
[10,     1] loss: 1208.100
[11,     1] loss: 1174.005
[12,     1] loss: 1134.181
[13,     1] loss: 1131.254
[14,     1] loss: 1168.596
[15,     1] loss: 1118.220
[16,     1] loss: 1118.552
[17,     1] loss: 1114.948
[18,     1] loss: 1068.965
[19,     1] loss: 1102.378
[20,     1] loss: 1033.777
[21,     1] loss: 1081.132
[22,     1] loss: 1063.750
[23,     1] loss: 1051.020
[24,     1] loss: 1074.259
[25,     1] loss: 1058.646
[26,     1] loss: 1034.861
[27,     1] loss: 1050.080
[28,     1] loss: 987.373
[29,     1] loss: 1010.974
[30,     1] loss: 1038.427
[31,     1] loss: 980.936
[32,     1] loss: 983.931
[33,     1] loss: 1037.901
[34,     1] loss: 981.706
[35,     1] loss: 935.715
[36,     1] loss: 980.222
[37,     1] loss: 936.755
[38,     1] loss: 947.676
[39,     1] loss: 918.960
[40,     1] loss: 919.676
[41,     1] loss: 908.606
[42,     1] loss: 939.442
[43,     1] loss: 876.588
[44,     1] loss: 871.594
[45,     1] loss: 900.136
[46,     1] loss: 912.203
[47,     1] loss: 838.054
[48,     1] loss: 847.592
[49,     1] loss: 827.026
[50,     1] loss: 823.062
[51,     1] loss: 779.496
[52,     1] loss: 770.374
[53,     1] loss: 823.530
[54,     1] loss: 858.260
Early stopping applied (best metric=0.7924900650978088)
Finished Training
Total time taken: 8.954187154769897
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1321.564
[2,     1] loss: 1324.619
[3,     1] loss: 1327.505
[4,     1] loss: 1322.951
[5,     1] loss: 1320.735
[6,     1] loss: 1320.481
[7,     1] loss: 1319.327
[8,     1] loss: 1320.122
[9,     1] loss: 1317.707
[10,     1] loss: 1316.419
[11,     1] loss: 1311.023
[12,     1] loss: 1306.317
[13,     1] loss: 1307.543
[14,     1] loss: 1281.842
[15,     1] loss: 1259.475
[16,     1] loss: 1240.805
[17,     1] loss: 1191.890
[18,     1] loss: 1189.972
[19,     1] loss: 1181.409
[20,     1] loss: 1171.111
[21,     1] loss: 1090.910
[22,     1] loss: 1142.617
[23,     1] loss: 1083.670
[24,     1] loss: 1135.010
[25,     1] loss: 1104.649
[26,     1] loss: 1075.109
[27,     1] loss: 1080.355
[28,     1] loss: 1089.169
[29,     1] loss: 1040.684
[30,     1] loss: 1031.271
[31,     1] loss: 1029.698
[32,     1] loss: 1026.516
[33,     1] loss: 1000.024
[34,     1] loss: 1009.458
[35,     1] loss: 988.924
[36,     1] loss: 1026.821
[37,     1] loss: 982.084
[38,     1] loss: 960.537
[39,     1] loss: 920.948
[40,     1] loss: 960.555
[41,     1] loss: 879.917
[42,     1] loss: 946.536
[43,     1] loss: 969.769
[44,     1] loss: 955.460
[45,     1] loss: 934.841
[46,     1] loss: 862.002
[47,     1] loss: 905.290
[48,     1] loss: 869.671
[49,     1] loss: 877.320
[50,     1] loss: 904.406
[51,     1] loss: 791.081
[52,     1] loss: 837.501
[53,     1] loss: 856.929
[54,     1] loss: 790.359
[55,     1] loss: 849.259
[56,     1] loss: 821.457
[57,     1] loss: 804.354
[58,     1] loss: 781.168
[59,     1] loss: 820.263
Early stopping applied (best metric=0.795932412147522)
Finished Training
Total time taken: 9.868207931518555
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1321.203
[2,     1] loss: 1318.987
[3,     1] loss: 1319.596
[4,     1] loss: 1316.296
[5,     1] loss: 1319.021
[6,     1] loss: 1312.504
[7,     1] loss: 1307.849
[8,     1] loss: 1305.625
[9,     1] loss: 1282.704
[10,     1] loss: 1252.823
[11,     1] loss: 1228.988
[12,     1] loss: 1196.197
[13,     1] loss: 1165.637
[14,     1] loss: 1126.024
[15,     1] loss: 1140.253
[16,     1] loss: 1131.070
[17,     1] loss: 1085.219
[18,     1] loss: 1040.378
[19,     1] loss: 1080.151
[20,     1] loss: 1076.859
[21,     1] loss: 1074.051
[22,     1] loss: 1067.265
[23,     1] loss: 1100.789
[24,     1] loss: 1047.466
[25,     1] loss: 966.692
[26,     1] loss: 1033.156
[27,     1] loss: 958.507
[28,     1] loss: 1017.406
[29,     1] loss: 1026.854
[30,     1] loss: 991.668
[31,     1] loss: 981.429
[32,     1] loss: 966.535
[33,     1] loss: 1008.400
[34,     1] loss: 959.285
[35,     1] loss: 953.718
[36,     1] loss: 932.386
[37,     1] loss: 918.488
[38,     1] loss: 904.276
[39,     1] loss: 901.134
[40,     1] loss: 854.704
[41,     1] loss: 889.377
[42,     1] loss: 895.131
[43,     1] loss: 869.118
[44,     1] loss: 852.401
[45,     1] loss: 849.135
[46,     1] loss: 833.436
[47,     1] loss: 771.162
[48,     1] loss: 829.507
[49,     1] loss: 790.526
[50,     1] loss: 766.363
[51,     1] loss: 757.339
[52,     1] loss: 711.599
[53,     1] loss: 751.660
[54,     1] loss: 740.332
[55,     1] loss: 759.481
[56,     1] loss: 806.544
[57,     1] loss: 794.953
Early stopping applied (best metric=0.7844374179840088)
Finished Training
Total time taken: 7.80416464805603
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1319.513
[2,     1] loss: 1324.586
[3,     1] loss: 1319.909
[4,     1] loss: 1314.197
[5,     1] loss: 1308.195
[6,     1] loss: 1296.345
[7,     1] loss: 1269.617
[8,     1] loss: 1239.134
[9,     1] loss: 1197.722
[10,     1] loss: 1123.350
[11,     1] loss: 1157.713
[12,     1] loss: 1163.616
[13,     1] loss: 1113.062
[14,     1] loss: 1092.411
[15,     1] loss: 1103.921
[16,     1] loss: 1106.860
[17,     1] loss: 1059.697
[18,     1] loss: 1069.940
[19,     1] loss: 1092.839
[20,     1] loss: 1087.518
[21,     1] loss: 1023.975
[22,     1] loss: 1046.728
[23,     1] loss: 1021.370
[24,     1] loss: 1048.617
[25,     1] loss: 989.611
[26,     1] loss: 982.721
[27,     1] loss: 1043.370
[28,     1] loss: 1006.756
[29,     1] loss: 1024.274
[30,     1] loss: 974.626
[31,     1] loss: 970.948
[32,     1] loss: 966.300
[33,     1] loss: 926.252
[34,     1] loss: 934.979
[35,     1] loss: 900.689
[36,     1] loss: 902.425
[37,     1] loss: 922.131
[38,     1] loss: 953.824
[39,     1] loss: 950.544
[40,     1] loss: 859.729
[41,     1] loss: 942.438
[42,     1] loss: 880.695
Early stopping applied (best metric=0.8908475637435913)
Finished Training
Total time taken: 6.78514552116394
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1322.875
[2,     1] loss: 1319.830
[3,     1] loss: 1319.431
[4,     1] loss: 1310.073
[5,     1] loss: 1306.602
[6,     1] loss: 1289.408
[7,     1] loss: 1254.637
[8,     1] loss: 1234.559
[9,     1] loss: 1196.637
[10,     1] loss: 1149.296
[11,     1] loss: 1133.439
[12,     1] loss: 1094.283
[13,     1] loss: 1078.533
[14,     1] loss: 1106.292
[15,     1] loss: 1077.724
[16,     1] loss: 1090.636
[17,     1] loss: 1061.342
[18,     1] loss: 1060.014
[19,     1] loss: 1076.515
[20,     1] loss: 1050.549
[21,     1] loss: 1016.142
[22,     1] loss: 1004.883
[23,     1] loss: 1005.979
[24,     1] loss: 1004.268
[25,     1] loss: 989.682
[26,     1] loss: 988.943
[27,     1] loss: 965.242
[28,     1] loss: 965.574
[29,     1] loss: 941.059
[30,     1] loss: 974.976
[31,     1] loss: 947.922
[32,     1] loss: 919.236
[33,     1] loss: 922.289
[34,     1] loss: 909.959
[35,     1] loss: 917.551
[36,     1] loss: 922.345
[37,     1] loss: 869.937
[38,     1] loss: 857.184
[39,     1] loss: 833.449
[40,     1] loss: 885.947
[41,     1] loss: 928.591
[42,     1] loss: 905.105
[43,     1] loss: 827.405
[44,     1] loss: 908.243
[45,     1] loss: 893.308
[46,     1] loss: 857.386
[47,     1] loss: 839.444
[48,     1] loss: 836.880
[49,     1] loss: 819.301
Early stopping applied (best metric=0.9763985276222229)
Finished Training
Total time taken: 7.757162570953369
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1316.914
[2,     1] loss: 1320.959
[3,     1] loss: 1321.504
[4,     1] loss: 1319.558
[5,     1] loss: 1319.149
[6,     1] loss: 1311.945
[7,     1] loss: 1302.022
[8,     1] loss: 1281.507
[9,     1] loss: 1245.550
[10,     1] loss: 1213.178
[11,     1] loss: 1164.703
[12,     1] loss: 1148.288
[13,     1] loss: 1153.467
[14,     1] loss: 1176.328
[15,     1] loss: 1162.352
[16,     1] loss: 1099.555
[17,     1] loss: 1119.049
[18,     1] loss: 1106.965
[19,     1] loss: 1088.635
[20,     1] loss: 1099.388
[21,     1] loss: 1073.702
[22,     1] loss: 1083.185
[23,     1] loss: 1042.274
[24,     1] loss: 1033.475
[25,     1] loss: 1100.210
[26,     1] loss: 968.514
[27,     1] loss: 1027.798
[28,     1] loss: 1046.672
[29,     1] loss: 1000.405
[30,     1] loss: 1002.352
[31,     1] loss: 1008.001
[32,     1] loss: 1003.439
[33,     1] loss: 924.511
[34,     1] loss: 934.897
[35,     1] loss: 936.351
[36,     1] loss: 949.380
[37,     1] loss: 947.666
[38,     1] loss: 910.960
[39,     1] loss: 912.600
[40,     1] loss: 920.691
[41,     1] loss: 923.555
[42,     1] loss: 886.551
[43,     1] loss: 912.904
[44,     1] loss: 844.451
[45,     1] loss: 868.353
[46,     1] loss: 811.297
[47,     1] loss: 793.418
[48,     1] loss: 930.571
[49,     1] loss: 878.004
[50,     1] loss: 784.319
[51,     1] loss: 880.147
[52,     1] loss: 809.035
[53,     1] loss: 811.957
[54,     1] loss: 777.259
[55,     1] loss: 829.487
[56,     1] loss: 742.680
[57,     1] loss: 798.352
[58,     1] loss: 728.239
[59,     1] loss: 702.291
[60,     1] loss: 687.919
[61,     1] loss: 696.677
Early stopping applied (best metric=0.7287158370018005)
Finished Training
Total time taken: 9.34220004081726
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1329.990
[2,     1] loss: 1326.066
[3,     1] loss: 1317.854
[4,     1] loss: 1320.182
[5,     1] loss: 1321.122
[6,     1] loss: 1316.940
[7,     1] loss: 1322.367
[8,     1] loss: 1309.580
[9,     1] loss: 1290.381
[10,     1] loss: 1277.041
[11,     1] loss: 1252.725
[12,     1] loss: 1221.287
[13,     1] loss: 1186.657
[14,     1] loss: 1163.166
[15,     1] loss: 1146.633
[16,     1] loss: 1132.790
[17,     1] loss: 1105.865
[18,     1] loss: 1075.574
[19,     1] loss: 1141.705
[20,     1] loss: 1104.290
[21,     1] loss: 1038.288
[22,     1] loss: 1142.874
[23,     1] loss: 1071.215
[24,     1] loss: 1080.219
[25,     1] loss: 1090.399
[26,     1] loss: 1059.962
[27,     1] loss: 1082.489
[28,     1] loss: 1076.248
[29,     1] loss: 1073.591
[30,     1] loss: 1004.067
[31,     1] loss: 1027.871
[32,     1] loss: 1009.446
[33,     1] loss: 1003.192
[34,     1] loss: 943.359
[35,     1] loss: 974.302
[36,     1] loss: 969.807
[37,     1] loss: 976.345
[38,     1] loss: 952.392
[39,     1] loss: 945.851
[40,     1] loss: 961.477
[41,     1] loss: 896.326
[42,     1] loss: 929.408
[43,     1] loss: 929.398
[44,     1] loss: 904.053
[45,     1] loss: 872.351
[46,     1] loss: 946.584
[47,     1] loss: 895.357
[48,     1] loss: 881.485
[49,     1] loss: 912.092
[50,     1] loss: 867.140
[51,     1] loss: 870.425
[52,     1] loss: 788.657
[53,     1] loss: 806.724
[54,     1] loss: 866.293
[55,     1] loss: 781.718
[56,     1] loss: 801.771
[57,     1] loss: 741.830
[58,     1] loss: 811.773
[59,     1] loss: 775.188
[60,     1] loss: 818.662
[61,     1] loss: 746.878
[62,     1] loss: 775.830
[63,     1] loss: 747.473
[64,     1] loss: 771.587
[65,     1] loss: 792.619
[66,     1] loss: 736.481
[67,     1] loss: 771.459
[68,     1] loss: 704.423
[69,     1] loss: 689.638
[70,     1] loss: 678.678
[71,     1] loss: 671.444
Early stopping applied (best metric=0.8486104011535645)
Finished Training
Total time taken: 10.000210762023926
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1320.377
[2,     1] loss: 1320.863
[3,     1] loss: 1327.154
[4,     1] loss: 1316.564
[5,     1] loss: 1317.185
[6,     1] loss: 1309.835
[7,     1] loss: 1302.163
[8,     1] loss: 1296.205
[9,     1] loss: 1256.089
[10,     1] loss: 1240.086
[11,     1] loss: 1188.782
[12,     1] loss: 1155.691
[13,     1] loss: 1120.788
[14,     1] loss: 1089.456
[15,     1] loss: 1083.882
[16,     1] loss: 1109.542
[17,     1] loss: 1129.327
[18,     1] loss: 1101.573
[19,     1] loss: 1071.747
[20,     1] loss: 1066.000
[21,     1] loss: 1087.596
[22,     1] loss: 1086.127
[23,     1] loss: 1055.428
[24,     1] loss: 1029.400
[25,     1] loss: 1000.231
[26,     1] loss: 998.564
[27,     1] loss: 1021.221
[28,     1] loss: 1033.779
[29,     1] loss: 985.232
[30,     1] loss: 982.688
[31,     1] loss: 1018.624
[32,     1] loss: 949.753
[33,     1] loss: 985.804
[34,     1] loss: 965.487
[35,     1] loss: 986.465
[36,     1] loss: 944.252
[37,     1] loss: 929.831
[38,     1] loss: 944.742
[39,     1] loss: 924.613
[40,     1] loss: 881.726
[41,     1] loss: 890.563
[42,     1] loss: 910.129
[43,     1] loss: 842.170
[44,     1] loss: 865.631
[45,     1] loss: 840.270
[46,     1] loss: 906.922
[47,     1] loss: 821.506
[48,     1] loss: 893.314
[49,     1] loss: 806.833
[50,     1] loss: 778.511
[51,     1] loss: 786.060
[52,     1] loss: 794.744
[53,     1] loss: 812.117
[54,     1] loss: 687.402
Early stopping applied (best metric=0.8229048848152161)
Finished Training
Total time taken: 9.017189264297485
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1322.347
[2,     1] loss: 1320.068
[3,     1] loss: 1320.573
[4,     1] loss: 1310.938
[5,     1] loss: 1315.887
[6,     1] loss: 1305.037
[7,     1] loss: 1287.307
[8,     1] loss: 1268.679
[9,     1] loss: 1276.913
[10,     1] loss: 1196.501
[11,     1] loss: 1174.655
[12,     1] loss: 1160.918
[13,     1] loss: 1155.049
[14,     1] loss: 1086.526
[15,     1] loss: 1154.655
[16,     1] loss: 1071.478
[17,     1] loss: 1137.174
[18,     1] loss: 1055.102
[19,     1] loss: 1104.663
[20,     1] loss: 1082.112
[21,     1] loss: 1066.148
[22,     1] loss: 1087.322
[23,     1] loss: 1036.128
[24,     1] loss: 1038.808
[25,     1] loss: 1042.697
[26,     1] loss: 1055.987
[27,     1] loss: 1054.463
[28,     1] loss: 1018.316
[29,     1] loss: 1002.133
[30,     1] loss: 999.981
[31,     1] loss: 1005.542
[32,     1] loss: 967.094
[33,     1] loss: 946.413
[34,     1] loss: 975.365
[35,     1] loss: 902.867
[36,     1] loss: 956.739
[37,     1] loss: 910.105
[38,     1] loss: 903.768
[39,     1] loss: 925.033
[40,     1] loss: 903.094
[41,     1] loss: 894.333
[42,     1] loss: 867.422
[43,     1] loss: 915.498
[44,     1] loss: 879.415
[45,     1] loss: 886.719
[46,     1] loss: 830.975
[47,     1] loss: 856.474
[48,     1] loss: 817.004
[49,     1] loss: 808.491
Early stopping applied (best metric=0.8264390230178833)
Finished Training
Total time taken: 7.473156452178955
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1325.486
[2,     1] loss: 1320.976
[3,     1] loss: 1316.363
[4,     1] loss: 1316.916
[5,     1] loss: 1315.474
[6,     1] loss: 1310.781
[7,     1] loss: 1294.793
[8,     1] loss: 1273.303
[9,     1] loss: 1227.725
[10,     1] loss: 1210.206
[11,     1] loss: 1206.801
[12,     1] loss: 1146.644
[13,     1] loss: 1141.541
[14,     1] loss: 1068.723
[15,     1] loss: 1104.010
[16,     1] loss: 1056.141
[17,     1] loss: 1028.209
[18,     1] loss: 1010.516
[19,     1] loss: 1099.302
[20,     1] loss: 1047.515
[21,     1] loss: 1050.981
[22,     1] loss: 1050.664
[23,     1] loss: 1012.652
[24,     1] loss: 1010.609
[25,     1] loss: 995.527
[26,     1] loss: 989.574
[27,     1] loss: 986.654
[28,     1] loss: 991.270
[29,     1] loss: 930.810
[30,     1] loss: 983.155
[31,     1] loss: 954.755
[32,     1] loss: 937.003
[33,     1] loss: 941.934
[34,     1] loss: 957.646
[35,     1] loss: 925.629
[36,     1] loss: 974.790
[37,     1] loss: 835.948
[38,     1] loss: 1029.933
[39,     1] loss: 865.662
[40,     1] loss: 911.536
[41,     1] loss: 905.534
[42,     1] loss: 901.597
Early stopping applied (best metric=0.9344540238380432)
Finished Training
Total time taken: 6.7671427726745605
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1322.708
[2,     1] loss: 1338.360
[3,     1] loss: 1319.560
[4,     1] loss: 1321.633
[5,     1] loss: 1316.403
[6,     1] loss: 1317.260
[7,     1] loss: 1315.849
[8,     1] loss: 1319.143
[9,     1] loss: 1313.418
[10,     1] loss: 1306.783
[11,     1] loss: 1303.129
[12,     1] loss: 1292.437
[13,     1] loss: 1271.248
[14,     1] loss: 1251.436
[15,     1] loss: 1209.133
[16,     1] loss: 1183.531
[17,     1] loss: 1159.970
[18,     1] loss: 1169.337
[19,     1] loss: 1140.791
[20,     1] loss: 1118.235
[21,     1] loss: 1089.138
[22,     1] loss: 1096.490
[23,     1] loss: 1095.417
[24,     1] loss: 1094.328
[25,     1] loss: 1076.047
[26,     1] loss: 1077.673
[27,     1] loss: 1120.586
[28,     1] loss: 1041.893
[29,     1] loss: 1030.205
[30,     1] loss: 1025.824
[31,     1] loss: 1015.187
[32,     1] loss: 1036.233
[33,     1] loss: 1020.299
[34,     1] loss: 1037.450
[35,     1] loss: 1029.131
[36,     1] loss: 986.031
[37,     1] loss: 992.291
[38,     1] loss: 968.064
[39,     1] loss: 946.133
[40,     1] loss: 977.880
[41,     1] loss: 941.658
[42,     1] loss: 948.232
[43,     1] loss: 988.461
[44,     1] loss: 931.078
[45,     1] loss: 935.613
[46,     1] loss: 929.522
[47,     1] loss: 927.768
[48,     1] loss: 876.465
[49,     1] loss: 824.786
[50,     1] loss: 886.443
[51,     1] loss: 938.214
[52,     1] loss: 914.062
[53,     1] loss: 819.233
[54,     1] loss: 781.200
[55,     1] loss: 856.268
[56,     1] loss: 784.717
[57,     1] loss: 798.219
[58,     1] loss: 753.512
[59,     1] loss: 835.606
[60,     1] loss: 823.081
[61,     1] loss: 674.513
[62,     1] loss: 740.722
Early stopping applied (best metric=0.8393195867538452)
Finished Training
Total time taken: 9.202194929122925
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1322.332
[2,     1] loss: 1328.940
[3,     1] loss: 1318.032
[4,     1] loss: 1321.336
[5,     1] loss: 1317.336
[6,     1] loss: 1315.222
[7,     1] loss: 1309.881
[8,     1] loss: 1296.682
[9,     1] loss: 1276.179
[10,     1] loss: 1243.807
[11,     1] loss: 1190.343
[12,     1] loss: 1183.144
[13,     1] loss: 1144.428
[14,     1] loss: 1106.539
[15,     1] loss: 1151.073
[16,     1] loss: 1123.448
[17,     1] loss: 1079.135
[18,     1] loss: 1095.436
[19,     1] loss: 1072.029
[20,     1] loss: 1118.816
[21,     1] loss: 1082.055
[22,     1] loss: 1035.255
[23,     1] loss: 1030.227
[24,     1] loss: 1029.286
[25,     1] loss: 1039.245
[26,     1] loss: 999.972
[27,     1] loss: 1019.438
[28,     1] loss: 1026.026
[29,     1] loss: 1083.734
[30,     1] loss: 959.035
[31,     1] loss: 941.691
[32,     1] loss: 1006.458
[33,     1] loss: 936.672
[34,     1] loss: 1003.302
[35,     1] loss: 932.371
[36,     1] loss: 948.439
[37,     1] loss: 1008.407
[38,     1] loss: 936.840
[39,     1] loss: 980.985
[40,     1] loss: 940.197
[41,     1] loss: 920.261
[42,     1] loss: 901.868
[43,     1] loss: 927.639
Early stopping applied (best metric=0.8984932899475098)
Finished Training
Total time taken: 5.920124530792236
{'Hydroxylation-K Validation Accuracy': 0.749290780141844, 'Hydroxylation-K Validation Sensitivity': 0.5822222222222222, 'Hydroxylation-K Validation Specificity': 0.7912280701754386, 'Hydroxylation-K Validation Precision': 0.41325994693002366, 'Hydroxylation-K AUC ROC': 0.7851072124756335, 'Hydroxylation-K AUC PR': 0.5397227804153399, 'Hydroxylation-K MCC': 0.3334182649899019, 'Hydroxylation-K F1': 0.47661064183718643, 'Validation Loss (Hydroxylation-K)': 0.46602676510810853, 'Hydroxylation-P Validation Accuracy': 0.799642826929259, 'Hydroxylation-P Validation Sensitivity': 0.7234920634920635, 'Hydroxylation-P Validation Specificity': 0.816008279714699, 'Hydroxylation-P Validation Precision': 0.4639584285400738, 'Hydroxylation-P AUC ROC': 0.8369680057668236, 'Hydroxylation-P AUC PR': 0.5799517373221537, 'Hydroxylation-P MCC': 0.46206578579217517, 'Hydroxylation-P F1': 0.5618263087998174, 'Validation Loss (Hydroxylation-P)': 0.38812101682027184, 'Validation Loss (total)': 0.8541477799415589, 'TimeToTrain': 7.78636425336202}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032381735864566437,
 'learning_rate_Hydroxylation-K': 0.007353969528476599,
 'learning_rate_Hydroxylation-P': 0.0008499181864595143,
 'log_base': 2.243338026906085,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1734498687,
 'sample_weights': [1.9504757975319855, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5246877377747924,
 'weight_decay_Hydroxylation-K': 3.6858301606993447,
 'weight_decay_Hydroxylation-P': 2.762866414594103}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1347.562
[2,     1] loss: 1349.052
[3,     1] loss: 1344.755
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004003700035682543,
 'learning_rate_Hydroxylation-K': 0.006349214794601923,
 'learning_rate_Hydroxylation-P': 0.005188380963200598,
 'log_base': 1.2611487823398904,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3152080392,
 'sample_weights': [2.0662321467932303, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.934745214904561,
 'weight_decay_Hydroxylation-K': 0.9312361930546134,
 'weight_decay_Hydroxylation-P': 1.0511652189251244}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2444.351
[2,     1] loss: 2421.170
[3,     1] loss: 2431.995
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005345105573111095,
 'learning_rate_Hydroxylation-K': 0.00309850451040151,
 'learning_rate_Hydroxylation-P': 0.007960310865146777,
 'log_base': 2.872710939146726,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 818337163,
 'sample_weights': [7.1951611558202515, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.0728439663318855,
 'weight_decay_Hydroxylation-K': 5.461593280024851,
 'weight_decay_Hydroxylation-P': 7.6756773432393395}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.743
[2,     1] loss: 1240.964
[3,     1] loss: 1244.835
[4,     1] loss: 1237.780
[5,     1] loss: 1215.746
[6,     1] loss: 1166.570
[7,     1] loss: 1122.517
[8,     1] loss: 1072.706
[9,     1] loss: 1087.046
[10,     1] loss: 1063.706
[11,     1] loss: 1051.121
[12,     1] loss: 1022.044
[13,     1] loss: 1031.078
[14,     1] loss: 977.551
[15,     1] loss: 995.919
[16,     1] loss: 980.662
[17,     1] loss: 978.175
[18,     1] loss: 983.236
[19,     1] loss: 963.680
[20,     1] loss: 920.627
[21,     1] loss: 982.174
[22,     1] loss: 925.120
[23,     1] loss: 936.270
[24,     1] loss: 955.592
[25,     1] loss: 926.823
[26,     1] loss: 905.092
[27,     1] loss: 870.532
[28,     1] loss: 893.024
[29,     1] loss: 917.940
[30,     1] loss: 906.892
[31,     1] loss: 943.435
[32,     1] loss: 895.870
[33,     1] loss: 895.454
[34,     1] loss: 902.880
[35,     1] loss: 873.500
[36,     1] loss: 852.024
[37,     1] loss: 877.496
[38,     1] loss: 847.095
[39,     1] loss: 877.564
[40,     1] loss: 902.848
[41,     1] loss: 823.658
[42,     1] loss: 841.077
[43,     1] loss: 822.589
[44,     1] loss: 807.256
[45,     1] loss: 813.005
[46,     1] loss: 796.910
[47,     1] loss: 761.714
[48,     1] loss: 823.294
[49,     1] loss: 855.975
[50,     1] loss: 826.479
[51,     1] loss: 828.466
[52,     1] loss: 831.463
[53,     1] loss: 838.415
[54,     1] loss: 770.179
[55,     1] loss: 789.759
[56,     1] loss: 743.397
[57,     1] loss: 746.085
[58,     1] loss: 818.053
[59,     1] loss: 761.957
[60,     1] loss: 766.546
[61,     1] loss: 785.785
[62,     1] loss: 682.822
[63,     1] loss: 749.017
Early stopping applied (best metric=0.8405023813247681)
Finished Training
Total time taken: 10.42007327079773
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.322
[2,     1] loss: 1240.906
[3,     1] loss: 1236.321
[4,     1] loss: 1237.391
[5,     1] loss: 1230.063
[6,     1] loss: 1216.159
[7,     1] loss: 1170.007
[8,     1] loss: 1116.312
[9,     1] loss: 1116.566
[10,     1] loss: 1166.310
[11,     1] loss: 1051.054
[12,     1] loss: 1073.818
[13,     1] loss: 1063.899
[14,     1] loss: 1049.990
[15,     1] loss: 1026.427
[16,     1] loss: 997.123
[17,     1] loss: 986.476
[18,     1] loss: 974.950
[19,     1] loss: 955.728
[20,     1] loss: 952.155
[21,     1] loss: 922.640
[22,     1] loss: 944.597
[23,     1] loss: 901.557
[24,     1] loss: 966.387
[25,     1] loss: 936.616
[26,     1] loss: 963.997
[27,     1] loss: 866.223
[28,     1] loss: 883.521
[29,     1] loss: 861.902
[30,     1] loss: 884.368
[31,     1] loss: 833.101
[32,     1] loss: 902.450
[33,     1] loss: 865.385
[34,     1] loss: 872.644
Early stopping applied (best metric=1.0034281015396118)
Finished Training
Total time taken: 5.019004821777344
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.509
[2,     1] loss: 1250.837
[3,     1] loss: 1259.674
[4,     1] loss: 1244.302
[5,     1] loss: 1239.114
[6,     1] loss: 1237.988
[7,     1] loss: 1237.880
[8,     1] loss: 1230.157
[9,     1] loss: 1228.406
[10,     1] loss: 1210.502
[11,     1] loss: 1193.159
[12,     1] loss: 1155.938
[13,     1] loss: 1104.961
[14,     1] loss: 1083.245
[15,     1] loss: 1105.241
[16,     1] loss: 1040.328
[17,     1] loss: 1057.829
[18,     1] loss: 1069.805
[19,     1] loss: 1030.422
[20,     1] loss: 1002.007
[21,     1] loss: 1029.743
[22,     1] loss: 1025.288
[23,     1] loss: 983.146
[24,     1] loss: 980.950
[25,     1] loss: 988.991
[26,     1] loss: 981.184
[27,     1] loss: 983.295
[28,     1] loss: 905.843
[29,     1] loss: 931.573
[30,     1] loss: 926.889
[31,     1] loss: 897.412
[32,     1] loss: 924.422
[33,     1] loss: 945.493
[34,     1] loss: 932.355
[35,     1] loss: 881.480
[36,     1] loss: 903.817
[37,     1] loss: 861.120
[38,     1] loss: 879.874
[39,     1] loss: 915.687
[40,     1] loss: 876.181
[41,     1] loss: 880.864
[42,     1] loss: 861.259
[43,     1] loss: 860.272
[44,     1] loss: 868.513
[45,     1] loss: 836.989
[46,     1] loss: 888.671
[47,     1] loss: 830.348
[48,     1] loss: 827.964
[49,     1] loss: 840.656
[50,     1] loss: 873.850
[51,     1] loss: 844.021
[52,     1] loss: 861.920
[53,     1] loss: 817.325
[54,     1] loss: 825.565
[55,     1] loss: 829.777
[56,     1] loss: 817.404
[57,     1] loss: 867.743
[58,     1] loss: 824.259
[59,     1] loss: 812.515
[60,     1] loss: 807.000
[61,     1] loss: 764.364
[62,     1] loss: 783.107
[63,     1] loss: 747.585
[64,     1] loss: 731.993
[65,     1] loss: 774.824
[66,     1] loss: 768.781
[67,     1] loss: 719.980
[68,     1] loss: 735.621
[69,     1] loss: 714.247
[70,     1] loss: 720.096
[71,     1] loss: 735.910
[72,     1] loss: 731.386
[73,     1] loss: 727.687
[74,     1] loss: 706.644
[75,     1] loss: 705.564
[76,     1] loss: 683.344
[77,     1] loss: 687.903
[78,     1] loss: 733.548
[79,     1] loss: 711.269
[80,     1] loss: 694.137
[81,     1] loss: 656.927
[82,     1] loss: 658.110
[83,     1] loss: 642.348
[84,     1] loss: 649.469
[85,     1] loss: 633.717
[86,     1] loss: 621.338
[87,     1] loss: 600.740
[88,     1] loss: 633.077
[89,     1] loss: 643.112
[90,     1] loss: 568.655
[91,     1] loss: 601.401
Early stopping applied (best metric=0.7936899662017822)
Finished Training
Total time taken: 13.305014371871948
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.647
[2,     1] loss: 1263.408
[3,     1] loss: 1244.316
[4,     1] loss: 1242.715
[5,     1] loss: 1241.971
[6,     1] loss: 1242.176
[7,     1] loss: 1238.762
[8,     1] loss: 1238.042
[9,     1] loss: 1239.290
[10,     1] loss: 1236.395
[11,     1] loss: 1233.168
[12,     1] loss: 1222.020
[13,     1] loss: 1208.000
[14,     1] loss: 1180.514
[15,     1] loss: 1148.845
[16,     1] loss: 1128.766
[17,     1] loss: 1111.148
[18,     1] loss: 1113.988
[19,     1] loss: 1070.641
[20,     1] loss: 1160.793
[21,     1] loss: 1022.225
[22,     1] loss: 1136.623
[23,     1] loss: 1072.707
[24,     1] loss: 1047.324
[25,     1] loss: 1013.479
[26,     1] loss: 1038.240
[27,     1] loss: 1026.843
[28,     1] loss: 1042.000
[29,     1] loss: 1006.878
[30,     1] loss: 1005.499
[31,     1] loss: 1000.436
[32,     1] loss: 1001.453
[33,     1] loss: 999.849
[34,     1] loss: 965.185
[35,     1] loss: 952.642
[36,     1] loss: 958.851
[37,     1] loss: 942.363
[38,     1] loss: 976.685
[39,     1] loss: 968.641
[40,     1] loss: 920.795
[41,     1] loss: 938.390
[42,     1] loss: 895.310
[43,     1] loss: 924.000
[44,     1] loss: 933.197
[45,     1] loss: 895.031
[46,     1] loss: 915.181
[47,     1] loss: 902.333
[48,     1] loss: 851.801
[49,     1] loss: 962.095
[50,     1] loss: 874.269
[51,     1] loss: 809.216
[52,     1] loss: 837.266
[53,     1] loss: 847.662
[54,     1] loss: 838.778
[55,     1] loss: 842.956
[56,     1] loss: 816.742
[57,     1] loss: 855.019
[58,     1] loss: 846.325
[59,     1] loss: 794.218
[60,     1] loss: 864.991
[61,     1] loss: 822.831
[62,     1] loss: 765.753
[63,     1] loss: 837.381
[64,     1] loss: 815.076
[65,     1] loss: 783.749
[66,     1] loss: 742.198
[67,     1] loss: 778.302
[68,     1] loss: 746.617
[69,     1] loss: 781.556
[70,     1] loss: 759.651
[71,     1] loss: 775.773
Early stopping applied (best metric=0.7592620253562927)
Finished Training
Total time taken: 11.8940110206604
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1243.741
[2,     1] loss: 1248.475
[3,     1] loss: 1239.814
[4,     1] loss: 1238.804
[5,     1] loss: 1230.000
[6,     1] loss: 1213.442
[7,     1] loss: 1168.845
[8,     1] loss: 1192.644
[9,     1] loss: 1107.147
[10,     1] loss: 1098.134
[11,     1] loss: 1102.167
[12,     1] loss: 1032.604
[13,     1] loss: 1017.999
[14,     1] loss: 1080.194
[15,     1] loss: 1038.839
[16,     1] loss: 995.867
[17,     1] loss: 1052.579
[18,     1] loss: 1013.563
[19,     1] loss: 981.547
[20,     1] loss: 976.102
[21,     1] loss: 993.122
[22,     1] loss: 967.293
[23,     1] loss: 959.581
[24,     1] loss: 944.783
[25,     1] loss: 955.346
[26,     1] loss: 965.384
[27,     1] loss: 920.510
[28,     1] loss: 929.990
[29,     1] loss: 950.019
[30,     1] loss: 905.979
[31,     1] loss: 936.783
[32,     1] loss: 858.370
[33,     1] loss: 919.912
[34,     1] loss: 915.151
[35,     1] loss: 887.300
[36,     1] loss: 898.016
[37,     1] loss: 937.665
[38,     1] loss: 867.263
[39,     1] loss: 871.768
[40,     1] loss: 880.943
[41,     1] loss: 878.959
[42,     1] loss: 867.249
[43,     1] loss: 800.029
[44,     1] loss: 800.867
[45,     1] loss: 864.316
[46,     1] loss: 873.755
[47,     1] loss: 785.135
[48,     1] loss: 864.228
[49,     1] loss: 795.862
[50,     1] loss: 818.423
[51,     1] loss: 869.904
[52,     1] loss: 775.881
[53,     1] loss: 861.635
[54,     1] loss: 802.074
[55,     1] loss: 787.230
[56,     1] loss: 813.408
[57,     1] loss: 773.572
[58,     1] loss: 783.760
[59,     1] loss: 826.533
[60,     1] loss: 766.803
[61,     1] loss: 798.349
[62,     1] loss: 714.470
[63,     1] loss: 742.184
[64,     1] loss: 710.197
[65,     1] loss: 647.990
[66,     1] loss: 711.095
[67,     1] loss: 656.903
[68,     1] loss: 658.104
[69,     1] loss: 665.392
[70,     1] loss: 727.016
[71,     1] loss: 683.442
Early stopping applied (best metric=0.7590348124504089)
Finished Training
Total time taken: 10.47501254081726
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1244.319
[2,     1] loss: 1261.695
[3,     1] loss: 1250.477
[4,     1] loss: 1241.204
[5,     1] loss: 1242.762
[6,     1] loss: 1246.500
[7,     1] loss: 1240.437
[8,     1] loss: 1239.344
[9,     1] loss: 1240.584
[10,     1] loss: 1239.913
[11,     1] loss: 1235.722
[12,     1] loss: 1234.177
[13,     1] loss: 1228.448
[14,     1] loss: 1222.861
[15,     1] loss: 1216.332
[16,     1] loss: 1190.631
[17,     1] loss: 1166.474
[18,     1] loss: 1127.526
[19,     1] loss: 1112.757
[20,     1] loss: 1070.264
[21,     1] loss: 1088.380
[22,     1] loss: 1083.068
[23,     1] loss: 1046.204
[24,     1] loss: 1060.813
[25,     1] loss: 1077.604
[26,     1] loss: 1073.204
[27,     1] loss: 1067.848
[28,     1] loss: 1028.686
[29,     1] loss: 1041.525
[30,     1] loss: 1030.694
[31,     1] loss: 1034.442
[32,     1] loss: 1030.043
[33,     1] loss: 1015.656
[34,     1] loss: 1025.669
[35,     1] loss: 1006.297
[36,     1] loss: 971.235
[37,     1] loss: 969.273
[38,     1] loss: 970.259
[39,     1] loss: 979.362
[40,     1] loss: 940.018
[41,     1] loss: 944.508
[42,     1] loss: 994.457
[43,     1] loss: 927.275
[44,     1] loss: 969.807
[45,     1] loss: 955.085
[46,     1] loss: 920.456
[47,     1] loss: 926.706
[48,     1] loss: 902.177
[49,     1] loss: 920.615
[50,     1] loss: 897.246
[51,     1] loss: 919.768
[52,     1] loss: 888.674
[53,     1] loss: 863.667
[54,     1] loss: 897.650
[55,     1] loss: 861.747
[56,     1] loss: 857.611
[57,     1] loss: 869.586
[58,     1] loss: 898.986
[59,     1] loss: 914.804
[60,     1] loss: 841.419
[61,     1] loss: 807.018
[62,     1] loss: 829.107
[63,     1] loss: 849.023
[64,     1] loss: 817.342
[65,     1] loss: 814.631
[66,     1] loss: 804.988
[67,     1] loss: 792.899
[68,     1] loss: 798.211
[69,     1] loss: 799.815
[70,     1] loss: 766.696
[71,     1] loss: 776.047
[72,     1] loss: 786.974
[73,     1] loss: 745.582
[74,     1] loss: 751.770
[75,     1] loss: 729.401
[76,     1] loss: 779.172
[77,     1] loss: 749.286
[78,     1] loss: 727.831
[79,     1] loss: 724.612
[80,     1] loss: 726.463
[81,     1] loss: 716.376
[82,     1] loss: 678.878
[83,     1] loss: 686.038
[84,     1] loss: 696.714
[85,     1] loss: 711.095
[86,     1] loss: 688.031
[87,     1] loss: 689.310
[88,     1] loss: 656.459
[89,     1] loss: 717.007
[90,     1] loss: 634.929
[91,     1] loss: 652.972
[92,     1] loss: 653.952
[93,     1] loss: 713.164
[94,     1] loss: 663.927
[95,     1] loss: 662.461
[96,     1] loss: 575.375
[97,     1] loss: 587.109
[98,     1] loss: 637.152
[99,     1] loss: 640.889
[100,     1] loss: 631.811
Early stopping applied (best metric=0.755989134311676)
Finished Training
Total time taken: 15.554013013839722
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.380
[2,     1] loss: 1253.644
[3,     1] loss: 1243.670
[4,     1] loss: 1242.244
[5,     1] loss: 1240.262
[6,     1] loss: 1240.783
[7,     1] loss: 1236.758
[8,     1] loss: 1232.700
[9,     1] loss: 1227.420
[10,     1] loss: 1212.527
[11,     1] loss: 1192.671
[12,     1] loss: 1145.214
[13,     1] loss: 1139.319
[14,     1] loss: 1099.309
[15,     1] loss: 1083.883
[16,     1] loss: 1053.379
[17,     1] loss: 1066.143
[18,     1] loss: 1010.711
[19,     1] loss: 1058.986
[20,     1] loss: 1021.898
[21,     1] loss: 1012.125
[22,     1] loss: 1004.456
[23,     1] loss: 1001.875
[24,     1] loss: 968.064
[25,     1] loss: 957.201
[26,     1] loss: 970.749
[27,     1] loss: 968.486
[28,     1] loss: 937.643
[29,     1] loss: 893.138
[30,     1] loss: 978.713
[31,     1] loss: 932.077
[32,     1] loss: 927.919
[33,     1] loss: 932.631
[34,     1] loss: 927.883
[35,     1] loss: 932.820
[36,     1] loss: 931.929
[37,     1] loss: 916.876
[38,     1] loss: 994.661
[39,     1] loss: 927.054
[40,     1] loss: 882.038
[41,     1] loss: 943.035
[42,     1] loss: 861.551
[43,     1] loss: 895.639
[44,     1] loss: 916.329
[45,     1] loss: 868.564
[46,     1] loss: 876.679
[47,     1] loss: 882.346
[48,     1] loss: 886.436
[49,     1] loss: 826.701
[50,     1] loss: 815.511
[51,     1] loss: 785.449
[52,     1] loss: 840.850
[53,     1] loss: 790.151
[54,     1] loss: 783.745
[55,     1] loss: 826.873
[56,     1] loss: 814.544
[57,     1] loss: 777.458
[58,     1] loss: 866.394
[59,     1] loss: 814.205
[60,     1] loss: 796.414
[61,     1] loss: 760.952
[62,     1] loss: 768.543
[63,     1] loss: 813.229
[64,     1] loss: 762.103
[65,     1] loss: 751.929
[66,     1] loss: 724.698
[67,     1] loss: 695.281
[68,     1] loss: 742.527
[69,     1] loss: 718.249
[70,     1] loss: 706.425
[71,     1] loss: 735.892
[72,     1] loss: 689.572
[73,     1] loss: 695.980
[74,     1] loss: 667.660
[75,     1] loss: 715.845
[76,     1] loss: 651.276
[77,     1] loss: 693.672
[78,     1] loss: 596.712
[79,     1] loss: 664.104
Early stopping applied (best metric=0.8206441402435303)
Finished Training
Total time taken: 11.283011198043823
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1247.387
[2,     1] loss: 1258.276
[3,     1] loss: 1251.227
[4,     1] loss: 1241.263
[5,     1] loss: 1239.176
[6,     1] loss: 1233.943
[7,     1] loss: 1229.632
[8,     1] loss: 1220.688
[9,     1] loss: 1203.939
[10,     1] loss: 1158.934
[11,     1] loss: 1125.238
[12,     1] loss: 1084.117
[13,     1] loss: 1073.127
[14,     1] loss: 1075.665
[15,     1] loss: 1071.779
[16,     1] loss: 1009.978
[17,     1] loss: 1008.435
[18,     1] loss: 991.989
[19,     1] loss: 1047.534
[20,     1] loss: 999.991
[21,     1] loss: 998.021
[22,     1] loss: 963.709
[23,     1] loss: 1002.199
[24,     1] loss: 958.596
[25,     1] loss: 974.539
[26,     1] loss: 946.002
[27,     1] loss: 951.872
[28,     1] loss: 927.426
[29,     1] loss: 942.410
[30,     1] loss: 965.894
[31,     1] loss: 923.826
[32,     1] loss: 872.018
[33,     1] loss: 868.611
[34,     1] loss: 873.233
[35,     1] loss: 933.729
[36,     1] loss: 899.336
[37,     1] loss: 870.778
[38,     1] loss: 915.098
[39,     1] loss: 887.945
[40,     1] loss: 884.772
[41,     1] loss: 887.588
[42,     1] loss: 893.359
[43,     1] loss: 868.119
[44,     1] loss: 867.872
[45,     1] loss: 826.834
[46,     1] loss: 822.652
[47,     1] loss: 821.401
[48,     1] loss: 837.272
[49,     1] loss: 799.396
[50,     1] loss: 772.954
[51,     1] loss: 801.067
[52,     1] loss: 798.346
[53,     1] loss: 795.264
[54,     1] loss: 799.990
[55,     1] loss: 786.444
[56,     1] loss: 757.858
[57,     1] loss: 787.463
[58,     1] loss: 702.490
[59,     1] loss: 736.286
[60,     1] loss: 739.346
Early stopping applied (best metric=0.8332042098045349)
Finished Training
Total time taken: 9.741009712219238
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.708
[2,     1] loss: 1256.574
[3,     1] loss: 1240.800
[4,     1] loss: 1242.313
[5,     1] loss: 1244.469
[6,     1] loss: 1239.244
[7,     1] loss: 1242.504
[8,     1] loss: 1240.629
[9,     1] loss: 1237.107
[10,     1] loss: 1237.474
[11,     1] loss: 1230.790
[12,     1] loss: 1225.405
[13,     1] loss: 1224.588
[14,     1] loss: 1197.749
[15,     1] loss: 1181.198
[16,     1] loss: 1163.974
[17,     1] loss: 1126.539
[18,     1] loss: 1071.497
[19,     1] loss: 1092.498
[20,     1] loss: 1042.971
[21,     1] loss: 1117.636
[22,     1] loss: 1130.781
[23,     1] loss: 1083.548
[24,     1] loss: 1055.161
[25,     1] loss: 1018.239
[26,     1] loss: 1059.897
[27,     1] loss: 1042.143
[28,     1] loss: 1036.187
[29,     1] loss: 1038.791
[30,     1] loss: 1037.381
[31,     1] loss: 1058.953
[32,     1] loss: 1011.731
[33,     1] loss: 985.855
[34,     1] loss: 1017.249
[35,     1] loss: 977.573
[36,     1] loss: 988.522
[37,     1] loss: 1007.792
[38,     1] loss: 984.772
[39,     1] loss: 987.690
[40,     1] loss: 977.559
[41,     1] loss: 969.736
[42,     1] loss: 956.754
[43,     1] loss: 939.875
[44,     1] loss: 899.111
[45,     1] loss: 885.190
[46,     1] loss: 867.294
[47,     1] loss: 897.130
[48,     1] loss: 898.670
[49,     1] loss: 915.009
[50,     1] loss: 915.662
[51,     1] loss: 932.626
[52,     1] loss: 869.287
[53,     1] loss: 935.574
[54,     1] loss: 877.216
[55,     1] loss: 921.076
[56,     1] loss: 939.217
[57,     1] loss: 935.809
[58,     1] loss: 908.802
[59,     1] loss: 881.314
[60,     1] loss: 923.639
[61,     1] loss: 817.820
[62,     1] loss: 809.589
[63,     1] loss: 828.698
[64,     1] loss: 831.420
[65,     1] loss: 852.902
[66,     1] loss: 862.592
[67,     1] loss: 853.851
[68,     1] loss: 819.274
[69,     1] loss: 833.947
[70,     1] loss: 784.024
[71,     1] loss: 816.265
[72,     1] loss: 786.937
Early stopping applied (best metric=0.869356632232666)
Finished Training
Total time taken: 10.864009380340576
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1254.762
[2,     1] loss: 1275.517
[3,     1] loss: 1243.823
[4,     1] loss: 1242.150
[5,     1] loss: 1250.275
[6,     1] loss: 1253.110
[7,     1] loss: 1247.601
[8,     1] loss: 1249.742
[9,     1] loss: 1240.569
[10,     1] loss: 1244.910
[11,     1] loss: 1243.160
[12,     1] loss: 1242.573
[13,     1] loss: 1244.540
[14,     1] loss: 1243.092
[15,     1] loss: 1240.765
[16,     1] loss: 1233.235
[17,     1] loss: 1229.904
[18,     1] loss: 1222.378
[19,     1] loss: 1216.562
[20,     1] loss: 1200.848
[21,     1] loss: 1185.991
[22,     1] loss: 1161.285
[23,     1] loss: 1150.629
[24,     1] loss: 1086.567
[25,     1] loss: 1141.049
[26,     1] loss: 1105.114
[27,     1] loss: 1098.030
[28,     1] loss: 1092.041
[29,     1] loss: 1018.862
[30,     1] loss: 1073.666
[31,     1] loss: 1057.722
[32,     1] loss: 1042.851
[33,     1] loss: 1058.156
[34,     1] loss: 1020.094
[35,     1] loss: 1039.425
[36,     1] loss: 1021.695
[37,     1] loss: 979.323
[38,     1] loss: 968.404
[39,     1] loss: 1007.121
[40,     1] loss: 989.046
[41,     1] loss: 938.919
[42,     1] loss: 978.036
[43,     1] loss: 986.109
[44,     1] loss: 984.315
[45,     1] loss: 963.044
[46,     1] loss: 980.806
[47,     1] loss: 957.850
[48,     1] loss: 943.479
[49,     1] loss: 921.544
[50,     1] loss: 925.823
[51,     1] loss: 911.824
[52,     1] loss: 927.222
[53,     1] loss: 909.167
[54,     1] loss: 921.630
[55,     1] loss: 891.951
[56,     1] loss: 875.557
[57,     1] loss: 911.550
[58,     1] loss: 883.138
[59,     1] loss: 912.603
[60,     1] loss: 941.781
[61,     1] loss: 856.562
[62,     1] loss: 878.989
[63,     1] loss: 849.910
[64,     1] loss: 835.960
[65,     1] loss: 861.036
[66,     1] loss: 808.493
[67,     1] loss: 865.471
[68,     1] loss: 801.242
[69,     1] loss: 827.119
[70,     1] loss: 811.383
[71,     1] loss: 773.080
[72,     1] loss: 797.464
[73,     1] loss: 760.881
[74,     1] loss: 745.209
[75,     1] loss: 831.882
[76,     1] loss: 750.102
[77,     1] loss: 808.611
[78,     1] loss: 795.238
[79,     1] loss: 776.188
[80,     1] loss: 821.103
[81,     1] loss: 751.874
[82,     1] loss: 757.434
[83,     1] loss: 728.015
[84,     1] loss: 764.405
Early stopping applied (best metric=0.8333560228347778)
Finished Training
Total time taken: 13.59601354598999
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.611
[2,     1] loss: 1248.790
[3,     1] loss: 1254.893
[4,     1] loss: 1240.828
[5,     1] loss: 1243.288
[6,     1] loss: 1242.045
[7,     1] loss: 1240.388
[8,     1] loss: 1236.978
[9,     1] loss: 1239.145
[10,     1] loss: 1230.852
[11,     1] loss: 1227.915
[12,     1] loss: 1211.509
[13,     1] loss: 1213.410
[14,     1] loss: 1192.470
[15,     1] loss: 1150.846
[16,     1] loss: 1148.463
[17,     1] loss: 1118.523
[18,     1] loss: 1084.947
[19,     1] loss: 1097.142
[20,     1] loss: 1023.575
[21,     1] loss: 1094.222
[22,     1] loss: 1012.779
[23,     1] loss: 1048.454
[24,     1] loss: 1069.907
[25,     1] loss: 1030.297
[26,     1] loss: 998.385
[27,     1] loss: 981.136
[28,     1] loss: 986.641
[29,     1] loss: 1009.732
[30,     1] loss: 969.749
[31,     1] loss: 1038.761
[32,     1] loss: 928.286
[33,     1] loss: 992.728
[34,     1] loss: 985.095
[35,     1] loss: 922.411
Early stopping applied (best metric=0.934255838394165)
Finished Training
Total time taken: 5.818007230758667
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.442
[2,     1] loss: 1245.437
[3,     1] loss: 1246.078
[4,     1] loss: 1241.296
[5,     1] loss: 1241.637
[6,     1] loss: 1236.512
[7,     1] loss: 1230.427
[8,     1] loss: 1219.778
[9,     1] loss: 1199.500
[10,     1] loss: 1167.755
[11,     1] loss: 1146.179
[12,     1] loss: 1148.940
[13,     1] loss: 1061.766
[14,     1] loss: 1069.721
[15,     1] loss: 1080.792
[16,     1] loss: 1083.612
[17,     1] loss: 1004.074
[18,     1] loss: 1013.185
[19,     1] loss: 999.898
[20,     1] loss: 1006.540
[21,     1] loss: 1001.087
[22,     1] loss: 992.728
[23,     1] loss: 1018.252
[24,     1] loss: 1009.946
[25,     1] loss: 962.994
[26,     1] loss: 930.551
[27,     1] loss: 987.845
[28,     1] loss: 956.054
[29,     1] loss: 929.869
[30,     1] loss: 956.791
[31,     1] loss: 930.939
[32,     1] loss: 939.324
[33,     1] loss: 921.686
[34,     1] loss: 888.347
[35,     1] loss: 877.729
[36,     1] loss: 895.390
[37,     1] loss: 878.173
[38,     1] loss: 945.776
[39,     1] loss: 864.745
[40,     1] loss: 878.292
[41,     1] loss: 893.121
[42,     1] loss: 867.118
[43,     1] loss: 851.577
[44,     1] loss: 848.213
[45,     1] loss: 834.311
[46,     1] loss: 811.346
[47,     1] loss: 838.377
[48,     1] loss: 833.032
[49,     1] loss: 846.833
[50,     1] loss: 796.873
[51,     1] loss: 837.985
[52,     1] loss: 787.022
[53,     1] loss: 784.766
[54,     1] loss: 814.079
[55,     1] loss: 791.815
[56,     1] loss: 797.719
[57,     1] loss: 750.935
[58,     1] loss: 774.460
[59,     1] loss: 681.090
[60,     1] loss: 757.206
[61,     1] loss: 754.494
[62,     1] loss: 723.804
[63,     1] loss: 745.661
[64,     1] loss: 744.924
[65,     1] loss: 714.251
[66,     1] loss: 690.217
[67,     1] loss: 629.284
[68,     1] loss: 704.433
[69,     1] loss: 718.539
[70,     1] loss: 664.540
Early stopping applied (best metric=0.8448354601860046)
Finished Training
Total time taken: 11.003012418746948
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.641
[2,     1] loss: 1244.317
[3,     1] loss: 1247.915
[4,     1] loss: 1242.876
[5,     1] loss: 1238.765
[6,     1] loss: 1240.137
[7,     1] loss: 1240.312
[8,     1] loss: 1233.093
[9,     1] loss: 1225.983
[10,     1] loss: 1210.940
[11,     1] loss: 1197.000
[12,     1] loss: 1178.332
[13,     1] loss: 1128.970
[14,     1] loss: 1108.182
[15,     1] loss: 1045.295
[16,     1] loss: 1072.915
[17,     1] loss: 1048.089
[18,     1] loss: 1042.319
[19,     1] loss: 1036.429
[20,     1] loss: 1058.685
[21,     1] loss: 1023.368
[22,     1] loss: 999.943
[23,     1] loss: 1022.295
[24,     1] loss: 1021.366
[25,     1] loss: 980.401
[26,     1] loss: 990.384
[27,     1] loss: 956.866
[28,     1] loss: 947.033
[29,     1] loss: 963.834
[30,     1] loss: 942.593
[31,     1] loss: 1017.808
[32,     1] loss: 967.555
[33,     1] loss: 918.526
[34,     1] loss: 953.207
[35,     1] loss: 918.268
[36,     1] loss: 916.592
[37,     1] loss: 900.850
[38,     1] loss: 923.331
[39,     1] loss: 939.506
[40,     1] loss: 909.808
[41,     1] loss: 885.169
[42,     1] loss: 848.260
[43,     1] loss: 917.101
[44,     1] loss: 850.116
[45,     1] loss: 876.858
[46,     1] loss: 901.019
[47,     1] loss: 848.980
[48,     1] loss: 852.327
[49,     1] loss: 864.532
[50,     1] loss: 876.442
[51,     1] loss: 850.698
[52,     1] loss: 825.710
[53,     1] loss: 858.819
[54,     1] loss: 878.679
[55,     1] loss: 820.055
[56,     1] loss: 810.302
[57,     1] loss: 802.275
[58,     1] loss: 748.581
[59,     1] loss: 870.721
[60,     1] loss: 783.847
[61,     1] loss: 854.776
[62,     1] loss: 791.157
[63,     1] loss: 816.592
[64,     1] loss: 828.249
[65,     1] loss: 827.654
[66,     1] loss: 795.799
[67,     1] loss: 788.610
[68,     1] loss: 792.861
[69,     1] loss: 729.287
[70,     1] loss: 753.321
[71,     1] loss: 787.978
[72,     1] loss: 725.103
[73,     1] loss: 761.267
[74,     1] loss: 715.249
[75,     1] loss: 729.612
[76,     1] loss: 753.330
[77,     1] loss: 704.687
[78,     1] loss: 691.491
[79,     1] loss: 688.734
[80,     1] loss: 695.032
[81,     1] loss: 718.552
[82,     1] loss: 737.897
[83,     1] loss: 723.202
[84,     1] loss: 683.555
[85,     1] loss: 667.834
Early stopping applied (best metric=0.8141692876815796)
Finished Training
Total time taken: 13.706012725830078
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.495
[2,     1] loss: 1240.459
[3,     1] loss: 1242.179
[4,     1] loss: 1238.629
[5,     1] loss: 1225.660
[6,     1] loss: 1193.985
[7,     1] loss: 1135.102
[8,     1] loss: 1092.853
[9,     1] loss: 1059.167
[10,     1] loss: 1177.746
[11,     1] loss: 1087.806
[12,     1] loss: 1024.247
[13,     1] loss: 982.012
[14,     1] loss: 995.073
[15,     1] loss: 1012.965
[16,     1] loss: 1013.044
[17,     1] loss: 964.923
[18,     1] loss: 994.471
[19,     1] loss: 972.483
[20,     1] loss: 943.466
[21,     1] loss: 989.013
[22,     1] loss: 911.269
[23,     1] loss: 884.131
[24,     1] loss: 921.858
[25,     1] loss: 904.157
[26,     1] loss: 925.309
[27,     1] loss: 889.184
[28,     1] loss: 901.128
[29,     1] loss: 910.846
[30,     1] loss: 907.380
[31,     1] loss: 855.507
[32,     1] loss: 873.193
Early stopping applied (best metric=0.9223484992980957)
Finished Training
Total time taken: 5.305005788803101
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1243.444
[2,     1] loss: 1248.321
[3,     1] loss: 1240.836
[4,     1] loss: 1238.034
[5,     1] loss: 1241.612
[6,     1] loss: 1232.810
[7,     1] loss: 1206.977
[8,     1] loss: 1175.911
[9,     1] loss: 1137.232
[10,     1] loss: 1086.406
[11,     1] loss: 1048.161
[12,     1] loss: 1111.911
[13,     1] loss: 1034.962
[14,     1] loss: 1075.820
[15,     1] loss: 1015.620
[16,     1] loss: 1053.893
[17,     1] loss: 1039.013
[18,     1] loss: 1038.576
[19,     1] loss: 1049.587
[20,     1] loss: 1002.582
[21,     1] loss: 1010.527
[22,     1] loss: 1021.041
[23,     1] loss: 1005.128
[24,     1] loss: 1014.798
[25,     1] loss: 969.244
[26,     1] loss: 995.901
[27,     1] loss: 931.728
[28,     1] loss: 999.527
[29,     1] loss: 946.532
[30,     1] loss: 990.745
[31,     1] loss: 947.192
[32,     1] loss: 968.464
[33,     1] loss: 911.889
[34,     1] loss: 917.498
[35,     1] loss: 921.407
[36,     1] loss: 880.728
[37,     1] loss: 934.922
[38,     1] loss: 945.084
[39,     1] loss: 859.906
[40,     1] loss: 954.235
[41,     1] loss: 904.751
[42,     1] loss: 835.254
[43,     1] loss: 862.313
[44,     1] loss: 881.124
[45,     1] loss: 851.880
[46,     1] loss: 897.300
[47,     1] loss: 844.002
[48,     1] loss: 833.937
[49,     1] loss: 839.870
[50,     1] loss: 834.582
[51,     1] loss: 804.873
[52,     1] loss: 858.669
[53,     1] loss: 819.744
[54,     1] loss: 796.457
[55,     1] loss: 779.511
[56,     1] loss: 725.205
[57,     1] loss: 800.934
[58,     1] loss: 776.847
[59,     1] loss: 760.675
[60,     1] loss: 755.209
[61,     1] loss: 757.278
Early stopping applied (best metric=0.7981442213058472)
Finished Training
Total time taken: 10.002009391784668
{'Hydroxylation-K Validation Accuracy': 0.7395685579196217, 'Hydroxylation-K Validation Sensitivity': 0.6044444444444445, 'Hydroxylation-K Validation Specificity': 0.7736842105263158, 'Hydroxylation-K Validation Precision': 0.40856005020091707, 'Hydroxylation-K AUC ROC': 0.7799025341130604, 'Hydroxylation-K AUC PR': 0.5357123330408101, 'Hydroxylation-K MCC': 0.33367156632004663, 'Hydroxylation-K F1': 0.4822457288024504, 'Validation Loss (Hydroxylation-K)': 0.4674717624982198, 'Hydroxylation-P Validation Accuracy': 0.7943397797066138, 'Hydroxylation-P Validation Sensitivity': 0.7917460317460318, 'Hydroxylation-P Validation Specificity': 0.7948950072322809, 'Hydroxylation-P Validation Precision': 0.4686269307412097, 'Hydroxylation-P AUC ROC': 0.8491564991168463, 'Hydroxylation-P AUC PR': 0.5790159318276508, 'Hydroxylation-P MCC': 0.492720917684297, 'Hydroxylation-P F1': 0.5822019255336176, 'Validation Loss (Hydroxylation-P)': 0.3713429609934489, 'Validation Loss (total)': 0.8388147155443827, 'TimeToTrain': 10.532348028818767}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0062173744237723145,
 'learning_rate_Hydroxylation-K': 0.0003188990660513147,
 'learning_rate_Hydroxylation-P': 0.006921700936714086,
 'log_base': 2.5585251065998595,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2546024923,
 'sample_weights': [1.5831999828817231, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.703096973737454,
 'weight_decay_Hydroxylation-K': 8.508149585595339,
 'weight_decay_Hydroxylation-P': 0.7519758087967992}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1284.476
[2,     1] loss: 1282.630
[3,     1] loss: 1282.559
[4,     1] loss: 1290.141
[5,     1] loss: 1271.570
[6,     1] loss: 1260.546
[7,     1] loss: 1215.849
[8,     1] loss: 1161.149
[9,     1] loss: 1129.235
[10,     1] loss: 1141.934
[11,     1] loss: 1129.798
[12,     1] loss: 1021.704
[13,     1] loss: 1062.083
[14,     1] loss: 1052.804
[15,     1] loss: 1102.714
[16,     1] loss: 1051.306
[17,     1] loss: 1029.402
[18,     1] loss: 997.002
[19,     1] loss: 996.692
[20,     1] loss: 997.273
[21,     1] loss: 952.677
[22,     1] loss: 980.342
[23,     1] loss: 955.965
[24,     1] loss: 928.268
[25,     1] loss: 948.812
[26,     1] loss: 949.960
[27,     1] loss: 988.560
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010930869968221676,
 'learning_rate_Hydroxylation-K': 0.0050696822371385465,
 'learning_rate_Hydroxylation-P': 0.005876067661969089,
 'log_base': 1.3644455768294836,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 34282895,
 'sample_weights': [1.7770791197475, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.25845217033046275,
 'weight_decay_Hydroxylation-K': 3.6598553292356653,
 'weight_decay_Hydroxylation-P': 0.48655537734467436}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2039.139
[2,     1] loss: 2045.746
[3,     1] loss: 2047.199
[4,     1] loss: 2037.548
[5,     1] loss: 2033.352
[6,     1] loss: 2028.359
[7,     1] loss: 2039.349
[8,     1] loss: 2034.209
[9,     1] loss: 2040.621
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008945811427351142,
 'learning_rate_Hydroxylation-K': 0.00631136056676402,
 'learning_rate_Hydroxylation-P': 0.0073703448648672325,
 'log_base': 2.262627188804946,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3407248195,
 'sample_weights': [5.372334514202736, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9848372245247208,
 'weight_decay_Hydroxylation-K': 7.474661479594483,
 'weight_decay_Hydroxylation-P': 0.5164227316265261}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1344.748
[2,     1] loss: 1372.575
[3,     1] loss: 1371.087
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004720308523609672,
 'learning_rate_Hydroxylation-K': 0.0005483304657703104,
 'learning_rate_Hydroxylation-P': 0.004781359387463971,
 'log_base': 1.653173025718093,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1787690591,
 'sample_weights': [2.044566735259217, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.536203819901132,
 'weight_decay_Hydroxylation-K': 0.3900057817876703,
 'weight_decay_Hydroxylation-P': 7.721567384166353}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1613.865
[2,     1] loss: 1618.033
[3,     1] loss: 1610.297
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0029713364841530794,
 'learning_rate_Hydroxylation-K': 0.006715373415416723,
 'learning_rate_Hydroxylation-P': 0.0038717902016932883,
 'log_base': 2.461982949647502,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 636742781,
 'sample_weights': [3.3209763549359494, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2580609777869496,
 'weight_decay_Hydroxylation-K': 3.27100041734427,
 'weight_decay_Hydroxylation-P': 1.005472176941448}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1300.117
[2,     1] loss: 1304.281
[3,     1] loss: 1298.346
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004746977735599783,
 'learning_rate_Hydroxylation-K': 0.0031576013107691347,
 'learning_rate_Hydroxylation-P': 0.006771552692456835,
 'log_base': 2.023575979680865,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3770475899,
 'sample_weights': [1.852945732540383, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.897682727187389,
 'weight_decay_Hydroxylation-K': 3.6780135362581214,
 'weight_decay_Hydroxylation-P': 1.418392441535161}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1405.283
[2,     1] loss: 1411.690
[3,     1] loss: 1415.263
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00014301690419646785,
 'learning_rate_Hydroxylation-K': 0.005446724737535212,
 'learning_rate_Hydroxylation-P': 0.006672952796811912,
 'log_base': 1.0600659741978171,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2624344977,
 'sample_weights': [2.368453854956836, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.186516868689871,
 'weight_decay_Hydroxylation-K': 1.779046581175774,
 'weight_decay_Hydroxylation-P': 4.835423297738723}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 9295.551
[2,     1] loss: 9321.179
[3,     1] loss: 9339.174
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004864864898837593,
 'learning_rate_Hydroxylation-K': 0.0077682063595316785,
 'learning_rate_Hydroxylation-P': 0.0034267215351770582,
 'log_base': 2.620500983310104,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 663265922,
 'sample_weights': [28.620098558086173, 3.577650139901291],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9956754108046078,
 'weight_decay_Hydroxylation-K': 3.8098070629332916,
 'weight_decay_Hydroxylation-P': 3.028693751968776}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1276.676
[2,     1] loss: 1280.746
[3,     1] loss: 1275.595
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025035877653270776,
 'learning_rate_Hydroxylation-K': 0.0037396984355834812,
 'learning_rate_Hydroxylation-P': 9.750149786712115e-05,
 'log_base': 2.6999722243584223,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3629726590,
 'sample_weights': [1.7329280758968104, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.27192193785052066,
 'weight_decay_Hydroxylation-K': 9.453386839905729,
 'weight_decay_Hydroxylation-P': 3.244202159392923}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1264.070
[2,     1] loss: 1263.687
[3,     1] loss: 1261.312
[4,     1] loss: 1260.838
[5,     1] loss: 1261.620
[6,     1] loss: 1258.709
[7,     1] loss: 1252.306
[8,     1] loss: 1259.273
[9,     1] loss: 1244.990
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0036599515830852652,
 'learning_rate_Hydroxylation-K': 0.007789161698732285,
 'learning_rate_Hydroxylation-P': 0.0024145793234780838,
 'log_base': 2.669865507846047,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3138924065,
 'sample_weights': [1.6808028777374018, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.45513624683747,
 'weight_decay_Hydroxylation-K': 6.463515304111586,
 'weight_decay_Hydroxylation-P': 1.3513140264239052}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1268.793
[2,     1] loss: 1273.743
[3,     1] loss: 1263.599
[4,     1] loss: 1267.433
[5,     1] loss: 1265.589
[6,     1] loss: 1265.758
[7,     1] loss: 1260.082
[8,     1] loss: 1252.109
[9,     1] loss: 1241.484
[10,     1] loss: 1220.752
[11,     1] loss: 1184.856
[12,     1] loss: 1148.422
[13,     1] loss: 1087.082
[14,     1] loss: 1072.779
[15,     1] loss: 1073.266
[16,     1] loss: 1076.104
[17,     1] loss: 1056.927
[18,     1] loss: 1047.866
[19,     1] loss: 1062.305
[20,     1] loss: 1038.779
[21,     1] loss: 1045.570
[22,     1] loss: 1058.605
[23,     1] loss: 1042.662
[24,     1] loss: 1018.103
[25,     1] loss: 981.060
[26,     1] loss: 988.051
[27,     1] loss: 962.626
[28,     1] loss: 1024.969
[29,     1] loss: 969.518
[30,     1] loss: 928.896
[31,     1] loss: 945.975
[32,     1] loss: 953.738
[33,     1] loss: 944.074
[34,     1] loss: 927.038
[35,     1] loss: 959.737
[36,     1] loss: 943.582
[37,     1] loss: 917.438
[38,     1] loss: 962.995
[39,     1] loss: 916.619
[40,     1] loss: 895.875
[41,     1] loss: 923.143
[42,     1] loss: 822.893
[43,     1] loss: 858.341
[44,     1] loss: 843.948
[45,     1] loss: 841.973
[46,     1] loss: 857.830
[47,     1] loss: 823.094
[48,     1] loss: 825.068
[49,     1] loss: 824.218
[50,     1] loss: 760.493
[51,     1] loss: 790.004
[52,     1] loss: 766.500
[53,     1] loss: 785.485
[54,     1] loss: 713.263
Early stopping applied (best metric=0.8083411455154419)
Finished Training
Total time taken: 7.8640100955963135
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1268.574
[2,     1] loss: 1273.413
[3,     1] loss: 1269.123
[4,     1] loss: 1263.719
[5,     1] loss: 1257.807
[6,     1] loss: 1266.632
[7,     1] loss: 1255.452
[8,     1] loss: 1244.238
[9,     1] loss: 1208.128
[10,     1] loss: 1184.603
[11,     1] loss: 1146.981
[12,     1] loss: 1117.369
[13,     1] loss: 1108.902
[14,     1] loss: 1066.805
[15,     1] loss: 1027.809
[16,     1] loss: 1062.799
[17,     1] loss: 1081.701
[18,     1] loss: 1045.888
[19,     1] loss: 1065.735
[20,     1] loss: 1039.842
[21,     1] loss: 1044.635
[22,     1] loss: 1049.995
[23,     1] loss: 999.615
[24,     1] loss: 1032.244
[25,     1] loss: 990.219
[26,     1] loss: 980.183
[27,     1] loss: 979.137
[28,     1] loss: 950.616
[29,     1] loss: 956.579
[30,     1] loss: 914.896
[31,     1] loss: 929.066
[32,     1] loss: 888.549
[33,     1] loss: 952.609
[34,     1] loss: 924.047
[35,     1] loss: 910.215
[36,     1] loss: 914.210
[37,     1] loss: 906.705
[38,     1] loss: 876.565
[39,     1] loss: 816.183
[40,     1] loss: 832.030
[41,     1] loss: 821.250
[42,     1] loss: 850.410
[43,     1] loss: 879.148
[44,     1] loss: 837.868
[45,     1] loss: 856.974
[46,     1] loss: 813.311
[47,     1] loss: 859.109
[48,     1] loss: 800.224
[49,     1] loss: 831.974
[50,     1] loss: 785.771
[51,     1] loss: 783.033
[52,     1] loss: 864.121
[53,     1] loss: 710.061
[54,     1] loss: 765.472
[55,     1] loss: 789.895
[56,     1] loss: 751.481
[57,     1] loss: 734.155
[58,     1] loss: 781.638
[59,     1] loss: 726.612
[60,     1] loss: 744.450
[61,     1] loss: 718.222
[62,     1] loss: 705.898
[63,     1] loss: 723.258
[64,     1] loss: 680.771
[65,     1] loss: 669.047
[66,     1] loss: 671.585
Early stopping applied (best metric=0.769753098487854)
Finished Training
Total time taken: 9.911011695861816
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1265.288
[2,     1] loss: 1267.976
[3,     1] loss: 1271.002
[4,     1] loss: 1261.556
[5,     1] loss: 1249.501
[6,     1] loss: 1218.644
[7,     1] loss: 1171.531
[8,     1] loss: 1113.052
[9,     1] loss: 1096.124
[10,     1] loss: 1122.447
[11,     1] loss: 1040.578
[12,     1] loss: 1042.423
[13,     1] loss: 1023.547
[14,     1] loss: 1024.235
[15,     1] loss: 1023.746
[16,     1] loss: 981.685
[17,     1] loss: 948.822
[18,     1] loss: 943.677
[19,     1] loss: 939.438
[20,     1] loss: 948.533
[21,     1] loss: 933.519
[22,     1] loss: 914.252
[23,     1] loss: 882.955
[24,     1] loss: 892.048
[25,     1] loss: 941.845
[26,     1] loss: 865.710
[27,     1] loss: 880.969
[28,     1] loss: 864.888
[29,     1] loss: 860.751
[30,     1] loss: 835.897
[31,     1] loss: 889.833
[32,     1] loss: 883.600
[33,     1] loss: 851.955
[34,     1] loss: 835.064
[35,     1] loss: 815.213
[36,     1] loss: 768.611
[37,     1] loss: 829.450
[38,     1] loss: 804.063
[39,     1] loss: 791.684
[40,     1] loss: 797.580
[41,     1] loss: 739.331
[42,     1] loss: 757.873
[43,     1] loss: 759.273
[44,     1] loss: 698.168
[45,     1] loss: 772.009
[46,     1] loss: 733.339
[47,     1] loss: 710.248
[48,     1] loss: 679.353
[49,     1] loss: 698.817
[50,     1] loss: 647.094
[51,     1] loss: 618.723
[52,     1] loss: 644.516
[53,     1] loss: 597.247
Early stopping applied (best metric=0.997742772102356)
Finished Training
Total time taken: 7.7160069942474365
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1266.645
[2,     1] loss: 1277.742
[3,     1] loss: 1269.792
[4,     1] loss: 1266.802
[5,     1] loss: 1262.314
[6,     1] loss: 1261.114
[7,     1] loss: 1259.880
[8,     1] loss: 1255.408
[9,     1] loss: 1242.290
[10,     1] loss: 1214.704
[11,     1] loss: 1180.904
[12,     1] loss: 1159.727
[13,     1] loss: 1127.427
[14,     1] loss: 1102.674
[15,     1] loss: 1113.918
[16,     1] loss: 1109.309
[17,     1] loss: 1041.435
[18,     1] loss: 1116.636
[19,     1] loss: 1037.549
[20,     1] loss: 987.943
[21,     1] loss: 1049.657
[22,     1] loss: 1050.871
[23,     1] loss: 1048.822
[24,     1] loss: 1013.363
[25,     1] loss: 985.891
[26,     1] loss: 1013.658
[27,     1] loss: 996.635
[28,     1] loss: 963.042
[29,     1] loss: 978.318
[30,     1] loss: 924.625
[31,     1] loss: 960.733
[32,     1] loss: 953.316
[33,     1] loss: 912.649
[34,     1] loss: 924.583
[35,     1] loss: 896.849
[36,     1] loss: 935.974
[37,     1] loss: 897.502
[38,     1] loss: 870.190
[39,     1] loss: 821.200
[40,     1] loss: 888.396
[41,     1] loss: 822.692
[42,     1] loss: 872.217
[43,     1] loss: 874.841
[44,     1] loss: 853.287
[45,     1] loss: 835.625
[46,     1] loss: 858.638
[47,     1] loss: 810.887
[48,     1] loss: 812.683
[49,     1] loss: 728.970
[50,     1] loss: 744.236
[51,     1] loss: 739.365
[52,     1] loss: 744.301
[53,     1] loss: 716.657
[54,     1] loss: 766.479
[55,     1] loss: 701.817
[56,     1] loss: 654.210
[57,     1] loss: 717.839
[58,     1] loss: 702.032
[59,     1] loss: 654.753
[60,     1] loss: 722.060
[61,     1] loss: 743.622
[62,     1] loss: 628.383
[63,     1] loss: 760.790
[64,     1] loss: 619.352
[65,     1] loss: 640.787
Early stopping applied (best metric=0.8096214532852173)
Finished Training
Total time taken: 10.43200969696045
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1271.255
[2,     1] loss: 1281.150
[3,     1] loss: 1271.780
[4,     1] loss: 1274.721
[5,     1] loss: 1267.091
[6,     1] loss: 1267.649
[7,     1] loss: 1267.854
[8,     1] loss: 1264.960
[9,     1] loss: 1265.884
[10,     1] loss: 1265.719
[11,     1] loss: 1262.070
[12,     1] loss: 1254.501
[13,     1] loss: 1240.573
[14,     1] loss: 1232.072
[15,     1] loss: 1207.006
[16,     1] loss: 1186.556
[17,     1] loss: 1153.632
[18,     1] loss: 1151.474
[19,     1] loss: 1102.269
[20,     1] loss: 1105.082
[21,     1] loss: 1043.757
[22,     1] loss: 1056.666
[23,     1] loss: 1080.442
[24,     1] loss: 1005.537
[25,     1] loss: 1028.531
[26,     1] loss: 1019.499
[27,     1] loss: 997.761
[28,     1] loss: 991.635
[29,     1] loss: 944.556
[30,     1] loss: 997.680
[31,     1] loss: 947.581
[32,     1] loss: 958.362
[33,     1] loss: 938.222
[34,     1] loss: 918.195
[35,     1] loss: 941.453
[36,     1] loss: 983.623
[37,     1] loss: 945.108
[38,     1] loss: 925.483
[39,     1] loss: 892.324
[40,     1] loss: 850.544
[41,     1] loss: 864.717
[42,     1] loss: 851.636
[43,     1] loss: 924.900
[44,     1] loss: 818.094
[45,     1] loss: 829.593
[46,     1] loss: 812.052
[47,     1] loss: 851.263
[48,     1] loss: 767.707
Early stopping applied (best metric=0.9018420577049255)
Finished Training
Total time taken: 7.159006118774414
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1267.907
[2,     1] loss: 1277.212
[3,     1] loss: 1267.544
[4,     1] loss: 1269.838
[5,     1] loss: 1267.269
[6,     1] loss: 1265.758
[7,     1] loss: 1256.175
[8,     1] loss: 1250.505
[9,     1] loss: 1227.281
[10,     1] loss: 1186.887
[11,     1] loss: 1141.148
[12,     1] loss: 1109.718
[13,     1] loss: 1007.076
[14,     1] loss: 1070.166
[15,     1] loss: 1085.061
[16,     1] loss: 1021.949
[17,     1] loss: 1043.649
[18,     1] loss: 1004.473
[19,     1] loss: 988.415
[20,     1] loss: 1011.082
[21,     1] loss: 1011.605
[22,     1] loss: 989.363
[23,     1] loss: 960.698
[24,     1] loss: 991.451
[25,     1] loss: 971.281
[26,     1] loss: 934.066
[27,     1] loss: 924.088
[28,     1] loss: 915.877
[29,     1] loss: 912.923
[30,     1] loss: 884.861
[31,     1] loss: 907.600
[32,     1] loss: 884.157
[33,     1] loss: 878.692
[34,     1] loss: 858.838
[35,     1] loss: 859.287
[36,     1] loss: 854.999
[37,     1] loss: 861.993
[38,     1] loss: 811.082
[39,     1] loss: 823.335
[40,     1] loss: 823.718
[41,     1] loss: 818.610
[42,     1] loss: 803.205
[43,     1] loss: 774.750
[44,     1] loss: 815.638
[45,     1] loss: 710.481
[46,     1] loss: 732.663
[47,     1] loss: 760.587
[48,     1] loss: 780.949
[49,     1] loss: 725.327
[50,     1] loss: 677.730
[51,     1] loss: 722.293
[52,     1] loss: 733.970
[53,     1] loss: 737.226
Early stopping applied (best metric=1.045052170753479)
Finished Training
Total time taken: 8.795008182525635
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1270.770
[2,     1] loss: 1270.805
[3,     1] loss: 1267.471
[4,     1] loss: 1263.251
[5,     1] loss: 1263.417
[6,     1] loss: 1255.075
[7,     1] loss: 1240.136
[8,     1] loss: 1211.736
[9,     1] loss: 1183.609
[10,     1] loss: 1157.291
[11,     1] loss: 1148.144
[12,     1] loss: 1093.767
[13,     1] loss: 1073.519
[14,     1] loss: 1086.450
[15,     1] loss: 1086.669
[16,     1] loss: 1076.935
[17,     1] loss: 1046.149
[18,     1] loss: 1099.613
[19,     1] loss: 1043.773
[20,     1] loss: 1005.471
[21,     1] loss: 1018.830
[22,     1] loss: 993.760
[23,     1] loss: 1018.398
[24,     1] loss: 1032.395
[25,     1] loss: 1010.242
[26,     1] loss: 976.254
[27,     1] loss: 962.426
[28,     1] loss: 971.899
[29,     1] loss: 930.240
[30,     1] loss: 919.845
[31,     1] loss: 911.546
[32,     1] loss: 893.271
[33,     1] loss: 914.908
[34,     1] loss: 897.678
[35,     1] loss: 908.852
[36,     1] loss: 845.276
[37,     1] loss: 843.435
[38,     1] loss: 871.459
[39,     1] loss: 845.739
[40,     1] loss: 882.710
[41,     1] loss: 904.662
[42,     1] loss: 837.407
[43,     1] loss: 886.268
[44,     1] loss: 829.477
[45,     1] loss: 880.389
[46,     1] loss: 790.879
[47,     1] loss: 876.162
[48,     1] loss: 808.116
[49,     1] loss: 799.723
[50,     1] loss: 738.431
[51,     1] loss: 810.584
[52,     1] loss: 734.167
[53,     1] loss: 752.552
[54,     1] loss: 718.056
[55,     1] loss: 693.634
[56,     1] loss: 708.390
[57,     1] loss: 710.076
[58,     1] loss: 635.843
[59,     1] loss: 674.988
[60,     1] loss: 728.046
[61,     1] loss: 700.526
[62,     1] loss: 634.889
[63,     1] loss: 665.370
[64,     1] loss: 666.656
[65,     1] loss: 770.202
[66,     1] loss: 695.462
[67,     1] loss: 605.440
[68,     1] loss: 590.312
[69,     1] loss: 604.861
[70,     1] loss: 557.353
[71,     1] loss: 543.147
[72,     1] loss: 513.408
[73,     1] loss: 582.833
[74,     1] loss: 549.535
[75,     1] loss: 545.739
[76,     1] loss: 569.509
[77,     1] loss: 537.138
[78,     1] loss: 526.649
Early stopping applied (best metric=0.7508683800697327)
Finished Training
Total time taken: 12.034011602401733
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1273.246
[2,     1] loss: 1266.348
[3,     1] loss: 1268.242
[4,     1] loss: 1259.260
[5,     1] loss: 1269.010
[6,     1] loss: 1256.672
[7,     1] loss: 1249.808
[8,     1] loss: 1227.004
[9,     1] loss: 1190.804
[10,     1] loss: 1170.849
[11,     1] loss: 1131.797
[12,     1] loss: 1080.288
[13,     1] loss: 1075.003
[14,     1] loss: 1017.704
[15,     1] loss: 1050.127
[16,     1] loss: 1050.664
[17,     1] loss: 1019.391
[18,     1] loss: 1035.142
[19,     1] loss: 1055.280
[20,     1] loss: 1055.606
[21,     1] loss: 993.833
[22,     1] loss: 1031.636
[23,     1] loss: 1000.973
[24,     1] loss: 989.377
[25,     1] loss: 973.587
[26,     1] loss: 941.435
[27,     1] loss: 1021.726
[28,     1] loss: 938.014
[29,     1] loss: 969.553
[30,     1] loss: 951.943
[31,     1] loss: 960.422
[32,     1] loss: 913.733
[33,     1] loss: 924.842
[34,     1] loss: 894.823
[35,     1] loss: 907.177
[36,     1] loss: 889.130
[37,     1] loss: 875.143
[38,     1] loss: 900.109
[39,     1] loss: 907.357
[40,     1] loss: 844.673
[41,     1] loss: 890.551
[42,     1] loss: 853.169
[43,     1] loss: 777.017
[44,     1] loss: 808.459
[45,     1] loss: 791.698
[46,     1] loss: 844.438
[47,     1] loss: 821.134
[48,     1] loss: 830.650
[49,     1] loss: 757.117
[50,     1] loss: 895.330
[51,     1] loss: 752.795
Early stopping applied (best metric=0.9135898351669312)
Finished Training
Total time taken: 7.140007495880127
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1275.345
[2,     1] loss: 1273.056
[3,     1] loss: 1267.449
[4,     1] loss: 1268.575
[5,     1] loss: 1259.651
[6,     1] loss: 1260.730
[7,     1] loss: 1262.111
[8,     1] loss: 1259.668
[9,     1] loss: 1243.271
[10,     1] loss: 1232.203
[11,     1] loss: 1209.134
[12,     1] loss: 1167.570
[13,     1] loss: 1150.249
[14,     1] loss: 1120.940
[15,     1] loss: 1076.202
[16,     1] loss: 1083.701
[17,     1] loss: 1031.062
[18,     1] loss: 1034.132
[19,     1] loss: 1019.589
[20,     1] loss: 1026.659
[21,     1] loss: 994.155
[22,     1] loss: 958.267
[23,     1] loss: 1012.652
[24,     1] loss: 968.774
[25,     1] loss: 1005.447
[26,     1] loss: 1004.978
[27,     1] loss: 959.190
[28,     1] loss: 935.254
[29,     1] loss: 950.302
[30,     1] loss: 917.524
[31,     1] loss: 914.982
[32,     1] loss: 963.035
[33,     1] loss: 921.393
[34,     1] loss: 894.174
[35,     1] loss: 891.246
[36,     1] loss: 839.274
[37,     1] loss: 839.688
[38,     1] loss: 864.226
[39,     1] loss: 801.885
[40,     1] loss: 818.991
[41,     1] loss: 789.310
[42,     1] loss: 824.317
[43,     1] loss: 868.378
[44,     1] loss: 800.871
[45,     1] loss: 802.671
[46,     1] loss: 789.417
[47,     1] loss: 816.678
[48,     1] loss: 774.825
[49,     1] loss: 780.226
[50,     1] loss: 762.310
[51,     1] loss: 828.077
[52,     1] loss: 684.136
[53,     1] loss: 785.168
[54,     1] loss: 681.514
[55,     1] loss: 686.611
[56,     1] loss: 673.570
Early stopping applied (best metric=0.9246038794517517)
Finished Training
Total time taken: 9.405008554458618
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1272.189
[2,     1] loss: 1265.583
[3,     1] loss: 1264.763
[4,     1] loss: 1262.298
[5,     1] loss: 1247.257
[6,     1] loss: 1213.867
[7,     1] loss: 1154.048
[8,     1] loss: 1092.813
[9,     1] loss: 1092.209
[10,     1] loss: 1097.965
[11,     1] loss: 1052.219
[12,     1] loss: 1063.518
[13,     1] loss: 1060.701
[14,     1] loss: 1083.919
[15,     1] loss: 1020.360
[16,     1] loss: 1042.814
[17,     1] loss: 1033.637
[18,     1] loss: 1016.164
[19,     1] loss: 1042.004
[20,     1] loss: 1017.672
[21,     1] loss: 985.715
[22,     1] loss: 992.918
[23,     1] loss: 991.150
[24,     1] loss: 985.202
[25,     1] loss: 967.570
[26,     1] loss: 953.017
[27,     1] loss: 945.840
[28,     1] loss: 929.073
[29,     1] loss: 916.301
[30,     1] loss: 963.943
[31,     1] loss: 933.753
[32,     1] loss: 895.126
[33,     1] loss: 932.507
[34,     1] loss: 886.883
[35,     1] loss: 900.172
[36,     1] loss: 847.639
[37,     1] loss: 828.711
[38,     1] loss: 867.274
[39,     1] loss: 870.841
[40,     1] loss: 853.359
[41,     1] loss: 838.436
[42,     1] loss: 823.640
[43,     1] loss: 779.696
[44,     1] loss: 802.614
[45,     1] loss: 739.567
[46,     1] loss: 785.024
[47,     1] loss: 832.830
[48,     1] loss: 791.047
[49,     1] loss: 751.293
[50,     1] loss: 769.468
[51,     1] loss: 801.390
[52,     1] loss: 733.715
[53,     1] loss: 740.596
[54,     1] loss: 712.974
[55,     1] loss: 724.941
[56,     1] loss: 732.283
[57,     1] loss: 686.010
[58,     1] loss: 648.424
[59,     1] loss: 611.080
[60,     1] loss: 597.534
[61,     1] loss: 653.304
[62,     1] loss: 680.531
[63,     1] loss: 725.149
[64,     1] loss: 684.010
[65,     1] loss: 599.579
[66,     1] loss: 655.041
[67,     1] loss: 568.110
[68,     1] loss: 654.346
[69,     1] loss: 583.342
[70,     1] loss: 625.330
[71,     1] loss: 612.978
[72,     1] loss: 540.090
[73,     1] loss: 565.302
[74,     1] loss: 548.470
[75,     1] loss: 618.031
[76,     1] loss: 552.932
[77,     1] loss: 533.480
[78,     1] loss: 569.370
[79,     1] loss: 590.331
[80,     1] loss: 505.122
[81,     1] loss: 488.904
[82,     1] loss: 544.886
[83,     1] loss: 516.823
[84,     1] loss: 517.860
Early stopping applied (best metric=0.6673370003700256)
Finished Training
Total time taken: 14.213015079498291
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1267.496
[2,     1] loss: 1270.681
[3,     1] loss: 1265.267
[4,     1] loss: 1266.827
[5,     1] loss: 1268.155
[6,     1] loss: 1263.092
[7,     1] loss: 1269.660
[8,     1] loss: 1260.802
[9,     1] loss: 1254.449
[10,     1] loss: 1247.825
[11,     1] loss: 1234.428
[12,     1] loss: 1205.524
[13,     1] loss: 1173.657
[14,     1] loss: 1126.287
[15,     1] loss: 1084.866
[16,     1] loss: 1079.580
[17,     1] loss: 1064.366
[18,     1] loss: 1033.710
[19,     1] loss: 1057.848
[20,     1] loss: 1061.412
[21,     1] loss: 1103.052
[22,     1] loss: 1023.697
[23,     1] loss: 1053.225
[24,     1] loss: 1021.684
[25,     1] loss: 993.271
[26,     1] loss: 1004.987
[27,     1] loss: 1013.320
[28,     1] loss: 1027.157
[29,     1] loss: 941.473
[30,     1] loss: 966.551
[31,     1] loss: 929.887
[32,     1] loss: 941.875
[33,     1] loss: 933.450
[34,     1] loss: 958.345
[35,     1] loss: 964.356
[36,     1] loss: 927.888
[37,     1] loss: 913.162
[38,     1] loss: 929.838
[39,     1] loss: 904.441
[40,     1] loss: 913.888
[41,     1] loss: 877.746
[42,     1] loss: 924.052
[43,     1] loss: 896.167
[44,     1] loss: 873.434
[45,     1] loss: 833.300
[46,     1] loss: 860.567
[47,     1] loss: 831.679
[48,     1] loss: 873.089
[49,     1] loss: 817.915
[50,     1] loss: 852.741
[51,     1] loss: 803.766
[52,     1] loss: 789.089
[53,     1] loss: 796.302
[54,     1] loss: 779.781
[55,     1] loss: 766.496
[56,     1] loss: 827.447
[57,     1] loss: 756.046
[58,     1] loss: 755.962
[59,     1] loss: 737.931
[60,     1] loss: 733.609
[61,     1] loss: 810.651
[62,     1] loss: 871.917
[63,     1] loss: 734.645
[64,     1] loss: 729.756
[65,     1] loss: 734.245
[66,     1] loss: 725.676
[67,     1] loss: 665.426
[68,     1] loss: 730.483
[69,     1] loss: 683.331
[70,     1] loss: 692.876
[71,     1] loss: 669.607
[72,     1] loss: 650.090
[73,     1] loss: 734.027
[74,     1] loss: 591.112
[75,     1] loss: 698.396
[76,     1] loss: 596.833
[77,     1] loss: 558.833
[78,     1] loss: 578.030
[79,     1] loss: 603.219
Early stopping applied (best metric=0.7574548721313477)
Finished Training
Total time taken: 11.030011892318726
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1268.127
[2,     1] loss: 1271.964
[3,     1] loss: 1270.335
[4,     1] loss: 1265.316
[5,     1] loss: 1269.821
[6,     1] loss: 1265.877
[7,     1] loss: 1263.854
[8,     1] loss: 1260.643
[9,     1] loss: 1253.301
[10,     1] loss: 1249.589
[11,     1] loss: 1222.777
[12,     1] loss: 1184.734
[13,     1] loss: 1167.285
[14,     1] loss: 1144.142
[15,     1] loss: 1124.181
[16,     1] loss: 1117.957
[17,     1] loss: 1092.866
[18,     1] loss: 1120.296
[19,     1] loss: 999.612
[20,     1] loss: 1107.053
[21,     1] loss: 1029.449
[22,     1] loss: 1071.735
[23,     1] loss: 1058.185
[24,     1] loss: 1028.218
[25,     1] loss: 1045.632
[26,     1] loss: 1016.627
[27,     1] loss: 1035.790
[28,     1] loss: 978.234
[29,     1] loss: 1006.610
[30,     1] loss: 990.849
[31,     1] loss: 989.162
[32,     1] loss: 990.776
[33,     1] loss: 940.141
[34,     1] loss: 925.222
[35,     1] loss: 945.618
[36,     1] loss: 935.333
[37,     1] loss: 904.403
[38,     1] loss: 895.663
[39,     1] loss: 899.246
[40,     1] loss: 900.921
[41,     1] loss: 820.458
[42,     1] loss: 872.449
[43,     1] loss: 831.578
[44,     1] loss: 862.193
[45,     1] loss: 843.293
[46,     1] loss: 822.156
[47,     1] loss: 847.351
[48,     1] loss: 841.549
[49,     1] loss: 817.096
[50,     1] loss: 817.390
[51,     1] loss: 782.611
[52,     1] loss: 766.960
[53,     1] loss: 777.765
[54,     1] loss: 763.893
Early stopping applied (best metric=0.878274142742157)
Finished Training
Total time taken: 8.219007730484009
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1269.284
[2,     1] loss: 1276.358
[3,     1] loss: 1266.614
[4,     1] loss: 1276.236
[5,     1] loss: 1268.349
[6,     1] loss: 1265.659
[7,     1] loss: 1263.410
[8,     1] loss: 1260.309
[9,     1] loss: 1254.659
[10,     1] loss: 1242.645
[11,     1] loss: 1220.287
[12,     1] loss: 1209.531
[13,     1] loss: 1162.833
[14,     1] loss: 1151.831
[15,     1] loss: 1092.847
[16,     1] loss: 1120.736
[17,     1] loss: 1043.315
[18,     1] loss: 1040.786
[19,     1] loss: 1026.280
[20,     1] loss: 1035.883
[21,     1] loss: 1017.505
[22,     1] loss: 1026.685
[23,     1] loss: 1008.634
[24,     1] loss: 988.877
[25,     1] loss: 986.632
[26,     1] loss: 983.216
[27,     1] loss: 1004.785
[28,     1] loss: 956.391
[29,     1] loss: 907.706
[30,     1] loss: 925.825
[31,     1] loss: 905.069
[32,     1] loss: 933.485
[33,     1] loss: 938.918
[34,     1] loss: 919.709
[35,     1] loss: 885.131
[36,     1] loss: 841.512
[37,     1] loss: 893.460
[38,     1] loss: 910.095
[39,     1] loss: 913.191
[40,     1] loss: 859.761
[41,     1] loss: 856.301
[42,     1] loss: 830.422
[43,     1] loss: 874.546
[44,     1] loss: 876.203
[45,     1] loss: 835.096
Early stopping applied (best metric=0.8453540802001953)
Finished Training
Total time taken: 6.676006555557251
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1271.135
[2,     1] loss: 1262.644
[3,     1] loss: 1271.742
[4,     1] loss: 1264.227
[5,     1] loss: 1252.809
[6,     1] loss: 1228.544
[7,     1] loss: 1212.000
[8,     1] loss: 1194.805
[9,     1] loss: 1136.390
[10,     1] loss: 1229.608
[11,     1] loss: 1120.042
[12,     1] loss: 1163.192
[13,     1] loss: 1109.258
[14,     1] loss: 1079.694
[15,     1] loss: 1085.957
[16,     1] loss: 1048.645
[17,     1] loss: 1074.906
[18,     1] loss: 1104.310
[19,     1] loss: 1016.201
[20,     1] loss: 1034.388
[21,     1] loss: 1020.290
[22,     1] loss: 1025.168
[23,     1] loss: 986.798
[24,     1] loss: 1025.347
[25,     1] loss: 1011.536
[26,     1] loss: 971.434
[27,     1] loss: 1019.403
[28,     1] loss: 987.591
[29,     1] loss: 977.374
[30,     1] loss: 974.916
[31,     1] loss: 953.749
[32,     1] loss: 933.299
[33,     1] loss: 937.447
[34,     1] loss: 916.284
[35,     1] loss: 926.382
[36,     1] loss: 915.318
[37,     1] loss: 896.243
[38,     1] loss: 836.652
[39,     1] loss: 862.761
[40,     1] loss: 883.469
[41,     1] loss: 873.100
[42,     1] loss: 870.471
[43,     1] loss: 886.763
[44,     1] loss: 880.611
[45,     1] loss: 793.180
[46,     1] loss: 863.720
[47,     1] loss: 801.105
[48,     1] loss: 855.483
[49,     1] loss: 870.853
[50,     1] loss: 794.773
[51,     1] loss: 840.307
[52,     1] loss: 766.737
[53,     1] loss: 805.410
[54,     1] loss: 742.972
[55,     1] loss: 810.709
[56,     1] loss: 710.049
[57,     1] loss: 768.023
[58,     1] loss: 686.352
[59,     1] loss: 709.762
[60,     1] loss: 680.880
[61,     1] loss: 668.547
[62,     1] loss: 663.404
[63,     1] loss: 687.848
[64,     1] loss: 692.156
[65,     1] loss: 607.909
[66,     1] loss: 664.600
[67,     1] loss: 599.275
[68,     1] loss: 625.181
[69,     1] loss: 594.789
Early stopping applied (best metric=0.744683563709259)
Finished Training
Total time taken: 11.517011404037476
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1269.031
[2,     1] loss: 1273.592
[3,     1] loss: 1264.247
[4,     1] loss: 1278.044
[5,     1] loss: 1267.340
[6,     1] loss: 1269.107
[7,     1] loss: 1264.299
[8,     1] loss: 1260.624
[9,     1] loss: 1256.559
[10,     1] loss: 1243.499
[11,     1] loss: 1212.278
[12,     1] loss: 1189.407
[13,     1] loss: 1145.943
[14,     1] loss: 1131.334
[15,     1] loss: 1059.658
[16,     1] loss: 1096.076
[17,     1] loss: 1064.220
[18,     1] loss: 1074.157
[19,     1] loss: 1052.668
[20,     1] loss: 1059.710
[21,     1] loss: 1047.957
[22,     1] loss: 1035.263
[23,     1] loss: 1017.457
[24,     1] loss: 990.016
[25,     1] loss: 978.995
[26,     1] loss: 1029.196
[27,     1] loss: 1006.822
[28,     1] loss: 956.854
[29,     1] loss: 975.245
[30,     1] loss: 956.047
[31,     1] loss: 920.088
[32,     1] loss: 930.718
[33,     1] loss: 927.125
[34,     1] loss: 923.454
[35,     1] loss: 897.430
[36,     1] loss: 910.436
[37,     1] loss: 897.018
[38,     1] loss: 866.026
[39,     1] loss: 878.021
[40,     1] loss: 854.932
[41,     1] loss: 847.485
[42,     1] loss: 851.625
[43,     1] loss: 840.381
[44,     1] loss: 829.603
[45,     1] loss: 781.351
[46,     1] loss: 879.462
[47,     1] loss: 885.711
[48,     1] loss: 790.841
[49,     1] loss: 770.546
[50,     1] loss: 778.526
[51,     1] loss: 772.850
[52,     1] loss: 740.030
Early stopping applied (best metric=0.7202359437942505)
Finished Training
Total time taken: 8.722009181976318
{'Hydroxylation-K Validation Accuracy': 0.7745567375886525, 'Hydroxylation-K Validation Sensitivity': 0.64, 'Hydroxylation-K Validation Specificity': 0.8087719298245614, 'Hydroxylation-K Validation Precision': 0.4675994702465291, 'Hydroxylation-K AUC ROC': 0.8051267056530215, 'Hydroxylation-K AUC PR': 0.6056545780188358, 'Hydroxylation-K MCC': 0.4050817371046336, 'Hydroxylation-K F1': 0.5340538595794126, 'Validation Loss (Hydroxylation-K)': 0.4434636851151784, 'Hydroxylation-P Validation Accuracy': 0.7725506488672318, 'Hydroxylation-P Validation Sensitivity': 0.7331216931216932, 'Hydroxylation-P Validation Specificity': 0.7810589056810814, 'Hydroxylation-P Validation Precision': 0.4268354433285663, 'Hydroxylation-P AUC ROC': 0.8323024957900762, 'Hydroxylation-P AUC PR': 0.5817196689244521, 'Hydroxylation-P MCC': 0.4287855411464094, 'Hydroxylation-P F1': 0.5364890133919283, 'Validation Loss (Hydroxylation-P)': 0.39218661387761433, 'Validation Loss (total)': 0.8356502930323283, 'TimeToTrain': 9.388876152038574}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003966915320437598,
 'learning_rate_Hydroxylation-K': 0.007653701894191038,
 'learning_rate_Hydroxylation-P': 0.0012576873916417112,
 'log_base': 2.001930376475072,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3682379802,
 'sample_weights': [1.7012563473896518, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.348772070940367,
 'weight_decay_Hydroxylation-K': 6.226464717696515,
 'weight_decay_Hydroxylation-P': 1.28167605583005}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1420.047
[2,     1] loss: 1419.445
[3,     1] loss: 1415.155
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006588853058028918,
 'learning_rate_Hydroxylation-K': 0.0035342403249925824,
 'learning_rate_Hydroxylation-P': 0.0006829532271834006,
 'log_base': 2.4880454952487687,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2994702726,
 'sample_weights': [2.405149860533874, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9381661940132187,
 'weight_decay_Hydroxylation-K': 1.4664481619018606,
 'weight_decay_Hydroxylation-P': 5.084658912651511}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1292.487
[2,     1] loss: 1298.331
[3,     1] loss: 1293.821
[4,     1] loss: 1295.994
[5,     1] loss: 1291.988
[6,     1] loss: 1289.209
[7,     1] loss: 1295.137
[8,     1] loss: 1292.205
[9,     1] loss: 1289.975
[10,     1] loss: 1291.840
[11,     1] loss: 1289.920
[12,     1] loss: 1285.855
[13,     1] loss: 1280.258
[14,     1] loss: 1276.550
[15,     1] loss: 1270.986
[16,     1] loss: 1266.667
[17,     1] loss: 1257.594
[18,     1] loss: 1240.040
[19,     1] loss: 1228.092
[20,     1] loss: 1219.123
[21,     1] loss: 1185.575
[22,     1] loss: 1179.864
[23,     1] loss: 1161.601
[24,     1] loss: 1133.904
[25,     1] loss: 1118.409
[26,     1] loss: 1130.369
[27,     1] loss: 1107.614
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006665932522726116,
 'learning_rate_Hydroxylation-K': 0.009587610024306378,
 'learning_rate_Hydroxylation-P': 0.006824182966696094,
 'log_base': 1.6610540513877927,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3099302706,
 'sample_weights': [1.8315389999646758, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.2168963303926,
 'weight_decay_Hydroxylation-K': 9.91767161103474,
 'weight_decay_Hydroxylation-P': 0.6174670374529134}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1612.806
[2,     1] loss: 1633.199
[3,     1] loss: 1605.481
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0036162373912543466,
 'learning_rate_Hydroxylation-K': 0.008059557856323774,
 'learning_rate_Hydroxylation-P': 0.001680848170026813,
 'log_base': 1.891099216340226,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1594802031,
 'sample_weights': [3.2898518973138304, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.569138049962575,
 'weight_decay_Hydroxylation-K': 5.5039637408164985,
 'weight_decay_Hydroxylation-P': 1.2072955972727983}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1467.198
[2,     1] loss: 1479.602
[3,     1] loss: 1465.651
[4,     1] loss: 1462.881
[5,     1] loss: 1458.615
[6,     1] loss: 1467.038
[7,     1] loss: 1459.638
[8,     1] loss: 1455.986
[9,     1] loss: 1456.591
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005592598476461331,
 'learning_rate_Hydroxylation-K': 0.009533511390210409,
 'learning_rate_Hydroxylation-P': 0.0008319468367350977,
 'log_base': 2.941812271771715,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2384405185,
 'sample_weights': [2.6201389243794564, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8719290072876351,
 'weight_decay_Hydroxylation-K': 8.732657711805201,
 'weight_decay_Hydroxylation-P': 3.4998600237919253}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1238.429
[2,     1] loss: 1234.746
[3,     1] loss: 1255.333
[4,     1] loss: 1231.588
[5,     1] loss: 1237.825
[6,     1] loss: 1234.897
[7,     1] loss: 1231.258
[8,     1] loss: 1227.837
[9,     1] loss: 1230.086
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025892627224929957,
 'learning_rate_Hydroxylation-K': 0.0007492200006448473,
 'learning_rate_Hydroxylation-P': 0.003208232004716182,
 'log_base': 2.0320891316374743,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3780104615,
 'sample_weights': [1.5471762874565316, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1282663032276963,
 'weight_decay_Hydroxylation-K': 0.11873936630612159,
 'weight_decay_Hydroxylation-P': 0.3587920597997041}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1410.345
[2,     1] loss: 1405.373
[3,     1] loss: 1404.972
[4,     1] loss: 1401.543
[5,     1] loss: 1404.268
[6,     1] loss: 1395.766
[7,     1] loss: 1394.659
[8,     1] loss: 1378.851
[9,     1] loss: 1365.436
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001310974709846647,
 'learning_rate_Hydroxylation-K': 0.0028464690940979984,
 'learning_rate_Hydroxylation-P': 0.0013952082601324063,
 'log_base': 1.9970597164012862,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4119036787,
 'sample_weights': [2.3544309437838273, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.448109304638239,
 'weight_decay_Hydroxylation-K': 1.3917877049588754,
 'weight_decay_Hydroxylation-P': 7.262816276922388}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1420.607
[2,     1] loss: 1416.585
[3,     1] loss: 1416.995
[4,     1] loss: 1412.243
[5,     1] loss: 1413.622
[6,     1] loss: 1414.936
[7,     1] loss: 1411.812
[8,     1] loss: 1415.311
[9,     1] loss: 1409.644
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00739419142078292,
 'learning_rate_Hydroxylation-K': 0.0077589242313507445,
 'learning_rate_Hydroxylation-P': 0.0027849804263777945,
 'log_base': 2.339893974830229,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 999364218,
 'sample_weights': [2.413620323834305, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.5036492847726635,
 'weight_decay_Hydroxylation-K': 7.714302838050601,
 'weight_decay_Hydroxylation-P': 0.8481912457308001}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1320.424
[2,     1] loss: 1323.408
[3,     1] loss: 1327.651
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00445903832869351,
 'learning_rate_Hydroxylation-K': 0.00755782552938929,
 'learning_rate_Hydroxylation-P': 0.004546690094801302,
 'log_base': 2.6435337069821117,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1758773410,
 'sample_weights': [1.9638067449598986, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.106865079224764,
 'weight_decay_Hydroxylation-K': 8.299195243351898,
 'weight_decay_Hydroxylation-P': 0.33059945265995005}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1268.920
[2,     1] loss: 1272.281
[3,     1] loss: 1283.708
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0050331653939606645,
 'learning_rate_Hydroxylation-K': 0.0015912080733573235,
 'learning_rate_Hydroxylation-P': 0.00037317322533773293,
 'log_base': 1.3662339953174132,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1023049762,
 'sample_weights': [1.7173281863276286, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.611000553883052,
 'weight_decay_Hydroxylation-K': 6.061082187075623,
 'weight_decay_Hydroxylation-P': 3.212012953848026}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2050.806
[2,     1] loss: 2028.298
[3,     1] loss: 2058.281
[4,     1] loss: 2033.279
[5,     1] loss: 2029.896
[6,     1] loss: 2042.009
[7,     1] loss: 2046.479
[8,     1] loss: 2039.313
[9,     1] loss: 2021.814
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00011315344621199569,
 'learning_rate_Hydroxylation-K': 0.0038301768106999766,
 'learning_rate_Hydroxylation-P': 0.0004261904632044929,
 'log_base': 2.9047798338757427,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1021428576,
 'sample_weights': [5.349784016637262, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.646470122065065,
 'weight_decay_Hydroxylation-K': 9.23049904643822,
 'weight_decay_Hydroxylation-P': 5.141429419601247}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.345
[2,     1] loss: 1241.443
[3,     1] loss: 1244.250
[4,     1] loss: 1239.575
[5,     1] loss: 1241.944
[6,     1] loss: 1242.902
[7,     1] loss: 1239.104
[8,     1] loss: 1239.192
[9,     1] loss: 1238.547
[10,     1] loss: 1238.081
[11,     1] loss: 1239.266
[12,     1] loss: 1238.182
[13,     1] loss: 1238.540
[14,     1] loss: 1240.763
[15,     1] loss: 1239.116
[16,     1] loss: 1236.273
[17,     1] loss: 1238.512
[18,     1] loss: 1240.646
[19,     1] loss: 1237.010
[20,     1] loss: 1240.254
[21,     1] loss: 1239.295
[22,     1] loss: 1235.368
[23,     1] loss: 1237.493
[24,     1] loss: 1236.118
[25,     1] loss: 1237.243
[26,     1] loss: 1235.776
[27,     1] loss: 1238.816
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033424970157309294,
 'learning_rate_Hydroxylation-K': 0.007524226930284554,
 'learning_rate_Hydroxylation-P': 0.005359004405316479,
 'log_base': 1.0584884528101592,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3585091508,
 'sample_weights': [1.565556572563111, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.169727848636711,
 'weight_decay_Hydroxylation-K': 1.5932440069745555,
 'weight_decay_Hydroxylation-P': 2.912728771276722}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 9516.086
[2,     1] loss: 9582.435
[3,     1] loss: 9524.072
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032257716835950375,
 'learning_rate_Hydroxylation-K': 0.006583095187253714,
 'learning_rate_Hydroxylation-P': 0.0019484362197880719,
 'log_base': 2.7053508244557913,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1114742953,
 'sample_weights': [29.369937904812925, 3.671383669094974],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.9313350142590933,
 'weight_decay_Hydroxylation-K': 6.910487166335653,
 'weight_decay_Hydroxylation-P': 1.1598428733962447}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1265.047
[2,     1] loss: 1260.915
[3,     1] loss: 1259.800
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005744314208983204,
 'learning_rate_Hydroxylation-K': 0.004463853796597911,
 'learning_rate_Hydroxylation-P': 0.006692132325743232,
 'log_base': 2.5245982017025437,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2468301029,
 'sample_weights': [1.677441863391014, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.648675792792496,
 'weight_decay_Hydroxylation-K': 6.043680024902095,
 'weight_decay_Hydroxylation-P': 0.06427904842253619}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1288.719
[2,     1] loss: 1298.839
[3,     1] loss: 1290.585
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022277120654705758,
 'learning_rate_Hydroxylation-K': 0.0004415277259836694,
 'learning_rate_Hydroxylation-P': 0.0023381305280810796,
 'log_base': 2.235080914000364,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3765384826,
 'sample_weights': [1.8026948887745056, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.40839949512638185,
 'weight_decay_Hydroxylation-K': 9.427113402558227,
 'weight_decay_Hydroxylation-P': 1.5962158805146853}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1346.721
[2,     1] loss: 1345.272
[3,     1] loss: 1357.921
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00038208514819653957,
 'learning_rate_Hydroxylation-K': 0.008919705782095201,
 'learning_rate_Hydroxylation-P': 0.003441552973111779,
 'log_base': 2.7679992177639656,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2050212688,
 'sample_weights': [2.0757055762436045, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.2690732103046787,
 'weight_decay_Hydroxylation-K': 3.2858411011001274,
 'weight_decay_Hydroxylation-P': 0.10844216285377084}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1262.623
[2,     1] loss: 1256.399
[3,     1] loss: 1254.295
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027733986948260897,
 'learning_rate_Hydroxylation-K': 0.009170133366816106,
 'learning_rate_Hydroxylation-P': 0.0051051420630726235,
 'log_base': 2.5459009237887757,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2702872758,
 'sample_weights': [1.6397235593868194, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.999343719044252,
 'weight_decay_Hydroxylation-K': 5.873788643205159,
 'weight_decay_Hydroxylation-P': 8.76774650110031}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1285.527
[2,     1] loss: 1284.846
[3,     1] loss: 1283.572
[4,     1] loss: 1286.828
[5,     1] loss: 1285.949
[6,     1] loss: 1274.818
[7,     1] loss: 1270.228
[8,     1] loss: 1253.611
[9,     1] loss: 1226.978
[10,     1] loss: 1197.432
[11,     1] loss: 1160.252
[12,     1] loss: 1117.357
[13,     1] loss: 1116.732
[14,     1] loss: 1099.322
[15,     1] loss: 1049.278
[16,     1] loss: 1052.942
[17,     1] loss: 1034.711
[18,     1] loss: 1091.648
[19,     1] loss: 1029.128
[20,     1] loss: 1063.551
[21,     1] loss: 1029.964
[22,     1] loss: 1066.984
[23,     1] loss: 1007.618
[24,     1] loss: 993.790
[25,     1] loss: 1013.321
[26,     1] loss: 1009.152
[27,     1] loss: 1003.246
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00595874517705291,
 'learning_rate_Hydroxylation-K': 0.006758880358133333,
 'learning_rate_Hydroxylation-P': 0.0007352322789735126,
 'log_base': 2.288716974446687,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2133769198,
 'sample_weights': [1.7864854855442622, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9099389757427976,
 'weight_decay_Hydroxylation-K': 5.916831214513076,
 'weight_decay_Hydroxylation-P': 1.9463288597863295}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1334.844
[2,     1] loss: 1333.196
[3,     1] loss: 1343.851
[4,     1] loss: 1335.710
[5,     1] loss: 1334.490
[6,     1] loss: 1327.123
[7,     1] loss: 1320.639
[8,     1] loss: 1299.684
[9,     1] loss: 1265.536
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010608615523914646,
 'learning_rate_Hydroxylation-K': 0.00036690825491313573,
 'learning_rate_Hydroxylation-P': 0.006725728860910968,
 'log_base': 2.650404961389615,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 796196018,
 'sample_weights': [2.0162566578040675, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.33454036848961743,
 'weight_decay_Hydroxylation-K': 9.99341988643882,
 'weight_decay_Hydroxylation-P': 3.2998461586176173}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1270.695
[2,     1] loss: 1267.149
[3,     1] loss: 1270.175
[4,     1] loss: 1271.782
[5,     1] loss: 1265.788
[6,     1] loss: 1266.912
[7,     1] loss: 1267.580
[8,     1] loss: 1264.643
[9,     1] loss: 1264.020
[10,     1] loss: 1263.743
[11,     1] loss: 1261.327
[12,     1] loss: 1252.313
[13,     1] loss: 1242.742
[14,     1] loss: 1234.146
[15,     1] loss: 1221.289
[16,     1] loss: 1194.375
[17,     1] loss: 1169.549
[18,     1] loss: 1161.505
[19,     1] loss: 1132.667
[20,     1] loss: 1104.605
[21,     1] loss: 1104.960
[22,     1] loss: 1072.858
[23,     1] loss: 1091.498
[24,     1] loss: 1039.203
[25,     1] loss: 1077.581
[26,     1] loss: 1106.222
[27,     1] loss: 1058.629
[28,     1] loss: 1026.393
[29,     1] loss: 1055.590
[30,     1] loss: 1036.757
[31,     1] loss: 1043.648
[32,     1] loss: 1052.079
[33,     1] loss: 1027.595
[34,     1] loss: 1065.502
[35,     1] loss: 1046.770
[36,     1] loss: 991.735
[37,     1] loss: 1027.919
[38,     1] loss: 1015.349
[39,     1] loss: 1058.320
[40,     1] loss: 978.675
[41,     1] loss: 1018.006
[42,     1] loss: 1003.927
[43,     1] loss: 997.235
[44,     1] loss: 984.650
[45,     1] loss: 971.345
[46,     1] loss: 984.900
[47,     1] loss: 956.464
[48,     1] loss: 928.547
[49,     1] loss: 957.973
[50,     1] loss: 958.285
[51,     1] loss: 897.584
[52,     1] loss: 924.836
[53,     1] loss: 916.836
[54,     1] loss: 915.045
[55,     1] loss: 934.473
[56,     1] loss: 948.831
[57,     1] loss: 945.304
[58,     1] loss: 915.479
[59,     1] loss: 919.770
[60,     1] loss: 896.294
[61,     1] loss: 881.040
[62,     1] loss: 903.570
[63,     1] loss: 853.894
[64,     1] loss: 876.966
[65,     1] loss: 826.816
[66,     1] loss: 868.121
Early stopping applied (best metric=0.6962001323699951)
Finished Training
Total time taken: 9.624009370803833
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1267.627
[2,     1] loss: 1269.955
[3,     1] loss: 1267.462
[4,     1] loss: 1264.701
[5,     1] loss: 1266.569
[6,     1] loss: 1263.174
[7,     1] loss: 1262.197
[8,     1] loss: 1264.946
[9,     1] loss: 1257.431
[10,     1] loss: 1250.201
[11,     1] loss: 1233.326
[12,     1] loss: 1213.385
[13,     1] loss: 1196.111
[14,     1] loss: 1169.033
[15,     1] loss: 1158.311
[16,     1] loss: 1129.196
[17,     1] loss: 1117.419
[18,     1] loss: 1100.207
[19,     1] loss: 1088.583
[20,     1] loss: 1088.355
[21,     1] loss: 1069.517
[22,     1] loss: 1076.259
[23,     1] loss: 1090.930
[24,     1] loss: 1067.204
[25,     1] loss: 1081.668
[26,     1] loss: 994.734
[27,     1] loss: 1047.229
[28,     1] loss: 1043.338
[29,     1] loss: 1066.249
[30,     1] loss: 1055.252
[31,     1] loss: 1034.441
[32,     1] loss: 1023.430
[33,     1] loss: 1002.544
[34,     1] loss: 979.635
[35,     1] loss: 975.055
[36,     1] loss: 990.068
[37,     1] loss: 1058.818
[38,     1] loss: 996.543
Early stopping applied (best metric=0.9612113237380981)
Finished Training
Total time taken: 5.192005157470703
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1267.872
[2,     1] loss: 1269.702
[3,     1] loss: 1269.012
[4,     1] loss: 1267.696
[5,     1] loss: 1270.557
[6,     1] loss: 1265.800
[7,     1] loss: 1265.468
[8,     1] loss: 1258.073
[9,     1] loss: 1261.560
[10,     1] loss: 1245.106
[11,     1] loss: 1236.682
[12,     1] loss: 1212.461
[13,     1] loss: 1193.646
[14,     1] loss: 1180.831
[15,     1] loss: 1154.750
[16,     1] loss: 1141.679
[17,     1] loss: 1124.494
[18,     1] loss: 1129.100
[19,     1] loss: 1116.288
[20,     1] loss: 1078.509
[21,     1] loss: 1085.814
[22,     1] loss: 1088.580
[23,     1] loss: 1104.578
[24,     1] loss: 1079.320
[25,     1] loss: 1040.918
[26,     1] loss: 1062.309
[27,     1] loss: 1079.642
[28,     1] loss: 1033.865
[29,     1] loss: 1047.762
[30,     1] loss: 1012.823
[31,     1] loss: 1010.926
[32,     1] loss: 1035.403
[33,     1] loss: 997.842
[34,     1] loss: 1001.445
[35,     1] loss: 1006.968
[36,     1] loss: 1003.713
[37,     1] loss: 998.811
[38,     1] loss: 986.954
[39,     1] loss: 936.689
[40,     1] loss: 980.478
[41,     1] loss: 988.176
[42,     1] loss: 1035.240
[43,     1] loss: 963.203
[44,     1] loss: 970.349
[45,     1] loss: 936.995
Early stopping applied (best metric=0.8803441524505615)
Finished Training
Total time taken: 6.119006156921387
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1284.645
[2,     1] loss: 1266.557
[3,     1] loss: 1269.395
[4,     1] loss: 1269.873
[5,     1] loss: 1272.020
[6,     1] loss: 1269.233
[7,     1] loss: 1267.036
[8,     1] loss: 1267.378
[9,     1] loss: 1264.349
[10,     1] loss: 1264.695
[11,     1] loss: 1263.305
[12,     1] loss: 1264.053
[13,     1] loss: 1259.249
[14,     1] loss: 1252.348
[15,     1] loss: 1240.330
[16,     1] loss: 1238.207
[17,     1] loss: 1223.401
[18,     1] loss: 1201.613
[19,     1] loss: 1198.092
[20,     1] loss: 1171.194
[21,     1] loss: 1140.467
[22,     1] loss: 1133.068
[23,     1] loss: 1112.294
[24,     1] loss: 1108.469
[25,     1] loss: 1112.719
[26,     1] loss: 1079.778
[27,     1] loss: 1072.663
[28,     1] loss: 1090.846
[29,     1] loss: 1109.117
[30,     1] loss: 1100.307
[31,     1] loss: 1019.274
[32,     1] loss: 1041.412
[33,     1] loss: 1048.523
[34,     1] loss: 1032.219
[35,     1] loss: 1001.374
[36,     1] loss: 1039.133
[37,     1] loss: 1036.801
[38,     1] loss: 1000.085
[39,     1] loss: 988.288
[40,     1] loss: 986.248
[41,     1] loss: 1025.889
[42,     1] loss: 979.731
[43,     1] loss: 989.019
Early stopping applied (best metric=0.9826158285140991)
Finished Training
Total time taken: 5.917006015777588
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1276.963
[2,     1] loss: 1274.518
[3,     1] loss: 1273.450
[4,     1] loss: 1269.397
[5,     1] loss: 1276.018
[6,     1] loss: 1274.158
[7,     1] loss: 1271.744
[8,     1] loss: 1265.670
[9,     1] loss: 1258.003
[10,     1] loss: 1256.493
[11,     1] loss: 1250.234
[12,     1] loss: 1234.578
[13,     1] loss: 1216.472
[14,     1] loss: 1194.220
[15,     1] loss: 1172.261
[16,     1] loss: 1143.581
[17,     1] loss: 1130.996
[18,     1] loss: 1100.691
[19,     1] loss: 1114.452
[20,     1] loss: 1099.493
[21,     1] loss: 1097.232
[22,     1] loss: 1046.707
[23,     1] loss: 1077.885
[24,     1] loss: 1058.978
[25,     1] loss: 1044.937
[26,     1] loss: 1043.137
[27,     1] loss: 1047.180
[28,     1] loss: 1037.865
[29,     1] loss: 981.953
[30,     1] loss: 1076.521
[31,     1] loss: 1031.708
[32,     1] loss: 1025.383
[33,     1] loss: 1008.542
[34,     1] loss: 1034.343
[35,     1] loss: 1006.500
[36,     1] loss: 1031.214
[37,     1] loss: 1051.037
[38,     1] loss: 943.472
Early stopping applied (best metric=1.0006972551345825)
Finished Training
Total time taken: 5.636006832122803
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1277.268
[2,     1] loss: 1271.632
[3,     1] loss: 1268.539
[4,     1] loss: 1267.866
[5,     1] loss: 1269.349
[6,     1] loss: 1270.312
[7,     1] loss: 1265.617
[8,     1] loss: 1262.843
[9,     1] loss: 1258.918
[10,     1] loss: 1253.029
[11,     1] loss: 1249.642
[12,     1] loss: 1232.467
[13,     1] loss: 1216.424
[14,     1] loss: 1203.544
[15,     1] loss: 1176.011
[16,     1] loss: 1168.211
[17,     1] loss: 1145.334
[18,     1] loss: 1111.901
[19,     1] loss: 1095.865
[20,     1] loss: 1075.678
[21,     1] loss: 1079.511
[22,     1] loss: 1042.869
[23,     1] loss: 1004.287
[24,     1] loss: 1019.129
[25,     1] loss: 1031.752
[26,     1] loss: 1066.817
[27,     1] loss: 1046.454
[28,     1] loss: 1023.769
[29,     1] loss: 1006.050
[30,     1] loss: 996.109
[31,     1] loss: 1008.594
[32,     1] loss: 992.015
[33,     1] loss: 1017.003
[34,     1] loss: 994.984
[35,     1] loss: 966.280
[36,     1] loss: 965.030
[37,     1] loss: 965.100
[38,     1] loss: 985.788
[39,     1] loss: 952.666
[40,     1] loss: 955.569
[41,     1] loss: 960.653
[42,     1] loss: 949.453
[43,     1] loss: 929.399
[44,     1] loss: 926.008
[45,     1] loss: 900.716
[46,     1] loss: 890.829
[47,     1] loss: 954.316
[48,     1] loss: 881.664
[49,     1] loss: 916.083
[50,     1] loss: 835.361
[51,     1] loss: 844.080
[52,     1] loss: 860.993
[53,     1] loss: 833.375
[54,     1] loss: 848.411
[55,     1] loss: 862.152
Early stopping applied (best metric=0.929262638092041)
Finished Training
Total time taken: 8.4320068359375
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1270.676
[2,     1] loss: 1270.209
[3,     1] loss: 1273.149
[4,     1] loss: 1268.319
[5,     1] loss: 1268.417
[6,     1] loss: 1268.868
[7,     1] loss: 1267.185
[8,     1] loss: 1266.477
[9,     1] loss: 1263.964
[10,     1] loss: 1260.755
[11,     1] loss: 1256.196
[12,     1] loss: 1248.461
[13,     1] loss: 1236.998
[14,     1] loss: 1229.984
[15,     1] loss: 1210.781
[16,     1] loss: 1198.997
[17,     1] loss: 1169.536
[18,     1] loss: 1144.290
[19,     1] loss: 1145.139
[20,     1] loss: 1113.520
[21,     1] loss: 1133.812
[22,     1] loss: 1123.661
[23,     1] loss: 1111.547
[24,     1] loss: 1084.587
[25,     1] loss: 1092.724
[26,     1] loss: 1066.482
[27,     1] loss: 1084.091
[28,     1] loss: 1054.472
[29,     1] loss: 1088.190
[30,     1] loss: 1021.835
[31,     1] loss: 1050.607
[32,     1] loss: 1032.982
[33,     1] loss: 1028.186
[34,     1] loss: 1051.646
[35,     1] loss: 1001.507
[36,     1] loss: 1019.677
[37,     1] loss: 976.077
[38,     1] loss: 979.665
[39,     1] loss: 985.493
[40,     1] loss: 971.134
[41,     1] loss: 992.278
[42,     1] loss: 950.689
[43,     1] loss: 968.141
[44,     1] loss: 1021.270
[45,     1] loss: 948.293
[46,     1] loss: 929.102
[47,     1] loss: 959.458
[48,     1] loss: 950.735
[49,     1] loss: 932.088
[50,     1] loss: 924.634
[51,     1] loss: 927.841
[52,     1] loss: 892.578
[53,     1] loss: 923.016
[54,     1] loss: 892.908
[55,     1] loss: 878.818
[56,     1] loss: 864.212
[57,     1] loss: 893.429
[58,     1] loss: 820.763
[59,     1] loss: 859.169
[60,     1] loss: 887.202
[61,     1] loss: 794.828
[62,     1] loss: 858.762
[63,     1] loss: 818.799
[64,     1] loss: 830.424
[65,     1] loss: 847.542
[66,     1] loss: 830.967
[67,     1] loss: 788.671
[68,     1] loss: 787.077
[69,     1] loss: 790.903
[70,     1] loss: 753.565
[71,     1] loss: 802.120
[72,     1] loss: 778.899
Early stopping applied (best metric=0.8599205613136292)
Finished Training
Total time taken: 10.984012365341187
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1274.799
[2,     1] loss: 1272.678
[3,     1] loss: 1270.062
[4,     1] loss: 1269.394
[5,     1] loss: 1265.564
[6,     1] loss: 1266.487
[7,     1] loss: 1272.189
[8,     1] loss: 1266.309
[9,     1] loss: 1263.970
[10,     1] loss: 1269.071
[11,     1] loss: 1257.994
[12,     1] loss: 1250.059
[13,     1] loss: 1240.527
[14,     1] loss: 1228.006
[15,     1] loss: 1210.192
[16,     1] loss: 1199.321
[17,     1] loss: 1163.982
[18,     1] loss: 1124.460
[19,     1] loss: 1117.282
[20,     1] loss: 1079.544
[21,     1] loss: 1057.019
[22,     1] loss: 1064.573
[23,     1] loss: 1006.205
[24,     1] loss: 1020.375
[25,     1] loss: 1048.959
[26,     1] loss: 1048.625
[27,     1] loss: 1036.856
[28,     1] loss: 1024.884
[29,     1] loss: 1000.557
[30,     1] loss: 1039.553
[31,     1] loss: 990.181
[32,     1] loss: 1010.386
[33,     1] loss: 995.334
[34,     1] loss: 966.686
[35,     1] loss: 1016.006
[36,     1] loss: 1011.418
[37,     1] loss: 955.979
[38,     1] loss: 955.947
[39,     1] loss: 982.594
[40,     1] loss: 958.414
[41,     1] loss: 990.383
[42,     1] loss: 961.009
[43,     1] loss: 955.175
[44,     1] loss: 974.086
[45,     1] loss: 938.792
[46,     1] loss: 964.145
[47,     1] loss: 923.278
[48,     1] loss: 901.473
[49,     1] loss: 890.115
[50,     1] loss: 917.702
[51,     1] loss: 890.918
[52,     1] loss: 919.183
[53,     1] loss: 923.643
[54,     1] loss: 895.247
[55,     1] loss: 870.899
[56,     1] loss: 872.647
Early stopping applied (best metric=1.0030381679534912)
Finished Training
Total time taken: 8.381006717681885
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1275.601
[2,     1] loss: 1271.248
[3,     1] loss: 1270.352
[4,     1] loss: 1271.092
[5,     1] loss: 1266.288
[6,     1] loss: 1269.607
[7,     1] loss: 1274.794
[8,     1] loss: 1266.833
[9,     1] loss: 1267.978
[10,     1] loss: 1267.590
[11,     1] loss: 1262.684
[12,     1] loss: 1256.995
[13,     1] loss: 1253.899
[14,     1] loss: 1243.750
[15,     1] loss: 1238.345
[16,     1] loss: 1218.479
[17,     1] loss: 1202.266
[18,     1] loss: 1172.529
[19,     1] loss: 1167.825
[20,     1] loss: 1144.906
[21,     1] loss: 1132.223
[22,     1] loss: 1118.997
[23,     1] loss: 1081.282
[24,     1] loss: 1091.929
[25,     1] loss: 1063.359
[26,     1] loss: 1043.297
[27,     1] loss: 994.987
[28,     1] loss: 1034.933
[29,     1] loss: 960.160
[30,     1] loss: 1017.533
[31,     1] loss: 1107.325
[32,     1] loss: 1094.386
[33,     1] loss: 1070.070
[34,     1] loss: 1036.916
[35,     1] loss: 1020.890
[36,     1] loss: 1034.359
[37,     1] loss: 1044.786
[38,     1] loss: 1028.630
[39,     1] loss: 1027.425
[40,     1] loss: 1034.967
[41,     1] loss: 1012.760
[42,     1] loss: 985.248
[43,     1] loss: 1005.626
[44,     1] loss: 1001.961
[45,     1] loss: 992.280
[46,     1] loss: 987.017
[47,     1] loss: 997.852
[48,     1] loss: 941.945
[49,     1] loss: 918.720
[50,     1] loss: 947.544
[51,     1] loss: 946.816
[52,     1] loss: 885.666
[53,     1] loss: 895.763
[54,     1] loss: 934.541
[55,     1] loss: 928.071
[56,     1] loss: 852.392
[57,     1] loss: 893.032
Early stopping applied (best metric=0.941094160079956)
Finished Training
Total time taken: 8.70400857925415
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1276.057
[2,     1] loss: 1271.210
[3,     1] loss: 1274.536
[4,     1] loss: 1269.882
[5,     1] loss: 1271.220
[6,     1] loss: 1268.334
[7,     1] loss: 1266.455
[8,     1] loss: 1270.397
[9,     1] loss: 1265.680
[10,     1] loss: 1265.571
[11,     1] loss: 1258.437
[12,     1] loss: 1263.271
[13,     1] loss: 1252.377
[14,     1] loss: 1242.069
[15,     1] loss: 1222.820
[16,     1] loss: 1208.299
[17,     1] loss: 1200.734
[18,     1] loss: 1158.799
[19,     1] loss: 1135.909
[20,     1] loss: 1139.930
[21,     1] loss: 1099.940
[22,     1] loss: 1076.265
[23,     1] loss: 1058.800
[24,     1] loss: 1066.313
[25,     1] loss: 1064.841
[26,     1] loss: 1039.697
[27,     1] loss: 1074.797
[28,     1] loss: 1062.288
[29,     1] loss: 995.965
[30,     1] loss: 1006.499
[31,     1] loss: 1076.231
[32,     1] loss: 979.707
[33,     1] loss: 1013.499
[34,     1] loss: 1007.025
[35,     1] loss: 998.024
[36,     1] loss: 994.960
[37,     1] loss: 982.753
[38,     1] loss: 948.183
[39,     1] loss: 946.987
[40,     1] loss: 1005.366
[41,     1] loss: 979.204
[42,     1] loss: 917.699
[43,     1] loss: 960.083
[44,     1] loss: 928.113
[45,     1] loss: 1024.569
[46,     1] loss: 949.073
[47,     1] loss: 988.147
[48,     1] loss: 904.565
[49,     1] loss: 946.470
[50,     1] loss: 915.826
[51,     1] loss: 847.676
[52,     1] loss: 915.456
[53,     1] loss: 888.714
[54,     1] loss: 885.821
[55,     1] loss: 860.529
[56,     1] loss: 878.281
[57,     1] loss: 914.733
[58,     1] loss: 831.339
[59,     1] loss: 841.363
[60,     1] loss: 892.812
[61,     1] loss: 860.148
[62,     1] loss: 796.574
[63,     1] loss: 853.870
[64,     1] loss: 806.980
[65,     1] loss: 811.975
[66,     1] loss: 826.620
[67,     1] loss: 774.519
Early stopping applied (best metric=0.7974252700805664)
Finished Training
Total time taken: 10.956010818481445
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1273.139
[2,     1] loss: 1270.225
[3,     1] loss: 1269.655
[4,     1] loss: 1269.196
[5,     1] loss: 1269.037
[6,     1] loss: 1265.750
[7,     1] loss: 1265.078
[8,     1] loss: 1262.408
[9,     1] loss: 1262.241
[10,     1] loss: 1254.121
[11,     1] loss: 1251.129
[12,     1] loss: 1240.350
[13,     1] loss: 1225.585
[14,     1] loss: 1198.968
[15,     1] loss: 1176.600
[16,     1] loss: 1155.842
[17,     1] loss: 1113.177
[18,     1] loss: 1123.964
[19,     1] loss: 1082.949
[20,     1] loss: 1065.527
[21,     1] loss: 1067.187
[22,     1] loss: 1040.377
[23,     1] loss: 1008.565
[24,     1] loss: 1050.025
[25,     1] loss: 1018.088
[26,     1] loss: 1043.924
[27,     1] loss: 1044.314
[28,     1] loss: 1034.188
[29,     1] loss: 1024.219
[30,     1] loss: 978.480
[31,     1] loss: 965.331
[32,     1] loss: 1057.181
[33,     1] loss: 983.423
[34,     1] loss: 991.343
[35,     1] loss: 987.188
[36,     1] loss: 945.426
[37,     1] loss: 961.119
[38,     1] loss: 972.651
[39,     1] loss: 942.542
[40,     1] loss: 960.594
[41,     1] loss: 909.638
[42,     1] loss: 933.026
[43,     1] loss: 944.953
[44,     1] loss: 933.526
[45,     1] loss: 872.454
[46,     1] loss: 896.233
[47,     1] loss: 917.915
[48,     1] loss: 901.367
[49,     1] loss: 889.033
[50,     1] loss: 883.628
[51,     1] loss: 928.527
Early stopping applied (best metric=0.9799047708511353)
Finished Training
Total time taken: 7.212006092071533
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1269.419
[2,     1] loss: 1270.094
[3,     1] loss: 1267.602
[4,     1] loss: 1271.261
[5,     1] loss: 1270.432
[6,     1] loss: 1267.063
[7,     1] loss: 1266.814
[8,     1] loss: 1263.207
[9,     1] loss: 1262.579
[10,     1] loss: 1258.057
[11,     1] loss: 1247.564
[12,     1] loss: 1233.334
[13,     1] loss: 1223.803
[14,     1] loss: 1195.651
[15,     1] loss: 1169.091
[16,     1] loss: 1143.189
[17,     1] loss: 1136.023
[18,     1] loss: 1106.256
[19,     1] loss: 1091.350
[20,     1] loss: 1106.811
[21,     1] loss: 1061.277
[22,     1] loss: 1081.561
[23,     1] loss: 1089.669
[24,     1] loss: 1029.421
[25,     1] loss: 1058.199
[26,     1] loss: 1005.601
[27,     1] loss: 1077.899
[28,     1] loss: 1032.075
[29,     1] loss: 1044.279
[30,     1] loss: 1032.532
[31,     1] loss: 1035.321
[32,     1] loss: 1024.398
[33,     1] loss: 1008.147
[34,     1] loss: 997.976
[35,     1] loss: 993.052
[36,     1] loss: 966.026
[37,     1] loss: 954.038
[38,     1] loss: 999.166
[39,     1] loss: 1002.903
[40,     1] loss: 937.469
[41,     1] loss: 949.189
[42,     1] loss: 981.701
[43,     1] loss: 985.229
[44,     1] loss: 925.420
[45,     1] loss: 931.505
[46,     1] loss: 934.099
[47,     1] loss: 965.803
[48,     1] loss: 968.346
[49,     1] loss: 940.163
[50,     1] loss: 916.013
[51,     1] loss: 934.362
[52,     1] loss: 925.877
[53,     1] loss: 927.319
[54,     1] loss: 903.866
[55,     1] loss: 883.308
[56,     1] loss: 871.864
[57,     1] loss: 870.571
[58,     1] loss: 876.305
[59,     1] loss: 932.833
[60,     1] loss: 845.282
[61,     1] loss: 847.286
[62,     1] loss: 885.146
[63,     1] loss: 901.367
[64,     1] loss: 880.947
[65,     1] loss: 864.314
[66,     1] loss: 843.551
[67,     1] loss: 883.481
[68,     1] loss: 882.052
[69,     1] loss: 862.728
[70,     1] loss: 852.219
[71,     1] loss: 784.821
[72,     1] loss: 830.268
[73,     1] loss: 785.338
[74,     1] loss: 827.215
[75,     1] loss: 824.563
[76,     1] loss: 734.696
[77,     1] loss: 743.478
[78,     1] loss: 780.712
[79,     1] loss: 769.116
[80,     1] loss: 729.173
[81,     1] loss: 742.430
[82,     1] loss: 744.621
[83,     1] loss: 718.894
Early stopping applied (best metric=0.9171522259712219)
Finished Training
Total time taken: 13.278013229370117
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1270.659
[2,     1] loss: 1267.534
[3,     1] loss: 1265.662
[4,     1] loss: 1270.937
[5,     1] loss: 1266.242
[6,     1] loss: 1264.360
[7,     1] loss: 1263.514
[8,     1] loss: 1256.260
[9,     1] loss: 1253.825
[10,     1] loss: 1242.591
[11,     1] loss: 1233.744
[12,     1] loss: 1210.698
[13,     1] loss: 1200.870
[14,     1] loss: 1179.691
[15,     1] loss: 1160.774
[16,     1] loss: 1110.988
[17,     1] loss: 1119.270
[18,     1] loss: 1128.388
[19,     1] loss: 1085.938
[20,     1] loss: 1091.102
[21,     1] loss: 1070.648
[22,     1] loss: 1067.943
[23,     1] loss: 1061.029
[24,     1] loss: 1063.164
[25,     1] loss: 1019.231
[26,     1] loss: 1053.440
[27,     1] loss: 1028.106
[28,     1] loss: 1070.953
[29,     1] loss: 1042.386
[30,     1] loss: 1079.285
[31,     1] loss: 1023.412
[32,     1] loss: 1026.934
[33,     1] loss: 1007.517
[34,     1] loss: 1048.349
[35,     1] loss: 1026.531
[36,     1] loss: 1018.902
[37,     1] loss: 985.194
[38,     1] loss: 977.766
[39,     1] loss: 964.215
[40,     1] loss: 985.025
[41,     1] loss: 959.687
[42,     1] loss: 1029.146
[43,     1] loss: 980.154
[44,     1] loss: 1011.897
[45,     1] loss: 963.880
[46,     1] loss: 936.977
[47,     1] loss: 965.705
[48,     1] loss: 950.503
[49,     1] loss: 947.809
[50,     1] loss: 955.445
[51,     1] loss: 1020.051
[52,     1] loss: 964.066
[53,     1] loss: 954.931
[54,     1] loss: 888.617
[55,     1] loss: 910.215
[56,     1] loss: 894.956
[57,     1] loss: 882.294
[58,     1] loss: 867.455
[59,     1] loss: 884.970
[60,     1] loss: 895.515
[61,     1] loss: 870.757
[62,     1] loss: 903.638
[63,     1] loss: 874.903
[64,     1] loss: 870.539
[65,     1] loss: 838.785
[66,     1] loss: 850.610
[67,     1] loss: 893.458
[68,     1] loss: 826.658
[69,     1] loss: 817.663
[70,     1] loss: 808.807
Early stopping applied (best metric=0.7623558044433594)
Finished Training
Total time taken: 10.33901047706604
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1273.116
[2,     1] loss: 1267.805
[3,     1] loss: 1268.228
[4,     1] loss: 1269.437
[5,     1] loss: 1271.192
[6,     1] loss: 1270.972
[7,     1] loss: 1267.103
[8,     1] loss: 1264.638
[9,     1] loss: 1260.111
[10,     1] loss: 1262.370
[11,     1] loss: 1254.174
[12,     1] loss: 1251.350
[13,     1] loss: 1246.321
[14,     1] loss: 1232.679
[15,     1] loss: 1216.928
[16,     1] loss: 1203.788
[17,     1] loss: 1174.133
[18,     1] loss: 1164.645
[19,     1] loss: 1156.031
[20,     1] loss: 1122.326
[21,     1] loss: 1090.756
[22,     1] loss: 1100.129
[23,     1] loss: 1084.666
[24,     1] loss: 1084.151
[25,     1] loss: 1038.314
[26,     1] loss: 1049.923
[27,     1] loss: 1079.651
[28,     1] loss: 1035.762
[29,     1] loss: 1034.822
[30,     1] loss: 1067.266
[31,     1] loss: 1032.261
[32,     1] loss: 1045.745
[33,     1] loss: 1047.646
[34,     1] loss: 1013.308
[35,     1] loss: 1036.140
[36,     1] loss: 1013.919
[37,     1] loss: 1005.328
[38,     1] loss: 1019.660
[39,     1] loss: 1021.647
[40,     1] loss: 964.686
[41,     1] loss: 990.243
[42,     1] loss: 963.245
[43,     1] loss: 983.062
[44,     1] loss: 995.498
[45,     1] loss: 943.367
[46,     1] loss: 893.853
[47,     1] loss: 950.730
[48,     1] loss: 937.482
[49,     1] loss: 916.863
[50,     1] loss: 918.269
[51,     1] loss: 937.053
[52,     1] loss: 934.291
[53,     1] loss: 921.579
[54,     1] loss: 877.060
[55,     1] loss: 929.465
[56,     1] loss: 841.572
[57,     1] loss: 895.107
[58,     1] loss: 924.521
[59,     1] loss: 912.316
[60,     1] loss: 876.237
[61,     1] loss: 866.320
[62,     1] loss: 877.246
[63,     1] loss: 867.460
[64,     1] loss: 811.249
[65,     1] loss: 826.644
[66,     1] loss: 836.938
[67,     1] loss: 852.826
[68,     1] loss: 831.490
[69,     1] loss: 816.060
[70,     1] loss: 869.718
[71,     1] loss: 786.910
[72,     1] loss: 795.333
[73,     1] loss: 789.111
Early stopping applied (best metric=0.7528822422027588)
Finished Training
Total time taken: 10.717010498046875
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1270.052
[2,     1] loss: 1274.421
[3,     1] loss: 1266.708
[4,     1] loss: 1261.557
[5,     1] loss: 1271.999
[6,     1] loss: 1262.182
[7,     1] loss: 1265.959
[8,     1] loss: 1262.923
[9,     1] loss: 1256.762
[10,     1] loss: 1253.521
[11,     1] loss: 1233.508
[12,     1] loss: 1219.504
[13,     1] loss: 1203.749
[14,     1] loss: 1168.031
[15,     1] loss: 1165.349
[16,     1] loss: 1119.622
[17,     1] loss: 1106.467
[18,     1] loss: 1107.732
[19,     1] loss: 1086.705
[20,     1] loss: 1093.346
[21,     1] loss: 1042.343
[22,     1] loss: 1101.321
[23,     1] loss: 1079.143
[24,     1] loss: 1097.023
[25,     1] loss: 1114.332
[26,     1] loss: 1006.024
[27,     1] loss: 1063.621
[28,     1] loss: 1030.890
[29,     1] loss: 1030.961
[30,     1] loss: 1028.035
[31,     1] loss: 1041.636
[32,     1] loss: 1034.839
[33,     1] loss: 1039.957
[34,     1] loss: 1010.667
[35,     1] loss: 1015.819
[36,     1] loss: 993.417
[37,     1] loss: 1004.160
[38,     1] loss: 1012.510
[39,     1] loss: 971.880
[40,     1] loss: 965.556
[41,     1] loss: 971.538
[42,     1] loss: 971.203
[43,     1] loss: 994.177
[44,     1] loss: 960.115
[45,     1] loss: 923.018
[46,     1] loss: 919.399
[47,     1] loss: 950.327
[48,     1] loss: 956.077
[49,     1] loss: 925.229
[50,     1] loss: 918.927
[51,     1] loss: 932.173
[52,     1] loss: 869.681
[53,     1] loss: 900.338
[54,     1] loss: 937.102
[55,     1] loss: 884.795
[56,     1] loss: 842.876
[57,     1] loss: 917.419
[58,     1] loss: 921.318
[59,     1] loss: 856.610
[60,     1] loss: 872.523
[61,     1] loss: 916.204
[62,     1] loss: 897.081
[63,     1] loss: 874.002
[64,     1] loss: 874.439
[65,     1] loss: 855.014
[66,     1] loss: 857.881
[67,     1] loss: 872.271
[68,     1] loss: 840.964
[69,     1] loss: 862.250
[70,     1] loss: 839.935
[71,     1] loss: 775.174
[72,     1] loss: 834.590
Early stopping applied (best metric=0.7434157729148865)
Finished Training
Total time taken: 11.9870126247406
{'Hydroxylation-K Validation Accuracy': 0.7199172576832151, 'Hydroxylation-K Validation Sensitivity': 0.6177777777777778, 'Hydroxylation-K Validation Specificity': 0.7456140350877193, 'Hydroxylation-K Validation Precision': 0.39053082366549857, 'Hydroxylation-K AUC ROC': 0.7327875243664718, 'Hydroxylation-K AUC PR': 0.49176368285656924, 'Hydroxylation-K MCC': 0.3157941930480085, 'Hydroxylation-K F1': 0.47571648032330593, 'Validation Loss (Hydroxylation-K)': 0.4828152438004812, 'Hydroxylation-P Validation Accuracy': 0.7537931915469603, 'Hydroxylation-P Validation Sensitivity': 0.7766137566137566, 'Hydroxylation-P Validation Specificity': 0.7488927128535089, 'Hydroxylation-P Validation Precision': 0.4050261726974122, 'Hydroxylation-P AUC ROC': 0.8296811146025571, 'Hydroxylation-P AUC PR': 0.5458180380017604, 'Hydroxylation-P MCC': 0.4257876454475436, 'Hydroxylation-P F1': 0.5292391917414475, 'Validation Loss (Hydroxylation-P)': 0.39768611192703246, 'Validation Loss (total)': 0.8805013537406922, 'TimeToTrain': 8.898542118072509}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00424365868459636,
 'learning_rate_Hydroxylation-K': 0.006061667726336071,
 'learning_rate_Hydroxylation-P': 0.004482162338314067,
 'log_base': 1.1897184852600553,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4270620298,
 'sample_weights': [1.7140250420099123, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.805344399264504,
 'weight_decay_Hydroxylation-K': 2.952779222374184,
 'weight_decay_Hydroxylation-P': 6.621932732652568}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3142.798
[2,     1] loss: 3139.677
[3,     1] loss: 3120.710
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004469962682018222,
 'learning_rate_Hydroxylation-K': 0.004381132532475927,
 'learning_rate_Hydroxylation-P': 0.00468493086299472,
 'log_base': 1.8708384546957273,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1431732261,
 'sample_weights': [9.610147043232766, 1.201314658085957],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.003299897350512,
 'weight_decay_Hydroxylation-K': 4.34052594953645,
 'weight_decay_Hydroxylation-P': 5.675074122063378}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1477.720
[2,     1] loss: 1475.502
[3,     1] loss: 1476.171
[4,     1] loss: 1469.058
[5,     1] loss: 1472.365
[6,     1] loss: 1463.485
[7,     1] loss: 1458.770
[8,     1] loss: 1445.237
[9,     1] loss: 1424.770
[10,     1] loss: 1368.084
[11,     1] loss: 1320.729
[12,     1] loss: 1328.543
[13,     1] loss: 1299.960
[14,     1] loss: 1247.639
[15,     1] loss: 1277.965
[16,     1] loss: 1252.598
[17,     1] loss: 1261.008
[18,     1] loss: 1239.811
[19,     1] loss: 1240.685
[20,     1] loss: 1226.311
[21,     1] loss: 1197.394
[22,     1] loss: 1167.641
[23,     1] loss: 1164.453
[24,     1] loss: 1176.904
[25,     1] loss: 1154.776
[26,     1] loss: 1079.770
[27,     1] loss: 1138.838
[28,     1] loss: 1089.261
[29,     1] loss: 1064.836
[30,     1] loss: 1030.085
[31,     1] loss: 1131.010
[32,     1] loss: 1047.394
[33,     1] loss: 1013.888
[34,     1] loss: 1100.578
[35,     1] loss: 1006.153
[36,     1] loss: 1024.981
[37,     1] loss: 999.042
[38,     1] loss: 981.606
[39,     1] loss: 1000.370
[40,     1] loss: 1068.729
[41,     1] loss: 893.659
[42,     1] loss: 966.561
[43,     1] loss: 1104.047
[44,     1] loss: 944.637
[45,     1] loss: 1029.187
[46,     1] loss: 936.928
[47,     1] loss: 1013.116
[48,     1] loss: 865.427
[49,     1] loss: 1018.908
[50,     1] loss: 875.716
[51,     1] loss: 1079.348
[52,     1] loss: 855.251
[53,     1] loss: 953.271
[54,     1] loss: 827.714
[55,     1] loss: 995.338
[56,     1] loss: 811.784
[57,     1] loss: 911.646
[58,     1] loss: 851.896
[59,     1] loss: 863.911
[60,     1] loss: 769.945
[61,     1] loss: 773.567
[62,     1] loss: 746.882
[63,     1] loss: 768.277
[64,     1] loss: 935.090
[65,     1] loss: 913.586
[66,     1] loss: 805.764
[67,     1] loss: 907.387
[68,     1] loss: 848.404
[69,     1] loss: 778.420
[70,     1] loss: 855.684
[71,     1] loss: 735.496
[72,     1] loss: 814.848
[73,     1] loss: 697.187
[74,     1] loss: 760.395
Early stopping applied (best metric=0.7463667392730713)
Finished Training
Total time taken: 12.277012348175049
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1488.328
[2,     1] loss: 1472.228
[3,     1] loss: 1465.350
[4,     1] loss: 1485.998
[5,     1] loss: 1466.338
[6,     1] loss: 1470.782
[7,     1] loss: 1469.771
[8,     1] loss: 1466.657
[9,     1] loss: 1459.113
[10,     1] loss: 1455.403
[11,     1] loss: 1441.552
[12,     1] loss: 1399.071
[13,     1] loss: 1413.598
[14,     1] loss: 1337.998
[15,     1] loss: 1293.478
[16,     1] loss: 1304.443
[17,     1] loss: 1274.751
[18,     1] loss: 1204.345
[19,     1] loss: 1223.769
[20,     1] loss: 1221.155
[21,     1] loss: 1222.404
[22,     1] loss: 1163.823
[23,     1] loss: 1130.213
[24,     1] loss: 1128.260
[25,     1] loss: 1119.636
[26,     1] loss: 1099.646
[27,     1] loss: 1100.218
[28,     1] loss: 1091.342
[29,     1] loss: 1088.170
[30,     1] loss: 1100.712
[31,     1] loss: 1120.548
[32,     1] loss: 1110.828
[33,     1] loss: 1051.230
[34,     1] loss: 1041.940
[35,     1] loss: 972.948
[36,     1] loss: 966.655
[37,     1] loss: 984.136
[38,     1] loss: 989.053
[39,     1] loss: 1021.270
[40,     1] loss: 946.491
[41,     1] loss: 943.961
[42,     1] loss: 1009.979
[43,     1] loss: 883.934
[44,     1] loss: 927.519
[45,     1] loss: 894.196
[46,     1] loss: 859.113
[47,     1] loss: 968.229
[48,     1] loss: 955.558
[49,     1] loss: 852.811
[50,     1] loss: 797.703
[51,     1] loss: 865.240
[52,     1] loss: 809.078
[53,     1] loss: 748.123
[54,     1] loss: 781.667
[55,     1] loss: 855.227
[56,     1] loss: 903.790
[57,     1] loss: 715.485
[58,     1] loss: 775.230
[59,     1] loss: 751.857
Early stopping applied (best metric=0.9103164672851562)
Finished Training
Total time taken: 8.247008323669434
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1466.343
[2,     1] loss: 1492.487
[3,     1] loss: 1468.666
[4,     1] loss: 1466.586
[5,     1] loss: 1465.226
[6,     1] loss: 1436.357
[7,     1] loss: 1400.560
[8,     1] loss: 1391.014
[9,     1] loss: 1305.280
[10,     1] loss: 1284.541
[11,     1] loss: 1357.265
[12,     1] loss: 1282.313
[13,     1] loss: 1275.230
[14,     1] loss: 1281.029
[15,     1] loss: 1266.871
[16,     1] loss: 1309.248
[17,     1] loss: 1268.133
[18,     1] loss: 1252.323
[19,     1] loss: 1224.826
[20,     1] loss: 1202.472
[21,     1] loss: 1230.854
[22,     1] loss: 1129.449
[23,     1] loss: 1156.749
[24,     1] loss: 1179.100
[25,     1] loss: 1113.634
[26,     1] loss: 1139.072
[27,     1] loss: 1127.799
[28,     1] loss: 1100.373
[29,     1] loss: 1129.283
[30,     1] loss: 1078.822
[31,     1] loss: 1070.066
[32,     1] loss: 1041.139
[33,     1] loss: 1012.989
[34,     1] loss: 1003.983
[35,     1] loss: 1015.764
[36,     1] loss: 1041.049
[37,     1] loss: 1002.159
[38,     1] loss: 985.826
[39,     1] loss: 1134.209
[40,     1] loss: 1168.715
[41,     1] loss: 965.572
[42,     1] loss: 1049.635
[43,     1] loss: 992.340
[44,     1] loss: 970.439
[45,     1] loss: 992.228
[46,     1] loss: 1015.398
[47,     1] loss: 973.530
[48,     1] loss: 901.349
[49,     1] loss: 872.809
[50,     1] loss: 881.170
[51,     1] loss: 934.960
Early stopping applied (best metric=0.7952520251274109)
Finished Training
Total time taken: 7.977007627487183
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1470.896
[2,     1] loss: 1465.421
[3,     1] loss: 1476.598
[4,     1] loss: 1472.284
[5,     1] loss: 1466.117
[6,     1] loss: 1473.385
[7,     1] loss: 1479.457
[8,     1] loss: 1474.830
[9,     1] loss: 1467.472
[10,     1] loss: 1466.706
[11,     1] loss: 1466.339
[12,     1] loss: 1460.759
[13,     1] loss: 1456.509
[14,     1] loss: 1448.474
[15,     1] loss: 1425.877
[16,     1] loss: 1392.819
[17,     1] loss: 1355.331
[18,     1] loss: 1302.949
[19,     1] loss: 1299.367
[20,     1] loss: 1273.318
[21,     1] loss: 1219.899
[22,     1] loss: 1266.244
[23,     1] loss: 1266.398
[24,     1] loss: 1263.160
[25,     1] loss: 1266.713
[26,     1] loss: 1221.774
[27,     1] loss: 1206.593
[28,     1] loss: 1210.760
[29,     1] loss: 1217.007
[30,     1] loss: 1143.082
[31,     1] loss: 1193.135
[32,     1] loss: 1189.672
[33,     1] loss: 1180.229
[34,     1] loss: 1157.362
[35,     1] loss: 1175.070
[36,     1] loss: 1102.603
[37,     1] loss: 1115.481
[38,     1] loss: 1095.066
[39,     1] loss: 1113.493
[40,     1] loss: 1085.612
[41,     1] loss: 1087.823
[42,     1] loss: 1125.116
[43,     1] loss: 1062.149
[44,     1] loss: 1053.854
[45,     1] loss: 1026.850
[46,     1] loss: 1093.131
[47,     1] loss: 1029.466
[48,     1] loss: 1021.569
[49,     1] loss: 1047.789
[50,     1] loss: 1057.169
[51,     1] loss: 966.337
[52,     1] loss: 1023.091
[53,     1] loss: 1041.200
[54,     1] loss: 986.463
[55,     1] loss: 929.616
[56,     1] loss: 954.170
[57,     1] loss: 917.183
[58,     1] loss: 978.601
[59,     1] loss: 992.824
[60,     1] loss: 943.482
[61,     1] loss: 939.429
[62,     1] loss: 1082.503
[63,     1] loss: 886.669
[64,     1] loss: 1051.083
[65,     1] loss: 927.838
[66,     1] loss: 1010.520
[67,     1] loss: 865.438
[68,     1] loss: 854.308
[69,     1] loss: 842.557
[70,     1] loss: 1001.700
[71,     1] loss: 783.562
[72,     1] loss: 747.371
[73,     1] loss: 810.689
[74,     1] loss: 748.728
[75,     1] loss: 769.570
[76,     1] loss: 735.720
[77,     1] loss: 753.112
[78,     1] loss: 723.865
[79,     1] loss: 645.628
[80,     1] loss: 618.628
[81,     1] loss: 619.049
[82,     1] loss: 618.893
[83,     1] loss: 684.399
[84,     1] loss: 847.731
[85,     1] loss: 1260.480
[86,     1] loss: 1094.247
[87,     1] loss: 987.831
[88,     1] loss: 935.494
Early stopping applied (best metric=0.612727701663971)
Finished Training
Total time taken: 13.398013353347778
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1477.452
[2,     1] loss: 1468.925
[3,     1] loss: 1478.903
[4,     1] loss: 1469.026
[5,     1] loss: 1467.180
[6,     1] loss: 1451.025
[7,     1] loss: 1424.213
[8,     1] loss: 1374.278
[9,     1] loss: 1319.458
[10,     1] loss: 1324.032
[11,     1] loss: 1261.416
[12,     1] loss: 1355.620
[13,     1] loss: 1294.004
[14,     1] loss: 1210.314
[15,     1] loss: 1197.876
[16,     1] loss: 1194.757
[17,     1] loss: 1244.532
[18,     1] loss: 1214.537
[19,     1] loss: 1237.254
[20,     1] loss: 1192.428
[21,     1] loss: 1185.986
[22,     1] loss: 1176.087
[23,     1] loss: 1139.526
[24,     1] loss: 1213.999
[25,     1] loss: 1185.923
[26,     1] loss: 1135.863
[27,     1] loss: 1198.744
[28,     1] loss: 1100.705
[29,     1] loss: 1123.478
[30,     1] loss: 1114.952
[31,     1] loss: 1121.378
[32,     1] loss: 1086.091
[33,     1] loss: 1052.289
[34,     1] loss: 1068.969
[35,     1] loss: 1109.816
[36,     1] loss: 1103.970
[37,     1] loss: 1051.324
[38,     1] loss: 1027.751
[39,     1] loss: 1024.844
[40,     1] loss: 1004.497
[41,     1] loss: 984.096
[42,     1] loss: 970.973
[43,     1] loss: 965.280
[44,     1] loss: 944.036
[45,     1] loss: 1023.240
[46,     1] loss: 1197.832
[47,     1] loss: 1055.142
[48,     1] loss: 1099.526
[49,     1] loss: 1009.340
[50,     1] loss: 1093.615
[51,     1] loss: 1024.700
[52,     1] loss: 977.153
[53,     1] loss: 994.392
[54,     1] loss: 968.245
[55,     1] loss: 1024.160
[56,     1] loss: 924.102
[57,     1] loss: 925.543
[58,     1] loss: 905.668
[59,     1] loss: 847.928
[60,     1] loss: 896.751
[61,     1] loss: 848.587
[62,     1] loss: 783.949
[63,     1] loss: 772.419
[64,     1] loss: 837.822
[65,     1] loss: 815.502
[66,     1] loss: 690.296
[67,     1] loss: 763.572
[68,     1] loss: 1073.966
[69,     1] loss: 1158.560
[70,     1] loss: 769.020
[71,     1] loss: 988.331
[72,     1] loss: 820.183
[73,     1] loss: 850.536
[74,     1] loss: 948.085
[75,     1] loss: 743.414
[76,     1] loss: 809.482
[77,     1] loss: 808.541
[78,     1] loss: 807.783
[79,     1] loss: 692.072
[80,     1] loss: 713.994
[81,     1] loss: 670.736
Early stopping applied (best metric=0.7056413292884827)
Finished Training
Total time taken: 12.602011919021606
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1471.744
[2,     1] loss: 1472.923
[3,     1] loss: 1476.620
[4,     1] loss: 1471.153
[5,     1] loss: 1466.335
[6,     1] loss: 1472.316
[7,     1] loss: 1462.279
[8,     1] loss: 1452.477
[9,     1] loss: 1440.356
[10,     1] loss: 1408.367
[11,     1] loss: 1395.854
[12,     1] loss: 1331.849
[13,     1] loss: 1307.962
[14,     1] loss: 1279.317
[15,     1] loss: 1247.482
[16,     1] loss: 1230.668
[17,     1] loss: 1237.132
[18,     1] loss: 1280.419
[19,     1] loss: 1241.472
[20,     1] loss: 1242.128
[21,     1] loss: 1219.351
[22,     1] loss: 1170.428
[23,     1] loss: 1212.680
[24,     1] loss: 1195.217
[25,     1] loss: 1135.155
[26,     1] loss: 1178.848
[27,     1] loss: 1162.778
[28,     1] loss: 1127.098
[29,     1] loss: 1131.385
[30,     1] loss: 1126.376
[31,     1] loss: 1155.513
[32,     1] loss: 1101.377
[33,     1] loss: 1058.546
[34,     1] loss: 1053.817
[35,     1] loss: 1016.324
[36,     1] loss: 1061.311
[37,     1] loss: 1012.779
[38,     1] loss: 1024.947
[39,     1] loss: 1020.026
[40,     1] loss: 959.431
[41,     1] loss: 954.718
[42,     1] loss: 1090.014
[43,     1] loss: 1109.696
[44,     1] loss: 915.520
[45,     1] loss: 1031.521
[46,     1] loss: 965.029
[47,     1] loss: 992.259
[48,     1] loss: 913.592
[49,     1] loss: 1059.195
[50,     1] loss: 897.311
[51,     1] loss: 931.487
[52,     1] loss: 834.736
[53,     1] loss: 947.009
[54,     1] loss: 821.833
[55,     1] loss: 939.280
Early stopping applied (best metric=0.6563887596130371)
Finished Training
Total time taken: 7.729007720947266
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1469.230
[2,     1] loss: 1478.453
[3,     1] loss: 1492.938
[4,     1] loss: 1469.806
[5,     1] loss: 1466.186
[6,     1] loss: 1473.089
[7,     1] loss: 1468.420
[8,     1] loss: 1469.977
[9,     1] loss: 1463.783
[10,     1] loss: 1448.074
[11,     1] loss: 1436.303
[12,     1] loss: 1396.111
[13,     1] loss: 1363.433
[14,     1] loss: 1302.686
[15,     1] loss: 1293.804
[16,     1] loss: 1230.456
[17,     1] loss: 1201.914
[18,     1] loss: 1275.170
[19,     1] loss: 1196.112
[20,     1] loss: 1254.859
[21,     1] loss: 1142.297
[22,     1] loss: 1196.534
[23,     1] loss: 1152.319
[24,     1] loss: 1175.012
[25,     1] loss: 1145.556
[26,     1] loss: 1143.470
[27,     1] loss: 1065.339
[28,     1] loss: 1189.094
[29,     1] loss: 1138.014
[30,     1] loss: 1125.143
[31,     1] loss: 1058.193
[32,     1] loss: 1074.083
[33,     1] loss: 1035.473
[34,     1] loss: 1032.173
[35,     1] loss: 1021.616
[36,     1] loss: 1031.584
[37,     1] loss: 965.880
[38,     1] loss: 984.071
[39,     1] loss: 1025.264
[40,     1] loss: 892.792
[41,     1] loss: 934.961
[42,     1] loss: 914.855
[43,     1] loss: 1031.111
[44,     1] loss: 1188.000
[45,     1] loss: 946.192
[46,     1] loss: 1006.081
[47,     1] loss: 975.712
[48,     1] loss: 1029.674
[49,     1] loss: 880.752
[50,     1] loss: 987.987
[51,     1] loss: 894.879
[52,     1] loss: 902.488
[53,     1] loss: 912.948
[54,     1] loss: 840.245
[55,     1] loss: 897.208
[56,     1] loss: 890.572
[57,     1] loss: 811.275
[58,     1] loss: 784.597
Early stopping applied (best metric=0.7847391963005066)
Finished Training
Total time taken: 7.964007616043091
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1471.687
[2,     1] loss: 1470.874
[3,     1] loss: 1474.367
[4,     1] loss: 1465.609
[5,     1] loss: 1461.337
[6,     1] loss: 1476.097
[7,     1] loss: 1472.182
[8,     1] loss: 1455.822
[9,     1] loss: 1443.007
[10,     1] loss: 1409.420
[11,     1] loss: 1350.602
[12,     1] loss: 1304.880
[13,     1] loss: 1297.809
[14,     1] loss: 1238.222
[15,     1] loss: 1339.178
[16,     1] loss: 1215.727
[17,     1] loss: 1226.017
[18,     1] loss: 1216.144
[19,     1] loss: 1222.413
[20,     1] loss: 1190.878
[21,     1] loss: 1153.572
[22,     1] loss: 1157.807
[23,     1] loss: 1190.142
[24,     1] loss: 1175.644
[25,     1] loss: 1127.349
[26,     1] loss: 1089.099
[27,     1] loss: 1105.616
[28,     1] loss: 1053.949
[29,     1] loss: 1101.070
[30,     1] loss: 1024.130
[31,     1] loss: 1019.390
[32,     1] loss: 1006.718
[33,     1] loss: 1063.744
[34,     1] loss: 1018.837
[35,     1] loss: 955.846
[36,     1] loss: 1015.364
[37,     1] loss: 1066.630
[38,     1] loss: 1009.129
[39,     1] loss: 1000.803
[40,     1] loss: 1046.457
[41,     1] loss: 972.751
[42,     1] loss: 934.227
[43,     1] loss: 925.109
[44,     1] loss: 969.047
[45,     1] loss: 1041.107
[46,     1] loss: 885.249
[47,     1] loss: 912.084
[48,     1] loss: 931.801
[49,     1] loss: 835.599
[50,     1] loss: 886.717
[51,     1] loss: 804.375
[52,     1] loss: 774.404
[53,     1] loss: 894.246
[54,     1] loss: 1023.655
[55,     1] loss: 795.413
[56,     1] loss: 851.712
[57,     1] loss: 867.976
[58,     1] loss: 774.219
[59,     1] loss: 786.512
[60,     1] loss: 779.238
[61,     1] loss: 794.328
[62,     1] loss: 831.022
[63,     1] loss: 798.010
[64,     1] loss: 799.377
[65,     1] loss: 648.528
[66,     1] loss: 744.404
Early stopping applied (best metric=0.8017840385437012)
Finished Training
Total time taken: 10.659010648727417
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1472.394
[2,     1] loss: 1485.200
[3,     1] loss: 1478.563
[4,     1] loss: 1473.830
[5,     1] loss: 1472.248
[6,     1] loss: 1463.900
[7,     1] loss: 1473.514
[8,     1] loss: 1466.399
[9,     1] loss: 1471.723
[10,     1] loss: 1472.121
[11,     1] loss: 1468.844
[12,     1] loss: 1469.798
[13,     1] loss: 1463.760
[14,     1] loss: 1456.533
[15,     1] loss: 1446.796
[16,     1] loss: 1429.095
[17,     1] loss: 1390.742
[18,     1] loss: 1367.448
[19,     1] loss: 1324.809
[20,     1] loss: 1292.293
[21,     1] loss: 1218.948
[22,     1] loss: 1226.051
[23,     1] loss: 1258.358
[24,     1] loss: 1213.900
[25,     1] loss: 1253.612
[26,     1] loss: 1181.956
[27,     1] loss: 1199.431
[28,     1] loss: 1193.625
[29,     1] loss: 1179.244
[30,     1] loss: 1153.230
[31,     1] loss: 1151.957
[32,     1] loss: 1145.193
[33,     1] loss: 1094.804
[34,     1] loss: 1105.285
[35,     1] loss: 1052.191
[36,     1] loss: 1087.030
[37,     1] loss: 1104.009
[38,     1] loss: 1104.998
[39,     1] loss: 1085.503
[40,     1] loss: 1053.999
[41,     1] loss: 1077.349
[42,     1] loss: 1038.098
[43,     1] loss: 1000.818
[44,     1] loss: 1054.350
[45,     1] loss: 1076.801
[46,     1] loss: 1063.864
[47,     1] loss: 1067.160
[48,     1] loss: 1031.663
[49,     1] loss: 993.944
[50,     1] loss: 1065.410
[51,     1] loss: 997.977
[52,     1] loss: 951.669
[53,     1] loss: 1027.080
[54,     1] loss: 921.235
[55,     1] loss: 936.848
[56,     1] loss: 924.414
[57,     1] loss: 863.086
[58,     1] loss: 878.832
[59,     1] loss: 876.654
[60,     1] loss: 977.218
[61,     1] loss: 1372.622
[62,     1] loss: 814.815
[63,     1] loss: 1140.369
[64,     1] loss: 1035.186
[65,     1] loss: 985.310
[66,     1] loss: 1056.459
[67,     1] loss: 1081.772
[68,     1] loss: 1036.104
[69,     1] loss: 967.820
Early stopping applied (best metric=0.8589776754379272)
Finished Training
Total time taken: 11.500012159347534
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1475.758
[2,     1] loss: 1471.344
[3,     1] loss: 1519.849
[4,     1] loss: 1477.295
[5,     1] loss: 1470.621
[6,     1] loss: 1475.391
[7,     1] loss: 1470.463
[8,     1] loss: 1474.773
[9,     1] loss: 1470.112
[10,     1] loss: 1470.802
[11,     1] loss: 1469.648
[12,     1] loss: 1472.068
[13,     1] loss: 1470.346
[14,     1] loss: 1469.079
[15,     1] loss: 1467.082
[16,     1] loss: 1469.394
[17,     1] loss: 1466.181
[18,     1] loss: 1461.756
[19,     1] loss: 1451.745
[20,     1] loss: 1434.449
[21,     1] loss: 1417.907
[22,     1] loss: 1392.314
[23,     1] loss: 1348.069
[24,     1] loss: 1296.221
[25,     1] loss: 1285.449
[26,     1] loss: 1282.100
[27,     1] loss: 1255.394
[28,     1] loss: 1227.302
[29,     1] loss: 1247.955
[30,     1] loss: 1196.132
[31,     1] loss: 1202.551
[32,     1] loss: 1223.788
[33,     1] loss: 1192.551
[34,     1] loss: 1217.369
[35,     1] loss: 1130.955
[36,     1] loss: 1203.738
[37,     1] loss: 1131.298
[38,     1] loss: 1151.066
[39,     1] loss: 1116.216
[40,     1] loss: 1186.332
[41,     1] loss: 1087.026
[42,     1] loss: 1156.253
[43,     1] loss: 1102.114
[44,     1] loss: 1074.193
[45,     1] loss: 1074.135
[46,     1] loss: 1023.281
[47,     1] loss: 1044.810
[48,     1] loss: 1016.259
[49,     1] loss: 1054.290
[50,     1] loss: 1033.386
[51,     1] loss: 979.160
[52,     1] loss: 1025.012
[53,     1] loss: 970.784
[54,     1] loss: 1053.228
[55,     1] loss: 968.401
[56,     1] loss: 993.199
[57,     1] loss: 1022.319
[58,     1] loss: 914.811
[59,     1] loss: 1013.213
[60,     1] loss: 925.437
[61,     1] loss: 870.529
[62,     1] loss: 1103.334
[63,     1] loss: 931.037
[64,     1] loss: 915.250
[65,     1] loss: 933.334
[66,     1] loss: 953.789
[67,     1] loss: 882.608
Early stopping applied (best metric=0.7941927909851074)
Finished Training
Total time taken: 11.189009189605713
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1476.101
[2,     1] loss: 1467.490
[3,     1] loss: 1487.338
[4,     1] loss: 1467.758
[5,     1] loss: 1471.968
[6,     1] loss: 1469.103
[7,     1] loss: 1464.639
[8,     1] loss: 1467.432
[9,     1] loss: 1460.046
[10,     1] loss: 1449.520
[11,     1] loss: 1438.910
[12,     1] loss: 1409.391
[13,     1] loss: 1369.107
[14,     1] loss: 1347.319
[15,     1] loss: 1258.943
[16,     1] loss: 1258.682
[17,     1] loss: 1218.557
[18,     1] loss: 1184.660
[19,     1] loss: 1236.065
[20,     1] loss: 1251.343
[21,     1] loss: 1285.308
[22,     1] loss: 1123.574
[23,     1] loss: 1235.798
[24,     1] loss: 1168.755
[25,     1] loss: 1195.614
[26,     1] loss: 1180.891
[27,     1] loss: 1195.800
[28,     1] loss: 1213.971
[29,     1] loss: 1138.481
[30,     1] loss: 1151.480
[31,     1] loss: 1173.902
[32,     1] loss: 1110.081
[33,     1] loss: 1169.656
[34,     1] loss: 1138.833
[35,     1] loss: 1071.860
[36,     1] loss: 1173.584
[37,     1] loss: 1049.787
[38,     1] loss: 1059.807
[39,     1] loss: 1122.760
[40,     1] loss: 1086.160
[41,     1] loss: 1029.525
[42,     1] loss: 995.397
[43,     1] loss: 1003.336
[44,     1] loss: 1005.561
[45,     1] loss: 983.699
[46,     1] loss: 878.346
[47,     1] loss: 1005.945
[48,     1] loss: 871.566
[49,     1] loss: 902.695
[50,     1] loss: 871.149
[51,     1] loss: 934.682
[52,     1] loss: 926.831
[53,     1] loss: 946.022
[54,     1] loss: 1082.010
[55,     1] loss: 912.775
[56,     1] loss: 934.674
[57,     1] loss: 876.062
[58,     1] loss: 850.969
[59,     1] loss: 811.231
[60,     1] loss: 827.993
[61,     1] loss: 834.949
[62,     1] loss: 793.881
[63,     1] loss: 781.278
Early stopping applied (best metric=0.8603427410125732)
Finished Training
Total time taken: 9.828009605407715
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1473.056
[2,     1] loss: 1473.795
[3,     1] loss: 1465.006
[4,     1] loss: 1471.438
[5,     1] loss: 1475.050
[6,     1] loss: 1475.900
[7,     1] loss: 1465.416
[8,     1] loss: 1461.074
[9,     1] loss: 1457.721
[10,     1] loss: 1448.012
[11,     1] loss: 1423.570
[12,     1] loss: 1380.393
[13,     1] loss: 1333.763
[14,     1] loss: 1278.972
[15,     1] loss: 1291.742
[16,     1] loss: 1248.693
[17,     1] loss: 1283.821
[18,     1] loss: 1203.355
[19,     1] loss: 1213.636
[20,     1] loss: 1228.585
[21,     1] loss: 1205.409
[22,     1] loss: 1201.978
[23,     1] loss: 1153.531
[24,     1] loss: 1138.837
[25,     1] loss: 1111.053
[26,     1] loss: 1116.313
[27,     1] loss: 1132.323
[28,     1] loss: 1127.371
[29,     1] loss: 1131.556
[30,     1] loss: 1058.612
[31,     1] loss: 1046.769
[32,     1] loss: 1034.813
[33,     1] loss: 1030.648
[34,     1] loss: 1050.145
[35,     1] loss: 1006.037
[36,     1] loss: 935.512
[37,     1] loss: 978.792
[38,     1] loss: 946.336
[39,     1] loss: 1001.731
[40,     1] loss: 1136.736
[41,     1] loss: 1169.492
[42,     1] loss: 941.445
[43,     1] loss: 1100.272
[44,     1] loss: 985.303
[45,     1] loss: 1022.380
[46,     1] loss: 983.499
[47,     1] loss: 909.286
[48,     1] loss: 1000.630
[49,     1] loss: 848.816
[50,     1] loss: 993.324
[51,     1] loss: 871.286
[52,     1] loss: 873.792
[53,     1] loss: 850.105
[54,     1] loss: 838.027
[55,     1] loss: 893.574
[56,     1] loss: 803.641
[57,     1] loss: 887.822
[58,     1] loss: 848.355
[59,     1] loss: 819.140
[60,     1] loss: 798.684
[61,     1] loss: 822.466
[62,     1] loss: 919.686
[63,     1] loss: 742.902
[64,     1] loss: 870.223
Early stopping applied (best metric=0.8978537321090698)
Finished Training
Total time taken: 9.122008800506592
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1469.723
[2,     1] loss: 1470.520
[3,     1] loss: 1468.868
[4,     1] loss: 1463.824
[5,     1] loss: 1468.788
[6,     1] loss: 1466.961
[7,     1] loss: 1428.057
[8,     1] loss: 1425.831
[9,     1] loss: 1358.241
[10,     1] loss: 1287.104
[11,     1] loss: 1275.796
[12,     1] loss: 1313.367
[13,     1] loss: 1246.068
[14,     1] loss: 1208.908
[15,     1] loss: 1214.656
[16,     1] loss: 1197.637
[17,     1] loss: 1185.177
[18,     1] loss: 1169.662
[19,     1] loss: 1192.185
[20,     1] loss: 1166.313
[21,     1] loss: 1160.549
[22,     1] loss: 1165.811
[23,     1] loss: 1059.986
[24,     1] loss: 1118.210
[25,     1] loss: 1084.322
[26,     1] loss: 1111.562
[27,     1] loss: 1082.759
[28,     1] loss: 1017.889
[29,     1] loss: 1045.896
[30,     1] loss: 1000.212
[31,     1] loss: 997.457
[32,     1] loss: 949.591
[33,     1] loss: 960.159
[34,     1] loss: 988.091
[35,     1] loss: 857.741
[36,     1] loss: 949.289
[37,     1] loss: 943.241
[38,     1] loss: 867.647
[39,     1] loss: 829.113
[40,     1] loss: 927.549
[41,     1] loss: 875.473
[42,     1] loss: 823.230
Early stopping applied (best metric=0.8007497191429138)
Finished Training
Total time taken: 7.047007322311401
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1465.464
[2,     1] loss: 1476.211
[3,     1] loss: 1481.079
[4,     1] loss: 1470.706
[5,     1] loss: 1463.453
[6,     1] loss: 1468.402
[7,     1] loss: 1466.439
[8,     1] loss: 1466.785
[9,     1] loss: 1454.496
[10,     1] loss: 1438.821
[11,     1] loss: 1419.985
[12,     1] loss: 1387.828
[13,     1] loss: 1343.925
[14,     1] loss: 1332.671
[15,     1] loss: 1281.967
[16,     1] loss: 1298.956
[17,     1] loss: 1244.234
[18,     1] loss: 1273.377
[19,     1] loss: 1226.908
[20,     1] loss: 1212.233
[21,     1] loss: 1255.224
[22,     1] loss: 1172.321
[23,     1] loss: 1222.054
[24,     1] loss: 1136.654
[25,     1] loss: 1120.542
[26,     1] loss: 1212.788
[27,     1] loss: 1051.685
[28,     1] loss: 1152.313
[29,     1] loss: 1130.832
[30,     1] loss: 1172.089
[31,     1] loss: 1097.458
[32,     1] loss: 1155.741
[33,     1] loss: 1081.116
[34,     1] loss: 1126.677
[35,     1] loss: 1076.823
[36,     1] loss: 1087.978
[37,     1] loss: 1018.374
[38,     1] loss: 1028.596
[39,     1] loss: 1007.385
[40,     1] loss: 1019.282
[41,     1] loss: 982.556
[42,     1] loss: 934.479
[43,     1] loss: 985.114
[44,     1] loss: 949.890
[45,     1] loss: 982.024
[46,     1] loss: 957.370
[47,     1] loss: 879.984
[48,     1] loss: 926.585
[49,     1] loss: 871.514
Early stopping applied (best metric=0.7210903167724609)
Finished Training
Total time taken: 7.614006757736206
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1475.074
[2,     1] loss: 1472.708
[3,     1] loss: 1469.599
[4,     1] loss: 1468.484
[5,     1] loss: 1474.069
[6,     1] loss: 1463.429
[7,     1] loss: 1462.777
[8,     1] loss: 1441.412
[9,     1] loss: 1403.692
[10,     1] loss: 1388.692
[11,     1] loss: 1316.845
[12,     1] loss: 1344.717
[13,     1] loss: 1297.220
[14,     1] loss: 1277.443
[15,     1] loss: 1245.038
[16,     1] loss: 1224.215
[17,     1] loss: 1245.312
[18,     1] loss: 1236.762
[19,     1] loss: 1220.903
[20,     1] loss: 1182.081
[21,     1] loss: 1194.377
[22,     1] loss: 1190.578
[23,     1] loss: 1200.615
[24,     1] loss: 1177.839
[25,     1] loss: 1109.423
[26,     1] loss: 1107.551
[27,     1] loss: 1112.011
[28,     1] loss: 1085.442
[29,     1] loss: 1036.008
[30,     1] loss: 1056.218
[31,     1] loss: 1008.326
[32,     1] loss: 979.443
[33,     1] loss: 1062.239
[34,     1] loss: 1132.181
[35,     1] loss: 1010.248
[36,     1] loss: 1036.306
[37,     1] loss: 942.804
[38,     1] loss: 939.340
[39,     1] loss: 933.135
[40,     1] loss: 875.958
[41,     1] loss: 927.904
[42,     1] loss: 857.534
[43,     1] loss: 862.725
[44,     1] loss: 830.200
Early stopping applied (best metric=0.8466484546661377)
Finished Training
Total time taken: 6.02900505065918
{'Hydroxylation-K Validation Accuracy': 0.7941193853427896, 'Hydroxylation-K Validation Sensitivity': 0.6940740740740741, 'Hydroxylation-K Validation Specificity': 0.8192982456140351, 'Hydroxylation-K Validation Precision': 0.5194095773507538, 'Hydroxylation-K AUC ROC': 0.824990253411306, 'Hydroxylation-K AUC PR': 0.6287334282611469, 'Hydroxylation-K MCC': 0.4699004299344789, 'Hydroxylation-K F1': 0.5821489998436432, 'Validation Loss (Hydroxylation-K)': 0.4090874433517456, 'Hydroxylation-P Validation Accuracy': 0.7953179872426104, 'Hydroxylation-P Validation Sensitivity': 0.7761904761904762, 'Hydroxylation-P Validation Specificity': 0.7993690458376976, 'Hydroxylation-P Validation Precision': 0.4655809976509762, 'Hydroxylation-P AUC ROC': 0.8402535098532405, 'Hydroxylation-P AUC PR': 0.603079337805629, 'Hydroxylation-P MCC': 0.4846880752449589, 'Hydroxylation-P F1': 0.5776144161222632, 'Validation Loss (Hydroxylation-P)': 0.3771173338095347, 'Validation Loss (total)': 0.7862047791481018, 'TimeToTrain': 9.545475896199545}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011481345306532855,
 'learning_rate_Hydroxylation-K': 0.006361276288871981,
 'learning_rate_Hydroxylation-P': 0.005469046375470224,
 'log_base': 2.5727041888549853,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 200123407,
 'sample_weights': [2.667172742778553, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.055873816086639,
 'weight_decay_Hydroxylation-K': 3.9340935341039174,
 'weight_decay_Hydroxylation-P': 9.36590634552335}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1279.608
[2,     1] loss: 1281.552
[3,     1] loss: 1280.786
[4,     1] loss: 1278.431
[5,     1] loss: 1278.416
[6,     1] loss: 1277.617
[7,     1] loss: 1272.157
[8,     1] loss: 1262.550
[9,     1] loss: 1260.128
[10,     1] loss: 1232.119
[11,     1] loss: 1213.535
[12,     1] loss: 1196.532
[13,     1] loss: 1169.908
[14,     1] loss: 1136.600
[15,     1] loss: 1132.501
[16,     1] loss: 1121.440
[17,     1] loss: 1102.205
[18,     1] loss: 1074.781
[19,     1] loss: 1056.911
[20,     1] loss: 1104.021
[21,     1] loss: 1022.243
[22,     1] loss: 1069.072
[23,     1] loss: 1053.346
[24,     1] loss: 1061.483
[25,     1] loss: 1040.215
[26,     1] loss: 1074.953
[27,     1] loss: 1086.160
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020757990571751966,
 'learning_rate_Hydroxylation-K': 0.0011470075219086966,
 'learning_rate_Hydroxylation-P': 0.008198856014316457,
 'log_base': 2.589364547187615,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2669319322,
 'sample_weights': [1.7666858485098982, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.511898245758791,
 'weight_decay_Hydroxylation-K': 4.043144589615666,
 'weight_decay_Hydroxylation-P': 1.5308441239529234}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1291.400
[2,     1] loss: 1279.616
[3,     1] loss: 1290.607
[4,     1] loss: 1277.536
[5,     1] loss: 1275.160
[6,     1] loss: 1277.987
[7,     1] loss: 1277.259
[8,     1] loss: 1270.591
[9,     1] loss: 1261.510
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004175316592012913,
 'learning_rate_Hydroxylation-K': 0.007291295932211762,
 'learning_rate_Hydroxylation-P': 0.003403311297501249,
 'log_base': 2.6388835376511595,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1233700181,
 'sample_weights': [1.7546996204390908, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4113513650503893,
 'weight_decay_Hydroxylation-K': 5.72284816099592,
 'weight_decay_Hydroxylation-P': 1.4189155690137627}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1280.583
[2,     1] loss: 1284.192
[3,     1] loss: 1274.984
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002738237379665316,
 'learning_rate_Hydroxylation-K': 0.002173059800847942,
 'learning_rate_Hydroxylation-P': 0.0020575598493734124,
 'log_base': 2.994423800561999,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1383138488,
 'sample_weights': [1.720444121469218, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.3664814843177333,
 'weight_decay_Hydroxylation-K': 3.0838952100038037,
 'weight_decay_Hydroxylation-P': 1.5951969526067549}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.410
[2,     1] loss: 1232.417
[3,     1] loss: 1227.956
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030005748194908426,
 'learning_rate_Hydroxylation-K': 0.005175605700208692,
 'learning_rate_Hydroxylation-P': 0.008491683792413753,
 'log_base': 1.0418146536784836,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1021582435,
 'sample_weights': [1.5221703834427822, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.76788809302166,
 'weight_decay_Hydroxylation-K': 1.9822040485949362,
 'weight_decay_Hydroxylation-P': 4.3993177321333325}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 13213.960
[2,     1] loss: 13252.248
[3,     1] loss: 13284.346
[4,     1] loss: 13251.528
[5,     1] loss: 13218.838
[6,     1] loss: 13206.996
[7,     1] loss: 13154.951
[8,     1] loss: 13117.141
[9,     1] loss: 13133.502
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0029803519190286015,
 'learning_rate_Hydroxylation-K': 0.0016876051614457238,
 'learning_rate_Hydroxylation-P': 0.005979785525137685,
 'log_base': 2.5673166774057656,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3379683338,
 'sample_weights': [40.75385777301932, 5.094428471909139],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.351519872144106,
 'weight_decay_Hydroxylation-K': 1.9655709303045656,
 'weight_decay_Hydroxylation-P': 2.928552340669764}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1281.369
[2,     1] loss: 1283.535
[3,     1] loss: 1283.497
[4,     1] loss: 1279.127
[5,     1] loss: 1282.978
[6,     1] loss: 1271.077
[7,     1] loss: 1257.302
[8,     1] loss: 1238.587
[9,     1] loss: 1217.604
[10,     1] loss: 1184.129
[11,     1] loss: 1135.012
[12,     1] loss: 1135.281
[13,     1] loss: 1078.026
[14,     1] loss: 1130.476
[15,     1] loss: 1062.295
[16,     1] loss: 1154.304
[17,     1] loss: 1053.887
[18,     1] loss: 1074.386
[19,     1] loss: 1091.073
[20,     1] loss: 1036.018
[21,     1] loss: 1043.443
[22,     1] loss: 1036.633
[23,     1] loss: 1017.277
[24,     1] loss: 1055.985
[25,     1] loss: 1015.117
[26,     1] loss: 1012.672
[27,     1] loss: 1007.674
[28,     1] loss: 999.718
[29,     1] loss: 990.792
[30,     1] loss: 1009.934
[31,     1] loss: 946.620
[32,     1] loss: 919.378
[33,     1] loss: 932.555
[34,     1] loss: 905.095
[35,     1] loss: 967.854
[36,     1] loss: 890.392
[37,     1] loss: 893.052
[38,     1] loss: 932.624
[39,     1] loss: 921.852
[40,     1] loss: 882.892
[41,     1] loss: 883.880
[42,     1] loss: 907.050
[43,     1] loss: 878.734
[44,     1] loss: 887.983
[45,     1] loss: 809.049
[46,     1] loss: 825.337
[47,     1] loss: 863.861
[48,     1] loss: 799.280
[49,     1] loss: 826.297
[50,     1] loss: 802.199
[51,     1] loss: 790.722
[52,     1] loss: 806.942
[53,     1] loss: 765.734
[54,     1] loss: 783.934
[55,     1] loss: 733.761
[56,     1] loss: 717.426
[57,     1] loss: 736.827
[58,     1] loss: 789.184
[59,     1] loss: 817.245
[60,     1] loss: 719.583
[61,     1] loss: 768.676
[62,     1] loss: 713.864
[63,     1] loss: 661.887
[64,     1] loss: 725.735
[65,     1] loss: 672.925
[66,     1] loss: 728.848
[67,     1] loss: 672.777
[68,     1] loss: 716.466
[69,     1] loss: 818.426
[70,     1] loss: 631.008
[71,     1] loss: 752.203
[72,     1] loss: 652.159
[73,     1] loss: 707.800
[74,     1] loss: 672.899
[75,     1] loss: 620.170
[76,     1] loss: 704.278
[77,     1] loss: 609.273
[78,     1] loss: 647.429
[79,     1] loss: 577.894
[80,     1] loss: 647.769
[81,     1] loss: 593.615
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003127315074144215,
 'learning_rate_Hydroxylation-K': 0.0023088921816529634,
 'learning_rate_Hydroxylation-P': 0.00607269533972769,
 'log_base': 2.7109965993173937,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3819676084,
 'sample_weights': [1.7706137900681282, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.8961622912808385,
 'weight_decay_Hydroxylation-K': 1.679325943792065,
 'weight_decay_Hydroxylation-P': 4.293491006073466}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1263.220
[2,     1] loss: 1265.063
[3,     1] loss: 1267.642
[4,     1] loss: 1259.161
[5,     1] loss: 1252.868
[6,     1] loss: 1247.347
[7,     1] loss: 1236.188
[8,     1] loss: 1206.277
[9,     1] loss: 1156.532
[10,     1] loss: 1133.107
[11,     1] loss: 1103.267
[12,     1] loss: 1077.779
[13,     1] loss: 1121.024
[14,     1] loss: 1099.323
[15,     1] loss: 1033.920
[16,     1] loss: 1034.174
[17,     1] loss: 1010.914
[18,     1] loss: 1034.368
[19,     1] loss: 1028.177
[20,     1] loss: 1009.503
[21,     1] loss: 1011.825
[22,     1] loss: 1008.418
[23,     1] loss: 999.599
[24,     1] loss: 995.287
[25,     1] loss: 997.430
[26,     1] loss: 973.316
[27,     1] loss: 977.824
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006842566954650891,
 'learning_rate_Hydroxylation-K': 0.009666635659983392,
 'learning_rate_Hydroxylation-P': 0.0052180064090505945,
 'log_base': 1.5010557067325392,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2736305209,
 'sample_weights': [1.6739354610463681, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.135875282819465,
 'weight_decay_Hydroxylation-K': 7.433226238710407,
 'weight_decay_Hydroxylation-P': 6.6784714197787665}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1775.964
[2,     1] loss: 1780.973
[3,     1] loss: 1780.097
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031982383578738637,
 'learning_rate_Hydroxylation-K': 0.0018465976699141048,
 'learning_rate_Hydroxylation-P': 0.006820036250775827,
 'log_base': 2.5362253406970323,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2602079354,
 'sample_weights': [4.1102214205762175, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.130000888863195,
 'weight_decay_Hydroxylation-K': 1.3963787517646038,
 'weight_decay_Hydroxylation-P': 2.674979278742078}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1293.167
[2,     1] loss: 1299.577
[3,     1] loss: 1287.061
[4,     1] loss: 1282.959
[5,     1] loss: 1279.681
[6,     1] loss: 1295.036
[7,     1] loss: 1280.345
[8,     1] loss: 1284.216
[9,     1] loss: 1284.197
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006477735468499915,
 'learning_rate_Hydroxylation-K': 0.006983355553992442,
 'learning_rate_Hydroxylation-P': 0.00599086253651265,
 'log_base': 2.7729614341905586,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2907668427,
 'sample_weights': [1.7937945666140103, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.799628324158109,
 'weight_decay_Hydroxylation-K': 9.271191049265397,
 'weight_decay_Hydroxylation-P': 6.9659990496120034}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1254.509
[2,     1] loss: 1258.625
[3,     1] loss: 1259.084
[4,     1] loss: 1252.921
[5,     1] loss: 1254.218
[6,     1] loss: 1254.754
[7,     1] loss: 1251.734
[8,     1] loss: 1248.850
[9,     1] loss: 1255.102
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005385051049341829,
 'learning_rate_Hydroxylation-K': 0.0025030695552387813,
 'learning_rate_Hydroxylation-P': 0.0075514125798584394,
 'log_base': 1.9332296774253073,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1279210459,
 'sample_weights': [1.6368439933703958, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.366155297522783,
 'weight_decay_Hydroxylation-K': 4.2801867051533,
 'weight_decay_Hydroxylation-P': 5.628973911675934}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1443.374
[2,     1] loss: 1465.007
[3,     1] loss: 1438.400
[4,     1] loss: 1439.988
[5,     1] loss: 1440.255
[6,     1] loss: 1440.959
[7,     1] loss: 1443.132
[8,     1] loss: 1429.528
[9,     1] loss: 1437.365
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006393793986513789,
 'learning_rate_Hydroxylation-K': 0.0027371097163329844,
 'learning_rate_Hydroxylation-P': 0.007730931715212816,
 'log_base': 2.419669372046926,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4007215544,
 'sample_weights': [2.5325597340642285, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.9711485177294676,
 'weight_decay_Hydroxylation-K': 2.182858962550363,
 'weight_decay_Hydroxylation-P': 2.666641178368168}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1310.482
[2,     1] loss: 1310.049
[3,     1] loss: 1297.571
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030995259302656806,
 'learning_rate_Hydroxylation-K': 0.0026081103612033666,
 'learning_rate_Hydroxylation-P': 0.005051899678876097,
 'log_base': 2.974954988186811,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 420340330,
 'sample_weights': [1.8892991778017074, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.415442838913588,
 'weight_decay_Hydroxylation-K': 2.801328935249116,
 'weight_decay_Hydroxylation-P': 4.190078770756686}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.689
[2,     1] loss: 1232.349
[3,     1] loss: 1229.869
[4,     1] loss: 1222.525
[5,     1] loss: 1222.172
[6,     1] loss: 1201.929
[7,     1] loss: 1161.660
[8,     1] loss: 1147.300
[9,     1] loss: 1100.168
[10,     1] loss: 1064.909
[11,     1] loss: 1034.295
[12,     1] loss: 999.006
[13,     1] loss: 1041.449
[14,     1] loss: 1016.239
[15,     1] loss: 1001.892
[16,     1] loss: 1021.489
[17,     1] loss: 972.918
[18,     1] loss: 994.324
[19,     1] loss: 981.064
[20,     1] loss: 974.426
[21,     1] loss: 972.287
[22,     1] loss: 927.450
[23,     1] loss: 947.506
[24,     1] loss: 930.348
[25,     1] loss: 939.760
[26,     1] loss: 897.880
[27,     1] loss: 850.475
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0052216916800974416,
 'learning_rate_Hydroxylation-K': 0.0010003768001441162,
 'learning_rate_Hydroxylation-P': 0.0079169254919258,
 'log_base': 2.396277434492703,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1516751007,
 'sample_weights': [1.5312776370665406, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8635540806265194,
 'weight_decay_Hydroxylation-K': 1.3545918923698625,
 'weight_decay_Hydroxylation-P': 5.071640316859859}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1313.486
[2,     1] loss: 1321.086
[3,     1] loss: 1313.854
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00489510379049152,
 'learning_rate_Hydroxylation-K': 0.002609599567278895,
 'learning_rate_Hydroxylation-P': 0.004276211605475351,
 'log_base': 2.6553349565057247,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1175171111,
 'sample_weights': [1.9103006016438542, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.023660283793146,
 'weight_decay_Hydroxylation-K': 1.0783469638642247,
 'weight_decay_Hydroxylation-P': 4.62478180559598}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1272.925
[2,     1] loss: 1273.613
[3,     1] loss: 1267.837
[4,     1] loss: 1273.119
[5,     1] loss: 1267.489
[6,     1] loss: 1266.469
[7,     1] loss: 1263.791
[8,     1] loss: 1267.817
[9,     1] loss: 1263.317
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002482302964428079,
 'learning_rate_Hydroxylation-K': 0.0014482205112684712,
 'learning_rate_Hydroxylation-P': 0.003458672298254038,
 'log_base': 2.4170738072577365,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 358406623,
 'sample_weights': [1.7094952407031743, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.626171439214886,
 'weight_decay_Hydroxylation-K': 5.947252231204768,
 'weight_decay_Hydroxylation-P': 0.5920044635366941}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1306.216
[2,     1] loss: 1307.346
[3,     1] loss: 1300.845
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002819182425135247,
 'learning_rate_Hydroxylation-K': 0.00976474701271353,
 'learning_rate_Hydroxylation-P': 0.0012470845987808453,
 'log_base': 2.2987040016433262,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1242835982,
 'sample_weights': [1.8915967361062633, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.89831776675784,
 'weight_decay_Hydroxylation-K': 2.6507479331866586,
 'weight_decay_Hydroxylation-P': 1.9342008054855127}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1330.427
[2,     1] loss: 1339.541
[3,     1] loss: 1336.817
[4,     1] loss: 1329.057
[5,     1] loss: 1329.053
[6,     1] loss: 1328.762
[7,     1] loss: 1329.731
[8,     1] loss: 1333.817
[9,     1] loss: 1325.402
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007889117140018312,
 'learning_rate_Hydroxylation-K': 0.006865171980707116,
 'learning_rate_Hydroxylation-P': 0.005196934983956736,
 'log_base': 1.0451410241136079,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 414183380,
 'sample_weights': [2.005709377114596, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8730574902004031,
 'weight_decay_Hydroxylation-K': 0.12959780232459406,
 'weight_decay_Hydroxylation-P': 0.13407999975391982}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 12214.141
[2,     1] loss: 12316.844
[3,     1] loss: 12253.152
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004884319121536182,
 'learning_rate_Hydroxylation-K': 0.003731690912553525,
 'learning_rate_Hydroxylation-P': 0.0043710434635619595,
 'log_base': 2.5184787258467276,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1677019709,
 'sample_weights': [37.81141659462677, 4.726609155278827],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2210039170929328,
 'weight_decay_Hydroxylation-K': 4.372713172070321,
 'weight_decay_Hydroxylation-P': 2.338744649903835}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1292.278
[2,     1] loss: 1288.333
[3,     1] loss: 1292.738
[4,     1] loss: 1287.710
[5,     1] loss: 1281.188
[6,     1] loss: 1276.601
[7,     1] loss: 1251.912
[8,     1] loss: 1214.973
[9,     1] loss: 1164.882
[10,     1] loss: 1177.860
[11,     1] loss: 1145.340
[12,     1] loss: 1087.569
[13,     1] loss: 1132.493
[14,     1] loss: 1032.796
[15,     1] loss: 1077.610
[16,     1] loss: 1046.190
[17,     1] loss: 1087.301
[18,     1] loss: 1059.207
[19,     1] loss: 1041.000
[20,     1] loss: 1017.706
[21,     1] loss: 1008.639
[22,     1] loss: 1035.723
[23,     1] loss: 997.439
[24,     1] loss: 1015.350
[25,     1] loss: 979.205
[26,     1] loss: 981.967
[27,     1] loss: 923.635
[28,     1] loss: 956.270
[29,     1] loss: 956.242
[30,     1] loss: 935.362
[31,     1] loss: 914.108
[32,     1] loss: 905.311
[33,     1] loss: 908.059
[34,     1] loss: 898.900
[35,     1] loss: 915.601
[36,     1] loss: 855.968
[37,     1] loss: 926.448
[38,     1] loss: 861.396
[39,     1] loss: 914.866
[40,     1] loss: 864.863
[41,     1] loss: 841.269
[42,     1] loss: 867.569
[43,     1] loss: 808.628
[44,     1] loss: 903.321
[45,     1] loss: 802.109
[46,     1] loss: 855.475
[47,     1] loss: 836.974
[48,     1] loss: 777.931
[49,     1] loss: 756.085
[50,     1] loss: 761.524
[51,     1] loss: 694.459
[52,     1] loss: 708.673
[53,     1] loss: 762.579
[54,     1] loss: 761.702
[55,     1] loss: 677.430
[56,     1] loss: 705.367
[57,     1] loss: 674.147
[58,     1] loss: 690.330
[59,     1] loss: 647.667
[60,     1] loss: 625.088
[61,     1] loss: 692.514
[62,     1] loss: 822.735
[63,     1] loss: 862.077
[64,     1] loss: 673.967
[65,     1] loss: 745.573
[66,     1] loss: 670.868
[67,     1] loss: 773.672
[68,     1] loss: 605.494
[69,     1] loss: 664.822
[70,     1] loss: 621.100
[71,     1] loss: 659.434
[72,     1] loss: 584.639
Early stopping applied (best metric=0.7274597883224487)
Finished Training
Total time taken: 11.012011528015137
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1293.660
[2,     1] loss: 1295.863
[3,     1] loss: 1287.844
[4,     1] loss: 1288.295
[5,     1] loss: 1287.836
[6,     1] loss: 1291.046
[7,     1] loss: 1286.738
[8,     1] loss: 1285.360
[9,     1] loss: 1283.374
[10,     1] loss: 1274.302
[11,     1] loss: 1255.976
[12,     1] loss: 1218.577
[13,     1] loss: 1181.598
[14,     1] loss: 1146.757
[15,     1] loss: 1080.734
[16,     1] loss: 1079.046
[17,     1] loss: 1059.020
[18,     1] loss: 1035.796
[19,     1] loss: 1079.109
[20,     1] loss: 1028.197
[21,     1] loss: 1027.670
[22,     1] loss: 1026.883
[23,     1] loss: 1052.873
[24,     1] loss: 955.105
[25,     1] loss: 1006.608
[26,     1] loss: 986.705
[27,     1] loss: 967.561
[28,     1] loss: 945.906
[29,     1] loss: 963.304
[30,     1] loss: 948.987
[31,     1] loss: 936.843
[32,     1] loss: 895.961
[33,     1] loss: 926.177
[34,     1] loss: 887.300
[35,     1] loss: 918.783
[36,     1] loss: 910.517
[37,     1] loss: 921.371
[38,     1] loss: 899.847
[39,     1] loss: 866.690
[40,     1] loss: 864.708
[41,     1] loss: 849.905
[42,     1] loss: 862.909
[43,     1] loss: 867.660
[44,     1] loss: 828.441
[45,     1] loss: 1045.296
[46,     1] loss: 816.720
[47,     1] loss: 983.448
[48,     1] loss: 836.386
[49,     1] loss: 975.141
[50,     1] loss: 848.491
[51,     1] loss: 848.057
[52,     1] loss: 871.806
[53,     1] loss: 790.226
[54,     1] loss: 796.184
[55,     1] loss: 880.526
[56,     1] loss: 802.751
[57,     1] loss: 811.918
[58,     1] loss: 802.922
[59,     1] loss: 758.400
[60,     1] loss: 800.232
[61,     1] loss: 765.147
[62,     1] loss: 702.758
[63,     1] loss: 755.509
[64,     1] loss: 756.570
[65,     1] loss: 703.460
[66,     1] loss: 746.615
[67,     1] loss: 654.118
[68,     1] loss: 686.560
[69,     1] loss: 687.480
[70,     1] loss: 696.921
[71,     1] loss: 659.350
[72,     1] loss: 641.850
[73,     1] loss: 578.958
[74,     1] loss: 595.854
[75,     1] loss: 623.280
[76,     1] loss: 593.894
[77,     1] loss: 517.802
[78,     1] loss: 577.746
[79,     1] loss: 590.763
[80,     1] loss: 530.519
[81,     1] loss: 505.027
[82,     1] loss: 543.140
[83,     1] loss: 571.044
[84,     1] loss: 541.960
[85,     1] loss: 504.458
[86,     1] loss: 511.287
[87,     1] loss: 510.349
[88,     1] loss: 472.016
[89,     1] loss: 559.878
[90,     1] loss: 515.223
[91,     1] loss: 557.016
[92,     1] loss: 522.713
[93,     1] loss: 419.121
[94,     1] loss: 467.287
[95,     1] loss: 513.592
[96,     1] loss: 498.288
[97,     1] loss: 449.900
[98,     1] loss: 421.191
[99,     1] loss: 427.038
[100,     1] loss: 417.966
[101,     1] loss: 415.864
[102,     1] loss: 392.268
[103,     1] loss: 381.494
[104,     1] loss: 503.312
[105,     1] loss: 473.934
[106,     1] loss: 366.554
[107,     1] loss: 408.710
[108,     1] loss: 452.464
[109,     1] loss: 395.584
[110,     1] loss: 419.579
Early stopping applied (best metric=0.8277816772460938)
Finished Training
Total time taken: 17.062016010284424
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1289.804
[2,     1] loss: 1293.875
[3,     1] loss: 1290.458
[4,     1] loss: 1290.158
[5,     1] loss: 1284.859
[6,     1] loss: 1282.608
[7,     1] loss: 1273.404
[8,     1] loss: 1250.422
[9,     1] loss: 1212.432
[10,     1] loss: 1166.134
[11,     1] loss: 1127.815
[12,     1] loss: 1104.344
[13,     1] loss: 1089.177
[14,     1] loss: 1054.182
[15,     1] loss: 1038.707
[16,     1] loss: 1060.993
[17,     1] loss: 1013.535
[18,     1] loss: 1014.916
[19,     1] loss: 983.787
[20,     1] loss: 987.337
[21,     1] loss: 987.982
[22,     1] loss: 1009.514
[23,     1] loss: 976.670
[24,     1] loss: 986.628
[25,     1] loss: 957.036
[26,     1] loss: 1008.797
[27,     1] loss: 989.345
[28,     1] loss: 989.202
[29,     1] loss: 918.827
[30,     1] loss: 954.787
[31,     1] loss: 917.077
[32,     1] loss: 928.799
[33,     1] loss: 913.904
[34,     1] loss: 918.659
[35,     1] loss: 891.734
[36,     1] loss: 931.419
[37,     1] loss: 904.929
[38,     1] loss: 904.383
[39,     1] loss: 880.178
[40,     1] loss: 848.660
[41,     1] loss: 777.025
[42,     1] loss: 807.967
[43,     1] loss: 849.219
[44,     1] loss: 805.628
[45,     1] loss: 859.544
[46,     1] loss: 779.148
[47,     1] loss: 764.901
[48,     1] loss: 815.546
[49,     1] loss: 767.063
[50,     1] loss: 759.908
[51,     1] loss: 727.829
[52,     1] loss: 705.830
[53,     1] loss: 689.252
[54,     1] loss: 767.554
[55,     1] loss: 677.868
[56,     1] loss: 655.136
[57,     1] loss: 676.334
[58,     1] loss: 639.392
[59,     1] loss: 667.904
[60,     1] loss: 713.344
Early stopping applied (best metric=0.7222090363502502)
Finished Training
Total time taken: 9.29601001739502
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1292.414
[2,     1] loss: 1288.180
[3,     1] loss: 1291.509
[4,     1] loss: 1286.855
[5,     1] loss: 1290.388
[6,     1] loss: 1287.829
[7,     1] loss: 1283.353
[8,     1] loss: 1271.919
[9,     1] loss: 1263.525
[10,     1] loss: 1234.537
[11,     1] loss: 1184.380
[12,     1] loss: 1197.187
[13,     1] loss: 1180.846
[14,     1] loss: 1151.079
[15,     1] loss: 1145.224
[16,     1] loss: 1124.919
[17,     1] loss: 1097.674
[18,     1] loss: 1097.230
[19,     1] loss: 1062.463
[20,     1] loss: 1135.786
[21,     1] loss: 1075.926
[22,     1] loss: 1051.071
[23,     1] loss: 1085.108
[24,     1] loss: 1056.159
[25,     1] loss: 1016.641
[26,     1] loss: 1048.568
[27,     1] loss: 1031.122
[28,     1] loss: 1003.164
[29,     1] loss: 976.786
[30,     1] loss: 1024.856
[31,     1] loss: 984.781
[32,     1] loss: 1005.994
[33,     1] loss: 932.753
[34,     1] loss: 962.131
[35,     1] loss: 941.706
[36,     1] loss: 942.151
[37,     1] loss: 980.896
[38,     1] loss: 894.210
[39,     1] loss: 886.851
[40,     1] loss: 934.464
[41,     1] loss: 925.341
[42,     1] loss: 909.399
[43,     1] loss: 899.411
[44,     1] loss: 854.580
[45,     1] loss: 888.100
[46,     1] loss: 828.624
[47,     1] loss: 852.147
[48,     1] loss: 776.371
[49,     1] loss: 886.781
[50,     1] loss: 889.642
[51,     1] loss: 798.735
[52,     1] loss: 816.697
[53,     1] loss: 865.818
[54,     1] loss: 751.728
[55,     1] loss: 789.640
[56,     1] loss: 692.126
[57,     1] loss: 761.667
[58,     1] loss: 715.993
[59,     1] loss: 669.813
[60,     1] loss: 708.595
[61,     1] loss: 713.475
[62,     1] loss: 674.437
[63,     1] loss: 706.830
[64,     1] loss: 706.318
Early stopping applied (best metric=0.7582618594169617)
Finished Training
Total time taken: 9.534009456634521
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1293.189
[2,     1] loss: 1302.204
[3,     1] loss: 1287.461
[4,     1] loss: 1298.761
[5,     1] loss: 1290.880
[6,     1] loss: 1283.591
[7,     1] loss: 1284.825
[8,     1] loss: 1262.965
[9,     1] loss: 1241.063
[10,     1] loss: 1205.396
[11,     1] loss: 1156.755
[12,     1] loss: 1093.173
[13,     1] loss: 1073.422
[14,     1] loss: 1088.303
[15,     1] loss: 1100.218
[16,     1] loss: 1044.097
[17,     1] loss: 1094.055
[18,     1] loss: 1028.412
[19,     1] loss: 1025.200
[20,     1] loss: 1022.337
[21,     1] loss: 1027.107
[22,     1] loss: 1006.419
[23,     1] loss: 975.522
[24,     1] loss: 991.514
[25,     1] loss: 958.849
[26,     1] loss: 924.954
[27,     1] loss: 954.702
[28,     1] loss: 944.324
[29,     1] loss: 919.362
[30,     1] loss: 922.379
[31,     1] loss: 988.822
[32,     1] loss: 930.868
[33,     1] loss: 904.215
[34,     1] loss: 925.589
[35,     1] loss: 900.692
[36,     1] loss: 970.511
[37,     1] loss: 866.099
[38,     1] loss: 925.254
[39,     1] loss: 911.816
[40,     1] loss: 888.736
[41,     1] loss: 880.680
[42,     1] loss: 875.997
[43,     1] loss: 826.964
[44,     1] loss: 858.304
Early stopping applied (best metric=0.9596275091171265)
Finished Training
Total time taken: 7.234008312225342
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1294.252
[2,     1] loss: 1292.353
[3,     1] loss: 1307.312
[4,     1] loss: 1286.262
[5,     1] loss: 1293.231
[6,     1] loss: 1290.311
[7,     1] loss: 1287.178
[8,     1] loss: 1283.756
[9,     1] loss: 1280.390
[10,     1] loss: 1280.226
[11,     1] loss: 1271.588
[12,     1] loss: 1248.118
[13,     1] loss: 1224.551
[14,     1] loss: 1189.273
[15,     1] loss: 1157.274
[16,     1] loss: 1144.332
[17,     1] loss: 1153.598
[18,     1] loss: 1098.283
[19,     1] loss: 1106.951
[20,     1] loss: 1049.794
[21,     1] loss: 1128.796
[22,     1] loss: 1054.563
[23,     1] loss: 1161.073
[24,     1] loss: 1076.741
[25,     1] loss: 1069.981
[26,     1] loss: 1050.655
[27,     1] loss: 1014.169
[28,     1] loss: 1000.529
[29,     1] loss: 983.980
[30,     1] loss: 975.952
[31,     1] loss: 977.373
[32,     1] loss: 959.823
[33,     1] loss: 916.186
[34,     1] loss: 954.078
[35,     1] loss: 940.917
[36,     1] loss: 958.943
[37,     1] loss: 938.739
[38,     1] loss: 923.531
[39,     1] loss: 900.728
[40,     1] loss: 959.125
[41,     1] loss: 900.740
[42,     1] loss: 892.075
[43,     1] loss: 898.059
[44,     1] loss: 852.854
[45,     1] loss: 869.555
[46,     1] loss: 937.508
[47,     1] loss: 852.187
[48,     1] loss: 841.389
[49,     1] loss: 847.358
[50,     1] loss: 821.154
[51,     1] loss: 785.824
[52,     1] loss: 777.111
[53,     1] loss: 782.143
[54,     1] loss: 802.556
[55,     1] loss: 928.106
[56,     1] loss: 799.825
[57,     1] loss: 768.131
[58,     1] loss: 822.678
[59,     1] loss: 811.589
[60,     1] loss: 775.492
[61,     1] loss: 727.589
[62,     1] loss: 758.187
[63,     1] loss: 781.279
[64,     1] loss: 752.286
[65,     1] loss: 697.883
[66,     1] loss: 712.023
[67,     1] loss: 707.974
[68,     1] loss: 620.019
[69,     1] loss: 685.530
[70,     1] loss: 658.692
[71,     1] loss: 652.228
Early stopping applied (best metric=0.8867607712745667)
Finished Training
Total time taken: 11.721012353897095
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1298.255
[2,     1] loss: 1302.516
[3,     1] loss: 1290.398
[4,     1] loss: 1290.565
[5,     1] loss: 1290.874
[6,     1] loss: 1290.617
[7,     1] loss: 1288.043
[8,     1] loss: 1286.068
[9,     1] loss: 1289.015
[10,     1] loss: 1290.878
[11,     1] loss: 1291.190
[12,     1] loss: 1284.385
[13,     1] loss: 1284.688
[14,     1] loss: 1281.202
[15,     1] loss: 1281.913
[16,     1] loss: 1276.333
[17,     1] loss: 1264.943
[18,     1] loss: 1247.414
[19,     1] loss: 1229.952
[20,     1] loss: 1190.070
[21,     1] loss: 1177.659
[22,     1] loss: 1112.078
[23,     1] loss: 1157.362
[24,     1] loss: 1133.977
[25,     1] loss: 1146.627
[26,     1] loss: 1112.282
[27,     1] loss: 1073.105
[28,     1] loss: 1095.631
[29,     1] loss: 1085.052
[30,     1] loss: 1062.741
[31,     1] loss: 1033.790
[32,     1] loss: 1051.643
[33,     1] loss: 1049.315
[34,     1] loss: 1043.524
[35,     1] loss: 1027.262
[36,     1] loss: 994.176
[37,     1] loss: 1022.178
[38,     1] loss: 997.858
[39,     1] loss: 979.420
[40,     1] loss: 990.253
[41,     1] loss: 971.447
[42,     1] loss: 1010.824
[43,     1] loss: 985.381
[44,     1] loss: 976.943
[45,     1] loss: 936.105
[46,     1] loss: 963.683
[47,     1] loss: 954.758
[48,     1] loss: 981.922
[49,     1] loss: 931.583
[50,     1] loss: 953.625
[51,     1] loss: 907.659
[52,     1] loss: 969.241
[53,     1] loss: 929.396
[54,     1] loss: 966.737
[55,     1] loss: 888.370
[56,     1] loss: 837.122
[57,     1] loss: 854.987
[58,     1] loss: 900.850
[59,     1] loss: 844.500
[60,     1] loss: 856.775
[61,     1] loss: 838.538
[62,     1] loss: 833.288
[63,     1] loss: 880.952
[64,     1] loss: 854.101
[65,     1] loss: 943.301
[66,     1] loss: 1012.770
[67,     1] loss: 813.842
[68,     1] loss: 983.543
[69,     1] loss: 809.718
[70,     1] loss: 907.303
[71,     1] loss: 786.667
[72,     1] loss: 804.091
[73,     1] loss: 870.805
[74,     1] loss: 755.131
[75,     1] loss: 811.704
[76,     1] loss: 754.196
[77,     1] loss: 744.038
[78,     1] loss: 751.580
[79,     1] loss: 784.181
[80,     1] loss: 692.456
[81,     1] loss: 768.732
[82,     1] loss: 726.840
[83,     1] loss: 762.598
[84,     1] loss: 678.523
[85,     1] loss: 735.284
[86,     1] loss: 709.407
[87,     1] loss: 716.892
[88,     1] loss: 650.818
[89,     1] loss: 655.073
[90,     1] loss: 647.069
[91,     1] loss: 616.107
[92,     1] loss: 742.577
[93,     1] loss: 741.156
[94,     1] loss: 624.967
[95,     1] loss: 674.360
[96,     1] loss: 583.391
[97,     1] loss: 614.852
[98,     1] loss: 578.155
[99,     1] loss: 516.353
[100,     1] loss: 580.554
[101,     1] loss: 576.250
[102,     1] loss: 605.169
[103,     1] loss: 504.310
[104,     1] loss: 477.179
[105,     1] loss: 550.076
[106,     1] loss: 495.562
[107,     1] loss: 527.014
[108,     1] loss: 512.651
[109,     1] loss: 484.485
[110,     1] loss: 494.997
[111,     1] loss: 544.706
[112,     1] loss: 482.001
[113,     1] loss: 533.365
[114,     1] loss: 490.956
[115,     1] loss: 458.974
[116,     1] loss: 523.354
[117,     1] loss: 704.034
[118,     1] loss: 652.478
[119,     1] loss: 485.357
[120,     1] loss: 574.887
[121,     1] loss: 480.183
[122,     1] loss: 561.074
[123,     1] loss: 512.610
[124,     1] loss: 528.312
[125,     1] loss: 445.561
[126,     1] loss: 521.473
[127,     1] loss: 549.038
[128,     1] loss: 445.105
[129,     1] loss: 657.161
[130,     1] loss: 431.565
[131,     1] loss: 541.844
[132,     1] loss: 423.829
[133,     1] loss: 571.630
[134,     1] loss: 451.962
[135,     1] loss: 470.357
[136,     1] loss: 431.712
[137,     1] loss: 401.190
[138,     1] loss: 416.657
[139,     1] loss: 365.642
[140,     1] loss: 366.723
[141,     1] loss: 395.664
[142,     1] loss: 371.222
[143,     1] loss: 348.456
Early stopping applied (best metric=0.5270198583602905)
Finished Training
Total time taken: 22.065022230148315
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1297.102
[2,     1] loss: 1284.823
[3,     1] loss: 1288.025
[4,     1] loss: 1287.164
[5,     1] loss: 1278.735
[6,     1] loss: 1265.617
[7,     1] loss: 1233.100
[8,     1] loss: 1176.930
[9,     1] loss: 1136.619
[10,     1] loss: 1108.377
[11,     1] loss: 1100.622
[12,     1] loss: 1069.187
[13,     1] loss: 1081.935
[14,     1] loss: 1041.200
[15,     1] loss: 1053.217
[16,     1] loss: 1068.360
[17,     1] loss: 1023.175
[18,     1] loss: 1030.172
[19,     1] loss: 1052.032
[20,     1] loss: 994.221
[21,     1] loss: 1011.959
[22,     1] loss: 981.046
[23,     1] loss: 1035.194
[24,     1] loss: 958.834
[25,     1] loss: 980.800
[26,     1] loss: 946.347
[27,     1] loss: 983.303
[28,     1] loss: 955.189
[29,     1] loss: 930.528
[30,     1] loss: 917.823
[31,     1] loss: 855.118
[32,     1] loss: 884.348
[33,     1] loss: 909.232
[34,     1] loss: 850.650
[35,     1] loss: 847.816
[36,     1] loss: 816.805
[37,     1] loss: 872.932
[38,     1] loss: 789.607
[39,     1] loss: 798.180
[40,     1] loss: 836.974
[41,     1] loss: 903.927
[42,     1] loss: 806.916
[43,     1] loss: 758.685
[44,     1] loss: 881.799
[45,     1] loss: 740.400
[46,     1] loss: 926.116
[47,     1] loss: 687.954
[48,     1] loss: 835.485
[49,     1] loss: 755.246
[50,     1] loss: 821.195
[51,     1] loss: 726.225
[52,     1] loss: 794.359
[53,     1] loss: 746.350
[54,     1] loss: 741.782
[55,     1] loss: 648.891
[56,     1] loss: 686.977
[57,     1] loss: 648.079
[58,     1] loss: 672.457
[59,     1] loss: 609.435
[60,     1] loss: 598.627
[61,     1] loss: 647.297
[62,     1] loss: 625.081
[63,     1] loss: 591.200
[64,     1] loss: 622.539
[65,     1] loss: 556.266
[66,     1] loss: 573.867
[67,     1] loss: 604.824
[68,     1] loss: 720.197
[69,     1] loss: 731.940
[70,     1] loss: 540.960
[71,     1] loss: 682.787
[72,     1] loss: 566.392
[73,     1] loss: 624.421
Early stopping applied (best metric=0.8547730445861816)
Finished Training
Total time taken: 9.954009771347046
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1291.439
[2,     1] loss: 1295.553
[3,     1] loss: 1295.355
[4,     1] loss: 1288.898
[5,     1] loss: 1292.869
[6,     1] loss: 1287.443
[7,     1] loss: 1285.781
[8,     1] loss: 1282.606
[9,     1] loss: 1268.466
[10,     1] loss: 1249.864
[11,     1] loss: 1217.164
[12,     1] loss: 1179.902
[13,     1] loss: 1145.424
[14,     1] loss: 1100.641
[15,     1] loss: 1091.000
[16,     1] loss: 1118.264
[17,     1] loss: 1063.903
[18,     1] loss: 1071.007
[19,     1] loss: 1070.494
[20,     1] loss: 1058.275
[21,     1] loss: 1087.485
[22,     1] loss: 1051.292
[23,     1] loss: 1068.783
[24,     1] loss: 1007.209
[25,     1] loss: 996.910
[26,     1] loss: 984.548
[27,     1] loss: 1057.576
[28,     1] loss: 979.206
[29,     1] loss: 995.202
[30,     1] loss: 931.519
[31,     1] loss: 967.305
[32,     1] loss: 936.985
[33,     1] loss: 940.984
[34,     1] loss: 903.189
[35,     1] loss: 931.250
[36,     1] loss: 945.396
[37,     1] loss: 893.053
[38,     1] loss: 882.166
[39,     1] loss: 935.250
[40,     1] loss: 830.754
[41,     1] loss: 839.634
[42,     1] loss: 852.065
[43,     1] loss: 810.816
[44,     1] loss: 792.477
[45,     1] loss: 801.162
[46,     1] loss: 790.330
[47,     1] loss: 764.493
[48,     1] loss: 715.495
[49,     1] loss: 759.724
[50,     1] loss: 962.975
[51,     1] loss: 1248.670
[52,     1] loss: 798.868
[53,     1] loss: 928.447
[54,     1] loss: 991.222
[55,     1] loss: 882.322
[56,     1] loss: 911.034
[57,     1] loss: 900.425
[58,     1] loss: 892.926
[59,     1] loss: 793.771
[60,     1] loss: 785.950
[61,     1] loss: 846.836
[62,     1] loss: 754.156
[63,     1] loss: 778.559
Early stopping applied (best metric=0.666591227054596)
Finished Training
Total time taken: 10.08201003074646
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1291.301
[2,     1] loss: 1293.727
[3,     1] loss: 1285.281
[4,     1] loss: 1314.382
[5,     1] loss: 1294.560
[6,     1] loss: 1288.813
[7,     1] loss: 1280.208
[8,     1] loss: 1270.518
[9,     1] loss: 1251.102
[10,     1] loss: 1212.200
[11,     1] loss: 1165.735
[12,     1] loss: 1188.298
[13,     1] loss: 1159.971
[14,     1] loss: 1079.148
[15,     1] loss: 1134.122
[16,     1] loss: 1091.026
[17,     1] loss: 1082.485
[18,     1] loss: 1103.944
[19,     1] loss: 1082.537
[20,     1] loss: 1023.948
[21,     1] loss: 1007.501
[22,     1] loss: 1021.027
[23,     1] loss: 1031.632
[24,     1] loss: 1054.649
[25,     1] loss: 1022.599
[26,     1] loss: 976.348
[27,     1] loss: 983.424
[28,     1] loss: 963.316
[29,     1] loss: 921.302
[30,     1] loss: 951.223
[31,     1] loss: 915.115
[32,     1] loss: 955.290
[33,     1] loss: 900.234
[34,     1] loss: 907.302
[35,     1] loss: 895.282
[36,     1] loss: 865.686
[37,     1] loss: 885.344
[38,     1] loss: 935.636
[39,     1] loss: 853.563
[40,     1] loss: 826.560
[41,     1] loss: 880.571
[42,     1] loss: 909.539
[43,     1] loss: 820.184
[44,     1] loss: 827.466
[45,     1] loss: 865.080
[46,     1] loss: 807.384
[47,     1] loss: 774.023
[48,     1] loss: 755.183
[49,     1] loss: 736.868
[50,     1] loss: 743.866
[51,     1] loss: 720.108
[52,     1] loss: 696.089
[53,     1] loss: 689.078
[54,     1] loss: 888.370
[55,     1] loss: 1091.225
[56,     1] loss: 834.911
[57,     1] loss: 873.485
Early stopping applied (best metric=0.9190429449081421)
Finished Training
Total time taken: 8.866008281707764
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1290.823
[2,     1] loss: 1293.368
[3,     1] loss: 1287.837
[4,     1] loss: 1287.838
[5,     1] loss: 1283.507
[6,     1] loss: 1278.199
[7,     1] loss: 1271.280
[8,     1] loss: 1243.564
[9,     1] loss: 1205.282
[10,     1] loss: 1158.570
[11,     1] loss: 1153.620
[12,     1] loss: 1123.039
[13,     1] loss: 1074.749
[14,     1] loss: 1134.038
[15,     1] loss: 1141.074
[16,     1] loss: 1049.334
[17,     1] loss: 1044.307
[18,     1] loss: 1052.267
[19,     1] loss: 1057.232
[20,     1] loss: 1035.574
[21,     1] loss: 1072.992
[22,     1] loss: 1004.504
[23,     1] loss: 1000.931
[24,     1] loss: 955.461
[25,     1] loss: 992.705
[26,     1] loss: 930.497
[27,     1] loss: 1028.118
[28,     1] loss: 962.390
[29,     1] loss: 941.646
[30,     1] loss: 957.938
[31,     1] loss: 919.850
[32,     1] loss: 859.295
[33,     1] loss: 887.198
[34,     1] loss: 815.876
[35,     1] loss: 836.651
[36,     1] loss: 887.681
[37,     1] loss: 857.325
[38,     1] loss: 857.717
[39,     1] loss: 936.337
[40,     1] loss: 943.554
[41,     1] loss: 785.506
[42,     1] loss: 789.961
[43,     1] loss: 810.894
[44,     1] loss: 913.338
[45,     1] loss: 820.777
[46,     1] loss: 827.732
[47,     1] loss: 796.738
[48,     1] loss: 789.771
[49,     1] loss: 762.085
[50,     1] loss: 775.202
[51,     1] loss: 723.896
[52,     1] loss: 719.960
[53,     1] loss: 757.010
[54,     1] loss: 665.098
[55,     1] loss: 634.319
[56,     1] loss: 682.717
[57,     1] loss: 646.237
[58,     1] loss: 665.272
[59,     1] loss: 614.013
[60,     1] loss: 695.531
[61,     1] loss: 795.633
[62,     1] loss: 826.654
[63,     1] loss: 606.599
[64,     1] loss: 664.312
[65,     1] loss: 610.333
[66,     1] loss: 617.588
[67,     1] loss: 514.767
[68,     1] loss: 538.971
[69,     1] loss: 552.813
[70,     1] loss: 569.208
[71,     1] loss: 595.957
[72,     1] loss: 600.877
[73,     1] loss: 518.876
[74,     1] loss: 611.839
[75,     1] loss: 649.771
[76,     1] loss: 545.033
[77,     1] loss: 689.786
Early stopping applied (best metric=0.63966965675354)
Finished Training
Total time taken: 11.528011560440063
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1294.715
[2,     1] loss: 1335.323
[3,     1] loss: 1290.750
[4,     1] loss: 1286.832
[5,     1] loss: 1293.804
[6,     1] loss: 1287.790
[7,     1] loss: 1286.445
[8,     1] loss: 1292.882
[9,     1] loss: 1289.361
[10,     1] loss: 1291.192
[11,     1] loss: 1289.836
[12,     1] loss: 1288.444
[13,     1] loss: 1288.268
[14,     1] loss: 1287.380
[15,     1] loss: 1285.911
[16,     1] loss: 1291.006
[17,     1] loss: 1287.630
[18,     1] loss: 1284.939
[19,     1] loss: 1284.379
[20,     1] loss: 1282.115
[21,     1] loss: 1279.387
[22,     1] loss: 1272.313
[23,     1] loss: 1263.550
[24,     1] loss: 1246.540
[25,     1] loss: 1214.355
[26,     1] loss: 1187.982
[27,     1] loss: 1169.602
[28,     1] loss: 1123.470
[29,     1] loss: 1085.848
[30,     1] loss: 1127.817
[31,     1] loss: 1076.620
[32,     1] loss: 1112.194
[33,     1] loss: 1043.713
[34,     1] loss: 997.580
[35,     1] loss: 1030.876
[36,     1] loss: 1024.035
[37,     1] loss: 1037.701
[38,     1] loss: 996.430
[39,     1] loss: 982.163
[40,     1] loss: 978.669
[41,     1] loss: 981.098
[42,     1] loss: 976.260
[43,     1] loss: 937.119
[44,     1] loss: 953.821
[45,     1] loss: 984.318
[46,     1] loss: 912.872
[47,     1] loss: 914.756
[48,     1] loss: 935.326
[49,     1] loss: 919.821
[50,     1] loss: 941.023
[51,     1] loss: 867.743
[52,     1] loss: 906.792
[53,     1] loss: 862.508
[54,     1] loss: 874.935
[55,     1] loss: 816.059
[56,     1] loss: 894.064
[57,     1] loss: 794.191
[58,     1] loss: 796.250
[59,     1] loss: 784.324
[60,     1] loss: 801.353
[61,     1] loss: 790.300
[62,     1] loss: 752.573
[63,     1] loss: 738.135
Early stopping applied (best metric=0.8421990871429443)
Finished Training
Total time taken: 10.543010234832764
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1293.638
[2,     1] loss: 1294.168
[3,     1] loss: 1299.255
[4,     1] loss: 1285.622
[5,     1] loss: 1290.324
[6,     1] loss: 1285.349
[7,     1] loss: 1281.547
[8,     1] loss: 1272.312
[9,     1] loss: 1259.588
[10,     1] loss: 1242.120
[11,     1] loss: 1211.837
[12,     1] loss: 1182.423
[13,     1] loss: 1171.442
[14,     1] loss: 1150.447
[15,     1] loss: 1096.641
[16,     1] loss: 1084.355
[17,     1] loss: 1068.111
[18,     1] loss: 1072.579
[19,     1] loss: 1056.401
[20,     1] loss: 1042.362
[21,     1] loss: 1055.410
[22,     1] loss: 1047.975
[23,     1] loss: 1048.346
[24,     1] loss: 1023.031
[25,     1] loss: 1054.569
[26,     1] loss: 1023.625
[27,     1] loss: 979.026
[28,     1] loss: 1017.014
[29,     1] loss: 989.960
[30,     1] loss: 987.541
[31,     1] loss: 1018.586
[32,     1] loss: 952.190
[33,     1] loss: 985.098
[34,     1] loss: 913.112
[35,     1] loss: 991.412
[36,     1] loss: 951.577
[37,     1] loss: 924.486
[38,     1] loss: 882.425
[39,     1] loss: 851.487
[40,     1] loss: 909.020
[41,     1] loss: 839.813
[42,     1] loss: 833.997
[43,     1] loss: 879.773
[44,     1] loss: 938.297
[45,     1] loss: 851.072
[46,     1] loss: 760.177
[47,     1] loss: 843.951
[48,     1] loss: 798.790
[49,     1] loss: 818.088
[50,     1] loss: 857.964
[51,     1] loss: 711.262
[52,     1] loss: 834.824
[53,     1] loss: 796.829
[54,     1] loss: 722.054
[55,     1] loss: 799.867
[56,     1] loss: 718.798
[57,     1] loss: 788.496
[58,     1] loss: 708.479
[59,     1] loss: 792.352
[60,     1] loss: 698.622
[61,     1] loss: 765.705
[62,     1] loss: 663.751
[63,     1] loss: 737.541
[64,     1] loss: 645.305
[65,     1] loss: 717.595
[66,     1] loss: 632.281
[67,     1] loss: 641.358
[68,     1] loss: 635.503
[69,     1] loss: 541.366
[70,     1] loss: 574.623
[71,     1] loss: 581.421
[72,     1] loss: 533.703
[73,     1] loss: 529.488
Early stopping applied (best metric=0.6774296164512634)
Finished Training
Total time taken: 12.20201301574707
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1292.065
[2,     1] loss: 1299.174
[3,     1] loss: 1286.066
[4,     1] loss: 1289.029
[5,     1] loss: 1285.123
[6,     1] loss: 1278.171
[7,     1] loss: 1267.426
[8,     1] loss: 1228.938
[9,     1] loss: 1183.799
[10,     1] loss: 1163.694
[11,     1] loss: 1106.029
[12,     1] loss: 1128.218
[13,     1] loss: 1245.224
[14,     1] loss: 1067.339
[15,     1] loss: 1093.203
[16,     1] loss: 1079.333
[17,     1] loss: 1064.699
[18,     1] loss: 1133.633
[19,     1] loss: 1084.823
[20,     1] loss: 1053.869
[21,     1] loss: 1012.003
[22,     1] loss: 1024.248
[23,     1] loss: 1040.549
[24,     1] loss: 976.338
[25,     1] loss: 1021.359
[26,     1] loss: 960.550
[27,     1] loss: 1030.022
[28,     1] loss: 931.813
[29,     1] loss: 1006.735
[30,     1] loss: 984.978
[31,     1] loss: 972.516
[32,     1] loss: 947.820
[33,     1] loss: 956.067
[34,     1] loss: 985.742
[35,     1] loss: 904.804
[36,     1] loss: 911.487
[37,     1] loss: 911.919
[38,     1] loss: 844.486
[39,     1] loss: 883.284
[40,     1] loss: 870.686
[41,     1] loss: 857.605
[42,     1] loss: 818.677
[43,     1] loss: 809.870
[44,     1] loss: 812.001
[45,     1] loss: 791.047
[46,     1] loss: 817.160
[47,     1] loss: 768.379
[48,     1] loss: 766.603
[49,     1] loss: 775.816
[50,     1] loss: 970.166
[51,     1] loss: 940.191
[52,     1] loss: 804.433
[53,     1] loss: 845.200
[54,     1] loss: 799.953
[55,     1] loss: 724.274
[56,     1] loss: 795.722
Early stopping applied (best metric=0.774208664894104)
Finished Training
Total time taken: 9.311009168624878
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1291.846
[2,     1] loss: 1291.272
[3,     1] loss: 1299.246
[4,     1] loss: 1291.645
[5,     1] loss: 1286.498
[6,     1] loss: 1290.436
[7,     1] loss: 1278.077
[8,     1] loss: 1269.982
[9,     1] loss: 1252.174
[10,     1] loss: 1228.962
[11,     1] loss: 1165.511
[12,     1] loss: 1170.666
[13,     1] loss: 1134.308
[14,     1] loss: 1130.849
[15,     1] loss: 1081.156
[16,     1] loss: 1075.960
[17,     1] loss: 1097.999
[18,     1] loss: 1036.945
[19,     1] loss: 1041.808
[20,     1] loss: 1044.615
[21,     1] loss: 1035.015
[22,     1] loss: 1060.892
[23,     1] loss: 1056.462
[24,     1] loss: 999.268
[25,     1] loss: 1089.122
[26,     1] loss: 998.358
[27,     1] loss: 989.886
[28,     1] loss: 1035.407
[29,     1] loss: 974.404
[30,     1] loss: 998.546
[31,     1] loss: 1027.576
[32,     1] loss: 923.446
[33,     1] loss: 1034.502
[34,     1] loss: 941.627
[35,     1] loss: 992.869
[36,     1] loss: 992.868
[37,     1] loss: 933.173
[38,     1] loss: 926.946
[39,     1] loss: 980.227
[40,     1] loss: 915.090
[41,     1] loss: 987.140
[42,     1] loss: 923.677
[43,     1] loss: 908.236
[44,     1] loss: 891.442
[45,     1] loss: 828.970
[46,     1] loss: 838.438
[47,     1] loss: 834.099
[48,     1] loss: 808.703
[49,     1] loss: 771.380
[50,     1] loss: 772.611
[51,     1] loss: 768.065
[52,     1] loss: 792.133
[53,     1] loss: 778.225
[54,     1] loss: 735.823
[55,     1] loss: 753.668
[56,     1] loss: 749.385
[57,     1] loss: 786.427
[58,     1] loss: 806.060
[59,     1] loss: 772.698
[60,     1] loss: 663.042
[61,     1] loss: 702.537
Early stopping applied (best metric=0.8467732667922974)
Finished Training
Total time taken: 8.76900863647461
{'Hydroxylation-K Validation Accuracy': 0.7614952718676123, 'Hydroxylation-K Validation Sensitivity': 0.6992592592592592, 'Hydroxylation-K Validation Specificity': 0.7771929824561403, 'Hydroxylation-K Validation Precision': 0.4484124040161192, 'Hydroxylation-K AUC ROC': 0.8178362573099416, 'Hydroxylation-K AUC PR': 0.6171486297951012, 'Hydroxylation-K MCC': 0.4143531021417297, 'Hydroxylation-K F1': 0.5405607318440901, 'Validation Loss (Hydroxylation-K)': 0.4188863297303518, 'Hydroxylation-P Validation Accuracy': 0.7996273624012318, 'Hydroxylation-P Validation Sensitivity': 0.7861375661375661, 'Hydroxylation-P Validation Specificity': 0.8025412738789964, 'Hydroxylation-P Validation Precision': 0.4671632870016005, 'Hydroxylation-P AUC ROC': 0.8654520254740964, 'Hydroxylation-P AUC PR': 0.6012625789484702, 'Hydroxylation-P MCC': 0.49283332422970033, 'Hydroxylation-P F1': 0.58369577055615, 'Validation Loss (Hydroxylation-P)': 0.35643421014149984, 'Validation Loss (total)': 0.7753205339113871, 'TimeToTrain': 11.278611373901366}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002300700355652843,
 'learning_rate_Hydroxylation-K': 0.006809447711976504,
 'learning_rate_Hydroxylation-P': 0.0045416796382581935,
 'log_base': 1.9008116985940133,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3174804790,
 'sample_weights': [1.8087721791195317, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1250847936429307,
 'weight_decay_Hydroxylation-K': 5.2027371991171565,
 'weight_decay_Hydroxylation-P': 4.5036952789025175}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1456.331
[2,     1] loss: 1455.482
[3,     1] loss: 1461.184
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004050033780979546,
 'learning_rate_Hydroxylation-K': 0.0034893927628834006,
 'learning_rate_Hydroxylation-P': 0.007300941560344852,
 'log_base': 2.961091258836795,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 295487820,
 'sample_weights': [2.5992410411139475, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7019064878626695,
 'weight_decay_Hydroxylation-K': 0.6916181043197565,
 'weight_decay_Hydroxylation-P': 3.906000764333323}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1235.138
[2,     1] loss: 1235.981
[3,     1] loss: 1234.988
[4,     1] loss: 1231.741
[5,     1] loss: 1231.258
[6,     1] loss: 1222.582
[7,     1] loss: 1212.129
[8,     1] loss: 1187.778
[9,     1] loss: 1147.181
[10,     1] loss: 1134.164
[11,     1] loss: 1125.946
[12,     1] loss: 1078.537
[13,     1] loss: 1062.995
[14,     1] loss: 1049.386
[15,     1] loss: 1078.042
[16,     1] loss: 983.595
[17,     1] loss: 1041.102
[18,     1] loss: 977.241
[19,     1] loss: 1034.901
[20,     1] loss: 1016.977
[21,     1] loss: 993.117
[22,     1] loss: 1003.152
[23,     1] loss: 991.765
[24,     1] loss: 986.602
[25,     1] loss: 955.142
[26,     1] loss: 932.935
[27,     1] loss: 903.615
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00351311589667253,
 'learning_rate_Hydroxylation-K': 0.004104146530167104,
 'learning_rate_Hydroxylation-P': 0.005959303160955665,
 'log_base': 2.766640701013229,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 891956492,
 'sample_weights': [1.53786656171909, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.579983895505101,
 'weight_decay_Hydroxylation-K': 0.9103112693247947,
 'weight_decay_Hydroxylation-P': 3.77057053962816}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1256.983
[2,     1] loss: 1271.756
[3,     1] loss: 1252.157
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009692778862763554,
 'learning_rate_Hydroxylation-K': 0.004204245974888383,
 'learning_rate_Hydroxylation-P': 0.004278020712231778,
 'log_base': 1.9494229326726165,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2875076425,
 'sample_weights': [1.6405145744008345, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.049054793840534,
 'weight_decay_Hydroxylation-K': 5.2391485226808285,
 'weight_decay_Hydroxylation-P': 5.045041681406247}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1438.704
[2,     1] loss: 1440.729
[3,     1] loss: 1434.622
[4,     1] loss: 1435.608
[5,     1] loss: 1434.931
[6,     1] loss: 1433.183
[7,     1] loss: 1431.022
[8,     1] loss: 1427.653
[9,     1] loss: 1432.678
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004341956876253897,
 'learning_rate_Hydroxylation-K': 0.008777104628521307,
 'learning_rate_Hydroxylation-P': 0.00013491287806772243,
 'log_base': 2.609524983159893,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 155399992,
 'sample_weights': [2.500913295702662, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.329204973709087,
 'weight_decay_Hydroxylation-K': 3.1992764785069516,
 'weight_decay_Hydroxylation-P': 5.491378789432157}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1278.113
[2,     1] loss: 1284.213
[3,     1] loss: 1274.862
[4,     1] loss: 1273.320
[5,     1] loss: 1275.066
[6,     1] loss: 1270.484
[7,     1] loss: 1268.734
[8,     1] loss: 1273.917
[9,     1] loss: 1252.734
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031661234975380132,
 'learning_rate_Hydroxylation-K': 0.005595626050945079,
 'learning_rate_Hydroxylation-P': 0.00873027283437968,
 'log_base': 2.9990649515666763,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1695535208,
 'sample_weights': [1.7405113482836527, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.970819363441766,
 'weight_decay_Hydroxylation-K': 1.1037291002913747,
 'weight_decay_Hydroxylation-P': 2.382479119562242}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1237.142
[2,     1] loss: 1230.020
[3,     1] loss: 1236.075
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016930186097949007,
 'learning_rate_Hydroxylation-K': 0.0038099310417809063,
 'learning_rate_Hydroxylation-P': 0.001590318396055611,
 'log_base': 2.9092002804992902,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 825663997,
 'sample_weights': [1.5200239464209437, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.346604991647892,
 'weight_decay_Hydroxylation-K': 2.3893136259641654,
 'weight_decay_Hydroxylation-P': 4.725651435948568}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.448
[2,     1] loss: 1246.099
[3,     1] loss: 1235.759
[4,     1] loss: 1234.894
[5,     1] loss: 1235.348
[6,     1] loss: 1237.107
[7,     1] loss: 1238.716
[8,     1] loss: 1230.345
[9,     1] loss: 1223.801
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004698657633957257,
 'learning_rate_Hydroxylation-K': 0.0037330990689708283,
 'learning_rate_Hydroxylation-P': 0.008016025156077498,
 'log_base': 2.8946344829611963,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2152498320,
 'sample_weights': [1.563327266368714, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2126299888180536,
 'weight_decay_Hydroxylation-K': 2.579979070400279,
 'weight_decay_Hydroxylation-P': 5.348678773635731}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.254
[2,     1] loss: 1238.248
[3,     1] loss: 1249.499
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00723962790084556,
 'learning_rate_Hydroxylation-K': 0.002895258747991916,
 'learning_rate_Hydroxylation-P': 0.009040878995247218,
 'log_base': 2.9630281061831303,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4239625390,
 'sample_weights': [1.5707101232329164, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.511050883121651,
 'weight_decay_Hydroxylation-K': 0.8393610484875156,
 'weight_decay_Hydroxylation-P': 3.3907397532060854}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.573
[2,     1] loss: 1258.945
[3,     1] loss: 1240.210
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037444434105669824,
 'learning_rate_Hydroxylation-K': 0.002477008510472164,
 'learning_rate_Hydroxylation-P': 0.007570099769194336,
 'log_base': 2.16362355478161,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3474850114,
 'sample_weights': [1.5369407860567894, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.221297738432547,
 'weight_decay_Hydroxylation-K': 7.666373851254859,
 'weight_decay_Hydroxylation-P': 2.031562098348381}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1361.600
[2,     1] loss: 1368.185
[3,     1] loss: 1365.904
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006234501654933278,
 'learning_rate_Hydroxylation-K': 0.0008969946085986793,
 'learning_rate_Hydroxylation-P': 0.000213026610650047,
 'log_base': 2.5940715745709686,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2539936649,
 'sample_weights': [2.1630952553689577, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1127368389050383,
 'weight_decay_Hydroxylation-K': 9.333600521707844,
 'weight_decay_Hydroxylation-P': 1.0492693472857404}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1283.648
[2,     1] loss: 1278.740
[3,     1] loss: 1286.298
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024899130584262095,
 'learning_rate_Hydroxylation-K': 0.0023335150004383442,
 'learning_rate_Hydroxylation-P': 0.005525532122932992,
 'log_base': 2.50781395403791,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2877969199,
 'sample_weights': [1.7513564018605838, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.34377260538623267,
 'weight_decay_Hydroxylation-K': 2.5676873595451637,
 'weight_decay_Hydroxylation-P': 5.304299357416485}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1290.838
[2,     1] loss: 1291.486
[3,     1] loss: 1292.590
[4,     1] loss: 1293.531
[5,     1] loss: 1285.213
[6,     1] loss: 1289.085
[7,     1] loss: 1276.791
[8,     1] loss: 1280.483
[9,     1] loss: 1252.408
[10,     1] loss: 1224.907
[11,     1] loss: 1192.668
[12,     1] loss: 1170.389
[13,     1] loss: 1129.951
[14,     1] loss: 1120.764
[15,     1] loss: 1120.255
[16,     1] loss: 1053.367
[17,     1] loss: 1091.049
[18,     1] loss: 1113.035
[19,     1] loss: 1055.708
[20,     1] loss: 993.543
[21,     1] loss: 1020.219
[22,     1] loss: 1065.320
[23,     1] loss: 1014.456
[24,     1] loss: 993.305
[25,     1] loss: 1003.732
[26,     1] loss: 1023.854
[27,     1] loss: 982.745
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005883840368938168,
 'learning_rate_Hydroxylation-K': 0.004624294261001633,
 'learning_rate_Hydroxylation-P': 0.0038311338145431205,
 'log_base': 1.9929906021808532,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 313114150,
 'sample_weights': [1.8157737402255034, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.07640319575895,
 'weight_decay_Hydroxylation-K': 5.159031816960892,
 'weight_decay_Hydroxylation-P': 8.879152200528054}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1422.644
[2,     1] loss: 1421.208
[3,     1] loss: 1425.810
[4,     1] loss: 1416.903
[5,     1] loss: 1419.527
[6,     1] loss: 1419.422
[7,     1] loss: 1415.107
[8,     1] loss: 1413.708
[9,     1] loss: 1409.968
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006366185972761559,
 'learning_rate_Hydroxylation-K': 0.005961726895705698,
 'learning_rate_Hydroxylation-P': 0.004374543925803482,
 'log_base': 1.9389568442950749,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2843812503,
 'sample_weights': [2.42075871724491, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.687706536196376,
 'weight_decay_Hydroxylation-K': 7.947616916357381,
 'weight_decay_Hydroxylation-P': 1.246989771082455}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1447.013
[2,     1] loss: 1453.599
[3,     1] loss: 1438.286
[4,     1] loss: 1453.461
[5,     1] loss: 1450.470
[6,     1] loss: 1440.194
[7,     1] loss: 1442.898
[8,     1] loss: 1437.957
[9,     1] loss: 1434.822
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0021476723462372843,
 'learning_rate_Hydroxylation-K': 0.0017832138428960811,
 'learning_rate_Hydroxylation-P': 0.007230353366140889,
 'log_base': 2.5444993380717666,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 622566850,
 'sample_weights': [2.5212457095211223, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.029121907301961014,
 'weight_decay_Hydroxylation-K': 2.5546105521520173,
 'weight_decay_Hydroxylation-P': 4.628954451515613}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1286.551
[2,     1] loss: 1285.676
[3,     1] loss: 1290.653
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024199556645238714,
 'learning_rate_Hydroxylation-K': 0.002444198040191101,
 'learning_rate_Hydroxylation-P': 0.005792752423094661,
 'log_base': 2.3916492174482675,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3043123285,
 'sample_weights': [1.7875388558858991, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9281358570794439,
 'weight_decay_Hydroxylation-K': 3.754348836262057,
 'weight_decay_Hydroxylation-P': 7.933815786651168}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1312.812
[2,     1] loss: 1309.819
[3,     1] loss: 1317.301
[4,     1] loss: 1308.650
[5,     1] loss: 1306.385
[6,     1] loss: 1303.630
[7,     1] loss: 1281.673
[8,     1] loss: 1265.384
[9,     1] loss: 1241.182
[10,     1] loss: 1177.014
[11,     1] loss: 1164.140
[12,     1] loss: 1180.597
[13,     1] loss: 1068.664
[14,     1] loss: 1097.367
[15,     1] loss: 1110.801
[16,     1] loss: 1013.917
[17,     1] loss: 1070.772
[18,     1] loss: 1078.315
[19,     1] loss: 1045.461
[20,     1] loss: 1018.312
[21,     1] loss: 1001.820
[22,     1] loss: 993.502
[23,     1] loss: 1010.116
[24,     1] loss: 989.457
[25,     1] loss: 1003.115
[26,     1] loss: 995.530
[27,     1] loss: 954.050
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003442832380176476,
 'learning_rate_Hydroxylation-K': 0.0011428509361674911,
 'learning_rate_Hydroxylation-P': 0.005303108891715517,
 'log_base': 2.8943229177146295,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4285983477,
 'sample_weights': [1.9145359580854482, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.34641804592749603,
 'weight_decay_Hydroxylation-K': 8.050812665662702,
 'weight_decay_Hydroxylation-P': 7.445191618205686}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.826
[2,     1] loss: 1240.744
[3,     1] loss: 1241.588
[4,     1] loss: 1244.512
[5,     1] loss: 1238.768
[6,     1] loss: 1240.633
[7,     1] loss: 1238.639
[8,     1] loss: 1236.713
[9,     1] loss: 1237.777
[10,     1] loss: 1240.145
[11,     1] loss: 1238.299
[12,     1] loss: 1237.808
[13,     1] loss: 1242.457
[14,     1] loss: 1234.805
[15,     1] loss: 1236.589
[16,     1] loss: 1232.651
[17,     1] loss: 1231.172
[18,     1] loss: 1229.040
[19,     1] loss: 1231.766
[20,     1] loss: 1226.818
[21,     1] loss: 1222.212
[22,     1] loss: 1219.197
[23,     1] loss: 1218.278
[24,     1] loss: 1211.579
[25,     1] loss: 1203.059
[26,     1] loss: 1192.827
[27,     1] loss: 1191.863
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017797147187491825,
 'learning_rate_Hydroxylation-K': 0.0004922285997102966,
 'learning_rate_Hydroxylation-P': 0.004116290982099065,
 'log_base': 2.421683693293839,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4111673841,
 'sample_weights': [1.5708692133084547, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.28499592600277784,
 'weight_decay_Hydroxylation-K': 3.9223381616247552,
 'weight_decay_Hydroxylation-P': 4.240424595546779}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1308.802
[2,     1] loss: 1306.333
[3,     1] loss: 1307.960
[4,     1] loss: 1310.582
[5,     1] loss: 1305.549
[6,     1] loss: 1302.690
[7,     1] loss: 1304.406
[8,     1] loss: 1298.269
[9,     1] loss: 1289.103
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006255431015394957,
 'learning_rate_Hydroxylation-K': 0.001596638538761001,
 'learning_rate_Hydroxylation-P': 0.00827626252995999,
 'log_base': 1.1771468597685064,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2963132644,
 'sample_weights': [1.8875216637385435, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.674293255088205,
 'weight_decay_Hydroxylation-K': 1.725690332532098,
 'weight_decay_Hydroxylation-P': 5.721966457996976}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3332.725
[2,     1] loss: 3460.532
[3,     1] loss: 3316.435
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006733780746516092,
 'learning_rate_Hydroxylation-K': 0.0041239871176541164,
 'learning_rate_Hydroxylation-P': 0.004270047331206228,
 'log_base': 2.403342296420387,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1797402025,
 'sample_weights': [10.236104893621478, 1.2795624036857975],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.964021474927975,
 'weight_decay_Hydroxylation-K': 2.078938322154112,
 'weight_decay_Hydroxylation-P': 6.041802018589798}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1313.269
[2,     1] loss: 1327.291
[3,     1] loss: 1331.573
[4,     1] loss: 1311.893
[5,     1] loss: 1310.129
[6,     1] loss: 1310.264
[7,     1] loss: 1313.402
[8,     1] loss: 1309.015
[9,     1] loss: 1307.837
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028862010338420543,
 'learning_rate_Hydroxylation-K': 0.000273639449384495,
 'learning_rate_Hydroxylation-P': 0.0004210815777850444,
 'log_base': 2.554811376519503,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3477091419,
 'sample_weights': [1.9038870526453784, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7493580684257822,
 'weight_decay_Hydroxylation-K': 9.613024209604012,
 'weight_decay_Hydroxylation-P': 0.2683602972869741}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1288.016
[2,     1] loss: 1286.970
[3,     1] loss: 1282.594
[4,     1] loss: 1283.376
[5,     1] loss: 1278.046
[6,     1] loss: 1269.679
[7,     1] loss: 1264.457
[8,     1] loss: 1244.017
[9,     1] loss: 1200.958
[10,     1] loss: 1189.601
[11,     1] loss: 1143.810
[12,     1] loss: 1111.453
[13,     1] loss: 1118.340
[14,     1] loss: 1131.079
[15,     1] loss: 1063.326
[16,     1] loss: 1093.344
[17,     1] loss: 1055.585
[18,     1] loss: 1023.336
[19,     1] loss: 1041.630
[20,     1] loss: 1030.697
[21,     1] loss: 1038.842
[22,     1] loss: 1047.078
[23,     1] loss: 1034.327
[24,     1] loss: 1007.830
[25,     1] loss: 1001.844
[26,     1] loss: 1010.262
[27,     1] loss: 928.062
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009119612958103504,
 'learning_rate_Hydroxylation-K': 0.005565490976967407,
 'learning_rate_Hydroxylation-P': 0.0032383477451569985,
 'log_base': 2.8226067749661303,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3006263095,
 'sample_weights': [1.7798311294679878, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5469817079513541,
 'weight_decay_Hydroxylation-K': 9.469199394142777,
 'weight_decay_Hydroxylation-P': 1.7810067170400097}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1249.258
[2,     1] loss: 1248.414
[3,     1] loss: 1244.070
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006623137823323876,
 'learning_rate_Hydroxylation-K': 0.00332280424044814,
 'learning_rate_Hydroxylation-P': 0.004423747629665306,
 'log_base': 2.917496584472628,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1009102692,
 'sample_weights': [1.6088524043799264, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.8048431585210625,
 'weight_decay_Hydroxylation-K': 4.589621961293603,
 'weight_decay_Hydroxylation-P': 2.7524326896277738}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.819
[2,     1] loss: 1243.581
[3,     1] loss: 1239.211
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008192987589803368,
 'learning_rate_Hydroxylation-K': 0.009903645389231618,
 'learning_rate_Hydroxylation-P': 0.0008032104541781642,
 'log_base': 1.374338218711253,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3581100191,
 'sample_weights': [1.5591694614425595, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.009491841840076454,
 'weight_decay_Hydroxylation-K': 7.160399100128089,
 'weight_decay_Hydroxylation-P': 5.407889164328054}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2017.035
[2,     1] loss: 2012.663
[3,     1] loss: 2004.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001468304190537739,
 'learning_rate_Hydroxylation-K': 0.0019342182403832297,
 'learning_rate_Hydroxylation-P': 0.007510801192147314,
 'log_base': 2.947479109509422,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1345004964,
 'sample_weights': [5.250278227362478, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.405981196902256,
 'weight_decay_Hydroxylation-K': 3.8686847726553766,
 'weight_decay_Hydroxylation-P': 2.190701453240547}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.195
[2,     1] loss: 1238.241
[3,     1] loss: 1231.577
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003617175611449393,
 'learning_rate_Hydroxylation-K': 0.006122946762780088,
 'learning_rate_Hydroxylation-P': 0.007149795880906389,
 'log_base': 1.2308374151487464,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3048565421,
 'sample_weights': [1.5444217926819053, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.285756844016695,
 'weight_decay_Hydroxylation-K': 0.44640167240796413,
 'weight_decay_Hydroxylation-P': 4.875557956804056}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2608.127
[2,     1] loss: 2614.270
[3,     1] loss: 2609.628
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014938608491458622,
 'learning_rate_Hydroxylation-K': 0.0013414901102868524,
 'learning_rate_Hydroxylation-P': 0.001779939189975335,
 'log_base': 2.641327169633914,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4095054987,
 'sample_weights': [8.037964573064313, 1.004784278467144],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.738167137625546,
 'weight_decay_Hydroxylation-K': 8.912225639977644,
 'weight_decay_Hydroxylation-P': 0.8043606263820587}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1269.652
[2,     1] loss: 1270.924
[3,     1] loss: 1265.892
[4,     1] loss: 1271.645
[5,     1] loss: 1266.433
[6,     1] loss: 1255.339
[7,     1] loss: 1244.316
[8,     1] loss: 1229.911
[9,     1] loss: 1196.562
[10,     1] loss: 1164.729
[11,     1] loss: 1138.678
[12,     1] loss: 1104.160
[13,     1] loss: 1047.759
[14,     1] loss: 1082.968
[15,     1] loss: 1101.181
[16,     1] loss: 1081.738
[17,     1] loss: 1030.184
[18,     1] loss: 1027.771
[19,     1] loss: 1067.726
[20,     1] loss: 1041.899
[21,     1] loss: 1055.694
[22,     1] loss: 1000.814
[23,     1] loss: 1022.638
[24,     1] loss: 1014.163
[25,     1] loss: 963.589
[26,     1] loss: 987.445
[27,     1] loss: 974.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0039967588952465,
 'learning_rate_Hydroxylation-K': 0.00024721708474310185,
 'learning_rate_Hydroxylation-P': 0.0006645748952890776,
 'log_base': 2.6208073114864208,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 562834096,
 'sample_weights': [1.7188046267363197, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8123450933461287,
 'weight_decay_Hydroxylation-K': 7.0893681391596015,
 'weight_decay_Hydroxylation-P': 1.222964867015754}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1281.134
[2,     1] loss: 1274.365
[3,     1] loss: 1271.305
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033324200934862335,
 'learning_rate_Hydroxylation-K': 0.003001659651984279,
 'learning_rate_Hydroxylation-P': 0.004474340588805735,
 'log_base': 2.847554762175878,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3815624183,
 'sample_weights': [1.7327178365560894, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.1130180119352797,
 'weight_decay_Hydroxylation-K': 6.824189668096126,
 'weight_decay_Hydroxylation-P': 4.412305006507516}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.441
[2,     1] loss: 1247.601
[3,     1] loss: 1241.545
[4,     1] loss: 1242.469
[5,     1] loss: 1231.156
[6,     1] loss: 1219.336
[7,     1] loss: 1178.038
[8,     1] loss: 1129.145
[9,     1] loss: 1092.121
[10,     1] loss: 1088.970
[11,     1] loss: 1069.243
[12,     1] loss: 1074.767
[13,     1] loss: 1026.571
[14,     1] loss: 1016.664
[15,     1] loss: 1065.311
[16,     1] loss: 1053.880
[17,     1] loss: 1009.808
[18,     1] loss: 1046.143
[19,     1] loss: 985.167
[20,     1] loss: 985.090
[21,     1] loss: 942.870
[22,     1] loss: 958.126
[23,     1] loss: 949.207
[24,     1] loss: 921.236
[25,     1] loss: 959.155
[26,     1] loss: 914.618
[27,     1] loss: 897.695
[28,     1] loss: 885.784
[29,     1] loss: 882.331
[30,     1] loss: 900.955
[31,     1] loss: 868.262
[32,     1] loss: 872.272
[33,     1] loss: 865.376
[34,     1] loss: 887.924
[35,     1] loss: 799.735
[36,     1] loss: 852.242
[37,     1] loss: 848.627
[38,     1] loss: 805.302
[39,     1] loss: 830.918
[40,     1] loss: 784.268
[41,     1] loss: 789.122
[42,     1] loss: 784.516
[43,     1] loss: 843.374
[44,     1] loss: 726.673
[45,     1] loss: 763.098
[46,     1] loss: 693.714
[47,     1] loss: 761.769
[48,     1] loss: 786.861
[49,     1] loss: 720.920
[50,     1] loss: 698.648
[51,     1] loss: 720.150
[52,     1] loss: 723.737
[53,     1] loss: 670.378
[54,     1] loss: 680.034
[55,     1] loss: 645.382
[56,     1] loss: 688.393
[57,     1] loss: 613.236
[58,     1] loss: 698.152
[59,     1] loss: 607.093
[60,     1] loss: 643.802
[61,     1] loss: 604.208
[62,     1] loss: 659.802
[63,     1] loss: 628.597
[64,     1] loss: 601.499
[65,     1] loss: 586.280
Early stopping applied (best metric=0.8129078149795532)
Finished Training
Total time taken: 8.820008754730225
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1248.757
[2,     1] loss: 1242.664
[3,     1] loss: 1246.936
[4,     1] loss: 1236.225
[5,     1] loss: 1228.358
[6,     1] loss: 1214.190
[7,     1] loss: 1189.198
[8,     1] loss: 1120.592
[9,     1] loss: 1074.266
[10,     1] loss: 1059.722
[11,     1] loss: 1019.359
[12,     1] loss: 1006.241
[13,     1] loss: 1097.402
[14,     1] loss: 975.862
[15,     1] loss: 980.373
[16,     1] loss: 978.328
[17,     1] loss: 1046.352
[18,     1] loss: 963.422
[19,     1] loss: 986.983
[20,     1] loss: 969.034
[21,     1] loss: 931.582
[22,     1] loss: 967.551
[23,     1] loss: 943.349
[24,     1] loss: 936.675
[25,     1] loss: 972.243
[26,     1] loss: 891.808
[27,     1] loss: 910.759
[28,     1] loss: 878.739
[29,     1] loss: 869.106
[30,     1] loss: 913.333
[31,     1] loss: 864.252
[32,     1] loss: 869.427
[33,     1] loss: 846.731
[34,     1] loss: 854.033
[35,     1] loss: 872.464
[36,     1] loss: 820.178
[37,     1] loss: 821.459
[38,     1] loss: 815.561
[39,     1] loss: 808.704
[40,     1] loss: 801.606
[41,     1] loss: 802.911
[42,     1] loss: 764.335
[43,     1] loss: 722.968
[44,     1] loss: 716.859
[45,     1] loss: 735.031
[46,     1] loss: 764.401
Early stopping applied (best metric=0.938030481338501)
Finished Training
Total time taken: 6.277006149291992
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.714
[2,     1] loss: 1251.424
[3,     1] loss: 1245.309
[4,     1] loss: 1244.670
[5,     1] loss: 1240.143
[6,     1] loss: 1241.772
[7,     1] loss: 1244.580
[8,     1] loss: 1231.973
[9,     1] loss: 1224.059
[10,     1] loss: 1209.873
[11,     1] loss: 1172.547
[12,     1] loss: 1161.990
[13,     1] loss: 1093.418
[14,     1] loss: 1071.276
[15,     1] loss: 1066.443
[16,     1] loss: 1033.130
[17,     1] loss: 1095.265
[18,     1] loss: 1069.177
[19,     1] loss: 1045.024
[20,     1] loss: 977.481
[21,     1] loss: 1041.522
[22,     1] loss: 1031.421
[23,     1] loss: 1004.359
[24,     1] loss: 1021.247
[25,     1] loss: 992.014
[26,     1] loss: 1009.185
[27,     1] loss: 994.438
[28,     1] loss: 967.567
[29,     1] loss: 980.515
[30,     1] loss: 951.362
[31,     1] loss: 930.721
[32,     1] loss: 894.930
[33,     1] loss: 951.507
[34,     1] loss: 926.307
[35,     1] loss: 889.045
[36,     1] loss: 872.120
[37,     1] loss: 900.391
[38,     1] loss: 910.912
[39,     1] loss: 871.329
[40,     1] loss: 871.635
[41,     1] loss: 877.956
[42,     1] loss: 812.854
[43,     1] loss: 829.404
[44,     1] loss: 856.514
[45,     1] loss: 933.811
[46,     1] loss: 813.373
[47,     1] loss: 845.489
[48,     1] loss: 803.876
[49,     1] loss: 786.163
[50,     1] loss: 777.031
[51,     1] loss: 811.778
[52,     1] loss: 759.621
[53,     1] loss: 754.873
[54,     1] loss: 745.251
[55,     1] loss: 771.647
[56,     1] loss: 713.392
[57,     1] loss: 772.664
Early stopping applied (best metric=0.9001479148864746)
Finished Training
Total time taken: 8.906008005142212
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1246.285
[2,     1] loss: 1247.820
[3,     1] loss: 1241.441
[4,     1] loss: 1244.753
[5,     1] loss: 1241.017
[6,     1] loss: 1235.914
[7,     1] loss: 1233.037
[8,     1] loss: 1211.085
[9,     1] loss: 1182.795
[10,     1] loss: 1139.961
[11,     1] loss: 1127.954
[12,     1] loss: 1073.766
[13,     1] loss: 1097.061
[14,     1] loss: 1046.722
[15,     1] loss: 1008.961
[16,     1] loss: 1013.371
[17,     1] loss: 1014.446
[18,     1] loss: 999.094
[19,     1] loss: 1036.359
[20,     1] loss: 961.509
[21,     1] loss: 936.786
[22,     1] loss: 994.133
[23,     1] loss: 1001.723
[24,     1] loss: 971.944
[25,     1] loss: 1003.099
[26,     1] loss: 947.043
[27,     1] loss: 953.337
[28,     1] loss: 950.726
[29,     1] loss: 931.651
[30,     1] loss: 867.445
[31,     1] loss: 890.094
[32,     1] loss: 952.172
[33,     1] loss: 896.525
[34,     1] loss: 875.343
[35,     1] loss: 895.983
[36,     1] loss: 842.200
[37,     1] loss: 881.223
[38,     1] loss: 842.370
[39,     1] loss: 859.747
[40,     1] loss: 813.899
[41,     1] loss: 882.848
[42,     1] loss: 779.063
[43,     1] loss: 834.357
[44,     1] loss: 804.423
[45,     1] loss: 815.523
[46,     1] loss: 751.450
[47,     1] loss: 804.515
[48,     1] loss: 739.177
Early stopping applied (best metric=0.9180465936660767)
Finished Training
Total time taken: 7.969007253646851
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1248.706
[2,     1] loss: 1248.276
[3,     1] loss: 1244.077
[4,     1] loss: 1241.147
[5,     1] loss: 1236.202
[6,     1] loss: 1226.903
[7,     1] loss: 1207.009
[8,     1] loss: 1181.791
[9,     1] loss: 1217.978
[10,     1] loss: 1119.252
[11,     1] loss: 1129.038
[12,     1] loss: 1068.933
[13,     1] loss: 1047.552
[14,     1] loss: 1051.567
[15,     1] loss: 1006.138
[16,     1] loss: 1075.787
[17,     1] loss: 1028.350
[18,     1] loss: 1024.380
[19,     1] loss: 993.995
[20,     1] loss: 965.128
[21,     1] loss: 999.663
[22,     1] loss: 957.971
[23,     1] loss: 996.907
[24,     1] loss: 957.506
[25,     1] loss: 1023.705
[26,     1] loss: 948.665
[27,     1] loss: 945.926
[28,     1] loss: 926.279
[29,     1] loss: 908.873
[30,     1] loss: 892.622
[31,     1] loss: 917.396
[32,     1] loss: 907.805
[33,     1] loss: 885.987
[34,     1] loss: 869.207
[35,     1] loss: 949.968
[36,     1] loss: 859.667
[37,     1] loss: 879.201
[38,     1] loss: 886.280
[39,     1] loss: 857.849
[40,     1] loss: 846.285
[41,     1] loss: 830.259
[42,     1] loss: 845.289
[43,     1] loss: 800.961
[44,     1] loss: 811.663
[45,     1] loss: 792.894
[46,     1] loss: 768.203
Early stopping applied (best metric=0.8781924247741699)
Finished Training
Total time taken: 6.585005760192871
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1248.115
[2,     1] loss: 1246.042
[3,     1] loss: 1238.960
[4,     1] loss: 1247.693
[5,     1] loss: 1241.073
[6,     1] loss: 1239.244
[7,     1] loss: 1232.013
[8,     1] loss: 1218.257
[9,     1] loss: 1185.371
[10,     1] loss: 1141.191
[11,     1] loss: 1115.168
[12,     1] loss: 1068.447
[13,     1] loss: 1020.767
[14,     1] loss: 1074.299
[15,     1] loss: 1071.298
[16,     1] loss: 1012.013
[17,     1] loss: 1002.443
[18,     1] loss: 1004.308
[19,     1] loss: 978.525
[20,     1] loss: 1001.486
[21,     1] loss: 988.150
[22,     1] loss: 982.056
[23,     1] loss: 970.144
[24,     1] loss: 941.004
[25,     1] loss: 988.745
[26,     1] loss: 957.750
[27,     1] loss: 989.779
[28,     1] loss: 969.095
[29,     1] loss: 973.185
[30,     1] loss: 899.062
[31,     1] loss: 950.889
[32,     1] loss: 918.057
[33,     1] loss: 917.369
[34,     1] loss: 887.186
[35,     1] loss: 893.162
[36,     1] loss: 891.373
[37,     1] loss: 909.068
[38,     1] loss: 876.971
[39,     1] loss: 853.932
[40,     1] loss: 815.794
[41,     1] loss: 803.848
[42,     1] loss: 842.834
[43,     1] loss: 838.603
[44,     1] loss: 807.635
[45,     1] loss: 796.703
[46,     1] loss: 811.917
[47,     1] loss: 797.812
[48,     1] loss: 775.533
[49,     1] loss: 726.588
Early stopping applied (best metric=0.9617632627487183)
Finished Training
Total time taken: 6.714006185531616
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1249.800
[2,     1] loss: 1242.876
[3,     1] loss: 1244.491
[4,     1] loss: 1246.109
[5,     1] loss: 1240.199
[6,     1] loss: 1230.931
[7,     1] loss: 1214.319
[8,     1] loss: 1185.096
[9,     1] loss: 1136.674
[10,     1] loss: 1094.195
[11,     1] loss: 1050.987
[12,     1] loss: 1066.605
[13,     1] loss: 1047.047
[14,     1] loss: 1018.819
[15,     1] loss: 1071.937
[16,     1] loss: 999.949
[17,     1] loss: 949.691
[18,     1] loss: 994.395
[19,     1] loss: 958.647
[20,     1] loss: 955.351
[21,     1] loss: 977.815
[22,     1] loss: 989.596
[23,     1] loss: 946.251
[24,     1] loss: 894.846
[25,     1] loss: 941.607
[26,     1] loss: 901.354
[27,     1] loss: 908.443
[28,     1] loss: 903.604
[29,     1] loss: 886.900
[30,     1] loss: 919.815
[31,     1] loss: 953.057
[32,     1] loss: 917.660
[33,     1] loss: 867.040
[34,     1] loss: 852.635
[35,     1] loss: 862.032
[36,     1] loss: 896.208
[37,     1] loss: 872.380
[38,     1] loss: 806.952
[39,     1] loss: 807.142
[40,     1] loss: 800.518
[41,     1] loss: 764.807
[42,     1] loss: 850.676
[43,     1] loss: 811.868
[44,     1] loss: 857.534
[45,     1] loss: 846.939
[46,     1] loss: 852.300
[47,     1] loss: 783.489
[48,     1] loss: 844.869
[49,     1] loss: 794.765
[50,     1] loss: 755.904
[51,     1] loss: 822.342
[52,     1] loss: 741.063
[53,     1] loss: 779.642
[54,     1] loss: 715.090
[55,     1] loss: 773.360
[56,     1] loss: 692.955
[57,     1] loss: 781.879
[58,     1] loss: 692.901
[59,     1] loss: 764.239
[60,     1] loss: 685.762
[61,     1] loss: 689.610
[62,     1] loss: 728.116
[63,     1] loss: 672.984
[64,     1] loss: 651.553
[65,     1] loss: 558.929
[66,     1] loss: 721.650
[67,     1] loss: 634.837
[68,     1] loss: 651.139
[69,     1] loss: 604.226
[70,     1] loss: 611.935
[71,     1] loss: 571.443
[72,     1] loss: 600.986
[73,     1] loss: 597.639
[74,     1] loss: 597.292
[75,     1] loss: 560.956
[76,     1] loss: 522.295
[77,     1] loss: 543.656
[78,     1] loss: 579.022
[79,     1] loss: 519.521
[80,     1] loss: 482.149
[81,     1] loss: 519.366
Early stopping applied (best metric=0.7278055548667908)
Finished Training
Total time taken: 11.73401165008545
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1248.349
[2,     1] loss: 1248.232
[3,     1] loss: 1252.396
[4,     1] loss: 1245.471
[5,     1] loss: 1240.920
[6,     1] loss: 1239.929
[7,     1] loss: 1232.516
[8,     1] loss: 1229.595
[9,     1] loss: 1214.219
[10,     1] loss: 1181.235
[11,     1] loss: 1136.710
[12,     1] loss: 1107.320
[13,     1] loss: 1060.235
[14,     1] loss: 1031.890
[15,     1] loss: 1011.003
[16,     1] loss: 1049.857
[17,     1] loss: 988.588
[18,     1] loss: 988.525
[19,     1] loss: 984.802
[20,     1] loss: 997.561
[21,     1] loss: 1038.236
[22,     1] loss: 975.632
[23,     1] loss: 1026.652
[24,     1] loss: 958.109
[25,     1] loss: 985.010
[26,     1] loss: 1018.755
[27,     1] loss: 920.067
[28,     1] loss: 960.854
[29,     1] loss: 917.488
[30,     1] loss: 934.402
[31,     1] loss: 915.668
[32,     1] loss: 978.433
[33,     1] loss: 899.049
[34,     1] loss: 878.022
[35,     1] loss: 884.372
[36,     1] loss: 868.757
[37,     1] loss: 875.037
[38,     1] loss: 900.931
[39,     1] loss: 882.409
[40,     1] loss: 836.319
[41,     1] loss: 862.762
[42,     1] loss: 840.461
[43,     1] loss: 872.737
[44,     1] loss: 806.243
[45,     1] loss: 843.248
[46,     1] loss: 805.015
[47,     1] loss: 854.905
[48,     1] loss: 801.113
[49,     1] loss: 810.028
[50,     1] loss: 788.475
[51,     1] loss: 829.087
[52,     1] loss: 790.235
[53,     1] loss: 756.191
[54,     1] loss: 786.512
[55,     1] loss: 778.178
[56,     1] loss: 728.923
[57,     1] loss: 753.110
[58,     1] loss: 751.431
[59,     1] loss: 685.891
[60,     1] loss: 720.217
[61,     1] loss: 737.275
[62,     1] loss: 719.864
[63,     1] loss: 679.891
[64,     1] loss: 683.864
[65,     1] loss: 753.259
[66,     1] loss: 709.917
[67,     1] loss: 665.937
[68,     1] loss: 621.098
[69,     1] loss: 669.385
[70,     1] loss: 663.265
[71,     1] loss: 609.945
[72,     1] loss: 641.064
[73,     1] loss: 647.167
[74,     1] loss: 667.352
[75,     1] loss: 612.185
[76,     1] loss: 634.725
[77,     1] loss: 573.016
[78,     1] loss: 595.286
[79,     1] loss: 603.324
[80,     1] loss: 564.010
[81,     1] loss: 570.998
[82,     1] loss: 562.323
[83,     1] loss: 521.263
[84,     1] loss: 548.847
[85,     1] loss: 562.263
[86,     1] loss: 577.142
[87,     1] loss: 580.758
[88,     1] loss: 553.754
[89,     1] loss: 530.377
[90,     1] loss: 567.929
[91,     1] loss: 512.577
[92,     1] loss: 528.407
[93,     1] loss: 532.765
[94,     1] loss: 539.600
[95,     1] loss: 518.063
[96,     1] loss: 504.198
Early stopping applied (best metric=0.7644244432449341)
Finished Training
Total time taken: 13.431013584136963
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.767
[2,     1] loss: 1246.838
[3,     1] loss: 1244.407
[4,     1] loss: 1243.821
[5,     1] loss: 1234.416
[6,     1] loss: 1224.915
[7,     1] loss: 1195.369
[8,     1] loss: 1162.710
[9,     1] loss: 1143.145
[10,     1] loss: 1098.811
[11,     1] loss: 1081.636
[12,     1] loss: 1117.089
[13,     1] loss: 1066.410
[14,     1] loss: 1033.616
[15,     1] loss: 1079.671
[16,     1] loss: 1024.070
[17,     1] loss: 1009.673
[18,     1] loss: 999.497
[19,     1] loss: 1006.859
[20,     1] loss: 957.510
[21,     1] loss: 968.856
[22,     1] loss: 994.611
[23,     1] loss: 1015.940
[24,     1] loss: 930.804
[25,     1] loss: 928.729
[26,     1] loss: 943.813
[27,     1] loss: 869.725
[28,     1] loss: 952.109
[29,     1] loss: 945.173
[30,     1] loss: 888.666
[31,     1] loss: 902.520
[32,     1] loss: 851.311
[33,     1] loss: 873.306
[34,     1] loss: 889.899
[35,     1] loss: 868.414
[36,     1] loss: 853.380
[37,     1] loss: 813.671
[38,     1] loss: 833.879
[39,     1] loss: 814.601
[40,     1] loss: 817.653
[41,     1] loss: 800.853
[42,     1] loss: 803.053
[43,     1] loss: 825.100
[44,     1] loss: 818.666
[45,     1] loss: 794.522
[46,     1] loss: 819.124
[47,     1] loss: 763.112
[48,     1] loss: 738.225
[49,     1] loss: 684.274
[50,     1] loss: 767.759
[51,     1] loss: 775.660
[52,     1] loss: 715.392
[53,     1] loss: 669.489
[54,     1] loss: 675.525
[55,     1] loss: 704.660
[56,     1] loss: 625.659
[57,     1] loss: 647.028
[58,     1] loss: 581.062
[59,     1] loss: 631.325
[60,     1] loss: 612.892
[61,     1] loss: 606.950
[62,     1] loss: 588.622
[63,     1] loss: 596.863
[64,     1] loss: 599.456
[65,     1] loss: 580.491
[66,     1] loss: 592.113
[67,     1] loss: 533.354
Early stopping applied (best metric=0.7655887603759766)
Finished Training
Total time taken: 11.098011255264282
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1251.071
[2,     1] loss: 1245.664
[3,     1] loss: 1257.040
[4,     1] loss: 1238.300
[5,     1] loss: 1243.231
[6,     1] loss: 1243.493
[7,     1] loss: 1235.309
[8,     1] loss: 1222.840
[9,     1] loss: 1207.626
[10,     1] loss: 1180.563
[11,     1] loss: 1141.307
[12,     1] loss: 1131.904
[13,     1] loss: 1089.123
[14,     1] loss: 1066.067
[15,     1] loss: 1079.726
[16,     1] loss: 1064.075
[17,     1] loss: 1022.494
[18,     1] loss: 1005.105
[19,     1] loss: 1038.998
[20,     1] loss: 1008.994
[21,     1] loss: 1051.736
[22,     1] loss: 1030.023
[23,     1] loss: 976.659
[24,     1] loss: 1005.021
[25,     1] loss: 958.340
[26,     1] loss: 1003.379
[27,     1] loss: 930.496
[28,     1] loss: 945.398
[29,     1] loss: 942.040
[30,     1] loss: 922.410
[31,     1] loss: 898.498
[32,     1] loss: 941.882
[33,     1] loss: 920.607
[34,     1] loss: 925.580
[35,     1] loss: 893.212
[36,     1] loss: 901.334
[37,     1] loss: 872.041
[38,     1] loss: 867.825
[39,     1] loss: 896.137
[40,     1] loss: 908.210
[41,     1] loss: 810.260
[42,     1] loss: 870.452
[43,     1] loss: 882.091
[44,     1] loss: 841.517
[45,     1] loss: 839.203
[46,     1] loss: 804.894
[47,     1] loss: 810.517
[48,     1] loss: 814.842
[49,     1] loss: 842.167
[50,     1] loss: 779.332
[51,     1] loss: 764.682
[52,     1] loss: 761.050
[53,     1] loss: 787.817
[54,     1] loss: 758.304
[55,     1] loss: 784.229
[56,     1] loss: 702.511
[57,     1] loss: 781.401
[58,     1] loss: 742.250
[59,     1] loss: 740.389
[60,     1] loss: 694.502
[61,     1] loss: 735.978
[62,     1] loss: 665.351
[63,     1] loss: 679.310
[64,     1] loss: 666.515
[65,     1] loss: 674.389
[66,     1] loss: 595.879
[67,     1] loss: 594.166
[68,     1] loss: 684.875
[69,     1] loss: 616.939
[70,     1] loss: 603.909
Early stopping applied (best metric=0.7752116918563843)
Finished Training
Total time taken: 11.65701150894165
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1248.520
[2,     1] loss: 1245.939
[3,     1] loss: 1245.920
[4,     1] loss: 1239.964
[5,     1] loss: 1239.850
[6,     1] loss: 1237.283
[7,     1] loss: 1224.763
[8,     1] loss: 1197.945
[9,     1] loss: 1145.807
[10,     1] loss: 1132.765
[11,     1] loss: 1082.867
[12,     1] loss: 1041.423
[13,     1] loss: 1010.414
[14,     1] loss: 1029.139
[15,     1] loss: 1063.154
[16,     1] loss: 1049.160
[17,     1] loss: 1034.547
[18,     1] loss: 1007.609
[19,     1] loss: 1019.947
[20,     1] loss: 976.440
[21,     1] loss: 986.499
[22,     1] loss: 970.485
[23,     1] loss: 983.050
[24,     1] loss: 987.349
[25,     1] loss: 958.418
[26,     1] loss: 960.715
[27,     1] loss: 897.295
[28,     1] loss: 928.293
[29,     1] loss: 969.787
[30,     1] loss: 893.207
[31,     1] loss: 890.017
[32,     1] loss: 900.115
[33,     1] loss: 919.842
[34,     1] loss: 876.023
[35,     1] loss: 836.449
[36,     1] loss: 863.542
[37,     1] loss: 911.543
[38,     1] loss: 873.166
[39,     1] loss: 814.805
[40,     1] loss: 843.734
[41,     1] loss: 825.911
[42,     1] loss: 808.998
[43,     1] loss: 799.176
[44,     1] loss: 832.202
[45,     1] loss: 791.779
[46,     1] loss: 764.165
[47,     1] loss: 767.900
[48,     1] loss: 733.788
[49,     1] loss: 754.969
[50,     1] loss: 751.964
Early stopping applied (best metric=0.948375940322876)
Finished Training
Total time taken: 8.337011337280273
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1248.615
[2,     1] loss: 1242.899
[3,     1] loss: 1244.380
[4,     1] loss: 1244.708
[5,     1] loss: 1244.657
[6,     1] loss: 1243.289
[7,     1] loss: 1246.726
[8,     1] loss: 1242.440
[9,     1] loss: 1237.141
[10,     1] loss: 1231.796
[11,     1] loss: 1224.293
[12,     1] loss: 1213.378
[13,     1] loss: 1199.129
[14,     1] loss: 1161.045
[15,     1] loss: 1121.385
[16,     1] loss: 1101.211
[17,     1] loss: 1049.803
[18,     1] loss: 1031.043
[19,     1] loss: 1053.978
[20,     1] loss: 1045.734
[21,     1] loss: 986.251
[22,     1] loss: 992.288
[23,     1] loss: 970.589
[24,     1] loss: 986.625
[25,     1] loss: 988.167
[26,     1] loss: 966.701
[27,     1] loss: 970.290
[28,     1] loss: 998.955
[29,     1] loss: 881.552
[30,     1] loss: 956.852
[31,     1] loss: 952.307
[32,     1] loss: 939.482
[33,     1] loss: 868.022
[34,     1] loss: 896.166
[35,     1] loss: 859.642
[36,     1] loss: 877.665
[37,     1] loss: 859.112
[38,     1] loss: 821.936
[39,     1] loss: 853.034
[40,     1] loss: 791.622
[41,     1] loss: 792.112
[42,     1] loss: 775.193
[43,     1] loss: 796.609
[44,     1] loss: 797.855
[45,     1] loss: 827.278
[46,     1] loss: 805.016
[47,     1] loss: 794.112
[48,     1] loss: 757.640
[49,     1] loss: 777.026
[50,     1] loss: 753.357
[51,     1] loss: 740.025
[52,     1] loss: 763.876
[53,     1] loss: 719.258
[54,     1] loss: 713.882
Early stopping applied (best metric=0.8578303456306458)
Finished Training
Total time taken: 8.28000807762146
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1245.297
[2,     1] loss: 1244.820
[3,     1] loss: 1245.401
[4,     1] loss: 1245.223
[5,     1] loss: 1243.384
[6,     1] loss: 1233.261
[7,     1] loss: 1212.042
[8,     1] loss: 1176.383
[9,     1] loss: 1143.925
[10,     1] loss: 1081.928
[11,     1] loss: 1067.029
[12,     1] loss: 1148.307
[13,     1] loss: 1079.276
[14,     1] loss: 1047.193
[15,     1] loss: 1022.070
[16,     1] loss: 1021.130
[17,     1] loss: 1022.973
[18,     1] loss: 990.559
[19,     1] loss: 985.740
[20,     1] loss: 982.649
[21,     1] loss: 999.862
[22,     1] loss: 975.800
[23,     1] loss: 962.932
[24,     1] loss: 939.385
[25,     1] loss: 920.424
[26,     1] loss: 949.674
[27,     1] loss: 882.129
[28,     1] loss: 935.400
[29,     1] loss: 905.768
[30,     1] loss: 954.909
Early stopping applied (best metric=1.0119044780731201)
Finished Training
Total time taken: 4.146006107330322
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1246.235
[2,     1] loss: 1247.645
[3,     1] loss: 1240.627
[4,     1] loss: 1244.805
[5,     1] loss: 1236.577
[6,     1] loss: 1230.899
[7,     1] loss: 1212.614
[8,     1] loss: 1191.595
[9,     1] loss: 1147.067
[10,     1] loss: 1142.324
[11,     1] loss: 1078.214
[12,     1] loss: 1078.581
[13,     1] loss: 1081.194
[14,     1] loss: 1043.653
[15,     1] loss: 1020.906
[16,     1] loss: 1045.423
[17,     1] loss: 1046.654
[18,     1] loss: 1059.906
[19,     1] loss: 1017.713
[20,     1] loss: 1006.706
[21,     1] loss: 997.574
[22,     1] loss: 950.732
[23,     1] loss: 1018.261
[24,     1] loss: 976.427
[25,     1] loss: 1002.649
[26,     1] loss: 958.072
[27,     1] loss: 915.249
[28,     1] loss: 937.921
[29,     1] loss: 906.636
[30,     1] loss: 931.660
[31,     1] loss: 899.493
[32,     1] loss: 923.922
[33,     1] loss: 993.768
[34,     1] loss: 915.248
[35,     1] loss: 958.576
[36,     1] loss: 912.100
[37,     1] loss: 935.659
[38,     1] loss: 870.074
[39,     1] loss: 914.386
[40,     1] loss: 821.781
[41,     1] loss: 880.492
[42,     1] loss: 819.464
[43,     1] loss: 807.144
[44,     1] loss: 829.592
[45,     1] loss: 842.436
[46,     1] loss: 806.608
[47,     1] loss: 877.110
[48,     1] loss: 770.238
[49,     1] loss: 817.153
[50,     1] loss: 760.965
[51,     1] loss: 784.487
[52,     1] loss: 790.590
[53,     1] loss: 768.923
[54,     1] loss: 717.547
[55,     1] loss: 755.006
[56,     1] loss: 752.337
[57,     1] loss: 759.893
Early stopping applied (best metric=0.7702873945236206)
Finished Training
Total time taken: 8.063007831573486
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1250.980
[2,     1] loss: 1246.686
[3,     1] loss: 1244.890
[4,     1] loss: 1246.209
[5,     1] loss: 1243.665
[6,     1] loss: 1231.609
[7,     1] loss: 1233.311
[8,     1] loss: 1213.995
[9,     1] loss: 1182.934
[10,     1] loss: 1154.131
[11,     1] loss: 1093.919
[12,     1] loss: 1067.768
[13,     1] loss: 1070.761
[14,     1] loss: 1085.367
[15,     1] loss: 1025.188
[16,     1] loss: 1021.388
[17,     1] loss: 1049.368
[18,     1] loss: 1006.971
[19,     1] loss: 1031.184
[20,     1] loss: 1021.823
[21,     1] loss: 984.295
[22,     1] loss: 1034.552
[23,     1] loss: 988.254
[24,     1] loss: 992.744
[25,     1] loss: 1007.574
[26,     1] loss: 946.395
[27,     1] loss: 933.021
[28,     1] loss: 973.276
[29,     1] loss: 973.092
[30,     1] loss: 916.489
[31,     1] loss: 919.940
[32,     1] loss: 875.332
[33,     1] loss: 915.876
[34,     1] loss: 874.343
[35,     1] loss: 886.691
[36,     1] loss: 866.441
[37,     1] loss: 902.721
[38,     1] loss: 911.440
Early stopping applied (best metric=0.8607723712921143)
Finished Training
Total time taken: 6.398006200790405
{'Hydroxylation-K Validation Accuracy': 0.7465721040189125, 'Hydroxylation-K Validation Sensitivity': 0.6259259259259259, 'Hydroxylation-K Validation Specificity': 0.7771929824561403, 'Hydroxylation-K Validation Precision': 0.4192378885877338, 'Hydroxylation-K AUC ROC': 0.7613060428849903, 'Hydroxylation-K AUC PR': 0.5399392708389739, 'Hydroxylation-K MCC': 0.3543821980594945, 'Hydroxylation-K F1': 0.493823046019494, 'Validation Loss (Hydroxylation-K)': 0.4584619124730428, 'Hydroxylation-P Validation Accuracy': 0.7906632150652251, 'Hydroxylation-P Validation Sensitivity': 0.7612698412698413, 'Hydroxylation-P Validation Specificity': 0.7969624420170582, 'Hydroxylation-P Validation Precision': 0.4565425994570925, 'Hydroxylation-P AUC ROC': 0.8347532731316212, 'Hydroxylation-P AUC PR': 0.5423588236072935, 'Hydroxylation-P MCC': 0.4699177532068576, 'Hydroxylation-P F1': 0.5654276599624575, 'Validation Loss (Hydroxylation-P)': 0.40095737973848977, 'Validation Loss (total)': 0.859419298171997, 'TimeToTrain': 8.561008644104003}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00015930938792660344,
 'learning_rate_Hydroxylation-K': 0.0010145735008651013,
 'learning_rate_Hydroxylation-P': 0.009065352590387328,
 'log_base': 2.874004075310679,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2010768856,
 'sample_weights': [1.596506797604739, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2911387024703451,
 'weight_decay_Hydroxylation-K': 3.8946034561688627,
 'weight_decay_Hydroxylation-P': 5.340336617726992}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.947
[2,     1] loss: 1247.148
[3,     1] loss: 1241.541
[4,     1] loss: 1242.680
[5,     1] loss: 1244.297
[6,     1] loss: 1240.307
[7,     1] loss: 1246.055
[8,     1] loss: 1242.655
[9,     1] loss: 1245.316
[10,     1] loss: 1241.883
[11,     1] loss: 1240.443
[12,     1] loss: 1242.164
[13,     1] loss: 1241.688
[14,     1] loss: 1241.058
[15,     1] loss: 1239.560
[16,     1] loss: 1241.317
[17,     1] loss: 1242.726
[18,     1] loss: 1241.760
[19,     1] loss: 1239.430
[20,     1] loss: 1241.597
[21,     1] loss: 1238.875
[22,     1] loss: 1239.317
[23,     1] loss: 1239.688
[24,     1] loss: 1242.289
[25,     1] loss: 1235.757
[26,     1] loss: 1238.771
[27,     1] loss: 1236.284
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004535878536896518,
 'learning_rate_Hydroxylation-K': 0.007522262438394187,
 'learning_rate_Hydroxylation-P': 0.005431463710301069,
 'log_base': 2.5793712436423237,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3396157518,
 'sample_weights': [1.5813520262470269, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8524516419859263,
 'weight_decay_Hydroxylation-K': 9.55259094757151,
 'weight_decay_Hydroxylation-P': 9.267423069458614}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.297
[2,     1] loss: 1289.628
[3,     1] loss: 1279.883
[4,     1] loss: 1281.235
[5,     1] loss: 1280.775
[6,     1] loss: 1279.672
[7,     1] loss: 1279.460
[8,     1] loss: 1276.027
[9,     1] loss: 1275.083
[10,     1] loss: 1277.064
[11,     1] loss: 1274.139
[12,     1] loss: 1278.784
[13,     1] loss: 1273.320
[14,     1] loss: 1270.925
[15,     1] loss: 1264.518
[16,     1] loss: 1251.534
[17,     1] loss: 1242.455
[18,     1] loss: 1216.414
[19,     1] loss: 1222.485
[20,     1] loss: 1161.425
[21,     1] loss: 1153.382
[22,     1] loss: 1117.430
[23,     1] loss: 1110.666
[24,     1] loss: 1155.167
[25,     1] loss: 1070.409
[26,     1] loss: 1109.670
[27,     1] loss: 1091.241
[28,     1] loss: 1040.389
[29,     1] loss: 1040.784
[30,     1] loss: 1036.918
[31,     1] loss: 1002.971
[32,     1] loss: 1060.118
[33,     1] loss: 1005.948
[34,     1] loss: 1053.473
[35,     1] loss: 1030.417
[36,     1] loss: 1026.587
[37,     1] loss: 981.868
[38,     1] loss: 974.129
[39,     1] loss: 929.885
[40,     1] loss: 986.571
[41,     1] loss: 876.382
[42,     1] loss: 912.157
[43,     1] loss: 935.759
[44,     1] loss: 896.428
[45,     1] loss: 921.926
[46,     1] loss: 919.554
[47,     1] loss: 920.378
[48,     1] loss: 885.663
[49,     1] loss: 880.558
[50,     1] loss: 847.676
[51,     1] loss: 858.286
[52,     1] loss: 862.637
[53,     1] loss: 838.343
[54,     1] loss: 892.002
[55,     1] loss: 844.685
[56,     1] loss: 851.515
[57,     1] loss: 851.777
[58,     1] loss: 833.926
[59,     1] loss: 847.777
Early stopping applied (best metric=0.8394184112548828)
Finished Training
Total time taken: 9.562009572982788
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1278.529
[2,     1] loss: 1285.146
[3,     1] loss: 1276.618
[4,     1] loss: 1283.266
[5,     1] loss: 1267.860
[6,     1] loss: 1245.058
[7,     1] loss: 1208.006
[8,     1] loss: 1163.535
[9,     1] loss: 1165.883
[10,     1] loss: 1139.167
[11,     1] loss: 1147.734
[12,     1] loss: 1094.307
[13,     1] loss: 1103.078
[14,     1] loss: 1096.964
[15,     1] loss: 1092.431
[16,     1] loss: 1109.847
[17,     1] loss: 1056.269
[18,     1] loss: 1081.719
[19,     1] loss: 1058.196
[20,     1] loss: 1051.766
[21,     1] loss: 1068.421
[22,     1] loss: 1013.030
[23,     1] loss: 1046.822
[24,     1] loss: 1036.674
[25,     1] loss: 968.074
[26,     1] loss: 969.513
[27,     1] loss: 1004.783
[28,     1] loss: 987.974
[29,     1] loss: 954.331
[30,     1] loss: 929.846
[31,     1] loss: 986.449
[32,     1] loss: 949.410
[33,     1] loss: 948.051
[34,     1] loss: 957.133
[35,     1] loss: 931.855
[36,     1] loss: 969.933
[37,     1] loss: 912.805
[38,     1] loss: 859.875
[39,     1] loss: 890.057
[40,     1] loss: 879.263
[41,     1] loss: 892.373
[42,     1] loss: 857.509
[43,     1] loss: 905.104
[44,     1] loss: 908.537
[45,     1] loss: 802.871
[46,     1] loss: 879.831
[47,     1] loss: 858.727
[48,     1] loss: 867.269
[49,     1] loss: 823.658
[50,     1] loss: 839.215
[51,     1] loss: 759.734
[52,     1] loss: 882.278
[53,     1] loss: 758.492
[54,     1] loss: 772.377
[55,     1] loss: 807.120
[56,     1] loss: 740.064
[57,     1] loss: 752.490
[58,     1] loss: 776.603
[59,     1] loss: 717.703
[60,     1] loss: 707.000
[61,     1] loss: 784.764
[62,     1] loss: 744.723
[63,     1] loss: 717.582
[64,     1] loss: 742.846
[65,     1] loss: 732.176
[66,     1] loss: 695.068
[67,     1] loss: 709.724
[68,     1] loss: 669.228
[69,     1] loss: 662.961
[70,     1] loss: 697.145
[71,     1] loss: 631.263
[72,     1] loss: 703.419
[73,     1] loss: 669.465
[74,     1] loss: 627.536
[75,     1] loss: 684.731
[76,     1] loss: 595.555
Early stopping applied (best metric=0.7978441715240479)
Finished Training
Total time taken: 10.845010995864868
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1289.540
[2,     1] loss: 1287.347
[3,     1] loss: 1281.772
[4,     1] loss: 1281.909
[5,     1] loss: 1283.220
[6,     1] loss: 1281.411
[7,     1] loss: 1279.374
[8,     1] loss: 1278.936
[9,     1] loss: 1277.770
[10,     1] loss: 1277.076
[11,     1] loss: 1275.271
[12,     1] loss: 1272.483
[13,     1] loss: 1269.664
[14,     1] loss: 1262.794
[15,     1] loss: 1250.998
[16,     1] loss: 1238.343
[17,     1] loss: 1214.790
[18,     1] loss: 1199.098
[19,     1] loss: 1171.407
[20,     1] loss: 1164.947
[21,     1] loss: 1117.313
[22,     1] loss: 1096.685
[23,     1] loss: 1117.842
[24,     1] loss: 1123.879
[25,     1] loss: 1116.235
[26,     1] loss: 1085.047
[27,     1] loss: 1044.539
[28,     1] loss: 1081.895
[29,     1] loss: 1072.418
[30,     1] loss: 1131.293
[31,     1] loss: 1089.542
[32,     1] loss: 1012.722
[33,     1] loss: 1061.142
[34,     1] loss: 1035.292
[35,     1] loss: 1020.539
[36,     1] loss: 1019.030
[37,     1] loss: 1027.314
[38,     1] loss: 994.971
[39,     1] loss: 993.787
[40,     1] loss: 1018.030
[41,     1] loss: 977.680
[42,     1] loss: 962.201
[43,     1] loss: 980.747
[44,     1] loss: 960.026
[45,     1] loss: 949.038
[46,     1] loss: 942.281
[47,     1] loss: 895.261
[48,     1] loss: 901.645
[49,     1] loss: 951.505
[50,     1] loss: 890.935
[51,     1] loss: 897.556
[52,     1] loss: 864.417
[53,     1] loss: 865.604
[54,     1] loss: 893.770
[55,     1] loss: 842.082
[56,     1] loss: 920.366
[57,     1] loss: 860.642
[58,     1] loss: 883.400
[59,     1] loss: 826.050
[60,     1] loss: 888.477
[61,     1] loss: 850.125
[62,     1] loss: 805.268
[63,     1] loss: 795.797
[64,     1] loss: 844.300
[65,     1] loss: 783.288
[66,     1] loss: 724.903
[67,     1] loss: 735.964
[68,     1] loss: 764.146
[69,     1] loss: 740.289
[70,     1] loss: 749.401
[71,     1] loss: 733.764
[72,     1] loss: 702.570
[73,     1] loss: 691.162
[74,     1] loss: 698.012
[75,     1] loss: 694.343
[76,     1] loss: 720.051
Early stopping applied (best metric=0.666854977607727)
Finished Training
Total time taken: 12.503012418746948
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.249
[2,     1] loss: 1288.041
[3,     1] loss: 1279.456
[4,     1] loss: 1285.756
[5,     1] loss: 1276.143
[6,     1] loss: 1276.177
[7,     1] loss: 1275.501
[8,     1] loss: 1270.201
[9,     1] loss: 1266.496
[10,     1] loss: 1248.286
[11,     1] loss: 1206.451
[12,     1] loss: 1183.146
[13,     1] loss: 1131.708
[14,     1] loss: 1081.410
[15,     1] loss: 1122.266
[16,     1] loss: 1055.413
[17,     1] loss: 1098.293
[18,     1] loss: 1037.129
[19,     1] loss: 1053.757
[20,     1] loss: 1029.818
[21,     1] loss: 1047.649
[22,     1] loss: 1023.388
[23,     1] loss: 1021.675
[24,     1] loss: 1006.330
[25,     1] loss: 953.842
[26,     1] loss: 993.175
[27,     1] loss: 964.344
[28,     1] loss: 995.986
[29,     1] loss: 963.385
[30,     1] loss: 931.566
[31,     1] loss: 915.117
[32,     1] loss: 914.934
[33,     1] loss: 929.923
[34,     1] loss: 947.040
[35,     1] loss: 899.587
[36,     1] loss: 923.906
[37,     1] loss: 900.001
[38,     1] loss: 925.954
[39,     1] loss: 899.206
[40,     1] loss: 851.856
[41,     1] loss: 867.569
[42,     1] loss: 909.347
[43,     1] loss: 855.358
[44,     1] loss: 870.054
[45,     1] loss: 847.346
[46,     1] loss: 781.646
Early stopping applied (best metric=0.9323571920394897)
Finished Training
Total time taken: 7.7310075759887695
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1282.264
[2,     1] loss: 1291.006
[3,     1] loss: 1285.137
[4,     1] loss: 1281.341
[5,     1] loss: 1277.988
[6,     1] loss: 1272.580
[7,     1] loss: 1262.256
[8,     1] loss: 1248.176
[9,     1] loss: 1200.793
[10,     1] loss: 1152.040
[11,     1] loss: 1103.802
[12,     1] loss: 1096.512
[13,     1] loss: 1067.586
[14,     1] loss: 1081.601
[15,     1] loss: 1063.940
[16,     1] loss: 1071.974
[17,     1] loss: 1044.172
[18,     1] loss: 1065.707
[19,     1] loss: 1028.292
[20,     1] loss: 1013.712
[21,     1] loss: 1036.735
[22,     1] loss: 1031.954
[23,     1] loss: 1004.249
[24,     1] loss: 1020.112
[25,     1] loss: 970.636
[26,     1] loss: 1020.977
[27,     1] loss: 979.685
[28,     1] loss: 949.328
[29,     1] loss: 1005.422
[30,     1] loss: 939.732
[31,     1] loss: 927.383
[32,     1] loss: 937.720
[33,     1] loss: 952.720
[34,     1] loss: 985.151
[35,     1] loss: 899.526
[36,     1] loss: 896.471
[37,     1] loss: 963.394
[38,     1] loss: 917.149
[39,     1] loss: 928.816
[40,     1] loss: 855.002
[41,     1] loss: 891.593
[42,     1] loss: 809.327
[43,     1] loss: 872.929
[44,     1] loss: 900.816
[45,     1] loss: 885.370
[46,     1] loss: 861.439
[47,     1] loss: 835.336
[48,     1] loss: 795.193
[49,     1] loss: 855.868
[50,     1] loss: 813.537
[51,     1] loss: 767.495
[52,     1] loss: 802.313
[53,     1] loss: 804.597
[54,     1] loss: 786.490
[55,     1] loss: 802.359
[56,     1] loss: 798.942
[57,     1] loss: 762.629
[58,     1] loss: 766.939
[59,     1] loss: 756.461
[60,     1] loss: 728.571
[61,     1] loss: 705.484
[62,     1] loss: 701.693
[63,     1] loss: 735.817
[64,     1] loss: 661.226
[65,     1] loss: 728.900
[66,     1] loss: 703.183
[67,     1] loss: 721.574
[68,     1] loss: 646.533
[69,     1] loss: 620.859
[70,     1] loss: 654.134
[71,     1] loss: 595.614
[72,     1] loss: 670.625
[73,     1] loss: 559.842
[74,     1] loss: 606.719
[75,     1] loss: 536.212
[76,     1] loss: 665.665
[77,     1] loss: 568.197
[78,     1] loss: 591.178
[79,     1] loss: 568.165
Early stopping applied (best metric=0.7894604206085205)
Finished Training
Total time taken: 13.102013111114502
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1280.690
[2,     1] loss: 1302.591
[3,     1] loss: 1280.647
[4,     1] loss: 1285.549
[5,     1] loss: 1279.509
[6,     1] loss: 1277.474
[7,     1] loss: 1278.062
[8,     1] loss: 1276.207
[9,     1] loss: 1277.834
[10,     1] loss: 1273.545
[11,     1] loss: 1268.662
[12,     1] loss: 1266.743
[13,     1] loss: 1259.406
[14,     1] loss: 1247.132
[15,     1] loss: 1226.598
[16,     1] loss: 1196.539
[17,     1] loss: 1161.758
[18,     1] loss: 1111.121
[19,     1] loss: 1077.643
[20,     1] loss: 1085.508
[21,     1] loss: 1059.589
[22,     1] loss: 1096.947
[23,     1] loss: 1090.772
[24,     1] loss: 1046.793
[25,     1] loss: 1031.606
[26,     1] loss: 1034.907
[27,     1] loss: 1021.578
[28,     1] loss: 998.406
[29,     1] loss: 1015.253
[30,     1] loss: 991.138
[31,     1] loss: 1013.999
[32,     1] loss: 1039.596
[33,     1] loss: 1002.762
[34,     1] loss: 985.645
[35,     1] loss: 990.263
[36,     1] loss: 980.060
[37,     1] loss: 990.765
[38,     1] loss: 997.988
[39,     1] loss: 936.382
[40,     1] loss: 938.945
[41,     1] loss: 987.701
[42,     1] loss: 976.464
[43,     1] loss: 915.653
[44,     1] loss: 928.753
[45,     1] loss: 946.669
[46,     1] loss: 908.629
[47,     1] loss: 915.152
[48,     1] loss: 918.005
[49,     1] loss: 916.635
[50,     1] loss: 923.182
[51,     1] loss: 896.210
[52,     1] loss: 862.489
[53,     1] loss: 869.567
[54,     1] loss: 863.525
[55,     1] loss: 838.487
[56,     1] loss: 827.050
[57,     1] loss: 809.169
[58,     1] loss: 810.823
[59,     1] loss: 848.292
[60,     1] loss: 833.455
[61,     1] loss: 804.355
[62,     1] loss: 809.910
Early stopping applied (best metric=0.9433876276016235)
Finished Training
Total time taken: 10.194010257720947
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1281.943
[2,     1] loss: 1273.920
[3,     1] loss: 1287.158
[4,     1] loss: 1284.810
[5,     1] loss: 1282.557
[6,     1] loss: 1277.051
[7,     1] loss: 1274.351
[8,     1] loss: 1272.437
[9,     1] loss: 1264.495
[10,     1] loss: 1260.113
[11,     1] loss: 1237.138
[12,     1] loss: 1214.589
[13,     1] loss: 1175.733
[14,     1] loss: 1123.200
[15,     1] loss: 1104.157
[16,     1] loss: 1089.410
[17,     1] loss: 1074.598
[18,     1] loss: 1103.009
[19,     1] loss: 1132.514
[20,     1] loss: 1061.089
[21,     1] loss: 1084.766
[22,     1] loss: 1119.851
[23,     1] loss: 1032.538
[24,     1] loss: 1056.895
[25,     1] loss: 1087.430
[26,     1] loss: 1062.312
[27,     1] loss: 1007.184
[28,     1] loss: 1047.891
[29,     1] loss: 1005.959
[30,     1] loss: 1002.158
[31,     1] loss: 1029.627
[32,     1] loss: 1034.514
[33,     1] loss: 966.827
[34,     1] loss: 982.910
[35,     1] loss: 1007.561
[36,     1] loss: 972.846
[37,     1] loss: 967.330
[38,     1] loss: 991.188
[39,     1] loss: 936.127
[40,     1] loss: 909.638
[41,     1] loss: 946.345
[42,     1] loss: 986.545
[43,     1] loss: 904.859
[44,     1] loss: 927.191
[45,     1] loss: 875.818
[46,     1] loss: 887.294
[47,     1] loss: 918.897
[48,     1] loss: 891.514
[49,     1] loss: 915.520
[50,     1] loss: 894.909
[51,     1] loss: 820.623
[52,     1] loss: 849.845
[53,     1] loss: 804.384
[54,     1] loss: 826.897
[55,     1] loss: 851.106
[56,     1] loss: 771.326
[57,     1] loss: 810.119
Early stopping applied (best metric=0.8318816423416138)
Finished Training
Total time taken: 8.070007801055908
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1281.551
[2,     1] loss: 1277.411
[3,     1] loss: 1283.216
[4,     1] loss: 1282.156
[5,     1] loss: 1278.652
[6,     1] loss: 1278.932
[7,     1] loss: 1271.837
[8,     1] loss: 1261.760
[9,     1] loss: 1248.677
[10,     1] loss: 1214.971
[11,     1] loss: 1182.155
[12,     1] loss: 1130.115
[13,     1] loss: 1087.508
[14,     1] loss: 1137.460
[15,     1] loss: 1037.248
[16,     1] loss: 1095.042
[17,     1] loss: 1029.093
[18,     1] loss: 1078.666
[19,     1] loss: 1051.624
[20,     1] loss: 1057.733
[21,     1] loss: 1024.526
[22,     1] loss: 1037.436
[23,     1] loss: 965.306
[24,     1] loss: 989.720
[25,     1] loss: 999.527
[26,     1] loss: 1005.174
[27,     1] loss: 941.250
[28,     1] loss: 940.155
[29,     1] loss: 964.507
[30,     1] loss: 966.475
[31,     1] loss: 884.252
[32,     1] loss: 898.682
[33,     1] loss: 943.054
[34,     1] loss: 880.698
[35,     1] loss: 871.990
[36,     1] loss: 940.520
[37,     1] loss: 932.440
[38,     1] loss: 868.226
[39,     1] loss: 902.841
[40,     1] loss: 879.544
[41,     1] loss: 864.920
[42,     1] loss: 842.634
[43,     1] loss: 832.226
[44,     1] loss: 803.279
[45,     1] loss: 798.340
[46,     1] loss: 814.391
[47,     1] loss: 831.155
[48,     1] loss: 775.634
[49,     1] loss: 781.792
[50,     1] loss: 759.024
[51,     1] loss: 793.831
Early stopping applied (best metric=0.8036247491836548)
Finished Training
Total time taken: 8.565010786056519
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1283.218
[2,     1] loss: 1288.158
[3,     1] loss: 1281.848
[4,     1] loss: 1279.687
[5,     1] loss: 1283.301
[6,     1] loss: 1275.494
[7,     1] loss: 1265.162
[8,     1] loss: 1249.501
[9,     1] loss: 1225.450
[10,     1] loss: 1176.593
[11,     1] loss: 1126.752
[12,     1] loss: 1100.452
[13,     1] loss: 1121.729
[14,     1] loss: 1101.079
[15,     1] loss: 1087.359
[16,     1] loss: 1082.218
[17,     1] loss: 1011.140
[18,     1] loss: 1069.300
[19,     1] loss: 1020.584
[20,     1] loss: 1049.835
[21,     1] loss: 1011.872
[22,     1] loss: 1059.517
[23,     1] loss: 1010.756
[24,     1] loss: 998.889
[25,     1] loss: 1009.818
[26,     1] loss: 1028.124
[27,     1] loss: 964.558
[28,     1] loss: 941.544
[29,     1] loss: 939.025
[30,     1] loss: 966.553
[31,     1] loss: 957.739
[32,     1] loss: 992.404
[33,     1] loss: 935.047
[34,     1] loss: 908.602
[35,     1] loss: 940.728
[36,     1] loss: 908.247
[37,     1] loss: 908.965
[38,     1] loss: 877.274
[39,     1] loss: 901.326
[40,     1] loss: 840.509
[41,     1] loss: 924.142
[42,     1] loss: 898.647
[43,     1] loss: 852.741
[44,     1] loss: 862.093
[45,     1] loss: 914.564
[46,     1] loss: 834.449
[47,     1] loss: 832.811
[48,     1] loss: 861.397
[49,     1] loss: 821.810
[50,     1] loss: 840.698
[51,     1] loss: 879.526
[52,     1] loss: 776.088
[53,     1] loss: 859.231
[54,     1] loss: 773.442
[55,     1] loss: 788.508
[56,     1] loss: 727.857
[57,     1] loss: 771.540
[58,     1] loss: 759.011
[59,     1] loss: 754.001
Early stopping applied (best metric=0.6966769695281982)
Finished Training
Total time taken: 8.179007291793823
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1284.190
[2,     1] loss: 1285.441
[3,     1] loss: 1278.363
[4,     1] loss: 1277.284
[5,     1] loss: 1278.405
[6,     1] loss: 1279.334
[7,     1] loss: 1283.003
[8,     1] loss: 1270.217
[9,     1] loss: 1254.185
[10,     1] loss: 1233.905
[11,     1] loss: 1200.594
[12,     1] loss: 1153.823
[13,     1] loss: 1100.135
[14,     1] loss: 1101.413
[15,     1] loss: 1119.930
[16,     1] loss: 1137.972
[17,     1] loss: 1087.250
[18,     1] loss: 1048.177
[19,     1] loss: 1055.631
[20,     1] loss: 1032.787
[21,     1] loss: 1055.253
[22,     1] loss: 1010.166
[23,     1] loss: 1033.558
[24,     1] loss: 1051.202
[25,     1] loss: 992.773
[26,     1] loss: 1008.849
[27,     1] loss: 1003.764
[28,     1] loss: 971.659
[29,     1] loss: 993.147
[30,     1] loss: 967.972
[31,     1] loss: 949.483
[32,     1] loss: 951.129
[33,     1] loss: 913.464
[34,     1] loss: 921.802
[35,     1] loss: 919.606
[36,     1] loss: 866.023
[37,     1] loss: 953.981
[38,     1] loss: 886.826
[39,     1] loss: 916.822
[40,     1] loss: 870.342
[41,     1] loss: 864.519
[42,     1] loss: 855.887
[43,     1] loss: 858.803
[44,     1] loss: 862.723
[45,     1] loss: 823.664
[46,     1] loss: 824.602
[47,     1] loss: 829.116
[48,     1] loss: 797.850
[49,     1] loss: 799.474
[50,     1] loss: 812.718
[51,     1] loss: 802.782
[52,     1] loss: 781.610
Early stopping applied (best metric=0.7924224138259888)
Finished Training
Total time taken: 8.001008033752441
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1284.987
[2,     1] loss: 1291.144
[3,     1] loss: 1278.252
[4,     1] loss: 1280.281
[5,     1] loss: 1282.310
[6,     1] loss: 1277.970
[7,     1] loss: 1279.094
[8,     1] loss: 1276.622
[9,     1] loss: 1276.899
[10,     1] loss: 1270.223
[11,     1] loss: 1269.762
[12,     1] loss: 1264.121
[13,     1] loss: 1218.998
[14,     1] loss: 1209.390
[15,     1] loss: 1149.437
[16,     1] loss: 1114.875
[17,     1] loss: 1113.676
[18,     1] loss: 1076.841
[19,     1] loss: 1089.368
[20,     1] loss: 1044.985
[21,     1] loss: 1009.753
[22,     1] loss: 1068.312
[23,     1] loss: 1075.204
[24,     1] loss: 998.196
[25,     1] loss: 1012.003
[26,     1] loss: 1033.404
[27,     1] loss: 981.217
[28,     1] loss: 1007.617
[29,     1] loss: 1012.855
[30,     1] loss: 951.472
[31,     1] loss: 970.484
[32,     1] loss: 988.381
[33,     1] loss: 950.965
[34,     1] loss: 964.753
[35,     1] loss: 928.589
[36,     1] loss: 915.921
[37,     1] loss: 885.301
[38,     1] loss: 894.325
[39,     1] loss: 939.678
[40,     1] loss: 908.193
[41,     1] loss: 899.398
[42,     1] loss: 887.557
[43,     1] loss: 834.952
[44,     1] loss: 838.324
[45,     1] loss: 851.658
[46,     1] loss: 831.346
[47,     1] loss: 835.258
[48,     1] loss: 815.093
[49,     1] loss: 873.059
[50,     1] loss: 801.449
[51,     1] loss: 882.049
[52,     1] loss: 823.145
[53,     1] loss: 831.273
[54,     1] loss: 771.922
[55,     1] loss: 865.979
[56,     1] loss: 812.069
[57,     1] loss: 772.158
[58,     1] loss: 767.906
[59,     1] loss: 849.073
Early stopping applied (best metric=0.9234474897384644)
Finished Training
Total time taken: 9.755008697509766
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1283.207
[2,     1] loss: 1283.978
[3,     1] loss: 1288.209
[4,     1] loss: 1276.678
[5,     1] loss: 1274.801
[6,     1] loss: 1271.628
[7,     1] loss: 1250.332
[8,     1] loss: 1222.461
[9,     1] loss: 1172.355
[10,     1] loss: 1139.764
[11,     1] loss: 1111.336
[12,     1] loss: 1086.386
[13,     1] loss: 1091.141
[14,     1] loss: 1084.688
[15,     1] loss: 1056.159
[16,     1] loss: 1065.828
[17,     1] loss: 1022.418
[18,     1] loss: 1037.437
[19,     1] loss: 1031.312
[20,     1] loss: 1024.739
[21,     1] loss: 1024.097
[22,     1] loss: 998.501
[23,     1] loss: 987.828
[24,     1] loss: 1055.214
[25,     1] loss: 975.936
[26,     1] loss: 969.729
[27,     1] loss: 969.679
[28,     1] loss: 1015.866
[29,     1] loss: 1005.107
[30,     1] loss: 1007.614
[31,     1] loss: 967.993
[32,     1] loss: 948.899
[33,     1] loss: 956.104
[34,     1] loss: 918.421
[35,     1] loss: 905.621
[36,     1] loss: 909.625
[37,     1] loss: 919.345
[38,     1] loss: 916.075
[39,     1] loss: 891.185
[40,     1] loss: 916.548
[41,     1] loss: 897.660
[42,     1] loss: 890.460
[43,     1] loss: 881.489
[44,     1] loss: 850.102
[45,     1] loss: 868.294
[46,     1] loss: 887.797
[47,     1] loss: 841.907
[48,     1] loss: 850.166
[49,     1] loss: 854.945
[50,     1] loss: 853.670
[51,     1] loss: 807.337
[52,     1] loss: 791.322
[53,     1] loss: 753.859
[54,     1] loss: 757.421
[55,     1] loss: 772.750
[56,     1] loss: 742.668
[57,     1] loss: 765.893
[58,     1] loss: 785.928
[59,     1] loss: 705.829
[60,     1] loss: 716.144
[61,     1] loss: 707.317
[62,     1] loss: 725.148
Early stopping applied (best metric=0.786308228969574)
Finished Training
Total time taken: 10.393010139465332
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1284.448
[2,     1] loss: 1289.860
[3,     1] loss: 1293.946
[4,     1] loss: 1281.244
[5,     1] loss: 1278.038
[6,     1] loss: 1275.931
[7,     1] loss: 1276.265
[8,     1] loss: 1275.275
[9,     1] loss: 1268.484
[10,     1] loss: 1273.072
[11,     1] loss: 1261.633
[12,     1] loss: 1248.660
[13,     1] loss: 1214.764
[14,     1] loss: 1188.331
[15,     1] loss: 1148.730
[16,     1] loss: 1099.780
[17,     1] loss: 1111.967
[18,     1] loss: 1123.821
[19,     1] loss: 1101.254
[20,     1] loss: 1084.982
[21,     1] loss: 1055.625
[22,     1] loss: 1075.643
[23,     1] loss: 1069.673
[24,     1] loss: 1068.698
[25,     1] loss: 1071.715
[26,     1] loss: 1021.126
[27,     1] loss: 1002.053
[28,     1] loss: 1025.006
[29,     1] loss: 985.158
[30,     1] loss: 992.529
[31,     1] loss: 976.921
[32,     1] loss: 973.160
[33,     1] loss: 966.905
[34,     1] loss: 901.948
[35,     1] loss: 956.404
[36,     1] loss: 921.861
[37,     1] loss: 921.564
[38,     1] loss: 918.043
[39,     1] loss: 895.923
[40,     1] loss: 945.075
[41,     1] loss: 856.885
[42,     1] loss: 905.420
[43,     1] loss: 859.233
[44,     1] loss: 885.488
[45,     1] loss: 846.818
[46,     1] loss: 840.815
[47,     1] loss: 848.590
[48,     1] loss: 848.584
[49,     1] loss: 836.652
[50,     1] loss: 821.639
[51,     1] loss: 804.829
[52,     1] loss: 861.070
[53,     1] loss: 863.920
[54,     1] loss: 773.628
[55,     1] loss: 823.471
[56,     1] loss: 746.926
[57,     1] loss: 864.719
Early stopping applied (best metric=0.7923966646194458)
Finished Training
Total time taken: 8.80800747871399
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1283.996
[2,     1] loss: 1286.862
[3,     1] loss: 1293.463
[4,     1] loss: 1280.547
[5,     1] loss: 1283.045
[6,     1] loss: 1281.261
[7,     1] loss: 1278.164
[8,     1] loss: 1282.571
[9,     1] loss: 1280.487
[10,     1] loss: 1276.893
[11,     1] loss: 1277.122
[12,     1] loss: 1275.949
[13,     1] loss: 1271.910
[14,     1] loss: 1259.068
[15,     1] loss: 1252.273
[16,     1] loss: 1240.560
[17,     1] loss: 1214.597
[18,     1] loss: 1188.698
[19,     1] loss: 1145.370
[20,     1] loss: 1131.041
[21,     1] loss: 1089.653
[22,     1] loss: 1089.036
[23,     1] loss: 1078.246
[24,     1] loss: 1076.661
[25,     1] loss: 1063.838
[26,     1] loss: 1086.728
[27,     1] loss: 1004.658
[28,     1] loss: 1001.759
[29,     1] loss: 1011.873
[30,     1] loss: 1022.653
[31,     1] loss: 1017.956
[32,     1] loss: 989.634
[33,     1] loss: 1003.199
[34,     1] loss: 995.210
[35,     1] loss: 935.523
[36,     1] loss: 963.177
[37,     1] loss: 922.153
[38,     1] loss: 972.819
[39,     1] loss: 932.646
[40,     1] loss: 908.722
[41,     1] loss: 923.486
[42,     1] loss: 906.011
[43,     1] loss: 936.747
[44,     1] loss: 917.364
[45,     1] loss: 903.385
[46,     1] loss: 951.417
[47,     1] loss: 896.223
[48,     1] loss: 925.108
[49,     1] loss: 899.102
[50,     1] loss: 864.726
[51,     1] loss: 944.524
[52,     1] loss: 892.753
[53,     1] loss: 844.599
[54,     1] loss: 930.685
[55,     1] loss: 917.818
[56,     1] loss: 792.374
[57,     1] loss: 888.755
[58,     1] loss: 857.061
[59,     1] loss: 820.899
[60,     1] loss: 835.510
[61,     1] loss: 801.414
[62,     1] loss: 769.716
[63,     1] loss: 800.747
[64,     1] loss: 830.752
[65,     1] loss: 777.916
[66,     1] loss: 808.539
[67,     1] loss: 816.846
[68,     1] loss: 739.162
[69,     1] loss: 788.941
[70,     1] loss: 740.108
[71,     1] loss: 729.416
[72,     1] loss: 776.077
[73,     1] loss: 697.248
[74,     1] loss: 757.943
[75,     1] loss: 737.084
[76,     1] loss: 671.822
[77,     1] loss: 707.564
[78,     1] loss: 722.237
Early stopping applied (best metric=0.7959911823272705)
Finished Training
Total time taken: 12.422015190124512
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1281.814
[2,     1] loss: 1280.575
[3,     1] loss: 1279.591
[4,     1] loss: 1279.443
[5,     1] loss: 1273.678
[6,     1] loss: 1266.358
[7,     1] loss: 1247.260
[8,     1] loss: 1200.557
[9,     1] loss: 1155.206
[10,     1] loss: 1123.507
[11,     1] loss: 1098.084
[12,     1] loss: 1070.852
[13,     1] loss: 1040.278
[14,     1] loss: 1061.062
[15,     1] loss: 1105.846
[16,     1] loss: 1021.717
[17,     1] loss: 1037.209
[18,     1] loss: 1026.172
[19,     1] loss: 1023.378
[20,     1] loss: 1015.874
[21,     1] loss: 964.158
[22,     1] loss: 1020.907
[23,     1] loss: 968.980
[24,     1] loss: 964.635
[25,     1] loss: 943.682
[26,     1] loss: 945.578
[27,     1] loss: 935.173
[28,     1] loss: 934.462
[29,     1] loss: 930.896
[30,     1] loss: 953.481
[31,     1] loss: 916.689
[32,     1] loss: 995.813
[33,     1] loss: 906.879
[34,     1] loss: 907.478
[35,     1] loss: 860.374
[36,     1] loss: 944.235
[37,     1] loss: 930.714
[38,     1] loss: 857.432
[39,     1] loss: 841.564
[40,     1] loss: 882.457
[41,     1] loss: 890.519
[42,     1] loss: 854.024
[43,     1] loss: 904.601
[44,     1] loss: 834.078
[45,     1] loss: 843.003
[46,     1] loss: 847.281
[47,     1] loss: 852.348
[48,     1] loss: 805.269
[49,     1] loss: 786.551
[50,     1] loss: 771.873
[51,     1] loss: 750.711
[52,     1] loss: 796.375
[53,     1] loss: 723.753
[54,     1] loss: 756.255
[55,     1] loss: 802.495
[56,     1] loss: 727.411
[57,     1] loss: 744.333
[58,     1] loss: 761.482
[59,     1] loss: 745.771
[60,     1] loss: 737.757
[61,     1] loss: 665.488
[62,     1] loss: 683.647
[63,     1] loss: 681.068
[64,     1] loss: 630.493
[65,     1] loss: 623.672
[66,     1] loss: 641.361
[67,     1] loss: 638.489
[68,     1] loss: 656.840
Early stopping applied (best metric=0.7605481743812561)
Finished Training
Total time taken: 11.37900996208191
{'Hydroxylation-K Validation Accuracy': 0.7843971631205674, 'Hydroxylation-K Validation Sensitivity': 0.674074074074074, 'Hydroxylation-K Validation Specificity': 0.8122807017543859, 'Hydroxylation-K Validation Precision': 0.4773514448514449, 'Hydroxylation-K AUC ROC': 0.8146978557504874, 'Hydroxylation-K AUC PR': 0.5857477633752962, 'Hydroxylation-K MCC': 0.43283327982957703, 'Hydroxylation-K F1': 0.5562972743842309, 'Validation Loss (Hydroxylation-K)': 0.4226837605237961, 'Hydroxylation-P Validation Accuracy': 0.7996662605959088, 'Hydroxylation-P Validation Sensitivity': 0.7334391534391534, 'Hydroxylation-P Validation Specificity': 0.8139907227293132, 'Hydroxylation-P Validation Precision': 0.4629602028140723, 'Hydroxylation-P AUC ROC': 0.8340540813894847, 'Hydroxylation-P AUC PR': 0.5652351583255546, 'Hydroxylation-P MCC': 0.466096481561788, 'Hydroxylation-P F1': 0.5649689516780225, 'Validation Loss (Hydroxylation-P)': 0.3874909241994222, 'Validation Loss (total)': 0.8101746877034505, 'TimeToTrain': 9.967276620864869}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016859789915260523,
 'learning_rate_Hydroxylation-K': 0.0032055875951736376,
 'learning_rate_Hydroxylation-P': 0.005934111074410027,
 'log_base': 1.763489944073123,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2494307900,
 'sample_weights': [1.763167305809969, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6172758415035053,
 'weight_decay_Hydroxylation-K': 1.0610990525461999,
 'weight_decay_Hydroxylation-P': 5.303332142211013}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1528.897
[2,     1] loss: 1535.126
[3,     1] loss: 1531.915
[4,     1] loss: 1528.923
[5,     1] loss: 1527.562
[6,     1] loss: 1524.688
[7,     1] loss: 1519.066
[8,     1] loss: 1520.440
[9,     1] loss: 1507.941
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031903827719977507,
 'learning_rate_Hydroxylation-K': 0.0016208098141178406,
 'learning_rate_Hydroxylation-P': 0.007532248761238926,
 'log_base': 1.029392470058225,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3436888109,
 'sample_weights': [2.942814283420322, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.787059746144023,
 'weight_decay_Hydroxylation-K': 3.988135844878172,
 'weight_decay_Hydroxylation-P': 2.9157439252834663}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 18682.166
Exploding loss, terminate run (best metric=1.0963656902313232)
Finished Training
Total time taken: 0.21199893951416016
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 18743.531
Exploding loss, terminate run (best metric=1.0911564826965332)
Finished Training
Total time taken: 0.22900056838989258
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 18723.256
Exploding loss, terminate run (best metric=1.0971100330352783)
Finished Training
Total time taken: 0.23099875450134277
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 18727.041
Exploding loss, terminate run (best metric=1.07273268699646)
Finished Training
Total time taken: 0.20499944686889648
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 18796.365
Exploding loss, terminate run (best metric=1.0803072452545166)
Finished Training
Total time taken: 0.21899938583374023
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 18639.172
Exploding loss, terminate run (best metric=1.1021023988723755)
Finished Training
Total time taken: 0.22799992561340332
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 18694.607
Exploding loss, terminate run (best metric=1.0953408479690552)
Finished Training
Total time taken: 0.2349989414215088
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 18666.316
Exploding loss, terminate run (best metric=1.0909020900726318)
Finished Training
Total time taken: 0.2090001106262207
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 18765.559
Exploding loss, terminate run (best metric=1.0730119943618774)
Finished Training
Total time taken: 0.23000192642211914
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 18786.812
Exploding loss, terminate run (best metric=1.0811376571655273)
Finished Training
Total time taken: 0.23400115966796875
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 18718.318
Exploding loss, terminate run (best metric=1.0964144468307495)
Finished Training
Total time taken: 0.20099759101867676
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 18632.383
Exploding loss, terminate run (best metric=1.1096312999725342)
Finished Training
Total time taken: 0.20300030708312988
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 18705.711
Exploding loss, terminate run (best metric=1.0923590660095215)
Finished Training
Total time taken: 0.22099947929382324
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 18715.609
Exploding loss, terminate run (best metric=1.0722436904907227)
Finished Training
Total time taken: 0.23800253868103027
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 18839.086
Exploding loss, terminate run (best metric=1.0859098434448242)
Finished Training
Total time taken: 0.24399900436401367
{'Hydroxylation-K Validation Accuracy': 0.4805555555555555, 'Hydroxylation-K Validation Sensitivity': 0.5333333333333333, 'Hydroxylation-K Validation Specificity': 0.4666666666666667, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.6520662768031189, 'Hydroxylation-K AUC PR': 0.36012543904974087, 'Hydroxylation-K MCC': 0.0, 'Hydroxylation-K F1': 0.1792282430213465, 'Validation Loss (Hydroxylation-K)': 0.5572483817736308, 'Hydroxylation-P Validation Accuracy': 0.48351413633825696, 'Hydroxylation-P Validation Sensitivity': 0.5333333333333333, 'Hydroxylation-P Validation Specificity': 0.47276422764227644, 'Hydroxylation-P Validation Precision': nan, 'Hydroxylation-P AUC ROC': 0.609458972343156, 'Hydroxylation-P AUC PR': 0.2849001158841076, 'Hydroxylation-P MCC': 0.008793414740966416, 'Hydroxylation-P F1': 0.16170204602988444, 'Validation Loss (Hydroxylation-P)': 0.5318666458129883, 'Validation Loss (total)': 1.089115031560262, 'TimeToTrain': 0.22259987195332845}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002207171928348131,
 'learning_rate_Hydroxylation-K': 0.0005008565032014135,
 'learning_rate_Hydroxylation-P': 0.005927117642281535,
 'log_base': 2.992997135752308,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4217248798,
 'sample_weights': [57.67176833697768, 7.193992073979866],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3756969275272388,
 'weight_decay_Hydroxylation-K': 2.441219237733593,
 'weight_decay_Hydroxylation-P': 2.3016288345672145}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.609
[2,     1] loss: 1235.607
[3,     1] loss: 1229.533
[4,     1] loss: 1229.462
[5,     1] loss: 1226.944
[6,     1] loss: 1226.376
[7,     1] loss: 1226.668
[8,     1] loss: 1225.072
[9,     1] loss: 1217.819
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006455799567180444,
 'learning_rate_Hydroxylation-K': 0.0014147949611861307,
 'learning_rate_Hydroxylation-P': 0.005390222018947006,
 'log_base': 1.4020882601669782,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3580510548,
 'sample_weights': [1.522832075331495, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.006758578391022,
 'weight_decay_Hydroxylation-K': 4.918874740026069,
 'weight_decay_Hydroxylation-P': 4.437061807913093}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1952.854
[2,     1] loss: 1971.165
[3,     1] loss: 1980.042
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031806349261865514,
 'learning_rate_Hydroxylation-K': 0.000784118044028148,
 'learning_rate_Hydroxylation-P': 0.007751164756894298,
 'log_base': 2.9779687602904805,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1975255549,
 'sample_weights': [4.939725453261171, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.65586438125017,
 'weight_decay_Hydroxylation-K': 0.2663020180941751,
 'weight_decay_Hydroxylation-P': 5.1531286637749885}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.811
[2,     1] loss: 1233.836
[3,     1] loss: 1234.450
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033592629447826783,
 'learning_rate_Hydroxylation-K': 0.0037214989083280007,
 'learning_rate_Hydroxylation-P': 0.006070524767066123,
 'log_base': 1.2308019193109747,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2059808812,
 'sample_weights': [1.5298568034947004, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.407473784239185,
 'weight_decay_Hydroxylation-K': 4.082484561258621,
 'weight_decay_Hydroxylation-P': 2.9910704554281606}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2597.587
[2,     1] loss: 2617.053
[3,     1] loss: 2613.949
[4,     1] loss: 2605.665
[5,     1] loss: 2617.409
[6,     1] loss: 2600.257
[7,     1] loss: 2595.519
[8,     1] loss: 2583.095
[9,     1] loss: 2611.518
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004461142954273351,
 'learning_rate_Hydroxylation-K': 0.008501051408212081,
 'learning_rate_Hydroxylation-P': 0.00795199245273155,
 'log_base': 2.605305004194697,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3742635356,
 'sample_weights': [8.03908082918406, 1.0049238158574458],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.035817870412874,
 'weight_decay_Hydroxylation-K': 9.623872991278642,
 'weight_decay_Hydroxylation-P': 8.124761660001623}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1277.224
[2,     1] loss: 1274.280
[3,     1] loss: 1275.941
[4,     1] loss: 1263.468
[5,     1] loss: 1255.016
[6,     1] loss: 1214.833
[7,     1] loss: 1170.612
[8,     1] loss: 1236.381
[9,     1] loss: 1134.947
[10,     1] loss: 1114.611
[11,     1] loss: 1083.140
[12,     1] loss: 1119.854
[13,     1] loss: 1012.940
[14,     1] loss: 1037.150
[15,     1] loss: 1069.217
[16,     1] loss: 1030.853
[17,     1] loss: 1013.585
[18,     1] loss: 1017.182
[19,     1] loss: 1033.311
[20,     1] loss: 1019.094
[21,     1] loss: 993.117
[22,     1] loss: 1009.237
[23,     1] loss: 986.426
[24,     1] loss: 970.703
[25,     1] loss: 971.728
[26,     1] loss: 950.017
[27,     1] loss: 923.517
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002243897058524635,
 'learning_rate_Hydroxylation-K': 0.0027718150129276715,
 'learning_rate_Hydroxylation-P': 0.005504523699849926,
 'log_base': 2.4734014248224865,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3413679937,
 'sample_weights': [1.7434531658257326, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8016360667812772,
 'weight_decay_Hydroxylation-K': 0.25973506408169356,
 'weight_decay_Hydroxylation-P': 3.578471994344545}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1303.642
[2,     1] loss: 1296.717
[3,     1] loss: 1295.943
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030021213024465543,
 'learning_rate_Hydroxylation-K': 0.0032485332987576884,
 'learning_rate_Hydroxylation-P': 0.005439934329030696,
 'log_base': 2.218592890157076,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4051850378,
 'sample_weights': [1.8434779794913707, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.21613343572105817,
 'weight_decay_Hydroxylation-K': 2.6804974924276004,
 'weight_decay_Hydroxylation-P': 3.8992446188936976}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1348.783
[2,     1] loss: 1353.752
[3,     1] loss: 1350.794
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00977897653055855,
 'learning_rate_Hydroxylation-K': 0.0075817989873561385,
 'learning_rate_Hydroxylation-P': 0.00917805442757947,
 'log_base': 2.415694746259825,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3282003906,
 'sample_weights': [2.0949923121225384, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5410532217053068,
 'weight_decay_Hydroxylation-K': 8.09883412020838,
 'weight_decay_Hydroxylation-P': 6.533845318764019}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1309.758
[2,     1] loss: 1318.037
[3,     1] loss: 1308.990
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013981922959761248,
 'learning_rate_Hydroxylation-K': 0.002787858167025337,
 'learning_rate_Hydroxylation-P': 0.006522960985157585,
 'log_base': 2.945511664696087,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 451500785,
 'sample_weights': [1.8928207430894815, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.475060159674156,
 'weight_decay_Hydroxylation-K': 1.2330575450252081,
 'weight_decay_Hydroxylation-P': 4.962378917623221}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.004
[2,     1] loss: 1236.551
[3,     1] loss: 1232.742
[4,     1] loss: 1231.025
[5,     1] loss: 1233.899
[6,     1] loss: 1232.475
[7,     1] loss: 1225.319
[8,     1] loss: 1225.051
[9,     1] loss: 1210.584
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00511472615200304,
 'learning_rate_Hydroxylation-K': 0.004094600114610271,
 'learning_rate_Hydroxylation-P': 0.005194455504145652,
 'log_base': 2.1817141079707993,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4073295476,
 'sample_weights': [1.545376401349398, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.56830070584407,
 'weight_decay_Hydroxylation-K': 6.0371605292912704,
 'weight_decay_Hydroxylation-P': 2.146729266792672}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1363.174
[2,     1] loss: 1368.900
[3,     1] loss: 1366.610
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003537018670839665,
 'learning_rate_Hydroxylation-K': 0.00015783371805989357,
 'learning_rate_Hydroxylation-P': 0.001845070691791256,
 'log_base': 2.2878518659336704,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1252420757,
 'sample_weights': [2.140007583282386, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.336711574274843,
 'weight_decay_Hydroxylation-K': 8.500440038211014,
 'weight_decay_Hydroxylation-P': 0.016779105222534896}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1334.643
[2,     1] loss: 1337.956
[3,     1] loss: 1337.658
[4,     1] loss: 1328.113
[5,     1] loss: 1328.866
[6,     1] loss: 1319.430
[7,     1] loss: 1310.190
[8,     1] loss: 1282.049
[9,     1] loss: 1252.815
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015177959070468167,
 'learning_rate_Hydroxylation-K': 0.002512036736993111,
 'learning_rate_Hydroxylation-P': 0.005760047862305374,
 'log_base': 1.15747429669139,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1453889288,
 'sample_weights': [2.0171776987249466, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.320576431266868,
 'weight_decay_Hydroxylation-K': 3.9379525456820095,
 'weight_decay_Hydroxylation-P': 1.5373564607649772}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3724.187
[2,     1] loss: 3692.346
[3,     1] loss: 3699.510
[4,     1] loss: 3696.909
[5,     1] loss: 3684.185
[6,     1] loss: 3673.716
[7,     1] loss: 3687.190
[8,     1] loss: 3691.080
[9,     1] loss: 3671.908
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035980198455489417,
 'learning_rate_Hydroxylation-K': 0.0034429832082030387,
 'learning_rate_Hydroxylation-P': 0.001319085104901258,
 'log_base': 2.5723107018550215,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3744652399,
 'sample_weights': [11.415752960884618, 1.4270240926912625],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9916419255548883,
 'weight_decay_Hydroxylation-K': 9.450585946940135,
 'weight_decay_Hydroxylation-P': 1.1002090231518373}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1280.035
[2,     1] loss: 1277.546
[3,     1] loss: 1294.518
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005519885979088021,
 'learning_rate_Hydroxylation-K': 0.004024102802830487,
 'learning_rate_Hydroxylation-P': 0.006582642674498772,
 'log_base': 2.707651703557928,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1025705841,
 'sample_weights': [1.7669718650047448, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.004597491803361,
 'weight_decay_Hydroxylation-K': 0.3030001169583032,
 'weight_decay_Hydroxylation-P': 6.135058108921669}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1264.587
[2,     1] loss: 1267.903
[3,     1] loss: 1256.779
[4,     1] loss: 1264.454
[5,     1] loss: 1256.501
[6,     1] loss: 1239.360
[7,     1] loss: 1207.119
[8,     1] loss: 1155.947
[9,     1] loss: 1207.429
[10,     1] loss: 1135.110
[11,     1] loss: 1077.691
[12,     1] loss: 1091.098
[13,     1] loss: 1045.677
[14,     1] loss: 1037.828
[15,     1] loss: 1069.150
[16,     1] loss: 1025.576
[17,     1] loss: 1015.565
[18,     1] loss: 1039.462
[19,     1] loss: 1009.042
[20,     1] loss: 1022.379
[21,     1] loss: 986.502
[22,     1] loss: 983.325
[23,     1] loss: 974.725
[24,     1] loss: 924.239
[25,     1] loss: 975.022
[26,     1] loss: 929.581
[27,     1] loss: 923.830
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0048594583998360745,
 'learning_rate_Hydroxylation-K': 0.003074595994739295,
 'learning_rate_Hydroxylation-P': 0.0025926203282957043,
 'log_base': 2.7649446937293414,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3917392558,
 'sample_weights': [1.676010209312476, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3649906349825867,
 'weight_decay_Hydroxylation-K': 4.027674357953012,
 'weight_decay_Hydroxylation-P': 0.45968955908342773}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1265.529
[2,     1] loss: 1310.141
[3,     1] loss: 1258.647
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014051666377349753,
 'learning_rate_Hydroxylation-K': 0.006511915658591062,
 'learning_rate_Hydroxylation-P': 0.0010855932154510254,
 'log_base': 2.2564391874900322,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2758463435,
 'sample_weights': [1.6415037159171872, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.236928365413144,
 'weight_decay_Hydroxylation-K': 6.4176598244004825,
 'weight_decay_Hydroxylation-P': 5.431716776195809}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1344.902
[2,     1] loss: 1343.174
[3,     1] loss: 1340.118
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032167350802113958,
 'learning_rate_Hydroxylation-K': 0.0006411462167585642,
 'learning_rate_Hydroxylation-P': 0.005481238243929325,
 'log_base': 2.642443317946235,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3009608503,
 'sample_weights': [2.051447266301062, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.356574776916309,
 'weight_decay_Hydroxylation-K': 2.3645514730795982,
 'weight_decay_Hydroxylation-P': 0.5326737191849453}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1270.850
[2,     1] loss: 1274.790
[3,     1] loss: 1272.506
[4,     1] loss: 1266.120
[5,     1] loss: 1261.432
[6,     1] loss: 1246.812
[7,     1] loss: 1221.477
[8,     1] loss: 1174.818
[9,     1] loss: 1132.052
[10,     1] loss: 1056.100
[11,     1] loss: 1118.644
[12,     1] loss: 1044.832
[13,     1] loss: 1044.536
[14,     1] loss: 1090.363
[15,     1] loss: 1048.990
[16,     1] loss: 1025.547
[17,     1] loss: 1044.319
[18,     1] loss: 1055.545
[19,     1] loss: 998.410
[20,     1] loss: 982.626
[21,     1] loss: 953.363
[22,     1] loss: 1037.777
[23,     1] loss: 949.721
[24,     1] loss: 1018.662
[25,     1] loss: 974.812
[26,     1] loss: 900.610
[27,     1] loss: 965.278
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004730312691510381,
 'learning_rate_Hydroxylation-K': 0.005572642386987702,
 'learning_rate_Hydroxylation-P': 0.001818279946044939,
 'log_base': 1.3656098139177248,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3779060471,
 'sample_weights': [1.7180573172537947, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.394598185084625,
 'weight_decay_Hydroxylation-K': 1.5260759011082992,
 'weight_decay_Hydroxylation-P': 5.370647244507459}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2052.859
[2,     1] loss: 2039.744
[3,     1] loss: 2032.535
[4,     1] loss: 2049.965
[5,     1] loss: 2045.230
[6,     1] loss: 2032.254
[7,     1] loss: 2033.047
[8,     1] loss: 2022.346
[9,     1] loss: 2001.942
[10,     1] loss: 1968.727
[11,     1] loss: 1921.380
[12,     1] loss: 1870.180
[13,     1] loss: 1897.352
[14,     1] loss: 1815.507
[15,     1] loss: 1883.869
[16,     1] loss: 1757.433
[17,     1] loss: 1719.618
[18,     1] loss: 1715.664
[19,     1] loss: 1661.380
[20,     1] loss: 1657.487
[21,     1] loss: 1673.489
[22,     1] loss: 1715.324
[23,     1] loss: 1575.491
[24,     1] loss: 1598.067
[25,     1] loss: 1626.894
[26,     1] loss: 1574.599
[27,     1] loss: 1473.789
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008002194625772202,
 'learning_rate_Hydroxylation-K': 0.00669378857260204,
 'learning_rate_Hydroxylation-P': 0.0019571226144509905,
 'log_base': 2.853302952299553,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2555957764,
 'sample_weights': [5.357629546082195, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.0103582265422695,
 'weight_decay_Hydroxylation-K': 1.6528086160839734,
 'weight_decay_Hydroxylation-P': 5.313697967883962}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.347
[2,     1] loss: 1253.166
[3,     1] loss: 1255.008
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0042045037838439655,
 'learning_rate_Hydroxylation-K': 0.003459365435329549,
 'learning_rate_Hydroxylation-P': 0.003842048398777509,
 'log_base': 2.4904377162131333,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2892946218,
 'sample_weights': [1.5922549976751406, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.274664311208893,
 'weight_decay_Hydroxylation-K': 3.5172856183570533,
 'weight_decay_Hydroxylation-P': 3.6732852493320167}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1296.486
[2,     1] loss: 1294.474
[3,     1] loss: 1298.502
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005175146703338907,
 'learning_rate_Hydroxylation-K': 0.0074677051354743226,
 'learning_rate_Hydroxylation-P': 0.0023725744213511616,
 'log_base': 2.578729237842153,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2234291286,
 'sample_weights': [1.8296099772968255, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.243213403027529,
 'weight_decay_Hydroxylation-K': 9.123177611234317,
 'weight_decay_Hydroxylation-P': 5.793557328243521}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.055
[2,     1] loss: 1282.062
[3,     1] loss: 1281.779
[4,     1] loss: 1283.723
[5,     1] loss: 1281.937
[6,     1] loss: 1279.350
[7,     1] loss: 1273.327
[8,     1] loss: 1273.232
[9,     1] loss: 1261.978
[10,     1] loss: 1233.807
[11,     1] loss: 1208.522
[12,     1] loss: 1161.292
[13,     1] loss: 1120.699
[14,     1] loss: 1118.302
[15,     1] loss: 1138.183
[16,     1] loss: 1106.633
[17,     1] loss: 1026.941
[18,     1] loss: 1050.799
[19,     1] loss: 1082.249
[20,     1] loss: 1033.903
[21,     1] loss: 1020.709
[22,     1] loss: 1058.048
[23,     1] loss: 1013.198
[24,     1] loss: 984.297
[25,     1] loss: 951.733
[26,     1] loss: 953.416
[27,     1] loss: 974.121
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002336528364686657,
 'learning_rate_Hydroxylation-K': 0.009535318641650248,
 'learning_rate_Hydroxylation-P': 0.0013913338763922708,
 'log_base': 2.6389283582696286,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 54193724,
 'sample_weights': [1.7623233431399885, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.499040258178224,
 'weight_decay_Hydroxylation-K': 6.308790241162543,
 'weight_decay_Hydroxylation-P': 0.7433889515321912}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1280.031
[2,     1] loss: 1274.042
[3,     1] loss: 1273.838
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00825962722926969,
 'learning_rate_Hydroxylation-K': 0.005043330893263317,
 'learning_rate_Hydroxylation-P': 0.0017932208332078997,
 'log_base': 1.3564047149724345,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4188501290,
 'sample_weights': [1.720414008343246, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2240517508881696,
 'weight_decay_Hydroxylation-K': 7.14425066658217,
 'weight_decay_Hydroxylation-P': 4.750055484296797}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2068.585
[2,     1] loss: 2109.033
[3,     1] loss: 2074.179
[4,     1] loss: 2065.655
[5,     1] loss: 2055.987
[6,     1] loss: 2085.834
[7,     1] loss: 2058.783
[8,     1] loss: 2072.393
[9,     1] loss: 2070.741
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004223415610483551,
 'learning_rate_Hydroxylation-K': 0.0042728453105062725,
 'learning_rate_Hydroxylation-P': 0.001293113997227906,
 'log_base': 2.5655133425867267,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 714920347,
 'sample_weights': [5.476499969614364, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.07736820039322057,
 'weight_decay_Hydroxylation-K': 4.239413438513233,
 'weight_decay_Hydroxylation-P': 2.4402099401364374}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1280.948
[2,     1] loss: 1282.974
[3,     1] loss: 1293.651
[4,     1] loss: 1279.559
[5,     1] loss: 1285.851
[6,     1] loss: 1273.347
[7,     1] loss: 1263.847
[8,     1] loss: 1246.336
[9,     1] loss: 1224.435
[10,     1] loss: 1175.548
[11,     1] loss: 1171.664
[12,     1] loss: 1146.514
[13,     1] loss: 1107.727
[14,     1] loss: 1105.133
[15,     1] loss: 1099.215
[16,     1] loss: 1049.840
[17,     1] loss: 1083.487
[18,     1] loss: 1073.598
[19,     1] loss: 1025.169
[20,     1] loss: 1055.308
[21,     1] loss: 1051.963
[22,     1] loss: 1017.105
[23,     1] loss: 1001.753
[24,     1] loss: 1038.857
[25,     1] loss: 998.562
[26,     1] loss: 965.272
[27,     1] loss: 953.529
[28,     1] loss: 989.323
[29,     1] loss: 978.254
[30,     1] loss: 958.186
[31,     1] loss: 924.099
[32,     1] loss: 940.847
[33,     1] loss: 888.309
[34,     1] loss: 908.238
[35,     1] loss: 954.963
[36,     1] loss: 905.480
[37,     1] loss: 937.639
[38,     1] loss: 885.061
[39,     1] loss: 854.134
[40,     1] loss: 843.309
[41,     1] loss: 906.003
[42,     1] loss: 867.116
[43,     1] loss: 851.588
[44,     1] loss: 879.369
[45,     1] loss: 866.558
[46,     1] loss: 823.081
[47,     1] loss: 784.368
[48,     1] loss: 774.421
[49,     1] loss: 784.981
[50,     1] loss: 847.324
[51,     1] loss: 772.474
[52,     1] loss: 792.552
[53,     1] loss: 769.469
[54,     1] loss: 769.268
[55,     1] loss: 717.957
Early stopping applied (best metric=0.7354155778884888)
Finished Training
Total time taken: 9.279008626937866
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.473
[2,     1] loss: 1284.459
[3,     1] loss: 1293.356
[4,     1] loss: 1277.114
[5,     1] loss: 1273.998
[6,     1] loss: 1261.579
[7,     1] loss: 1245.879
[8,     1] loss: 1211.236
[9,     1] loss: 1149.839
[10,     1] loss: 1140.329
[11,     1] loss: 1102.558
[12,     1] loss: 1106.064
[13,     1] loss: 1041.666
[14,     1] loss: 1043.577
[15,     1] loss: 1027.143
[16,     1] loss: 1043.527
[17,     1] loss: 989.457
[18,     1] loss: 1055.943
[19,     1] loss: 1024.689
[20,     1] loss: 987.996
[21,     1] loss: 977.491
[22,     1] loss: 1012.969
[23,     1] loss: 972.011
[24,     1] loss: 936.138
[25,     1] loss: 964.968
[26,     1] loss: 966.012
[27,     1] loss: 999.556
[28,     1] loss: 896.222
[29,     1] loss: 916.145
[30,     1] loss: 923.352
[31,     1] loss: 878.516
[32,     1] loss: 938.279
[33,     1] loss: 889.695
[34,     1] loss: 888.329
[35,     1] loss: 880.186
[36,     1] loss: 936.720
[37,     1] loss: 890.119
[38,     1] loss: 861.167
[39,     1] loss: 885.820
[40,     1] loss: 852.788
[41,     1] loss: 843.199
[42,     1] loss: 821.428
[43,     1] loss: 827.888
[44,     1] loss: 894.677
[45,     1] loss: 788.732
[46,     1] loss: 761.310
[47,     1] loss: 803.542
[48,     1] loss: 793.441
[49,     1] loss: 795.600
[50,     1] loss: 801.500
[51,     1] loss: 762.505
[52,     1] loss: 769.193
[53,     1] loss: 747.336
[54,     1] loss: 761.080
[55,     1] loss: 716.507
[56,     1] loss: 734.167
[57,     1] loss: 713.078
[58,     1] loss: 779.594
[59,     1] loss: 677.177
Early stopping applied (best metric=0.94609135389328)
Finished Training
Total time taken: 9.502009391784668
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1281.800
[2,     1] loss: 1287.842
[3,     1] loss: 1284.563
[4,     1] loss: 1282.259
[5,     1] loss: 1282.042
[6,     1] loss: 1276.250
[7,     1] loss: 1268.032
[8,     1] loss: 1267.461
[9,     1] loss: 1238.131
[10,     1] loss: 1202.159
[11,     1] loss: 1164.729
[12,     1] loss: 1155.960
[13,     1] loss: 1088.999
[14,     1] loss: 1049.593
[15,     1] loss: 1095.256
[16,     1] loss: 1121.435
[17,     1] loss: 1084.700
[18,     1] loss: 1074.926
[19,     1] loss: 1059.692
[20,     1] loss: 1013.458
[21,     1] loss: 1062.464
[22,     1] loss: 994.342
[23,     1] loss: 986.529
[24,     1] loss: 1003.733
[25,     1] loss: 962.605
[26,     1] loss: 1015.307
[27,     1] loss: 1023.778
[28,     1] loss: 971.582
[29,     1] loss: 1006.047
[30,     1] loss: 1009.928
[31,     1] loss: 949.343
[32,     1] loss: 950.007
[33,     1] loss: 953.001
[34,     1] loss: 987.469
[35,     1] loss: 921.632
[36,     1] loss: 935.715
[37,     1] loss: 910.405
[38,     1] loss: 974.123
[39,     1] loss: 840.114
[40,     1] loss: 947.813
[41,     1] loss: 937.099
[42,     1] loss: 930.419
[43,     1] loss: 895.142
[44,     1] loss: 872.618
[45,     1] loss: 897.422
[46,     1] loss: 851.381
[47,     1] loss: 900.339
[48,     1] loss: 899.713
[49,     1] loss: 823.486
[50,     1] loss: 870.026
[51,     1] loss: 823.224
[52,     1] loss: 839.872
[53,     1] loss: 835.126
[54,     1] loss: 814.464
[55,     1] loss: 794.204
[56,     1] loss: 770.398
[57,     1] loss: 792.805
[58,     1] loss: 859.656
[59,     1] loss: 767.646
[60,     1] loss: 823.405
[61,     1] loss: 747.808
[62,     1] loss: 817.091
[63,     1] loss: 735.852
[64,     1] loss: 745.783
[65,     1] loss: 755.745
[66,     1] loss: 714.852
[67,     1] loss: 751.194
[68,     1] loss: 689.941
[69,     1] loss: 720.989
[70,     1] loss: 649.888
[71,     1] loss: 778.226
[72,     1] loss: 689.525
[73,     1] loss: 794.627
[74,     1] loss: 717.050
[75,     1] loss: 704.862
[76,     1] loss: 730.288
[77,     1] loss: 643.952
[78,     1] loss: 689.463
[79,     1] loss: 664.589
Early stopping applied (best metric=0.7944658398628235)
Finished Training
Total time taken: 12.90901231765747
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.597
[2,     1] loss: 1282.717
[3,     1] loss: 1303.900
[4,     1] loss: 1283.464
[5,     1] loss: 1279.777
[6,     1] loss: 1277.900
[7,     1] loss: 1276.149
[8,     1] loss: 1269.263
[9,     1] loss: 1257.245
[10,     1] loss: 1240.131
[11,     1] loss: 1197.168
[12,     1] loss: 1173.322
[13,     1] loss: 1123.927
[14,     1] loss: 1097.882
[15,     1] loss: 1065.346
[16,     1] loss: 1124.822
[17,     1] loss: 1073.953
[18,     1] loss: 1073.872
[19,     1] loss: 1061.707
[20,     1] loss: 983.912
[21,     1] loss: 1021.146
[22,     1] loss: 1001.750
[23,     1] loss: 1013.497
[24,     1] loss: 1016.919
[25,     1] loss: 984.372
[26,     1] loss: 991.122
[27,     1] loss: 1035.541
[28,     1] loss: 976.349
[29,     1] loss: 995.829
[30,     1] loss: 948.331
[31,     1] loss: 961.786
[32,     1] loss: 933.472
[33,     1] loss: 939.639
[34,     1] loss: 938.683
[35,     1] loss: 911.741
[36,     1] loss: 910.597
[37,     1] loss: 925.177
[38,     1] loss: 892.110
[39,     1] loss: 910.880
[40,     1] loss: 928.556
[41,     1] loss: 878.473
[42,     1] loss: 946.887
[43,     1] loss: 913.590
[44,     1] loss: 878.362
Early stopping applied (best metric=0.8788127899169922)
Finished Training
Total time taken: 6.506006240844727
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1288.947
[2,     1] loss: 1283.354
[3,     1] loss: 1283.313
[4,     1] loss: 1284.386
[5,     1] loss: 1285.372
[6,     1] loss: 1280.460
[7,     1] loss: 1280.435
[8,     1] loss: 1273.726
[9,     1] loss: 1263.505
[10,     1] loss: 1251.339
[11,     1] loss: 1224.445
[12,     1] loss: 1168.895
[13,     1] loss: 1143.110
[14,     1] loss: 1123.453
[15,     1] loss: 1191.286
[16,     1] loss: 1092.499
[17,     1] loss: 1080.775
[18,     1] loss: 1059.177
[19,     1] loss: 1109.781
[20,     1] loss: 1065.626
[21,     1] loss: 1055.285
[22,     1] loss: 1039.268
[23,     1] loss: 1047.764
[24,     1] loss: 1026.890
[25,     1] loss: 1030.438
[26,     1] loss: 1035.888
[27,     1] loss: 1025.009
[28,     1] loss: 1014.762
[29,     1] loss: 996.893
[30,     1] loss: 1019.343
[31,     1] loss: 1022.000
[32,     1] loss: 969.582
[33,     1] loss: 955.869
[34,     1] loss: 945.273
[35,     1] loss: 986.164
[36,     1] loss: 946.792
[37,     1] loss: 945.274
[38,     1] loss: 938.100
[39,     1] loss: 932.450
[40,     1] loss: 935.062
[41,     1] loss: 899.822
[42,     1] loss: 862.880
[43,     1] loss: 899.259
[44,     1] loss: 901.427
[45,     1] loss: 874.675
[46,     1] loss: 850.056
[47,     1] loss: 862.040
[48,     1] loss: 868.380
[49,     1] loss: 833.880
[50,     1] loss: 850.995
[51,     1] loss: 810.517
[52,     1] loss: 856.647
[53,     1] loss: 863.840
[54,     1] loss: 833.770
[55,     1] loss: 810.518
[56,     1] loss: 800.616
[57,     1] loss: 849.883
[58,     1] loss: 823.507
[59,     1] loss: 813.966
Early stopping applied (best metric=0.8147410750389099)
Finished Training
Total time taken: 8.204007863998413
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1281.105
[2,     1] loss: 1286.784
[3,     1] loss: 1283.451
[4,     1] loss: 1279.285
[5,     1] loss: 1272.440
[6,     1] loss: 1250.236
[7,     1] loss: 1221.510
[8,     1] loss: 1179.674
[9,     1] loss: 1146.956
[10,     1] loss: 1099.371
[11,     1] loss: 1110.302
[12,     1] loss: 1119.531
[13,     1] loss: 1094.373
[14,     1] loss: 1063.291
[15,     1] loss: 1113.647
[16,     1] loss: 1058.781
[17,     1] loss: 1071.151
[18,     1] loss: 1069.779
[19,     1] loss: 1016.107
[20,     1] loss: 1057.579
[21,     1] loss: 1063.910
[22,     1] loss: 1003.695
[23,     1] loss: 994.011
[24,     1] loss: 995.505
[25,     1] loss: 1059.602
[26,     1] loss: 983.353
[27,     1] loss: 959.067
[28,     1] loss: 987.910
[29,     1] loss: 975.852
[30,     1] loss: 964.338
[31,     1] loss: 925.625
[32,     1] loss: 972.810
[33,     1] loss: 952.911
[34,     1] loss: 943.926
[35,     1] loss: 896.480
[36,     1] loss: 917.976
[37,     1] loss: 897.269
[38,     1] loss: 912.268
[39,     1] loss: 902.308
[40,     1] loss: 896.986
[41,     1] loss: 871.441
Early stopping applied (best metric=0.8542781472206116)
Finished Training
Total time taken: 6.349006175994873
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1285.164
[2,     1] loss: 1283.369
[3,     1] loss: 1293.208
[4,     1] loss: 1280.274
[5,     1] loss: 1282.245
[6,     1] loss: 1280.337
[7,     1] loss: 1275.463
[8,     1] loss: 1274.397
[9,     1] loss: 1259.309
[10,     1] loss: 1247.600
[11,     1] loss: 1215.053
[12,     1] loss: 1178.641
[13,     1] loss: 1135.611
[14,     1] loss: 1079.787
[15,     1] loss: 1092.160
[16,     1] loss: 1049.683
[17,     1] loss: 1038.385
[18,     1] loss: 1018.836
[19,     1] loss: 1103.679
[20,     1] loss: 1077.391
[21,     1] loss: 1009.771
[22,     1] loss: 1019.679
[23,     1] loss: 1045.627
[24,     1] loss: 1004.296
[25,     1] loss: 1000.436
[26,     1] loss: 958.511
[27,     1] loss: 961.068
[28,     1] loss: 1031.855
[29,     1] loss: 922.585
[30,     1] loss: 1046.308
[31,     1] loss: 928.525
[32,     1] loss: 979.183
[33,     1] loss: 965.122
[34,     1] loss: 958.432
[35,     1] loss: 965.856
[36,     1] loss: 943.052
[37,     1] loss: 919.492
[38,     1] loss: 903.892
[39,     1] loss: 932.769
[40,     1] loss: 921.562
[41,     1] loss: 894.005
[42,     1] loss: 929.667
[43,     1] loss: 927.834
[44,     1] loss: 856.063
[45,     1] loss: 927.588
[46,     1] loss: 850.122
[47,     1] loss: 876.456
[48,     1] loss: 884.509
[49,     1] loss: 871.206
[50,     1] loss: 919.476
[51,     1] loss: 813.744
[52,     1] loss: 847.370
[53,     1] loss: 880.850
[54,     1] loss: 847.049
[55,     1] loss: 869.282
[56,     1] loss: 847.631
[57,     1] loss: 773.398
[58,     1] loss: 799.230
[59,     1] loss: 781.825
Early stopping applied (best metric=0.8565335273742676)
Finished Training
Total time taken: 9.226008892059326
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.512
[2,     1] loss: 1299.300
[3,     1] loss: 1281.052
[4,     1] loss: 1281.931
[5,     1] loss: 1286.857
[6,     1] loss: 1280.790
[7,     1] loss: 1276.705
[8,     1] loss: 1277.951
[9,     1] loss: 1277.208
[10,     1] loss: 1274.005
[11,     1] loss: 1274.069
[12,     1] loss: 1268.652
[13,     1] loss: 1252.026
[14,     1] loss: 1245.603
[15,     1] loss: 1214.355
[16,     1] loss: 1194.131
[17,     1] loss: 1165.080
[18,     1] loss: 1141.910
[19,     1] loss: 1103.838
[20,     1] loss: 1114.313
[21,     1] loss: 1089.870
[22,     1] loss: 1114.968
[23,     1] loss: 1055.536
[24,     1] loss: 1088.397
[25,     1] loss: 1065.547
[26,     1] loss: 1042.988
[27,     1] loss: 1048.148
[28,     1] loss: 1015.547
[29,     1] loss: 1031.506
[30,     1] loss: 999.175
[31,     1] loss: 1014.356
[32,     1] loss: 1031.216
[33,     1] loss: 973.273
[34,     1] loss: 1005.204
[35,     1] loss: 989.429
[36,     1] loss: 972.876
[37,     1] loss: 979.146
[38,     1] loss: 922.388
[39,     1] loss: 928.436
[40,     1] loss: 931.666
[41,     1] loss: 980.004
[42,     1] loss: 953.539
[43,     1] loss: 899.336
[44,     1] loss: 866.340
[45,     1] loss: 907.239
[46,     1] loss: 895.040
[47,     1] loss: 932.536
[48,     1] loss: 869.686
Early stopping applied (best metric=0.8427339196205139)
Finished Training
Total time taken: 6.578006267547607
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.594
[2,     1] loss: 1286.836
[3,     1] loss: 1282.694
[4,     1] loss: 1279.631
[5,     1] loss: 1279.440
[6,     1] loss: 1276.421
[7,     1] loss: 1268.750
[8,     1] loss: 1264.854
[9,     1] loss: 1247.405
[10,     1] loss: 1217.958
[11,     1] loss: 1184.270
[12,     1] loss: 1153.112
[13,     1] loss: 1151.704
[14,     1] loss: 1131.411
[15,     1] loss: 1115.530
[16,     1] loss: 1136.216
[17,     1] loss: 1097.520
[18,     1] loss: 1099.051
[19,     1] loss: 1085.619
[20,     1] loss: 1059.682
[21,     1] loss: 1073.665
[22,     1] loss: 1056.143
[23,     1] loss: 1044.202
[24,     1] loss: 1046.344
[25,     1] loss: 1030.338
[26,     1] loss: 1051.814
[27,     1] loss: 1026.239
[28,     1] loss: 1047.252
[29,     1] loss: 1018.682
[30,     1] loss: 990.677
[31,     1] loss: 1000.236
[32,     1] loss: 992.098
[33,     1] loss: 974.064
[34,     1] loss: 971.321
[35,     1] loss: 905.753
[36,     1] loss: 966.336
[37,     1] loss: 941.759
[38,     1] loss: 935.654
[39,     1] loss: 988.531
[40,     1] loss: 899.606
[41,     1] loss: 901.795
[42,     1] loss: 896.102
[43,     1] loss: 931.050
[44,     1] loss: 909.939
[45,     1] loss: 889.497
[46,     1] loss: 897.172
[47,     1] loss: 847.861
[48,     1] loss: 934.056
[49,     1] loss: 845.143
[50,     1] loss: 853.928
[51,     1] loss: 846.696
[52,     1] loss: 871.152
[53,     1] loss: 818.405
[54,     1] loss: 862.329
[55,     1] loss: 817.450
[56,     1] loss: 873.634
[57,     1] loss: 812.759
[58,     1] loss: 772.463
[59,     1] loss: 794.943
Early stopping applied (best metric=0.7105989456176758)
Finished Training
Total time taken: 9.72101092338562
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1283.216
[2,     1] loss: 1295.234
[3,     1] loss: 1281.154
[4,     1] loss: 1289.237
[5,     1] loss: 1279.944
[6,     1] loss: 1289.950
[7,     1] loss: 1279.579
[8,     1] loss: 1266.298
[9,     1] loss: 1256.127
[10,     1] loss: 1232.341
[11,     1] loss: 1192.940
[12,     1] loss: 1183.348
[13,     1] loss: 1125.660
[14,     1] loss: 1101.095
[15,     1] loss: 1074.708
[16,     1] loss: 1082.425
[17,     1] loss: 1053.067
[18,     1] loss: 1068.535
[19,     1] loss: 1006.614
[20,     1] loss: 1025.295
[21,     1] loss: 978.064
[22,     1] loss: 1000.318
[23,     1] loss: 1003.640
[24,     1] loss: 945.957
[25,     1] loss: 1010.856
[26,     1] loss: 947.542
[27,     1] loss: 986.751
[28,     1] loss: 1009.308
[29,     1] loss: 918.142
[30,     1] loss: 941.001
[31,     1] loss: 958.832
[32,     1] loss: 956.740
[33,     1] loss: 961.502
[34,     1] loss: 906.594
[35,     1] loss: 932.302
[36,     1] loss: 904.293
[37,     1] loss: 910.675
[38,     1] loss: 897.862
[39,     1] loss: 884.742
[40,     1] loss: 906.110
[41,     1] loss: 852.451
[42,     1] loss: 891.490
Early stopping applied (best metric=0.8942869901657104)
Finished Training
Total time taken: 6.961007356643677
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1281.078
[2,     1] loss: 1292.722
[3,     1] loss: 1284.604
[4,     1] loss: 1283.222
[5,     1] loss: 1285.148
[6,     1] loss: 1285.016
[7,     1] loss: 1281.314
[8,     1] loss: 1278.497
[9,     1] loss: 1277.620
[10,     1] loss: 1271.210
[11,     1] loss: 1271.923
[12,     1] loss: 1257.952
[13,     1] loss: 1248.986
[14,     1] loss: 1237.583
[15,     1] loss: 1211.610
[16,     1] loss: 1188.130
[17,     1] loss: 1156.024
[18,     1] loss: 1138.399
[19,     1] loss: 1113.011
[20,     1] loss: 1141.328
[21,     1] loss: 1138.161
[22,     1] loss: 1095.997
[23,     1] loss: 1094.859
[24,     1] loss: 1058.814
[25,     1] loss: 1039.647
[26,     1] loss: 1044.285
[27,     1] loss: 1039.365
[28,     1] loss: 1068.671
[29,     1] loss: 984.996
[30,     1] loss: 1037.814
[31,     1] loss: 1026.579
[32,     1] loss: 992.854
[33,     1] loss: 956.210
[34,     1] loss: 995.358
[35,     1] loss: 1021.354
[36,     1] loss: 943.955
[37,     1] loss: 967.434
[38,     1] loss: 953.313
[39,     1] loss: 956.688
[40,     1] loss: 926.951
[41,     1] loss: 889.089
[42,     1] loss: 877.722
[43,     1] loss: 948.471
[44,     1] loss: 965.871
[45,     1] loss: 882.090
[46,     1] loss: 919.027
[47,     1] loss: 896.946
[48,     1] loss: 937.148
Early stopping applied (best metric=0.8615806102752686)
Finished Training
Total time taken: 8.014006853103638
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.140
[2,     1] loss: 1285.416
[3,     1] loss: 1289.241
[4,     1] loss: 1283.155
[5,     1] loss: 1282.630
[6,     1] loss: 1275.213
[7,     1] loss: 1267.680
[8,     1] loss: 1257.162
[9,     1] loss: 1215.635
[10,     1] loss: 1176.294
[11,     1] loss: 1130.994
[12,     1] loss: 1100.218
[13,     1] loss: 1083.001
[14,     1] loss: 1163.521
[15,     1] loss: 1066.811
[16,     1] loss: 1073.028
[17,     1] loss: 1039.364
[18,     1] loss: 1033.665
[19,     1] loss: 1040.125
[20,     1] loss: 1022.236
[21,     1] loss: 1006.203
[22,     1] loss: 1031.600
[23,     1] loss: 1007.444
[24,     1] loss: 1054.672
[25,     1] loss: 1014.535
[26,     1] loss: 1017.835
[27,     1] loss: 975.972
[28,     1] loss: 948.962
[29,     1] loss: 1005.426
[30,     1] loss: 927.495
[31,     1] loss: 929.340
[32,     1] loss: 960.536
[33,     1] loss: 952.736
[34,     1] loss: 947.031
[35,     1] loss: 926.698
[36,     1] loss: 924.684
[37,     1] loss: 929.890
[38,     1] loss: 971.575
[39,     1] loss: 991.924
[40,     1] loss: 940.378
[41,     1] loss: 900.764
[42,     1] loss: 898.941
[43,     1] loss: 890.751
[44,     1] loss: 898.579
[45,     1] loss: 902.398
[46,     1] loss: 905.936
[47,     1] loss: 904.675
[48,     1] loss: 845.564
[49,     1] loss: 868.030
[50,     1] loss: 820.916
[51,     1] loss: 883.019
[52,     1] loss: 839.738
[53,     1] loss: 838.697
[54,     1] loss: 802.920
[55,     1] loss: 864.602
[56,     1] loss: 786.616
[57,     1] loss: 814.395
[58,     1] loss: 756.876
[59,     1] loss: 771.026
[60,     1] loss: 820.697
[61,     1] loss: 784.502
Early stopping applied (best metric=0.8307595252990723)
Finished Training
Total time taken: 10.069010019302368
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1292.014
[2,     1] loss: 1292.042
[3,     1] loss: 1281.597
[4,     1] loss: 1288.628
[5,     1] loss: 1292.706
[6,     1] loss: 1282.648
[7,     1] loss: 1282.842
[8,     1] loss: 1278.762
[9,     1] loss: 1282.048
[10,     1] loss: 1276.385
[11,     1] loss: 1275.271
[12,     1] loss: 1260.801
[13,     1] loss: 1256.167
[14,     1] loss: 1237.532
[15,     1] loss: 1212.565
[16,     1] loss: 1177.490
[17,     1] loss: 1179.620
[18,     1] loss: 1117.322
[19,     1] loss: 1133.736
[20,     1] loss: 1121.278
[21,     1] loss: 1122.913
[22,     1] loss: 1152.187
[23,     1] loss: 1110.981
[24,     1] loss: 1080.665
[25,     1] loss: 1038.249
[26,     1] loss: 1080.269
[27,     1] loss: 1055.641
[28,     1] loss: 1059.583
[29,     1] loss: 1026.450
[30,     1] loss: 1105.511
[31,     1] loss: 1041.993
[32,     1] loss: 1028.865
[33,     1] loss: 1026.452
[34,     1] loss: 1026.196
[35,     1] loss: 1031.740
[36,     1] loss: 1017.494
[37,     1] loss: 1029.901
[38,     1] loss: 1021.402
[39,     1] loss: 973.327
[40,     1] loss: 1028.752
[41,     1] loss: 974.759
[42,     1] loss: 976.742
[43,     1] loss: 988.757
[44,     1] loss: 976.219
[45,     1] loss: 945.009
[46,     1] loss: 991.005
[47,     1] loss: 954.553
[48,     1] loss: 919.287
[49,     1] loss: 925.386
[50,     1] loss: 965.660
[51,     1] loss: 913.947
[52,     1] loss: 879.456
[53,     1] loss: 906.781
[54,     1] loss: 880.227
[55,     1] loss: 869.851
[56,     1] loss: 869.080
[57,     1] loss: 947.031
[58,     1] loss: 895.962
[59,     1] loss: 825.337
[60,     1] loss: 865.643
[61,     1] loss: 853.664
[62,     1] loss: 855.308
[63,     1] loss: 845.900
[64,     1] loss: 828.115
[65,     1] loss: 834.136
[66,     1] loss: 789.847
[67,     1] loss: 904.129
[68,     1] loss: 767.548
[69,     1] loss: 835.189
[70,     1] loss: 768.333
[71,     1] loss: 926.141
[72,     1] loss: 765.734
[73,     1] loss: 786.964
[74,     1] loss: 815.928
[75,     1] loss: 739.722
[76,     1] loss: 818.816
[77,     1] loss: 731.530
[78,     1] loss: 773.240
[79,     1] loss: 754.622
Early stopping applied (best metric=0.8266301155090332)
Finished Training
Total time taken: 12.242011785507202
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1281.837
[2,     1] loss: 1283.853
[3,     1] loss: 1275.828
[4,     1] loss: 1273.131
[5,     1] loss: 1266.365
[6,     1] loss: 1262.714
[7,     1] loss: 1185.255
[8,     1] loss: 1154.842
[9,     1] loss: 1127.743
[10,     1] loss: 1077.096
[11,     1] loss: 1033.813
[12,     1] loss: 1016.618
[13,     1] loss: 1038.307
[14,     1] loss: 1031.588
[15,     1] loss: 1046.661
[16,     1] loss: 1036.469
[17,     1] loss: 1005.135
[18,     1] loss: 1041.025
[19,     1] loss: 977.150
[20,     1] loss: 1012.019
[21,     1] loss: 1018.315
[22,     1] loss: 956.681
[23,     1] loss: 1012.406
[24,     1] loss: 987.824
[25,     1] loss: 943.676
[26,     1] loss: 976.172
[27,     1] loss: 963.489
[28,     1] loss: 980.803
[29,     1] loss: 905.473
[30,     1] loss: 884.902
[31,     1] loss: 901.009
[32,     1] loss: 853.621
[33,     1] loss: 893.816
[34,     1] loss: 884.165
[35,     1] loss: 894.407
Early stopping applied (best metric=0.9991417527198792)
Finished Training
Total time taken: 5.1040050983428955
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1282.828
[2,     1] loss: 1284.964
[3,     1] loss: 1288.128
[4,     1] loss: 1282.062
[5,     1] loss: 1282.536
[6,     1] loss: 1282.142
[7,     1] loss: 1281.273
[8,     1] loss: 1266.760
[9,     1] loss: 1249.088
[10,     1] loss: 1218.139
[11,     1] loss: 1190.858
[12,     1] loss: 1157.318
[13,     1] loss: 1122.104
[14,     1] loss: 1100.279
[15,     1] loss: 1078.201
[16,     1] loss: 1075.058
[17,     1] loss: 1059.897
[18,     1] loss: 1054.352
[19,     1] loss: 1077.351
[20,     1] loss: 1068.831
[21,     1] loss: 1045.111
[22,     1] loss: 1026.572
[23,     1] loss: 1045.240
[24,     1] loss: 1052.832
[25,     1] loss: 1010.257
[26,     1] loss: 1045.332
[27,     1] loss: 992.816
[28,     1] loss: 1064.773
[29,     1] loss: 971.706
[30,     1] loss: 1007.062
[31,     1] loss: 956.085
[32,     1] loss: 979.918
[33,     1] loss: 959.682
[34,     1] loss: 947.735
[35,     1] loss: 947.971
[36,     1] loss: 954.553
[37,     1] loss: 944.146
[38,     1] loss: 930.400
[39,     1] loss: 889.922
[40,     1] loss: 878.975
[41,     1] loss: 876.859
[42,     1] loss: 893.023
[43,     1] loss: 861.256
[44,     1] loss: 918.615
[45,     1] loss: 870.897
[46,     1] loss: 866.987
[47,     1] loss: 849.447
[48,     1] loss: 822.246
[49,     1] loss: 875.191
[50,     1] loss: 830.328
[51,     1] loss: 838.572
[52,     1] loss: 821.456
[53,     1] loss: 813.448
[54,     1] loss: 877.107
[55,     1] loss: 764.306
[56,     1] loss: 774.327
[57,     1] loss: 785.214
[58,     1] loss: 810.406
[59,     1] loss: 800.905
[60,     1] loss: 750.048
[61,     1] loss: 782.715
[62,     1] loss: 777.052
[63,     1] loss: 728.597
[64,     1] loss: 807.805
[65,     1] loss: 728.522
[66,     1] loss: 807.490
[67,     1] loss: 731.441
[68,     1] loss: 735.065
[69,     1] loss: 693.927
[70,     1] loss: 723.588
[71,     1] loss: 689.367
[72,     1] loss: 627.420
[73,     1] loss: 688.784
[74,     1] loss: 661.160
[75,     1] loss: 620.292
[76,     1] loss: 618.978
Early stopping applied (best metric=0.7030102014541626)
Finished Training
Total time taken: 11.897011995315552
{'Hydroxylation-K Validation Accuracy': 0.7533096926713948, 'Hydroxylation-K Validation Sensitivity': 0.6222222222222222, 'Hydroxylation-K Validation Specificity': 0.7859649122807018, 'Hydroxylation-K Validation Precision': 0.43126912074280493, 'Hydroxylation-K AUC ROC': 0.7666666666666667, 'Hydroxylation-K AUC PR': 0.588177127681026, 'Hydroxylation-K MCC': 0.3632865267285075, 'Hydroxylation-K F1': 0.5046225834198164, 'Validation Loss (Hydroxylation-K)': 0.46969871123631796, 'Hydroxylation-P Validation Accuracy': 0.7755338476896265, 'Hydroxylation-P Validation Sensitivity': 0.8123280423280423, 'Hydroxylation-P Validation Specificity': 0.7676118509651354, 'Hydroxylation-P Validation Precision': 0.43389658759192906, 'Hydroxylation-P AUC ROC': 0.8552806932539089, 'Hydroxylation-P AUC PR': 0.5881548930826758, 'Hydroxylation-P MCC': 0.47173548250043507, 'Hydroxylation-P F1': 0.5640583511961428, 'Validation Loss (Hydroxylation-P)': 0.36690664688746133, 'Validation Loss (total)': 0.8366053581237793, 'TimeToTrain': 8.83740865389506}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030353187720492595,
 'learning_rate_Hydroxylation-K': 0.0018031494974410577,
 'learning_rate_Hydroxylation-P': 0.006400564434628137,
 'log_base': 2.922375224438558,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2302030547,
 'sample_weights': [1.7732487413220468, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.992511098207391,
 'weight_decay_Hydroxylation-K': 6.976156149907408,
 'weight_decay_Hydroxylation-P': 0.10589101822597966}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.684
[2,     1] loss: 1236.970
[3,     1] loss: 1235.100
[4,     1] loss: 1230.380
[5,     1] loss: 1221.867
[6,     1] loss: 1197.557
[7,     1] loss: 1180.781
[8,     1] loss: 1123.963
[9,     1] loss: 1088.271
[10,     1] loss: 1069.674
[11,     1] loss: 1045.892
[12,     1] loss: 1033.432
[13,     1] loss: 1055.260
[14,     1] loss: 1029.559
[15,     1] loss: 986.102
[16,     1] loss: 1023.155
[17,     1] loss: 973.718
[18,     1] loss: 962.297
[19,     1] loss: 993.205
[20,     1] loss: 963.897
[21,     1] loss: 963.694
[22,     1] loss: 945.180
[23,     1] loss: 933.532
[24,     1] loss: 927.993
[25,     1] loss: 916.236
[26,     1] loss: 932.026
[27,     1] loss: 857.915
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006109860604617813,
 'learning_rate_Hydroxylation-K': 0.004580017085844525,
 'learning_rate_Hydroxylation-P': 0.0018141315402553483,
 'log_base': 2.8910910040791498,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1905685089,
 'sample_weights': [1.5567402607550525, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.1661881972353564,
 'weight_decay_Hydroxylation-K': 3.25208298047672,
 'weight_decay_Hydroxylation-P': 1.5021913293332874}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.742
[2,     1] loss: 1246.155
[3,     1] loss: 1251.007
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004296929393040862,
 'learning_rate_Hydroxylation-K': 0.004116250038380834,
 'learning_rate_Hydroxylation-P': 0.002903053758145064,
 'log_base': 2.391816648423435,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1620975025,
 'sample_weights': [1.5725223949923517, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.12969299974143889,
 'weight_decay_Hydroxylation-K': 3.812206396847528,
 'weight_decay_Hydroxylation-P': 2.0651284728689183}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1310.844
[2,     1] loss: 1315.159
[3,     1] loss: 1321.310
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009549374397300733,
 'learning_rate_Hydroxylation-K': 0.004469311964118631,
 'learning_rate_Hydroxylation-P': 0.009011726017089475,
 'log_base': 2.365096894438749,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3885458753,
 'sample_weights': [1.91438226876861, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.9869607661249984,
 'weight_decay_Hydroxylation-K': 9.663190112962889,
 'weight_decay_Hydroxylation-P': 2.977901836281816}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1318.072
[2,     1] loss: 1344.317
[3,     1] loss: 1335.492
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011656852527100236,
 'learning_rate_Hydroxylation-K': 0.009398044965818468,
 'learning_rate_Hydroxylation-P': 0.00022860258567676452,
 'log_base': 2.6775529506263327,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1295268144,
 'sample_weights': [1.939366073885733, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.8144305254654505,
 'weight_decay_Hydroxylation-K': 0.6160606467272665,
 'weight_decay_Hydroxylation-P': 7.837349019593996}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1264.784
[2,     1] loss: 1263.201
[3,     1] loss: 1266.898
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037046610984310894,
 'learning_rate_Hydroxylation-K': 0.0069789561885073,
 'learning_rate_Hydroxylation-P': 0.009340270928900999,
 'log_base': 1.6373076910717976,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1989242148,
 'sample_weights': [1.6950325464740255, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.4740247733930065,
 'weight_decay_Hydroxylation-K': 8.430226407641335,
 'weight_decay_Hydroxylation-P': 8.634474915880874}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1622.854
[2,     1] loss: 1618.778
[3,     1] loss: 1627.261
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033013044500834546,
 'learning_rate_Hydroxylation-K': 0.00020865591640813154,
 'learning_rate_Hydroxylation-P': 0.00017327628714853616,
 'log_base': 2.72926830743818,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2242763380,
 'sample_weights': [3.385928756541395, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3270969866210336,
 'weight_decay_Hydroxylation-K': 9.383204137388418,
 'weight_decay_Hydroxylation-P': 0.620075179906047}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1257.367
[2,     1] loss: 1258.872
[3,     1] loss: 1259.438
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001991535043848121,
 'learning_rate_Hydroxylation-K': 0.001032752032403184,
 'learning_rate_Hydroxylation-P': 0.004166519393399836,
 'log_base': 2.4444180913108324,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1362687933,
 'sample_weights': [1.662736410291946, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7167711103564889,
 'weight_decay_Hydroxylation-K': 4.433011519828255,
 'weight_decay_Hydroxylation-P': 0.06718257998986799}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1299.003
[2,     1] loss: 1312.209
[3,     1] loss: 1305.570
[4,     1] loss: 1301.292
[5,     1] loss: 1301.024
[6,     1] loss: 1304.152
[7,     1] loss: 1300.282
[8,     1] loss: 1294.006
[9,     1] loss: 1282.453
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019964100990621948,
 'learning_rate_Hydroxylation-K': 0.0031504399257305535,
 'learning_rate_Hydroxylation-P': 0.004756159817112158,
 'log_base': 2.371649314933293,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1875020060,
 'sample_weights': [1.8677890973426874, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.8016290530814985,
 'weight_decay_Hydroxylation-K': 0.9521203734684827,
 'weight_decay_Hydroxylation-P': 0.7753456221181088}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1320.268
[2,     1] loss: 1314.547
[3,     1] loss: 1313.786
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003362920186026084,
 'learning_rate_Hydroxylation-K': 0.002877796860324005,
 'learning_rate_Hydroxylation-P': 0.008898059566973131,
 'log_base': 1.544137251263839,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1261425612,
 'sample_weights': [1.9331530030489423, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.278508947971153,
 'weight_decay_Hydroxylation-K': 5.044832060571199,
 'weight_decay_Hydroxylation-P': 3.9558966383623058}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1728.402
[2,     1] loss: 1717.164
[3,     1] loss: 1721.571
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003300565203812611,
 'learning_rate_Hydroxylation-K': 0.0058799739916148884,
 'learning_rate_Hydroxylation-P': 0.0034609477449444883,
 'log_base': 2.7976793034413143,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 969023864,
 'sample_weights': [3.8425231889494933, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.4807955108669795,
 'weight_decay_Hydroxylation-K': 6.498191582494111,
 'weight_decay_Hydroxylation-P': 9.01311648378502}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1248.817
[2,     1] loss: 1255.137
[3,     1] loss: 1248.956
[4,     1] loss: 1251.530
[5,     1] loss: 1253.110
[6,     1] loss: 1250.120
[7,     1] loss: 1245.513
[8,     1] loss: 1252.256
[9,     1] loss: 1249.950
[10,     1] loss: 1247.179
[11,     1] loss: 1245.445
[12,     1] loss: 1248.850
[13,     1] loss: 1246.728
[14,     1] loss: 1246.644
[15,     1] loss: 1243.131
[16,     1] loss: 1241.655
[17,     1] loss: 1242.806
[18,     1] loss: 1239.853
[19,     1] loss: 1235.978
[20,     1] loss: 1235.303
[21,     1] loss: 1231.276
[22,     1] loss: 1229.198
[23,     1] loss: 1221.419
[24,     1] loss: 1221.785
[25,     1] loss: 1211.357
[26,     1] loss: 1199.287
[27,     1] loss: 1196.170
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005228016648611408,
 'learning_rate_Hydroxylation-K': 0.006169130582323524,
 'learning_rate_Hydroxylation-P': 0.004197744159638444,
 'log_base': 2.237165836005117,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3922439697,
 'sample_weights': [1.6227244980556519, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.138646203920703,
 'weight_decay_Hydroxylation-K': 9.498196789381444,
 'weight_decay_Hydroxylation-P': 9.650563389239805}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1345.697
[2,     1] loss: 1350.217
[3,     1] loss: 1356.801
[4,     1] loss: 1343.590
[5,     1] loss: 1344.218
[6,     1] loss: 1341.161
[7,     1] loss: 1332.549
[8,     1] loss: 1318.362
[9,     1] loss: 1289.551
[10,     1] loss: 1264.543
[11,     1] loss: 1212.075
[12,     1] loss: 1181.415
[13,     1] loss: 1176.680
[14,     1] loss: 1146.536
[15,     1] loss: 1214.628
[16,     1] loss: 1173.889
[17,     1] loss: 1131.509
[18,     1] loss: 1129.251
[19,     1] loss: 1121.071
[20,     1] loss: 1120.527
[21,     1] loss: 1068.184
[22,     1] loss: 1105.799
[23,     1] loss: 1059.677
[24,     1] loss: 1062.606
[25,     1] loss: 1037.817
[26,     1] loss: 1017.329
[27,     1] loss: 980.562
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004524247000389467,
 'learning_rate_Hydroxylation-K': 0.0002494948898792487,
 'learning_rate_Hydroxylation-P': 0.005915159012809921,
 'log_base': 2.505485810543012,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4136006472,
 'sample_weights': [2.0733020394425226, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.654057578242953,
 'weight_decay_Hydroxylation-K': 4.385936011926211,
 'weight_decay_Hydroxylation-P': 0.1815028664499982}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1292.416
[2,     1] loss: 1297.984
[3,     1] loss: 1288.166
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006052242122368514,
 'learning_rate_Hydroxylation-K': 0.0016690509054468228,
 'learning_rate_Hydroxylation-P': 0.00900683786246335,
 'log_base': 1.0381643293787057,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1580349155,
 'sample_weights': [1.8176098847881963, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.471702576143257,
 'weight_decay_Hydroxylation-K': 2.412765752232983,
 'weight_decay_Hydroxylation-P': 2.902086941939647}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 14483.210
[2,     1] loss: 14486.207
[3,     1] loss: 14535.803
[4,     1] loss: 14448.682
[5,     1] loss: 14384.516
[6,     1] loss: 14357.107
[7,     1] loss: 14279.564
[8,     1] loss: 14212.889
[9,     1] loss: 13852.037
[10,     1] loss: 13449.357
[11,     1] loss: 13188.764
[12,     1] loss: 12564.484
[13,     1] loss: 12438.671
[14,     1] loss: 11847.395
[15,     1] loss: 12037.156
[16,     1] loss: 11777.885
[17,     1] loss: 12185.633
[18,     1] loss: 11829.030
[19,     1] loss: 11572.639
[20,     1] loss: 11190.523
[21,     1] loss: 10196.848
[22,     1] loss: 11251.471
[23,     1] loss: 10637.314
[24,     1] loss: 10703.348
[25,     1] loss: 10440.234
[26,     1] loss: 10238.535
[27,     1] loss: 10583.190
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037219980487506873,
 'learning_rate_Hydroxylation-K': 0.0027491468258695785,
 'learning_rate_Hydroxylation-P': 0.0042539496658367685,
 'log_base': 2.61674945783728,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2243335112,
 'sample_weights': [44.573058375234666, 5.571846938554018],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.5713355619017637,
 'weight_decay_Hydroxylation-K': 2.6763532926842926,
 'weight_decay_Hydroxylation-P': 2.5391521902422483}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1275.151
[2,     1] loss: 1276.206
[3,     1] loss: 1278.736
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003386086670650361,
 'learning_rate_Hydroxylation-K': 0.003138738735488194,
 'learning_rate_Hydroxylation-P': 0.007846150488782056,
 'log_base': 1.2620691008078737,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3523256365,
 'sample_weights': [1.7355089712441412, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.621716195206565,
 'weight_decay_Hydroxylation-K': 2.7779747523640994,
 'weight_decay_Hydroxylation-P': 1.7778757431661503}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2418.061
[2,     1] loss: 2412.104
[3,     1] loss: 2421.184
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028719734734542948,
 'learning_rate_Hydroxylation-K': 0.0015213002921107368,
 'learning_rate_Hydroxylation-P': 0.008134914586675757,
 'log_base': 1.158517507619275,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2570588361,
 'sample_weights': [7.17261048132333, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.225063507961972,
 'weight_decay_Hydroxylation-K': 4.4213719479006865,
 'weight_decay_Hydroxylation-P': 3.586925817261636}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3683.273
[2,     1] loss: 3665.261
[3,     1] loss: 3690.718
[4,     1] loss: 3701.470
[5,     1] loss: 3718.504
[6,     1] loss: 3649.884
[7,     1] loss: 3678.197
[8,     1] loss: 3656.176
[9,     1] loss: 3675.737
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037323992653715797,
 'learning_rate_Hydroxylation-K': 7.387554734685726e-05,
 'learning_rate_Hydroxylation-P': 0.0039412241507183554,
 'log_base': 1.0784216390192776,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4077085241,
 'sample_weights': [11.345859673033802, 1.4182870951386464],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.9164480707028835,
 'weight_decay_Hydroxylation-K': 2.3658753452656613,
 'weight_decay_Hydroxylation-P': 9.9895489479689}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 7191.132
[2,     1] loss: 7202.812
[3,     1] loss: 7244.386
[4,     1] loss: 7153.188
[5,     1] loss: 7185.176
[6,     1] loss: 7163.295
[7,     1] loss: 7136.758
[8,     1] loss: 7085.168
[9,     1] loss: 7032.557
[10,     1] loss: 6890.675
[11,     1] loss: 6708.866
[12,     1] loss: 6536.545
[13,     1] loss: 6367.821
[14,     1] loss: 6312.288
[15,     1] loss: 5865.594
[16,     1] loss: 6289.797
[17,     1] loss: 6062.859
[18,     1] loss: 5820.376
[19,     1] loss: 5779.086
[20,     1] loss: 6045.130
[21,     1] loss: 5696.956
[22,     1] loss: 5920.614
[23,     1] loss: 5741.359
[24,     1] loss: 5245.196
[25,     1] loss: 5557.672
[26,     1] loss: 5549.406
[27,     1] loss: 5571.806
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0044420365975919845,
 'learning_rate_Hydroxylation-K': 0.003569342392743581,
 'learning_rate_Hydroxylation-P': 0.009085630275045217,
 'log_base': 2.5193378281298426,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2078692649,
 'sample_weights': [22.11226122552439, 2.7641391348276794],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4979055620110358,
 'weight_decay_Hydroxylation-K': 0.4913395860372125,
 'weight_decay_Hydroxylation-P': 2.577718450431156}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1297.616
[2,     1] loss: 1312.184
[3,     1] loss: 1293.458
[4,     1] loss: 1289.263
[5,     1] loss: 1287.778
[6,     1] loss: 1293.631
[7,     1] loss: 1294.276
[8,     1] loss: 1283.750
[9,     1] loss: 1288.733
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009104932213486436,
 'learning_rate_Hydroxylation-K': 0.002999912354029475,
 'learning_rate_Hydroxylation-P': 0.0018846198025531105,
 'log_base': 1.4988976057614116,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2165012119,
 'sample_weights': [1.80676427826797, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.120763563040517,
 'weight_decay_Hydroxylation-K': 4.09994522619726,
 'weight_decay_Hydroxylation-P': 6.480768365093015}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1777.475
[2,     1] loss: 1817.057
[3,     1] loss: 1781.538
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037447453360920126,
 'learning_rate_Hydroxylation-K': 0.005661348164565474,
 'learning_rate_Hydroxylation-P': 0.009307709946795232,
 'log_base': 1.6776990851125746,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3457363208,
 'sample_weights': [4.124832666628863, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.278375165235092,
 'weight_decay_Hydroxylation-K': 2.2715794209650086,
 'weight_decay_Hydroxylation-P': 1.9157400228876202}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1593.528
[2,     1] loss: 1596.975
[3,     1] loss: 1590.105
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002441761332530086,
 'learning_rate_Hydroxylation-K': 0.00958993830329891,
 'learning_rate_Hydroxylation-P': 0.007872078775634398,
 'log_base': 1.0277246375340159,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3919308517,
 'sample_weights': [3.2264555316840786, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.771918546734834,
 'weight_decay_Hydroxylation-K': 4.1045836986256665,
 'weight_decay_Hydroxylation-P': 6.205834788968016}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 19835.350
Exploding loss, terminate run (best metric=1.0961635112762451)
Finished Training
Total time taken: 0.2050004005432129
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 19825.361
Exploding loss, terminate run (best metric=1.093123197555542)
Finished Training
Total time taken: 0.22500038146972656
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 19834.094
Exploding loss, terminate run (best metric=1.09372878074646)
Finished Training
Total time taken: 0.23399996757507324
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 19782.500
Exploding loss, terminate run (best metric=1.079010009765625)
Finished Training
Total time taken: 0.22699975967407227
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 19862.572
Exploding loss, terminate run (best metric=1.073179006576538)
Finished Training
Total time taken: 0.2070000171661377
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 19787.254
Exploding loss, terminate run (best metric=1.096804141998291)
Finished Training
Total time taken: 0.22899985313415527
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 19859.469
Exploding loss, terminate run (best metric=1.0914292335510254)
Finished Training
Total time taken: 0.22899985313415527
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 19840.465
Exploding loss, terminate run (best metric=1.091905117034912)
Finished Training
Total time taken: 0.2329998016357422
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 19829.576
Exploding loss, terminate run (best metric=1.0730220079421997)
Finished Training
Total time taken: 0.23600196838378906
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 19810.012
Exploding loss, terminate run (best metric=1.0743889808654785)
Finished Training
Total time taken: 0.23799896240234375
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 19817.900
Exploding loss, terminate run (best metric=1.096329927444458)
Finished Training
Total time taken: 0.2369983196258545
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 19909.836
Exploding loss, terminate run (best metric=1.0926449298858643)
Finished Training
Total time taken: 0.20999884605407715
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 19826.680
Exploding loss, terminate run (best metric=1.0944422483444214)
Finished Training
Total time taken: 0.22100043296813965
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 19891.594
Exploding loss, terminate run (best metric=1.0730080604553223)
Finished Training
Total time taken: 0.20900249481201172
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 19795.584
Exploding loss, terminate run (best metric=1.0767087936401367)
Finished Training
Total time taken: 0.2259969711303711
{'Hydroxylation-K Validation Accuracy': 0.4783096926713948, 'Hydroxylation-K Validation Sensitivity': 0.5333333333333333, 'Hydroxylation-K Validation Specificity': 0.4666666666666667, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.6283430799220273, 'Hydroxylation-K AUC PR': 0.30923770305642484, 'Hydroxylation-K MCC': 0.0, 'Hydroxylation-K F1': 0.17766830870279146, 'Validation Loss (Hydroxylation-K)': 0.5563062906265259, 'Hydroxylation-P Validation Accuracy': 0.47817647158350673, 'Hydroxylation-P Validation Sensitivity': 0.5333333333333333, 'Hydroxylation-P Validation Specificity': 0.4666666666666667, 'Hydroxylation-P Validation Precision': nan, 'Hydroxylation-P AUC ROC': 0.6187119097892703, 'Hydroxylation-P AUC PR': 0.2817205701067915, 'Hydroxylation-P MCC': 0.0, 'Hydroxylation-P F1': 0.16011130737252802, 'Validation Loss (Hydroxylation-P)': 0.5300862312316894, 'Validation Loss (total)': 1.0863925298055013, 'TimeToTrain': 0.2243998686472575}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017248017482074684,
 'learning_rate_Hydroxylation-K': 0.005522633425755463,
 'learning_rate_Hydroxylation-P': 0.006094747950832273,
 'log_base': 2.8695767736527413,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1555609550,
 'sample_weights': [61.091348757068616, 7.620551465998678],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.788474285474564,
 'weight_decay_Hydroxylation-K': 6.701445548882954,
 'weight_decay_Hydroxylation-P': 7.600405481430674}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1244.095
[2,     1] loss: 1240.721
[3,     1] loss: 1240.211
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008606394076851084,
 'learning_rate_Hydroxylation-K': 0.009539498265288724,
 'learning_rate_Hydroxylation-P': 0.007823463667418729,
 'log_base': 1.113472587342239,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3692434532,
 'sample_weights': [1.5836646586561993, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.533912186662114,
 'weight_decay_Hydroxylation-K': 8.365945766348498,
 'weight_decay_Hydroxylation-P': 9.24337753539604}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 5031.731
[2,     1] loss: 5100.651
[3,     1] loss: 5039.422
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009187599585660414,
 'learning_rate_Hydroxylation-K': 0.009051717932647004,
 'learning_rate_Hydroxylation-P': 0.003926123521300289,
 'log_base': 1.9192940031664634,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1100900658,
 'sample_weights': [15.532074837964094, 1.941584149482238],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.010268330915882,
 'weight_decay_Hydroxylation-K': 6.261479373310752,
 'weight_decay_Hydroxylation-P': 5.361162230550697}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1447.505
[2,     1] loss: 1450.478
[3,     1] loss: 1460.949
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004163126587116382,
 'learning_rate_Hydroxylation-K': 0.008834050268425889,
 'learning_rate_Hydroxylation-P': 0.006669572915908666,
 'log_base': 1.5609180575244064,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1958663221,
 'sample_weights': [2.5606628859103506, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.978420382618621,
 'weight_decay_Hydroxylation-K': 2.4560061247283818,
 'weight_decay_Hydroxylation-P': 6.7321218682898865}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1698.775
[2,     1] loss: 1702.850
[3,     1] loss: 1707.760
[4,     1] loss: 1707.508
[5,     1] loss: 1695.162
[6,     1] loss: 1689.746
[7,     1] loss: 1689.007
[8,     1] loss: 1689.397
[9,     1] loss: 1679.506
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004341482030815183,
 'learning_rate_Hydroxylation-K': 0.007008841144054843,
 'learning_rate_Hydroxylation-P': 0.009120898665185265,
 'log_base': 1.4585561965833613,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1095960853,
 'sample_weights': [3.7492478740489052, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.991590149707013,
 'weight_decay_Hydroxylation-K': 3.761954471971068,
 'weight_decay_Hydroxylation-P': 2.973445864272711}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1871.093
[2,     1] loss: 1841.602
[3,     1] loss: 1840.103
[4,     1] loss: 1840.953
[5,     1] loss: 1832.688
[6,     1] loss: 1846.049
[7,     1] loss: 1843.413
[8,     1] loss: 1845.481
[9,     1] loss: 1836.822
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004133930002709051,
 'learning_rate_Hydroxylation-K': 0.009164663221192484,
 'learning_rate_Hydroxylation-P': 0.008171758899140784,
 'log_base': 1.0370727592604896,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2329021257,
 'sample_weights': [4.422986460597334, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.1999404623264036,
 'weight_decay_Hydroxylation-K': 4.27964528364319,
 'weight_decay_Hydroxylation-P': 7.048022488452389}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 14870.726
[2,     1] loss: 14830.759
[3,     1] loss: 14920.587
[4,     1] loss: 14829.098
[5,     1] loss: 14929.753
[6,     1] loss: 14782.619
[7,     1] loss: 14737.591
[8,     1] loss: 14746.465
[9,     1] loss: 14600.320
[10,     1] loss: 14329.755
[11,     1] loss: 13939.348
[12,     1] loss: 13611.292
[13,     1] loss: 12951.807
[14,     1] loss: 13258.502
[15,     1] loss: 13346.933
[16,     1] loss: 12323.531
[17,     1] loss: 13062.506
[18,     1] loss: 12319.924
[19,     1] loss: 12910.729
[20,     1] loss: 12718.193
[21,     1] loss: 12695.409
[22,     1] loss: 12620.158
[23,     1] loss: 11575.854
[24,     1] loss: 11681.885
[25,     1] loss: 11515.787
[26,     1] loss: 11127.051
[27,     1] loss: 10579.989
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004119259469005487,
 'learning_rate_Hydroxylation-K': 0.003936929500193143,
 'learning_rate_Hydroxylation-P': 0.008526675068747935,
 'log_base': 1.9868124534844802,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3074466964,
 'sample_weights': [45.861189483509484, 5.73286953008624],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.8613733610469,
 'weight_decay_Hydroxylation-K': 5.9401834660384285,
 'weight_decay_Hydroxylation-P': 0.5424619509389318}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1421.501
[2,     1] loss: 1431.913
[3,     1] loss: 1421.032
[4,     1] loss: 1416.600
[5,     1] loss: 1420.266
[6,     1] loss: 1415.010
[7,     1] loss: 1408.794
[8,     1] loss: 1390.915
[9,     1] loss: 1357.741
[10,     1] loss: 1322.336
[11,     1] loss: 1269.379
[12,     1] loss: 1240.078
[13,     1] loss: 1207.799
[14,     1] loss: 1232.406
[15,     1] loss: 1178.911
[16,     1] loss: 1188.531
[17,     1] loss: 1173.016
[18,     1] loss: 1159.210
[19,     1] loss: 1153.348
[20,     1] loss: 1140.625
[21,     1] loss: 1127.993
[22,     1] loss: 1165.314
[23,     1] loss: 1065.101
[24,     1] loss: 1079.921
[25,     1] loss: 1110.974
[26,     1] loss: 1076.382
[27,     1] loss: 1099.073
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004423319925479267,
 'learning_rate_Hydroxylation-K': 0.00048073063285482796,
 'learning_rate_Hydroxylation-P': 0.004455132817800803,
 'log_base': 1.7984024552932192,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3701562397,
 'sample_weights': [2.431706296806887, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.138295314458647,
 'weight_decay_Hydroxylation-K': 5.394808796879994,
 'weight_decay_Hydroxylation-P': 1.7151404632634037}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1507.862
[2,     1] loss: 1511.146
[3,     1] loss: 1506.685
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014772444262768324,
 'learning_rate_Hydroxylation-K': 0.009435968273062593,
 'learning_rate_Hydroxylation-P': 0.006770498005018402,
 'log_base': 1.108907133065364,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1533095250,
 'sample_weights': [2.8445164670292873, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.6129745532349564,
 'weight_decay_Hydroxylation-K': 2.709235832928364,
 'weight_decay_Hydroxylation-P': 5.310377085876962}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 5320.663
[2,     1] loss: 5261.001
[3,     1] loss: 5223.767
[4,     1] loss: 5242.972
[5,     1] loss: 5257.411
[6,     1] loss: 5273.417
[7,     1] loss: 5214.012
[8,     1] loss: 5240.345
[9,     1] loss: 5215.323
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003942932411014091,
 'learning_rate_Hydroxylation-K': 0.0032238000328960897,
 'learning_rate_Hydroxylation-P': 0.005773468385458616,
 'log_base': 1.9872057332045492,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1622172313,
 'sample_weights': [16.14939496319193, 2.0187521378419864],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.108160256713118,
 'weight_decay_Hydroxylation-K': 1.1647056755971583,
 'weight_decay_Hydroxylation-P': 5.6740731006056135}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1418.974
[2,     1] loss: 1418.515
[3,     1] loss: 1426.657
[4,     1] loss: 1419.295
[5,     1] loss: 1411.740
[6,     1] loss: 1386.202
[7,     1] loss: 1350.959
[8,     1] loss: 1308.983
[9,     1] loss: 1277.032
[10,     1] loss: 1273.330
[11,     1] loss: 1197.205
[12,     1] loss: 1189.577
[13,     1] loss: 1201.113
[14,     1] loss: 1207.835
[15,     1] loss: 1204.280
[16,     1] loss: 1270.067
[17,     1] loss: 1151.457
[18,     1] loss: 1198.737
[19,     1] loss: 1159.694
[20,     1] loss: 1198.505
[21,     1] loss: 1092.635
[22,     1] loss: 1148.789
[23,     1] loss: 1099.924
[24,     1] loss: 1066.330
[25,     1] loss: 1102.676
[26,     1] loss: 1049.089
[27,     1] loss: 1042.673
[28,     1] loss: 1061.622
[29,     1] loss: 1020.768
[30,     1] loss: 1016.103
[31,     1] loss: 977.871
[32,     1] loss: 978.714
[33,     1] loss: 969.277
[34,     1] loss: 989.992
[35,     1] loss: 1058.527
[36,     1] loss: 980.077
[37,     1] loss: 988.964
[38,     1] loss: 961.098
[39,     1] loss: 921.476
[40,     1] loss: 936.230
[41,     1] loss: 931.719
[42,     1] loss: 935.132
[43,     1] loss: 917.562
[44,     1] loss: 858.012
[45,     1] loss: 930.349
[46,     1] loss: 950.560
[47,     1] loss: 823.630
[48,     1] loss: 771.665
[49,     1] loss: 885.926
[50,     1] loss: 819.114
[51,     1] loss: 752.021
Early stopping applied (best metric=0.8053067922592163)
Finished Training
Total time taken: 7.628007173538208
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1422.088
[2,     1] loss: 1420.190
[3,     1] loss: 1422.778
[4,     1] loss: 1418.402
[5,     1] loss: 1419.250
[6,     1] loss: 1426.630
[7,     1] loss: 1405.213
[8,     1] loss: 1394.561
[9,     1] loss: 1379.114
[10,     1] loss: 1346.825
[11,     1] loss: 1329.491
[12,     1] loss: 1299.778
[13,     1] loss: 1265.444
[14,     1] loss: 1222.587
[15,     1] loss: 1186.022
[16,     1] loss: 1235.486
[17,     1] loss: 1214.355
[18,     1] loss: 1173.940
[19,     1] loss: 1168.485
[20,     1] loss: 1182.508
[21,     1] loss: 1154.786
[22,     1] loss: 1135.319
[23,     1] loss: 1154.112
[24,     1] loss: 1090.131
[25,     1] loss: 1097.105
[26,     1] loss: 1099.939
[27,     1] loss: 1053.496
[28,     1] loss: 1027.954
[29,     1] loss: 1023.695
[30,     1] loss: 1127.427
[31,     1] loss: 1180.939
[32,     1] loss: 1062.834
[33,     1] loss: 1069.233
[34,     1] loss: 1062.538
[35,     1] loss: 1063.857
[36,     1] loss: 1039.799
[37,     1] loss: 1089.737
[38,     1] loss: 1024.850
[39,     1] loss: 1001.329
[40,     1] loss: 986.548
[41,     1] loss: 991.617
[42,     1] loss: 951.545
[43,     1] loss: 1040.247
[44,     1] loss: 1044.252
[45,     1] loss: 911.373
[46,     1] loss: 916.570
[47,     1] loss: 994.173
[48,     1] loss: 915.261
[49,     1] loss: 896.126
[50,     1] loss: 890.118
[51,     1] loss: 902.405
[52,     1] loss: 1009.267
[53,     1] loss: 1049.404
[54,     1] loss: 859.599
[55,     1] loss: 927.477
[56,     1] loss: 879.031
[57,     1] loss: 929.915
[58,     1] loss: 886.381
[59,     1] loss: 880.292
[60,     1] loss: 801.623
[61,     1] loss: 847.148
[62,     1] loss: 819.970
[63,     1] loss: 778.080
[64,     1] loss: 764.220
[65,     1] loss: 765.392
[66,     1] loss: 890.213
[67,     1] loss: 881.307
[68,     1] loss: 825.332
Early stopping applied (best metric=0.6984822750091553)
Finished Training
Total time taken: 11.228013515472412
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1422.654
[2,     1] loss: 1421.633
[3,     1] loss: 1419.971
[4,     1] loss: 1418.688
[5,     1] loss: 1413.557
[6,     1] loss: 1425.927
[7,     1] loss: 1421.137
[8,     1] loss: 1411.964
[9,     1] loss: 1405.589
[10,     1] loss: 1409.216
[11,     1] loss: 1391.181
[12,     1] loss: 1362.390
[13,     1] loss: 1321.818
[14,     1] loss: 1310.591
[15,     1] loss: 1285.206
[16,     1] loss: 1256.067
[17,     1] loss: 1244.728
[18,     1] loss: 1178.849
[19,     1] loss: 1268.372
[20,     1] loss: 1161.277
[21,     1] loss: 1245.582
[22,     1] loss: 1145.532
[23,     1] loss: 1169.779
[24,     1] loss: 1127.472
[25,     1] loss: 1120.504
[26,     1] loss: 1117.201
[27,     1] loss: 1048.730
[28,     1] loss: 1058.733
[29,     1] loss: 1055.788
[30,     1] loss: 1076.791
[31,     1] loss: 1026.980
[32,     1] loss: 985.029
[33,     1] loss: 1013.610
[34,     1] loss: 1033.602
[35,     1] loss: 940.173
[36,     1] loss: 948.024
[37,     1] loss: 976.037
[38,     1] loss: 990.922
[39,     1] loss: 950.198
[40,     1] loss: 911.224
[41,     1] loss: 954.887
[42,     1] loss: 933.766
[43,     1] loss: 907.332
[44,     1] loss: 861.292
[45,     1] loss: 887.008
Early stopping applied (best metric=0.8277891874313354)
Finished Training
Total time taken: 7.413005828857422
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1427.686
[2,     1] loss: 1422.617
[3,     1] loss: 1417.827
[4,     1] loss: 1418.023
[5,     1] loss: 1415.270
[6,     1] loss: 1403.688
[7,     1] loss: 1383.855
[8,     1] loss: 1342.413
[9,     1] loss: 1335.448
[10,     1] loss: 1291.284
[11,     1] loss: 1204.645
[12,     1] loss: 1152.356
[13,     1] loss: 1167.493
[14,     1] loss: 1146.879
[15,     1] loss: 1122.045
[16,     1] loss: 1118.720
[17,     1] loss: 1161.229
[18,     1] loss: 1136.580
[19,     1] loss: 1147.451
[20,     1] loss: 1099.875
[21,     1] loss: 1001.969
[22,     1] loss: 1054.560
[23,     1] loss: 1130.925
[24,     1] loss: 1070.703
[25,     1] loss: 1044.450
[26,     1] loss: 974.411
[27,     1] loss: 1061.776
[28,     1] loss: 979.887
[29,     1] loss: 1026.626
[30,     1] loss: 1023.514
[31,     1] loss: 966.837
[32,     1] loss: 990.375
[33,     1] loss: 952.931
[34,     1] loss: 941.873
[35,     1] loss: 892.642
[36,     1] loss: 947.218
[37,     1] loss: 885.692
[38,     1] loss: 891.703
[39,     1] loss: 858.722
Early stopping applied (best metric=0.9669116735458374)
Finished Training
Total time taken: 6.588006019592285
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1424.851
[2,     1] loss: 1426.487
[3,     1] loss: 1428.214
[4,     1] loss: 1426.003
[5,     1] loss: 1413.727
[6,     1] loss: 1407.849
[7,     1] loss: 1394.108
[8,     1] loss: 1364.250
[9,     1] loss: 1318.478
[10,     1] loss: 1272.146
[11,     1] loss: 1255.448
[12,     1] loss: 1196.960
[13,     1] loss: 1175.407
[14,     1] loss: 1180.272
[15,     1] loss: 1132.891
[16,     1] loss: 1165.144
[17,     1] loss: 1099.697
[18,     1] loss: 1120.941
[19,     1] loss: 1120.772
[20,     1] loss: 1131.977
[21,     1] loss: 1080.176
[22,     1] loss: 1055.883
[23,     1] loss: 1050.073
[24,     1] loss: 1063.247
[25,     1] loss: 1143.985
[26,     1] loss: 1079.428
[27,     1] loss: 981.192
[28,     1] loss: 1021.832
[29,     1] loss: 983.901
[30,     1] loss: 1018.157
[31,     1] loss: 1010.879
[32,     1] loss: 1121.675
[33,     1] loss: 1092.886
[34,     1] loss: 972.501
[35,     1] loss: 1065.881
[36,     1] loss: 953.783
[37,     1] loss: 1042.114
[38,     1] loss: 1000.167
[39,     1] loss: 948.913
[40,     1] loss: 929.182
[41,     1] loss: 891.746
[42,     1] loss: 932.254
[43,     1] loss: 905.073
[44,     1] loss: 904.593
[45,     1] loss: 846.109
[46,     1] loss: 814.756
[47,     1] loss: 812.078
[48,     1] loss: 816.825
[49,     1] loss: 1041.662
[50,     1] loss: 1333.801
[51,     1] loss: 913.216
[52,     1] loss: 988.764
[53,     1] loss: 1078.640
[54,     1] loss: 991.875
[55,     1] loss: 963.349
[56,     1] loss: 1021.669
[57,     1] loss: 965.773
[58,     1] loss: 902.012
[59,     1] loss: 886.231
[60,     1] loss: 902.188
[61,     1] loss: 870.932
[62,     1] loss: 879.043
[63,     1] loss: 841.733
[64,     1] loss: 847.788
Early stopping applied (best metric=0.835415244102478)
Finished Training
Total time taken: 10.478012800216675
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1419.917
[2,     1] loss: 1424.922
[3,     1] loss: 1421.390
[4,     1] loss: 1422.037
[5,     1] loss: 1411.042
[6,     1] loss: 1380.370
[7,     1] loss: 1328.249
[8,     1] loss: 1286.037
[9,     1] loss: 1300.029
[10,     1] loss: 1221.356
[11,     1] loss: 1221.231
[12,     1] loss: 1180.765
[13,     1] loss: 1183.813
[14,     1] loss: 1121.479
[15,     1] loss: 1184.057
[16,     1] loss: 1128.354
[17,     1] loss: 1241.266
[18,     1] loss: 1129.406
[19,     1] loss: 1129.882
[20,     1] loss: 1163.969
[21,     1] loss: 1105.422
[22,     1] loss: 1126.255
[23,     1] loss: 1100.220
[24,     1] loss: 1044.469
[25,     1] loss: 1064.235
[26,     1] loss: 1060.345
[27,     1] loss: 1009.323
[28,     1] loss: 1035.758
[29,     1] loss: 1034.444
[30,     1] loss: 1054.305
[31,     1] loss: 999.285
[32,     1] loss: 961.480
[33,     1] loss: 961.389
[34,     1] loss: 937.990
[35,     1] loss: 907.475
[36,     1] loss: 945.005
[37,     1] loss: 916.635
[38,     1] loss: 938.703
[39,     1] loss: 869.922
[40,     1] loss: 959.597
[41,     1] loss: 1091.116
[42,     1] loss: 993.243
[43,     1] loss: 1026.424
[44,     1] loss: 950.021
[45,     1] loss: 997.238
[46,     1] loss: 945.748
[47,     1] loss: 866.657
[48,     1] loss: 972.607
[49,     1] loss: 862.120
[50,     1] loss: 861.861
[51,     1] loss: 897.027
[52,     1] loss: 853.855
[53,     1] loss: 811.806
[54,     1] loss: 816.048
Early stopping applied (best metric=0.8787552118301392)
Finished Training
Total time taken: 7.4470055103302
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1425.036
[2,     1] loss: 1420.574
[3,     1] loss: 1422.905
[4,     1] loss: 1418.687
[5,     1] loss: 1411.931
[6,     1] loss: 1407.439
[7,     1] loss: 1393.153
[8,     1] loss: 1371.479
[9,     1] loss: 1324.726
[10,     1] loss: 1295.573
[11,     1] loss: 1279.911
[12,     1] loss: 1235.604
[13,     1] loss: 1211.722
[14,     1] loss: 1198.430
[15,     1] loss: 1219.455
[16,     1] loss: 1210.453
[17,     1] loss: 1188.865
[18,     1] loss: 1156.120
[19,     1] loss: 1191.805
[20,     1] loss: 1166.560
[21,     1] loss: 1163.663
[22,     1] loss: 1116.498
[23,     1] loss: 1130.391
[24,     1] loss: 1113.260
[25,     1] loss: 1099.600
[26,     1] loss: 1125.668
[27,     1] loss: 1157.070
[28,     1] loss: 1085.065
[29,     1] loss: 1113.477
[30,     1] loss: 1064.685
[31,     1] loss: 1074.497
[32,     1] loss: 1023.555
[33,     1] loss: 1060.577
[34,     1] loss: 1030.467
[35,     1] loss: 955.791
[36,     1] loss: 975.914
[37,     1] loss: 1002.201
[38,     1] loss: 1009.455
[39,     1] loss: 1011.713
[40,     1] loss: 954.660
[41,     1] loss: 1001.568
[42,     1] loss: 944.862
[43,     1] loss: 931.995
[44,     1] loss: 963.051
[45,     1] loss: 1047.325
[46,     1] loss: 1169.208
[47,     1] loss: 888.837
[48,     1] loss: 1067.224
[49,     1] loss: 969.142
[50,     1] loss: 990.469
[51,     1] loss: 1026.263
[52,     1] loss: 918.077
[53,     1] loss: 983.498
[54,     1] loss: 884.710
[55,     1] loss: 906.829
[56,     1] loss: 803.556
[57,     1] loss: 907.484
[58,     1] loss: 835.627
[59,     1] loss: 895.710
[60,     1] loss: 828.043
[61,     1] loss: 884.852
[62,     1] loss: 802.064
[63,     1] loss: 824.964
[64,     1] loss: 892.590
[65,     1] loss: 823.046
[66,     1] loss: 727.198
[67,     1] loss: 765.011
[68,     1] loss: 1013.704
[69,     1] loss: 1140.942
[70,     1] loss: 861.314
[71,     1] loss: 1021.968
[72,     1] loss: 853.701
[73,     1] loss: 992.132
[74,     1] loss: 914.051
[75,     1] loss: 890.514
Early stopping applied (best metric=0.7107511758804321)
Finished Training
Total time taken: 10.942010641098022
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1428.575
[2,     1] loss: 1422.090
[3,     1] loss: 1418.461
[4,     1] loss: 1422.952
[5,     1] loss: 1423.566
[6,     1] loss: 1413.735
[7,     1] loss: 1413.215
[8,     1] loss: 1411.193
[9,     1] loss: 1389.032
[10,     1] loss: 1360.508
[11,     1] loss: 1325.123
[12,     1] loss: 1284.268
[13,     1] loss: 1247.843
[14,     1] loss: 1241.283
[15,     1] loss: 1228.046
[16,     1] loss: 1180.679
[17,     1] loss: 1159.721
[18,     1] loss: 1201.650
[19,     1] loss: 1144.016
[20,     1] loss: 1180.808
[21,     1] loss: 1139.642
[22,     1] loss: 1136.936
[23,     1] loss: 1080.291
[24,     1] loss: 1152.254
[25,     1] loss: 1060.525
[26,     1] loss: 1160.840
[27,     1] loss: 1114.341
[28,     1] loss: 1137.117
[29,     1] loss: 1064.329
[30,     1] loss: 1109.488
[31,     1] loss: 1086.434
[32,     1] loss: 1071.617
[33,     1] loss: 1067.846
[34,     1] loss: 985.928
[35,     1] loss: 985.958
[36,     1] loss: 1000.665
[37,     1] loss: 932.314
[38,     1] loss: 947.264
[39,     1] loss: 1042.171
[40,     1] loss: 958.132
[41,     1] loss: 877.977
[42,     1] loss: 972.043
[43,     1] loss: 947.523
[44,     1] loss: 965.094
[45,     1] loss: 954.454
[46,     1] loss: 937.417
[47,     1] loss: 919.099
[48,     1] loss: 938.987
[49,     1] loss: 828.441
[50,     1] loss: 895.012
[51,     1] loss: 827.234
[52,     1] loss: 851.973
[53,     1] loss: 863.905
[54,     1] loss: 922.455
[55,     1] loss: 1045.030
[56,     1] loss: 784.077
Early stopping applied (best metric=0.8274354338645935)
Finished Training
Total time taken: 9.366008996963501
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1419.794
[2,     1] loss: 1420.612
[3,     1] loss: 1426.780
[4,     1] loss: 1421.948
[5,     1] loss: 1420.499
[6,     1] loss: 1414.145
[7,     1] loss: 1409.147
[8,     1] loss: 1394.792
[9,     1] loss: 1385.111
[10,     1] loss: 1336.142
[11,     1] loss: 1341.522
[12,     1] loss: 1285.361
[13,     1] loss: 1288.374
[14,     1] loss: 1242.329
[15,     1] loss: 1179.587
[16,     1] loss: 1240.451
[17,     1] loss: 1209.535
[18,     1] loss: 1210.201
[19,     1] loss: 1166.204
[20,     1] loss: 1120.742
[21,     1] loss: 1187.452
[22,     1] loss: 1147.935
[23,     1] loss: 1186.802
[24,     1] loss: 1179.843
[25,     1] loss: 1123.196
[26,     1] loss: 1114.237
[27,     1] loss: 1117.714
[28,     1] loss: 1100.652
[29,     1] loss: 1081.248
[30,     1] loss: 1058.088
[31,     1] loss: 1039.706
[32,     1] loss: 1054.789
[33,     1] loss: 1055.052
[34,     1] loss: 1005.717
[35,     1] loss: 1037.155
[36,     1] loss: 945.908
[37,     1] loss: 1040.500
[38,     1] loss: 965.549
[39,     1] loss: 936.237
[40,     1] loss: 956.219
[41,     1] loss: 1048.533
[42,     1] loss: 991.334
[43,     1] loss: 923.756
[44,     1] loss: 923.815
[45,     1] loss: 887.124
[46,     1] loss: 857.407
[47,     1] loss: 952.470
[48,     1] loss: 981.842
[49,     1] loss: 1637.731
[50,     1] loss: 1053.479
[51,     1] loss: 1169.950
[52,     1] loss: 1089.863
[53,     1] loss: 1119.348
[54,     1] loss: 1130.461
[55,     1] loss: 1128.931
[56,     1] loss: 1135.496
Early stopping applied (best metric=0.8226861953735352)
Finished Training
Total time taken: 9.374008417129517
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1422.623
[2,     1] loss: 1419.079
[3,     1] loss: 1429.553
[4,     1] loss: 1420.184
[5,     1] loss: 1424.324
[6,     1] loss: 1414.866
[7,     1] loss: 1399.556
[8,     1] loss: 1378.546
[9,     1] loss: 1320.640
[10,     1] loss: 1281.545
[11,     1] loss: 1232.435
[12,     1] loss: 1241.641
[13,     1] loss: 1213.387
[14,     1] loss: 1241.108
[15,     1] loss: 1131.914
[16,     1] loss: 1168.779
[17,     1] loss: 1132.078
[18,     1] loss: 1181.377
[19,     1] loss: 1158.694
[20,     1] loss: 1164.075
[21,     1] loss: 1134.643
[22,     1] loss: 1101.479
[23,     1] loss: 1131.052
[24,     1] loss: 1086.489
[25,     1] loss: 1063.295
[26,     1] loss: 1094.606
[27,     1] loss: 999.234
[28,     1] loss: 1102.514
[29,     1] loss: 1007.865
[30,     1] loss: 1025.726
[31,     1] loss: 1013.598
[32,     1] loss: 1025.658
[33,     1] loss: 941.793
[34,     1] loss: 964.183
[35,     1] loss: 974.997
[36,     1] loss: 985.133
[37,     1] loss: 999.026
[38,     1] loss: 980.862
[39,     1] loss: 904.528
[40,     1] loss: 1021.837
[41,     1] loss: 923.893
[42,     1] loss: 931.040
[43,     1] loss: 944.748
[44,     1] loss: 894.289
[45,     1] loss: 850.685
[46,     1] loss: 865.764
[47,     1] loss: 829.604
[48,     1] loss: 800.900
[49,     1] loss: 796.320
[50,     1] loss: 790.682
[51,     1] loss: 879.968
[52,     1] loss: 929.716
[53,     1] loss: 1360.547
[54,     1] loss: 927.771
[55,     1] loss: 1029.194
[56,     1] loss: 973.781
[57,     1] loss: 983.785
[58,     1] loss: 984.540
[59,     1] loss: 961.843
[60,     1] loss: 876.510
[61,     1] loss: 970.943
[62,     1] loss: 887.899
[63,     1] loss: 830.797
[64,     1] loss: 870.071
[65,     1] loss: 791.956
[66,     1] loss: 952.934
[67,     1] loss: 834.208
[68,     1] loss: 824.608
[69,     1] loss: 813.830
[70,     1] loss: 795.930
[71,     1] loss: 746.338
[72,     1] loss: 736.397
[73,     1] loss: 682.676
Early stopping applied (best metric=0.8267651796340942)
Finished Training
Total time taken: 11.519010543823242
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1418.646
[2,     1] loss: 1425.509
[3,     1] loss: 1418.140
[4,     1] loss: 1417.978
[5,     1] loss: 1411.105
[6,     1] loss: 1390.198
[7,     1] loss: 1347.297
[8,     1] loss: 1327.499
[9,     1] loss: 1262.253
[10,     1] loss: 1249.660
[11,     1] loss: 1210.701
[12,     1] loss: 1179.469
[13,     1] loss: 1183.994
[14,     1] loss: 1196.141
[15,     1] loss: 1115.960
[16,     1] loss: 1166.198
[17,     1] loss: 1152.592
[18,     1] loss: 1193.420
[19,     1] loss: 1151.927
[20,     1] loss: 1108.507
[21,     1] loss: 1136.594
[22,     1] loss: 1128.245
[23,     1] loss: 1091.034
[24,     1] loss: 1081.814
[25,     1] loss: 1053.936
[26,     1] loss: 1096.988
[27,     1] loss: 1036.590
[28,     1] loss: 1072.657
[29,     1] loss: 1044.160
[30,     1] loss: 1051.252
[31,     1] loss: 1058.123
[32,     1] loss: 1033.847
[33,     1] loss: 1057.715
[34,     1] loss: 1031.677
[35,     1] loss: 973.761
[36,     1] loss: 948.518
[37,     1] loss: 985.235
[38,     1] loss: 989.811
[39,     1] loss: 983.726
[40,     1] loss: 1120.428
[41,     1] loss: 892.242
[42,     1] loss: 986.904
[43,     1] loss: 922.518
[44,     1] loss: 974.019
[45,     1] loss: 974.322
[46,     1] loss: 923.503
[47,     1] loss: 915.935
[48,     1] loss: 917.111
[49,     1] loss: 859.771
[50,     1] loss: 857.076
[51,     1] loss: 889.417
[52,     1] loss: 787.082
[53,     1] loss: 802.964
[54,     1] loss: 914.434
[55,     1] loss: 843.419
[56,     1] loss: 765.882
[57,     1] loss: 830.292
[58,     1] loss: 766.925
[59,     1] loss: 757.538
[60,     1] loss: 775.226
[61,     1] loss: 726.155
[62,     1] loss: 737.193
[63,     1] loss: 1494.586
[64,     1] loss: 2092.693
[65,     1] loss: 1231.562
[66,     1] loss: 1074.840
[67,     1] loss: 1191.710
[68,     1] loss: 1256.343
[69,     1] loss: 1274.905
[70,     1] loss: 1286.135
[71,     1] loss: 1321.420
[72,     1] loss: 1298.138
Early stopping applied (best metric=0.7875582575798035)
Finished Training
Total time taken: 11.38301134109497
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1424.855
[2,     1] loss: 1423.744
[3,     1] loss: 1423.248
[4,     1] loss: 1433.244
[5,     1] loss: 1421.473
[6,     1] loss: 1417.293
[7,     1] loss: 1420.512
[8,     1] loss: 1418.123
[9,     1] loss: 1415.523
[10,     1] loss: 1412.583
[11,     1] loss: 1407.842
[12,     1] loss: 1396.245
[13,     1] loss: 1379.474
[14,     1] loss: 1349.958
[15,     1] loss: 1328.779
[16,     1] loss: 1282.131
[17,     1] loss: 1273.785
[18,     1] loss: 1270.362
[19,     1] loss: 1199.582
[20,     1] loss: 1212.618
[21,     1] loss: 1232.616
[22,     1] loss: 1276.626
[23,     1] loss: 1171.201
[24,     1] loss: 1165.632
[25,     1] loss: 1166.703
[26,     1] loss: 1125.717
[27,     1] loss: 1160.071
[28,     1] loss: 1142.714
[29,     1] loss: 1108.149
[30,     1] loss: 1106.385
[31,     1] loss: 1090.163
[32,     1] loss: 1143.394
[33,     1] loss: 1050.681
[34,     1] loss: 1054.339
[35,     1] loss: 1068.464
[36,     1] loss: 980.399
[37,     1] loss: 1058.116
[38,     1] loss: 1047.806
[39,     1] loss: 1144.450
[40,     1] loss: 1007.190
[41,     1] loss: 1002.455
[42,     1] loss: 972.469
[43,     1] loss: 982.192
[44,     1] loss: 947.905
[45,     1] loss: 936.193
[46,     1] loss: 969.361
[47,     1] loss: 960.672
[48,     1] loss: 1102.869
[49,     1] loss: 1105.236
[50,     1] loss: 927.565
[51,     1] loss: 1058.771
[52,     1] loss: 970.670
[53,     1] loss: 992.358
[54,     1] loss: 962.963
[55,     1] loss: 917.384
[56,     1] loss: 954.098
[57,     1] loss: 899.319
[58,     1] loss: 879.448
[59,     1] loss: 951.520
[60,     1] loss: 879.070
[61,     1] loss: 872.718
[62,     1] loss: 993.104
[63,     1] loss: 805.622
[64,     1] loss: 903.144
[65,     1] loss: 838.893
[66,     1] loss: 823.357
[67,     1] loss: 813.097
[68,     1] loss: 799.705
[69,     1] loss: 802.248
[70,     1] loss: 810.947
[71,     1] loss: 848.984
[72,     1] loss: 809.029
[73,     1] loss: 758.371
[74,     1] loss: 745.487
[75,     1] loss: 825.896
[76,     1] loss: 1009.824
[77,     1] loss: 735.147
[78,     1] loss: 803.436
[79,     1] loss: 761.735
[80,     1] loss: 756.903
[81,     1] loss: 773.818
[82,     1] loss: 700.441
[83,     1] loss: 725.518
[84,     1] loss: 974.898
[85,     1] loss: 1216.531
[86,     1] loss: 735.145
[87,     1] loss: 1047.910
Early stopping applied (best metric=0.639724850654602)
Finished Training
Total time taken: 13.118014574050903
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1426.845
[2,     1] loss: 1421.587
[3,     1] loss: 1420.527
[4,     1] loss: 1417.292
[5,     1] loss: 1421.054
[6,     1] loss: 1418.915
[7,     1] loss: 1403.097
[8,     1] loss: 1374.907
[9,     1] loss: 1333.434
[10,     1] loss: 1292.430
[11,     1] loss: 1275.655
[12,     1] loss: 1225.587
[13,     1] loss: 1219.002
[14,     1] loss: 1265.327
[15,     1] loss: 1245.365
[16,     1] loss: 1191.936
[17,     1] loss: 1164.424
[18,     1] loss: 1184.469
[19,     1] loss: 1157.031
[20,     1] loss: 1137.711
[21,     1] loss: 1142.854
[22,     1] loss: 1104.379
[23,     1] loss: 1125.156
[24,     1] loss: 1102.591
[25,     1] loss: 1095.071
[26,     1] loss: 1132.438
[27,     1] loss: 1065.618
[28,     1] loss: 1065.229
[29,     1] loss: 1054.165
[30,     1] loss: 1008.743
[31,     1] loss: 1081.066
[32,     1] loss: 991.000
[33,     1] loss: 1037.191
[34,     1] loss: 942.862
[35,     1] loss: 933.693
[36,     1] loss: 966.548
[37,     1] loss: 926.976
[38,     1] loss: 926.574
[39,     1] loss: 878.119
[40,     1] loss: 876.577
[41,     1] loss: 892.156
[42,     1] loss: 894.362
[43,     1] loss: 975.102
[44,     1] loss: 1367.565
[45,     1] loss: 999.155
[46,     1] loss: 1044.514
[47,     1] loss: 1021.479
[48,     1] loss: 1026.800
[49,     1] loss: 969.514
[50,     1] loss: 955.376
[51,     1] loss: 936.711
[52,     1] loss: 999.909
[53,     1] loss: 918.974
[54,     1] loss: 797.925
[55,     1] loss: 826.680
[56,     1] loss: 823.888
[57,     1] loss: 874.532
[58,     1] loss: 796.599
[59,     1] loss: 799.026
[60,     1] loss: 769.694
[61,     1] loss: 737.501
[62,     1] loss: 762.602
[63,     1] loss: 707.561
[64,     1] loss: 681.092
[65,     1] loss: 737.292
[66,     1] loss: 1171.767
[67,     1] loss: 1437.922
[68,     1] loss: 820.320
[69,     1] loss: 1127.304
[70,     1] loss: 937.060
[71,     1] loss: 931.220
[72,     1] loss: 1018.567
[73,     1] loss: 1052.481
Early stopping applied (best metric=0.8149513006210327)
Finished Training
Total time taken: 12.237012147903442
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1417.774
[2,     1] loss: 1439.298
[3,     1] loss: 1416.862
[4,     1] loss: 1417.026
[5,     1] loss: 1420.024
[6,     1] loss: 1416.801
[7,     1] loss: 1415.647
[8,     1] loss: 1400.402
[9,     1] loss: 1379.428
[10,     1] loss: 1354.771
[11,     1] loss: 1296.924
[12,     1] loss: 1290.072
[13,     1] loss: 1230.826
[14,     1] loss: 1229.517
[15,     1] loss: 1199.359
[16,     1] loss: 1178.605
[17,     1] loss: 1196.007
[18,     1] loss: 1186.335
[19,     1] loss: 1202.830
[20,     1] loss: 1123.162
[21,     1] loss: 1112.394
[22,     1] loss: 1118.057
[23,     1] loss: 1157.687
[24,     1] loss: 1086.473
[25,     1] loss: 1102.259
[26,     1] loss: 1041.705
[27,     1] loss: 1047.930
[28,     1] loss: 1039.098
[29,     1] loss: 1063.034
[30,     1] loss: 1156.981
[31,     1] loss: 1075.617
[32,     1] loss: 1071.739
[33,     1] loss: 1042.834
[34,     1] loss: 1051.624
[35,     1] loss: 1039.942
[36,     1] loss: 1009.125
[37,     1] loss: 1031.110
[38,     1] loss: 989.989
[39,     1] loss: 1059.827
[40,     1] loss: 920.285
[41,     1] loss: 1006.206
[42,     1] loss: 929.685
[43,     1] loss: 963.815
[44,     1] loss: 893.496
[45,     1] loss: 974.316
[46,     1] loss: 926.215
[47,     1] loss: 973.893
[48,     1] loss: 902.488
[49,     1] loss: 959.396
[50,     1] loss: 885.227
[51,     1] loss: 934.172
Early stopping applied (best metric=0.8670015335083008)
Finished Training
Total time taken: 8.436007976531982
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1432.604
[2,     1] loss: 1427.755
[3,     1] loss: 1421.276
[4,     1] loss: 1427.084
[5,     1] loss: 1419.292
[6,     1] loss: 1427.101
[7,     1] loss: 1423.145
[8,     1] loss: 1420.747
[9,     1] loss: 1416.420
[10,     1] loss: 1406.947
[11,     1] loss: 1390.299
[12,     1] loss: 1352.327
[13,     1] loss: 1346.364
[14,     1] loss: 1292.201
[15,     1] loss: 1260.477
[16,     1] loss: 1278.127
[17,     1] loss: 1202.957
[18,     1] loss: 1221.063
[19,     1] loss: 1155.008
[20,     1] loss: 1128.789
[21,     1] loss: 1145.052
[22,     1] loss: 1118.097
[23,     1] loss: 1134.377
[24,     1] loss: 1159.482
[25,     1] loss: 1093.062
[26,     1] loss: 1113.978
[27,     1] loss: 1075.390
[28,     1] loss: 1146.698
[29,     1] loss: 1052.057
[30,     1] loss: 1085.500
[31,     1] loss: 1034.536
[32,     1] loss: 1007.585
[33,     1] loss: 930.787
[34,     1] loss: 1056.914
[35,     1] loss: 1058.112
[36,     1] loss: 961.016
[37,     1] loss: 1052.406
[38,     1] loss: 1063.907
[39,     1] loss: 992.610
[40,     1] loss: 1041.111
[41,     1] loss: 976.642
[42,     1] loss: 867.018
[43,     1] loss: 985.359
[44,     1] loss: 885.950
[45,     1] loss: 934.681
[46,     1] loss: 847.821
[47,     1] loss: 867.102
[48,     1] loss: 854.631
[49,     1] loss: 839.707
[50,     1] loss: 767.923
[51,     1] loss: 804.030
[52,     1] loss: 1104.443
[53,     1] loss: 1525.052
[54,     1] loss: 874.907
[55,     1] loss: 1068.554
Early stopping applied (best metric=0.7838985919952393)
Finished Training
Total time taken: 8.221007108688354
{'Hydroxylation-K Validation Accuracy': 0.7657505910165484, 'Hydroxylation-K Validation Sensitivity': 0.6985185185185185, 'Hydroxylation-K Validation Specificity': 0.7824561403508772, 'Hydroxylation-K Validation Precision': 0.4569694277743813, 'Hydroxylation-K AUC ROC': 0.8288888888888889, 'Hydroxylation-K AUC PR': 0.5993478918764954, 'Hydroxylation-K MCC': 0.42139717843418883, 'Hydroxylation-K F1': 0.5401583025768998, 'Validation Loss (Hydroxylation-K)': 0.414663960536321, 'Hydroxylation-P Validation Accuracy': 0.7761699913709964, 'Hydroxylation-P Validation Sensitivity': 0.7635978835978836, 'Hydroxylation-P Validation Specificity': 0.7789540625467605, 'Hydroxylation-P Validation Precision': 0.4366367522459282, 'Hydroxylation-P AUC ROC': 0.8297260283733424, 'Hydroxylation-P AUC PR': 0.561796331609312, 'Hydroxylation-P MCC': 0.4510066046021855, 'Hydroxylation-P F1': 0.5511217636687082, 'Validation Loss (Hydroxylation-P)': 0.39156488577524823, 'Validation Loss (total)': 0.8062288602193196, 'TimeToTrain': 9.69187617301941}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0036237182830514973,
 'learning_rate_Hydroxylation-K': 0.002441699250609812,
 'learning_rate_Hydroxylation-P': 0.0061192868965036906,
 'log_base': 1.4791296207677733,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3984463854,
 'sample_weights': [2.432808759459739, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.492494351642565,
 'weight_decay_Hydroxylation-K': 1.2055864794966589,
 'weight_decay_Hydroxylation-P': 7.144785928802585}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1805.666
[2,     1] loss: 1801.104
[3,     1] loss: 1811.515
[4,     1] loss: 1806.822
[5,     1] loss: 1802.520
[6,     1] loss: 1793.093
[7,     1] loss: 1791.610
[8,     1] loss: 1744.939
[9,     1] loss: 1706.082
[10,     1] loss: 1657.227
[11,     1] loss: 1630.738
[12,     1] loss: 1550.584
[13,     1] loss: 1549.221
[14,     1] loss: 1516.629
[15,     1] loss: 1515.492
[16,     1] loss: 1437.066
[17,     1] loss: 1382.938
[18,     1] loss: 1511.861
[19,     1] loss: 1515.903
[20,     1] loss: 1411.451
[21,     1] loss: 1438.382
[22,     1] loss: 1492.865
[23,     1] loss: 1396.772
[24,     1] loss: 1525.586
[25,     1] loss: 1370.088
[26,     1] loss: 1401.732
[27,     1] loss: 1303.263
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028275636149148378,
 'learning_rate_Hydroxylation-K': 0.003493687352045323,
 'learning_rate_Hydroxylation-P': 0.006845268654874125,
 'log_base': 2.1894023191814496,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2949400398,
 'sample_weights': [4.264725643542951, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.1591801673512,
 'weight_decay_Hydroxylation-K': 4.67630736037297,
 'weight_decay_Hydroxylation-P': 5.896837546984731}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1355.075
[2,     1] loss: 1359.774
[3,     1] loss: 1354.495
[4,     1] loss: 1362.251
[5,     1] loss: 1349.082
[6,     1] loss: 1336.740
[7,     1] loss: 1314.944
[8,     1] loss: 1271.690
[9,     1] loss: 1232.729
[10,     1] loss: 1181.196
[11,     1] loss: 1184.445
[12,     1] loss: 1138.812
[13,     1] loss: 1146.919
[14,     1] loss: 1087.738
[15,     1] loss: 1100.543
[16,     1] loss: 1087.339
[17,     1] loss: 1097.324
[18,     1] loss: 1112.571
[19,     1] loss: 1050.484
[20,     1] loss: 1045.642
[21,     1] loss: 1064.065
[22,     1] loss: 1072.767
[23,     1] loss: 1059.701
[24,     1] loss: 995.415
[25,     1] loss: 987.519
[26,     1] loss: 993.601
[27,     1] loss: 1049.866
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001707986390731271,
 'learning_rate_Hydroxylation-K': 0.0030802175944173228,
 'learning_rate_Hydroxylation-P': 0.0037694232296409534,
 'log_base': 1.348467308227767,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3735173056,
 'sample_weights': [2.1304010119222063, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.903214290785597,
 'weight_decay_Hydroxylation-K': 8.425309047608026,
 'weight_decay_Hydroxylation-P': 0.930808561638485}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2087.812
[2,     1] loss: 2093.320
[3,     1] loss: 2086.883
[4,     1] loss: 2074.444
[5,     1] loss: 2087.428
[6,     1] loss: 2077.499
[7,     1] loss: 2088.355
[8,     1] loss: 2087.884
[9,     1] loss: 2075.910
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001404074729212412,
 'learning_rate_Hydroxylation-K': 0.0007772665049958992,
 'learning_rate_Hydroxylation-P': 0.0002520201283600081,
 'log_base': 2.8253164626769935,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1930000044,
 'sample_weights': [5.584007933964832, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.39163164566237574,
 'weight_decay_Hydroxylation-K': 7.773749889900152,
 'weight_decay_Hydroxylation-P': 4.060480121762314}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1244.953
[2,     1] loss: 1249.104
[3,     1] loss: 1248.424
[4,     1] loss: 1246.772
[5,     1] loss: 1242.947
[6,     1] loss: 1242.723
[7,     1] loss: 1235.869
[8,     1] loss: 1221.785
[9,     1] loss: 1204.528
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00681908784664919,
 'learning_rate_Hydroxylation-K': 0.0036165155670857658,
 'learning_rate_Hydroxylation-P': 0.005024586545080418,
 'log_base': 1.5249789663422724,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4208330894,
 'sample_weights': [1.6073660586194298, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.723607361920372,
 'weight_decay_Hydroxylation-K': 4.886877690038629,
 'weight_decay_Hydroxylation-P': 3.8050030260162595}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1742.685
[2,     1] loss: 1762.024
[3,     1] loss: 1752.550
[4,     1] loss: 1742.286
[5,     1] loss: 1739.008
[6,     1] loss: 1749.546
[7,     1] loss: 1742.830
[8,     1] loss: 1742.059
[9,     1] loss: 1746.133
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033514164858195385,
 'learning_rate_Hydroxylation-K': 0.0021372447635749324,
 'learning_rate_Hydroxylation-P': 0.005813671683442125,
 'log_base': 1.7426154605440864,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3067026508,
 'sample_weights': [3.9562081256306123, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.473232293214386,
 'weight_decay_Hydroxylation-K': 6.764681015290765,
 'weight_decay_Hydroxylation-P': 0.8189205952888485}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1551.463
[2,     1] loss: 1540.773
[3,     1] loss: 1543.830
[4,     1] loss: 1545.171
[5,     1] loss: 1539.918
[6,     1] loss: 1546.834
[7,     1] loss: 1530.434
[8,     1] loss: 1534.363
[9,     1] loss: 1516.057
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005434676782452517,
 'learning_rate_Hydroxylation-K': 0.005455518597971276,
 'learning_rate_Hydroxylation-P': 0.005249748976678482,
 'log_base': 2.53811111977142,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4072315803,
 'sample_weights': [3.005908993245239, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.15284108744293756,
 'weight_decay_Hydroxylation-K': 6.248477769596381,
 'weight_decay_Hydroxylation-P': 9.271281787816568}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1290.840
[2,     1] loss: 1295.171
[3,     1] loss: 1293.141
[4,     1] loss: 1287.226
[5,     1] loss: 1290.172
[6,     1] loss: 1291.438
[7,     1] loss: 1285.436
[8,     1] loss: 1287.939
[9,     1] loss: 1284.977
[10,     1] loss: 1287.926
[11,     1] loss: 1285.468
[12,     1] loss: 1285.074
[13,     1] loss: 1283.550
[14,     1] loss: 1283.647
[15,     1] loss: 1282.574
[16,     1] loss: 1280.512
[17,     1] loss: 1280.141
[18,     1] loss: 1274.561
[19,     1] loss: 1268.642
[20,     1] loss: 1269.198
[21,     1] loss: 1249.569
[22,     1] loss: 1236.467
[23,     1] loss: 1217.335
[24,     1] loss: 1198.604
[25,     1] loss: 1164.142
[26,     1] loss: 1171.351
[27,     1] loss: 1135.037
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005488573413016739,
 'learning_rate_Hydroxylation-K': 9.929129864676237e-05,
 'learning_rate_Hydroxylation-P': 0.004301471940182187,
 'log_base': 1.064526299958135,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3482991720,
 'sample_weights': [1.7923631414674452, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.97407927620947,
 'weight_decay_Hydroxylation-K': 1.0046019616989568,
 'weight_decay_Hydroxylation-P': 4.843906728495668}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 8631.059
[2,     1] loss: 8689.547
[3,     1] loss: 8734.853
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009281016349182941,
 'learning_rate_Hydroxylation-K': 0.008674344032635792,
 'learning_rate_Hydroxylation-P': 0.00826921843011032,
 'log_base': 1.3113126653639844,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2095206248,
 'sample_weights': [26.698312998205083, 3.337417690554037],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6525287311575223,
 'weight_decay_Hydroxylation-K': 5.856823131878784,
 'weight_decay_Hydroxylation-P': 4.4645838579795605}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2215.832
[2,     1] loss: 2209.477
[3,     1] loss: 2212.014
[4,     1] loss: 2204.128
[5,     1] loss: 2205.566
[6,     1] loss: 2202.214
[7,     1] loss: 2207.944
[8,     1] loss: 2207.456
[9,     1] loss: 2198.963
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019748367023323817,
 'learning_rate_Hydroxylation-K': 0.002352363883375019,
 'learning_rate_Hydroxylation-P': 0.0003163483487092849,
 'log_base': 2.4122907380126946,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3338836539,
 'sample_weights': [6.159655163265128, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.06436056178196259,
 'weight_decay_Hydroxylation-K': 5.841094821553018,
 'weight_decay_Hydroxylation-P': 0.21414111922604984}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1308.392
[2,     1] loss: 1307.892
[3,     1] loss: 1301.172
[4,     1] loss: 1293.993
[5,     1] loss: 1283.287
[6,     1] loss: 1248.994
[7,     1] loss: 1211.726
[8,     1] loss: 1169.396
[9,     1] loss: 1149.976
[10,     1] loss: 1139.248
[11,     1] loss: 1110.955
[12,     1] loss: 1125.359
[13,     1] loss: 1118.918
[14,     1] loss: 1083.073
[15,     1] loss: 1041.907
[16,     1] loss: 1121.055
[17,     1] loss: 1073.032
[18,     1] loss: 1080.446
[19,     1] loss: 1094.605
[20,     1] loss: 1053.103
[21,     1] loss: 1099.447
[22,     1] loss: 1123.520
[23,     1] loss: 1050.324
[24,     1] loss: 1026.023
[25,     1] loss: 1026.854
[26,     1] loss: 1098.303
[27,     1] loss: 1055.516
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007492677394549294,
 'learning_rate_Hydroxylation-K': 0.007758605102300641,
 'learning_rate_Hydroxylation-P': 0.006448017161177566,
 'log_base': 1.2675025284012764,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4247771137,
 'sample_weights': [1.8958518200134424, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.068948079393291,
 'weight_decay_Hydroxylation-K': 5.26598083805354,
 'weight_decay_Hydroxylation-P': 6.414100437269496}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2391.917
[2,     1] loss: 2410.551
[3,     1] loss: 2392.763
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004864695182258783,
 'learning_rate_Hydroxylation-K': 0.009361187448713238,
 'learning_rate_Hydroxylation-P': 0.009097704462028448,
 'log_base': 1.0530934036844348,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2489752179,
 'sample_weights': [7.042624148959824, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.255636194663991,
 'weight_decay_Hydroxylation-K': 7.829728765991176,
 'weight_decay_Hydroxylation-P': 6.177085735021919}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 10529.888
[2,     1] loss: 10480.416
[3,     1] loss: 10495.101
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001388977137115937,
 'learning_rate_Hydroxylation-K': 0.005373587615641227,
 'learning_rate_Hydroxylation-P': 0.004541114674698454,
 'log_base': 2.4866869772439153,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2208332675,
 'sample_weights': [32.27103828244569, 4.034035186553605],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.994591177353456,
 'weight_decay_Hydroxylation-K': 2.863780452484157,
 'weight_decay_Hydroxylation-P': 6.162874038270428}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1302.847
[2,     1] loss: 1292.174
[3,     1] loss: 1294.323
[4,     1] loss: 1292.981
[5,     1] loss: 1292.105
[6,     1] loss: 1299.094
[7,     1] loss: 1292.674
[8,     1] loss: 1290.473
[9,     1] loss: 1287.822
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027148674406897834,
 'learning_rate_Hydroxylation-K': 0.002671145977041888,
 'learning_rate_Hydroxylation-P': 0.004401412362668958,
 'log_base': 2.427024371041844,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 112506535,
 'sample_weights': [1.8326371120938414, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.042442112830667,
 'weight_decay_Hydroxylation-K': 3.1268254385096395,
 'weight_decay_Hydroxylation-P': 5.607851312313987}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1308.570
[2,     1] loss: 1304.777
[3,     1] loss: 1313.544
[4,     1] loss: 1303.801
[5,     1] loss: 1305.098
[6,     1] loss: 1310.688
[7,     1] loss: 1301.863
[8,     1] loss: 1293.708
[9,     1] loss: 1288.792
[10,     1] loss: 1273.195
[11,     1] loss: 1245.566
[12,     1] loss: 1221.165
[13,     1] loss: 1161.727
[14,     1] loss: 1152.788
[15,     1] loss: 1162.635
[16,     1] loss: 1131.905
[17,     1] loss: 1125.078
[18,     1] loss: 1028.147
[19,     1] loss: 1115.144
[20,     1] loss: 1095.184
[21,     1] loss: 1055.299
[22,     1] loss: 1065.841
[23,     1] loss: 1048.201
[24,     1] loss: 1037.498
[25,     1] loss: 1040.451
[26,     1] loss: 1024.416
[27,     1] loss: 967.799
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005960457380362296,
 'learning_rate_Hydroxylation-K': 0.0018895923875677741,
 'learning_rate_Hydroxylation-P': 0.007821747148226102,
 'log_base': 1.1824111792383207,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 749060807,
 'sample_weights': [1.88283210031697, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.66408610884465,
 'weight_decay_Hydroxylation-K': 8.060177985885922,
 'weight_decay_Hydroxylation-P': 9.475426529644718}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3255.405
[2,     1] loss: 3328.125
[3,     1] loss: 3234.989
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005151777896060262,
 'learning_rate_Hydroxylation-K': 0.00028507598198967564,
 'learning_rate_Hydroxylation-P': 0.009378917389066658,
 'log_base': 2.1708480739960603,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3954815641,
 'sample_weights': [9.963509983174221, 1.2454867271985668],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.7132445135536285,
 'weight_decay_Hydroxylation-K': 7.6781760772661,
 'weight_decay_Hydroxylation-P': 2.5826311499052856}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1363.713
[2,     1] loss: 1383.641
[3,     1] loss: 1376.521
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004197549939648911,
 'learning_rate_Hydroxylation-K': 0.0025473238372208627,
 'learning_rate_Hydroxylation-P': 0.004396608129322798,
 'log_base': 1.780164126514435,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1071655465,
 'sample_weights': [2.1537925116399768, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.857161718869369,
 'weight_decay_Hydroxylation-K': 3.322464463105333,
 'weight_decay_Hydroxylation-P': 2.432332078802451}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1522.809
[2,     1] loss: 1516.713
[3,     1] loss: 1521.713
[4,     1] loss: 1515.569
[5,     1] loss: 1516.043
[6,     1] loss: 1515.482
[7,     1] loss: 1505.011
[8,     1] loss: 1499.684
[9,     1] loss: 1486.338
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017893816205508534,
 'learning_rate_Hydroxylation-K': 0.009196842992317586,
 'learning_rate_Hydroxylation-P': 0.008149503156993657,
 'log_base': 1.2925255321162763,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1805371118,
 'sample_weights': [2.8947928474452493, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.433461305393849,
 'weight_decay_Hydroxylation-K': 6.451098070449117,
 'weight_decay_Hydroxylation-P': 9.154982687818567}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2277.813
[2,     1] loss: 2278.164
[3,     1] loss: 2286.813
[4,     1] loss: 2272.807
[5,     1] loss: 2279.027
[6,     1] loss: 2276.544
[7,     1] loss: 2276.312
[8,     1] loss: 2267.724
[9,     1] loss: 2266.069
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007112505519453983,
 'learning_rate_Hydroxylation-K': 0.00480585370638411,
 'learning_rate_Hydroxylation-P': 0.0089872812604659,
 'log_base': 1.8939163364567486,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 265460637,
 'sample_weights': [6.506062474134186, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.72886031602849,
 'weight_decay_Hydroxylation-K': 1.4268843172184713,
 'weight_decay_Hydroxylation-P': 3.2911958691618475}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1462.348
[2,     1] loss: 1487.813
[3,     1] loss: 1460.552
[4,     1] loss: 1459.314
[5,     1] loss: 1455.624
[6,     1] loss: 1463.088
[7,     1] loss: 1458.509
[8,     1] loss: 1456.134
[9,     1] loss: 1459.009
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004464528344225929,
 'learning_rate_Hydroxylation-K': 0.005866784295247058,
 'learning_rate_Hydroxylation-P': 5.07561088358532e-05,
 'log_base': 2.2798596854286157,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2657296461,
 'sample_weights': [2.6140318763339527, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3898589359769529,
 'weight_decay_Hydroxylation-K': 4.638631757103858,
 'weight_decay_Hydroxylation-P': 5.441293383061898}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1343.564
[2,     1] loss: 1334.672
[3,     1] loss: 1348.394
[4,     1] loss: 1337.998
[5,     1] loss: 1334.376
[6,     1] loss: 1333.124
[7,     1] loss: 1327.163
[8,     1] loss: 1330.936
[9,     1] loss: 1319.866
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00779081187804927,
 'learning_rate_Hydroxylation-K': 0.009393646828928546,
 'learning_rate_Hydroxylation-P': 0.0013149631692134928,
 'log_base': 1.3779933167644987,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3091645015,
 'sample_weights': [2.0257432234140103, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.346322392471695,
 'weight_decay_Hydroxylation-K': 1.1448499707797244,
 'weight_decay_Hydroxylation-P': 9.475465992323961}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2005.946
[2,     1] loss: 2024.868
[3,     1] loss: 2070.769
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024724241120640394,
 'learning_rate_Hydroxylation-K': 0.008571608916747164,
 'learning_rate_Hydroxylation-P': 1.5334497552122427e-05,
 'log_base': 2.8969209270009175,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 621180628,
 'sample_weights': [5.206786268124996, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.679792848170033,
 'weight_decay_Hydroxylation-K': 3.7241749636132164,
 'weight_decay_Hydroxylation-P': 3.3831590013636235}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1245.246
[2,     1] loss: 1243.334
[3,     1] loss: 1240.766
[4,     1] loss: 1239.148
[5,     1] loss: 1238.150
[6,     1] loss: 1237.888
[7,     1] loss: 1241.661
[8,     1] loss: 1236.981
[9,     1] loss: 1230.828
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033808057859364385,
 'learning_rate_Hydroxylation-K': 0.0020821960915959167,
 'learning_rate_Hydroxylation-P': 0.009117947618568257,
 'log_base': 1.0355023869779632,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2788674506,
 'sample_weights': [1.5695441372727754, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.827044054292961,
 'weight_decay_Hydroxylation-K': 1.9109673345154046,
 'weight_decay_Hydroxylation-P': 4.618704701839207}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15519.297
Exploding loss, terminate run (best metric=1.0963190793991089)
Finished Training
Total time taken: 0.22799992561340332
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15539.936
Exploding loss, terminate run (best metric=1.0917763710021973)
Finished Training
Total time taken: 0.24300265312194824
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15562.798
Exploding loss, terminate run (best metric=1.0947129726409912)
Finished Training
Total time taken: 0.21899890899658203
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15549.383
Exploding loss, terminate run (best metric=1.0748544931411743)
Finished Training
Total time taken: 0.24699974060058594
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 15489.886
Exploding loss, terminate run (best metric=1.0741324424743652)
Finished Training
Total time taken: 0.2069995403289795
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15544.955
Exploding loss, terminate run (best metric=1.0964701175689697)
Finished Training
Total time taken: 0.21500015258789062
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15502.920
Exploding loss, terminate run (best metric=1.090689778327942)
Finished Training
Total time taken: 0.22999906539916992
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15539.895
Exploding loss, terminate run (best metric=1.0950989723205566)
Finished Training
Total time taken: 0.22799968719482422
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15549.715
Exploding loss, terminate run (best metric=1.0714423656463623)
Finished Training
Total time taken: 0.20799922943115234
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 15572.727
Exploding loss, terminate run (best metric=1.0876929759979248)
Finished Training
Total time taken: 0.22500228881835938
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15559.711
Exploding loss, terminate run (best metric=1.0969438552856445)
Finished Training
Total time taken: 0.22800016403198242
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15529.916
Exploding loss, terminate run (best metric=1.095794916152954)
Finished Training
Total time taken: 0.24500179290771484
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15687.328
Exploding loss, terminate run (best metric=1.0924255847930908)
Finished Training
Total time taken: 0.2310013771057129
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 15528.887
Exploding loss, terminate run (best metric=1.0748623609542847)
Finished Training
Total time taken: 0.2369999885559082
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 15578.966
Exploding loss, terminate run (best metric=1.0770074129104614)
Finished Training
Total time taken: 0.24199962615966797
{'Hydroxylation-K Validation Accuracy': 0.5605791962174941, 'Hydroxylation-K Validation Sensitivity': 0.4, 'Hydroxylation-K Validation Specificity': 0.6, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.6837816764132554, 'Hydroxylation-K AUC PR': 0.3776757089349909, 'Hydroxylation-K MCC': 0.0, 'Hydroxylation-K F1': 0.13481116584564862, 'Validation Loss (Hydroxylation-K)': 0.556613830725352, 'Hydroxylation-P Validation Accuracy': 0.5641551867079505, 'Hydroxylation-P Validation Sensitivity': 0.40190476190476193, 'Hydroxylation-P Validation Specificity': 0.5991869918699188, 'Hydroxylation-P Validation Precision': nan, 'Hydroxylation-P AUC ROC': 0.5895017326597455, 'Hydroxylation-P AUC PR': 0.265874820630859, 'Hydroxylation-P MCC': 0.0034110806305369824, 'Hydroxylation-P F1': 0.12364844705604222, 'Validation Loss (Hydroxylation-P)': 0.5307344317436218, 'Validation Loss (total)': 1.0873482465744018, 'TimeToTrain': 0.22886694272359212}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011390231088724292,
 'learning_rate_Hydroxylation-K': 0.0010682168170433198,
 'learning_rate_Hydroxylation-P': 0.0038581504725953117,
 'log_base': 2.0680703864580243,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 829657006,
 'sample_weights': [47.88877144120255, 5.973658379393796],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8857485447918695,
 'weight_decay_Hydroxylation-K': 1.4399001624976253,
 'weight_decay_Hydroxylation-P': 0.29649235738524254}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1393.865
[2,     1] loss: 1394.680
[3,     1] loss: 1391.781
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006766869145747657,
 'learning_rate_Hydroxylation-K': 0.005337621574171357,
 'learning_rate_Hydroxylation-P': 0.0040294407759290055,
 'log_base': 2.3263946919742775,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 544459467,
 'sample_weights': [2.2975590485746773, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.2676857190351063,
 'weight_decay_Hydroxylation-K': 3.1252859872201024,
 'weight_decay_Hydroxylation-P': 0.539713915444692}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1330.927
[2,     1] loss: 1351.136
[3,     1] loss: 1337.624
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002367318231442199,
 'learning_rate_Hydroxylation-K': 0.009864572734337152,
 'learning_rate_Hydroxylation-P': 0.009858384272779297,
 'log_base': 1.2103167498986873,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1412857217,
 'sample_weights': [1.9772641744801032, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2066281436928987,
 'weight_decay_Hydroxylation-K': 3.09084097809578,
 'weight_decay_Hydroxylation-P': 6.594509236542381}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2852.217
[2,     1] loss: 2845.980
[3,     1] loss: 2842.072
[4,     1] loss: 2845.905
[5,     1] loss: 2840.074
[6,     1] loss: 2824.902
[7,     1] loss: 2824.081
[8,     1] loss: 2833.027
[9,     1] loss: 2827.823
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007785991898521735,
 'learning_rate_Hydroxylation-K': 0.009034911893750861,
 'learning_rate_Hydroxylation-P': 0.0026707134865420535,
 'log_base': 2.911971612107496,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3633875797,
 'sample_weights': [8.745938612485206, 1.0932844426451256],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.2003659318761795,
 'weight_decay_Hydroxylation-K': 6.810099761176274,
 'weight_decay_Hydroxylation-P': 7.695845389622193}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.371
[2,     1] loss: 1244.581
[3,     1] loss: 1258.984
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0038942446867360233,
 'learning_rate_Hydroxylation-K': 0.0020910153255623972,
 'learning_rate_Hydroxylation-P': 0.00869013171926404,
 'log_base': 1.2971461006874145,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1505119999,
 'sample_weights': [1.5619345931880664, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.79019767780205,
 'weight_decay_Hydroxylation-K': 2.4254008633588198,
 'weight_decay_Hydroxylation-P': 5.482667353044201}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2265.606
[2,     1] loss: 2269.160
[3,     1] loss: 2262.593
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006084346815087267,
 'learning_rate_Hydroxylation-K': 0.008495094923630299,
 'learning_rate_Hydroxylation-P': 0.005107553902053361,
 'log_base': 2.776706865488068,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3003026658,
 'sample_weights': [6.416824858464968, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4591347730715891,
 'weight_decay_Hydroxylation-K': 7.905072234037063,
 'weight_decay_Hydroxylation-P': 8.47309016149882}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1251.390
[2,     1] loss: 1256.062
[3,     1] loss: 1268.063
[4,     1] loss: 1263.067
[5,     1] loss: 1246.811
[6,     1] loss: 1252.254
[7,     1] loss: 1249.267
[8,     1] loss: 1238.738
[9,     1] loss: 1221.191
[10,     1] loss: 1184.682
[11,     1] loss: 1151.542
[12,     1] loss: 1115.488
[13,     1] loss: 1118.124
[14,     1] loss: 1063.801
[15,     1] loss: 1129.684
[16,     1] loss: 1068.614
[17,     1] loss: 1099.754
[18,     1] loss: 1026.929
[19,     1] loss: 1055.247
[20,     1] loss: 1024.109
[21,     1] loss: 1004.394
[22,     1] loss: 1035.878
[23,     1] loss: 984.514
[24,     1] loss: 1004.971
[25,     1] loss: 948.340
[26,     1] loss: 985.661
[27,     1] loss: 992.965
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000412768116275896,
 'learning_rate_Hydroxylation-K': 0.0006760297413633744,
 'learning_rate_Hydroxylation-P': 0.004615165493243166,
 'log_base': 2.755149330980542,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 620072863,
 'sample_weights': [1.6346806102496156, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.761850408393837,
 'weight_decay_Hydroxylation-K': 0.6355031837749918,
 'weight_decay_Hydroxylation-P': 0.7139373515445768}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1257.481
[2,     1] loss: 1256.968
[3,     1] loss: 1253.781
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003650901998356635,
 'learning_rate_Hydroxylation-K': 0.003350227099424316,
 'learning_rate_Hydroxylation-P': 0.006983179155283447,
 'log_base': 2.5466861859651253,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3753280313,
 'sample_weights': [1.6472519542678403, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.322010871520518,
 'weight_decay_Hydroxylation-K': 3.2442824643174477,
 'weight_decay_Hydroxylation-P': 3.6784191044658603}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.542
[2,     1] loss: 1284.355
[3,     1] loss: 1283.155
[4,     1] loss: 1281.227
[5,     1] loss: 1286.751
[6,     1] loss: 1280.081
[7,     1] loss: 1253.704
[8,     1] loss: 1241.262
[9,     1] loss: 1181.796
[10,     1] loss: 1156.017
[11,     1] loss: 1099.238
[12,     1] loss: 1084.224
[13,     1] loss: 1079.635
[14,     1] loss: 1100.763
[15,     1] loss: 1058.524
[16,     1] loss: 1021.541
[17,     1] loss: 1082.601
[18,     1] loss: 1012.966
[19,     1] loss: 1056.030
[20,     1] loss: 983.377
[21,     1] loss: 1047.604
[22,     1] loss: 959.353
[23,     1] loss: 1055.981
[24,     1] loss: 899.637
[25,     1] loss: 962.140
[26,     1] loss: 983.990
[27,     1] loss: 967.490
[28,     1] loss: 906.586
[29,     1] loss: 901.960
[30,     1] loss: 928.486
[31,     1] loss: 897.924
[32,     1] loss: 931.220
[33,     1] loss: 867.736
[34,     1] loss: 825.005
[35,     1] loss: 897.312
[36,     1] loss: 826.590
[37,     1] loss: 867.558
[38,     1] loss: 891.882
[39,     1] loss: 777.225
[40,     1] loss: 809.143
[41,     1] loss: 778.568
[42,     1] loss: 828.114
[43,     1] loss: 818.563
[44,     1] loss: 781.584
[45,     1] loss: 750.156
[46,     1] loss: 767.222
Early stopping applied (best metric=0.8327733278274536)
Finished Training
Total time taken: 6.461007595062256
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1292.940
[2,     1] loss: 1287.641
[3,     1] loss: 1284.495
[4,     1] loss: 1284.412
[5,     1] loss: 1283.202
[6,     1] loss: 1286.426
[7,     1] loss: 1280.967
[8,     1] loss: 1275.907
[9,     1] loss: 1263.812
[10,     1] loss: 1246.188
[11,     1] loss: 1213.944
[12,     1] loss: 1196.416
[13,     1] loss: 1142.819
[14,     1] loss: 1133.157
[15,     1] loss: 1113.499
[16,     1] loss: 1078.582
[17,     1] loss: 1034.772
[18,     1] loss: 1041.594
[19,     1] loss: 1042.042
[20,     1] loss: 1045.500
[21,     1] loss: 1046.188
[22,     1] loss: 1046.400
[23,     1] loss: 1039.663
[24,     1] loss: 1046.977
[25,     1] loss: 1021.309
[26,     1] loss: 994.597
[27,     1] loss: 969.906
[28,     1] loss: 1007.593
[29,     1] loss: 956.356
[30,     1] loss: 977.345
[31,     1] loss: 967.950
[32,     1] loss: 995.740
[33,     1] loss: 934.329
[34,     1] loss: 949.777
[35,     1] loss: 928.218
[36,     1] loss: 959.335
[37,     1] loss: 936.416
[38,     1] loss: 964.831
[39,     1] loss: 952.749
[40,     1] loss: 892.975
[41,     1] loss: 875.775
[42,     1] loss: 907.380
[43,     1] loss: 901.160
[44,     1] loss: 878.308
[45,     1] loss: 859.804
[46,     1] loss: 802.794
[47,     1] loss: 812.826
[48,     1] loss: 825.181
[49,     1] loss: 885.818
[50,     1] loss: 787.979
[51,     1] loss: 786.927
[52,     1] loss: 831.637
[53,     1] loss: 775.309
[54,     1] loss: 777.299
[55,     1] loss: 746.799
[56,     1] loss: 755.611
[57,     1] loss: 698.345
[58,     1] loss: 678.704
[59,     1] loss: 734.615
[60,     1] loss: 726.802
[61,     1] loss: 776.469
[62,     1] loss: 759.609
[63,     1] loss: 739.190
[64,     1] loss: 700.930
[65,     1] loss: 729.882
[66,     1] loss: 693.756
[67,     1] loss: 725.408
[68,     1] loss: 632.666
[69,     1] loss: 747.909
Early stopping applied (best metric=0.7385537624359131)
Finished Training
Total time taken: 9.438007354736328
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1290.694
[2,     1] loss: 1289.726
[3,     1] loss: 1285.308
[4,     1] loss: 1281.957
[5,     1] loss: 1281.942
[6,     1] loss: 1275.354
[7,     1] loss: 1260.391
[8,     1] loss: 1235.621
[9,     1] loss: 1192.488
[10,     1] loss: 1153.481
[11,     1] loss: 1115.059
[12,     1] loss: 1119.226
[13,     1] loss: 1175.908
[14,     1] loss: 1065.533
[15,     1] loss: 1088.228
[16,     1] loss: 1038.542
[17,     1] loss: 1078.651
[18,     1] loss: 1082.774
[19,     1] loss: 1049.363
[20,     1] loss: 1056.272
[21,     1] loss: 1074.873
[22,     1] loss: 1045.982
[23,     1] loss: 1047.314
[24,     1] loss: 1045.918
[25,     1] loss: 1033.326
[26,     1] loss: 1020.323
[27,     1] loss: 1009.306
[28,     1] loss: 969.344
[29,     1] loss: 967.716
[30,     1] loss: 937.845
[31,     1] loss: 912.761
[32,     1] loss: 944.461
[33,     1] loss: 939.141
[34,     1] loss: 943.805
[35,     1] loss: 871.515
[36,     1] loss: 942.929
[37,     1] loss: 905.560
[38,     1] loss: 890.135
[39,     1] loss: 869.442
[40,     1] loss: 838.702
[41,     1] loss: 831.273
[42,     1] loss: 898.870
[43,     1] loss: 792.872
[44,     1] loss: 856.570
[45,     1] loss: 809.210
[46,     1] loss: 776.013
[47,     1] loss: 800.688
[48,     1] loss: 763.192
[49,     1] loss: 749.184
[50,     1] loss: 756.953
[51,     1] loss: 658.931
[52,     1] loss: 689.633
[53,     1] loss: 816.238
[54,     1] loss: 842.960
[55,     1] loss: 708.776
[56,     1] loss: 726.927
[57,     1] loss: 687.452
[58,     1] loss: 706.697
[59,     1] loss: 654.206
[60,     1] loss: 736.948
[61,     1] loss: 637.345
[62,     1] loss: 740.617
[63,     1] loss: 632.066
[64,     1] loss: 680.489
[65,     1] loss: 631.009
[66,     1] loss: 564.311
[67,     1] loss: 569.027
Early stopping applied (best metric=0.7692334651947021)
Finished Training
Total time taken: 9.498008728027344
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.569
[2,     1] loss: 1285.335
[3,     1] loss: 1289.688
[4,     1] loss: 1282.907
[5,     1] loss: 1274.393
[6,     1] loss: 1252.270
[7,     1] loss: 1213.551
[8,     1] loss: 1154.905
[9,     1] loss: 1125.016
[10,     1] loss: 1157.751
[11,     1] loss: 1136.405
[12,     1] loss: 1118.814
[13,     1] loss: 1074.205
[14,     1] loss: 1063.672
[15,     1] loss: 1058.353
[16,     1] loss: 1080.336
[17,     1] loss: 1072.612
[18,     1] loss: 1086.584
[19,     1] loss: 1014.351
[20,     1] loss: 997.484
[21,     1] loss: 997.599
[22,     1] loss: 998.465
[23,     1] loss: 1012.291
[24,     1] loss: 969.364
[25,     1] loss: 1000.403
[26,     1] loss: 995.340
[27,     1] loss: 1025.933
[28,     1] loss: 973.268
[29,     1] loss: 1029.959
[30,     1] loss: 957.991
[31,     1] loss: 951.837
[32,     1] loss: 951.681
[33,     1] loss: 941.548
[34,     1] loss: 933.327
[35,     1] loss: 943.065
[36,     1] loss: 908.347
[37,     1] loss: 841.661
[38,     1] loss: 883.925
[39,     1] loss: 847.088
[40,     1] loss: 893.326
[41,     1] loss: 905.079
[42,     1] loss: 831.460
[43,     1] loss: 854.861
[44,     1] loss: 832.554
[45,     1] loss: 813.367
[46,     1] loss: 883.481
[47,     1] loss: 780.775
[48,     1] loss: 911.900
[49,     1] loss: 844.036
[50,     1] loss: 826.448
[51,     1] loss: 824.174
[52,     1] loss: 797.749
[53,     1] loss: 737.824
[54,     1] loss: 773.502
[55,     1] loss: 754.471
[56,     1] loss: 755.425
[57,     1] loss: 698.887
[58,     1] loss: 727.853
[59,     1] loss: 703.803
[60,     1] loss: 670.872
[61,     1] loss: 675.907
[62,     1] loss: 623.260
[63,     1] loss: 678.886
[64,     1] loss: 651.406
[65,     1] loss: 592.357
[66,     1] loss: 628.629
[67,     1] loss: 726.721
[68,     1] loss: 635.657
[69,     1] loss: 548.045
[70,     1] loss: 635.447
[71,     1] loss: 592.816
[72,     1] loss: 586.178
[73,     1] loss: 593.645
[74,     1] loss: 592.345
[75,     1] loss: 597.221
[76,     1] loss: 527.102
[77,     1] loss: 567.168
[78,     1] loss: 519.509
[79,     1] loss: 543.860
[80,     1] loss: 547.101
[81,     1] loss: 559.083
[82,     1] loss: 515.193
[83,     1] loss: 528.737
[84,     1] loss: 579.102
[85,     1] loss: 510.351
[86,     1] loss: 521.444
[87,     1] loss: 506.910
[88,     1] loss: 466.334
[89,     1] loss: 498.748
[90,     1] loss: 475.569
[91,     1] loss: 490.585
[92,     1] loss: 592.165
[93,     1] loss: 599.197
[94,     1] loss: 496.492
[95,     1] loss: 638.068
[96,     1] loss: 502.714
Early stopping applied (best metric=0.5891404151916504)
Finished Training
Total time taken: 13.757013320922852
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1286.234
[2,     1] loss: 1287.821
[3,     1] loss: 1284.207
[4,     1] loss: 1284.712
[5,     1] loss: 1283.062
[6,     1] loss: 1273.205
[7,     1] loss: 1259.346
[8,     1] loss: 1217.681
[9,     1] loss: 1155.176
[10,     1] loss: 1133.531
[11,     1] loss: 1106.535
[12,     1] loss: 1118.958
[13,     1] loss: 1100.179
[14,     1] loss: 1057.519
[15,     1] loss: 1037.174
[16,     1] loss: 1037.462
[17,     1] loss: 1023.967
[18,     1] loss: 1038.947
[19,     1] loss: 1025.387
[20,     1] loss: 1048.940
[21,     1] loss: 1016.447
[22,     1] loss: 967.789
[23,     1] loss: 993.709
[24,     1] loss: 971.100
[25,     1] loss: 978.055
[26,     1] loss: 964.394
[27,     1] loss: 937.596
[28,     1] loss: 916.046
[29,     1] loss: 913.466
[30,     1] loss: 920.197
[31,     1] loss: 940.090
[32,     1] loss: 892.079
[33,     1] loss: 866.995
[34,     1] loss: 925.913
[35,     1] loss: 873.944
[36,     1] loss: 857.199
[37,     1] loss: 893.978
[38,     1] loss: 852.819
[39,     1] loss: 819.606
[40,     1] loss: 827.151
[41,     1] loss: 800.183
[42,     1] loss: 787.908
[43,     1] loss: 788.850
[44,     1] loss: 774.350
[45,     1] loss: 742.688
[46,     1] loss: 809.710
[47,     1] loss: 773.357
[48,     1] loss: 724.411
[49,     1] loss: 723.303
[50,     1] loss: 720.739
Early stopping applied (best metric=0.8251340985298157)
Finished Training
Total time taken: 7.0080060958862305
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1283.286
[2,     1] loss: 1283.599
[3,     1] loss: 1285.547
[4,     1] loss: 1275.671
[5,     1] loss: 1260.368
[6,     1] loss: 1228.324
[7,     1] loss: 1183.824
[8,     1] loss: 1142.375
[9,     1] loss: 1082.308
[10,     1] loss: 1093.411
[11,     1] loss: 1065.205
[12,     1] loss: 1075.500
[13,     1] loss: 1027.769
[14,     1] loss: 1049.874
[15,     1] loss: 1023.776
[16,     1] loss: 1032.645
[17,     1] loss: 997.308
[18,     1] loss: 1024.569
[19,     1] loss: 977.980
[20,     1] loss: 997.754
[21,     1] loss: 1025.833
[22,     1] loss: 1008.285
[23,     1] loss: 1012.074
[24,     1] loss: 971.000
[25,     1] loss: 979.427
[26,     1] loss: 956.184
[27,     1] loss: 1007.985
[28,     1] loss: 982.364
[29,     1] loss: 922.176
[30,     1] loss: 909.327
[31,     1] loss: 951.970
[32,     1] loss: 925.647
[33,     1] loss: 850.380
[34,     1] loss: 882.534
[35,     1] loss: 892.218
[36,     1] loss: 889.909
[37,     1] loss: 819.271
[38,     1] loss: 921.254
[39,     1] loss: 842.606
[40,     1] loss: 860.097
[41,     1] loss: 777.318
[42,     1] loss: 848.219
[43,     1] loss: 811.801
[44,     1] loss: 777.869
[45,     1] loss: 762.765
[46,     1] loss: 823.091
[47,     1] loss: 772.451
[48,     1] loss: 786.146
[49,     1] loss: 791.456
[50,     1] loss: 711.559
[51,     1] loss: 807.108
[52,     1] loss: 718.954
[53,     1] loss: 731.218
[54,     1] loss: 750.436
[55,     1] loss: 664.503
[56,     1] loss: 714.112
[57,     1] loss: 656.426
[58,     1] loss: 702.018
[59,     1] loss: 703.919
[60,     1] loss: 613.774
[61,     1] loss: 649.786
[62,     1] loss: 674.776
[63,     1] loss: 604.435
[64,     1] loss: 639.691
[65,     1] loss: 611.594
[66,     1] loss: 614.072
Early stopping applied (best metric=0.8502994775772095)
Finished Training
Total time taken: 10.032009840011597
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1288.096
[2,     1] loss: 1281.249
[3,     1] loss: 1288.399
[4,     1] loss: 1290.494
[5,     1] loss: 1283.948
[6,     1] loss: 1280.738
[7,     1] loss: 1276.940
[8,     1] loss: 1268.645
[9,     1] loss: 1255.177
[10,     1] loss: 1224.470
[11,     1] loss: 1176.958
[12,     1] loss: 1145.027
[13,     1] loss: 1125.542
[14,     1] loss: 1098.289
[15,     1] loss: 1115.564
[16,     1] loss: 1071.504
[17,     1] loss: 1075.448
[18,     1] loss: 1053.993
[19,     1] loss: 1034.767
[20,     1] loss: 1072.917
[21,     1] loss: 1021.032
[22,     1] loss: 1024.859
[23,     1] loss: 1027.520
[24,     1] loss: 1007.560
[25,     1] loss: 955.066
[26,     1] loss: 967.685
[27,     1] loss: 991.566
[28,     1] loss: 990.458
[29,     1] loss: 961.840
[30,     1] loss: 941.980
[31,     1] loss: 938.002
[32,     1] loss: 936.161
[33,     1] loss: 892.975
[34,     1] loss: 926.561
[35,     1] loss: 924.207
[36,     1] loss: 900.616
[37,     1] loss: 903.797
[38,     1] loss: 950.039
[39,     1] loss: 923.141
[40,     1] loss: 835.464
[41,     1] loss: 900.916
[42,     1] loss: 838.865
[43,     1] loss: 885.473
[44,     1] loss: 894.354
[45,     1] loss: 831.003
[46,     1] loss: 894.743
[47,     1] loss: 770.927
[48,     1] loss: 824.060
[49,     1] loss: 750.549
[50,     1] loss: 770.150
[51,     1] loss: 865.497
[52,     1] loss: 760.774
[53,     1] loss: 870.404
[54,     1] loss: 721.310
[55,     1] loss: 775.296
[56,     1] loss: 762.399
[57,     1] loss: 818.421
[58,     1] loss: 715.188
[59,     1] loss: 762.594
[60,     1] loss: 653.288
[61,     1] loss: 788.448
[62,     1] loss: 708.221
[63,     1] loss: 637.766
[64,     1] loss: 672.024
[65,     1] loss: 678.698
[66,     1] loss: 703.727
[67,     1] loss: 568.814
[68,     1] loss: 636.325
[69,     1] loss: 650.915
[70,     1] loss: 607.955
[71,     1] loss: 590.781
[72,     1] loss: 627.311
[73,     1] loss: 560.009
[74,     1] loss: 558.677
[75,     1] loss: 605.121
[76,     1] loss: 565.732
[77,     1] loss: 528.978
Early stopping applied (best metric=0.8528742790222168)
Finished Training
Total time taken: 12.86101245880127
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1290.524
[2,     1] loss: 1283.758
[3,     1] loss: 1284.875
[4,     1] loss: 1283.440
[5,     1] loss: 1285.600
[6,     1] loss: 1279.634
[7,     1] loss: 1268.776
[8,     1] loss: 1255.753
[9,     1] loss: 1218.176
[10,     1] loss: 1167.327
[11,     1] loss: 1133.106
[12,     1] loss: 1099.130
[13,     1] loss: 1082.493
[14,     1] loss: 1081.466
[15,     1] loss: 1046.699
[16,     1] loss: 1066.705
[17,     1] loss: 1074.487
[18,     1] loss: 1036.757
[19,     1] loss: 1012.866
[20,     1] loss: 1035.779
[21,     1] loss: 994.831
[22,     1] loss: 1014.212
[23,     1] loss: 970.105
[24,     1] loss: 975.447
[25,     1] loss: 990.623
[26,     1] loss: 921.012
[27,     1] loss: 940.753
[28,     1] loss: 941.646
[29,     1] loss: 907.772
[30,     1] loss: 901.437
[31,     1] loss: 919.266
[32,     1] loss: 949.331
[33,     1] loss: 882.971
[34,     1] loss: 955.019
[35,     1] loss: 864.514
[36,     1] loss: 928.178
[37,     1] loss: 836.624
[38,     1] loss: 870.702
[39,     1] loss: 822.331
[40,     1] loss: 838.363
[41,     1] loss: 793.667
[42,     1] loss: 818.560
[43,     1] loss: 758.446
[44,     1] loss: 771.591
[45,     1] loss: 736.780
[46,     1] loss: 718.905
[47,     1] loss: 733.159
[48,     1] loss: 825.465
[49,     1] loss: 726.312
[50,     1] loss: 708.168
[51,     1] loss: 684.599
[52,     1] loss: 713.033
[53,     1] loss: 701.653
[54,     1] loss: 689.977
[55,     1] loss: 606.635
[56,     1] loss: 697.889
[57,     1] loss: 812.473
[58,     1] loss: 987.351
[59,     1] loss: 639.318
[60,     1] loss: 748.580
[61,     1] loss: 653.322
[62,     1] loss: 682.810
[63,     1] loss: 625.204
[64,     1] loss: 621.355
[65,     1] loss: 614.179
Early stopping applied (best metric=0.8597396612167358)
Finished Training
Total time taken: 10.661010026931763
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.378
[2,     1] loss: 1286.011
[3,     1] loss: 1291.170
[4,     1] loss: 1281.170
[5,     1] loss: 1278.383
[6,     1] loss: 1274.347
[7,     1] loss: 1256.712
[8,     1] loss: 1224.904
[9,     1] loss: 1173.942
[10,     1] loss: 1117.255
[11,     1] loss: 1101.205
[12,     1] loss: 1021.176
[13,     1] loss: 1068.229
[14,     1] loss: 1083.645
[15,     1] loss: 1038.946
[16,     1] loss: 1041.646
[17,     1] loss: 1002.739
[18,     1] loss: 1025.635
[19,     1] loss: 1023.203
[20,     1] loss: 1013.907
[21,     1] loss: 974.938
[22,     1] loss: 985.133
[23,     1] loss: 978.141
[24,     1] loss: 980.512
[25,     1] loss: 927.063
[26,     1] loss: 899.474
[27,     1] loss: 890.271
[28,     1] loss: 966.511
[29,     1] loss: 901.106
Early stopping applied (best metric=0.993293046951294)
Finished Training
Total time taken: 4.017004013061523
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1290.299
[2,     1] loss: 1285.080
[3,     1] loss: 1289.428
[4,     1] loss: 1284.834
[5,     1] loss: 1293.402
[6,     1] loss: 1280.551
[7,     1] loss: 1280.555
[8,     1] loss: 1268.116
[9,     1] loss: 1251.341
[10,     1] loss: 1218.487
[11,     1] loss: 1187.379
[12,     1] loss: 1129.790
[13,     1] loss: 1084.980
[14,     1] loss: 1085.652
[15,     1] loss: 1075.803
[16,     1] loss: 1081.198
[17,     1] loss: 995.079
[18,     1] loss: 1067.542
[19,     1] loss: 1035.975
[20,     1] loss: 1051.345
[21,     1] loss: 1026.477
[22,     1] loss: 1036.435
[23,     1] loss: 1018.353
[24,     1] loss: 1025.685
[25,     1] loss: 931.528
[26,     1] loss: 922.376
[27,     1] loss: 997.704
[28,     1] loss: 972.241
[29,     1] loss: 948.252
[30,     1] loss: 973.912
[31,     1] loss: 924.190
[32,     1] loss: 922.580
[33,     1] loss: 987.264
[34,     1] loss: 898.640
[35,     1] loss: 898.110
[36,     1] loss: 908.797
[37,     1] loss: 868.931
[38,     1] loss: 857.237
[39,     1] loss: 843.037
[40,     1] loss: 854.836
[41,     1] loss: 792.592
[42,     1] loss: 797.398
[43,     1] loss: 798.208
[44,     1] loss: 844.365
[45,     1] loss: 750.864
[46,     1] loss: 784.474
[47,     1] loss: 775.331
[48,     1] loss: 763.301
[49,     1] loss: 746.943
[50,     1] loss: 712.363
Early stopping applied (best metric=0.7894638776779175)
Finished Training
Total time taken: 7.837007522583008
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1290.021
[2,     1] loss: 1286.840
[3,     1] loss: 1283.679
[4,     1] loss: 1284.066
[5,     1] loss: 1283.174
[6,     1] loss: 1267.505
[7,     1] loss: 1254.397
[8,     1] loss: 1230.065
[9,     1] loss: 1189.453
[10,     1] loss: 1156.933
[11,     1] loss: 1114.948
[12,     1] loss: 1089.222
[13,     1] loss: 1084.523
[14,     1] loss: 1066.667
[15,     1] loss: 1147.552
[16,     1] loss: 1052.464
[17,     1] loss: 1124.420
[18,     1] loss: 1016.530
[19,     1] loss: 1060.951
[20,     1] loss: 1074.821
[21,     1] loss: 1011.445
[22,     1] loss: 1038.565
[23,     1] loss: 1002.730
[24,     1] loss: 994.842
[25,     1] loss: 976.709
[26,     1] loss: 1015.164
[27,     1] loss: 972.534
[28,     1] loss: 963.587
[29,     1] loss: 926.661
[30,     1] loss: 969.507
[31,     1] loss: 931.080
[32,     1] loss: 933.094
[33,     1] loss: 872.485
[34,     1] loss: 935.788
[35,     1] loss: 930.804
[36,     1] loss: 843.679
[37,     1] loss: 875.573
[38,     1] loss: 888.192
[39,     1] loss: 814.564
[40,     1] loss: 886.073
[41,     1] loss: 839.947
[42,     1] loss: 802.752
[43,     1] loss: 847.922
[44,     1] loss: 823.943
[45,     1] loss: 737.387
[46,     1] loss: 782.664
[47,     1] loss: 791.175
[48,     1] loss: 736.763
Early stopping applied (best metric=0.8307245969772339)
Finished Training
Total time taken: 7.291007041931152
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1282.393
[2,     1] loss: 1289.121
[3,     1] loss: 1290.808
[4,     1] loss: 1283.054
[5,     1] loss: 1281.396
[6,     1] loss: 1271.354
[7,     1] loss: 1262.789
[8,     1] loss: 1232.872
[9,     1] loss: 1187.512
[10,     1] loss: 1173.661
[11,     1] loss: 1108.989
[12,     1] loss: 1104.487
[13,     1] loss: 1059.544
[14,     1] loss: 1122.311
[15,     1] loss: 1031.890
[16,     1] loss: 1075.578
[17,     1] loss: 994.038
[18,     1] loss: 1031.933
[19,     1] loss: 1011.752
[20,     1] loss: 1048.814
[21,     1] loss: 982.542
[22,     1] loss: 998.396
[23,     1] loss: 1013.023
[24,     1] loss: 1003.548
[25,     1] loss: 963.320
[26,     1] loss: 967.381
[27,     1] loss: 948.114
[28,     1] loss: 954.497
[29,     1] loss: 950.693
[30,     1] loss: 930.603
[31,     1] loss: 919.559
[32,     1] loss: 938.867
[33,     1] loss: 863.683
[34,     1] loss: 901.057
[35,     1] loss: 883.065
[36,     1] loss: 862.954
[37,     1] loss: 844.709
[38,     1] loss: 821.248
Early stopping applied (best metric=1.0155987739562988)
Finished Training
Total time taken: 5.892004728317261
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1285.864
[2,     1] loss: 1288.569
[3,     1] loss: 1286.617
[4,     1] loss: 1288.983
[5,     1] loss: 1284.660
[6,     1] loss: 1286.235
[7,     1] loss: 1284.725
[8,     1] loss: 1279.572
[9,     1] loss: 1280.771
[10,     1] loss: 1270.121
[11,     1] loss: 1268.036
[12,     1] loss: 1253.324
[13,     1] loss: 1240.857
[14,     1] loss: 1211.944
[15,     1] loss: 1161.976
[16,     1] loss: 1128.419
[17,     1] loss: 1117.264
[18,     1] loss: 1077.936
[19,     1] loss: 1111.013
[20,     1] loss: 1157.909
[21,     1] loss: 1060.295
[22,     1] loss: 1111.430
[23,     1] loss: 1064.394
[24,     1] loss: 1075.307
[25,     1] loss: 1008.300
[26,     1] loss: 1025.129
[27,     1] loss: 1013.044
[28,     1] loss: 984.264
[29,     1] loss: 990.574
[30,     1] loss: 1042.415
[31,     1] loss: 1001.343
[32,     1] loss: 951.155
[33,     1] loss: 953.679
[34,     1] loss: 959.051
[35,     1] loss: 958.151
[36,     1] loss: 968.915
[37,     1] loss: 925.701
[38,     1] loss: 940.458
[39,     1] loss: 911.551
[40,     1] loss: 948.334
[41,     1] loss: 904.405
[42,     1] loss: 904.284
[43,     1] loss: 895.580
[44,     1] loss: 840.693
[45,     1] loss: 860.823
[46,     1] loss: 903.634
[47,     1] loss: 802.591
[48,     1] loss: 848.889
[49,     1] loss: 881.735
[50,     1] loss: 844.914
[51,     1] loss: 803.140
[52,     1] loss: 776.011
[53,     1] loss: 738.095
[54,     1] loss: 809.242
[55,     1] loss: 763.406
[56,     1] loss: 740.916
[57,     1] loss: 767.268
[58,     1] loss: 817.867
[59,     1] loss: 735.924
[60,     1] loss: 693.288
[61,     1] loss: 789.426
Early stopping applied (best metric=0.6737334132194519)
Finished Training
Total time taken: 9.652008533477783
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1283.307
[2,     1] loss: 1282.875
[3,     1] loss: 1284.828
[4,     1] loss: 1284.031
[5,     1] loss: 1283.433
[6,     1] loss: 1281.665
[7,     1] loss: 1275.643
[8,     1] loss: 1270.673
[9,     1] loss: 1260.434
[10,     1] loss: 1244.237
[11,     1] loss: 1220.094
[12,     1] loss: 1184.431
[13,     1] loss: 1182.481
[14,     1] loss: 1123.693
[15,     1] loss: 1139.000
[16,     1] loss: 1075.668
[17,     1] loss: 1088.677
[18,     1] loss: 1070.995
[19,     1] loss: 1069.248
[20,     1] loss: 1004.907
[21,     1] loss: 980.116
[22,     1] loss: 993.856
[23,     1] loss: 996.947
[24,     1] loss: 1022.588
[25,     1] loss: 1005.777
[26,     1] loss: 980.826
[27,     1] loss: 963.927
[28,     1] loss: 996.696
[29,     1] loss: 949.073
[30,     1] loss: 963.651
[31,     1] loss: 963.160
[32,     1] loss: 889.071
[33,     1] loss: 942.056
[34,     1] loss: 872.649
[35,     1] loss: 950.600
[36,     1] loss: 912.162
[37,     1] loss: 885.901
[38,     1] loss: 893.454
[39,     1] loss: 846.321
[40,     1] loss: 873.021
[41,     1] loss: 813.851
[42,     1] loss: 850.336
[43,     1] loss: 761.804
[44,     1] loss: 800.676
[45,     1] loss: 788.239
[46,     1] loss: 777.505
[47,     1] loss: 737.877
[48,     1] loss: 721.643
Early stopping applied (best metric=0.8826862573623657)
Finished Training
Total time taken: 7.492007493972778
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1290.160
[2,     1] loss: 1299.975
[3,     1] loss: 1295.628
[4,     1] loss: 1284.572
[5,     1] loss: 1292.107
[6,     1] loss: 1291.397
[7,     1] loss: 1284.896
[8,     1] loss: 1283.552
[9,     1] loss: 1283.595
[10,     1] loss: 1280.466
[11,     1] loss: 1282.458
[12,     1] loss: 1275.582
[13,     1] loss: 1269.747
[14,     1] loss: 1254.528
[15,     1] loss: 1245.025
[16,     1] loss: 1214.743
[17,     1] loss: 1187.640
[18,     1] loss: 1141.959
[19,     1] loss: 1122.724
[20,     1] loss: 1080.710
[21,     1] loss: 1025.325
[22,     1] loss: 1050.926
[23,     1] loss: 1052.031
[24,     1] loss: 1013.838
[25,     1] loss: 1029.716
[26,     1] loss: 1037.020
[27,     1] loss: 979.971
[28,     1] loss: 1025.987
[29,     1] loss: 974.871
[30,     1] loss: 995.576
[31,     1] loss: 965.070
[32,     1] loss: 969.000
[33,     1] loss: 943.003
[34,     1] loss: 968.304
[35,     1] loss: 907.554
[36,     1] loss: 918.217
[37,     1] loss: 938.039
[38,     1] loss: 906.363
[39,     1] loss: 849.703
[40,     1] loss: 894.296
[41,     1] loss: 860.155
[42,     1] loss: 883.135
[43,     1] loss: 871.717
[44,     1] loss: 918.570
[45,     1] loss: 889.318
[46,     1] loss: 849.884
[47,     1] loss: 796.808
[48,     1] loss: 845.925
[49,     1] loss: 824.060
[50,     1] loss: 883.032
[51,     1] loss: 781.688
[52,     1] loss: 882.314
[53,     1] loss: 758.694
[54,     1] loss: 837.853
[55,     1] loss: 742.608
[56,     1] loss: 800.059
[57,     1] loss: 730.808
[58,     1] loss: 740.166
[59,     1] loss: 707.235
[60,     1] loss: 736.863
[61,     1] loss: 656.527
[62,     1] loss: 744.726
[63,     1] loss: 651.203
[64,     1] loss: 652.184
[65,     1] loss: 617.188
Early stopping applied (best metric=0.9140183925628662)
Finished Training
Total time taken: 9.345008373260498
{'Hydroxylation-K Validation Accuracy': 0.7549645390070922, 'Hydroxylation-K Validation Sensitivity': 0.6607407407407407, 'Hydroxylation-K Validation Specificity': 0.7789473684210526, 'Hydroxylation-K Validation Precision': 0.43908113672819554, 'Hydroxylation-K AUC ROC': 0.7849707602339181, 'Hydroxylation-K AUC PR': 0.5875031232388006, 'Hydroxylation-K MCC': 0.38617158222807046, 'Hydroxylation-K F1': 0.5227390773049523, 'Validation Loss (Hydroxylation-K)': 0.4519772042830785, 'Hydroxylation-P Validation Accuracy': 0.7784934267296076, 'Hydroxylation-P Validation Sensitivity': 0.7707407407407407, 'Hydroxylation-P Validation Specificity': 0.7801960197516086, 'Hydroxylation-P Validation Precision': 0.4501464964010404, 'Hydroxylation-P AUC ROC': 0.8476835305089832, 'Hydroxylation-P AUC PR': 0.5999670953488843, 'Hydroxylation-P MCC': 0.4635554538769595, 'Hydroxylation-P F1': 0.5608911615935046, 'Validation Loss (Hydroxylation-P)': 0.37584059635798134, 'Validation Loss (total)': 0.8278177897135417, 'TimeToTrain': 8.749474875132243}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002496635917644549,
 'learning_rate_Hydroxylation-K': 0.004748035822943509,
 'learning_rate_Hydroxylation-P': 0.006216597034281002,
 'log_base': 2.6451644785900634,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2699262057,
 'sample_weights': [1.7872208873831872, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2361751557615848,
 'weight_decay_Hydroxylation-K': 4.887594347959992,
 'weight_decay_Hydroxylation-P': 5.965584350501592}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1265.426
[2,     1] loss: 1275.802
[3,     1] loss: 1273.964
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00785304310978742,
 'learning_rate_Hydroxylation-K': 0.0055964877204786176,
 'learning_rate_Hydroxylation-P': 0.00799016755619742,
 'log_base': 1.9526596638414346,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1332050589,
 'sample_weights': [1.7162394219445252, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.336521835447875,
 'weight_decay_Hydroxylation-K': 9.002609435781501,
 'weight_decay_Hydroxylation-P': 8.629507375946337}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1441.080
[2,     1] loss: 1445.409
[3,     1] loss: 1432.027
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035439859065022642,
 'learning_rate_Hydroxylation-K': 0.0038843193000026952,
 'learning_rate_Hydroxylation-P': 0.007557892432736968,
 'log_base': 2.398134784307431,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2196243684,
 'sample_weights': [2.494713349518052, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8700118772360925,
 'weight_decay_Hydroxylation-K': 2.8903994817483643,
 'weight_decay_Hydroxylation-P': 3.943014624408303}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1313.229
[2,     1] loss: 1333.128
[3,     1] loss: 1307.594
[4,     1] loss: 1314.938
[5,     1] loss: 1306.818
[6,     1] loss: 1306.958
[7,     1] loss: 1310.705
[8,     1] loss: 1308.591
[9,     1] loss: 1306.165
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009488235902741623,
 'learning_rate_Hydroxylation-K': 0.0008227279059736247,
 'learning_rate_Hydroxylation-P': 0.00557715702311946,
 'log_base': 2.9909373999666156,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 421679681,
 'sample_weights': [1.908608465597112, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.739465841981774,
 'weight_decay_Hydroxylation-K': 5.437562987346711,
 'weight_decay_Hydroxylation-P': 0.4331106306353424}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1231.361
[2,     1] loss: 1228.877
[3,     1] loss: 1226.811
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004606989067051239,
 'learning_rate_Hydroxylation-K': 0.008715673699860534,
 'learning_rate_Hydroxylation-P': 0.001956427176017829,
 'log_base': 2.376011275146334,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3233750503,
 'sample_weights': [1.5237889606658501, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6074788860461684,
 'weight_decay_Hydroxylation-K': 7.721918486654953,
 'weight_decay_Hydroxylation-P': 2.467275950123824}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1321.210
[2,     1] loss: 1329.527
[3,     1] loss: 1318.058
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004695132763706651,
 'learning_rate_Hydroxylation-K': 0.0005937102895454752,
 'learning_rate_Hydroxylation-P': 0.00557243959980349,
 'log_base': 2.9682018996888417,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2462456426,
 'sample_weights': [1.929048412170421, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9401445981673286,
 'weight_decay_Hydroxylation-K': 5.451123420565877,
 'weight_decay_Hydroxylation-P': 6.1497344901072175}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1238.707
[2,     1] loss: 1242.735
[3,     1] loss: 1237.104
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00499704934288103,
 'learning_rate_Hydroxylation-K': 0.003158185341436652,
 'learning_rate_Hydroxylation-P': 0.009334932832774942,
 'log_base': 2.8588598695854377,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 236439953,
 'sample_weights': [1.5344762220799755, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7496598868022293,
 'weight_decay_Hydroxylation-K': 5.655466728143331,
 'weight_decay_Hydroxylation-P': 3.1519193819675335}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1245.381
[2,     1] loss: 1251.214
[3,     1] loss: 1248.035
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004627066887561148,
 'learning_rate_Hydroxylation-K': 0.006732713580983117,
 'learning_rate_Hydroxylation-P': 0.004042222422351353,
 'log_base': 2.2673144713930258,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 155079793,
 'sample_weights': [1.589305745373162, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.302632589901493,
 'weight_decay_Hydroxylation-K': 3.4520955073753603,
 'weight_decay_Hydroxylation-P': 4.34861217637543}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1337.987
[2,     1] loss: 1336.847
[3,     1] loss: 1340.774
[4,     1] loss: 1331.725
[5,     1] loss: 1304.114
[6,     1] loss: 1266.616
[7,     1] loss: 1239.365
[8,     1] loss: 1245.303
[9,     1] loss: 1194.263
[10,     1] loss: 1142.948
[11,     1] loss: 1220.518
[12,     1] loss: 1129.226
[13,     1] loss: 1140.940
[14,     1] loss: 1116.184
[15,     1] loss: 1072.592
[16,     1] loss: 1099.269
[17,     1] loss: 1135.163
[18,     1] loss: 1096.270
[19,     1] loss: 1078.726
[20,     1] loss: 1115.388
[21,     1] loss: 1041.813
[22,     1] loss: 1031.980
[23,     1] loss: 1062.970
[24,     1] loss: 1037.720
[25,     1] loss: 986.467
[26,     1] loss: 990.888
[27,     1] loss: 1015.585
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00691550935451105,
 'learning_rate_Hydroxylation-K': 0.00972721246677411,
 'learning_rate_Hydroxylation-P': 0.0075036213342683155,
 'log_base': 2.1464626817935826,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 720550433,
 'sample_weights': [2.039397928338486, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.754958504668715,
 'weight_decay_Hydroxylation-K': 5.218755075865719,
 'weight_decay_Hydroxylation-P': 0.40407591137049587}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1370.456
[2,     1] loss: 1387.255
[3,     1] loss: 1404.249
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005330972790753009,
 'learning_rate_Hydroxylation-K': 0.009546143455469214,
 'learning_rate_Hydroxylation-P': 0.008976306637029977,
 'log_base': 2.909613491468624,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3229096312,
 'sample_weights': [2.185646454065644, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.292527215088242,
 'weight_decay_Hydroxylation-K': 7.068695843191505,
 'weight_decay_Hydroxylation-P': 1.3400004662864626}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.280
[2,     1] loss: 1237.750
[3,     1] loss: 1233.317
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025886211702852375,
 'learning_rate_Hydroxylation-K': 0.004106979786818679,
 'learning_rate_Hydroxylation-P': 0.00022955797451166974,
 'log_base': 2.2123293669139708,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3097665112,
 'sample_weights': [1.5631193743601688, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7339478789809677,
 'weight_decay_Hydroxylation-K': 2.9614139149896763,
 'weight_decay_Hydroxylation-P': 2.7939126517989266}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1352.872
[2,     1] loss: 1351.934
[3,     1] loss: 1358.137
[4,     1] loss: 1349.780
[5,     1] loss: 1350.115
[6,     1] loss: 1352.191
[7,     1] loss: 1344.222
[8,     1] loss: 1342.411
[9,     1] loss: 1319.727
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035261208736882287,
 'learning_rate_Hydroxylation-K': 0.003465301286356132,
 'learning_rate_Hydroxylation-P': 0.004127923087383893,
 'log_base': 1.2326130803627173,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1393739568,
 'sample_weights': [2.1024515015173773, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.5065167565672635,
 'weight_decay_Hydroxylation-K': 2.5270325552447552,
 'weight_decay_Hydroxylation-P': 3.3894193668856083}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2574.499
[2,     1] loss: 2604.062
[3,     1] loss: 2608.438
[4,     1] loss: 2571.082
[5,     1] loss: 2568.379
[6,     1] loss: 2577.619
[7,     1] loss: 2550.699
[8,     1] loss: 2545.370
[9,     1] loss: 2520.409
[10,     1] loss: 2496.259
[11,     1] loss: 2390.164
[12,     1] loss: 2352.064
[13,     1] loss: 2179.769
[14,     1] loss: 2109.512
[15,     1] loss: 2138.108
[16,     1] loss: 2144.733
[17,     1] loss: 2178.443
[18,     1] loss: 2028.244
[19,     1] loss: 2094.078
[20,     1] loss: 2092.666
[21,     1] loss: 2053.941
[22,     1] loss: 2014.816
[23,     1] loss: 1997.492
[24,     1] loss: 1996.501
[25,     1] loss: 1864.229
[26,     1] loss: 1981.674
[27,     1] loss: 1948.772
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002549013887277141,
 'learning_rate_Hydroxylation-K': 0.00034835883501478735,
 'learning_rate_Hydroxylation-P': 0.007223785237403798,
 'log_base': 1.4336840951149346,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2973417927,
 'sample_weights': [7.982557674963363, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.954548430045776,
 'weight_decay_Hydroxylation-K': 7.21516793066305,
 'weight_decay_Hydroxylation-P': 1.7452610289187855}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1886.147
[2,     1] loss: 1884.472
[3,     1] loss: 1888.242
[4,     1] loss: 1892.870
[5,     1] loss: 1876.778
[6,     1] loss: 1872.021
[7,     1] loss: 1877.356
[8,     1] loss: 1851.897
[9,     1] loss: 1822.605
[10,     1] loss: 1766.462
[11,     1] loss: 1755.678
[12,     1] loss: 1740.272
[13,     1] loss: 1659.776
[14,     1] loss: 1619.643
[15,     1] loss: 1595.153
[16,     1] loss: 1605.227
[17,     1] loss: 1634.670
[18,     1] loss: 1640.311
[19,     1] loss: 1568.387
[20,     1] loss: 1608.359
[21,     1] loss: 1539.871
[22,     1] loss: 1497.416
[23,     1] loss: 1585.240
[24,     1] loss: 1577.000
[25,     1] loss: 1542.787
[26,     1] loss: 1506.282
[27,     1] loss: 1454.040
[28,     1] loss: 1455.035
[29,     1] loss: 1440.735
[30,     1] loss: 1411.228
[31,     1] loss: 1462.735
[32,     1] loss: 1464.487
[33,     1] loss: 1407.832
[34,     1] loss: 1376.162
[35,     1] loss: 1292.824
[36,     1] loss: 1368.804
[37,     1] loss: 1300.778
[38,     1] loss: 1325.182
[39,     1] loss: 1270.740
[40,     1] loss: 1281.747
[41,     1] loss: 1201.577
[42,     1] loss: 1219.439
[43,     1] loss: 1173.413
[44,     1] loss: 1292.912
[45,     1] loss: 1059.392
[46,     1] loss: 1227.129
[47,     1] loss: 1058.696
[48,     1] loss: 1060.824
[49,     1] loss: 1017.874
[50,     1] loss: 1086.198
[51,     1] loss: 1077.063
[52,     1] loss: 950.493
[53,     1] loss: 932.469
Early stopping applied (best metric=0.7951713800430298)
Finished Training
Total time taken: 8.436007738113403
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1891.231
[2,     1] loss: 1878.771
[3,     1] loss: 1900.636
[4,     1] loss: 1875.721
[5,     1] loss: 1882.026
[6,     1] loss: 1878.789
[7,     1] loss: 1879.021
[8,     1] loss: 1876.928
[9,     1] loss: 1877.870
[10,     1] loss: 1859.012
[11,     1] loss: 1827.627
[12,     1] loss: 1796.263
[13,     1] loss: 1760.684
[14,     1] loss: 1744.994
[15,     1] loss: 1697.521
[16,     1] loss: 1652.462
[17,     1] loss: 1679.149
[18,     1] loss: 1626.714
[19,     1] loss: 1557.005
[20,     1] loss: 1597.694
[21,     1] loss: 1594.160
[22,     1] loss: 1504.758
[23,     1] loss: 1558.346
[24,     1] loss: 1505.528
[25,     1] loss: 1412.920
[26,     1] loss: 1523.913
[27,     1] loss: 1483.799
[28,     1] loss: 1486.598
[29,     1] loss: 1449.222
[30,     1] loss: 1453.975
[31,     1] loss: 1439.349
[32,     1] loss: 1350.279
[33,     1] loss: 1328.373
[34,     1] loss: 1294.081
[35,     1] loss: 1292.939
[36,     1] loss: 1348.519
[37,     1] loss: 1325.625
[38,     1] loss: 1271.956
[39,     1] loss: 1233.389
[40,     1] loss: 1206.324
[41,     1] loss: 1174.466
[42,     1] loss: 1278.018
[43,     1] loss: 1306.769
[44,     1] loss: 1079.796
[45,     1] loss: 1151.130
[46,     1] loss: 1061.948
[47,     1] loss: 1123.315
[48,     1] loss: 977.033
[49,     1] loss: 1085.019
[50,     1] loss: 1009.563
[51,     1] loss: 1022.065
Early stopping applied (best metric=0.8046300411224365)
Finished Training
Total time taken: 7.04900860786438
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1884.948
[2,     1] loss: 1885.544
[3,     1] loss: 1886.021
[4,     1] loss: 1883.250
[5,     1] loss: 1879.917
[6,     1] loss: 1888.809
[7,     1] loss: 1895.695
[8,     1] loss: 1870.794
[9,     1] loss: 1870.371
[10,     1] loss: 1871.143
[11,     1] loss: 1849.908
[12,     1] loss: 1839.743
[13,     1] loss: 1796.879
[14,     1] loss: 1765.734
[15,     1] loss: 1720.325
[16,     1] loss: 1731.166
[17,     1] loss: 1625.074
[18,     1] loss: 1619.382
[19,     1] loss: 1670.257
[20,     1] loss: 1684.088
[21,     1] loss: 1640.230
[22,     1] loss: 1632.222
[23,     1] loss: 1623.081
[24,     1] loss: 1599.053
[25,     1] loss: 1610.207
[26,     1] loss: 1610.588
[27,     1] loss: 1633.837
[28,     1] loss: 1550.451
[29,     1] loss: 1619.458
[30,     1] loss: 1500.748
[31,     1] loss: 1534.326
[32,     1] loss: 1560.147
[33,     1] loss: 1528.883
[34,     1] loss: 1498.575
[35,     1] loss: 1518.637
[36,     1] loss: 1458.236
[37,     1] loss: 1453.963
[38,     1] loss: 1456.026
[39,     1] loss: 1441.852
[40,     1] loss: 1385.433
[41,     1] loss: 1369.663
[42,     1] loss: 1404.351
[43,     1] loss: 1370.992
[44,     1] loss: 1302.294
[45,     1] loss: 1508.116
[46,     1] loss: 1331.549
[47,     1] loss: 1342.047
[48,     1] loss: 1273.485
[49,     1] loss: 1366.957
[50,     1] loss: 1301.149
[51,     1] loss: 1341.763
[52,     1] loss: 1300.870
[53,     1] loss: 1195.655
[54,     1] loss: 1301.928
[55,     1] loss: 1214.253
[56,     1] loss: 1258.709
[57,     1] loss: 1027.078
[58,     1] loss: 1269.728
[59,     1] loss: 1026.889
[60,     1] loss: 1200.011
[61,     1] loss: 1126.109
[62,     1] loss: 1173.699
[63,     1] loss: 1074.119
[64,     1] loss: 1060.102
[65,     1] loss: 1093.882
Early stopping applied (best metric=0.6695798635482788)
Finished Training
Total time taken: 9.260007381439209
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1875.735
[2,     1] loss: 1921.263
[3,     1] loss: 1873.373
[4,     1] loss: 1889.132
[5,     1] loss: 1884.472
[6,     1] loss: 1884.169
[7,     1] loss: 1882.760
[8,     1] loss: 1881.527
[9,     1] loss: 1873.722
[10,     1] loss: 1873.742
[11,     1] loss: 1869.565
[12,     1] loss: 1849.809
[13,     1] loss: 1828.283
[14,     1] loss: 1788.049
[15,     1] loss: 1749.325
[16,     1] loss: 1720.151
[17,     1] loss: 1701.344
[18,     1] loss: 1671.699
[19,     1] loss: 1646.664
[20,     1] loss: 1683.430
[21,     1] loss: 1660.951
[22,     1] loss: 1655.417
[23,     1] loss: 1569.573
[24,     1] loss: 1574.122
[25,     1] loss: 1544.521
[26,     1] loss: 1556.523
[27,     1] loss: 1526.966
[28,     1] loss: 1568.615
[29,     1] loss: 1501.245
[30,     1] loss: 1476.282
[31,     1] loss: 1460.925
[32,     1] loss: 1473.729
[33,     1] loss: 1393.298
[34,     1] loss: 1432.016
[35,     1] loss: 1391.121
[36,     1] loss: 1337.235
[37,     1] loss: 1388.802
[38,     1] loss: 1470.059
[39,     1] loss: 1308.855
[40,     1] loss: 1327.997
[41,     1] loss: 1296.108
[42,     1] loss: 1261.896
[43,     1] loss: 1246.896
[44,     1] loss: 1308.628
[45,     1] loss: 1248.198
[46,     1] loss: 1159.921
[47,     1] loss: 1155.364
[48,     1] loss: 1148.230
[49,     1] loss: 1144.292
[50,     1] loss: 1060.388
[51,     1] loss: 1153.806
[52,     1] loss: 1126.106
[53,     1] loss: 1042.935
[54,     1] loss: 1161.425
[55,     1] loss: 1011.315
[56,     1] loss: 1148.232
[57,     1] loss: 1074.942
[58,     1] loss: 1070.233
[59,     1] loss: 1079.181
[60,     1] loss: 1025.747
Early stopping applied (best metric=0.7597459554672241)
Finished Training
Total time taken: 9.876009941101074
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1897.351
[2,     1] loss: 1886.273
[3,     1] loss: 1897.985
[4,     1] loss: 1885.625
[5,     1] loss: 1889.599
[6,     1] loss: 1884.391
[7,     1] loss: 1883.543
[8,     1] loss: 1885.120
[9,     1] loss: 1883.428
[10,     1] loss: 1874.135
[11,     1] loss: 1883.247
[12,     1] loss: 1872.696
[13,     1] loss: 1864.742
[14,     1] loss: 1828.421
[15,     1] loss: 1824.069
[16,     1] loss: 1780.038
[17,     1] loss: 1740.330
[18,     1] loss: 1717.800
[19,     1] loss: 1709.181
[20,     1] loss: 1617.663
[21,     1] loss: 1731.367
[22,     1] loss: 1623.658
[23,     1] loss: 1654.721
[24,     1] loss: 1671.131
[25,     1] loss: 1628.798
[26,     1] loss: 1553.688
[27,     1] loss: 1590.299
[28,     1] loss: 1515.429
[29,     1] loss: 1583.360
[30,     1] loss: 1604.894
[31,     1] loss: 1493.359
[32,     1] loss: 1505.280
[33,     1] loss: 1486.775
[34,     1] loss: 1484.507
[35,     1] loss: 1502.220
[36,     1] loss: 1405.841
[37,     1] loss: 1461.046
[38,     1] loss: 1334.949
[39,     1] loss: 1510.987
[40,     1] loss: 1419.204
[41,     1] loss: 1391.983
[42,     1] loss: 1302.644
[43,     1] loss: 1523.355
[44,     1] loss: 1323.517
[45,     1] loss: 1482.905
[46,     1] loss: 1459.560
[47,     1] loss: 1213.766
[48,     1] loss: 1400.668
[49,     1] loss: 1348.893
[50,     1] loss: 1287.068
[51,     1] loss: 1248.708
[52,     1] loss: 1211.107
[53,     1] loss: 1253.150
[54,     1] loss: 1295.864
[55,     1] loss: 1193.081
Early stopping applied (best metric=0.6965179443359375)
Finished Training
Total time taken: 9.268009424209595
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1882.686
[2,     1] loss: 1898.248
[3,     1] loss: 1892.003
[4,     1] loss: 1885.310
[5,     1] loss: 1885.308
[6,     1] loss: 1885.564
[7,     1] loss: 1881.498
[8,     1] loss: 1881.880
[9,     1] loss: 1870.080
[10,     1] loss: 1865.063
[11,     1] loss: 1839.294
[12,     1] loss: 1833.233
[13,     1] loss: 1782.925
[14,     1] loss: 1730.785
[15,     1] loss: 1716.274
[16,     1] loss: 1704.216
[17,     1] loss: 1735.660
[18,     1] loss: 1654.584
[19,     1] loss: 1636.509
[20,     1] loss: 1629.631
[21,     1] loss: 1644.412
[22,     1] loss: 1659.178
[23,     1] loss: 1583.823
[24,     1] loss: 1588.196
[25,     1] loss: 1539.804
[26,     1] loss: 1578.031
[27,     1] loss: 1607.331
[28,     1] loss: 1566.667
[29,     1] loss: 1543.321
[30,     1] loss: 1462.689
[31,     1] loss: 1456.524
[32,     1] loss: 1477.919
[33,     1] loss: 1424.312
[34,     1] loss: 1435.221
[35,     1] loss: 1339.181
[36,     1] loss: 1324.790
[37,     1] loss: 1268.327
[38,     1] loss: 1244.922
[39,     1] loss: 1184.057
[40,     1] loss: 1199.961
[41,     1] loss: 1171.119
[42,     1] loss: 1222.690
[43,     1] loss: 1312.583
[44,     1] loss: 1225.672
[45,     1] loss: 1318.353
[46,     1] loss: 1132.603
[47,     1] loss: 1149.797
[48,     1] loss: 1125.220
[49,     1] loss: 1093.389
[50,     1] loss: 1037.756
[51,     1] loss: 1066.404
Early stopping applied (best metric=0.789807915687561)
Finished Training
Total time taken: 8.569008111953735
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1889.758
[2,     1] loss: 1885.190
[3,     1] loss: 1890.361
[4,     1] loss: 1882.530
[5,     1] loss: 1878.449
[6,     1] loss: 1885.346
[7,     1] loss: 1887.756
[8,     1] loss: 1864.286
[9,     1] loss: 1865.062
[10,     1] loss: 1841.208
[11,     1] loss: 1821.827
[12,     1] loss: 1766.573
[13,     1] loss: 1736.671
[14,     1] loss: 1717.588
[15,     1] loss: 1643.338
[16,     1] loss: 1645.094
[17,     1] loss: 1669.065
[18,     1] loss: 1593.583
[19,     1] loss: 1630.393
[20,     1] loss: 1571.568
[21,     1] loss: 1503.202
[22,     1] loss: 1519.459
[23,     1] loss: 1478.636
[24,     1] loss: 1511.250
[25,     1] loss: 1461.860
[26,     1] loss: 1458.837
[27,     1] loss: 1438.902
[28,     1] loss: 1412.177
[29,     1] loss: 1433.251
[30,     1] loss: 1393.870
[31,     1] loss: 1411.089
[32,     1] loss: 1366.841
[33,     1] loss: 1352.212
[34,     1] loss: 1289.458
[35,     1] loss: 1323.086
[36,     1] loss: 1256.043
Early stopping applied (best metric=0.8940147161483765)
Finished Training
Total time taken: 6.059008598327637
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1883.200
[2,     1] loss: 1901.763
[3,     1] loss: 1875.384
[4,     1] loss: 1873.222
[5,     1] loss: 1901.437
[6,     1] loss: 1889.837
[7,     1] loss: 1884.507
[8,     1] loss: 1870.061
[9,     1] loss: 1880.667
[10,     1] loss: 1876.385
[11,     1] loss: 1849.796
[12,     1] loss: 1819.984
[13,     1] loss: 1775.995
[14,     1] loss: 1734.123
[15,     1] loss: 1690.446
[16,     1] loss: 1646.638
[17,     1] loss: 1597.097
[18,     1] loss: 1543.635
[19,     1] loss: 1617.621
[20,     1] loss: 1642.562
[21,     1] loss: 1604.843
[22,     1] loss: 1574.506
[23,     1] loss: 1522.628
[24,     1] loss: 1570.410
[25,     1] loss: 1557.086
[26,     1] loss: 1502.449
[27,     1] loss: 1558.817
[28,     1] loss: 1505.909
[29,     1] loss: 1593.759
[30,     1] loss: 1519.469
[31,     1] loss: 1533.443
[32,     1] loss: 1451.205
[33,     1] loss: 1413.722
[34,     1] loss: 1426.358
[35,     1] loss: 1378.711
[36,     1] loss: 1398.057
[37,     1] loss: 1331.348
[38,     1] loss: 1436.013
[39,     1] loss: 1317.918
[40,     1] loss: 1307.191
[41,     1] loss: 1334.641
[42,     1] loss: 1331.013
[43,     1] loss: 1315.732
[44,     1] loss: 1219.434
[45,     1] loss: 1202.296
[46,     1] loss: 1264.284
[47,     1] loss: 1206.336
[48,     1] loss: 1097.395
[49,     1] loss: 1144.474
[50,     1] loss: 1120.324
[51,     1] loss: 1092.934
[52,     1] loss: 1063.807
[53,     1] loss: 1065.069
[54,     1] loss: 1145.315
[55,     1] loss: 1035.405
[56,     1] loss: 1074.704
[57,     1] loss: 1136.678
[58,     1] loss: 1023.042
Early stopping applied (best metric=0.8724161386489868)
Finished Training
Total time taken: 9.82801103591919
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1890.695
[2,     1] loss: 1882.350
[3,     1] loss: 1890.269
[4,     1] loss: 1882.968
[5,     1] loss: 1878.285
[6,     1] loss: 1882.143
[7,     1] loss: 1872.611
[8,     1] loss: 1870.617
[9,     1] loss: 1860.950
[10,     1] loss: 1845.702
[11,     1] loss: 1810.703
[12,     1] loss: 1783.102
[13,     1] loss: 1709.879
[14,     1] loss: 1631.938
[15,     1] loss: 1658.483
[16,     1] loss: 1652.194
[17,     1] loss: 1577.141
[18,     1] loss: 1672.758
[19,     1] loss: 1651.859
[20,     1] loss: 1624.053
[21,     1] loss: 1593.372
[22,     1] loss: 1694.697
[23,     1] loss: 1582.693
[24,     1] loss: 1552.909
[25,     1] loss: 1635.523
[26,     1] loss: 1539.248
[27,     1] loss: 1546.705
[28,     1] loss: 1513.547
[29,     1] loss: 1435.686
[30,     1] loss: 1514.675
[31,     1] loss: 1398.204
[32,     1] loss: 1486.207
[33,     1] loss: 1478.352
[34,     1] loss: 1444.914
[35,     1] loss: 1355.597
[36,     1] loss: 1305.403
[37,     1] loss: 1313.714
[38,     1] loss: 1402.328
Early stopping applied (best metric=0.7733416557312012)
Finished Training
Total time taken: 5.8020031452178955
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1905.001
[2,     1] loss: 1884.926
[3,     1] loss: 1893.287
[4,     1] loss: 1882.158
[5,     1] loss: 1881.130
[6,     1] loss: 1883.592
[7,     1] loss: 1879.653
[8,     1] loss: 1884.774
[9,     1] loss: 1873.942
[10,     1] loss: 1859.139
[11,     1] loss: 1848.694
[12,     1] loss: 1809.804
[13,     1] loss: 1777.515
[14,     1] loss: 1742.441
[15,     1] loss: 1709.709
[16,     1] loss: 1647.286
[17,     1] loss: 1632.828
[18,     1] loss: 1674.987
[19,     1] loss: 1655.180
[20,     1] loss: 1605.312
[21,     1] loss: 1560.144
[22,     1] loss: 1603.328
[23,     1] loss: 1583.009
[24,     1] loss: 1557.173
[25,     1] loss: 1531.298
[26,     1] loss: 1517.852
[27,     1] loss: 1470.885
[28,     1] loss: 1504.886
[29,     1] loss: 1467.208
[30,     1] loss: 1466.434
[31,     1] loss: 1333.118
[32,     1] loss: 1439.887
[33,     1] loss: 1402.960
[34,     1] loss: 1453.999
[35,     1] loss: 1450.210
[36,     1] loss: 1479.387
[37,     1] loss: 1301.629
[38,     1] loss: 1337.162
[39,     1] loss: 1240.266
[40,     1] loss: 1315.249
[41,     1] loss: 1211.949
[42,     1] loss: 1273.131
[43,     1] loss: 1389.861
[44,     1] loss: 1226.176
[45,     1] loss: 1322.090
[46,     1] loss: 1227.235
[47,     1] loss: 1280.132
[48,     1] loss: 1142.929
[49,     1] loss: 1253.639
[50,     1] loss: 1127.767
[51,     1] loss: 1137.924
[52,     1] loss: 1055.561
[53,     1] loss: 1250.311
[54,     1] loss: 1070.384
Early stopping applied (best metric=0.745253324508667)
Finished Training
Total time taken: 7.751007556915283
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1882.279
[2,     1] loss: 1883.944
[3,     1] loss: 1885.533
[4,     1] loss: 1886.749
[5,     1] loss: 1881.691
[6,     1] loss: 1888.430
[7,     1] loss: 1879.162
[8,     1] loss: 1874.033
[9,     1] loss: 1866.387
[10,     1] loss: 1848.846
[11,     1] loss: 1818.436
[12,     1] loss: 1786.122
[13,     1] loss: 1746.909
[14,     1] loss: 1696.624
[15,     1] loss: 1698.858
[16,     1] loss: 1675.902
[17,     1] loss: 1641.018
[18,     1] loss: 1607.717
[19,     1] loss: 1593.257
[20,     1] loss: 1609.356
[21,     1] loss: 1633.995
[22,     1] loss: 1619.217
[23,     1] loss: 1637.647
[24,     1] loss: 1581.376
[25,     1] loss: 1579.255
[26,     1] loss: 1568.988
[27,     1] loss: 1517.490
[28,     1] loss: 1491.170
[29,     1] loss: 1433.621
[30,     1] loss: 1475.744
[31,     1] loss: 1448.741
[32,     1] loss: 1490.551
[33,     1] loss: 1366.716
[34,     1] loss: 1414.150
[35,     1] loss: 1400.259
[36,     1] loss: 1372.449
[37,     1] loss: 1362.044
[38,     1] loss: 1276.050
[39,     1] loss: 1318.459
[40,     1] loss: 1317.470
[41,     1] loss: 1275.111
[42,     1] loss: 1379.490
[43,     1] loss: 1303.386
[44,     1] loss: 1266.868
[45,     1] loss: 1294.705
[46,     1] loss: 1198.447
[47,     1] loss: 1282.810
[48,     1] loss: 1210.483
[49,     1] loss: 1193.826
[50,     1] loss: 1235.982
[51,     1] loss: 1143.096
[52,     1] loss: 1128.830
[53,     1] loss: 1076.184
[54,     1] loss: 1005.669
[55,     1] loss: 1013.816
[56,     1] loss: 1050.458
[57,     1] loss: 1036.259
[58,     1] loss: 1004.893
[59,     1] loss: 1143.526
[60,     1] loss: 1018.960
Early stopping applied (best metric=0.6705663204193115)
Finished Training
Total time taken: 9.76400876045227
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1883.257
[2,     1] loss: 1889.254
[3,     1] loss: 1889.071
[4,     1] loss: 1884.946
[5,     1] loss: 1887.287
[6,     1] loss: 1883.519
[7,     1] loss: 1877.215
[8,     1] loss: 1879.357
[9,     1] loss: 1869.722
[10,     1] loss: 1846.933
[11,     1] loss: 1836.563
[12,     1] loss: 1798.455
[13,     1] loss: 1759.198
[14,     1] loss: 1721.921
[15,     1] loss: 1667.586
[16,     1] loss: 1604.795
[17,     1] loss: 1665.384
[18,     1] loss: 1664.908
[19,     1] loss: 1644.031
[20,     1] loss: 1601.591
[21,     1] loss: 1553.108
[22,     1] loss: 1559.786
[23,     1] loss: 1559.085
[24,     1] loss: 1566.948
[25,     1] loss: 1560.736
[26,     1] loss: 1520.137
[27,     1] loss: 1516.980
[28,     1] loss: 1475.092
[29,     1] loss: 1494.849
[30,     1] loss: 1527.953
[31,     1] loss: 1366.767
[32,     1] loss: 1435.714
[33,     1] loss: 1475.519
[34,     1] loss: 1413.193
[35,     1] loss: 1402.840
[36,     1] loss: 1258.387
[37,     1] loss: 1425.886
[38,     1] loss: 1270.927
[39,     1] loss: 1307.383
[40,     1] loss: 1276.082
[41,     1] loss: 1348.333
[42,     1] loss: 1255.861
[43,     1] loss: 1395.512
[44,     1] loss: 1168.428
[45,     1] loss: 1273.450
[46,     1] loss: 1175.002
[47,     1] loss: 1172.035
[48,     1] loss: 1297.920
[49,     1] loss: 1139.288
[50,     1] loss: 1125.576
[51,     1] loss: 1069.169
[52,     1] loss: 1153.844
[53,     1] loss: 1104.766
Early stopping applied (best metric=0.6952368021011353)
Finished Training
Total time taken: 7.286006212234497
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1889.629
[2,     1] loss: 1883.552
[3,     1] loss: 1889.178
[4,     1] loss: 1880.753
[5,     1] loss: 1884.817
[6,     1] loss: 1884.251
[7,     1] loss: 1876.797
[8,     1] loss: 1875.628
[9,     1] loss: 1862.412
[10,     1] loss: 1853.006
[11,     1] loss: 1831.007
[12,     1] loss: 1783.147
[13,     1] loss: 1731.698
[14,     1] loss: 1728.205
[15,     1] loss: 1672.980
[16,     1] loss: 1608.026
[17,     1] loss: 1580.539
[18,     1] loss: 1595.252
[19,     1] loss: 1658.639
[20,     1] loss: 1706.328
[21,     1] loss: 1603.196
[22,     1] loss: 1593.533
[23,     1] loss: 1535.537
[24,     1] loss: 1533.286
[25,     1] loss: 1560.945
[26,     1] loss: 1541.475
[27,     1] loss: 1570.560
[28,     1] loss: 1512.616
[29,     1] loss: 1514.728
[30,     1] loss: 1523.491
[31,     1] loss: 1442.098
[32,     1] loss: 1426.966
[33,     1] loss: 1378.054
[34,     1] loss: 1391.156
[35,     1] loss: 1334.144
[36,     1] loss: 1311.417
[37,     1] loss: 1220.250
[38,     1] loss: 1306.631
[39,     1] loss: 1303.355
[40,     1] loss: 1442.946
Early stopping applied (best metric=0.8743366599082947)
Finished Training
Total time taken: 5.494005441665649
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1884.499
[2,     1] loss: 1887.342
[3,     1] loss: 1886.405
[4,     1] loss: 1878.900
[5,     1] loss: 1883.076
[6,     1] loss: 1876.555
[7,     1] loss: 1869.600
[8,     1] loss: 1867.771
[9,     1] loss: 1845.629
[10,     1] loss: 1834.761
[11,     1] loss: 1791.024
[12,     1] loss: 1748.954
[13,     1] loss: 1688.191
[14,     1] loss: 1664.608
[15,     1] loss: 1666.530
[16,     1] loss: 1620.606
[17,     1] loss: 1688.523
[18,     1] loss: 1561.066
[19,     1] loss: 1484.675
[20,     1] loss: 1634.108
[21,     1] loss: 1565.441
[22,     1] loss: 1548.477
[23,     1] loss: 1604.792
[24,     1] loss: 1569.503
[25,     1] loss: 1531.595
[26,     1] loss: 1536.790
[27,     1] loss: 1509.975
[28,     1] loss: 1500.229
[29,     1] loss: 1490.156
[30,     1] loss: 1478.532
[31,     1] loss: 1472.254
[32,     1] loss: 1391.298
[33,     1] loss: 1491.417
[34,     1] loss: 1467.677
[35,     1] loss: 1420.379
[36,     1] loss: 1333.034
[37,     1] loss: 1380.254
[38,     1] loss: 1418.776
[39,     1] loss: 1324.225
[40,     1] loss: 1329.452
[41,     1] loss: 1303.944
[42,     1] loss: 1178.311
[43,     1] loss: 1216.784
[44,     1] loss: 1220.590
[45,     1] loss: 1195.178
[46,     1] loss: 1145.433
[47,     1] loss: 1121.546
[48,     1] loss: 1153.832
[49,     1] loss: 1196.053
[50,     1] loss: 1194.532
[51,     1] loss: 1146.301
[52,     1] loss: 1130.095
[53,     1] loss: 1103.271
[54,     1] loss: 1142.304
[55,     1] loss: 1151.279
[56,     1] loss: 1041.407
[57,     1] loss: 976.436
[58,     1] loss: 956.341
Early stopping applied (best metric=0.7697351574897766)
Finished Training
Total time taken: 9.014007568359375
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1891.443
[2,     1] loss: 1882.823
[3,     1] loss: 1893.552
[4,     1] loss: 1882.225
[5,     1] loss: 1879.565
[6,     1] loss: 1888.685
[7,     1] loss: 1878.432
[8,     1] loss: 1877.764
[9,     1] loss: 1866.004
[10,     1] loss: 1849.995
[11,     1] loss: 1828.922
[12,     1] loss: 1781.225
[13,     1] loss: 1738.891
[14,     1] loss: 1705.978
[15,     1] loss: 1690.972
[16,     1] loss: 1655.549
[17,     1] loss: 1632.928
[18,     1] loss: 1677.145
[19,     1] loss: 1680.120
[20,     1] loss: 1617.896
[21,     1] loss: 1664.416
[22,     1] loss: 1529.919
[23,     1] loss: 1624.768
[24,     1] loss: 1588.214
[25,     1] loss: 1583.365
[26,     1] loss: 1562.955
[27,     1] loss: 1618.434
[28,     1] loss: 1511.324
[29,     1] loss: 1467.499
[30,     1] loss: 1503.823
[31,     1] loss: 1463.701
[32,     1] loss: 1406.887
[33,     1] loss: 1443.453
[34,     1] loss: 1454.989
[35,     1] loss: 1428.848
[36,     1] loss: 1356.790
[37,     1] loss: 1418.062
[38,     1] loss: 1286.271
[39,     1] loss: 1331.212
[40,     1] loss: 1394.613
[41,     1] loss: 1318.831
[42,     1] loss: 1319.042
[43,     1] loss: 1318.021
[44,     1] loss: 1329.912
[45,     1] loss: 1209.294
[46,     1] loss: 1181.476
[47,     1] loss: 1200.217
[48,     1] loss: 1118.074
[49,     1] loss: 1201.925
[50,     1] loss: 1130.031
[51,     1] loss: 1072.154
[52,     1] loss: 1120.234
[53,     1] loss: 1065.729
[54,     1] loss: 1104.005
[55,     1] loss: 1082.954
[56,     1] loss: 1021.065
[57,     1] loss: 1107.929
[58,     1] loss: 1068.836
[59,     1] loss: 992.974
[60,     1] loss: 1041.967
[61,     1] loss: 942.974
Early stopping applied (best metric=0.8401412963867188)
Finished Training
Total time taken: 10.185009002685547
{'Hydroxylation-K Validation Accuracy': 0.7841016548463356, 'Hydroxylation-K Validation Sensitivity': 0.8185185185185185, 'Hydroxylation-K Validation Specificity': 0.775438596491228, 'Hydroxylation-K Validation Precision': 0.4850502971400804, 'Hydroxylation-K AUC ROC': 0.8447368421052631, 'Hydroxylation-K AUC PR': 0.6554626848654258, 'Hydroxylation-K MCC': 0.5055883001102645, 'Hydroxylation-K F1': 0.6052939091130318, 'Validation Loss (Hydroxylation-K)': 0.38899867932001747, 'Hydroxylation-P Validation Accuracy': 0.7868888550496591, 'Hydroxylation-P Validation Sensitivity': 0.734973544973545, 'Hydroxylation-P Validation Specificity': 0.7981021497331537, 'Hydroxylation-P Validation Precision': 0.4420571737026114, 'Hydroxylation-P AUC ROC': 0.8354482292193649, 'Hydroxylation-P AUC PR': 0.5802366153588585, 'Hydroxylation-P MCC': 0.4473982955882925, 'Hydroxylation-P F1': 0.5495464459020302, 'Validation Loss (Hydroxylation-P)': 0.3877009908358256, 'Validation Loss (total)': 0.7766996781031291, 'TimeToTrain': 8.242741235097249}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008848661387991756,
 'learning_rate_Hydroxylation-K': 0.009598981662931747,
 'learning_rate_Hydroxylation-P': 0.005788459467681726,
 'log_base': 2.2921781825168055,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 309570752,
 'sample_weights': [4.637594712503636, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.480528320761087,
 'weight_decay_Hydroxylation-K': 8.90658161038682,
 'weight_decay_Hydroxylation-P': 0.38178307958774876}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1336.308
[2,     1] loss: 1422.630
[3,     1] loss: 1331.692
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010028391235485474,
 'learning_rate_Hydroxylation-K': 0.0011978786573981024,
 'learning_rate_Hydroxylation-P': 0.009705389817399554,
 'log_base': 1.0547837998255127,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2449611825,
 'sample_weights': [2.012583534312955, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.207228926999797,
 'weight_decay_Hydroxylation-K': 0.5321383389857799,
 'weight_decay_Hydroxylation-P': 5.1338613840412695}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 10190.180
[2,     1] loss: 10164.185
[3,     1] loss: 10130.173
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022466788482025475,
 'learning_rate_Hydroxylation-K': 0.004743792706729006,
 'learning_rate_Hydroxylation-P': 0.007025685274375009,
 'log_base': 1.1299913795218566,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1361325053,
 'sample_weights': [31.300601471253763, 3.9127259120142552],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.999972860220657,
 'weight_decay_Hydroxylation-K': 3.771914281802762,
 'weight_decay_Hydroxylation-P': 5.682099448040556}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 4466.377
[2,     1] loss: 4430.102
[3,     1] loss: 4434.577
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013882131643048645,
 'learning_rate_Hydroxylation-K': 0.0007763832428754047,
 'learning_rate_Hydroxylation-P': 0.006772779862360429,
 'log_base': 1.4020669891943613,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 236778083,
 'sample_weights': [13.66044589982858, 1.7076215193824906],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.9528649125323465,
 'weight_decay_Hydroxylation-K': 8.232099802506628,
 'weight_decay_Hydroxylation-P': 3.2020006183845573}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1948.837
[2,     1] loss: 1949.241
[3,     1] loss: 1949.793
[4,     1] loss: 1943.379
[5,     1] loss: 1950.661
[6,     1] loss: 1947.045
[7,     1] loss: 1936.037
[8,     1] loss: 1950.053
[9,     1] loss: 1952.491
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005272821084548502,
 'learning_rate_Hydroxylation-K': 0.0043785814197159975,
 'learning_rate_Hydroxylation-P': 0.0014157125524768685,
 'log_base': 2.90594759074607,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 424033867,
 'sample_weights': [4.939947205889207, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.1080437109135649,
 'weight_decay_Hydroxylation-K': 4.856352596964128,
 'weight_decay_Hydroxylation-P': 4.2910844839414235}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.227
[2,     1] loss: 1235.985
[3,     1] loss: 1242.891
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002396538368000061,
 'learning_rate_Hydroxylation-K': 0.00043817413761979804,
 'learning_rate_Hydroxylation-P': 0.008642596123989389,
 'log_base': 2.7704455096808593,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1202971870,
 'sample_weights': [1.5649667054774918, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.924792313544081,
 'weight_decay_Hydroxylation-K': 6.720851301983067,
 'weight_decay_Hydroxylation-P': 0.23338325560079265}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1254.774
[2,     1] loss: 1253.399
[3,     1] loss: 1252.628
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0056216138055044055,
 'learning_rate_Hydroxylation-K': 0.005506722699807873,
 'learning_rate_Hydroxylation-P': 0.0023354318612906926,
 'log_base': 2.49103597641639,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4227286399,
 'sample_weights': [1.6383020705245421, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.271941050163385,
 'weight_decay_Hydroxylation-K': 1.4300868642942424,
 'weight_decay_Hydroxylation-P': 3.0048347353506295}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1299.093
[2,     1] loss: 1297.581
[3,     1] loss: 1292.243
[4,     1] loss: 1292.789
[5,     1] loss: 1292.515
[6,     1] loss: 1288.593
[7,     1] loss: 1281.493
[8,     1] loss: 1265.582
[9,     1] loss: 1241.851
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005757111730111577,
 'learning_rate_Hydroxylation-K': 0.0001411847349402631,
 'learning_rate_Hydroxylation-P': 0.008397421310504322,
 'log_base': 1.757030875211391,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1312978546,
 'sample_weights': [1.8291284805370438, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.8993349332790537,
 'weight_decay_Hydroxylation-K': 9.028119496788111,
 'weight_decay_Hydroxylation-P': 5.371804526892846}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1536.516
[2,     1] loss: 1551.954
[3,     1] loss: 1537.225
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031260201787519423,
 'learning_rate_Hydroxylation-K': 0.009230732043672476,
 'learning_rate_Hydroxylation-P': 0.005638968409947032,
 'log_base': 2.1455897775735275,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1578007337,
 'sample_weights': [2.96197297268001, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.50466552361557,
 'weight_decay_Hydroxylation-K': 9.855073302075018,
 'weight_decay_Hydroxylation-P': 7.783824482233038}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1366.589
[2,     1] loss: 1370.037
[3,     1] loss: 1363.758
[4,     1] loss: 1366.464
[5,     1] loss: 1352.900
[6,     1] loss: 1334.698
[7,     1] loss: 1292.505
[8,     1] loss: 1231.820
[9,     1] loss: 1150.293
[10,     1] loss: 1149.285
[11,     1] loss: 1130.620
[12,     1] loss: 1101.868
[13,     1] loss: 1102.323
[14,     1] loss: 1120.735
[15,     1] loss: 1121.604
[16,     1] loss: 1067.878
[17,     1] loss: 1126.111
[18,     1] loss: 1120.477
[19,     1] loss: 1031.116
[20,     1] loss: 1070.374
[21,     1] loss: 1071.817
[22,     1] loss: 1078.566
[23,     1] loss: 1044.768
[24,     1] loss: 1025.792
[25,     1] loss: 993.024
[26,     1] loss: 1025.115
[27,     1] loss: 999.650
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030301749241134204,
 'learning_rate_Hydroxylation-K': 0.0053507635355722945,
 'learning_rate_Hydroxylation-P': 0.005362317152576439,
 'log_base': 2.865892923459261,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 334697271,
 'sample_weights': [2.1868109851861917, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.124577226061903,
 'weight_decay_Hydroxylation-K': 9.855913694089383,
 'weight_decay_Hydroxylation-P': 8.841357631196374}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.744
[2,     1] loss: 1241.553
[3,     1] loss: 1237.482
[4,     1] loss: 1240.546
[5,     1] loss: 1229.412
[6,     1] loss: 1221.482
[7,     1] loss: 1199.974
[8,     1] loss: 1135.062
[9,     1] loss: 1080.133
[10,     1] loss: 1067.762
[11,     1] loss: 1080.389
[12,     1] loss: 1042.208
[13,     1] loss: 974.431
[14,     1] loss: 1013.004
[15,     1] loss: 1004.875
[16,     1] loss: 1009.955
[17,     1] loss: 1044.379
[18,     1] loss: 982.138
[19,     1] loss: 1001.549
[20,     1] loss: 980.589
[21,     1] loss: 967.968
[22,     1] loss: 988.924
[23,     1] loss: 975.827
[24,     1] loss: 979.313
[25,     1] loss: 971.207
[26,     1] loss: 923.595
[27,     1] loss: 934.192
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023557196323510444,
 'learning_rate_Hydroxylation-K': 0.001543329258165748,
 'learning_rate_Hydroxylation-P': 0.008077592837017453,
 'log_base': 1.5754827321518732,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 238157416,
 'sample_weights': [1.585596837795883, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.235974716129633,
 'weight_decay_Hydroxylation-K': 7.7741880310899365,
 'weight_decay_Hydroxylation-P': 2.4227057049364573}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1686.870
[2,     1] loss: 1683.725
[3,     1] loss: 1684.310
[4,     1] loss: 1678.864
[5,     1] loss: 1676.052
[6,     1] loss: 1679.067
[7,     1] loss: 1663.740
[8,     1] loss: 1663.115
[9,     1] loss: 1647.508
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0054813681075720835,
 'learning_rate_Hydroxylation-K': 0.005911839457345929,
 'learning_rate_Hydroxylation-P': 0.003546007395464514,
 'log_base': 2.708489790810227,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2286123479,
 'sample_weights': [3.672643486932409, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.746408269349951,
 'weight_decay_Hydroxylation-K': 4.81711743533776,
 'weight_decay_Hydroxylation-P': 2.5895132760716466}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1259.818
[2,     1] loss: 1255.490
[3,     1] loss: 1302.538
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007126734242641318,
 'learning_rate_Hydroxylation-K': 0.00985286675285801,
 'learning_rate_Hydroxylation-P': 0.0013680317563781004,
 'log_base': 1.337596489170363,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3239407191,
 'sample_weights': [1.6754896430648287, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.121102975768917,
 'weight_decay_Hydroxylation-K': 7.577805293019945,
 'weight_decay_Hydroxylation-P': 6.374984076636858}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2130.348
[2,     1] loss: 2118.124
[3,     1] loss: 2125.240
[4,     1] loss: 2118.174
[5,     1] loss: 2119.019
[6,     1] loss: 2113.122
[7,     1] loss: 2115.882
[8,     1] loss: 2112.644
[9,     1] loss: 2106.253
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023266829343487985,
 'learning_rate_Hydroxylation-K': 0.0034947099270184814,
 'learning_rate_Hydroxylation-P': 0.005413977647703628,
 'log_base': 2.8990742665979856,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1495003115,
 'sample_weights': [5.739396453238341, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.943791805009308,
 'weight_decay_Hydroxylation-K': 4.6298816358218975,
 'weight_decay_Hydroxylation-P': 0.6745809248374544}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.537
[2,     1] loss: 1242.167
[3,     1] loss: 1237.751
[4,     1] loss: 1247.735
[5,     1] loss: 1241.511
[6,     1] loss: 1236.232
[7,     1] loss: 1236.181
[8,     1] loss: 1234.828
[9,     1] loss: 1235.959
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028191516911540496,
 'learning_rate_Hydroxylation-K': 0.00023128084471796804,
 'learning_rate_Hydroxylation-P': 0.007980879301071261,
 'log_base': 1.7810583681243988,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 668335644,
 'sample_weights': [1.5684484498559976, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.5919138330596585,
 'weight_decay_Hydroxylation-K': 7.313337278954904,
 'weight_decay_Hydroxylation-P': 2.1016087511849775}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1520.714
[2,     1] loss: 1516.558
[3,     1] loss: 1519.864
[4,     1] loss: 1520.043
[5,     1] loss: 1510.813
[6,     1] loss: 1522.552
[7,     1] loss: 1499.614
[8,     1] loss: 1489.437
[9,     1] loss: 1470.694
[10,     1] loss: 1431.836
[11,     1] loss: 1396.449
[12,     1] loss: 1380.914
[13,     1] loss: 1354.447
[14,     1] loss: 1302.179
[15,     1] loss: 1307.746
[16,     1] loss: 1291.952
[17,     1] loss: 1232.434
[18,     1] loss: 1291.131
[19,     1] loss: 1264.003
[20,     1] loss: 1259.640
[21,     1] loss: 1214.096
[22,     1] loss: 1211.077
[23,     1] loss: 1224.599
[24,     1] loss: 1170.631
[25,     1] loss: 1153.538
[26,     1] loss: 1181.374
[27,     1] loss: 1116.574
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0050389311335040585,
 'learning_rate_Hydroxylation-K': 0.0030357606554874215,
 'learning_rate_Hydroxylation-P': 0.005958879527869225,
 'log_base': 2.0277478978009307,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 617542380,
 'sample_weights': [2.8922741784944432, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.815641232438686,
 'weight_decay_Hydroxylation-K': 1.7466701949048353,
 'weight_decay_Hydroxylation-P': 6.035261753233493}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1407.762
[2,     1] loss: 1406.944
[3,     1] loss: 1404.528
[4,     1] loss: 1415.534
[5,     1] loss: 1404.613
[6,     1] loss: 1403.254
[7,     1] loss: 1390.605
[8,     1] loss: 1373.074
[9,     1] loss: 1337.493
[10,     1] loss: 1282.332
[11,     1] loss: 1249.723
[12,     1] loss: 1266.250
[13,     1] loss: 1182.683
[14,     1] loss: 1185.621
[15,     1] loss: 1181.930
[16,     1] loss: 1146.116
[17,     1] loss: 1114.854
[18,     1] loss: 1153.798
[19,     1] loss: 1184.910
[20,     1] loss: 1128.850
[21,     1] loss: 1085.615
[22,     1] loss: 1080.209
[23,     1] loss: 1081.509
[24,     1] loss: 1068.842
[25,     1] loss: 1197.299
[26,     1] loss: 1081.021
[27,     1] loss: 1081.954
[28,     1] loss: 1071.224
[29,     1] loss: 1116.825
[30,     1] loss: 994.612
[31,     1] loss: 1037.176
[32,     1] loss: 994.223
[33,     1] loss: 1055.330
[34,     1] loss: 976.011
[35,     1] loss: 971.839
[36,     1] loss: 1009.521
[37,     1] loss: 922.787
[38,     1] loss: 1075.622
[39,     1] loss: 946.783
[40,     1] loss: 912.605
[41,     1] loss: 914.268
[42,     1] loss: 890.200
[43,     1] loss: 866.879
[44,     1] loss: 977.217
[45,     1] loss: 1350.247
[46,     1] loss: 1037.703
[47,     1] loss: 985.741
[48,     1] loss: 982.169
[49,     1] loss: 1045.984
[50,     1] loss: 1021.158
[51,     1] loss: 1039.805
[52,     1] loss: 940.185
[53,     1] loss: 1012.579
[54,     1] loss: 915.491
[55,     1] loss: 935.193
[56,     1] loss: 909.522
[57,     1] loss: 825.104
[58,     1] loss: 906.297
[59,     1] loss: 836.086
[60,     1] loss: 857.815
[61,     1] loss: 866.058
[62,     1] loss: 818.800
[63,     1] loss: 784.787
[64,     1] loss: 768.682
[65,     1] loss: 738.656
[66,     1] loss: 707.913
[67,     1] loss: 666.989
[68,     1] loss: 921.270
[69,     1] loss: 1317.057
[70,     1] loss: 1298.958
[71,     1] loss: 1108.239
[72,     1] loss: 1150.165
[73,     1] loss: 1185.820
[74,     1] loss: 1157.194
[75,     1] loss: 1141.565
[76,     1] loss: 1096.246
Early stopping applied (best metric=0.798448920249939)
Finished Training
Total time taken: 11.177011251449585
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1415.333
[2,     1] loss: 1412.992
[3,     1] loss: 1413.084
[4,     1] loss: 1401.345
[5,     1] loss: 1407.816
[6,     1] loss: 1405.746
[7,     1] loss: 1413.499
[8,     1] loss: 1407.800
[9,     1] loss: 1402.048
[10,     1] loss: 1400.029
[11,     1] loss: 1403.549
[12,     1] loss: 1398.017
[13,     1] loss: 1384.630
[14,     1] loss: 1362.930
[15,     1] loss: 1334.128
[16,     1] loss: 1302.748
[17,     1] loss: 1248.825
[18,     1] loss: 1236.348
[19,     1] loss: 1196.910
[20,     1] loss: 1152.241
[21,     1] loss: 1158.930
[22,     1] loss: 1201.220
[23,     1] loss: 1124.699
[24,     1] loss: 1230.645
[25,     1] loss: 1114.202
[26,     1] loss: 1156.375
[27,     1] loss: 1132.043
[28,     1] loss: 1128.675
[29,     1] loss: 1122.154
[30,     1] loss: 1092.490
[31,     1] loss: 1104.142
[32,     1] loss: 1082.714
[33,     1] loss: 1004.818
[34,     1] loss: 1015.455
[35,     1] loss: 997.419
[36,     1] loss: 1014.101
[37,     1] loss: 1031.619
[38,     1] loss: 1060.293
[39,     1] loss: 1008.489
[40,     1] loss: 987.319
[41,     1] loss: 1013.977
[42,     1] loss: 1008.527
[43,     1] loss: 1001.087
[44,     1] loss: 908.461
[45,     1] loss: 1062.366
[46,     1] loss: 1044.563
[47,     1] loss: 971.486
[48,     1] loss: 990.924
[49,     1] loss: 964.321
[50,     1] loss: 981.992
[51,     1] loss: 880.769
[52,     1] loss: 938.784
[53,     1] loss: 877.703
[54,     1] loss: 897.185
[55,     1] loss: 978.980
[56,     1] loss: 1098.554
[57,     1] loss: 883.086
[58,     1] loss: 1057.427
[59,     1] loss: 903.935
[60,     1] loss: 980.048
[61,     1] loss: 956.726
[62,     1] loss: 850.116
[63,     1] loss: 923.512
[64,     1] loss: 876.460
[65,     1] loss: 846.643
[66,     1] loss: 882.681
[67,     1] loss: 804.120
[68,     1] loss: 762.948
Early stopping applied (best metric=0.8052997589111328)
Finished Training
Total time taken: 11.254009485244751
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1406.664
[2,     1] loss: 1413.911
[3,     1] loss: 1416.087
[4,     1] loss: 1404.065
[5,     1] loss: 1404.422
[6,     1] loss: 1400.865
[7,     1] loss: 1400.787
[8,     1] loss: 1400.962
[9,     1] loss: 1395.923
[10,     1] loss: 1382.899
[11,     1] loss: 1366.969
[12,     1] loss: 1330.274
[13,     1] loss: 1317.574
[14,     1] loss: 1293.276
[15,     1] loss: 1264.295
[16,     1] loss: 1213.166
[17,     1] loss: 1191.344
[18,     1] loss: 1173.875
[19,     1] loss: 1174.504
[20,     1] loss: 1192.240
[21,     1] loss: 1123.168
[22,     1] loss: 1123.211
[23,     1] loss: 1099.002
[24,     1] loss: 1084.793
[25,     1] loss: 1111.348
[26,     1] loss: 1062.421
[27,     1] loss: 1064.618
[28,     1] loss: 1148.814
[29,     1] loss: 1071.784
[30,     1] loss: 1078.004
[31,     1] loss: 1026.618
[32,     1] loss: 1099.952
[33,     1] loss: 1068.001
[34,     1] loss: 1044.168
[35,     1] loss: 1050.536
[36,     1] loss: 1021.362
[37,     1] loss: 972.511
[38,     1] loss: 956.539
[39,     1] loss: 1008.718
[40,     1] loss: 974.754
[41,     1] loss: 1020.295
[42,     1] loss: 943.439
[43,     1] loss: 948.863
[44,     1] loss: 978.542
[45,     1] loss: 969.955
[46,     1] loss: 994.576
[47,     1] loss: 958.386
[48,     1] loss: 885.101
[49,     1] loss: 901.658
[50,     1] loss: 900.346
[51,     1] loss: 950.923
[52,     1] loss: 1214.779
[53,     1] loss: 916.531
[54,     1] loss: 1054.756
[55,     1] loss: 977.004
[56,     1] loss: 1008.163
[57,     1] loss: 1033.512
[58,     1] loss: 934.590
[59,     1] loss: 1056.617
[60,     1] loss: 950.393
[61,     1] loss: 908.629
[62,     1] loss: 976.922
[63,     1] loss: 907.148
[64,     1] loss: 955.771
Early stopping applied (best metric=0.7788762450218201)
Finished Training
Total time taken: 10.232009649276733
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1405.783
[2,     1] loss: 1402.007
[3,     1] loss: 1412.848
[4,     1] loss: 1408.811
[5,     1] loss: 1396.420
[6,     1] loss: 1398.166
[7,     1] loss: 1386.739
[8,     1] loss: 1361.990
[9,     1] loss: 1316.758
[10,     1] loss: 1276.429
[11,     1] loss: 1286.212
[12,     1] loss: 1206.174
[13,     1] loss: 1245.989
[14,     1] loss: 1146.913
[15,     1] loss: 1167.949
[16,     1] loss: 1215.480
[17,     1] loss: 1169.035
[18,     1] loss: 1160.181
[19,     1] loss: 1180.804
[20,     1] loss: 1166.927
[21,     1] loss: 1147.138
[22,     1] loss: 1150.170
[23,     1] loss: 1188.584
[24,     1] loss: 1108.715
[25,     1] loss: 1131.439
[26,     1] loss: 1105.787
[27,     1] loss: 1093.144
[28,     1] loss: 1028.291
[29,     1] loss: 1039.786
[30,     1] loss: 1021.617
[31,     1] loss: 1000.282
[32,     1] loss: 1063.277
[33,     1] loss: 1049.807
[34,     1] loss: 955.581
[35,     1] loss: 980.894
[36,     1] loss: 1000.562
[37,     1] loss: 1001.504
[38,     1] loss: 965.409
[39,     1] loss: 934.996
[40,     1] loss: 993.052
[41,     1] loss: 1019.989
[42,     1] loss: 1005.567
[43,     1] loss: 926.943
[44,     1] loss: 976.313
[45,     1] loss: 899.230
[46,     1] loss: 1054.232
[47,     1] loss: 1013.083
[48,     1] loss: 890.970
[49,     1] loss: 1051.530
[50,     1] loss: 860.050
[51,     1] loss: 961.294
[52,     1] loss: 875.902
[53,     1] loss: 900.354
[54,     1] loss: 860.132
[55,     1] loss: 839.781
[56,     1] loss: 867.891
[57,     1] loss: 884.882
[58,     1] loss: 772.970
[59,     1] loss: 773.646
[60,     1] loss: 708.283
[61,     1] loss: 772.683
[62,     1] loss: 1052.525
[63,     1] loss: 1950.927
[64,     1] loss: 1025.844
[65,     1] loss: 1005.834
[66,     1] loss: 1278.492
[67,     1] loss: 1184.720
[68,     1] loss: 1220.990
[69,     1] loss: 1263.160
[70,     1] loss: 1243.003
[71,     1] loss: 1231.318
[72,     1] loss: 1197.458
[73,     1] loss: 1151.020
[74,     1] loss: 1183.356
[75,     1] loss: 1178.876
[76,     1] loss: 1177.544
[77,     1] loss: 1186.993
[78,     1] loss: 1142.654
Early stopping applied (best metric=0.6950253844261169)
Finished Training
Total time taken: 11.060013055801392
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1415.772
[2,     1] loss: 1428.854
[3,     1] loss: 1408.045
[4,     1] loss: 1409.899
[5,     1] loss: 1408.809
[6,     1] loss: 1405.565
[7,     1] loss: 1406.954
[8,     1] loss: 1407.446
[9,     1] loss: 1405.802
[10,     1] loss: 1401.254
[11,     1] loss: 1402.098
[12,     1] loss: 1391.441
[13,     1] loss: 1382.241
[14,     1] loss: 1370.070
[15,     1] loss: 1342.492
[16,     1] loss: 1320.847
[17,     1] loss: 1303.992
[18,     1] loss: 1221.181
[19,     1] loss: 1226.773
[20,     1] loss: 1205.685
[21,     1] loss: 1173.212
[22,     1] loss: 1207.709
[23,     1] loss: 1201.738
[24,     1] loss: 1151.934
[25,     1] loss: 1162.430
[26,     1] loss: 1157.546
[27,     1] loss: 1120.798
[28,     1] loss: 1131.450
[29,     1] loss: 1108.129
[30,     1] loss: 1116.148
[31,     1] loss: 1127.494
[32,     1] loss: 1137.491
[33,     1] loss: 1026.878
[34,     1] loss: 1013.655
[35,     1] loss: 1094.542
[36,     1] loss: 1035.840
[37,     1] loss: 999.551
[38,     1] loss: 1020.269
[39,     1] loss: 973.809
[40,     1] loss: 993.117
[41,     1] loss: 991.489
[42,     1] loss: 975.431
[43,     1] loss: 993.429
[44,     1] loss: 1410.544
[45,     1] loss: 1029.265
[46,     1] loss: 1170.417
[47,     1] loss: 1116.592
[48,     1] loss: 1123.636
[49,     1] loss: 1098.296
[50,     1] loss: 1083.941
[51,     1] loss: 1055.226
[52,     1] loss: 1001.243
[53,     1] loss: 1093.454
[54,     1] loss: 976.390
[55,     1] loss: 1015.825
[56,     1] loss: 934.438
[57,     1] loss: 979.818
[58,     1] loss: 950.974
[59,     1] loss: 962.167
[60,     1] loss: 926.840
[61,     1] loss: 870.069
[62,     1] loss: 967.756
[63,     1] loss: 866.561
[64,     1] loss: 1127.683
[65,     1] loss: 1143.712
[66,     1] loss: 908.137
[67,     1] loss: 993.693
[68,     1] loss: 929.166
[69,     1] loss: 997.660
[70,     1] loss: 826.012
[71,     1] loss: 926.823
[72,     1] loss: 802.226
[73,     1] loss: 979.675
[74,     1] loss: 1009.856
[75,     1] loss: 774.313
[76,     1] loss: 971.701
[77,     1] loss: 884.658
[78,     1] loss: 891.721
[79,     1] loss: 881.479
[80,     1] loss: 879.026
Early stopping applied (best metric=0.7754718065261841)
Finished Training
Total time taken: 13.354009628295898
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1411.548
[2,     1] loss: 1407.693
[3,     1] loss: 1408.160
[4,     1] loss: 1406.564
[5,     1] loss: 1403.671
[6,     1] loss: 1399.988
[7,     1] loss: 1388.164
[8,     1] loss: 1374.635
[9,     1] loss: 1353.477
[10,     1] loss: 1286.346
[11,     1] loss: 1224.206
[12,     1] loss: 1233.678
[13,     1] loss: 1212.915
[14,     1] loss: 1119.970
[15,     1] loss: 1225.468
[16,     1] loss: 1155.997
[17,     1] loss: 1183.379
[18,     1] loss: 1165.428
[19,     1] loss: 1190.978
[20,     1] loss: 1135.261
[21,     1] loss: 1145.584
[22,     1] loss: 1132.519
[23,     1] loss: 1090.428
[24,     1] loss: 1078.025
[25,     1] loss: 1047.981
[26,     1] loss: 1041.710
[27,     1] loss: 1036.433
[28,     1] loss: 1016.003
[29,     1] loss: 1018.022
[30,     1] loss: 985.340
[31,     1] loss: 1013.994
[32,     1] loss: 1006.264
[33,     1] loss: 948.544
[34,     1] loss: 893.929
[35,     1] loss: 1015.578
[36,     1] loss: 1089.434
[37,     1] loss: 1097.621
[38,     1] loss: 938.112
[39,     1] loss: 1042.023
[40,     1] loss: 1026.750
[41,     1] loss: 962.982
[42,     1] loss: 968.223
[43,     1] loss: 934.924
[44,     1] loss: 936.410
[45,     1] loss: 939.414
[46,     1] loss: 869.566
[47,     1] loss: 965.826
[48,     1] loss: 946.912
[49,     1] loss: 886.502
[50,     1] loss: 877.607
[51,     1] loss: 909.826
[52,     1] loss: 829.828
[53,     1] loss: 855.455
[54,     1] loss: 785.967
[55,     1] loss: 879.274
[56,     1] loss: 919.419
[57,     1] loss: 832.901
[58,     1] loss: 696.918
[59,     1] loss: 786.846
[60,     1] loss: 874.878
[61,     1] loss: 770.714
[62,     1] loss: 722.391
[63,     1] loss: 798.081
[64,     1] loss: 748.318
[65,     1] loss: 707.425
[66,     1] loss: 722.818
[67,     1] loss: 877.070
[68,     1] loss: 1130.273
[69,     1] loss: 813.977
[70,     1] loss: 913.574
[71,     1] loss: 863.070
Early stopping applied (best metric=0.8920576572418213)
Finished Training
Total time taken: 11.841013193130493
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1407.130
[2,     1] loss: 1409.781
[3,     1] loss: 1402.326
[4,     1] loss: 1404.901
[5,     1] loss: 1411.324
[6,     1] loss: 1404.328
[7,     1] loss: 1404.583
[8,     1] loss: 1395.952
[9,     1] loss: 1393.730
[10,     1] loss: 1383.192
[11,     1] loss: 1347.411
[12,     1] loss: 1301.420
[13,     1] loss: 1270.508
[14,     1] loss: 1241.752
[15,     1] loss: 1248.433
[16,     1] loss: 1186.008
[17,     1] loss: 1185.966
[18,     1] loss: 1216.099
[19,     1] loss: 1142.861
[20,     1] loss: 1131.705
[21,     1] loss: 1149.007
[22,     1] loss: 1158.435
[23,     1] loss: 1142.938
[24,     1] loss: 1094.307
[25,     1] loss: 1193.859
[26,     1] loss: 1096.185
[27,     1] loss: 1071.138
[28,     1] loss: 1040.547
[29,     1] loss: 1044.299
[30,     1] loss: 979.864
[31,     1] loss: 1004.567
[32,     1] loss: 985.095
[33,     1] loss: 1176.818
[34,     1] loss: 1198.588
[35,     1] loss: 977.132
[36,     1] loss: 1049.892
[37,     1] loss: 1104.672
Early stopping applied (best metric=0.8385355472564697)
Finished Training
Total time taken: 6.239008665084839
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1407.792
[2,     1] loss: 1405.804
[3,     1] loss: 1404.229
[4,     1] loss: 1403.356
[5,     1] loss: 1398.434
[6,     1] loss: 1400.190
[7,     1] loss: 1365.907
[8,     1] loss: 1338.858
[9,     1] loss: 1344.068
[10,     1] loss: 1253.756
[11,     1] loss: 1286.895
[12,     1] loss: 1237.658
[13,     1] loss: 1221.266
[14,     1] loss: 1166.237
[15,     1] loss: 1158.336
[16,     1] loss: 1201.184
[17,     1] loss: 1148.941
[18,     1] loss: 1168.229
[19,     1] loss: 1145.073
[20,     1] loss: 1158.623
[21,     1] loss: 1117.564
[22,     1] loss: 1130.589
[23,     1] loss: 1109.811
[24,     1] loss: 1064.835
[25,     1] loss: 1085.333
[26,     1] loss: 1021.219
[27,     1] loss: 1055.362
[28,     1] loss: 999.552
[29,     1] loss: 999.233
[30,     1] loss: 986.536
[31,     1] loss: 1003.581
[32,     1] loss: 1044.253
[33,     1] loss: 968.726
[34,     1] loss: 946.249
[35,     1] loss: 939.294
[36,     1] loss: 979.063
[37,     1] loss: 970.211
[38,     1] loss: 1016.775
[39,     1] loss: 1274.213
[40,     1] loss: 998.115
[41,     1] loss: 1103.592
[42,     1] loss: 1043.437
[43,     1] loss: 1042.318
[44,     1] loss: 1045.561
[45,     1] loss: 992.485
[46,     1] loss: 958.620
[47,     1] loss: 1030.483
[48,     1] loss: 914.506
[49,     1] loss: 955.342
[50,     1] loss: 918.893
[51,     1] loss: 1004.250
[52,     1] loss: 902.620
[53,     1] loss: 970.242
[54,     1] loss: 885.273
Early stopping applied (best metric=0.85903400182724)
Finished Training
Total time taken: 7.849005222320557
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1418.718
[2,     1] loss: 1410.534
[3,     1] loss: 1406.972
[4,     1] loss: 1414.380
[5,     1] loss: 1403.602
[6,     1] loss: 1402.983
[7,     1] loss: 1401.932
[8,     1] loss: 1398.752
[9,     1] loss: 1391.060
[10,     1] loss: 1383.557
[11,     1] loss: 1360.931
[12,     1] loss: 1325.211
[13,     1] loss: 1298.997
[14,     1] loss: 1259.649
[15,     1] loss: 1242.708
[16,     1] loss: 1202.957
[17,     1] loss: 1172.323
[18,     1] loss: 1245.743
[19,     1] loss: 1188.217
[20,     1] loss: 1243.505
[21,     1] loss: 1160.100
[22,     1] loss: 1204.662
[23,     1] loss: 1169.266
[24,     1] loss: 1160.128
[25,     1] loss: 1162.950
[26,     1] loss: 1119.724
[27,     1] loss: 1120.094
[28,     1] loss: 1058.989
[29,     1] loss: 1110.965
[30,     1] loss: 1102.993
[31,     1] loss: 1043.072
[32,     1] loss: 1102.485
[33,     1] loss: 1052.252
[34,     1] loss: 1035.212
[35,     1] loss: 1018.176
[36,     1] loss: 1017.875
[37,     1] loss: 1100.516
[38,     1] loss: 1164.976
[39,     1] loss: 1046.874
[40,     1] loss: 1096.892
[41,     1] loss: 1016.342
[42,     1] loss: 1051.220
[43,     1] loss: 1024.285
[44,     1] loss: 975.526
[45,     1] loss: 972.209
[46,     1] loss: 937.197
[47,     1] loss: 1047.031
[48,     1] loss: 1059.796
[49,     1] loss: 933.214
[50,     1] loss: 933.376
[51,     1] loss: 911.265
[52,     1] loss: 879.386
[53,     1] loss: 918.871
[54,     1] loss: 930.428
[55,     1] loss: 802.270
[56,     1] loss: 824.192
[57,     1] loss: 938.736
[58,     1] loss: 1273.820
[59,     1] loss: 880.372
[60,     1] loss: 1088.829
[61,     1] loss: 957.389
[62,     1] loss: 981.858
[63,     1] loss: 1042.587
[64,     1] loss: 913.361
[65,     1] loss: 966.679
[66,     1] loss: 911.254
[67,     1] loss: 910.233
[68,     1] loss: 876.576
[69,     1] loss: 859.130
[70,     1] loss: 833.274
[71,     1] loss: 833.452
[72,     1] loss: 776.734
[73,     1] loss: 871.408
[74,     1] loss: 1117.181
[75,     1] loss: 804.205
Early stopping applied (best metric=0.7461013197898865)
Finished Training
Total time taken: 11.672011613845825
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1409.324
[2,     1] loss: 1409.366
[3,     1] loss: 1406.727
[4,     1] loss: 1411.617
[5,     1] loss: 1401.950
[6,     1] loss: 1387.689
[7,     1] loss: 1357.428
[8,     1] loss: 1302.419
[9,     1] loss: 1277.107
[10,     1] loss: 1250.625
[11,     1] loss: 1198.770
[12,     1] loss: 1272.868
[13,     1] loss: 1159.844
[14,     1] loss: 1200.183
[15,     1] loss: 1157.642
[16,     1] loss: 1130.189
[17,     1] loss: 1113.271
[18,     1] loss: 1130.692
[19,     1] loss: 1084.278
[20,     1] loss: 1099.901
[21,     1] loss: 1067.693
[22,     1] loss: 1037.149
[23,     1] loss: 1077.478
[24,     1] loss: 1073.867
[25,     1] loss: 982.363
[26,     1] loss: 1106.628
[27,     1] loss: 1022.649
[28,     1] loss: 998.524
[29,     1] loss: 987.058
[30,     1] loss: 966.838
[31,     1] loss: 962.544
[32,     1] loss: 1023.350
[33,     1] loss: 969.626
[34,     1] loss: 938.535
[35,     1] loss: 980.267
[36,     1] loss: 1062.148
[37,     1] loss: 903.844
[38,     1] loss: 951.285
[39,     1] loss: 950.206
Early stopping applied (best metric=0.8859514594078064)
Finished Training
Total time taken: 5.759005308151245
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1406.740
[2,     1] loss: 1401.995
[3,     1] loss: 1407.609
[4,     1] loss: 1419.664
[5,     1] loss: 1404.563
[6,     1] loss: 1406.389
[7,     1] loss: 1395.930
[8,     1] loss: 1397.957
[9,     1] loss: 1373.807
[10,     1] loss: 1349.010
[11,     1] loss: 1311.024
[12,     1] loss: 1259.712
[13,     1] loss: 1236.929
[14,     1] loss: 1216.387
[15,     1] loss: 1281.770
[16,     1] loss: 1179.782
[17,     1] loss: 1272.337
[18,     1] loss: 1164.759
[19,     1] loss: 1220.970
[20,     1] loss: 1203.115
[21,     1] loss: 1170.526
[22,     1] loss: 1162.252
[23,     1] loss: 1145.148
[24,     1] loss: 1138.086
[25,     1] loss: 1111.270
[26,     1] loss: 1141.830
[27,     1] loss: 1089.340
[28,     1] loss: 1089.286
[29,     1] loss: 1081.201
[30,     1] loss: 1074.476
[31,     1] loss: 1062.192
[32,     1] loss: 991.816
[33,     1] loss: 1054.027
[34,     1] loss: 1062.781
[35,     1] loss: 1019.329
[36,     1] loss: 1000.846
[37,     1] loss: 1044.816
[38,     1] loss: 1000.386
[39,     1] loss: 992.346
[40,     1] loss: 1016.237
[41,     1] loss: 974.451
[42,     1] loss: 978.243
[43,     1] loss: 1085.776
[44,     1] loss: 1212.052
[45,     1] loss: 998.190
[46,     1] loss: 1127.599
[47,     1] loss: 1085.185
[48,     1] loss: 1015.190
[49,     1] loss: 997.665
[50,     1] loss: 1024.492
[51,     1] loss: 1012.223
[52,     1] loss: 1030.518
[53,     1] loss: 945.824
[54,     1] loss: 948.979
[55,     1] loss: 938.043
[56,     1] loss: 920.724
[57,     1] loss: 961.119
[58,     1] loss: 935.584
[59,     1] loss: 906.784
[60,     1] loss: 875.700
[61,     1] loss: 827.110
[62,     1] loss: 878.163
[63,     1] loss: 896.690
[64,     1] loss: 923.946
[65,     1] loss: 829.645
[66,     1] loss: 809.822
[67,     1] loss: 785.573
[68,     1] loss: 738.295
[69,     1] loss: 692.660
[70,     1] loss: 696.510
[71,     1] loss: 870.525
[72,     1] loss: 2887.539
[73,     1] loss: 1686.310
[74,     1] loss: 1113.937
[75,     1] loss: 1221.944
[76,     1] loss: 1298.020
[77,     1] loss: 1260.263
[78,     1] loss: 1289.641
[79,     1] loss: 1305.895
[80,     1] loss: 1277.383
[81,     1] loss: 1273.056
[82,     1] loss: 1235.865
[83,     1] loss: 1278.148
Early stopping applied (best metric=0.7207329273223877)
Finished Training
Total time taken: 13.767013788223267
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1406.853
[2,     1] loss: 1410.174
[3,     1] loss: 1405.525
[4,     1] loss: 1400.045
[5,     1] loss: 1402.647
[6,     1] loss: 1402.311
[7,     1] loss: 1396.154
[8,     1] loss: 1387.461
[9,     1] loss: 1360.871
[10,     1] loss: 1365.094
[11,     1] loss: 1303.379
[12,     1] loss: 1264.918
[13,     1] loss: 1273.460
[14,     1] loss: 1244.240
[15,     1] loss: 1237.672
[16,     1] loss: 1224.257
[17,     1] loss: 1209.466
[18,     1] loss: 1138.849
[19,     1] loss: 1238.926
[20,     1] loss: 1188.423
[21,     1] loss: 1177.516
[22,     1] loss: 1211.463
[23,     1] loss: 1149.576
[24,     1] loss: 1219.371
[25,     1] loss: 1097.744
[26,     1] loss: 1112.604
[27,     1] loss: 1170.271
[28,     1] loss: 1119.345
[29,     1] loss: 1170.185
[30,     1] loss: 1114.908
[31,     1] loss: 1055.725
[32,     1] loss: 1143.972
[33,     1] loss: 1125.502
[34,     1] loss: 1099.680
[35,     1] loss: 1033.550
[36,     1] loss: 1051.294
[37,     1] loss: 1053.116
[38,     1] loss: 1049.510
[39,     1] loss: 1008.473
[40,     1] loss: 1014.296
[41,     1] loss: 1021.427
[42,     1] loss: 1000.382
[43,     1] loss: 988.941
[44,     1] loss: 1005.737
[45,     1] loss: 936.885
[46,     1] loss: 929.617
[47,     1] loss: 921.935
[48,     1] loss: 888.856
[49,     1] loss: 857.453
[50,     1] loss: 873.262
[51,     1] loss: 1707.461
[52,     1] loss: 1118.598
[53,     1] loss: 1138.356
[54,     1] loss: 1174.621
[55,     1] loss: 1194.644
[56,     1] loss: 1175.458
[57,     1] loss: 1140.979
[58,     1] loss: 1128.880
[59,     1] loss: 1086.823
[60,     1] loss: 1065.573
[61,     1] loss: 1063.447
[62,     1] loss: 1046.936
[63,     1] loss: 989.502
[64,     1] loss: 963.410
[65,     1] loss: 1009.182
[66,     1] loss: 946.014
[67,     1] loss: 960.866
Early stopping applied (best metric=0.6365833282470703)
Finished Training
Total time taken: 9.719012022018433
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1410.932
[2,     1] loss: 1408.482
[3,     1] loss: 1408.959
[4,     1] loss: 1406.573
[5,     1] loss: 1401.094
[6,     1] loss: 1392.930
[7,     1] loss: 1385.968
[8,     1] loss: 1363.952
[9,     1] loss: 1311.266
[10,     1] loss: 1271.239
[11,     1] loss: 1224.964
[12,     1] loss: 1238.566
[13,     1] loss: 1166.084
[14,     1] loss: 1193.075
[15,     1] loss: 1157.692
[16,     1] loss: 1165.192
[17,     1] loss: 1145.971
[18,     1] loss: 1162.793
[19,     1] loss: 1143.617
[20,     1] loss: 1081.213
[21,     1] loss: 1111.061
[22,     1] loss: 1085.752
[23,     1] loss: 1057.795
[24,     1] loss: 1064.461
[25,     1] loss: 1033.664
[26,     1] loss: 1091.777
[27,     1] loss: 1155.036
[28,     1] loss: 996.332
[29,     1] loss: 1124.750
[30,     1] loss: 1040.004
[31,     1] loss: 1075.756
[32,     1] loss: 997.538
[33,     1] loss: 1024.221
[34,     1] loss: 1023.709
[35,     1] loss: 965.179
[36,     1] loss: 957.383
[37,     1] loss: 916.137
[38,     1] loss: 941.187
[39,     1] loss: 907.827
[40,     1] loss: 865.571
[41,     1] loss: 868.849
[42,     1] loss: 914.708
[43,     1] loss: 994.435
[44,     1] loss: 1227.013
[45,     1] loss: 918.386
[46,     1] loss: 1032.727
[47,     1] loss: 926.461
[48,     1] loss: 982.032
[49,     1] loss: 989.060
[50,     1] loss: 950.379
[51,     1] loss: 924.311
[52,     1] loss: 966.844
[53,     1] loss: 854.308
[54,     1] loss: 864.465
[55,     1] loss: 892.896
[56,     1] loss: 832.846
[57,     1] loss: 823.495
Early stopping applied (best metric=0.8583378791809082)
Finished Training
Total time taken: 8.613008737564087
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1406.613
[2,     1] loss: 1422.255
[3,     1] loss: 1410.231
[4,     1] loss: 1406.596
[5,     1] loss: 1404.795
[6,     1] loss: 1404.035
[7,     1] loss: 1402.645
[8,     1] loss: 1402.344
[9,     1] loss: 1396.376
[10,     1] loss: 1392.524
[11,     1] loss: 1375.052
[12,     1] loss: 1345.352
[13,     1] loss: 1335.401
[14,     1] loss: 1290.649
[15,     1] loss: 1247.619
[16,     1] loss: 1190.360
[17,     1] loss: 1207.472
[18,     1] loss: 1198.471
[19,     1] loss: 1168.029
[20,     1] loss: 1160.591
[21,     1] loss: 1123.393
[22,     1] loss: 1079.902
[23,     1] loss: 1103.502
[24,     1] loss: 1084.289
[25,     1] loss: 1078.647
[26,     1] loss: 1181.150
[27,     1] loss: 1078.885
[28,     1] loss: 1158.681
[29,     1] loss: 1064.444
[30,     1] loss: 1121.563
[31,     1] loss: 1055.819
[32,     1] loss: 1048.130
[33,     1] loss: 1098.765
[34,     1] loss: 1010.964
[35,     1] loss: 1036.770
[36,     1] loss: 1013.478
[37,     1] loss: 992.645
[38,     1] loss: 956.692
[39,     1] loss: 964.017
[40,     1] loss: 932.400
[41,     1] loss: 971.036
[42,     1] loss: 891.351
[43,     1] loss: 906.372
[44,     1] loss: 970.822
[45,     1] loss: 1201.790
[46,     1] loss: 1000.002
[47,     1] loss: 1076.286
[48,     1] loss: 1020.429
[49,     1] loss: 1038.671
[50,     1] loss: 1001.630
[51,     1] loss: 922.148
[52,     1] loss: 1071.960
[53,     1] loss: 938.151
[54,     1] loss: 1020.351
[55,     1] loss: 901.724
[56,     1] loss: 996.409
[57,     1] loss: 945.550
[58,     1] loss: 921.124
Early stopping applied (best metric=0.8572973012924194)
Finished Training
Total time taken: 9.413007736206055
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1410.991
[2,     1] loss: 1415.967
[3,     1] loss: 1407.937
[4,     1] loss: 1402.818
[5,     1] loss: 1405.165
[6,     1] loss: 1406.485
[7,     1] loss: 1391.927
[8,     1] loss: 1386.976
[9,     1] loss: 1336.707
[10,     1] loss: 1302.338
[11,     1] loss: 1274.668
[12,     1] loss: 1238.700
[13,     1] loss: 1190.710
[14,     1] loss: 1203.880
[15,     1] loss: 1221.551
[16,     1] loss: 1177.216
[17,     1] loss: 1156.206
[18,     1] loss: 1181.828
[19,     1] loss: 1097.432
[20,     1] loss: 1140.232
[21,     1] loss: 1121.186
[22,     1] loss: 1077.739
[23,     1] loss: 1066.443
[24,     1] loss: 1058.721
[25,     1] loss: 1030.777
[26,     1] loss: 1046.040
[27,     1] loss: 1022.007
[28,     1] loss: 1050.947
[29,     1] loss: 1010.069
[30,     1] loss: 993.559
[31,     1] loss: 1071.447
[32,     1] loss: 960.484
[33,     1] loss: 976.283
[34,     1] loss: 973.833
[35,     1] loss: 875.292
[36,     1] loss: 986.209
[37,     1] loss: 1095.106
[38,     1] loss: 951.746
[39,     1] loss: 983.616
[40,     1] loss: 940.561
[41,     1] loss: 981.387
[42,     1] loss: 897.990
[43,     1] loss: 947.972
[44,     1] loss: 864.300
[45,     1] loss: 908.680
[46,     1] loss: 898.018
Early stopping applied (best metric=0.8344199657440186)
Finished Training
Total time taken: 6.337005376815796
{'Hydroxylation-K Validation Accuracy': 0.7758274231678487, 'Hydroxylation-K Validation Sensitivity': 0.6881481481481482, 'Hydroxylation-K Validation Specificity': 0.7982456140350878, 'Hydroxylation-K Validation Precision': 0.4675513538748833, 'Hydroxylation-K AUC ROC': 0.8073489278752437, 'Hydroxylation-K AUC PR': 0.5927356203541853, 'Hydroxylation-K MCC': 0.42840278724836567, 'Hydroxylation-K F1': 0.5523234650481027, 'Validation Loss (Hydroxylation-K)': 0.4227914710839589, 'Hydroxylation-P Validation Accuracy': 0.7761734091332081, 'Hydroxylation-P Validation Sensitivity': 0.7880423280423281, 'Hydroxylation-P Validation Specificity': 0.7736695097012319, 'Hydroxylation-P Validation Precision': 0.4326532398392502, 'Hydroxylation-P AUC ROC': 0.8477244441594285, 'Hydroxylation-P AUC PR': 0.5866264457053174, 'Hydroxylation-P MCC': 0.4602440592628943, 'Hydroxylation-P F1': 0.5553771726138366, 'Validation Loss (Hydroxylation-P)': 0.37602009971936545, 'Validation Loss (total)': 0.7988115668296814, 'TimeToTrain': 9.885742982228598}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028871087897423056,
 'learning_rate_Hydroxylation-K': 0.0003129992412149818,
 'learning_rate_Hydroxylation-P': 0.006142647083553058,
 'log_base': 2.8202935709232864,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4094687877,
 'sample_weights': [2.363305477133201, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8523934343911415,
 'weight_decay_Hydroxylation-K': 2.7635313763480207,
 'weight_decay_Hydroxylation-P': 5.0982231516068515}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1249.763
[2,     1] loss: 1249.226
[3,     1] loss: 1248.150
[4,     1] loss: 1247.803
[5,     1] loss: 1242.542
[6,     1] loss: 1235.273
[7,     1] loss: 1216.555
[8,     1] loss: 1193.641
[9,     1] loss: 1150.275
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030112014461961137,
 'learning_rate_Hydroxylation-K': 0.0014436887107963038,
 'learning_rate_Hydroxylation-P': 0.00029112987781872374,
 'log_base': 2.4900411243495943,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3241602390,
 'sample_weights': [1.6101245757887168, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5954594628881709,
 'weight_decay_Hydroxylation-K': 9.319299235806639,
 'weight_decay_Hydroxylation-P': 0.10979031882583801}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1295.159
[2,     1] loss: 1297.259
[3,     1] loss: 1291.234
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031273516627919576,
 'learning_rate_Hydroxylation-K': 0.0008091490769284276,
 'learning_rate_Hydroxylation-P': 0.004635479251100607,
 'log_base': 1.206492644587328,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 572011128,
 'sample_weights': [1.8299293692061915, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.848126974812279,
 'weight_decay_Hydroxylation-K': 8.482574651848168,
 'weight_decay_Hydroxylation-P': 0.6896542214182353}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2887.849
[2,     1] loss: 2889.994
[3,     1] loss: 2889.243
[4,     1] loss: 2880.445
[5,     1] loss: 2878.310
[6,     1] loss: 2890.237
[7,     1] loss: 2866.670
[8,     1] loss: 2875.728
[9,     1] loss: 2845.314
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004592820462473187,
 'learning_rate_Hydroxylation-K': 0.006892629672489344,
 'learning_rate_Hydroxylation-P': 0.0027342327095977786,
 'log_base': 1.86708917705336,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 400726653,
 'sample_weights': [8.893380011222582, 1.1117153274916414],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.33495113344301874,
 'weight_decay_Hydroxylation-K': 5.472557966818924,
 'weight_decay_Hydroxylation-P': 1.5609843547519893}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1472.292
[2,     1] loss: 1478.007
[3,     1] loss: 1467.480
[4,     1] loss: 1474.083
[5,     1] loss: 1470.325
[6,     1] loss: 1473.427
[7,     1] loss: 1459.103
[8,     1] loss: 1460.830
[9,     1] loss: 1453.142
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007526060943607861,
 'learning_rate_Hydroxylation-K': 0.003517496512360708,
 'learning_rate_Hydroxylation-P': 0.009042633244650225,
 'log_base': 2.7109053150027718,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2142463436,
 'sample_weights': [2.6737587166020496, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.751248616004197,
 'weight_decay_Hydroxylation-K': 5.78600303655253,
 'weight_decay_Hydroxylation-P': 7.079936858425971}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1264.159
[2,     1] loss: 1299.147
[3,     1] loss: 1260.518
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002231870779180808,
 'learning_rate_Hydroxylation-K': 0.005899762995109176,
 'learning_rate_Hydroxylation-P': 0.0036154845216329772,
 'log_base': 2.4477886194529783,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2094534123,
 'sample_weights': [1.6739919801085557, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.682900833080482,
 'weight_decay_Hydroxylation-K': 5.074897223522067,
 'weight_decay_Hydroxylation-P': 4.345086117047925}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1300.592
[2,     1] loss: 1305.783
[3,     1] loss: 1299.255
[4,     1] loss: 1299.867
[5,     1] loss: 1296.388
[6,     1] loss: 1292.704
[7,     1] loss: 1279.692
[8,     1] loss: 1258.164
[9,     1] loss: 1243.363
[10,     1] loss: 1218.007
[11,     1] loss: 1196.385
[12,     1] loss: 1182.981
[13,     1] loss: 1124.474
[14,     1] loss: 1143.472
[15,     1] loss: 1122.381
[16,     1] loss: 1125.155
[17,     1] loss: 1115.679
[18,     1] loss: 1113.706
[19,     1] loss: 1091.922
[20,     1] loss: 1085.747
[21,     1] loss: 1096.487
[22,     1] loss: 1046.837
[23,     1] loss: 1077.945
[24,     1] loss: 1079.607
[25,     1] loss: 1070.103
[26,     1] loss: 1073.914
[27,     1] loss: 1031.400
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0066386026095057475,
 'learning_rate_Hydroxylation-K': 0.004181811017815935,
 'learning_rate_Hydroxylation-P': 0.003037894071681363,
 'log_base': 1.459069527712923,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 183907473,
 'sample_weights': [1.8649140946456726, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.391106200988199,
 'weight_decay_Hydroxylation-K': 0.12284985236460866,
 'weight_decay_Hydroxylation-P': 9.993928769725137}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1839.523
[2,     1] loss: 1844.603
[3,     1] loss: 1842.249
[4,     1] loss: 1842.024
[5,     1] loss: 1853.439
[6,     1] loss: 1832.170
[7,     1] loss: 1846.176
[8,     1] loss: 1833.153
[9,     1] loss: 1813.816
[10,     1] loss: 1807.982
[11,     1] loss: 1779.654
[12,     1] loss: 1745.769
[13,     1] loss: 1688.492
[14,     1] loss: 1718.955
[15,     1] loss: 1638.576
[16,     1] loss: 1698.229
[17,     1] loss: 1643.786
[18,     1] loss: 1634.864
[19,     1] loss: 1625.680
[20,     1] loss: 1633.835
[21,     1] loss: 1494.270
[22,     1] loss: 1489.996
[23,     1] loss: 1510.236
[24,     1] loss: 1410.439
[25,     1] loss: 1433.664
[26,     1] loss: 1502.813
[27,     1] loss: 1342.816
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025271478025803732,
 'learning_rate_Hydroxylation-K': 0.004713180002484956,
 'learning_rate_Hydroxylation-P': 0.003144773460330001,
 'log_base': 2.40794865179982,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 300044426,
 'sample_weights': [4.4188668808250045, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.2925928463513232,
 'weight_decay_Hydroxylation-K': 6.7378765239834495,
 'weight_decay_Hydroxylation-P': 4.071588308784258}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1310.926
[2,     1] loss: 1309.876
[3,     1] loss: 1310.811
[4,     1] loss: 1304.340
[5,     1] loss: 1304.019
[6,     1] loss: 1290.775
[7,     1] loss: 1268.862
[8,     1] loss: 1228.942
[9,     1] loss: 1195.158
[10,     1] loss: 1137.796
[11,     1] loss: 1112.574
[12,     1] loss: 1109.638
[13,     1] loss: 1099.144
[14,     1] loss: 1091.669
[15,     1] loss: 1076.798
[16,     1] loss: 1068.252
[17,     1] loss: 1070.495
[18,     1] loss: 1062.643
[19,     1] loss: 1041.279
[20,     1] loss: 1053.872
[21,     1] loss: 1022.703
[22,     1] loss: 1014.889
[23,     1] loss: 988.101
[24,     1] loss: 1012.088
[25,     1] loss: 1049.091
[26,     1] loss: 969.962
[27,     1] loss: 1000.759
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0048403048461229435,
 'learning_rate_Hydroxylation-K': 0.0026880169583303644,
 'learning_rate_Hydroxylation-P': 0.0055753028079404444,
 'log_base': 1.758616043286069,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 44375402,
 'sample_weights': [1.8997385694480902, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.9731124471673365,
 'weight_decay_Hydroxylation-K': 1.431439366219349,
 'weight_decay_Hydroxylation-P': 3.4003633981985937}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1539.776
[2,     1] loss: 1530.769
[3,     1] loss: 1534.061
[4,     1] loss: 1537.068
[5,     1] loss: 1527.453
[6,     1] loss: 1524.833
[7,     1] loss: 1523.719
[8,     1] loss: 1519.735
[9,     1] loss: 1493.517
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006344827152422582,
 'learning_rate_Hydroxylation-K': 0.001970403662201232,
 'learning_rate_Hydroxylation-P': 0.006639019470431326,
 'log_base': 2.4563507617882228,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1025625822,
 'sample_weights': [2.957241499963934, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.124396595686908,
 'weight_decay_Hydroxylation-K': 1.4847152403280899,
 'weight_decay_Hydroxylation-P': 8.820217779341014}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1299.978
[2,     1] loss: 1326.952
[3,     1] loss: 1301.518
[4,     1] loss: 1301.173
[5,     1] loss: 1298.656
[6,     1] loss: 1299.893
[7,     1] loss: 1299.714
[8,     1] loss: 1299.718
[9,     1] loss: 1297.928
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009127352201952085,
 'learning_rate_Hydroxylation-K': 0.009857338532277608,
 'learning_rate_Hydroxylation-P': 0.004288909601509648,
 'log_base': 1.3075365696848813,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3362509816,
 'sample_weights': [1.8576679772230376, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2463446491557775,
 'weight_decay_Hydroxylation-K': 5.932940150122242,
 'weight_decay_Hydroxylation-P': 5.809281161440003}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2218.861
[2,     1] loss: 2225.561
[3,     1] loss: 2220.545
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005380910887286647,
 'learning_rate_Hydroxylation-K': 0.001347570786608326,
 'learning_rate_Hydroxylation-P': 0.006280158612074242,
 'log_base': 1.8150864986097774,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1493627158,
 'sample_weights': [6.2258996395396045, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.771358044000758,
 'weight_decay_Hydroxylation-K': 3.953358929843399,
 'weight_decay_Hydroxylation-P': 5.325971649317149}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1497.953
[2,     1] loss: 1501.132
[3,     1] loss: 1501.525
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020977731206239395,
 'learning_rate_Hydroxylation-K': 0.00660362652734905,
 'learning_rate_Hydroxylation-P': 0.005024265106395764,
 'log_base': 2.5228495432005262,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4083946520,
 'sample_weights': [2.8004535893138343, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.078349721935396,
 'weight_decay_Hydroxylation-K': 4.153582233291293,
 'weight_decay_Hydroxylation-P': 1.8099651186844161}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1291.810
[2,     1] loss: 1289.119
[3,     1] loss: 1289.476
[4,     1] loss: 1293.145
[5,     1] loss: 1290.974
[6,     1] loss: 1286.652
[7,     1] loss: 1286.127
[8,     1] loss: 1283.632
[9,     1] loss: 1283.193
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006323659270615338,
 'learning_rate_Hydroxylation-K': 0.004163458463151526,
 'learning_rate_Hydroxylation-P': 0.005703354689737147,
 'log_base': 2.7232210515974105,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3488006801,
 'sample_weights': [1.8040446627924152, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.26720451345067087,
 'weight_decay_Hydroxylation-K': 4.934702257390611,
 'weight_decay_Hydroxylation-P': 0.47057412726323955}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1260.500
[2,     1] loss: 1291.656
[3,     1] loss: 1270.649
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0036115851138997478,
 'learning_rate_Hydroxylation-K': 0.006724608726617578,
 'learning_rate_Hydroxylation-P': 0.0019140363121655057,
 'log_base': 2.913689376671133,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4226723684,
 'sample_weights': [1.6664179492257072, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8167760694971855,
 'weight_decay_Hydroxylation-K': 5.95566437354654,
 'weight_decay_Hydroxylation-P': 1.9242838599066434}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1238.612
[2,     1] loss: 1237.695
[3,     1] loss: 1234.166
[4,     1] loss: 1228.450
[5,     1] loss: 1221.780
[6,     1] loss: 1204.368
[7,     1] loss: 1184.402
[8,     1] loss: 1155.022
[9,     1] loss: 1096.130
[10,     1] loss: 1063.286
[11,     1] loss: 1011.646
[12,     1] loss: 1034.340
[13,     1] loss: 1048.552
[14,     1] loss: 1066.716
[15,     1] loss: 1025.283
[16,     1] loss: 1033.952
[17,     1] loss: 987.242
[18,     1] loss: 993.502
[19,     1] loss: 1002.373
[20,     1] loss: 1008.293
[21,     1] loss: 981.702
[22,     1] loss: 993.027
[23,     1] loss: 985.366
[24,     1] loss: 956.134
[25,     1] loss: 965.483
[26,     1] loss: 926.689
[27,     1] loss: 949.047
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005663834836724509,
 'learning_rate_Hydroxylation-K': 0.0015867678307879606,
 'learning_rate_Hydroxylation-P': 0.007708862495423103,
 'log_base': 1.3949501781817724,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2220678307,
 'sample_weights': [1.5610732763482518, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.850685576684922,
 'weight_decay_Hydroxylation-K': 9.140971019573767,
 'weight_decay_Hydroxylation-P': 0.33831743634617495}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1974.091
[2,     1] loss: 1959.678
[3,     1] loss: 1983.938
[4,     1] loss: 1957.370
[5,     1] loss: 1946.967
[6,     1] loss: 1954.042
[7,     1] loss: 1912.567
[8,     1] loss: 1855.207
[9,     1] loss: 1781.205
[10,     1] loss: 1769.905
[11,     1] loss: 1813.530
[12,     1] loss: 1692.294
[13,     1] loss: 1642.627
[14,     1] loss: 1720.828
[15,     1] loss: 1653.169
[16,     1] loss: 1628.850
[17,     1] loss: 1588.925
[18,     1] loss: 1647.177
[19,     1] loss: 1633.452
[20,     1] loss: 1556.622
[21,     1] loss: 1717.155
[22,     1] loss: 1635.382
[23,     1] loss: 1570.267
[24,     1] loss: 1632.020
[25,     1] loss: 1549.789
[26,     1] loss: 1590.025
[27,     1] loss: 1608.420
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006866069802633569,
 'learning_rate_Hydroxylation-K': 0.0009167978616158683,
 'learning_rate_Hydroxylation-P': 0.008655410174936425,
 'log_base': 1.0914033651283237,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3900206613,
 'sample_weights': [5.015470970324726, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.419313945651458,
 'weight_decay_Hydroxylation-K': 2.3207954971761517,
 'weight_decay_Hydroxylation-P': 5.828373007965653}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 6230.016
[2,     1] loss: 6212.048
[3,     1] loss: 6227.503
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0034371411467746505,
 'learning_rate_Hydroxylation-K': 0.0005965147685227894,
 'learning_rate_Hydroxylation-P': 0.0033397619126986655,
 'log_base': 2.8446081458967583,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1824758632,
 'sample_weights': [19.08712491589013, 2.385982528573588],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.5477994577165504,
 'weight_decay_Hydroxylation-K': 2.2338265122620964,
 'weight_decay_Hydroxylation-P': 0.6767000956262827}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1244.417
[2,     1] loss: 1242.220
[3,     1] loss: 1241.070
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00285400430116971,
 'learning_rate_Hydroxylation-K': 0.004772186261456149,
 'learning_rate_Hydroxylation-P': 0.005512256240747449,
 'log_base': 2.0696045294276293,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2913741184,
 'sample_weights': [1.5969032980559634, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9543595584307183,
 'weight_decay_Hydroxylation-K': 0.7066233339100894,
 'weight_decay_Hydroxylation-P': 1.8769668028176811}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1394.418
[2,     1] loss: 1395.492
[3,     1] loss: 1395.524
[4,     1] loss: 1387.925
[5,     1] loss: 1391.699
[6,     1] loss: 1390.084
[7,     1] loss: 1374.743
[8,     1] loss: 1366.286
[9,     1] loss: 1340.785
[10,     1] loss: 1300.450
[11,     1] loss: 1276.955
[12,     1] loss: 1224.314
[13,     1] loss: 1187.783
[14,     1] loss: 1148.814
[15,     1] loss: 1197.918
[16,     1] loss: 1202.310
[17,     1] loss: 1145.052
[18,     1] loss: 1133.781
[19,     1] loss: 1163.833
[20,     1] loss: 1143.556
[21,     1] loss: 1140.517
[22,     1] loss: 1108.976
[23,     1] loss: 1086.356
[24,     1] loss: 1092.229
[25,     1] loss: 1089.683
[26,     1] loss: 1066.040
[27,     1] loss: 1054.154
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003266118731329719,
 'learning_rate_Hydroxylation-K': 0.00446235685817358,
 'learning_rate_Hydroxylation-P': 0.005367380778211587,
 'log_base': 1.0486111530859008,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1123309328,
 'sample_weights': [2.2952166638912654, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.133345186553375,
 'weight_decay_Hydroxylation-K': 1.048937275944536,
 'weight_decay_Hydroxylation-P': 3.5188858850391456}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 11499.030
[2,     1] loss: 11426.241
[3,     1] loss: 11440.002
[4,     1] loss: 11425.044
[5,     1] loss: 11369.513
[6,     1] loss: 11416.393
[7,     1] loss: 11361.662
[8,     1] loss: 11429.684
[9,     1] loss: 11376.505
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005111828901917718,
 'learning_rate_Hydroxylation-K': 0.0018693481381260215,
 'learning_rate_Hydroxylation-P': 0.008364475153237782,
 'log_base': 2.796044541479722,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4184456116,
 'sample_weights': [35.17091906590905, 4.396534248868104],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.58485332859176,
 'weight_decay_Hydroxylation-K': 4.69034858194118,
 'weight_decay_Hydroxylation-P': 2.108611841519016}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1258.987
[2,     1] loss: 1282.349
[3,     1] loss: 1255.464
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009561769404048287,
 'learning_rate_Hydroxylation-K': 0.009774534930046257,
 'learning_rate_Hydroxylation-P': 0.005932965860535959,
 'log_base': 2.246918130287764,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2909807750,
 'sample_weights': [1.6236469596042762, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.328652986542807,
 'weight_decay_Hydroxylation-K': 3.293546814480709,
 'weight_decay_Hydroxylation-P': 3.0239382610455405}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1354.147
[2,     1] loss: 1416.037
[3,     1] loss: 1339.450
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00345685831761717,
 'learning_rate_Hydroxylation-K': 0.006092980115475093,
 'learning_rate_Hydroxylation-P': 0.001989262590187514,
 'log_base': 1.5839369967109325,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 109682810,
 'sample_weights': [2.0621622363931404, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.319537922899064,
 'weight_decay_Hydroxylation-K': 6.725785610326702,
 'weight_decay_Hydroxylation-P': 6.799501766040642}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1674.070
[2,     1] loss: 1678.884
[3,     1] loss: 1672.694
[4,     1] loss: 1671.137
[5,     1] loss: 1667.044
[6,     1] loss: 1665.021
[7,     1] loss: 1658.823
[8,     1] loss: 1642.046
[9,     1] loss: 1596.000
[10,     1] loss: 1568.656
[11,     1] loss: 1525.431
[12,     1] loss: 1466.101
[13,     1] loss: 1419.197
[14,     1] loss: 1559.702
[15,     1] loss: 1456.357
[16,     1] loss: 1481.617
[17,     1] loss: 1343.318
[18,     1] loss: 1403.428
[19,     1] loss: 1368.984
[20,     1] loss: 1382.036
[21,     1] loss: 1403.039
[22,     1] loss: 1387.325
[23,     1] loss: 1355.439
[24,     1] loss: 1340.196
[25,     1] loss: 1333.421
[26,     1] loss: 1311.311
[27,     1] loss: 1268.656
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0034454384127556767,
 'learning_rate_Hydroxylation-K': 0.0042799148380138026,
 'learning_rate_Hydroxylation-P': 0.008516769463078971,
 'log_base': 2.2061812392971345,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 130185537,
 'sample_weights': [3.629906673364534, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.803778726840884,
 'weight_decay_Hydroxylation-K': 1.628853594520078,
 'weight_decay_Hydroxylation-P': 7.750647793843868}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1353.859
[2,     1] loss: 1358.922
[3,     1] loss: 1351.716
[4,     1] loss: 1353.283
[5,     1] loss: 1353.445
[6,     1] loss: 1348.760
[7,     1] loss: 1339.004
[8,     1] loss: 1326.817
[9,     1] loss: 1309.948
[10,     1] loss: 1278.024
[11,     1] loss: 1246.750
[12,     1] loss: 1243.615
[13,     1] loss: 1199.922
[14,     1] loss: 1168.630
[15,     1] loss: 1112.426
[16,     1] loss: 1140.392
[17,     1] loss: 1177.903
[18,     1] loss: 1129.012
[19,     1] loss: 1115.388
[20,     1] loss: 1096.816
[21,     1] loss: 1100.819
[22,     1] loss: 1090.583
[23,     1] loss: 1123.083
[24,     1] loss: 1049.495
[25,     1] loss: 1074.297
[26,     1] loss: 1033.842
[27,     1] loss: 1009.227
[28,     1] loss: 1034.577
[29,     1] loss: 1001.058
[30,     1] loss: 1040.628
[31,     1] loss: 947.012
[32,     1] loss: 999.340
[33,     1] loss: 1031.054
[34,     1] loss: 1004.031
[35,     1] loss: 960.138
[36,     1] loss: 946.835
[37,     1] loss: 977.900
[38,     1] loss: 948.542
[39,     1] loss: 925.071
[40,     1] loss: 935.503
[41,     1] loss: 957.962
[42,     1] loss: 927.360
[43,     1] loss: 837.584
[44,     1] loss: 891.455
[45,     1] loss: 897.000
[46,     1] loss: 844.523
[47,     1] loss: 1056.920
[48,     1] loss: 1194.294
[49,     1] loss: 839.403
[50,     1] loss: 973.559
[51,     1] loss: 934.002
[52,     1] loss: 939.786
[53,     1] loss: 956.280
[54,     1] loss: 977.802
[55,     1] loss: 866.805
[56,     1] loss: 879.087
[57,     1] loss: 908.432
[58,     1] loss: 829.281
[59,     1] loss: 858.258
[60,     1] loss: 877.936
[61,     1] loss: 832.214
[62,     1] loss: 755.438
[63,     1] loss: 822.360
[64,     1] loss: 759.464
[65,     1] loss: 756.927
[66,     1] loss: 761.951
[67,     1] loss: 840.443
[68,     1] loss: 719.792
[69,     1] loss: 939.834
[70,     1] loss: 739.598
[71,     1] loss: 880.922
[72,     1] loss: 826.074
[73,     1] loss: 808.938
[74,     1] loss: 785.351
[75,     1] loss: 812.793
Early stopping applied (best metric=0.8535711765289307)
Finished Training
Total time taken: 11.32901120185852
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1354.226
[2,     1] loss: 1353.323
[3,     1] loss: 1352.206
[4,     1] loss: 1350.806
[5,     1] loss: 1347.427
[6,     1] loss: 1329.827
[7,     1] loss: 1292.926
[8,     1] loss: 1250.902
[9,     1] loss: 1212.264
[10,     1] loss: 1222.253
[11,     1] loss: 1156.708
[12,     1] loss: 1163.260
[13,     1] loss: 1192.165
[14,     1] loss: 1119.925
[15,     1] loss: 1137.215
[16,     1] loss: 1098.183
[17,     1] loss: 1093.729
[18,     1] loss: 1104.414
[19,     1] loss: 1054.977
[20,     1] loss: 1094.429
[21,     1] loss: 1088.223
[22,     1] loss: 985.955
[23,     1] loss: 1026.985
[24,     1] loss: 1006.735
[25,     1] loss: 1046.554
[26,     1] loss: 1019.733
[27,     1] loss: 961.092
[28,     1] loss: 1004.463
[29,     1] loss: 995.026
[30,     1] loss: 972.389
[31,     1] loss: 916.323
[32,     1] loss: 959.816
[33,     1] loss: 940.477
[34,     1] loss: 882.640
[35,     1] loss: 903.518
[36,     1] loss: 1056.229
[37,     1] loss: 953.262
[38,     1] loss: 935.515
[39,     1] loss: 889.566
[40,     1] loss: 939.190
[41,     1] loss: 852.280
[42,     1] loss: 964.893
[43,     1] loss: 873.378
[44,     1] loss: 984.048
[45,     1] loss: 855.278
[46,     1] loss: 855.185
[47,     1] loss: 803.905
[48,     1] loss: 859.809
[49,     1] loss: 767.340
[50,     1] loss: 861.765
[51,     1] loss: 747.308
[52,     1] loss: 764.931
[53,     1] loss: 777.050
[54,     1] loss: 725.846
[55,     1] loss: 767.807
[56,     1] loss: 732.354
[57,     1] loss: 685.488
[58,     1] loss: 775.413
[59,     1] loss: 886.514
[60,     1] loss: 827.537
[61,     1] loss: 734.907
[62,     1] loss: 811.069
[63,     1] loss: 747.952
[64,     1] loss: 777.285
[65,     1] loss: 728.385
[66,     1] loss: 745.157
[67,     1] loss: 751.562
[68,     1] loss: 676.170
Early stopping applied (best metric=0.9457385540008545)
Finished Training
Total time taken: 9.75700831413269
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1354.509
[2,     1] loss: 1354.536
[3,     1] loss: 1350.230
[4,     1] loss: 1350.146
[5,     1] loss: 1351.772
[6,     1] loss: 1336.876
[7,     1] loss: 1325.866
[8,     1] loss: 1294.065
[9,     1] loss: 1279.871
[10,     1] loss: 1222.948
[11,     1] loss: 1194.815
[12,     1] loss: 1168.907
[13,     1] loss: 1200.514
[14,     1] loss: 1114.837
[15,     1] loss: 1151.493
[16,     1] loss: 1119.734
[17,     1] loss: 1125.901
[18,     1] loss: 1181.546
[19,     1] loss: 1117.134
[20,     1] loss: 1136.655
[21,     1] loss: 1112.071
[22,     1] loss: 1103.470
[23,     1] loss: 1073.710
[24,     1] loss: 1079.587
[25,     1] loss: 1074.006
[26,     1] loss: 1061.807
[27,     1] loss: 1088.963
[28,     1] loss: 1051.074
[29,     1] loss: 1023.279
[30,     1] loss: 1027.498
[31,     1] loss: 1031.474
[32,     1] loss: 985.830
[33,     1] loss: 1019.697
[34,     1] loss: 1031.330
[35,     1] loss: 990.874
[36,     1] loss: 990.453
[37,     1] loss: 966.325
[38,     1] loss: 950.434
[39,     1] loss: 920.055
[40,     1] loss: 919.337
[41,     1] loss: 888.792
[42,     1] loss: 840.642
[43,     1] loss: 839.893
[44,     1] loss: 943.892
[45,     1] loss: 942.295
[46,     1] loss: 817.433
[47,     1] loss: 974.801
[48,     1] loss: 820.362
[49,     1] loss: 969.501
[50,     1] loss: 843.346
[51,     1] loss: 952.694
[52,     1] loss: 876.883
[53,     1] loss: 818.838
[54,     1] loss: 806.761
[55,     1] loss: 794.271
[56,     1] loss: 813.019
[57,     1] loss: 850.112
[58,     1] loss: 778.323
[59,     1] loss: 755.780
[60,     1] loss: 738.621
[61,     1] loss: 776.376
[62,     1] loss: 838.128
Early stopping applied (best metric=0.7652780413627625)
Finished Training
Total time taken: 8.530008316040039
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1355.913
[2,     1] loss: 1353.158
[3,     1] loss: 1358.434
[4,     1] loss: 1352.767
[5,     1] loss: 1352.511
[6,     1] loss: 1351.047
[7,     1] loss: 1349.295
[8,     1] loss: 1348.643
[9,     1] loss: 1339.465
[10,     1] loss: 1330.559
[11,     1] loss: 1309.396
[12,     1] loss: 1271.486
[13,     1] loss: 1237.849
[14,     1] loss: 1211.196
[15,     1] loss: 1156.899
[16,     1] loss: 1148.708
[17,     1] loss: 1107.649
[18,     1] loss: 1081.584
[19,     1] loss: 1130.359
[20,     1] loss: 1122.121
[21,     1] loss: 1117.564
[22,     1] loss: 1067.477
[23,     1] loss: 1074.593
[24,     1] loss: 1079.831
[25,     1] loss: 1047.239
[26,     1] loss: 1047.169
[27,     1] loss: 1043.310
[28,     1] loss: 1060.265
[29,     1] loss: 953.304
[30,     1] loss: 977.284
[31,     1] loss: 942.652
[32,     1] loss: 1000.897
[33,     1] loss: 958.140
[34,     1] loss: 927.585
[35,     1] loss: 927.280
[36,     1] loss: 918.164
[37,     1] loss: 941.651
[38,     1] loss: 941.999
[39,     1] loss: 1004.738
[40,     1] loss: 1046.069
[41,     1] loss: 879.019
[42,     1] loss: 984.563
[43,     1] loss: 906.469
[44,     1] loss: 900.512
[45,     1] loss: 884.370
[46,     1] loss: 908.265
[47,     1] loss: 864.080
[48,     1] loss: 874.025
[49,     1] loss: 891.660
[50,     1] loss: 845.525
[51,     1] loss: 843.007
[52,     1] loss: 916.384
[53,     1] loss: 789.596
[54,     1] loss: 886.614
[55,     1] loss: 786.135
[56,     1] loss: 837.854
[57,     1] loss: 729.335
[58,     1] loss: 766.702
[59,     1] loss: 861.072
[60,     1] loss: 771.716
[61,     1] loss: 713.375
[62,     1] loss: 865.756
[63,     1] loss: 825.792
[64,     1] loss: 766.916
[65,     1] loss: 810.916
[66,     1] loss: 670.198
Early stopping applied (best metric=0.8089542388916016)
Finished Training
Total time taken: 10.717010736465454
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1362.829
[2,     1] loss: 1350.754
[3,     1] loss: 1381.493
[4,     1] loss: 1356.525
[5,     1] loss: 1359.380
[6,     1] loss: 1359.015
[7,     1] loss: 1357.442
[8,     1] loss: 1354.191
[9,     1] loss: 1347.911
[10,     1] loss: 1347.691
[11,     1] loss: 1335.609
[12,     1] loss: 1322.848
[13,     1] loss: 1296.237
[14,     1] loss: 1277.611
[15,     1] loss: 1257.449
[16,     1] loss: 1250.964
[17,     1] loss: 1199.326
[18,     1] loss: 1184.847
[19,     1] loss: 1184.979
[20,     1] loss: 1160.845
[21,     1] loss: 1129.982
[22,     1] loss: 1089.201
[23,     1] loss: 1137.271
[24,     1] loss: 1157.411
[25,     1] loss: 1099.432
[26,     1] loss: 1108.461
[27,     1] loss: 1074.395
[28,     1] loss: 1134.116
[29,     1] loss: 1086.971
[30,     1] loss: 1056.902
[31,     1] loss: 1045.276
[32,     1] loss: 1042.015
[33,     1] loss: 1031.297
[34,     1] loss: 977.625
[35,     1] loss: 1017.017
[36,     1] loss: 978.844
[37,     1] loss: 984.826
[38,     1] loss: 918.975
[39,     1] loss: 980.741
[40,     1] loss: 921.709
[41,     1] loss: 970.348
[42,     1] loss: 887.509
[43,     1] loss: 951.061
[44,     1] loss: 1134.092
[45,     1] loss: 1033.754
[46,     1] loss: 995.163
[47,     1] loss: 951.808
[48,     1] loss: 975.719
[49,     1] loss: 941.986
[50,     1] loss: 922.510
[51,     1] loss: 921.763
[52,     1] loss: 981.625
[53,     1] loss: 913.349
[54,     1] loss: 959.991
[55,     1] loss: 858.249
[56,     1] loss: 847.890
[57,     1] loss: 866.139
[58,     1] loss: 857.451
[59,     1] loss: 856.607
[60,     1] loss: 860.874
[61,     1] loss: 792.519
[62,     1] loss: 830.462
[63,     1] loss: 817.330
[64,     1] loss: 797.947
[65,     1] loss: 792.816
[66,     1] loss: 721.329
[67,     1] loss: 741.715
[68,     1] loss: 774.752
[69,     1] loss: 879.688
[70,     1] loss: 942.542
[71,     1] loss: 700.854
Early stopping applied (best metric=0.8311383724212646)
Finished Training
Total time taken: 11.699013471603394
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1353.125
[2,     1] loss: 1364.990
[3,     1] loss: 1351.881
[4,     1] loss: 1354.246
[5,     1] loss: 1351.347
[6,     1] loss: 1349.591
[7,     1] loss: 1356.205
[8,     1] loss: 1344.903
[9,     1] loss: 1338.256
[10,     1] loss: 1317.806
[11,     1] loss: 1286.523
[12,     1] loss: 1246.995
[13,     1] loss: 1250.710
[14,     1] loss: 1194.950
[15,     1] loss: 1165.366
[16,     1] loss: 1167.202
[17,     1] loss: 1161.352
[18,     1] loss: 1144.086
[19,     1] loss: 1133.608
[20,     1] loss: 1093.038
[21,     1] loss: 1109.457
[22,     1] loss: 1125.970
[23,     1] loss: 1060.790
[24,     1] loss: 1107.575
[25,     1] loss: 1099.310
[26,     1] loss: 1063.019
[27,     1] loss: 1120.659
[28,     1] loss: 1039.435
[29,     1] loss: 1042.681
[30,     1] loss: 1030.301
[31,     1] loss: 970.209
[32,     1] loss: 1112.251
[33,     1] loss: 996.573
[34,     1] loss: 1063.152
[35,     1] loss: 957.150
[36,     1] loss: 1051.990
[37,     1] loss: 953.744
[38,     1] loss: 982.109
[39,     1] loss: 945.870
[40,     1] loss: 971.149
[41,     1] loss: 969.637
[42,     1] loss: 955.004
[43,     1] loss: 915.450
[44,     1] loss: 895.258
[45,     1] loss: 872.149
[46,     1] loss: 902.686
[47,     1] loss: 842.638
[48,     1] loss: 857.323
[49,     1] loss: 917.952
[50,     1] loss: 1064.234
[51,     1] loss: 835.320
[52,     1] loss: 982.903
[53,     1] loss: 894.357
[54,     1] loss: 896.935
[55,     1] loss: 917.702
[56,     1] loss: 822.725
[57,     1] loss: 865.443
[58,     1] loss: 812.106
[59,     1] loss: 797.884
[60,     1] loss: 860.699
[61,     1] loss: 813.445
[62,     1] loss: 780.595
[63,     1] loss: 783.619
[64,     1] loss: 788.051
Early stopping applied (best metric=0.7709344029426575)
Finished Training
Total time taken: 10.677011966705322
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1353.782
[2,     1] loss: 1353.582
[3,     1] loss: 1358.759
[4,     1] loss: 1361.535
[5,     1] loss: 1348.928
[6,     1] loss: 1358.742
[7,     1] loss: 1341.870
[8,     1] loss: 1336.806
[9,     1] loss: 1305.752
[10,     1] loss: 1268.247
[11,     1] loss: 1223.206
[12,     1] loss: 1183.042
[13,     1] loss: 1193.193
[14,     1] loss: 1144.028
[15,     1] loss: 1134.743
[16,     1] loss: 1128.016
[17,     1] loss: 1120.218
[18,     1] loss: 1118.685
[19,     1] loss: 1083.735
[20,     1] loss: 1122.069
[21,     1] loss: 1106.218
[22,     1] loss: 1078.609
[23,     1] loss: 1132.364
[24,     1] loss: 1065.836
[25,     1] loss: 1158.011
[26,     1] loss: 1014.811
[27,     1] loss: 1051.490
[28,     1] loss: 973.614
[29,     1] loss: 1047.867
[30,     1] loss: 1068.489
[31,     1] loss: 968.720
[32,     1] loss: 1067.762
[33,     1] loss: 1009.616
[34,     1] loss: 970.917
[35,     1] loss: 968.344
[36,     1] loss: 934.642
[37,     1] loss: 944.948
[38,     1] loss: 932.937
[39,     1] loss: 908.797
[40,     1] loss: 993.000
[41,     1] loss: 887.083
[42,     1] loss: 891.079
[43,     1] loss: 864.563
[44,     1] loss: 859.275
[45,     1] loss: 883.695
[46,     1] loss: 872.307
[47,     1] loss: 820.359
[48,     1] loss: 846.594
[49,     1] loss: 827.441
[50,     1] loss: 811.159
[51,     1] loss: 752.209
[52,     1] loss: 764.822
Early stopping applied (best metric=0.9191111326217651)
Finished Training
Total time taken: 8.724005699157715
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1355.350
[2,     1] loss: 1354.520
[3,     1] loss: 1352.710
[4,     1] loss: 1353.100
[5,     1] loss: 1349.872
[6,     1] loss: 1349.185
[7,     1] loss: 1347.135
[8,     1] loss: 1341.157
[9,     1] loss: 1326.562
[10,     1] loss: 1294.147
[11,     1] loss: 1265.322
[12,     1] loss: 1215.801
[13,     1] loss: 1170.765
[14,     1] loss: 1150.321
[15,     1] loss: 1128.174
[16,     1] loss: 1135.982
[17,     1] loss: 1189.822
[18,     1] loss: 1080.693
[19,     1] loss: 1104.469
[20,     1] loss: 1095.343
[21,     1] loss: 1077.244
[22,     1] loss: 1090.237
[23,     1] loss: 1127.388
[24,     1] loss: 1108.141
[25,     1] loss: 1064.431
[26,     1] loss: 1071.071
[27,     1] loss: 1032.038
[28,     1] loss: 1037.600
[29,     1] loss: 1024.657
[30,     1] loss: 989.029
[31,     1] loss: 983.128
[32,     1] loss: 997.508
[33,     1] loss: 1069.180
[34,     1] loss: 1004.667
[35,     1] loss: 1051.601
[36,     1] loss: 987.569
[37,     1] loss: 1034.133
[38,     1] loss: 962.050
[39,     1] loss: 966.883
[40,     1] loss: 987.575
[41,     1] loss: 966.454
[42,     1] loss: 915.521
[43,     1] loss: 917.609
[44,     1] loss: 902.229
[45,     1] loss: 935.241
[46,     1] loss: 948.572
[47,     1] loss: 932.464
[48,     1] loss: 923.943
[49,     1] loss: 979.538
[50,     1] loss: 854.319
[51,     1] loss: 941.133
[52,     1] loss: 851.309
[53,     1] loss: 911.403
[54,     1] loss: 839.348
[55,     1] loss: 854.655
[56,     1] loss: 822.281
[57,     1] loss: 794.745
[58,     1] loss: 844.528
[59,     1] loss: 835.052
[60,     1] loss: 796.664
[61,     1] loss: 814.514
[62,     1] loss: 801.801
[63,     1] loss: 765.359
[64,     1] loss: 762.230
[65,     1] loss: 740.442
[66,     1] loss: 778.933
[67,     1] loss: 731.166
[68,     1] loss: 707.694
[69,     1] loss: 690.001
[70,     1] loss: 821.731
[71,     1] loss: 980.965
[72,     1] loss: 851.976
[73,     1] loss: 796.186
[74,     1] loss: 792.005
[75,     1] loss: 780.224
[76,     1] loss: 714.694
[77,     1] loss: 780.433
[78,     1] loss: 732.361
[79,     1] loss: 783.589
Early stopping applied (best metric=0.7019259929656982)
Finished Training
Total time taken: 11.575013875961304
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1354.884
[2,     1] loss: 1354.953
[3,     1] loss: 1359.365
[4,     1] loss: 1351.361
[5,     1] loss: 1350.226
[6,     1] loss: 1354.821
[7,     1] loss: 1353.462
[8,     1] loss: 1347.352
[9,     1] loss: 1347.474
[10,     1] loss: 1330.130
[11,     1] loss: 1325.121
[12,     1] loss: 1301.601
[13,     1] loss: 1281.114
[14,     1] loss: 1268.339
[15,     1] loss: 1251.025
[16,     1] loss: 1215.415
[17,     1] loss: 1176.865
[18,     1] loss: 1217.748
[19,     1] loss: 1211.779
[20,     1] loss: 1137.744
[21,     1] loss: 1143.224
[22,     1] loss: 1079.761
[23,     1] loss: 1104.496
[24,     1] loss: 1088.864
[25,     1] loss: 1053.661
[26,     1] loss: 1053.833
[27,     1] loss: 1034.756
[28,     1] loss: 1057.416
[29,     1] loss: 1031.846
[30,     1] loss: 1027.389
[31,     1] loss: 1019.143
[32,     1] loss: 1033.837
[33,     1] loss: 1026.542
[34,     1] loss: 983.925
[35,     1] loss: 972.555
[36,     1] loss: 991.856
[37,     1] loss: 958.995
[38,     1] loss: 974.109
[39,     1] loss: 902.274
[40,     1] loss: 920.561
[41,     1] loss: 882.277
[42,     1] loss: 918.583
[43,     1] loss: 1006.239
Early stopping applied (best metric=0.842004656791687)
Finished Training
Total time taken: 7.248006820678711
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1351.718
[2,     1] loss: 1364.516
[3,     1] loss: 1353.942
[4,     1] loss: 1354.695
[5,     1] loss: 1351.829
[6,     1] loss: 1350.136
[7,     1] loss: 1341.941
[8,     1] loss: 1318.102
[9,     1] loss: 1292.909
[10,     1] loss: 1249.733
[11,     1] loss: 1193.272
[12,     1] loss: 1213.103
[13,     1] loss: 1195.939
[14,     1] loss: 1138.237
[15,     1] loss: 1187.568
[16,     1] loss: 1183.793
[17,     1] loss: 1184.914
[18,     1] loss: 1127.972
[19,     1] loss: 1118.075
[20,     1] loss: 1087.554
[21,     1] loss: 1146.967
[22,     1] loss: 1092.758
[23,     1] loss: 1098.567
[24,     1] loss: 1078.467
[25,     1] loss: 1045.419
[26,     1] loss: 1067.125
[27,     1] loss: 1055.459
[28,     1] loss: 1005.601
[29,     1] loss: 982.312
[30,     1] loss: 977.268
[31,     1] loss: 978.434
[32,     1] loss: 1022.317
[33,     1] loss: 1080.599
[34,     1] loss: 950.667
[35,     1] loss: 1066.106
[36,     1] loss: 974.847
[37,     1] loss: 995.279
[38,     1] loss: 954.921
[39,     1] loss: 996.775
[40,     1] loss: 967.290
[41,     1] loss: 961.139
[42,     1] loss: 921.515
[43,     1] loss: 946.520
[44,     1] loss: 876.948
[45,     1] loss: 902.344
[46,     1] loss: 875.991
[47,     1] loss: 821.650
[48,     1] loss: 897.764
[49,     1] loss: 1022.588
[50,     1] loss: 981.312
[51,     1] loss: 878.500
[52,     1] loss: 930.683
[53,     1] loss: 883.636
[54,     1] loss: 846.523
[55,     1] loss: 922.464
[56,     1] loss: 833.546
[57,     1] loss: 889.712
[58,     1] loss: 799.388
[59,     1] loss: 828.194
[60,     1] loss: 787.541
[61,     1] loss: 782.658
[62,     1] loss: 865.078
[63,     1] loss: 722.685
[64,     1] loss: 826.190
Early stopping applied (best metric=0.7437431812286377)
Finished Training
Total time taken: 9.194008827209473
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1359.430
[2,     1] loss: 1355.409
[3,     1] loss: 1356.080
[4,     1] loss: 1352.080
[5,     1] loss: 1346.149
[6,     1] loss: 1347.339
[7,     1] loss: 1324.465
[8,     1] loss: 1320.617
[9,     1] loss: 1276.054
[10,     1] loss: 1242.642
[11,     1] loss: 1186.925
[12,     1] loss: 1188.104
[13,     1] loss: 1160.042
[14,     1] loss: 1168.724
[15,     1] loss: 1107.348
[16,     1] loss: 1102.192
[17,     1] loss: 1105.814
[18,     1] loss: 1107.452
[19,     1] loss: 1067.027
[20,     1] loss: 1079.004
[21,     1] loss: 1090.806
[22,     1] loss: 1073.714
[23,     1] loss: 1054.267
[24,     1] loss: 1033.061
[25,     1] loss: 1001.951
[26,     1] loss: 1040.019
[27,     1] loss: 956.375
[28,     1] loss: 1043.981
[29,     1] loss: 1012.303
[30,     1] loss: 947.963
[31,     1] loss: 977.998
[32,     1] loss: 947.374
[33,     1] loss: 921.939
[34,     1] loss: 947.641
[35,     1] loss: 901.644
[36,     1] loss: 890.470
[37,     1] loss: 856.469
[38,     1] loss: 920.086
[39,     1] loss: 944.357
[40,     1] loss: 1261.345
[41,     1] loss: 880.124
[42,     1] loss: 1058.679
[43,     1] loss: 1001.478
[44,     1] loss: 962.509
[45,     1] loss: 1038.324
[46,     1] loss: 1005.677
[47,     1] loss: 930.477
[48,     1] loss: 901.519
[49,     1] loss: 953.581
[50,     1] loss: 868.505
[51,     1] loss: 898.562
[52,     1] loss: 862.799
[53,     1] loss: 843.439
[54,     1] loss: 902.718
[55,     1] loss: 814.491
[56,     1] loss: 864.781
Early stopping applied (best metric=0.7551897764205933)
Finished Training
Total time taken: 8.818008422851562
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1356.384
[2,     1] loss: 1367.416
[3,     1] loss: 1355.702
[4,     1] loss: 1353.694
[5,     1] loss: 1351.076
[6,     1] loss: 1350.849
[7,     1] loss: 1356.131
[8,     1] loss: 1350.702
[9,     1] loss: 1343.883
[10,     1] loss: 1336.164
[11,     1] loss: 1315.459
[12,     1] loss: 1300.551
[13,     1] loss: 1262.846
[14,     1] loss: 1232.414
[15,     1] loss: 1208.983
[16,     1] loss: 1180.961
[17,     1] loss: 1183.885
[18,     1] loss: 1186.635
[19,     1] loss: 1174.660
[20,     1] loss: 1096.194
[21,     1] loss: 1152.793
[22,     1] loss: 1123.698
[23,     1] loss: 1145.394
[24,     1] loss: 1158.777
[25,     1] loss: 1091.643
[26,     1] loss: 1082.219
[27,     1] loss: 1079.163
[28,     1] loss: 1096.412
[29,     1] loss: 1045.126
[30,     1] loss: 1013.453
[31,     1] loss: 1075.910
[32,     1] loss: 983.587
[33,     1] loss: 1034.998
[34,     1] loss: 1052.791
[35,     1] loss: 1020.123
[36,     1] loss: 932.855
[37,     1] loss: 977.051
[38,     1] loss: 917.845
[39,     1] loss: 1098.833
[40,     1] loss: 1000.630
[41,     1] loss: 927.426
[42,     1] loss: 969.090
[43,     1] loss: 923.179
[44,     1] loss: 937.511
[45,     1] loss: 903.647
[46,     1] loss: 950.148
[47,     1] loss: 900.019
[48,     1] loss: 889.099
[49,     1] loss: 870.449
[50,     1] loss: 853.778
[51,     1] loss: 880.605
[52,     1] loss: 837.923
[53,     1] loss: 796.673
[54,     1] loss: 819.093
Early stopping applied (best metric=0.8231980800628662)
Finished Training
Total time taken: 8.977008581161499
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1360.982
[2,     1] loss: 1351.301
[3,     1] loss: 1360.358
[4,     1] loss: 1350.282
[5,     1] loss: 1346.885
[6,     1] loss: 1346.241
[7,     1] loss: 1325.109
[8,     1] loss: 1297.340
[9,     1] loss: 1258.638
[10,     1] loss: 1215.294
[11,     1] loss: 1178.103
[12,     1] loss: 1148.271
[13,     1] loss: 1188.764
[14,     1] loss: 1127.626
[15,     1] loss: 1129.888
[16,     1] loss: 1086.109
[17,     1] loss: 1089.890
[18,     1] loss: 1034.865
[19,     1] loss: 1069.687
[20,     1] loss: 1050.972
[21,     1] loss: 1044.543
[22,     1] loss: 1042.608
[23,     1] loss: 988.082
[24,     1] loss: 998.694
[25,     1] loss: 974.211
[26,     1] loss: 1015.838
[27,     1] loss: 985.276
[28,     1] loss: 926.190
[29,     1] loss: 1013.757
[30,     1] loss: 962.510
[31,     1] loss: 918.118
[32,     1] loss: 949.415
[33,     1] loss: 916.111
[34,     1] loss: 890.412
[35,     1] loss: 865.247
[36,     1] loss: 898.524
[37,     1] loss: 907.158
[38,     1] loss: 878.627
[39,     1] loss: 819.741
[40,     1] loss: 823.448
[41,     1] loss: 836.798
[42,     1] loss: 970.945
[43,     1] loss: 896.196
[44,     1] loss: 815.759
[45,     1] loss: 881.154
[46,     1] loss: 836.098
[47,     1] loss: 897.922
[48,     1] loss: 784.279
[49,     1] loss: 855.189
[50,     1] loss: 759.709
[51,     1] loss: 748.161
[52,     1] loss: 818.577
[53,     1] loss: 757.164
[54,     1] loss: 687.171
[55,     1] loss: 691.687
[56,     1] loss: 752.691
[57,     1] loss: 794.900
[58,     1] loss: 741.381
[59,     1] loss: 666.399
[60,     1] loss: 817.982
[61,     1] loss: 722.423
[62,     1] loss: 665.241
[63,     1] loss: 620.975
[64,     1] loss: 621.114
Early stopping applied (best metric=0.8658126592636108)
Finished Training
Total time taken: 9.617008447647095
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1354.203
[2,     1] loss: 1350.417
[3,     1] loss: 1356.480
[4,     1] loss: 1350.420
[5,     1] loss: 1345.167
[6,     1] loss: 1335.652
[7,     1] loss: 1321.979
[8,     1] loss: 1296.132
[9,     1] loss: 1236.292
[10,     1] loss: 1227.055
[11,     1] loss: 1199.730
[12,     1] loss: 1152.774
[13,     1] loss: 1215.290
[14,     1] loss: 1139.711
[15,     1] loss: 1138.428
[16,     1] loss: 1115.018
[17,     1] loss: 1075.521
[18,     1] loss: 1124.159
[19,     1] loss: 1105.164
[20,     1] loss: 1036.061
[21,     1] loss: 1060.756
[22,     1] loss: 1018.735
[23,     1] loss: 993.498
[24,     1] loss: 1026.586
[25,     1] loss: 1068.731
[26,     1] loss: 996.349
[27,     1] loss: 993.073
[28,     1] loss: 969.607
[29,     1] loss: 980.400
[30,     1] loss: 932.587
[31,     1] loss: 1002.826
[32,     1] loss: 912.930
[33,     1] loss: 933.182
[34,     1] loss: 916.104
[35,     1] loss: 920.743
[36,     1] loss: 894.180
[37,     1] loss: 837.613
[38,     1] loss: 831.288
[39,     1] loss: 835.057
[40,     1] loss: 873.357
[41,     1] loss: 908.373
[42,     1] loss: 827.620
[43,     1] loss: 940.115
[44,     1] loss: 823.242
[45,     1] loss: 853.702
[46,     1] loss: 807.082
[47,     1] loss: 778.864
Early stopping applied (best metric=0.8616611957550049)
Finished Training
Total time taken: 6.7060065269470215
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1356.558
[2,     1] loss: 1359.038
[3,     1] loss: 1356.958
[4,     1] loss: 1354.305
[5,     1] loss: 1346.576
[6,     1] loss: 1339.491
[7,     1] loss: 1314.104
[8,     1] loss: 1284.532
[9,     1] loss: 1247.876
[10,     1] loss: 1223.593
[11,     1] loss: 1182.419
[12,     1] loss: 1168.201
[13,     1] loss: 1120.891
[14,     1] loss: 1164.571
[15,     1] loss: 1145.813
[16,     1] loss: 1115.588
[17,     1] loss: 1086.182
[18,     1] loss: 1068.179
[19,     1] loss: 1084.823
[20,     1] loss: 1081.456
[21,     1] loss: 1046.035
[22,     1] loss: 1039.311
[23,     1] loss: 1105.516
[24,     1] loss: 1031.829
[25,     1] loss: 1070.550
[26,     1] loss: 991.456
[27,     1] loss: 1053.716
[28,     1] loss: 1006.566
[29,     1] loss: 1019.845
[30,     1] loss: 980.473
[31,     1] loss: 992.087
[32,     1] loss: 955.884
[33,     1] loss: 925.558
[34,     1] loss: 968.450
[35,     1] loss: 968.984
[36,     1] loss: 949.201
[37,     1] loss: 921.917
[38,     1] loss: 941.271
[39,     1] loss: 859.969
[40,     1] loss: 948.605
[41,     1] loss: 987.121
[42,     1] loss: 1121.855
[43,     1] loss: 877.454
[44,     1] loss: 981.625
[45,     1] loss: 900.643
[46,     1] loss: 946.037
[47,     1] loss: 969.230
[48,     1] loss: 851.389
[49,     1] loss: 928.037
[50,     1] loss: 872.016
[51,     1] loss: 877.810
[52,     1] loss: 802.702
[53,     1] loss: 879.180
[54,     1] loss: 824.002
[55,     1] loss: 802.629
[56,     1] loss: 813.789
[57,     1] loss: 748.685
[58,     1] loss: 734.190
[59,     1] loss: 766.773
[60,     1] loss: 729.527
[61,     1] loss: 725.545
[62,     1] loss: 702.527
[63,     1] loss: 717.038
[64,     1] loss: 972.038
[65,     1] loss: 1977.238
[66,     1] loss: 904.353
[67,     1] loss: 961.677
[68,     1] loss: 1156.959
[69,     1] loss: 1113.851
[70,     1] loss: 1137.944
[71,     1] loss: 1178.057
[72,     1] loss: 1200.195
[73,     1] loss: 1210.349
[74,     1] loss: 1186.101
[75,     1] loss: 1158.596
[76,     1] loss: 1112.281
[77,     1] loss: 1075.422
[78,     1] loss: 1112.940
Early stopping applied (best metric=0.6763260960578918)
Finished Training
Total time taken: 11.394011497497559
{'Hydroxylation-K Validation Accuracy': 0.7703014184397163, 'Hydroxylation-K Validation Sensitivity': 0.6674074074074074, 'Hydroxylation-K Validation Specificity': 0.7964912280701755, 'Hydroxylation-K Validation Precision': 0.45698573757397287, 'Hydroxylation-K AUC ROC': 0.789551656920078, 'Hydroxylation-K AUC PR': 0.5801421058729536, 'Hydroxylation-K MCC': 0.409418104496746, 'Hydroxylation-K F1': 0.5386158198103278, 'Validation Loss (Hydroxylation-K)': 0.44162537654240924, 'Hydroxylation-P Validation Accuracy': 0.8040249902712214, 'Hydroxylation-P Validation Sensitivity': 0.7840211640211641, 'Hydroxylation-P Validation Specificity': 0.8083320863883485, 'Hydroxylation-P Validation Precision': 0.47441065737371513, 'Hydroxylation-P AUC ROC': 0.8525839095010874, 'Hydroxylation-P AUC PR': 0.5876911183764967, 'Hydroxylation-P MCC': 0.4986798187236264, 'Hydroxylation-P F1': 0.5883257630774399, 'Validation Loss (Hydroxylation-P)': 0.3693471312522888, 'Validation Loss (total)': 0.8109725038210551, 'TimeToTrain': 9.664142847061157}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009508299626593835,
 'learning_rate_Hydroxylation-K': 0.0005562842879609345,
 'learning_rate_Hydroxylation-P': 0.004710343192839463,
 'log_base': 1.0591521669614956,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 72427798,
 'sample_weights': [2.1114109715129006, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.5468511807751675,
 'weight_decay_Hydroxylation-K': 2.303742818204749,
 'weight_decay_Hydroxylation-P': 8.009604934834144}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 9430.229
[2,     1] loss: 9470.399
[3,     1] loss: 9409.684
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006153119220508906,
 'learning_rate_Hydroxylation-K': 0.005571836699232664,
 'learning_rate_Hydroxylation-P': 0.0056954787852128395,
 'log_base': 1.70611210985251,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4035480745,
 'sample_weights': [29.049583913483726, 3.631337877513553],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.086798885685216,
 'weight_decay_Hydroxylation-K': 2.0789693679848047,
 'weight_decay_Hydroxylation-P': 7.801728512639182}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1567.864
[2,     1] loss: 1566.965
[3,     1] loss: 1566.621
[4,     1] loss: 1570.656
[5,     1] loss: 1564.305
[6,     1] loss: 1556.490
[7,     1] loss: 1560.763
[8,     1] loss: 1560.306
[9,     1] loss: 1558.865
[10,     1] loss: 1544.764
[11,     1] loss: 1524.598
[12,     1] loss: 1483.913
[13,     1] loss: 1469.595
[14,     1] loss: 1423.564
[15,     1] loss: 1375.406
[16,     1] loss: 1336.559
[17,     1] loss: 1371.304
[18,     1] loss: 1360.634
[19,     1] loss: 1320.594
[20,     1] loss: 1327.916
[21,     1] loss: 1304.456
[22,     1] loss: 1322.875
[23,     1] loss: 1295.690
[24,     1] loss: 1261.545
[25,     1] loss: 1333.264
[26,     1] loss: 1332.317
[27,     1] loss: 1238.048
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025948369392434336,
 'learning_rate_Hydroxylation-K': 0.008929262922089454,
 'learning_rate_Hydroxylation-P': 0.0031135081450375237,
 'log_base': 1.6118197359597215,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1152646084,
 'sample_weights': [3.1250271731055497, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.559458683109935,
 'weight_decay_Hydroxylation-K': 5.94038330788289,
 'weight_decay_Hydroxylation-P': 7.542379988446533}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1644.063
[2,     1] loss: 1661.979
[3,     1] loss: 1640.276
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035391977062227513,
 'learning_rate_Hydroxylation-K': 0.007688646581043496,
 'learning_rate_Hydroxylation-P': 0.0025272102108274057,
 'log_base': 1.9453843906342827,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3287244750,
 'sample_weights': [3.4972134610810697, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.502295863860298,
 'weight_decay_Hydroxylation-K': 8.741667715173751,
 'weight_decay_Hydroxylation-P': 6.219897192367795}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1438.307
[2,     1] loss: 1441.620
[3,     1] loss: 1443.830
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027023971319382867,
 'learning_rate_Hydroxylation-K': 0.004872891788856924,
 'learning_rate_Hydroxylation-P': 0.003523982841395961,
 'log_base': 1.430589596673185,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3948792834,
 'sample_weights': [2.5087070324105163, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.402654511141817,
 'weight_decay_Hydroxylation-K': 6.234784469806046,
 'weight_decay_Hydroxylation-P': 4.852906322148558}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1898.185
[2,     1] loss: 1894.069
[3,     1] loss: 1892.108
[4,     1] loss: 1895.060
[5,     1] loss: 1891.402
[6,     1] loss: 1892.782
[7,     1] loss: 1892.319
[8,     1] loss: 1893.237
[9,     1] loss: 1883.068
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003446500554370795,
 'learning_rate_Hydroxylation-K': 0.005023809097802933,
 'learning_rate_Hydroxylation-P': 0.002540004507268432,
 'log_base': 2.5823150724328614,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2021052372,
 'sample_weights': [4.662120408739531, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.487450231392921,
 'weight_decay_Hydroxylation-K': 4.10623156275239,
 'weight_decay_Hydroxylation-P': 4.199783762403277}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1284.962
[2,     1] loss: 1281.346
[3,     1] loss: 1275.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022093381824324896,
 'learning_rate_Hydroxylation-K': 0.0028550297389031832,
 'learning_rate_Hydroxylation-P': 0.004649122861435146,
 'log_base': 2.666325533006873,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2235575727,
 'sample_weights': [1.7597420002960154, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.936363733138807,
 'weight_decay_Hydroxylation-K': 1.685752344284618,
 'weight_decay_Hydroxylation-P': 2.651846338792289}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1266.128
[2,     1] loss: 1264.742
[3,     1] loss: 1267.297
[4,     1] loss: 1266.917
[5,     1] loss: 1261.586
[6,     1] loss: 1252.172
[7,     1] loss: 1243.173
[8,     1] loss: 1219.412
[9,     1] loss: 1156.756
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018807302056805771,
 'learning_rate_Hydroxylation-K': 0.006334500305809377,
 'learning_rate_Hydroxylation-P': 0.007605280095738733,
 'log_base': 2.848582359781914,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2216170555,
 'sample_weights': [1.7022951982198091, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2486134363438839,
 'weight_decay_Hydroxylation-K': 6.805546961832515,
 'weight_decay_Hydroxylation-P': 9.562274635328325}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1250.171
[2,     1] loss: 1244.277
[3,     1] loss: 1255.042
[4,     1] loss: 1241.125
[5,     1] loss: 1241.753
[6,     1] loss: 1241.643
[7,     1] loss: 1233.948
[8,     1] loss: 1233.349
[9,     1] loss: 1219.724
[10,     1] loss: 1204.251
[11,     1] loss: 1166.830
[12,     1] loss: 1151.855
[13,     1] loss: 1120.803
[14,     1] loss: 1085.115
[15,     1] loss: 1093.235
[16,     1] loss: 1031.352
[17,     1] loss: 1031.451
[18,     1] loss: 1023.304
[19,     1] loss: 989.661
[20,     1] loss: 994.017
[21,     1] loss: 1017.438
[22,     1] loss: 1027.856
[23,     1] loss: 956.999
[24,     1] loss: 1036.244
[25,     1] loss: 981.321
[26,     1] loss: 1011.493
[27,     1] loss: 976.825
[28,     1] loss: 957.392
[29,     1] loss: 958.042
[30,     1] loss: 933.902
[31,     1] loss: 956.644
[32,     1] loss: 933.172
[33,     1] loss: 884.379
[34,     1] loss: 952.832
[35,     1] loss: 889.576
[36,     1] loss: 916.003
[37,     1] loss: 953.289
[38,     1] loss: 887.448
[39,     1] loss: 912.802
[40,     1] loss: 895.824
[41,     1] loss: 916.760
[42,     1] loss: 848.877
[43,     1] loss: 866.502
[44,     1] loss: 853.432
[45,     1] loss: 854.188
[46,     1] loss: 832.349
[47,     1] loss: 807.698
[48,     1] loss: 834.396
[49,     1] loss: 833.232
[50,     1] loss: 812.133
[51,     1] loss: 793.684
[52,     1] loss: 784.239
[53,     1] loss: 790.871
[54,     1] loss: 744.616
[55,     1] loss: 770.192
[56,     1] loss: 740.963
[57,     1] loss: 782.322
[58,     1] loss: 817.464
[59,     1] loss: 717.014
[60,     1] loss: 728.935
[61,     1] loss: 736.779
[62,     1] loss: 718.877
[63,     1] loss: 727.477
[64,     1] loss: 739.999
[65,     1] loss: 683.501
[66,     1] loss: 692.545
Early stopping applied (best metric=0.7699022889137268)
Finished Training
Total time taken: 10.35101056098938
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1248.533
[2,     1] loss: 1245.417
[3,     1] loss: 1248.479
[4,     1] loss: 1247.370
[5,     1] loss: 1243.128
[6,     1] loss: 1236.501
[7,     1] loss: 1237.778
[8,     1] loss: 1223.388
[9,     1] loss: 1207.572
[10,     1] loss: 1175.847
[11,     1] loss: 1157.051
[12,     1] loss: 1127.582
[13,     1] loss: 1096.588
[14,     1] loss: 1063.632
[15,     1] loss: 1011.216
[16,     1] loss: 1037.866
[17,     1] loss: 1033.373
[18,     1] loss: 1046.286
[19,     1] loss: 1014.061
[20,     1] loss: 1038.913
[21,     1] loss: 977.576
[22,     1] loss: 972.019
[23,     1] loss: 985.480
[24,     1] loss: 1001.636
[25,     1] loss: 955.284
[26,     1] loss: 987.039
[27,     1] loss: 957.851
[28,     1] loss: 929.303
[29,     1] loss: 978.976
[30,     1] loss: 959.804
[31,     1] loss: 918.174
[32,     1] loss: 937.678
[33,     1] loss: 886.980
[34,     1] loss: 898.877
[35,     1] loss: 950.415
[36,     1] loss: 893.311
[37,     1] loss: 898.307
[38,     1] loss: 839.448
[39,     1] loss: 879.179
[40,     1] loss: 890.919
[41,     1] loss: 834.851
[42,     1] loss: 839.547
[43,     1] loss: 818.962
[44,     1] loss: 882.093
[45,     1] loss: 794.949
[46,     1] loss: 856.414
[47,     1] loss: 831.284
[48,     1] loss: 738.778
[49,     1] loss: 798.799
[50,     1] loss: 776.058
[51,     1] loss: 770.307
[52,     1] loss: 741.598
[53,     1] loss: 765.930
[54,     1] loss: 766.327
[55,     1] loss: 754.459
[56,     1] loss: 723.049
[57,     1] loss: 664.738
Early stopping applied (best metric=0.8521958589553833)
Finished Training
Total time taken: 8.914008855819702
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1249.871
[2,     1] loss: 1243.802
[3,     1] loss: 1242.694
[4,     1] loss: 1246.747
[5,     1] loss: 1246.489
[6,     1] loss: 1243.037
[7,     1] loss: 1238.028
[8,     1] loss: 1233.036
[9,     1] loss: 1223.974
[10,     1] loss: 1213.941
[11,     1] loss: 1199.287
[12,     1] loss: 1160.774
[13,     1] loss: 1132.304
[14,     1] loss: 1107.563
[15,     1] loss: 1084.625
[16,     1] loss: 1050.374
[17,     1] loss: 1057.283
[18,     1] loss: 1038.751
[19,     1] loss: 1003.585
[20,     1] loss: 1059.982
[21,     1] loss: 1024.716
[22,     1] loss: 1039.147
[23,     1] loss: 982.415
[24,     1] loss: 990.245
[25,     1] loss: 1005.492
[26,     1] loss: 979.779
[27,     1] loss: 986.299
[28,     1] loss: 953.504
[29,     1] loss: 950.991
[30,     1] loss: 976.031
[31,     1] loss: 958.421
[32,     1] loss: 971.771
[33,     1] loss: 975.460
[34,     1] loss: 921.499
[35,     1] loss: 923.000
[36,     1] loss: 900.524
[37,     1] loss: 892.325
[38,     1] loss: 951.517
[39,     1] loss: 915.502
[40,     1] loss: 923.798
[41,     1] loss: 951.235
[42,     1] loss: 890.909
[43,     1] loss: 884.371
[44,     1] loss: 819.372
[45,     1] loss: 884.337
[46,     1] loss: 901.979
[47,     1] loss: 935.095
[48,     1] loss: 861.505
[49,     1] loss: 852.074
[50,     1] loss: 903.861
[51,     1] loss: 832.817
[52,     1] loss: 856.544
[53,     1] loss: 835.776
[54,     1] loss: 847.631
[55,     1] loss: 854.609
[56,     1] loss: 828.031
[57,     1] loss: 803.217
[58,     1] loss: 784.290
[59,     1] loss: 778.630
[60,     1] loss: 736.651
[61,     1] loss: 816.642
[62,     1] loss: 749.225
[63,     1] loss: 763.854
[64,     1] loss: 744.832
[65,     1] loss: 741.072
[66,     1] loss: 746.620
[67,     1] loss: 738.636
[68,     1] loss: 702.507
[69,     1] loss: 737.626
[70,     1] loss: 701.639
[71,     1] loss: 723.125
[72,     1] loss: 748.632
[73,     1] loss: 723.550
[74,     1] loss: 680.323
[75,     1] loss: 683.815
[76,     1] loss: 648.861
[77,     1] loss: 698.134
[78,     1] loss: 722.727
Early stopping applied (best metric=0.7384251356124878)
Finished Training
Total time taken: 11.425012111663818
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.197
[2,     1] loss: 1243.808
[3,     1] loss: 1244.952
[4,     1] loss: 1244.032
[5,     1] loss: 1243.460
[6,     1] loss: 1246.858
[7,     1] loss: 1241.309
[8,     1] loss: 1241.522
[9,     1] loss: 1233.003
[10,     1] loss: 1223.838
[11,     1] loss: 1208.425
[12,     1] loss: 1197.625
[13,     1] loss: 1165.948
[14,     1] loss: 1121.893
[15,     1] loss: 1128.576
[16,     1] loss: 1090.011
[17,     1] loss: 1115.221
[18,     1] loss: 1090.930
[19,     1] loss: 1072.530
[20,     1] loss: 1022.220
[21,     1] loss: 1085.950
[22,     1] loss: 1021.255
[23,     1] loss: 1047.013
[24,     1] loss: 984.005
[25,     1] loss: 1035.557
[26,     1] loss: 1017.264
[27,     1] loss: 1025.512
[28,     1] loss: 999.297
[29,     1] loss: 1015.177
[30,     1] loss: 992.324
[31,     1] loss: 965.620
[32,     1] loss: 963.911
[33,     1] loss: 994.824
[34,     1] loss: 932.679
[35,     1] loss: 971.858
[36,     1] loss: 965.130
[37,     1] loss: 960.418
[38,     1] loss: 940.757
[39,     1] loss: 918.612
[40,     1] loss: 947.588
[41,     1] loss: 872.960
[42,     1] loss: 903.093
[43,     1] loss: 925.115
[44,     1] loss: 870.663
[45,     1] loss: 811.763
[46,     1] loss: 864.199
[47,     1] loss: 827.833
[48,     1] loss: 869.443
[49,     1] loss: 848.715
[50,     1] loss: 840.478
[51,     1] loss: 806.317
[52,     1] loss: 858.417
[53,     1] loss: 819.290
[54,     1] loss: 830.285
[55,     1] loss: 801.817
[56,     1] loss: 801.508
[57,     1] loss: 779.704
[58,     1] loss: 791.390
[59,     1] loss: 779.889
[60,     1] loss: 714.930
[61,     1] loss: 716.682
Early stopping applied (best metric=0.7107670307159424)
Finished Training
Total time taken: 8.936008214950562
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1247.863
[2,     1] loss: 1246.493
[3,     1] loss: 1247.172
[4,     1] loss: 1243.276
[5,     1] loss: 1235.308
[6,     1] loss: 1228.820
[7,     1] loss: 1213.243
[8,     1] loss: 1183.319
[9,     1] loss: 1138.106
[10,     1] loss: 1124.137
[11,     1] loss: 1091.411
[12,     1] loss: 1061.415
[13,     1] loss: 1068.893
[14,     1] loss: 1073.293
[15,     1] loss: 1039.954
[16,     1] loss: 1023.949
[17,     1] loss: 1019.987
[18,     1] loss: 1005.342
[19,     1] loss: 1034.321
[20,     1] loss: 1040.623
[21,     1] loss: 1048.247
[22,     1] loss: 996.740
[23,     1] loss: 1023.247
[24,     1] loss: 965.225
[25,     1] loss: 979.411
[26,     1] loss: 1007.542
[27,     1] loss: 947.927
[28,     1] loss: 961.069
[29,     1] loss: 936.849
[30,     1] loss: 975.623
[31,     1] loss: 938.586
[32,     1] loss: 928.026
[33,     1] loss: 962.943
[34,     1] loss: 936.693
[35,     1] loss: 929.500
[36,     1] loss: 890.362
[37,     1] loss: 906.883
[38,     1] loss: 874.248
[39,     1] loss: 867.961
[40,     1] loss: 872.509
[41,     1] loss: 887.679
[42,     1] loss: 841.944
[43,     1] loss: 842.065
[44,     1] loss: 823.210
[45,     1] loss: 823.251
[46,     1] loss: 854.941
[47,     1] loss: 801.888
[48,     1] loss: 861.594
[49,     1] loss: 803.555
[50,     1] loss: 766.913
[51,     1] loss: 778.344
Early stopping applied (best metric=0.8364702463150024)
Finished Training
Total time taken: 8.23100757598877
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1253.485
[2,     1] loss: 1246.720
[3,     1] loss: 1248.636
[4,     1] loss: 1244.800
[5,     1] loss: 1246.116
[6,     1] loss: 1243.660
[7,     1] loss: 1246.927
[8,     1] loss: 1247.166
[9,     1] loss: 1245.082
[10,     1] loss: 1242.435
[11,     1] loss: 1242.211
[12,     1] loss: 1238.637
[13,     1] loss: 1235.043
[14,     1] loss: 1233.033
[15,     1] loss: 1225.577
[16,     1] loss: 1214.124
[17,     1] loss: 1196.027
[18,     1] loss: 1173.516
[19,     1] loss: 1151.164
[20,     1] loss: 1140.572
[21,     1] loss: 1109.502
[22,     1] loss: 1069.389
[23,     1] loss: 1071.395
[24,     1] loss: 1085.840
[25,     1] loss: 1056.837
[26,     1] loss: 1038.206
[27,     1] loss: 1043.691
[28,     1] loss: 1064.278
[29,     1] loss: 1057.558
[30,     1] loss: 997.233
[31,     1] loss: 999.839
[32,     1] loss: 1016.983
[33,     1] loss: 1006.659
[34,     1] loss: 1009.445
[35,     1] loss: 945.571
[36,     1] loss: 984.221
[37,     1] loss: 964.843
[38,     1] loss: 955.339
[39,     1] loss: 970.923
[40,     1] loss: 942.054
[41,     1] loss: 995.240
[42,     1] loss: 912.620
[43,     1] loss: 946.008
[44,     1] loss: 891.811
[45,     1] loss: 922.406
[46,     1] loss: 885.360
[47,     1] loss: 886.898
[48,     1] loss: 915.727
[49,     1] loss: 887.333
[50,     1] loss: 877.655
[51,     1] loss: 852.206
[52,     1] loss: 882.011
[53,     1] loss: 846.880
[54,     1] loss: 830.420
[55,     1] loss: 825.675
[56,     1] loss: 812.734
[57,     1] loss: 822.571
[58,     1] loss: 795.926
[59,     1] loss: 803.012
[60,     1] loss: 779.061
[61,     1] loss: 803.536
[62,     1] loss: 790.842
[63,     1] loss: 767.760
[64,     1] loss: 781.413
Early stopping applied (best metric=0.7432581782341003)
Finished Training
Total time taken: 8.821008682250977
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1246.424
[2,     1] loss: 1251.360
[3,     1] loss: 1248.766
[4,     1] loss: 1247.865
[5,     1] loss: 1242.765
[6,     1] loss: 1244.098
[7,     1] loss: 1242.323
[8,     1] loss: 1243.778
[9,     1] loss: 1239.734
[10,     1] loss: 1239.032
[11,     1] loss: 1232.864
[12,     1] loss: 1227.483
[13,     1] loss: 1213.120
[14,     1] loss: 1202.787
[15,     1] loss: 1172.917
[16,     1] loss: 1134.281
[17,     1] loss: 1114.908
[18,     1] loss: 1102.824
[19,     1] loss: 1083.819
[20,     1] loss: 1090.928
[21,     1] loss: 1053.403
[22,     1] loss: 1104.841
[23,     1] loss: 1053.912
[24,     1] loss: 1050.999
[25,     1] loss: 1007.712
[26,     1] loss: 1011.625
[27,     1] loss: 1041.556
[28,     1] loss: 1001.629
[29,     1] loss: 1009.335
[30,     1] loss: 988.246
[31,     1] loss: 981.931
[32,     1] loss: 976.868
[33,     1] loss: 971.862
[34,     1] loss: 981.718
[35,     1] loss: 959.799
[36,     1] loss: 930.512
[37,     1] loss: 953.211
[38,     1] loss: 922.320
[39,     1] loss: 958.276
[40,     1] loss: 911.968
[41,     1] loss: 930.705
[42,     1] loss: 929.021
[43,     1] loss: 903.018
[44,     1] loss: 953.305
[45,     1] loss: 926.148
[46,     1] loss: 905.374
[47,     1] loss: 913.441
[48,     1] loss: 891.867
[49,     1] loss: 910.136
[50,     1] loss: 840.920
[51,     1] loss: 940.231
[52,     1] loss: 900.325
[53,     1] loss: 823.445
[54,     1] loss: 844.462
[55,     1] loss: 875.839
[56,     1] loss: 802.388
[57,     1] loss: 808.609
[58,     1] loss: 838.087
[59,     1] loss: 787.583
[60,     1] loss: 868.637
[61,     1] loss: 773.621
[62,     1] loss: 805.812
[63,     1] loss: 762.706
[64,     1] loss: 739.478
[65,     1] loss: 809.887
[66,     1] loss: 773.139
[67,     1] loss: 776.760
[68,     1] loss: 700.397
[69,     1] loss: 787.389
[70,     1] loss: 757.310
[71,     1] loss: 731.328
[72,     1] loss: 748.632
[73,     1] loss: 699.979
[74,     1] loss: 765.806
[75,     1] loss: 701.472
[76,     1] loss: 656.807
Early stopping applied (best metric=0.8013091683387756)
Finished Training
Total time taken: 11.85701584815979
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1245.272
[2,     1] loss: 1242.854
[3,     1] loss: 1245.700
[4,     1] loss: 1240.528
[5,     1] loss: 1240.985
[6,     1] loss: 1235.856
[7,     1] loss: 1233.988
[8,     1] loss: 1222.329
[9,     1] loss: 1205.901
[10,     1] loss: 1203.707
[11,     1] loss: 1169.059
[12,     1] loss: 1134.536
[13,     1] loss: 1103.464
[14,     1] loss: 1104.538
[15,     1] loss: 1074.574
[16,     1] loss: 1075.415
[17,     1] loss: 1088.693
[18,     1] loss: 1070.574
[19,     1] loss: 1031.052
[20,     1] loss: 1039.814
[21,     1] loss: 1033.284
[22,     1] loss: 1040.783
[23,     1] loss: 1022.259
[24,     1] loss: 1036.297
[25,     1] loss: 1037.708
[26,     1] loss: 1016.856
[27,     1] loss: 990.006
[28,     1] loss: 1004.153
[29,     1] loss: 1020.486
[30,     1] loss: 938.638
[31,     1] loss: 978.375
[32,     1] loss: 987.698
[33,     1] loss: 973.232
[34,     1] loss: 961.313
[35,     1] loss: 929.773
[36,     1] loss: 961.428
[37,     1] loss: 927.815
[38,     1] loss: 897.558
[39,     1] loss: 876.649
[40,     1] loss: 911.243
[41,     1] loss: 909.483
[42,     1] loss: 908.385
[43,     1] loss: 885.348
[44,     1] loss: 892.101
[45,     1] loss: 877.036
[46,     1] loss: 896.317
[47,     1] loss: 869.770
[48,     1] loss: 918.715
[49,     1] loss: 876.994
[50,     1] loss: 887.474
[51,     1] loss: 796.401
[52,     1] loss: 822.142
[53,     1] loss: 819.129
[54,     1] loss: 822.682
[55,     1] loss: 812.748
[56,     1] loss: 820.857
[57,     1] loss: 817.286
[58,     1] loss: 833.395
[59,     1] loss: 817.446
[60,     1] loss: 819.158
Early stopping applied (best metric=0.7517572641372681)
Finished Training
Total time taken: 8.586009502410889
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.995
[2,     1] loss: 1251.773
[3,     1] loss: 1243.224
[4,     1] loss: 1242.691
[5,     1] loss: 1241.003
[6,     1] loss: 1238.040
[7,     1] loss: 1234.938
[8,     1] loss: 1223.017
[9,     1] loss: 1212.125
[10,     1] loss: 1183.011
[11,     1] loss: 1145.714
[12,     1] loss: 1122.237
[13,     1] loss: 1074.904
[14,     1] loss: 1055.146
[15,     1] loss: 1045.278
[16,     1] loss: 1066.745
[17,     1] loss: 992.405
[18,     1] loss: 980.739
[19,     1] loss: 1018.710
[20,     1] loss: 1016.882
[21,     1] loss: 983.115
[22,     1] loss: 990.222
[23,     1] loss: 980.201
[24,     1] loss: 969.061
[25,     1] loss: 964.151
[26,     1] loss: 1009.095
[27,     1] loss: 919.705
[28,     1] loss: 942.645
[29,     1] loss: 910.872
[30,     1] loss: 970.401
[31,     1] loss: 911.054
[32,     1] loss: 885.058
[33,     1] loss: 955.717
[34,     1] loss: 902.930
[35,     1] loss: 916.424
[36,     1] loss: 910.040
[37,     1] loss: 878.759
[38,     1] loss: 866.680
[39,     1] loss: 894.539
[40,     1] loss: 905.858
[41,     1] loss: 899.599
[42,     1] loss: 859.675
[43,     1] loss: 811.008
[44,     1] loss: 847.799
[45,     1] loss: 780.810
[46,     1] loss: 788.630
[47,     1] loss: 832.771
[48,     1] loss: 849.361
[49,     1] loss: 839.362
[50,     1] loss: 838.170
[51,     1] loss: 820.462
[52,     1] loss: 823.942
[53,     1] loss: 761.247
[54,     1] loss: 806.600
[55,     1] loss: 770.151
[56,     1] loss: 801.893
[57,     1] loss: 748.603
[58,     1] loss: 801.886
[59,     1] loss: 765.195
[60,     1] loss: 715.495
[61,     1] loss: 705.751
[62,     1] loss: 740.376
[63,     1] loss: 696.662
[64,     1] loss: 689.617
[65,     1] loss: 635.620
[66,     1] loss: 668.515
[67,     1] loss: 630.301
[68,     1] loss: 654.520
[69,     1] loss: 638.817
[70,     1] loss: 606.064
[71,     1] loss: 636.275
Early stopping applied (best metric=0.8848375082015991)
Finished Training
Total time taken: 11.510010719299316
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1251.450
[2,     1] loss: 1244.011
[3,     1] loss: 1245.695
[4,     1] loss: 1247.908
[5,     1] loss: 1240.589
[6,     1] loss: 1243.224
[7,     1] loss: 1241.242
[8,     1] loss: 1247.465
[9,     1] loss: 1235.366
[10,     1] loss: 1235.753
[11,     1] loss: 1229.463
[12,     1] loss: 1212.972
[13,     1] loss: 1193.975
[14,     1] loss: 1166.463
[15,     1] loss: 1156.770
[16,     1] loss: 1135.099
[17,     1] loss: 1088.395
[18,     1] loss: 1070.070
[19,     1] loss: 1080.114
[20,     1] loss: 1030.023
[21,     1] loss: 1068.748
[22,     1] loss: 985.049
[23,     1] loss: 1034.052
[24,     1] loss: 1033.216
[25,     1] loss: 1040.922
[26,     1] loss: 999.404
[27,     1] loss: 999.638
[28,     1] loss: 1009.744
[29,     1] loss: 1044.755
[30,     1] loss: 998.302
[31,     1] loss: 994.471
[32,     1] loss: 969.760
[33,     1] loss: 955.731
[34,     1] loss: 957.105
[35,     1] loss: 912.117
[36,     1] loss: 916.648
[37,     1] loss: 910.644
[38,     1] loss: 957.064
[39,     1] loss: 881.338
[40,     1] loss: 924.328
[41,     1] loss: 878.044
[42,     1] loss: 879.385
[43,     1] loss: 895.850
[44,     1] loss: 907.473
[45,     1] loss: 877.362
[46,     1] loss: 875.238
[47,     1] loss: 871.104
[48,     1] loss: 858.117
[49,     1] loss: 853.774
[50,     1] loss: 803.140
[51,     1] loss: 816.980
[52,     1] loss: 851.380
[53,     1] loss: 893.568
[54,     1] loss: 827.731
[55,     1] loss: 904.098
[56,     1] loss: 795.533
[57,     1] loss: 843.178
[58,     1] loss: 789.010
[59,     1] loss: 775.702
[60,     1] loss: 794.567
[61,     1] loss: 758.845
Early stopping applied (best metric=0.8127903938293457)
Finished Training
Total time taken: 8.781010150909424
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.710
[2,     1] loss: 1244.928
[3,     1] loss: 1242.803
[4,     1] loss: 1247.386
[5,     1] loss: 1231.773
[6,     1] loss: 1226.818
[7,     1] loss: 1206.479
[8,     1] loss: 1174.754
[9,     1] loss: 1141.437
[10,     1] loss: 1126.711
[11,     1] loss: 1075.423
[12,     1] loss: 1070.244
[13,     1] loss: 1047.846
[14,     1] loss: 1028.713
[15,     1] loss: 986.169
[16,     1] loss: 1085.769
[17,     1] loss: 980.426
[18,     1] loss: 990.774
[19,     1] loss: 982.846
[20,     1] loss: 1005.554
[21,     1] loss: 960.414
[22,     1] loss: 963.387
[23,     1] loss: 975.951
[24,     1] loss: 992.339
[25,     1] loss: 970.925
[26,     1] loss: 948.769
[27,     1] loss: 1022.135
[28,     1] loss: 893.844
[29,     1] loss: 938.839
[30,     1] loss: 943.523
[31,     1] loss: 963.677
[32,     1] loss: 924.919
[33,     1] loss: 906.926
[34,     1] loss: 886.421
[35,     1] loss: 915.215
[36,     1] loss: 842.208
[37,     1] loss: 889.339
[38,     1] loss: 849.866
[39,     1] loss: 867.337
[40,     1] loss: 887.914
[41,     1] loss: 850.993
[42,     1] loss: 885.826
[43,     1] loss: 821.201
[44,     1] loss: 867.432
[45,     1] loss: 846.140
[46,     1] loss: 816.235
[47,     1] loss: 798.917
[48,     1] loss: 817.825
[49,     1] loss: 750.266
[50,     1] loss: 847.637
[51,     1] loss: 760.702
[52,     1] loss: 843.361
[53,     1] loss: 681.121
[54,     1] loss: 750.714
Early stopping applied (best metric=0.8428601026535034)
Finished Training
Total time taken: 9.123008489608765
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1246.393
[2,     1] loss: 1244.252
[3,     1] loss: 1243.201
[4,     1] loss: 1238.877
[5,     1] loss: 1251.373
[6,     1] loss: 1241.625
[7,     1] loss: 1233.763
[8,     1] loss: 1229.827
[9,     1] loss: 1199.007
[10,     1] loss: 1193.507
[11,     1] loss: 1171.089
[12,     1] loss: 1130.474
[13,     1] loss: 1120.502
[14,     1] loss: 1083.479
[15,     1] loss: 1077.014
[16,     1] loss: 1021.578
[17,     1] loss: 975.729
[18,     1] loss: 978.494
[19,     1] loss: 1032.987
[20,     1] loss: 1033.747
[21,     1] loss: 1009.357
[22,     1] loss: 989.975
[23,     1] loss: 953.152
[24,     1] loss: 981.287
[25,     1] loss: 985.829
[26,     1] loss: 973.645
[27,     1] loss: 970.199
[28,     1] loss: 941.727
[29,     1] loss: 922.217
[30,     1] loss: 941.266
[31,     1] loss: 901.120
[32,     1] loss: 941.678
[33,     1] loss: 865.973
[34,     1] loss: 953.870
[35,     1] loss: 911.550
[36,     1] loss: 884.144
[37,     1] loss: 888.828
[38,     1] loss: 896.248
[39,     1] loss: 894.510
[40,     1] loss: 887.709
[41,     1] loss: 845.339
[42,     1] loss: 833.577
[43,     1] loss: 852.437
[44,     1] loss: 826.760
[45,     1] loss: 811.729
[46,     1] loss: 795.929
[47,     1] loss: 809.090
[48,     1] loss: 762.124
[49,     1] loss: 813.430
[50,     1] loss: 813.172
Early stopping applied (best metric=0.8849045038223267)
Finished Training
Total time taken: 8.492008209228516
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1246.241
[2,     1] loss: 1245.110
[3,     1] loss: 1242.648
[4,     1] loss: 1247.612
[5,     1] loss: 1240.388
[6,     1] loss: 1237.678
[7,     1] loss: 1225.989
[8,     1] loss: 1214.292
[9,     1] loss: 1180.811
[10,     1] loss: 1157.562
[11,     1] loss: 1112.719
[12,     1] loss: 1087.530
[13,     1] loss: 1067.404
[14,     1] loss: 1022.762
[15,     1] loss: 1035.383
[16,     1] loss: 1053.989
[17,     1] loss: 1011.003
[18,     1] loss: 990.985
[19,     1] loss: 972.880
[20,     1] loss: 1030.185
[21,     1] loss: 981.644
[22,     1] loss: 979.538
[23,     1] loss: 1020.369
[24,     1] loss: 985.377
[25,     1] loss: 1006.210
[26,     1] loss: 963.603
[27,     1] loss: 964.541
[28,     1] loss: 910.042
[29,     1] loss: 969.662
[30,     1] loss: 950.909
[31,     1] loss: 933.128
[32,     1] loss: 920.170
[33,     1] loss: 904.402
[34,     1] loss: 913.083
[35,     1] loss: 928.244
[36,     1] loss: 916.073
[37,     1] loss: 915.187
[38,     1] loss: 866.148
[39,     1] loss: 869.383
[40,     1] loss: 868.732
[41,     1] loss: 840.653
[42,     1] loss: 844.557
[43,     1] loss: 841.869
[44,     1] loss: 830.207
[45,     1] loss: 822.600
Early stopping applied (best metric=0.9908286333084106)
Finished Training
Total time taken: 7.5660080909729
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1246.653
[2,     1] loss: 1243.984
[3,     1] loss: 1241.807
[4,     1] loss: 1245.667
[5,     1] loss: 1239.552
[6,     1] loss: 1233.651
[7,     1] loss: 1223.604
[8,     1] loss: 1204.246
[9,     1] loss: 1192.177
[10,     1] loss: 1152.219
[11,     1] loss: 1119.442
[12,     1] loss: 1079.035
[13,     1] loss: 1069.508
[14,     1] loss: 1057.019
[15,     1] loss: 1038.603
[16,     1] loss: 1022.241
[17,     1] loss: 1002.735
[18,     1] loss: 1083.139
[19,     1] loss: 1002.305
[20,     1] loss: 1013.639
[21,     1] loss: 1000.622
[22,     1] loss: 1017.037
[23,     1] loss: 1019.697
[24,     1] loss: 1011.578
[25,     1] loss: 996.193
[26,     1] loss: 970.479
[27,     1] loss: 1026.451
[28,     1] loss: 971.903
[29,     1] loss: 935.192
[30,     1] loss: 943.164
[31,     1] loss: 972.911
[32,     1] loss: 942.217
[33,     1] loss: 956.006
[34,     1] loss: 926.680
[35,     1] loss: 919.385
[36,     1] loss: 909.961
[37,     1] loss: 953.895
[38,     1] loss: 874.782
[39,     1] loss: 898.653
[40,     1] loss: 888.019
[41,     1] loss: 832.622
[42,     1] loss: 902.927
[43,     1] loss: 903.319
[44,     1] loss: 880.902
[45,     1] loss: 902.704
[46,     1] loss: 896.697
[47,     1] loss: 838.264
[48,     1] loss: 903.065
[49,     1] loss: 826.489
[50,     1] loss: 838.950
[51,     1] loss: 833.540
[52,     1] loss: 792.289
[53,     1] loss: 874.425
[54,     1] loss: 857.354
[55,     1] loss: 779.588
[56,     1] loss: 796.223
[57,     1] loss: 783.226
[58,     1] loss: 834.434
[59,     1] loss: 793.801
[60,     1] loss: 806.338
[61,     1] loss: 767.490
[62,     1] loss: 803.435
[63,     1] loss: 756.928
[64,     1] loss: 757.685
[65,     1] loss: 747.915
[66,     1] loss: 705.639
[67,     1] loss: 749.893
[68,     1] loss: 767.657
[69,     1] loss: 725.798
[70,     1] loss: 715.332
[71,     1] loss: 692.592
[72,     1] loss: 686.002
[73,     1] loss: 674.703
[74,     1] loss: 678.846
[75,     1] loss: 647.256
[76,     1] loss: 660.172
[77,     1] loss: 674.144
[78,     1] loss: 685.056
[79,     1] loss: 618.755
[80,     1] loss: 620.688
[81,     1] loss: 658.046
[82,     1] loss: 672.627
[83,     1] loss: 638.229
[84,     1] loss: 638.297
[85,     1] loss: 590.971
[86,     1] loss: 691.275
[87,     1] loss: 609.348
[88,     1] loss: 641.240
[89,     1] loss: 557.634
[90,     1] loss: 651.760
[91,     1] loss: 583.042
[92,     1] loss: 636.520
[93,     1] loss: 539.050
[94,     1] loss: 595.617
[95,     1] loss: 583.489
[96,     1] loss: 552.177
[97,     1] loss: 583.854
[98,     1] loss: 570.257
[99,     1] loss: 541.341
[100,     1] loss: 496.798
[101,     1] loss: 520.311
[102,     1] loss: 571.742
[103,     1] loss: 565.832
[104,     1] loss: 562.698
[105,     1] loss: 512.038
[106,     1] loss: 536.623
Early stopping applied (best metric=0.697248101234436)
Finished Training
Total time taken: 17.650017023086548
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1251.601
[2,     1] loss: 1244.671
[3,     1] loss: 1249.723
[4,     1] loss: 1249.123
[5,     1] loss: 1244.658
[6,     1] loss: 1244.492
[7,     1] loss: 1243.496
[8,     1] loss: 1239.116
[9,     1] loss: 1230.639
[10,     1] loss: 1222.755
[11,     1] loss: 1201.325
[12,     1] loss: 1167.032
[13,     1] loss: 1138.385
[14,     1] loss: 1096.984
[15,     1] loss: 1075.328
[16,     1] loss: 1049.153
[17,     1] loss: 1084.298
[18,     1] loss: 1065.784
[19,     1] loss: 1001.774
[20,     1] loss: 984.542
[21,     1] loss: 989.885
[22,     1] loss: 942.822
[23,     1] loss: 990.602
[24,     1] loss: 990.052
[25,     1] loss: 986.625
[26,     1] loss: 974.847
[27,     1] loss: 980.622
[28,     1] loss: 959.853
[29,     1] loss: 922.953
[30,     1] loss: 956.940
[31,     1] loss: 903.984
[32,     1] loss: 904.068
[33,     1] loss: 871.106
[34,     1] loss: 905.070
[35,     1] loss: 889.966
[36,     1] loss: 892.254
[37,     1] loss: 894.059
[38,     1] loss: 849.124
[39,     1] loss: 844.418
[40,     1] loss: 874.926
[41,     1] loss: 826.549
[42,     1] loss: 858.833
[43,     1] loss: 799.298
[44,     1] loss: 826.190
[45,     1] loss: 808.545
[46,     1] loss: 818.243
[47,     1] loss: 817.072
[48,     1] loss: 783.269
[49,     1] loss: 787.988
[50,     1] loss: 796.341
[51,     1] loss: 767.107
[52,     1] loss: 750.766
[53,     1] loss: 777.600
[54,     1] loss: 762.068
Early stopping applied (best metric=0.8214519023895264)
Finished Training
Total time taken: 8.00000786781311
{'Hydroxylation-K Validation Accuracy': 0.7704787234042553, 'Hydroxylation-K Validation Sensitivity': 0.6592592592592592, 'Hydroxylation-K Validation Specificity': 0.7982456140350878, 'Hydroxylation-K Validation Precision': 0.4576525054466231, 'Hydroxylation-K AUC ROC': 0.808654970760234, 'Hydroxylation-K AUC PR': 0.5995961893114699, 'Hydroxylation-K MCC': 0.40587831187932766, 'Hydroxylation-K F1': 0.5381437939408954, 'Validation Loss (Hydroxylation-K)': 0.4381145894527435, 'Hydroxylation-P Validation Accuracy': 0.7942388711232933, 'Hydroxylation-P Validation Sensitivity': 0.7692063492063492, 'Hydroxylation-P Validation Specificity': 0.7997007332036511, 'Hydroxylation-P Validation Precision': 0.4640077617946813, 'Hydroxylation-P AUC ROC': 0.8464882684248987, 'Hydroxylation-P AUC PR': 0.6267208326208872, 'Hydroxylation-P MCC': 0.4800523994359823, 'Hydroxylation-P F1': 0.5728694500546657, 'Validation Loss (Hydroxylation-P)': 0.37115249832471214, 'Validation Loss (total)': 0.8092670877774556, 'TimeToTrain': 9.882876793543497}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0034628355884547338,
 'learning_rate_Hydroxylation-K': 0.007236755560283873,
 'learning_rate_Hydroxylation-P': 0.0029298131384543975,
 'log_base': 1.3733486870611735,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 161406509,
 'sample_weights': [1.5959565339775785, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.207392229367062,
 'weight_decay_Hydroxylation-K': 9.02654508865587,
 'weight_decay_Hydroxylation-P': 8.478243251863027}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2013.534
[2,     1] loss: 2032.385
[3,     1] loss: 2012.139
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004052916626115094,
 'learning_rate_Hydroxylation-K': 0.0057579459704641366,
 'learning_rate_Hydroxylation-P': 0.002540704418007628,
 'log_base': 1.2246651544897715,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 717317113,
 'sample_weights': [5.26219806487386, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.308233693815037,
 'weight_decay_Hydroxylation-K': 4.646429880546982,
 'weight_decay_Hydroxylation-P': 6.498068615686924}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2670.177
[2,     1] loss: 2671.851
[3,     1] loss: 2660.875
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009042249744718346,
 'learning_rate_Hydroxylation-K': 0.0015139467846109205,
 'learning_rate_Hydroxylation-P': 0.003824733809804316,
 'log_base': 2.704176911315448,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 431236219,
 'sample_weights': [8.237351569724296, 1.0297086131981137],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.835847516214535,
 'weight_decay_Hydroxylation-K': 2.679048204038198,
 'weight_decay_Hydroxylation-P': 6.947953028230094}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1260.430
[2,     1] loss: 1272.740
[3,     1] loss: 1271.394
[4,     1] loss: 1259.088
[5,     1] loss: 1262.262
[6,     1] loss: 1259.403
[7,     1] loss: 1252.630
[8,     1] loss: 1252.467
[9,     1] loss: 1230.133
[10,     1] loss: 1218.725
[11,     1] loss: 1174.647
[12,     1] loss: 1134.200
[13,     1] loss: 1157.591
[14,     1] loss: 1080.185
[15,     1] loss: 1086.708
[16,     1] loss: 1081.479
[17,     1] loss: 1047.713
[18,     1] loss: 1046.669
[19,     1] loss: 1030.564
[20,     1] loss: 998.207
[21,     1] loss: 1009.211
[22,     1] loss: 990.352
[23,     1] loss: 961.091
[24,     1] loss: 923.244
[25,     1] loss: 982.814
[26,     1] loss: 1225.909
[27,     1] loss: 1051.050
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006840442605722845,
 'learning_rate_Hydroxylation-K': 0.0032988614898475277,
 'learning_rate_Hydroxylation-P': 0.004613908980225754,
 'log_base': 1.3428818909676472,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 629199802,
 'sample_weights': [1.678173708830851, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.788202673188915,
 'weight_decay_Hydroxylation-K': 4.250077477326645,
 'weight_decay_Hydroxylation-P': 9.505465382541441}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 2103.940
[2,     1] loss: 2119.289
[3,     1] loss: 2096.775
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005119635776241262,
 'learning_rate_Hydroxylation-K': 0.0003448376084349924,
 'learning_rate_Hydroxylation-P': 0.0005757172917301583,
 'log_base': 2.2266064357474007,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1251803000,
 'sample_weights': [5.662623449596141, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.25229053750575847,
 'weight_decay_Hydroxylation-K': 9.366165874874735,
 'weight_decay_Hydroxylation-P': 2.208040392509906}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1357.349
[2,     1] loss: 1349.767
[3,     1] loss: 1347.019
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003258222043300829,
 'learning_rate_Hydroxylation-K': 0.008074714721228862,
 'learning_rate_Hydroxylation-P': 0.004846666549739322,
 'log_base': 2.6540530756982372,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1986600266,
 'sample_weights': [2.085556123369121, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5791621353088967,
 'weight_decay_Hydroxylation-K': 4.8835854444366,
 'weight_decay_Hydroxylation-P': 4.725885146632511}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1268.885
[2,     1] loss: 1265.964
[3,     1] loss: 1269.705
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001272850504569008,
 'learning_rate_Hydroxylation-K': 0.0062728921542787195,
 'learning_rate_Hydroxylation-P': 0.009610844744000492,
 'log_base': 2.886706793243529,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1855176582,
 'sample_weights': [1.7103409325323409, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.317557223045879,
 'weight_decay_Hydroxylation-K': 6.237726946423502,
 'weight_decay_Hydroxylation-P': 9.572930638606504}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1242.373
[2,     1] loss: 1240.666
[3,     1] loss: 1237.234
[4,     1] loss: 1239.629
[5,     1] loss: 1237.494
[6,     1] loss: 1237.867
[7,     1] loss: 1238.983
[8,     1] loss: 1238.432
[9,     1] loss: 1229.086
[10,     1] loss: 1232.391
[11,     1] loss: 1224.573
[12,     1] loss: 1214.241
[13,     1] loss: 1198.061
[14,     1] loss: 1182.054
[15,     1] loss: 1158.190
[16,     1] loss: 1124.613
[17,     1] loss: 1129.695
[18,     1] loss: 1094.618
[19,     1] loss: 1087.013
[20,     1] loss: 1051.356
[21,     1] loss: 1058.731
[22,     1] loss: 1035.086
[23,     1] loss: 1029.774
[24,     1] loss: 1032.396
[25,     1] loss: 997.865
[26,     1] loss: 1062.576
[27,     1] loss: 1000.491
[28,     1] loss: 962.473
[29,     1] loss: 1037.665
[30,     1] loss: 976.910
[31,     1] loss: 1028.468
[32,     1] loss: 991.304
[33,     1] loss: 1017.071
[34,     1] loss: 985.548
[35,     1] loss: 982.837
[36,     1] loss: 990.710
[37,     1] loss: 976.341
[38,     1] loss: 929.752
[39,     1] loss: 966.549
[40,     1] loss: 983.097
[41,     1] loss: 932.521
[42,     1] loss: 980.530
[43,     1] loss: 921.866
[44,     1] loss: 927.353
[45,     1] loss: 970.648
[46,     1] loss: 937.541
[47,     1] loss: 884.295
[48,     1] loss: 914.163
[49,     1] loss: 895.161
[50,     1] loss: 885.709
[51,     1] loss: 889.620
[52,     1] loss: 890.683
[53,     1] loss: 876.463
[54,     1] loss: 852.358
[55,     1] loss: 844.670
[56,     1] loss: 855.794
[57,     1] loss: 842.710
[58,     1] loss: 802.271
[59,     1] loss: 868.218
[60,     1] loss: 828.509
[61,     1] loss: 816.587
[62,     1] loss: 822.587
[63,     1] loss: 836.716
[64,     1] loss: 820.200
[65,     1] loss: 793.465
[66,     1] loss: 797.976
[67,     1] loss: 742.684
[68,     1] loss: 778.736
[69,     1] loss: 712.388
[70,     1] loss: 723.911
[71,     1] loss: 715.650
[72,     1] loss: 722.599
[73,     1] loss: 690.842
[74,     1] loss: 723.573
[75,     1] loss: 692.153
[76,     1] loss: 726.911
Early stopping applied (best metric=0.7024457454681396)
Finished Training
Total time taken: 12.122012376785278
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.301
[2,     1] loss: 1238.248
[3,     1] loss: 1241.046
[4,     1] loss: 1240.162
[5,     1] loss: 1239.157
[6,     1] loss: 1238.193
[7,     1] loss: 1232.876
[8,     1] loss: 1236.255
[9,     1] loss: 1228.437
[10,     1] loss: 1220.697
[11,     1] loss: 1203.399
[12,     1] loss: 1193.337
[13,     1] loss: 1169.858
[14,     1] loss: 1154.370
[15,     1] loss: 1119.635
[16,     1] loss: 1109.865
[17,     1] loss: 1096.035
[18,     1] loss: 1087.116
[19,     1] loss: 1065.490
[20,     1] loss: 1070.343
[21,     1] loss: 1041.337
[22,     1] loss: 1023.750
[23,     1] loss: 1027.525
[24,     1] loss: 1026.579
[25,     1] loss: 1009.977
[26,     1] loss: 973.995
[27,     1] loss: 960.097
[28,     1] loss: 970.016
[29,     1] loss: 945.423
[30,     1] loss: 936.209
[31,     1] loss: 960.203
[32,     1] loss: 1009.508
[33,     1] loss: 925.437
[34,     1] loss: 930.684
[35,     1] loss: 925.106
[36,     1] loss: 985.358
[37,     1] loss: 935.460
[38,     1] loss: 945.256
[39,     1] loss: 876.774
[40,     1] loss: 909.866
[41,     1] loss: 899.307
[42,     1] loss: 900.615
[43,     1] loss: 937.963
[44,     1] loss: 878.936
[45,     1] loss: 873.707
[46,     1] loss: 852.261
[47,     1] loss: 899.254
[48,     1] loss: 856.911
[49,     1] loss: 881.383
[50,     1] loss: 864.351
[51,     1] loss: 866.139
[52,     1] loss: 876.781
[53,     1] loss: 795.821
[54,     1] loss: 791.395
[55,     1] loss: 776.782
[56,     1] loss: 815.590
[57,     1] loss: 811.159
[58,     1] loss: 805.300
[59,     1] loss: 755.634
[60,     1] loss: 834.454
[61,     1] loss: 779.904
[62,     1] loss: 769.973
[63,     1] loss: 760.915
[64,     1] loss: 748.994
[65,     1] loss: 779.737
[66,     1] loss: 746.318
[67,     1] loss: 736.437
[68,     1] loss: 747.242
[69,     1] loss: 741.836
[70,     1] loss: 713.325
[71,     1] loss: 699.625
[72,     1] loss: 700.598
[73,     1] loss: 711.620
[74,     1] loss: 699.882
[75,     1] loss: 701.678
[76,     1] loss: 689.962
[77,     1] loss: 722.757
[78,     1] loss: 681.755
[79,     1] loss: 656.168
[80,     1] loss: 678.190
[81,     1] loss: 664.369
[82,     1] loss: 680.833
[83,     1] loss: 689.314
[84,     1] loss: 633.696
[85,     1] loss: 660.904
[86,     1] loss: 657.353
[87,     1] loss: 600.018
[88,     1] loss: 593.250
[89,     1] loss: 640.439
[90,     1] loss: 612.150
[91,     1] loss: 708.569
[92,     1] loss: 634.893
[93,     1] loss: 639.808
[94,     1] loss: 600.272
[95,     1] loss: 598.339
[96,     1] loss: 586.910
[97,     1] loss: 586.457
[98,     1] loss: 581.506
[99,     1] loss: 559.492
[100,     1] loss: 577.387
[101,     1] loss: 565.410
[102,     1] loss: 569.779
[103,     1] loss: 598.663
Early stopping applied (best metric=0.8281047344207764)
Finished Training
Total time taken: 15.456015348434448
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1244.700
[2,     1] loss: 1238.999
[3,     1] loss: 1240.984
[4,     1] loss: 1241.408
[5,     1] loss: 1235.453
[6,     1] loss: 1246.123
[7,     1] loss: 1241.510
[8,     1] loss: 1234.277
[9,     1] loss: 1230.933
[10,     1] loss: 1236.768
[11,     1] loss: 1221.749
[12,     1] loss: 1219.809
[13,     1] loss: 1204.715
[14,     1] loss: 1187.373
[15,     1] loss: 1169.498
[16,     1] loss: 1143.407
[17,     1] loss: 1111.673
[18,     1] loss: 1103.474
[19,     1] loss: 1092.074
[20,     1] loss: 1096.362
[21,     1] loss: 1071.189
[22,     1] loss: 1063.330
[23,     1] loss: 1001.639
[24,     1] loss: 1023.563
[25,     1] loss: 1048.542
[26,     1] loss: 1024.736
[27,     1] loss: 1036.248
[28,     1] loss: 1002.899
[29,     1] loss: 1031.267
[30,     1] loss: 1035.011
[31,     1] loss: 993.661
[32,     1] loss: 983.262
[33,     1] loss: 979.764
[34,     1] loss: 992.352
[35,     1] loss: 987.484
[36,     1] loss: 1000.254
[37,     1] loss: 971.009
[38,     1] loss: 994.751
[39,     1] loss: 940.810
[40,     1] loss: 929.152
[41,     1] loss: 909.609
[42,     1] loss: 909.825
[43,     1] loss: 943.644
[44,     1] loss: 886.784
[45,     1] loss: 911.692
[46,     1] loss: 905.531
[47,     1] loss: 927.579
[48,     1] loss: 902.591
[49,     1] loss: 897.755
[50,     1] loss: 892.543
[51,     1] loss: 882.265
[52,     1] loss: 846.787
[53,     1] loss: 865.367
[54,     1] loss: 838.997
[55,     1] loss: 832.624
[56,     1] loss: 799.507
[57,     1] loss: 771.661
[58,     1] loss: 813.214
[59,     1] loss: 794.959
[60,     1] loss: 797.973
[61,     1] loss: 885.620
[62,     1] loss: 801.856
[63,     1] loss: 849.964
[64,     1] loss: 734.407
[65,     1] loss: 750.000
[66,     1] loss: 793.836
[67,     1] loss: 762.266
Early stopping applied (best metric=0.8198577761650085)
Finished Training
Total time taken: 9.987009763717651
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1244.027
[2,     1] loss: 1241.113
[3,     1] loss: 1239.076
[4,     1] loss: 1239.605
[5,     1] loss: 1240.017
[6,     1] loss: 1236.793
[7,     1] loss: 1236.559
[8,     1] loss: 1232.010
[9,     1] loss: 1224.481
[10,     1] loss: 1216.740
[11,     1] loss: 1194.561
[12,     1] loss: 1173.080
[13,     1] loss: 1141.137
[14,     1] loss: 1127.242
[15,     1] loss: 1100.521
[16,     1] loss: 1091.558
[17,     1] loss: 1093.556
[18,     1] loss: 1070.767
[19,     1] loss: 1077.376
[20,     1] loss: 1060.587
[21,     1] loss: 1044.112
[22,     1] loss: 1008.000
[23,     1] loss: 1032.599
[24,     1] loss: 1016.262
[25,     1] loss: 991.610
[26,     1] loss: 1048.003
[27,     1] loss: 1064.336
[28,     1] loss: 1005.361
[29,     1] loss: 1019.792
[30,     1] loss: 1036.427
[31,     1] loss: 1058.052
[32,     1] loss: 1047.414
[33,     1] loss: 999.555
[34,     1] loss: 984.630
[35,     1] loss: 992.715
[36,     1] loss: 1003.655
[37,     1] loss: 980.629
[38,     1] loss: 981.269
[39,     1] loss: 940.925
[40,     1] loss: 975.257
[41,     1] loss: 956.555
[42,     1] loss: 902.583
[43,     1] loss: 970.246
[44,     1] loss: 945.943
[45,     1] loss: 950.996
[46,     1] loss: 939.096
[47,     1] loss: 920.785
[48,     1] loss: 913.904
[49,     1] loss: 901.175
[50,     1] loss: 898.385
[51,     1] loss: 955.236
[52,     1] loss: 899.849
[53,     1] loss: 887.509
[54,     1] loss: 885.720
[55,     1] loss: 846.718
[56,     1] loss: 859.362
[57,     1] loss: 868.160
[58,     1] loss: 839.603
[59,     1] loss: 864.429
[60,     1] loss: 824.940
[61,     1] loss: 865.707
[62,     1] loss: 811.501
[63,     1] loss: 853.078
[64,     1] loss: 788.765
[65,     1] loss: 848.715
[66,     1] loss: 818.116
[67,     1] loss: 776.194
[68,     1] loss: 790.396
[69,     1] loss: 860.063
[70,     1] loss: 767.985
[71,     1] loss: 735.989
[72,     1] loss: 712.935
[73,     1] loss: 730.137
[74,     1] loss: 752.604
[75,     1] loss: 809.635
[76,     1] loss: 723.334
[77,     1] loss: 737.145
[78,     1] loss: 729.281
[79,     1] loss: 777.291
[80,     1] loss: 715.647
[81,     1] loss: 703.346
[82,     1] loss: 723.387
[83,     1] loss: 714.726
[84,     1] loss: 694.187
[85,     1] loss: 705.188
[86,     1] loss: 667.303
[87,     1] loss: 670.760
[88,     1] loss: 647.655
[89,     1] loss: 615.483
[90,     1] loss: 624.079
[91,     1] loss: 642.271
[92,     1] loss: 629.434
[93,     1] loss: 631.714
[94,     1] loss: 643.444
[95,     1] loss: 603.540
[96,     1] loss: 613.430
[97,     1] loss: 602.882
[98,     1] loss: 569.977
[99,     1] loss: 632.491
[100,     1] loss: 593.651
[101,     1] loss: 585.054
[102,     1] loss: 607.364
[103,     1] loss: 571.593
[104,     1] loss: 525.482
[105,     1] loss: 549.151
[106,     1] loss: 549.854
[107,     1] loss: 548.430
[108,     1] loss: 543.114
[109,     1] loss: 557.087
[110,     1] loss: 510.691
[111,     1] loss: 517.463
[112,     1] loss: 507.335
Early stopping applied (best metric=0.6814892292022705)
Finished Training
Total time taken: 17.50302004814148
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1243.796
[2,     1] loss: 1242.284
[3,     1] loss: 1240.875
[4,     1] loss: 1242.306
[5,     1] loss: 1240.286
[6,     1] loss: 1239.957
[7,     1] loss: 1237.429
[8,     1] loss: 1239.667
[9,     1] loss: 1235.219
[10,     1] loss: 1224.742
[11,     1] loss: 1223.743
[12,     1] loss: 1208.928
[13,     1] loss: 1196.422
[14,     1] loss: 1175.854
[15,     1] loss: 1158.541
[16,     1] loss: 1123.099
[17,     1] loss: 1108.312
[18,     1] loss: 1094.146
[19,     1] loss: 1065.209
[20,     1] loss: 1048.363
[21,     1] loss: 1011.676
[22,     1] loss: 1037.876
[23,     1] loss: 1001.749
[24,     1] loss: 1065.592
[25,     1] loss: 1037.819
[26,     1] loss: 1017.708
[27,     1] loss: 986.195
[28,     1] loss: 997.481
[29,     1] loss: 1019.788
[30,     1] loss: 967.884
[31,     1] loss: 947.547
[32,     1] loss: 942.831
[33,     1] loss: 995.531
[34,     1] loss: 946.132
[35,     1] loss: 950.757
[36,     1] loss: 970.938
[37,     1] loss: 987.051
[38,     1] loss: 922.871
[39,     1] loss: 917.340
[40,     1] loss: 942.818
[41,     1] loss: 912.893
[42,     1] loss: 951.649
[43,     1] loss: 869.616
[44,     1] loss: 879.259
[45,     1] loss: 879.483
[46,     1] loss: 898.962
[47,     1] loss: 862.659
[48,     1] loss: 920.442
[49,     1] loss: 879.263
[50,     1] loss: 864.173
[51,     1] loss: 829.075
[52,     1] loss: 857.145
[53,     1] loss: 860.624
[54,     1] loss: 816.876
[55,     1] loss: 801.589
[56,     1] loss: 844.760
[57,     1] loss: 822.412
[58,     1] loss: 800.438
[59,     1] loss: 806.705
[60,     1] loss: 768.011
[61,     1] loss: 807.525
[62,     1] loss: 783.501
[63,     1] loss: 778.218
[64,     1] loss: 748.854
[65,     1] loss: 737.358
[66,     1] loss: 726.875
[67,     1] loss: 734.054
[68,     1] loss: 761.770
[69,     1] loss: 773.372
[70,     1] loss: 722.624
[71,     1] loss: 688.376
[72,     1] loss: 679.677
[73,     1] loss: 729.380
[74,     1] loss: 639.496
[75,     1] loss: 675.043
[76,     1] loss: 696.558
[77,     1] loss: 677.107
[78,     1] loss: 654.133
[79,     1] loss: 705.005
[80,     1] loss: 684.470
Early stopping applied (best metric=0.730239748954773)
Finished Training
Total time taken: 12.529011487960815
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.212
[2,     1] loss: 1239.762
[3,     1] loss: 1238.384
[4,     1] loss: 1234.432
[5,     1] loss: 1234.654
[6,     1] loss: 1230.834
[7,     1] loss: 1226.739
[8,     1] loss: 1221.057
[9,     1] loss: 1201.253
[10,     1] loss: 1173.303
[11,     1] loss: 1152.918
[12,     1] loss: 1116.982
[13,     1] loss: 1103.366
[14,     1] loss: 1060.527
[15,     1] loss: 1032.151
[16,     1] loss: 1038.189
[17,     1] loss: 992.372
[18,     1] loss: 1017.148
[19,     1] loss: 1004.704
[20,     1] loss: 990.957
[21,     1] loss: 998.963
[22,     1] loss: 1035.368
[23,     1] loss: 987.814
[24,     1] loss: 1006.467
[25,     1] loss: 963.306
[26,     1] loss: 986.560
[27,     1] loss: 998.143
[28,     1] loss: 972.172
[29,     1] loss: 956.457
[30,     1] loss: 955.297
[31,     1] loss: 962.771
[32,     1] loss: 962.775
[33,     1] loss: 946.386
[34,     1] loss: 961.625
[35,     1] loss: 906.704
[36,     1] loss: 929.251
[37,     1] loss: 918.062
[38,     1] loss: 896.871
[39,     1] loss: 914.866
[40,     1] loss: 920.636
[41,     1] loss: 903.017
[42,     1] loss: 875.323
[43,     1] loss: 890.896
[44,     1] loss: 875.531
[45,     1] loss: 886.063
[46,     1] loss: 882.542
[47,     1] loss: 895.454
[48,     1] loss: 859.914
[49,     1] loss: 854.732
[50,     1] loss: 830.959
[51,     1] loss: 867.626
[52,     1] loss: 870.234
[53,     1] loss: 855.656
[54,     1] loss: 902.248
[55,     1] loss: 825.358
[56,     1] loss: 781.346
[57,     1] loss: 853.116
[58,     1] loss: 772.082
[59,     1] loss: 832.719
[60,     1] loss: 786.141
[61,     1] loss: 780.010
[62,     1] loss: 765.495
[63,     1] loss: 755.074
[64,     1] loss: 767.305
[65,     1] loss: 751.088
[66,     1] loss: 771.375
[67,     1] loss: 751.440
[68,     1] loss: 721.878
[69,     1] loss: 729.193
[70,     1] loss: 730.161
[71,     1] loss: 725.060
[72,     1] loss: 664.075
[73,     1] loss: 673.038
[74,     1] loss: 722.658
[75,     1] loss: 647.314
[76,     1] loss: 681.455
[77,     1] loss: 620.001
[78,     1] loss: 589.078
[79,     1] loss: 624.967
[80,     1] loss: 643.110
[81,     1] loss: 576.252
[82,     1] loss: 652.643
[83,     1] loss: 666.784
[84,     1] loss: 600.452
[85,     1] loss: 618.029
[86,     1] loss: 623.942
[87,     1] loss: 608.824
Early stopping applied (best metric=0.8072291612625122)
Finished Training
Total time taken: 12.419011354446411
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1254.757
[2,     1] loss: 1242.531
[3,     1] loss: 1237.375
[4,     1] loss: 1238.509
[5,     1] loss: 1247.682
[6,     1] loss: 1238.672
[7,     1] loss: 1235.846
[8,     1] loss: 1237.862
[9,     1] loss: 1233.272
[10,     1] loss: 1232.537
[11,     1] loss: 1226.727
[12,     1] loss: 1217.389
[13,     1] loss: 1210.142
[14,     1] loss: 1198.154
[15,     1] loss: 1169.554
[16,     1] loss: 1154.069
[17,     1] loss: 1151.177
[18,     1] loss: 1113.959
[19,     1] loss: 1104.299
[20,     1] loss: 1106.357
[21,     1] loss: 1098.417
[22,     1] loss: 1100.472
[23,     1] loss: 1097.199
[24,     1] loss: 1069.732
[25,     1] loss: 1041.255
[26,     1] loss: 1084.375
[27,     1] loss: 1054.896
[28,     1] loss: 1013.489
[29,     1] loss: 1001.861
[30,     1] loss: 1004.042
[31,     1] loss: 1019.414
[32,     1] loss: 1009.948
[33,     1] loss: 1014.142
[34,     1] loss: 1020.199
[35,     1] loss: 1019.459
[36,     1] loss: 985.710
[37,     1] loss: 956.357
[38,     1] loss: 954.040
[39,     1] loss: 946.952
[40,     1] loss: 977.679
[41,     1] loss: 955.736
[42,     1] loss: 931.496
[43,     1] loss: 962.724
[44,     1] loss: 918.410
[45,     1] loss: 926.466
[46,     1] loss: 923.065
[47,     1] loss: 939.858
[48,     1] loss: 924.224
[49,     1] loss: 872.713
[50,     1] loss: 917.464
[51,     1] loss: 865.248
[52,     1] loss: 858.639
[53,     1] loss: 848.063
[54,     1] loss: 833.916
[55,     1] loss: 814.318
[56,     1] loss: 803.569
[57,     1] loss: 821.564
[58,     1] loss: 809.302
[59,     1] loss: 769.151
[60,     1] loss: 821.094
[61,     1] loss: 815.924
[62,     1] loss: 863.881
[63,     1] loss: 802.631
[64,     1] loss: 815.993
[65,     1] loss: 801.867
[66,     1] loss: 773.090
[67,     1] loss: 777.032
[68,     1] loss: 778.277
[69,     1] loss: 708.646
[70,     1] loss: 753.934
[71,     1] loss: 739.129
[72,     1] loss: 675.590
[73,     1] loss: 726.877
[74,     1] loss: 729.954
[75,     1] loss: 692.292
[76,     1] loss: 761.317
[77,     1] loss: 696.100
[78,     1] loss: 718.245
[79,     1] loss: 687.323
[80,     1] loss: 680.563
[81,     1] loss: 716.281
[82,     1] loss: 636.437
[83,     1] loss: 656.480
[84,     1] loss: 591.864
[85,     1] loss: 659.304
[86,     1] loss: 691.767
[87,     1] loss: 658.647
[88,     1] loss: 610.632
[89,     1] loss: 613.882
[90,     1] loss: 606.370
Early stopping applied (best metric=0.7168785333633423)
Finished Training
Total time taken: 13.677014589309692
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1241.655
[2,     1] loss: 1243.839
[3,     1] loss: 1241.082
[4,     1] loss: 1242.109
[5,     1] loss: 1239.470
[6,     1] loss: 1237.597
[7,     1] loss: 1239.896
[8,     1] loss: 1236.327
[9,     1] loss: 1233.015
[10,     1] loss: 1232.596
[11,     1] loss: 1224.741
[12,     1] loss: 1221.522
[13,     1] loss: 1202.057
[14,     1] loss: 1176.895
[15,     1] loss: 1157.076
[16,     1] loss: 1140.879
[17,     1] loss: 1134.617
[18,     1] loss: 1089.474
[19,     1] loss: 1093.561
[20,     1] loss: 1039.650
[21,     1] loss: 1015.193
[22,     1] loss: 1018.305
[23,     1] loss: 1021.264
[24,     1] loss: 998.104
[25,     1] loss: 1091.167
[26,     1] loss: 1035.643
[27,     1] loss: 1017.864
[28,     1] loss: 1040.473
[29,     1] loss: 1003.172
[30,     1] loss: 1002.725
[31,     1] loss: 1020.369
[32,     1] loss: 976.293
[33,     1] loss: 989.315
[34,     1] loss: 995.895
[35,     1] loss: 983.947
[36,     1] loss: 956.227
[37,     1] loss: 973.077
[38,     1] loss: 946.951
[39,     1] loss: 927.592
[40,     1] loss: 950.646
[41,     1] loss: 910.365
[42,     1] loss: 904.019
[43,     1] loss: 919.223
[44,     1] loss: 937.410
[45,     1] loss: 914.503
[46,     1] loss: 889.805
[47,     1] loss: 866.221
[48,     1] loss: 880.341
[49,     1] loss: 891.667
[50,     1] loss: 885.786
[51,     1] loss: 879.895
[52,     1] loss: 833.529
[53,     1] loss: 838.306
[54,     1] loss: 854.059
[55,     1] loss: 835.180
[56,     1] loss: 859.208
[57,     1] loss: 770.066
[58,     1] loss: 789.317
[59,     1] loss: 819.291
[60,     1] loss: 778.257
[61,     1] loss: 815.808
[62,     1] loss: 768.995
[63,     1] loss: 772.377
[64,     1] loss: 783.095
[65,     1] loss: 684.428
[66,     1] loss: 782.704
[67,     1] loss: 741.070
[68,     1] loss: 788.470
[69,     1] loss: 780.752
[70,     1] loss: 689.548
[71,     1] loss: 689.964
Early stopping applied (best metric=0.8402054309844971)
Finished Training
Total time taken: 10.007010698318481
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.292
[2,     1] loss: 1238.899
[3,     1] loss: 1240.823
[4,     1] loss: 1236.727
[5,     1] loss: 1234.109
[6,     1] loss: 1227.520
[7,     1] loss: 1217.601
[8,     1] loss: 1203.149
[9,     1] loss: 1185.146
[10,     1] loss: 1166.675
[11,     1] loss: 1129.223
[12,     1] loss: 1103.493
[13,     1] loss: 1103.344
[14,     1] loss: 1045.802
[15,     1] loss: 1033.769
[16,     1] loss: 1027.276
[17,     1] loss: 1093.142
[18,     1] loss: 1026.838
[19,     1] loss: 1057.858
[20,     1] loss: 1051.522
[21,     1] loss: 999.425
[22,     1] loss: 1070.346
[23,     1] loss: 1024.790
[24,     1] loss: 1043.469
[25,     1] loss: 1036.509
[26,     1] loss: 1017.315
[27,     1] loss: 1034.712
[28,     1] loss: 984.930
[29,     1] loss: 1007.977
[30,     1] loss: 987.494
[31,     1] loss: 956.986
[32,     1] loss: 989.999
[33,     1] loss: 984.435
[34,     1] loss: 988.915
[35,     1] loss: 933.636
[36,     1] loss: 926.028
[37,     1] loss: 938.267
[38,     1] loss: 902.741
[39,     1] loss: 923.426
[40,     1] loss: 903.503
[41,     1] loss: 904.430
[42,     1] loss: 919.426
[43,     1] loss: 908.699
[44,     1] loss: 907.697
[45,     1] loss: 904.984
[46,     1] loss: 908.115
[47,     1] loss: 947.454
[48,     1] loss: 884.238
[49,     1] loss: 887.301
[50,     1] loss: 919.930
[51,     1] loss: 891.541
[52,     1] loss: 814.228
[53,     1] loss: 850.735
[54,     1] loss: 842.922
[55,     1] loss: 852.989
[56,     1] loss: 804.051
[57,     1] loss: 829.291
[58,     1] loss: 794.302
[59,     1] loss: 836.426
[60,     1] loss: 833.067
[61,     1] loss: 832.216
[62,     1] loss: 771.850
[63,     1] loss: 794.485
[64,     1] loss: 760.061
[65,     1] loss: 808.488
[66,     1] loss: 801.469
[67,     1] loss: 776.239
[68,     1] loss: 716.191
[69,     1] loss: 793.097
[70,     1] loss: 713.295
[71,     1] loss: 751.693
[72,     1] loss: 719.681
[73,     1] loss: 731.886
[74,     1] loss: 664.424
[75,     1] loss: 729.016
[76,     1] loss: 699.049
[77,     1] loss: 697.423
[78,     1] loss: 635.840
[79,     1] loss: 729.895
[80,     1] loss: 621.117
[81,     1] loss: 744.421
[82,     1] loss: 638.903
[83,     1] loss: 633.461
[84,     1] loss: 657.255
[85,     1] loss: 630.475
[86,     1] loss: 658.670
[87,     1] loss: 580.404
[88,     1] loss: 613.033
Early stopping applied (best metric=0.7027269601821899)
Finished Training
Total time taken: 12.88401174545288
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1244.175
[2,     1] loss: 1241.073
[3,     1] loss: 1241.496
[4,     1] loss: 1241.184
[5,     1] loss: 1241.128
[6,     1] loss: 1241.671
[7,     1] loss: 1240.278
[8,     1] loss: 1237.956
[9,     1] loss: 1239.438
[10,     1] loss: 1236.482
[11,     1] loss: 1229.006
[12,     1] loss: 1225.490
[13,     1] loss: 1220.322
[14,     1] loss: 1218.655
[15,     1] loss: 1195.963
[16,     1] loss: 1166.668
[17,     1] loss: 1142.250
[18,     1] loss: 1114.340
[19,     1] loss: 1109.575
[20,     1] loss: 1075.208
[21,     1] loss: 1042.106
[22,     1] loss: 1033.557
[23,     1] loss: 1019.262
[24,     1] loss: 1023.070
[25,     1] loss: 1037.685
[26,     1] loss: 999.831
[27,     1] loss: 1043.273
[28,     1] loss: 997.735
[29,     1] loss: 979.436
[30,     1] loss: 991.645
[31,     1] loss: 980.020
[32,     1] loss: 985.256
[33,     1] loss: 984.870
[34,     1] loss: 992.758
[35,     1] loss: 963.415
[36,     1] loss: 947.259
[37,     1] loss: 941.857
[38,     1] loss: 925.011
[39,     1] loss: 919.492
[40,     1] loss: 939.051
[41,     1] loss: 922.256
[42,     1] loss: 906.706
[43,     1] loss: 892.964
[44,     1] loss: 883.170
[45,     1] loss: 865.127
[46,     1] loss: 945.971
[47,     1] loss: 861.365
[48,     1] loss: 834.353
[49,     1] loss: 868.944
[50,     1] loss: 851.902
[51,     1] loss: 849.864
Early stopping applied (best metric=0.9084101319313049)
Finished Training
Total time taken: 6.978006839752197
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.563
[2,     1] loss: 1239.299
[3,     1] loss: 1241.726
[4,     1] loss: 1237.048
[5,     1] loss: 1236.650
[6,     1] loss: 1231.115
[7,     1] loss: 1227.407
[8,     1] loss: 1216.911
[9,     1] loss: 1202.510
[10,     1] loss: 1179.123
[11,     1] loss: 1157.595
[12,     1] loss: 1118.862
[13,     1] loss: 1086.986
[14,     1] loss: 1064.677
[15,     1] loss: 1063.765
[16,     1] loss: 1013.756
[17,     1] loss: 1011.353
[18,     1] loss: 1071.647
[19,     1] loss: 1044.093
[20,     1] loss: 1037.120
[21,     1] loss: 1029.547
[22,     1] loss: 1016.880
[23,     1] loss: 1004.890
[24,     1] loss: 972.365
[25,     1] loss: 987.555
[26,     1] loss: 998.589
[27,     1] loss: 1023.210
[28,     1] loss: 969.612
[29,     1] loss: 1009.663
[30,     1] loss: 963.855
[31,     1] loss: 952.956
[32,     1] loss: 938.153
[33,     1] loss: 984.508
[34,     1] loss: 939.027
[35,     1] loss: 934.160
[36,     1] loss: 922.219
[37,     1] loss: 899.734
[38,     1] loss: 925.911
[39,     1] loss: 915.280
[40,     1] loss: 922.492
[41,     1] loss: 876.997
[42,     1] loss: 888.214
[43,     1] loss: 828.889
[44,     1] loss: 877.860
[45,     1] loss: 879.540
[46,     1] loss: 880.050
[47,     1] loss: 822.363
[48,     1] loss: 867.268
[49,     1] loss: 842.113
[50,     1] loss: 814.276
[51,     1] loss: 792.249
[52,     1] loss: 869.682
[53,     1] loss: 813.719
[54,     1] loss: 801.372
[55,     1] loss: 844.381
[56,     1] loss: 811.738
[57,     1] loss: 840.235
[58,     1] loss: 816.829
[59,     1] loss: 783.115
[60,     1] loss: 791.319
[61,     1] loss: 752.058
[62,     1] loss: 761.968
Early stopping applied (best metric=0.9091013669967651)
Finished Training
Total time taken: 10.405011653900146
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.046
[2,     1] loss: 1241.019
[3,     1] loss: 1238.358
[4,     1] loss: 1240.367
[5,     1] loss: 1237.568
[6,     1] loss: 1237.077
[7,     1] loss: 1234.141
[8,     1] loss: 1232.939
[9,     1] loss: 1224.509
[10,     1] loss: 1213.753
[11,     1] loss: 1196.318
[12,     1] loss: 1172.486
[13,     1] loss: 1150.619
[14,     1] loss: 1099.412
[15,     1] loss: 1082.409
[16,     1] loss: 1057.134
[17,     1] loss: 1032.545
[18,     1] loss: 1072.111
[19,     1] loss: 1052.077
[20,     1] loss: 1032.347
[21,     1] loss: 1027.697
[22,     1] loss: 1070.150
[23,     1] loss: 1017.540
[24,     1] loss: 1027.429
[25,     1] loss: 1028.772
[26,     1] loss: 991.417
[27,     1] loss: 1006.975
[28,     1] loss: 979.003
[29,     1] loss: 961.974
[30,     1] loss: 983.929
[31,     1] loss: 955.596
[32,     1] loss: 984.960
[33,     1] loss: 965.394
[34,     1] loss: 987.706
[35,     1] loss: 974.208
[36,     1] loss: 956.146
[37,     1] loss: 968.519
[38,     1] loss: 944.835
[39,     1] loss: 928.989
[40,     1] loss: 933.742
[41,     1] loss: 924.604
[42,     1] loss: 878.852
[43,     1] loss: 937.906
[44,     1] loss: 901.889
[45,     1] loss: 923.326
[46,     1] loss: 871.519
[47,     1] loss: 915.174
[48,     1] loss: 870.831
[49,     1] loss: 854.597
[50,     1] loss: 936.951
[51,     1] loss: 860.198
[52,     1] loss: 886.596
[53,     1] loss: 882.782
[54,     1] loss: 862.277
[55,     1] loss: 894.541
[56,     1] loss: 839.726
[57,     1] loss: 856.571
[58,     1] loss: 845.280
[59,     1] loss: 871.877
[60,     1] loss: 806.358
[61,     1] loss: 852.148
Early stopping applied (best metric=0.8528861999511719)
Finished Training
Total time taken: 8.608007669448853
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1245.199
[2,     1] loss: 1238.877
[3,     1] loss: 1238.873
[4,     1] loss: 1241.242
[5,     1] loss: 1238.788
[6,     1] loss: 1234.890
[7,     1] loss: 1233.600
[8,     1] loss: 1236.050
[9,     1] loss: 1224.676
[10,     1] loss: 1216.109
[11,     1] loss: 1195.749
[12,     1] loss: 1179.217
[13,     1] loss: 1153.923
[14,     1] loss: 1120.191
[15,     1] loss: 1085.327
[16,     1] loss: 1072.860
[17,     1] loss: 1041.219
[18,     1] loss: 1008.109
[19,     1] loss: 1052.478
[20,     1] loss: 1026.158
[21,     1] loss: 1014.620
[22,     1] loss: 1043.541
[23,     1] loss: 1059.109
[24,     1] loss: 1033.179
[25,     1] loss: 1024.637
[26,     1] loss: 1001.205
[27,     1] loss: 1017.832
[28,     1] loss: 1020.323
[29,     1] loss: 1002.310
[30,     1] loss: 990.950
[31,     1] loss: 979.201
[32,     1] loss: 990.630
[33,     1] loss: 977.665
[34,     1] loss: 986.529
[35,     1] loss: 943.177
[36,     1] loss: 1009.483
[37,     1] loss: 931.741
[38,     1] loss: 908.128
[39,     1] loss: 916.486
[40,     1] loss: 956.133
[41,     1] loss: 916.963
[42,     1] loss: 933.279
[43,     1] loss: 910.426
[44,     1] loss: 906.098
[45,     1] loss: 902.816
[46,     1] loss: 930.362
[47,     1] loss: 880.007
[48,     1] loss: 866.032
[49,     1] loss: 868.898
[50,     1] loss: 879.488
[51,     1] loss: 935.255
[52,     1] loss: 842.810
[53,     1] loss: 817.949
[54,     1] loss: 847.470
[55,     1] loss: 873.493
[56,     1] loss: 820.670
[57,     1] loss: 794.009
[58,     1] loss: 846.669
[59,     1] loss: 784.527
[60,     1] loss: 814.579
[61,     1] loss: 838.983
[62,     1] loss: 792.387
[63,     1] loss: 811.477
[64,     1] loss: 793.610
[65,     1] loss: 763.458
[66,     1] loss: 764.314
[67,     1] loss: 700.654
[68,     1] loss: 825.058
[69,     1] loss: 718.742
Early stopping applied (best metric=0.8567947745323181)
Finished Training
Total time taken: 9.579009056091309
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1243.410
[2,     1] loss: 1238.589
[3,     1] loss: 1239.836
[4,     1] loss: 1236.769
[5,     1] loss: 1235.510
[6,     1] loss: 1242.676
[7,     1] loss: 1228.270
[8,     1] loss: 1227.070
[9,     1] loss: 1208.746
[10,     1] loss: 1198.040
[11,     1] loss: 1181.937
[12,     1] loss: 1146.725
[13,     1] loss: 1123.941
[14,     1] loss: 1112.882
[15,     1] loss: 1094.599
[16,     1] loss: 1090.779
[17,     1] loss: 1059.182
[18,     1] loss: 1048.346
[19,     1] loss: 1037.203
[20,     1] loss: 1018.940
[21,     1] loss: 1064.036
[22,     1] loss: 1019.014
[23,     1] loss: 1004.490
[24,     1] loss: 1005.038
[25,     1] loss: 1037.977
[26,     1] loss: 1014.683
[27,     1] loss: 1039.768
[28,     1] loss: 1030.089
[29,     1] loss: 1030.898
[30,     1] loss: 998.157
[31,     1] loss: 986.426
[32,     1] loss: 1001.447
[33,     1] loss: 1024.057
[34,     1] loss: 983.119
[35,     1] loss: 1008.417
[36,     1] loss: 968.665
[37,     1] loss: 937.467
[38,     1] loss: 966.338
[39,     1] loss: 953.445
[40,     1] loss: 974.251
[41,     1] loss: 958.638
[42,     1] loss: 927.552
[43,     1] loss: 982.530
[44,     1] loss: 971.639
[45,     1] loss: 912.895
[46,     1] loss: 924.154
[47,     1] loss: 863.355
[48,     1] loss: 958.947
[49,     1] loss: 948.832
[50,     1] loss: 869.796
[51,     1] loss: 902.627
[52,     1] loss: 943.213
[53,     1] loss: 846.003
[54,     1] loss: 886.670
[55,     1] loss: 844.755
[56,     1] loss: 934.114
[57,     1] loss: 876.678
[58,     1] loss: 833.951
[59,     1] loss: 877.532
[60,     1] loss: 850.859
[61,     1] loss: 827.058
[62,     1] loss: 809.729
[63,     1] loss: 832.672
[64,     1] loss: 859.686
[65,     1] loss: 844.660
[66,     1] loss: 835.385
[67,     1] loss: 863.545
[68,     1] loss: 749.352
[69,     1] loss: 818.234
[70,     1] loss: 732.578
[71,     1] loss: 747.249
[72,     1] loss: 827.111
[73,     1] loss: 706.459
[74,     1] loss: 762.684
[75,     1] loss: 801.280
[76,     1] loss: 712.307
[77,     1] loss: 747.542
[78,     1] loss: 738.802
[79,     1] loss: 732.466
[80,     1] loss: 771.351
[81,     1] loss: 673.887
[82,     1] loss: 773.857
[83,     1] loss: 661.424
[84,     1] loss: 678.922
[85,     1] loss: 677.742
[86,     1] loss: 634.382
[87,     1] loss: 711.083
Early stopping applied (best metric=0.6879804134368896)
Finished Training
Total time taken: 14.548012733459473
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1246.860
[2,     1] loss: 1245.436
[3,     1] loss: 1241.204
[4,     1] loss: 1239.872
[5,     1] loss: 1240.178
[6,     1] loss: 1240.356
[7,     1] loss: 1237.752
[8,     1] loss: 1236.552
[9,     1] loss: 1231.569
[10,     1] loss: 1225.880
[11,     1] loss: 1215.170
[12,     1] loss: 1201.083
[13,     1] loss: 1180.781
[14,     1] loss: 1164.645
[15,     1] loss: 1141.281
[16,     1] loss: 1112.142
[17,     1] loss: 1102.112
[18,     1] loss: 1041.587
[19,     1] loss: 1033.291
[20,     1] loss: 1034.395
[21,     1] loss: 1007.124
[22,     1] loss: 1007.142
[23,     1] loss: 990.364
[24,     1] loss: 992.429
[25,     1] loss: 971.376
[26,     1] loss: 978.543
[27,     1] loss: 1011.684
[28,     1] loss: 1006.724
[29,     1] loss: 992.211
[30,     1] loss: 922.263
[31,     1] loss: 967.815
[32,     1] loss: 953.927
[33,     1] loss: 945.123
[34,     1] loss: 934.297
[35,     1] loss: 896.163
[36,     1] loss: 906.686
[37,     1] loss: 882.487
[38,     1] loss: 901.457
[39,     1] loss: 889.784
[40,     1] loss: 922.636
[41,     1] loss: 893.992
[42,     1] loss: 890.917
[43,     1] loss: 905.727
[44,     1] loss: 897.390
[45,     1] loss: 820.293
[46,     1] loss: 883.243
[47,     1] loss: 855.129
[48,     1] loss: 829.470
[49,     1] loss: 870.712
[50,     1] loss: 833.296
[51,     1] loss: 809.959
[52,     1] loss: 798.168
Early stopping applied (best metric=0.942251443862915)
Finished Training
Total time taken: 8.725011348724365
{'Hydroxylation-K Validation Accuracy': 0.7646276595744681, 'Hydroxylation-K Validation Sensitivity': 0.6585185185185185, 'Hydroxylation-K Validation Specificity': 0.7912280701754386, 'Hydroxylation-K Validation Precision': 0.4488464313464313, 'Hydroxylation-K AUC ROC': 0.8203508771929825, 'Hydroxylation-K AUC PR': 0.5696423972843067, 'Hydroxylation-K MCC': 0.3975900144500646, 'Hydroxylation-K F1': 0.5279822526824816, 'Validation Loss (Hydroxylation-K)': 0.4266763647397359, 'Hydroxylation-P Validation Accuracy': 0.7875231544930037, 'Hydroxylation-P Validation Sensitivity': 0.7842328042328043, 'Hydroxylation-P Validation Specificity': 0.7882612599132126, 'Hydroxylation-P Validation Precision': 0.45037133742913504, 'Hydroxylation-P AUC ROC': 0.846913710219486, 'Hydroxylation-P AUC PR': 0.5852423219820053, 'Hydroxylation-P MCC': 0.47525809647212697, 'Hydroxylation-P F1': 0.5694669657686973, 'Validation Loss (Hydroxylation-P)': 0.3724304139614105, 'Validation Loss (total)': 0.799106776714325, 'TimeToTrain': 11.695145114262898}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016042554724304003,
 'learning_rate_Hydroxylation-K': 0.0036814081848863542,
 'learning_rate_Hydroxylation-P': 0.008777779294553256,
 'log_base': 2.181071508506222,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 457808650,
 'sample_weights': [1.5759416993682476, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 7.920900223494783,
 'weight_decay_Hydroxylation-K': 1.3310429775206227,
 'weight_decay_Hydroxylation-P': 6.9773062257570135}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1361.369
[2,     1] loss: 1360.476
[3,     1] loss: 1362.680
[4,     1] loss: 1359.995
[5,     1] loss: 1358.788
[6,     1] loss: 1361.618
[7,     1] loss: 1357.986
[8,     1] loss: 1354.645
[9,     1] loss: 1347.322
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0051080840601473365,
 'learning_rate_Hydroxylation-K': 0.003018797627150645,
 'learning_rate_Hydroxylation-P': 0.0061068950347954384,
 'log_base': 2.2580608669621247,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2336737387,
 'sample_weights': [2.1408159892368466, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.610828689123267,
 'weight_decay_Hydroxylation-K': 0.4734940802322436,
 'weight_decay_Hydroxylation-P': 6.688818222128014}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1342.261
[2,     1] loss: 1340.017
[3,     1] loss: 1338.909
[4,     1] loss: 1338.568
[5,     1] loss: 1330.785
[6,     1] loss: 1320.843
[7,     1] loss: 1288.379
[8,     1] loss: 1246.521
[9,     1] loss: 1205.741
[10,     1] loss: 1176.310
[11,     1] loss: 1156.290
[12,     1] loss: 1100.739
[13,     1] loss: 1106.706
[14,     1] loss: 1079.010
[15,     1] loss: 1028.340
[16,     1] loss: 1062.244
[17,     1] loss: 1078.402
[18,     1] loss: 1080.475
[19,     1] loss: 1035.477
[20,     1] loss: 1050.163
[21,     1] loss: 1030.413
[22,     1] loss: 1058.035
[23,     1] loss: 1003.000
[24,     1] loss: 1036.260
[25,     1] loss: 947.121
[26,     1] loss: 975.686
[27,     1] loss: 1014.999
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0021519646299837446,
 'learning_rate_Hydroxylation-K': 0.0020464565705752853,
 'learning_rate_Hydroxylation-P': 0.006147726182234758,
 'log_base': 1.8729058557666076,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 272804578,
 'sample_weights': [2.0496377970139266, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.853014271221986,
 'weight_decay_Hydroxylation-K': 0.5749094855644591,
 'weight_decay_Hydroxylation-P': 0.33807318941336795}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1469.265
[2,     1] loss: 1467.859
[3,     1] loss: 1471.965
[4,     1] loss: 1466.938
[5,     1] loss: 1464.884
[6,     1] loss: 1459.158
[7,     1] loss: 1453.716
[8,     1] loss: 1430.524
[9,     1] loss: 1404.491
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031548270435572934,
 'learning_rate_Hydroxylation-K': 0.0022123187726379705,
 'learning_rate_Hydroxylation-P': 0.008726688925227972,
 'log_base': 1.190359398938048,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2660984373,
 'sample_weights': [2.660504654563039, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.892933632416631,
 'weight_decay_Hydroxylation-K': 1.026109862482802,
 'weight_decay_Hydroxylation-P': 3.9540993455024194}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3114.473
[2,     1] loss: 3096.311
[3,     1] loss: 3133.741
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001796421630685041,
 'learning_rate_Hydroxylation-K': 0.0026634865218758377,
 'learning_rate_Hydroxylation-P': 0.004370140238879526,
 'log_base': 1.400560961781696,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 363444596,
 'sample_weights': [9.580445263686045, 1.1976017926136395],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2520743034933004,
 'weight_decay_Hydroxylation-K': 0.168375437775785,
 'weight_decay_Hydroxylation-P': 0.7419154218183024}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1957.809
[2,     1] loss: 1954.833
[3,     1] loss: 1946.163
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0066929464734577625,
 'learning_rate_Hydroxylation-K': 0.005757711100689897,
 'learning_rate_Hydroxylation-P': 0.0003810758028367752,
 'log_base': 1.4576989645892091,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3315763291,
 'sample_weights': [4.955707117259824, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.932982370649425,
 'weight_decay_Hydroxylation-K': 6.144455768004782,
 'weight_decay_Hydroxylation-P': 5.169732798274595}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1848.411
[2,     1] loss: 1856.302
[3,     1] loss: 1850.120
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019428595347581003,
 'learning_rate_Hydroxylation-K': 0.007271530038359163,
 'learning_rate_Hydroxylation-P': 0.0005186311151268021,
 'log_base': 1.1688122333244195,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1128394470,
 'sample_weights': [4.429886306884288, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.485125564946232,
 'weight_decay_Hydroxylation-K': 5.544150234732395,
 'weight_decay_Hydroxylation-P': 4.32351868786048}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3475.658
[2,     1] loss: 3467.806
[3,     1] loss: 3474.954
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009700595955678835,
 'learning_rate_Hydroxylation-K': 0.006221100994253891,
 'learning_rate_Hydroxylation-P': 0.0061304672220080896,
 'log_base': 2.9749015174990943,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1157556927,
 'sample_weights': [10.702378606423933, 1.3378488631280794],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.0718793570920662,
 'weight_decay_Hydroxylation-K': 1.948281436046643,
 'weight_decay_Hydroxylation-P': 5.870296014077879}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.195
[2,     1] loss: 1229.159
[3,     1] loss: 1228.537
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016258214595766289,
 'learning_rate_Hydroxylation-K': 0.004101646809554209,
 'learning_rate_Hydroxylation-P': 0.0070539644318277014,
 'log_base': 2.55646074697017,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 753511248,
 'sample_weights': [1.5313028824911699, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.076763569531065,
 'weight_decay_Hydroxylation-K': 8.612267102865605,
 'weight_decay_Hydroxylation-P': 1.6271713339749012}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1285.611
[2,     1] loss: 1278.616
[3,     1] loss: 1285.429
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031360478051686057,
 'learning_rate_Hydroxylation-K': 0.004273518274362613,
 'learning_rate_Hydroxylation-P': 0.0068823830357010556,
 'log_base': 2.9796109653761427,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1163498263,
 'sample_weights': [1.7786073407024658, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4139974629283092,
 'weight_decay_Hydroxylation-K': 1.8729101558446999,
 'weight_decay_Hydroxylation-P': 2.027880333496982}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.020
[2,     1] loss: 1234.867
[3,     1] loss: 1227.862
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004336087371106423,
 'learning_rate_Hydroxylation-K': 0.004324287905677714,
 'learning_rate_Hydroxylation-P': 0.00597433390809886,
 'log_base': 1.888000741167364,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1014701609,
 'sample_weights': [1.5290843041578674, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.19280713050901,
 'weight_decay_Hydroxylation-K': 3.137341803025053,
 'weight_decay_Hydroxylation-P': 5.341945405465331}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1463.330
[2,     1] loss: 1460.520
[3,     1] loss: 1458.502
[4,     1] loss: 1457.414
[5,     1] loss: 1453.539
[6,     1] loss: 1442.057
[7,     1] loss: 1413.832
[8,     1] loss: 1369.994
[9,     1] loss: 1341.010
[10,     1] loss: 1291.520
[11,     1] loss: 1255.943
[12,     1] loss: 1217.186
[13,     1] loss: 1263.683
[14,     1] loss: 1184.995
[15,     1] loss: 1191.322
[16,     1] loss: 1147.768
[17,     1] loss: 1147.275
[18,     1] loss: 1195.987
[19,     1] loss: 1154.397
[20,     1] loss: 1131.385
[21,     1] loss: 1092.122
[22,     1] loss: 1130.391
[23,     1] loss: 1101.869
[24,     1] loss: 1062.882
[25,     1] loss: 1061.929
[26,     1] loss: 1065.066
[27,     1] loss: 1103.654
[28,     1] loss: 1021.934
[29,     1] loss: 1047.019
[30,     1] loss: 1024.455
[31,     1] loss: 1009.255
[32,     1] loss: 1099.367
[33,     1] loss: 973.358
[34,     1] loss: 1036.634
[35,     1] loss: 976.525
[36,     1] loss: 952.011
[37,     1] loss: 967.395
[38,     1] loss: 955.169
[39,     1] loss: 962.149
[40,     1] loss: 1019.679
[41,     1] loss: 914.726
[42,     1] loss: 1005.367
[43,     1] loss: 883.831
[44,     1] loss: 946.168
[45,     1] loss: 929.956
[46,     1] loss: 818.926
[47,     1] loss: 800.471
[48,     1] loss: 801.128
[49,     1] loss: 841.585
[50,     1] loss: 760.120
[51,     1] loss: 884.765
[52,     1] loss: 943.171
[53,     1] loss: 746.716
[54,     1] loss: 893.710
[55,     1] loss: 772.510
[56,     1] loss: 832.707
[57,     1] loss: 788.580
Early stopping applied (best metric=0.8031724691390991)
Finished Training
Total time taken: 7.84900689125061
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1463.926
[2,     1] loss: 1471.575
[3,     1] loss: 1459.769
[4,     1] loss: 1461.362
[5,     1] loss: 1461.124
[6,     1] loss: 1452.569
[7,     1] loss: 1447.023
[8,     1] loss: 1433.234
[9,     1] loss: 1390.313
[10,     1] loss: 1361.562
[11,     1] loss: 1281.641
[12,     1] loss: 1256.399
[13,     1] loss: 1254.408
[14,     1] loss: 1309.991
[15,     1] loss: 1172.181
[16,     1] loss: 1302.351
[17,     1] loss: 1171.072
[18,     1] loss: 1298.384
[19,     1] loss: 1188.907
[20,     1] loss: 1198.582
[21,     1] loss: 1234.236
[22,     1] loss: 1173.744
[23,     1] loss: 1143.999
[24,     1] loss: 1163.941
[25,     1] loss: 1110.952
[26,     1] loss: 1097.450
[27,     1] loss: 1194.917
[28,     1] loss: 1093.596
[29,     1] loss: 1073.074
[30,     1] loss: 1102.404
[31,     1] loss: 1061.539
[32,     1] loss: 1024.813
[33,     1] loss: 1047.325
[34,     1] loss: 1051.569
[35,     1] loss: 1010.709
[36,     1] loss: 1027.044
[37,     1] loss: 1075.535
[38,     1] loss: 929.093
[39,     1] loss: 1033.597
[40,     1] loss: 977.624
[41,     1] loss: 945.173
[42,     1] loss: 910.373
[43,     1] loss: 879.517
[44,     1] loss: 846.953
[45,     1] loss: 825.823
[46,     1] loss: 902.990
[47,     1] loss: 1063.826
[48,     1] loss: 1494.847
[49,     1] loss: 910.421
[50,     1] loss: 1167.722
[51,     1] loss: 1150.620
[52,     1] loss: 1100.125
[53,     1] loss: 1041.816
[54,     1] loss: 1068.074
[55,     1] loss: 1079.063
[56,     1] loss: 1057.066
[57,     1] loss: 946.194
[58,     1] loss: 891.208
[59,     1] loss: 947.523
[60,     1] loss: 951.272
[61,     1] loss: 860.020
Early stopping applied (best metric=0.825175404548645)
Finished Training
Total time taken: 9.838009357452393
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1462.955
[2,     1] loss: 1461.497
[3,     1] loss: 1461.813
[4,     1] loss: 1458.330
[5,     1] loss: 1452.018
[6,     1] loss: 1415.765
[7,     1] loss: 1389.543
[8,     1] loss: 1316.241
[9,     1] loss: 1298.201
[10,     1] loss: 1296.324
[11,     1] loss: 1224.917
[12,     1] loss: 1211.403
[13,     1] loss: 1239.227
[14,     1] loss: 1199.533
[15,     1] loss: 1166.556
[16,     1] loss: 1230.029
[17,     1] loss: 1192.227
[18,     1] loss: 1170.974
[19,     1] loss: 1166.634
[20,     1] loss: 1142.655
[21,     1] loss: 1151.738
[22,     1] loss: 1112.082
[23,     1] loss: 1128.051
[24,     1] loss: 1078.584
[25,     1] loss: 1087.095
[26,     1] loss: 1052.901
[27,     1] loss: 1009.966
[28,     1] loss: 1092.287
[29,     1] loss: 1033.414
[30,     1] loss: 1024.255
[31,     1] loss: 1002.599
[32,     1] loss: 969.906
[33,     1] loss: 1030.689
[34,     1] loss: 1115.945
[35,     1] loss: 1138.189
[36,     1] loss: 993.907
[37,     1] loss: 1024.834
[38,     1] loss: 1010.969
[39,     1] loss: 921.567
[40,     1] loss: 978.297
[41,     1] loss: 895.783
[42,     1] loss: 1027.696
[43,     1] loss: 875.111
[44,     1] loss: 934.895
[45,     1] loss: 898.761
[46,     1] loss: 912.145
[47,     1] loss: 836.306
[48,     1] loss: 834.834
[49,     1] loss: 843.121
[50,     1] loss: 1130.864
Early stopping applied (best metric=0.7777499556541443)
Finished Training
Total time taken: 7.041009426116943
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1463.326
[2,     1] loss: 1467.502
[3,     1] loss: 1464.317
[4,     1] loss: 1458.676
[5,     1] loss: 1459.515
[6,     1] loss: 1457.916
[7,     1] loss: 1445.832
[8,     1] loss: 1428.560
[9,     1] loss: 1380.753
[10,     1] loss: 1337.896
[11,     1] loss: 1293.833
[12,     1] loss: 1227.110
[13,     1] loss: 1243.262
[14,     1] loss: 1230.217
[15,     1] loss: 1225.197
[16,     1] loss: 1187.520
[17,     1] loss: 1192.547
[18,     1] loss: 1203.425
[19,     1] loss: 1198.021
[20,     1] loss: 1194.744
[21,     1] loss: 1229.574
[22,     1] loss: 1141.354
[23,     1] loss: 1151.419
[24,     1] loss: 1124.044
[25,     1] loss: 1071.862
[26,     1] loss: 1120.519
[27,     1] loss: 1124.141
[28,     1] loss: 1114.140
[29,     1] loss: 1074.731
[30,     1] loss: 1096.683
[31,     1] loss: 1050.499
[32,     1] loss: 1047.257
[33,     1] loss: 1084.229
[34,     1] loss: 1131.081
[35,     1] loss: 1053.941
[36,     1] loss: 1065.564
[37,     1] loss: 1110.582
[38,     1] loss: 984.790
[39,     1] loss: 1068.813
[40,     1] loss: 1011.822
[41,     1] loss: 934.892
[42,     1] loss: 1006.582
[43,     1] loss: 902.275
[44,     1] loss: 993.280
[45,     1] loss: 886.700
[46,     1] loss: 976.405
[47,     1] loss: 924.673
[48,     1] loss: 875.744
[49,     1] loss: 903.272
[50,     1] loss: 838.880
[51,     1] loss: 880.380
[52,     1] loss: 864.309
[53,     1] loss: 842.528
[54,     1] loss: 874.115
[55,     1] loss: 764.501
[56,     1] loss: 766.754
[57,     1] loss: 841.443
[58,     1] loss: 850.029
[59,     1] loss: 710.183
[60,     1] loss: 699.104
[61,     1] loss: 770.857
[62,     1] loss: 843.368
[63,     1] loss: 862.047
[64,     1] loss: 678.284
[65,     1] loss: 712.527
[66,     1] loss: 742.352
[67,     1] loss: 725.002
[68,     1] loss: 653.189
[69,     1] loss: 677.792
[70,     1] loss: 619.581
[71,     1] loss: 659.076
[72,     1] loss: 662.354
[73,     1] loss: 531.664
Early stopping applied (best metric=0.6922451853752136)
Finished Training
Total time taken: 11.243012189865112
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1466.916
[2,     1] loss: 1466.947
[3,     1] loss: 1465.696
[4,     1] loss: 1465.084
[5,     1] loss: 1460.147
[6,     1] loss: 1448.980
[7,     1] loss: 1455.789
[8,     1] loss: 1435.259
[9,     1] loss: 1405.513
[10,     1] loss: 1381.351
[11,     1] loss: 1353.823
[12,     1] loss: 1317.385
[13,     1] loss: 1274.108
[14,     1] loss: 1291.048
[15,     1] loss: 1232.359
[16,     1] loss: 1232.877
[17,     1] loss: 1225.380
[18,     1] loss: 1234.789
[19,     1] loss: 1216.942
[20,     1] loss: 1235.394
[21,     1] loss: 1198.827
[22,     1] loss: 1217.178
[23,     1] loss: 1145.990
[24,     1] loss: 1133.801
[25,     1] loss: 1155.084
[26,     1] loss: 1100.305
[27,     1] loss: 1108.375
[28,     1] loss: 1083.995
[29,     1] loss: 1036.330
[30,     1] loss: 1024.039
[31,     1] loss: 1063.229
[32,     1] loss: 1043.403
[33,     1] loss: 1030.645
[34,     1] loss: 1076.778
[35,     1] loss: 965.019
[36,     1] loss: 956.782
[37,     1] loss: 959.822
[38,     1] loss: 929.401
[39,     1] loss: 961.040
[40,     1] loss: 957.765
[41,     1] loss: 906.607
[42,     1] loss: 861.994
[43,     1] loss: 850.982
[44,     1] loss: 900.999
[45,     1] loss: 868.549
[46,     1] loss: 849.088
[47,     1] loss: 1003.325
Early stopping applied (best metric=0.8380600214004517)
Finished Training
Total time taken: 6.454004526138306
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1463.459
[2,     1] loss: 1462.968
[3,     1] loss: 1455.282
[4,     1] loss: 1472.345
[5,     1] loss: 1467.055
[6,     1] loss: 1457.313
[7,     1] loss: 1455.201
[8,     1] loss: 1447.635
[9,     1] loss: 1433.185
[10,     1] loss: 1405.460
[11,     1] loss: 1347.564
[12,     1] loss: 1299.971
[13,     1] loss: 1324.495
[14,     1] loss: 1405.396
[15,     1] loss: 1286.068
[16,     1] loss: 1283.029
[17,     1] loss: 1228.388
[18,     1] loss: 1284.240
[19,     1] loss: 1243.210
[20,     1] loss: 1207.661
[21,     1] loss: 1215.953
[22,     1] loss: 1181.554
[23,     1] loss: 1242.713
[24,     1] loss: 1153.300
[25,     1] loss: 1128.927
[26,     1] loss: 1129.894
[27,     1] loss: 1087.360
[28,     1] loss: 1069.863
[29,     1] loss: 1105.314
[30,     1] loss: 1046.763
[31,     1] loss: 1079.150
[32,     1] loss: 1064.515
[33,     1] loss: 1147.158
[34,     1] loss: 999.903
[35,     1] loss: 1030.229
[36,     1] loss: 1019.881
[37,     1] loss: 1054.032
[38,     1] loss: 946.155
[39,     1] loss: 1023.301
[40,     1] loss: 949.388
[41,     1] loss: 936.432
[42,     1] loss: 1006.976
[43,     1] loss: 911.584
[44,     1] loss: 950.790
[45,     1] loss: 982.521
[46,     1] loss: 950.849
[47,     1] loss: 852.934
[48,     1] loss: 871.872
[49,     1] loss: 859.462
[50,     1] loss: 831.847
[51,     1] loss: 953.491
[52,     1] loss: 974.815
[53,     1] loss: 760.594
[54,     1] loss: 818.672
[55,     1] loss: 782.261
[56,     1] loss: 793.251
[57,     1] loss: 708.074
[58,     1] loss: 741.870
[59,     1] loss: 652.174
[60,     1] loss: 715.904
Early stopping applied (best metric=0.7778929471969604)
Finished Training
Total time taken: 9.33100938796997
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1459.524
[2,     1] loss: 1455.509
[3,     1] loss: 1465.945
[4,     1] loss: 1455.962
[5,     1] loss: 1457.326
[6,     1] loss: 1469.884
[7,     1] loss: 1435.733
[8,     1] loss: 1403.885
[9,     1] loss: 1373.587
[10,     1] loss: 1352.503
[11,     1] loss: 1284.996
[12,     1] loss: 1267.069
[13,     1] loss: 1293.120
[14,     1] loss: 1226.521
[15,     1] loss: 1262.799
[16,     1] loss: 1192.372
[17,     1] loss: 1243.100
[18,     1] loss: 1218.878
[19,     1] loss: 1202.930
[20,     1] loss: 1183.583
[21,     1] loss: 1162.786
[22,     1] loss: 1274.760
[23,     1] loss: 1143.856
[24,     1] loss: 1157.960
[25,     1] loss: 1116.042
[26,     1] loss: 1114.036
[27,     1] loss: 1112.978
[28,     1] loss: 1075.829
[29,     1] loss: 1076.159
[30,     1] loss: 1060.639
[31,     1] loss: 1034.850
[32,     1] loss: 1041.895
[33,     1] loss: 1049.816
[34,     1] loss: 1079.424
[35,     1] loss: 1065.576
[36,     1] loss: 1043.094
[37,     1] loss: 960.839
[38,     1] loss: 952.805
[39,     1] loss: 937.994
[40,     1] loss: 950.935
Early stopping applied (best metric=0.7597514390945435)
Finished Training
Total time taken: 5.52400541305542
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1462.490
[2,     1] loss: 1467.261
[3,     1] loss: 1462.812
[4,     1] loss: 1460.748
[5,     1] loss: 1458.857
[6,     1] loss: 1452.485
[7,     1] loss: 1440.306
[8,     1] loss: 1405.194
[9,     1] loss: 1376.238
[10,     1] loss: 1319.787
[11,     1] loss: 1278.650
[12,     1] loss: 1278.159
[13,     1] loss: 1221.053
[14,     1] loss: 1269.337
[15,     1] loss: 1232.806
[16,     1] loss: 1293.570
[17,     1] loss: 1251.013
[18,     1] loss: 1248.503
[19,     1] loss: 1246.781
[20,     1] loss: 1187.505
[21,     1] loss: 1226.932
[22,     1] loss: 1173.211
[23,     1] loss: 1165.630
[24,     1] loss: 1143.174
[25,     1] loss: 1093.545
[26,     1] loss: 1095.630
[27,     1] loss: 1086.917
[28,     1] loss: 1138.768
[29,     1] loss: 1085.578
[30,     1] loss: 1090.579
[31,     1] loss: 1081.847
[32,     1] loss: 1067.921
[33,     1] loss: 1134.392
[34,     1] loss: 1065.518
[35,     1] loss: 1098.661
[36,     1] loss: 1050.973
[37,     1] loss: 1071.379
[38,     1] loss: 990.912
[39,     1] loss: 1022.160
[40,     1] loss: 978.135
[41,     1] loss: 974.036
[42,     1] loss: 960.903
[43,     1] loss: 1028.421
[44,     1] loss: 933.762
[45,     1] loss: 964.553
[46,     1] loss: 1049.623
[47,     1] loss: 901.292
[48,     1] loss: 924.626
[49,     1] loss: 1010.816
[50,     1] loss: 869.497
[51,     1] loss: 905.333
[52,     1] loss: 897.308
[53,     1] loss: 916.070
[54,     1] loss: 837.178
[55,     1] loss: 893.321
[56,     1] loss: 930.403
[57,     1] loss: 806.565
[58,     1] loss: 914.713
[59,     1] loss: 808.973
[60,     1] loss: 884.121
[61,     1] loss: 836.674
[62,     1] loss: 849.741
[63,     1] loss: 807.045
Early stopping applied (best metric=0.7277153730392456)
Finished Training
Total time taken: 9.481011629104614
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1460.447
[2,     1] loss: 1465.173
[3,     1] loss: 1469.719
[4,     1] loss: 1455.460
[5,     1] loss: 1464.649
[6,     1] loss: 1447.597
[7,     1] loss: 1445.585
[8,     1] loss: 1422.719
[9,     1] loss: 1389.247
[10,     1] loss: 1351.837
[11,     1] loss: 1288.600
[12,     1] loss: 1250.713
[13,     1] loss: 1285.161
[14,     1] loss: 1237.588
[15,     1] loss: 1228.841
[16,     1] loss: 1159.676
[17,     1] loss: 1095.498
[18,     1] loss: 1150.446
[19,     1] loss: 1152.025
[20,     1] loss: 1134.046
[21,     1] loss: 1103.767
[22,     1] loss: 1146.813
[23,     1] loss: 1064.304
[24,     1] loss: 1039.519
[25,     1] loss: 1035.185
[26,     1] loss: 1126.475
[27,     1] loss: 1073.450
[28,     1] loss: 989.281
[29,     1] loss: 1098.069
[30,     1] loss: 1019.996
Early stopping applied (best metric=1.0272865295410156)
Finished Training
Total time taken: 4.50400447845459
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1462.576
[2,     1] loss: 1462.431
[3,     1] loss: 1463.078
[4,     1] loss: 1462.917
[5,     1] loss: 1457.465
[6,     1] loss: 1465.124
[7,     1] loss: 1440.604
[8,     1] loss: 1433.513
[9,     1] loss: 1391.745
[10,     1] loss: 1402.876
[11,     1] loss: 1315.923
[12,     1] loss: 1325.231
[13,     1] loss: 1297.214
[14,     1] loss: 1240.159
[15,     1] loss: 1252.078
[16,     1] loss: 1188.573
[17,     1] loss: 1310.893
[18,     1] loss: 1202.862
[19,     1] loss: 1236.526
[20,     1] loss: 1176.107
[21,     1] loss: 1168.196
[22,     1] loss: 1146.626
[23,     1] loss: 1139.741
[24,     1] loss: 1205.607
[25,     1] loss: 1115.011
[26,     1] loss: 1101.628
[27,     1] loss: 1096.398
[28,     1] loss: 1110.987
[29,     1] loss: 1097.776
[30,     1] loss: 1070.094
[31,     1] loss: 1042.114
[32,     1] loss: 1126.001
[33,     1] loss: 1034.042
[34,     1] loss: 1020.499
[35,     1] loss: 1068.845
[36,     1] loss: 1065.736
[37,     1] loss: 984.027
[38,     1] loss: 977.833
[39,     1] loss: 994.746
[40,     1] loss: 965.855
[41,     1] loss: 906.923
[42,     1] loss: 853.665
[43,     1] loss: 911.557
[44,     1] loss: 858.944
[45,     1] loss: 977.146
[46,     1] loss: 1173.373
[47,     1] loss: 1099.721
[48,     1] loss: 986.303
[49,     1] loss: 901.272
[50,     1] loss: 1001.265
[51,     1] loss: 877.229
[52,     1] loss: 836.388
[53,     1] loss: 845.727
[54,     1] loss: 831.066
[55,     1] loss: 813.394
[56,     1] loss: 794.359
[57,     1] loss: 747.919
Early stopping applied (best metric=0.7577105164527893)
Finished Training
Total time taken: 9.365007400512695
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1461.242
[2,     1] loss: 1463.052
[3,     1] loss: 1460.917
[4,     1] loss: 1465.245
[5,     1] loss: 1458.636
[6,     1] loss: 1467.152
[7,     1] loss: 1458.397
[8,     1] loss: 1450.062
[9,     1] loss: 1434.547
[10,     1] loss: 1409.808
[11,     1] loss: 1368.350
[12,     1] loss: 1310.082
[13,     1] loss: 1280.406
[14,     1] loss: 1303.456
[15,     1] loss: 1274.223
[16,     1] loss: 1259.741
[17,     1] loss: 1253.072
[18,     1] loss: 1244.847
[19,     1] loss: 1251.531
[20,     1] loss: 1198.060
[21,     1] loss: 1206.897
[22,     1] loss: 1180.758
[23,     1] loss: 1159.368
[24,     1] loss: 1150.488
[25,     1] loss: 1212.605
[26,     1] loss: 1156.647
[27,     1] loss: 1097.626
[28,     1] loss: 1132.395
[29,     1] loss: 1153.941
[30,     1] loss: 1070.432
[31,     1] loss: 1123.089
[32,     1] loss: 1016.641
[33,     1] loss: 1137.274
[34,     1] loss: 1093.069
[35,     1] loss: 1092.766
[36,     1] loss: 965.763
[37,     1] loss: 1063.122
[38,     1] loss: 1011.382
[39,     1] loss: 974.561
[40,     1] loss: 976.820
[41,     1] loss: 991.935
[42,     1] loss: 907.571
[43,     1] loss: 1005.429
[44,     1] loss: 944.371
[45,     1] loss: 892.640
[46,     1] loss: 879.257
[47,     1] loss: 872.705
[48,     1] loss: 916.199
[49,     1] loss: 898.066
[50,     1] loss: 870.909
[51,     1] loss: 868.869
[52,     1] loss: 826.429
[53,     1] loss: 797.157
[54,     1] loss: 761.322
[55,     1] loss: 797.939
[56,     1] loss: 797.621
[57,     1] loss: 788.318
[58,     1] loss: 749.341
[59,     1] loss: 739.753
[60,     1] loss: 808.305
[61,     1] loss: 889.015
[62,     1] loss: 819.472
[63,     1] loss: 765.351
[64,     1] loss: 754.755
[65,     1] loss: 759.878
[66,     1] loss: 707.387
[67,     1] loss: 750.517
[68,     1] loss: 685.432
[69,     1] loss: 600.237
Early stopping applied (best metric=0.673578679561615)
Finished Training
Total time taken: 10.150007486343384
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1465.510
[2,     1] loss: 1468.260
[3,     1] loss: 1458.441
[4,     1] loss: 1464.309
[5,     1] loss: 1462.857
[6,     1] loss: 1459.406
[7,     1] loss: 1457.566
[8,     1] loss: 1452.050
[9,     1] loss: 1438.868
[10,     1] loss: 1414.750
[11,     1] loss: 1384.828
[12,     1] loss: 1336.845
[13,     1] loss: 1316.883
[14,     1] loss: 1289.863
[15,     1] loss: 1235.889
[16,     1] loss: 1215.959
[17,     1] loss: 1300.316
[18,     1] loss: 1211.689
[19,     1] loss: 1236.049
[20,     1] loss: 1228.462
[21,     1] loss: 1228.339
[22,     1] loss: 1165.472
[23,     1] loss: 1284.803
[24,     1] loss: 1174.443
[25,     1] loss: 1174.398
[26,     1] loss: 1165.282
[27,     1] loss: 1126.548
[28,     1] loss: 1130.083
[29,     1] loss: 1123.964
[30,     1] loss: 1115.931
[31,     1] loss: 1061.860
[32,     1] loss: 1095.097
[33,     1] loss: 1054.789
[34,     1] loss: 1013.472
[35,     1] loss: 1039.182
[36,     1] loss: 1105.680
[37,     1] loss: 1049.508
[38,     1] loss: 962.356
[39,     1] loss: 1041.651
[40,     1] loss: 995.588
[41,     1] loss: 998.441
[42,     1] loss: 996.917
[43,     1] loss: 976.113
[44,     1] loss: 1005.787
[45,     1] loss: 874.455
[46,     1] loss: 964.332
[47,     1] loss: 993.188
[48,     1] loss: 874.977
[49,     1] loss: 983.391
[50,     1] loss: 847.058
Early stopping applied (best metric=0.8352874517440796)
Finished Training
Total time taken: 7.881007671356201
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1463.948
[2,     1] loss: 1478.067
[3,     1] loss: 1463.307
[4,     1] loss: 1463.432
[5,     1] loss: 1461.194
[6,     1] loss: 1462.195
[7,     1] loss: 1460.660
[8,     1] loss: 1460.983
[9,     1] loss: 1458.157
[10,     1] loss: 1457.540
[11,     1] loss: 1451.125
[12,     1] loss: 1450.136
[13,     1] loss: 1444.263
[14,     1] loss: 1419.739
[15,     1] loss: 1393.274
[16,     1] loss: 1360.502
[17,     1] loss: 1327.319
[18,     1] loss: 1294.004
[19,     1] loss: 1252.223
[20,     1] loss: 1264.225
[21,     1] loss: 1276.394
[22,     1] loss: 1204.690
[23,     1] loss: 1225.635
[24,     1] loss: 1173.884
[25,     1] loss: 1199.642
[26,     1] loss: 1167.111
[27,     1] loss: 1146.628
[28,     1] loss: 1149.883
[29,     1] loss: 1167.176
[30,     1] loss: 1131.811
[31,     1] loss: 1117.349
[32,     1] loss: 1171.983
[33,     1] loss: 1096.693
[34,     1] loss: 1155.269
[35,     1] loss: 1073.345
[36,     1] loss: 1081.189
[37,     1] loss: 1036.571
[38,     1] loss: 1096.036
[39,     1] loss: 996.110
[40,     1] loss: 951.619
[41,     1] loss: 999.424
[42,     1] loss: 1055.961
[43,     1] loss: 950.177
[44,     1] loss: 997.695
[45,     1] loss: 921.274
[46,     1] loss: 905.492
[47,     1] loss: 833.120
[48,     1] loss: 828.020
[49,     1] loss: 844.949
[50,     1] loss: 825.076
[51,     1] loss: 915.240
[52,     1] loss: 896.628
[53,     1] loss: 799.344
[54,     1] loss: 881.971
[55,     1] loss: 775.238
[56,     1] loss: 874.286
[57,     1] loss: 821.406
[58,     1] loss: 806.536
[59,     1] loss: 780.110
[60,     1] loss: 728.321
Early stopping applied (best metric=0.7409374713897705)
Finished Training
Total time taken: 10.096010208129883
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1466.966
[2,     1] loss: 1456.868
[3,     1] loss: 1473.225
[4,     1] loss: 1457.940
[5,     1] loss: 1458.174
[6,     1] loss: 1445.135
[7,     1] loss: 1426.675
[8,     1] loss: 1380.260
[9,     1] loss: 1332.950
[10,     1] loss: 1336.877
[11,     1] loss: 1264.099
[12,     1] loss: 1292.543
[13,     1] loss: 1228.130
[14,     1] loss: 1287.324
[15,     1] loss: 1227.683
[16,     1] loss: 1305.694
[17,     1] loss: 1220.255
[18,     1] loss: 1259.998
[19,     1] loss: 1211.017
[20,     1] loss: 1172.966
[21,     1] loss: 1197.594
[22,     1] loss: 1184.758
[23,     1] loss: 1108.532
[24,     1] loss: 1133.813
[25,     1] loss: 1182.620
[26,     1] loss: 1137.379
[27,     1] loss: 1152.256
[28,     1] loss: 1092.914
[29,     1] loss: 1086.494
[30,     1] loss: 1059.255
[31,     1] loss: 1101.148
[32,     1] loss: 1081.922
[33,     1] loss: 1048.070
[34,     1] loss: 1054.597
[35,     1] loss: 993.775
[36,     1] loss: 1070.838
[37,     1] loss: 1023.681
[38,     1] loss: 1009.924
[39,     1] loss: 1019.946
[40,     1] loss: 1011.716
[41,     1] loss: 918.819
[42,     1] loss: 938.035
[43,     1] loss: 994.032
[44,     1] loss: 891.518
[45,     1] loss: 907.013
[46,     1] loss: 890.359
[47,     1] loss: 896.824
[48,     1] loss: 920.006
[49,     1] loss: 938.827
[50,     1] loss: 843.340
[51,     1] loss: 842.541
[52,     1] loss: 817.764
[53,     1] loss: 797.262
[54,     1] loss: 718.233
[55,     1] loss: 827.443
[56,     1] loss: 1147.961
[57,     1] loss: 1192.380
[58,     1] loss: 849.148
[59,     1] loss: 867.815
[60,     1] loss: 1007.241
[61,     1] loss: 881.382
[62,     1] loss: 910.670
[63,     1] loss: 940.743
Early stopping applied (best metric=0.8390891551971436)
Finished Training
Total time taken: 10.39900803565979
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1463.647
[2,     1] loss: 1463.984
[3,     1] loss: 1463.293
[4,     1] loss: 1469.179
[5,     1] loss: 1462.861
[6,     1] loss: 1462.796
[7,     1] loss: 1461.159
[8,     1] loss: 1456.769
[9,     1] loss: 1458.978
[10,     1] loss: 1455.029
[11,     1] loss: 1437.850
[12,     1] loss: 1438.048
[13,     1] loss: 1394.438
[14,     1] loss: 1391.513
[15,     1] loss: 1325.525
[16,     1] loss: 1321.128
[17,     1] loss: 1281.859
[18,     1] loss: 1262.633
[19,     1] loss: 1270.305
[20,     1] loss: 1279.013
[21,     1] loss: 1218.791
[22,     1] loss: 1280.349
[23,     1] loss: 1198.172
[24,     1] loss: 1188.357
[25,     1] loss: 1256.978
[26,     1] loss: 1154.941
[27,     1] loss: 1153.115
[28,     1] loss: 1171.339
[29,     1] loss: 1106.842
[30,     1] loss: 1176.590
[31,     1] loss: 1112.165
[32,     1] loss: 1117.005
[33,     1] loss: 1107.252
[34,     1] loss: 1068.349
[35,     1] loss: 1141.325
[36,     1] loss: 1026.847
[37,     1] loss: 1081.845
[38,     1] loss: 1052.247
[39,     1] loss: 1067.054
[40,     1] loss: 1030.698
[41,     1] loss: 1066.863
[42,     1] loss: 982.357
[43,     1] loss: 1013.898
[44,     1] loss: 987.561
[45,     1] loss: 928.369
[46,     1] loss: 948.720
[47,     1] loss: 891.120
[48,     1] loss: 932.005
[49,     1] loss: 921.156
[50,     1] loss: 889.584
[51,     1] loss: 868.064
[52,     1] loss: 894.380
[53,     1] loss: 849.142
[54,     1] loss: 843.605
[55,     1] loss: 853.901
[56,     1] loss: 805.870
[57,     1] loss: 857.758
[58,     1] loss: 1442.906
[59,     1] loss: 1164.729
[60,     1] loss: 1073.004
[61,     1] loss: 997.958
[62,     1] loss: 1062.019
Early stopping applied (best metric=0.8570960760116577)
Finished Training
Total time taken: 10.408010721206665
{'Hydroxylation-K Validation Accuracy': 0.7699763593380614, 'Hydroxylation-K Validation Sensitivity': 0.7451851851851852, 'Hydroxylation-K Validation Specificity': 0.775438596491228, 'Hydroxylation-K Validation Precision': 0.45549338088811775, 'Hydroxylation-K AUC ROC': 0.8252046783625732, 'Hydroxylation-K AUC PR': 0.5820157501046519, 'Hydroxylation-K MCC': 0.4455802353778254, 'Hydroxylation-K F1': 0.5630911540566713, 'Validation Loss (Hydroxylation-K)': 0.40880447427431743, 'Hydroxylation-P Validation Accuracy': 0.7919626584098945, 'Hydroxylation-P Validation Sensitivity': 0.7671428571428571, 'Hydroxylation-P Validation Specificity': 0.7972941293830116, 'Hydroxylation-P Validation Precision': 0.45219420946076955, 'Hydroxylation-P AUC ROC': 0.8367404026801004, 'Hydroxylation-P AUC PR': 0.5710660237815605, 'Hydroxylation-P MCC': 0.47097187103022214, 'Hydroxylation-P F1': 0.5669969640127017, 'Validation Loss (Hydroxylation-P)': 0.3867121080557505, 'Validation Loss (total)': 0.795516578356425, 'TimeToTrain': 8.637608321507772}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032758166648292624,
 'learning_rate_Hydroxylation-K': 0.009875785519613375,
 'learning_rate_Hydroxylation-P': 0.003245648000583477,
 'log_base': 2.99420474224769,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 76941659,
 'sample_weights': [2.628848164238431, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.641366720247909,
 'weight_decay_Hydroxylation-K': 5.163718641116671,
 'weight_decay_Hydroxylation-P': 3.0246162651513067}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.010
[2,     1] loss: 1233.621
[3,     1] loss: 1231.287
[4,     1] loss: 1229.281
[5,     1] loss: 1226.562
[6,     1] loss: 1227.745
[7,     1] loss: 1225.335
[8,     1] loss: 1213.953
[9,     1] loss: 1207.430
[10,     1] loss: 1178.652
[11,     1] loss: 1159.965
[12,     1] loss: 1124.463
[13,     1] loss: 1103.953
[14,     1] loss: 1040.746
[15,     1] loss: 1041.614
[16,     1] loss: 1051.893
[17,     1] loss: 1099.360
[18,     1] loss: 1062.751
[19,     1] loss: 977.162
[20,     1] loss: 1025.642
[21,     1] loss: 1004.271
[22,     1] loss: 999.786
[23,     1] loss: 1004.406
[24,     1] loss: 964.301
[25,     1] loss: 995.713
[26,     1] loss: 912.896
[27,     1] loss: 979.603
[28,     1] loss: 906.962
[29,     1] loss: 952.698
[30,     1] loss: 944.985
[31,     1] loss: 936.080
[32,     1] loss: 912.036
[33,     1] loss: 870.643
[34,     1] loss: 863.011
[35,     1] loss: 879.723
[36,     1] loss: 904.071
[37,     1] loss: 842.735
[38,     1] loss: 887.582
[39,     1] loss: 850.301
[40,     1] loss: 883.954
[41,     1] loss: 818.103
[42,     1] loss: 833.434
[43,     1] loss: 815.338
[44,     1] loss: 826.779
[45,     1] loss: 786.509
[46,     1] loss: 813.903
[47,     1] loss: 846.237
[48,     1] loss: 823.436
[49,     1] loss: 760.622
[50,     1] loss: 827.790
[51,     1] loss: 797.549
[52,     1] loss: 889.455
[53,     1] loss: 708.952
[54,     1] loss: 874.690
[55,     1] loss: 728.861
[56,     1] loss: 832.463
[57,     1] loss: 743.575
[58,     1] loss: 800.706
[59,     1] loss: 755.885
[60,     1] loss: 729.241
[61,     1] loss: 720.798
[62,     1] loss: 651.310
[63,     1] loss: 746.239
[64,     1] loss: 674.206
[65,     1] loss: 670.743
[66,     1] loss: 707.709
[67,     1] loss: 611.587
[68,     1] loss: 604.089
[69,     1] loss: 632.547
[70,     1] loss: 743.543
[71,     1] loss: 793.851
[72,     1] loss: 577.200
[73,     1] loss: 792.500
[74,     1] loss: 614.489
[75,     1] loss: 748.610
[76,     1] loss: 632.068
[77,     1] loss: 707.315
[78,     1] loss: 653.072
[79,     1] loss: 663.380
[80,     1] loss: 568.650
[81,     1] loss: 585.016
[82,     1] loss: 493.371
[83,     1] loss: 555.351
[84,     1] loss: 551.068
[85,     1] loss: 562.879
[86,     1] loss: 490.003
[87,     1] loss: 548.012
[88,     1] loss: 485.226
[89,     1] loss: 475.651
[90,     1] loss: 475.276
[91,     1] loss: 476.353
[92,     1] loss: 493.710
[93,     1] loss: 520.483
[94,     1] loss: 623.059
[95,     1] loss: 617.915
[96,     1] loss: 566.611
[97,     1] loss: 468.798
[98,     1] loss: 565.143
[99,     1] loss: 454.417
[100,     1] loss: 548.726
[101,     1] loss: 530.483
[102,     1] loss: 428.385
[103,     1] loss: 508.355
[104,     1] loss: 507.418
[105,     1] loss: 501.003
Early stopping applied (best metric=0.6347649097442627)
Finished Training
Total time taken: 17.154067754745483
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.452
[2,     1] loss: 1228.534
[3,     1] loss: 1228.027
[4,     1] loss: 1225.049
[5,     1] loss: 1216.140
[6,     1] loss: 1206.435
[7,     1] loss: 1188.052
[8,     1] loss: 1135.748
[9,     1] loss: 1099.887
[10,     1] loss: 1086.192
[11,     1] loss: 1078.510
[12,     1] loss: 998.082
[13,     1] loss: 1009.803
[14,     1] loss: 1049.094
[15,     1] loss: 1039.962
[16,     1] loss: 1061.127
[17,     1] loss: 979.043
[18,     1] loss: 1028.307
[19,     1] loss: 988.696
[20,     1] loss: 978.159
[21,     1] loss: 984.662
[22,     1] loss: 961.622
[23,     1] loss: 986.140
[24,     1] loss: 929.178
[25,     1] loss: 917.461
[26,     1] loss: 919.648
[27,     1] loss: 904.184
[28,     1] loss: 940.882
[29,     1] loss: 908.428
[30,     1] loss: 882.748
[31,     1] loss: 860.093
[32,     1] loss: 930.556
[33,     1] loss: 901.096
[34,     1] loss: 863.207
[35,     1] loss: 904.922
[36,     1] loss: 877.692
[37,     1] loss: 868.486
[38,     1] loss: 856.438
[39,     1] loss: 882.423
[40,     1] loss: 773.989
[41,     1] loss: 822.239
[42,     1] loss: 889.863
[43,     1] loss: 819.751
[44,     1] loss: 802.929
[45,     1] loss: 763.831
[46,     1] loss: 786.911
[47,     1] loss: 714.059
[48,     1] loss: 800.496
[49,     1] loss: 997.389
[50,     1] loss: 1108.653
[51,     1] loss: 771.268
[52,     1] loss: 826.013
[53,     1] loss: 955.978
[54,     1] loss: 853.605
[55,     1] loss: 829.965
[56,     1] loss: 862.006
[57,     1] loss: 870.560
[58,     1] loss: 792.042
[59,     1] loss: 764.981
[60,     1] loss: 782.552
[61,     1] loss: 766.456
[62,     1] loss: 726.908
[63,     1] loss: 785.571
[64,     1] loss: 737.592
[65,     1] loss: 730.240
[66,     1] loss: 739.734
Early stopping applied (best metric=0.7560951113700867)
Finished Training
Total time taken: 9.261011123657227
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1231.576
[2,     1] loss: 1229.796
[3,     1] loss: 1230.071
[4,     1] loss: 1229.942
[5,     1] loss: 1227.392
[6,     1] loss: 1220.183
[7,     1] loss: 1214.499
[8,     1] loss: 1186.292
[9,     1] loss: 1170.667
[10,     1] loss: 1125.775
[11,     1] loss: 1098.476
[12,     1] loss: 1093.340
[13,     1] loss: 1062.616
[14,     1] loss: 1070.251
[15,     1] loss: 1029.186
[16,     1] loss: 1003.580
[17,     1] loss: 1041.274
[18,     1] loss: 1037.717
[19,     1] loss: 1011.206
[20,     1] loss: 1017.151
[21,     1] loss: 979.222
[22,     1] loss: 967.008
[23,     1] loss: 970.030
[24,     1] loss: 926.159
[25,     1] loss: 961.949
[26,     1] loss: 917.292
[27,     1] loss: 901.481
[28,     1] loss: 928.731
[29,     1] loss: 870.515
[30,     1] loss: 934.615
[31,     1] loss: 908.883
[32,     1] loss: 909.257
[33,     1] loss: 850.853
[34,     1] loss: 845.727
[35,     1] loss: 880.145
[36,     1] loss: 806.611
[37,     1] loss: 801.119
[38,     1] loss: 822.314
[39,     1] loss: 817.309
[40,     1] loss: 802.394
[41,     1] loss: 809.562
[42,     1] loss: 785.456
[43,     1] loss: 755.520
[44,     1] loss: 815.353
[45,     1] loss: 728.647
[46,     1] loss: 724.996
[47,     1] loss: 762.246
[48,     1] loss: 685.308
[49,     1] loss: 755.059
[50,     1] loss: 709.330
[51,     1] loss: 698.255
[52,     1] loss: 697.590
[53,     1] loss: 668.924
[54,     1] loss: 687.432
[55,     1] loss: 773.363
[56,     1] loss: 1332.472
[57,     1] loss: 794.397
[58,     1] loss: 964.682
[59,     1] loss: 832.212
[60,     1] loss: 887.866
[61,     1] loss: 898.481
[62,     1] loss: 904.535
Early stopping applied (best metric=0.8278027772903442)
Finished Training
Total time taken: 10.394010305404663
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1231.236
[2,     1] loss: 1230.623
[3,     1] loss: 1229.687
[4,     1] loss: 1230.254
[5,     1] loss: 1214.515
[6,     1] loss: 1198.718
[7,     1] loss: 1167.748
[8,     1] loss: 1104.474
[9,     1] loss: 1063.663
[10,     1] loss: 1026.439
[11,     1] loss: 1030.881
[12,     1] loss: 1020.094
[13,     1] loss: 1049.235
[14,     1] loss: 981.054
[15,     1] loss: 1018.707
[16,     1] loss: 979.250
[17,     1] loss: 981.391
[18,     1] loss: 1011.253
[19,     1] loss: 973.552
[20,     1] loss: 1012.240
[21,     1] loss: 959.797
[22,     1] loss: 910.965
[23,     1] loss: 963.330
[24,     1] loss: 911.520
[25,     1] loss: 872.052
[26,     1] loss: 975.906
[27,     1] loss: 882.689
[28,     1] loss: 910.870
[29,     1] loss: 914.032
[30,     1] loss: 893.443
[31,     1] loss: 916.189
[32,     1] loss: 863.943
[33,     1] loss: 896.537
[34,     1] loss: 880.940
[35,     1] loss: 862.455
[36,     1] loss: 889.872
[37,     1] loss: 825.122
[38,     1] loss: 836.251
[39,     1] loss: 803.219
[40,     1] loss: 815.370
[41,     1] loss: 791.527
[42,     1] loss: 781.930
[43,     1] loss: 739.986
[44,     1] loss: 791.260
[45,     1] loss: 716.597
[46,     1] loss: 734.272
[47,     1] loss: 724.192
[48,     1] loss: 710.338
[49,     1] loss: 760.301
[50,     1] loss: 677.630
[51,     1] loss: 710.426
[52,     1] loss: 710.054
[53,     1] loss: 711.282
[54,     1] loss: 662.338
[55,     1] loss: 664.159
[56,     1] loss: 645.750
[57,     1] loss: 651.264
[58,     1] loss: 689.857
[59,     1] loss: 724.723
[60,     1] loss: 678.912
Early stopping applied (best metric=0.8223665356636047)
Finished Training
Total time taken: 10.114011287689209
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1233.183
[2,     1] loss: 1231.088
[3,     1] loss: 1228.660
[4,     1] loss: 1226.950
[5,     1] loss: 1216.211
[6,     1] loss: 1191.123
[7,     1] loss: 1140.117
[8,     1] loss: 1093.007
[9,     1] loss: 1064.205
[10,     1] loss: 1034.924
[11,     1] loss: 1021.575
[12,     1] loss: 967.185
[13,     1] loss: 957.591
[14,     1] loss: 981.632
[15,     1] loss: 943.365
[16,     1] loss: 934.211
[17,     1] loss: 994.977
[18,     1] loss: 952.805
[19,     1] loss: 931.128
[20,     1] loss: 923.236
[21,     1] loss: 883.974
[22,     1] loss: 922.409
[23,     1] loss: 891.593
[24,     1] loss: 891.476
[25,     1] loss: 904.677
[26,     1] loss: 872.138
[27,     1] loss: 847.118
[28,     1] loss: 851.436
[29,     1] loss: 882.891
[30,     1] loss: 842.191
[31,     1] loss: 840.886
[32,     1] loss: 853.288
[33,     1] loss: 765.609
[34,     1] loss: 789.420
[35,     1] loss: 782.865
[36,     1] loss: 753.918
[37,     1] loss: 770.993
[38,     1] loss: 750.521
[39,     1] loss: 717.579
[40,     1] loss: 775.659
[41,     1] loss: 686.811
[42,     1] loss: 722.055
[43,     1] loss: 729.373
[44,     1] loss: 883.793
[45,     1] loss: 824.586
[46,     1] loss: 724.786
[47,     1] loss: 788.480
[48,     1] loss: 777.318
[49,     1] loss: 712.505
[50,     1] loss: 782.798
[51,     1] loss: 662.424
[52,     1] loss: 742.372
[53,     1] loss: 698.967
[54,     1] loss: 724.320
[55,     1] loss: 672.121
[56,     1] loss: 615.427
[57,     1] loss: 707.142
[58,     1] loss: 668.213
[59,     1] loss: 611.188
[60,     1] loss: 613.183
[61,     1] loss: 587.472
[62,     1] loss: 707.253
[63,     1] loss: 600.307
[64,     1] loss: 659.444
[65,     1] loss: 585.894
[66,     1] loss: 530.814
[67,     1] loss: 619.235
Early stopping applied (best metric=0.9109119176864624)
Finished Training
Total time taken: 10.139011144638062
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.366
[2,     1] loss: 1226.513
[3,     1] loss: 1226.163
[4,     1] loss: 1226.810
[5,     1] loss: 1230.727
[6,     1] loss: 1219.211
[7,     1] loss: 1195.653
[8,     1] loss: 1168.690
[9,     1] loss: 1132.296
[10,     1] loss: 1084.014
[11,     1] loss: 1089.311
[12,     1] loss: 1011.721
[13,     1] loss: 1034.369
[14,     1] loss: 1061.562
[15,     1] loss: 1016.447
[16,     1] loss: 1006.213
[17,     1] loss: 1020.010
[18,     1] loss: 985.984
[19,     1] loss: 1033.476
[20,     1] loss: 966.293
[21,     1] loss: 1018.612
[22,     1] loss: 958.652
[23,     1] loss: 906.819
[24,     1] loss: 960.830
[25,     1] loss: 919.289
[26,     1] loss: 1009.995
[27,     1] loss: 910.303
[28,     1] loss: 943.490
[29,     1] loss: 906.164
[30,     1] loss: 893.841
[31,     1] loss: 969.282
[32,     1] loss: 916.215
[33,     1] loss: 868.011
[34,     1] loss: 837.692
[35,     1] loss: 861.420
[36,     1] loss: 893.733
[37,     1] loss: 858.417
[38,     1] loss: 781.922
[39,     1] loss: 792.316
[40,     1] loss: 810.731
[41,     1] loss: 793.680
[42,     1] loss: 731.795
Early stopping applied (best metric=0.9530818462371826)
Finished Training
Total time taken: 5.77000617980957
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1235.274
[2,     1] loss: 1234.872
[3,     1] loss: 1230.725
[4,     1] loss: 1231.890
[5,     1] loss: 1228.662
[6,     1] loss: 1230.231
[7,     1] loss: 1221.146
[8,     1] loss: 1228.700
[9,     1] loss: 1220.609
[10,     1] loss: 1211.714
[11,     1] loss: 1200.091
[12,     1] loss: 1179.623
[13,     1] loss: 1162.583
[14,     1] loss: 1128.799
[15,     1] loss: 1063.859
[16,     1] loss: 1072.768
[17,     1] loss: 1067.577
[18,     1] loss: 1067.064
[19,     1] loss: 1090.282
[20,     1] loss: 996.868
[21,     1] loss: 1055.233
[22,     1] loss: 997.787
[23,     1] loss: 1011.199
[24,     1] loss: 988.483
[25,     1] loss: 986.490
[26,     1] loss: 994.040
[27,     1] loss: 974.225
[28,     1] loss: 958.435
[29,     1] loss: 938.695
[30,     1] loss: 944.015
[31,     1] loss: 956.834
[32,     1] loss: 907.672
[33,     1] loss: 931.806
[34,     1] loss: 914.369
[35,     1] loss: 910.140
[36,     1] loss: 922.608
[37,     1] loss: 889.084
[38,     1] loss: 866.352
[39,     1] loss: 890.597
[40,     1] loss: 812.997
[41,     1] loss: 884.023
[42,     1] loss: 873.350
[43,     1] loss: 819.579
[44,     1] loss: 866.387
[45,     1] loss: 810.093
[46,     1] loss: 849.226
[47,     1] loss: 800.069
[48,     1] loss: 788.890
[49,     1] loss: 753.857
[50,     1] loss: 823.981
[51,     1] loss: 774.326
[52,     1] loss: 730.333
[53,     1] loss: 866.124
[54,     1] loss: 724.817
[55,     1] loss: 807.905
[56,     1] loss: 704.009
[57,     1] loss: 830.765
[58,     1] loss: 700.529
[59,     1] loss: 729.231
[60,     1] loss: 672.505
[61,     1] loss: 707.958
[62,     1] loss: 690.457
[63,     1] loss: 596.590
[64,     1] loss: 643.687
[65,     1] loss: 594.221
[66,     1] loss: 596.456
[67,     1] loss: 556.298
[68,     1] loss: 587.897
[69,     1] loss: 744.407
[70,     1] loss: 947.881
[71,     1] loss: 704.173
[72,     1] loss: 737.274
[73,     1] loss: 649.796
[74,     1] loss: 745.274
[75,     1] loss: 728.773
[76,     1] loss: 630.327
[77,     1] loss: 649.644
[78,     1] loss: 677.123
[79,     1] loss: 549.793
[80,     1] loss: 716.304
[81,     1] loss: 555.370
[82,     1] loss: 671.499
[83,     1] loss: 542.500
[84,     1] loss: 706.861
[85,     1] loss: 509.284
Early stopping applied (best metric=0.654171347618103)
Finished Training
Total time taken: 14.034012794494629
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.103
[2,     1] loss: 1232.639
[3,     1] loss: 1228.215
[4,     1] loss: 1232.189
[5,     1] loss: 1229.905
[6,     1] loss: 1223.973
[7,     1] loss: 1217.629
[8,     1] loss: 1216.462
[9,     1] loss: 1189.759
[10,     1] loss: 1163.247
[11,     1] loss: 1132.936
[12,     1] loss: 1086.767
[13,     1] loss: 1109.564
[14,     1] loss: 1038.995
[15,     1] loss: 1036.775
[16,     1] loss: 1063.003
[17,     1] loss: 1031.769
[18,     1] loss: 1036.422
[19,     1] loss: 1012.317
[20,     1] loss: 989.982
[21,     1] loss: 1005.435
[22,     1] loss: 1008.942
[23,     1] loss: 964.238
[24,     1] loss: 965.283
[25,     1] loss: 981.250
[26,     1] loss: 966.331
[27,     1] loss: 1030.286
[28,     1] loss: 942.784
[29,     1] loss: 923.289
[30,     1] loss: 918.653
[31,     1] loss: 949.273
[32,     1] loss: 920.008
[33,     1] loss: 922.310
[34,     1] loss: 894.629
[35,     1] loss: 911.224
[36,     1] loss: 872.566
[37,     1] loss: 838.594
[38,     1] loss: 865.558
[39,     1] loss: 924.191
[40,     1] loss: 866.802
[41,     1] loss: 872.302
[42,     1] loss: 887.135
[43,     1] loss: 852.830
[44,     1] loss: 802.555
[45,     1] loss: 839.133
[46,     1] loss: 803.112
[47,     1] loss: 807.786
[48,     1] loss: 784.879
[49,     1] loss: 784.989
[50,     1] loss: 784.736
[51,     1] loss: 806.813
[52,     1] loss: 823.158
[53,     1] loss: 745.633
[54,     1] loss: 778.515
[55,     1] loss: 751.645
[56,     1] loss: 699.417
[57,     1] loss: 713.021
[58,     1] loss: 723.230
[59,     1] loss: 718.367
[60,     1] loss: 713.026
[61,     1] loss: 682.907
[62,     1] loss: 718.982
[63,     1] loss: 635.390
[64,     1] loss: 688.140
[65,     1] loss: 587.986
[66,     1] loss: 604.570
[67,     1] loss: 588.747
[68,     1] loss: 643.363
[69,     1] loss: 728.096
[70,     1] loss: 1118.729
[71,     1] loss: 893.874
[72,     1] loss: 889.906
[73,     1] loss: 730.753
[74,     1] loss: 838.964
[75,     1] loss: 890.491
[76,     1] loss: 843.215
[77,     1] loss: 835.063
[78,     1] loss: 866.548
[79,     1] loss: 812.234
Early stopping applied (best metric=0.6617565155029297)
Finished Training
Total time taken: 12.257012605667114
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1228.677
[2,     1] loss: 1230.907
[3,     1] loss: 1228.097
[4,     1] loss: 1226.446
[5,     1] loss: 1213.812
[6,     1] loss: 1181.421
[7,     1] loss: 1135.027
[8,     1] loss: 1074.533
[9,     1] loss: 1084.489
[10,     1] loss: 1067.572
[11,     1] loss: 997.537
[12,     1] loss: 1060.555
[13,     1] loss: 1011.029
[14,     1] loss: 1015.037
[15,     1] loss: 949.677
[16,     1] loss: 962.693
[17,     1] loss: 979.706
[18,     1] loss: 995.543
[19,     1] loss: 915.482
[20,     1] loss: 990.410
[21,     1] loss: 919.486
[22,     1] loss: 929.997
[23,     1] loss: 940.439
[24,     1] loss: 881.823
[25,     1] loss: 913.902
[26,     1] loss: 928.413
[27,     1] loss: 901.441
[28,     1] loss: 880.732
[29,     1] loss: 855.936
[30,     1] loss: 864.793
[31,     1] loss: 825.718
[32,     1] loss: 889.680
[33,     1] loss: 832.893
[34,     1] loss: 826.323
[35,     1] loss: 847.022
[36,     1] loss: 791.792
[37,     1] loss: 865.360
[38,     1] loss: 801.906
[39,     1] loss: 801.211
[40,     1] loss: 793.150
[41,     1] loss: 768.367
[42,     1] loss: 768.810
[43,     1] loss: 782.807
[44,     1] loss: 686.043
[45,     1] loss: 748.014
[46,     1] loss: 793.478
[47,     1] loss: 695.376
[48,     1] loss: 707.912
[49,     1] loss: 736.510
[50,     1] loss: 701.558
[51,     1] loss: 692.306
[52,     1] loss: 731.019
Early stopping applied (best metric=0.9121888875961304)
Finished Training
Total time taken: 7.706007480621338
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1230.334
[2,     1] loss: 1231.878
[3,     1] loss: 1234.523
[4,     1] loss: 1233.592
[5,     1] loss: 1224.424
[6,     1] loss: 1225.281
[7,     1] loss: 1211.663
[8,     1] loss: 1188.786
[9,     1] loss: 1142.693
[10,     1] loss: 1106.061
[11,     1] loss: 1065.730
[12,     1] loss: 1050.307
[13,     1] loss: 1080.880
[14,     1] loss: 1031.081
[15,     1] loss: 1002.896
[16,     1] loss: 1006.412
[17,     1] loss: 1012.771
[18,     1] loss: 991.888
[19,     1] loss: 978.805
[20,     1] loss: 1003.983
[21,     1] loss: 999.528
[22,     1] loss: 948.535
[23,     1] loss: 985.244
[24,     1] loss: 949.627
[25,     1] loss: 931.064
[26,     1] loss: 990.543
[27,     1] loss: 887.261
[28,     1] loss: 913.296
[29,     1] loss: 889.176
[30,     1] loss: 928.178
[31,     1] loss: 880.106
[32,     1] loss: 857.096
[33,     1] loss: 821.256
[34,     1] loss: 905.464
[35,     1] loss: 903.503
[36,     1] loss: 832.368
[37,     1] loss: 868.370
[38,     1] loss: 829.585
[39,     1] loss: 812.062
[40,     1] loss: 793.291
[41,     1] loss: 790.683
[42,     1] loss: 800.546
[43,     1] loss: 828.390
[44,     1] loss: 767.189
[45,     1] loss: 801.317
[46,     1] loss: 740.221
[47,     1] loss: 679.909
[48,     1] loss: 708.290
[49,     1] loss: 735.035
[50,     1] loss: 799.098
[51,     1] loss: 705.917
[52,     1] loss: 692.295
[53,     1] loss: 657.932
[54,     1] loss: 676.718
[55,     1] loss: 684.963
[56,     1] loss: 672.344
[57,     1] loss: 680.532
[58,     1] loss: 619.634
[59,     1] loss: 595.236
[60,     1] loss: 833.839
[61,     1] loss: 1007.202
[62,     1] loss: 618.584
[63,     1] loss: 873.053
[64,     1] loss: 717.467
[65,     1] loss: 794.707
[66,     1] loss: 814.312
[67,     1] loss: 761.945
[68,     1] loss: 661.702
[69,     1] loss: 722.423
[70,     1] loss: 657.726
[71,     1] loss: 624.087
[72,     1] loss: 730.994
[73,     1] loss: 650.774
[74,     1] loss: 616.634
[75,     1] loss: 583.877
Early stopping applied (best metric=0.6803237199783325)
Finished Training
Total time taken: 11.792011260986328
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.212
[2,     1] loss: 1229.150
[3,     1] loss: 1227.022
[4,     1] loss: 1225.838
[5,     1] loss: 1224.286
[6,     1] loss: 1207.275
[7,     1] loss: 1171.696
[8,     1] loss: 1139.389
[9,     1] loss: 1085.026
[10,     1] loss: 1034.062
[11,     1] loss: 980.924
[12,     1] loss: 985.507
[13,     1] loss: 993.480
[14,     1] loss: 986.910
[15,     1] loss: 988.211
[16,     1] loss: 1021.888
[17,     1] loss: 957.614
[18,     1] loss: 944.892
[19,     1] loss: 965.690
[20,     1] loss: 978.945
[21,     1] loss: 945.982
[22,     1] loss: 926.392
[23,     1] loss: 914.001
[24,     1] loss: 947.168
[25,     1] loss: 906.799
[26,     1] loss: 928.413
[27,     1] loss: 862.288
[28,     1] loss: 913.470
[29,     1] loss: 886.458
[30,     1] loss: 889.978
[31,     1] loss: 839.822
[32,     1] loss: 836.443
[33,     1] loss: 848.632
[34,     1] loss: 836.459
[35,     1] loss: 827.530
[36,     1] loss: 862.842
[37,     1] loss: 784.477
[38,     1] loss: 805.450
[39,     1] loss: 794.887
[40,     1] loss: 812.996
[41,     1] loss: 777.558
[42,     1] loss: 764.759
[43,     1] loss: 741.172
[44,     1] loss: 802.475
[45,     1] loss: 687.278
[46,     1] loss: 709.109
[47,     1] loss: 720.615
[48,     1] loss: 823.640
[49,     1] loss: 849.756
[50,     1] loss: 662.989
[51,     1] loss: 843.500
[52,     1] loss: 715.852
[53,     1] loss: 814.772
Early stopping applied (best metric=0.8942421674728394)
Finished Training
Total time taken: 7.692007303237915
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1231.015
[2,     1] loss: 1232.192
[3,     1] loss: 1229.634
[4,     1] loss: 1238.596
[5,     1] loss: 1226.547
[6,     1] loss: 1223.463
[7,     1] loss: 1226.920
[8,     1] loss: 1210.156
[9,     1] loss: 1197.103
[10,     1] loss: 1165.134
[11,     1] loss: 1136.450
[12,     1] loss: 1098.558
[13,     1] loss: 1072.155
[14,     1] loss: 1072.161
[15,     1] loss: 1079.415
[16,     1] loss: 1070.925
[17,     1] loss: 1014.446
[18,     1] loss: 1019.940
[19,     1] loss: 1016.794
[20,     1] loss: 1020.244
[21,     1] loss: 986.044
[22,     1] loss: 1011.228
[23,     1] loss: 961.805
[24,     1] loss: 1006.258
[25,     1] loss: 948.644
[26,     1] loss: 958.144
[27,     1] loss: 935.345
[28,     1] loss: 937.472
[29,     1] loss: 913.494
[30,     1] loss: 880.546
[31,     1] loss: 884.076
[32,     1] loss: 949.162
[33,     1] loss: 891.119
[34,     1] loss: 884.490
[35,     1] loss: 892.099
[36,     1] loss: 862.773
[37,     1] loss: 858.765
[38,     1] loss: 859.144
[39,     1] loss: 861.267
[40,     1] loss: 832.843
[41,     1] loss: 870.027
[42,     1] loss: 808.922
[43,     1] loss: 874.452
[44,     1] loss: 807.569
[45,     1] loss: 873.547
[46,     1] loss: 787.907
[47,     1] loss: 860.912
[48,     1] loss: 801.766
[49,     1] loss: 790.179
[50,     1] loss: 794.961
[51,     1] loss: 748.546
[52,     1] loss: 876.001
[53,     1] loss: 742.727
[54,     1] loss: 797.627
[55,     1] loss: 729.651
[56,     1] loss: 711.002
[57,     1] loss: 675.750
[58,     1] loss: 695.528
[59,     1] loss: 708.341
[60,     1] loss: 696.771
[61,     1] loss: 649.293
[62,     1] loss: 695.038
[63,     1] loss: 641.020
[64,     1] loss: 628.229
[65,     1] loss: 606.408
[66,     1] loss: 599.854
[67,     1] loss: 598.868
[68,     1] loss: 632.471
[69,     1] loss: 635.673
[70,     1] loss: 612.195
[71,     1] loss: 558.312
[72,     1] loss: 560.618
[73,     1] loss: 667.605
[74,     1] loss: 934.486
[75,     1] loss: 1113.014
[76,     1] loss: 721.476
[77,     1] loss: 751.909
[78,     1] loss: 818.514
Early stopping applied (best metric=0.7606752514839172)
Finished Training
Total time taken: 11.958014965057373
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1228.255
[2,     1] loss: 1233.631
[3,     1] loss: 1231.935
[4,     1] loss: 1227.069
[5,     1] loss: 1213.737
[6,     1] loss: 1197.014
[7,     1] loss: 1175.899
[8,     1] loss: 1105.041
[9,     1] loss: 1048.938
[10,     1] loss: 1069.915
[11,     1] loss: 1065.883
[12,     1] loss: 1077.288
[13,     1] loss: 1000.376
[14,     1] loss: 1066.405
[15,     1] loss: 988.025
[16,     1] loss: 968.629
[17,     1] loss: 962.616
[18,     1] loss: 988.459
[19,     1] loss: 961.071
[20,     1] loss: 939.087
[21,     1] loss: 928.610
[22,     1] loss: 913.869
[23,     1] loss: 939.265
[24,     1] loss: 907.395
[25,     1] loss: 912.289
[26,     1] loss: 903.295
[27,     1] loss: 881.786
[28,     1] loss: 902.157
[29,     1] loss: 896.586
[30,     1] loss: 881.116
[31,     1] loss: 862.772
[32,     1] loss: 859.703
[33,     1] loss: 919.334
[34,     1] loss: 856.737
[35,     1] loss: 827.046
[36,     1] loss: 839.538
[37,     1] loss: 772.628
[38,     1] loss: 780.267
[39,     1] loss: 783.102
[40,     1] loss: 768.488
[41,     1] loss: 795.938
[42,     1] loss: 755.924
[43,     1] loss: 807.854
[44,     1] loss: 883.748
[45,     1] loss: 832.568
[46,     1] loss: 771.152
[47,     1] loss: 793.563
[48,     1] loss: 776.228
[49,     1] loss: 785.219
[50,     1] loss: 704.554
[51,     1] loss: 737.440
[52,     1] loss: 706.064
[53,     1] loss: 704.950
[54,     1] loss: 723.671
[55,     1] loss: 643.199
[56,     1] loss: 685.160
[57,     1] loss: 727.588
[58,     1] loss: 662.881
[59,     1] loss: 643.055
[60,     1] loss: 651.767
[61,     1] loss: 602.178
[62,     1] loss: 622.773
[63,     1] loss: 611.203
[64,     1] loss: 622.006
[65,     1] loss: 607.320
[66,     1] loss: 577.090
[67,     1] loss: 585.857
[68,     1] loss: 593.413
[69,     1] loss: 547.821
[70,     1] loss: 524.665
[71,     1] loss: 474.128
[72,     1] loss: 505.785
[73,     1] loss: 553.520
[74,     1] loss: 506.194
Early stopping applied (best metric=0.8373708724975586)
Finished Training
Total time taken: 10.63801121711731
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1228.891
[2,     1] loss: 1232.361
[3,     1] loss: 1234.649
[4,     1] loss: 1232.741
[5,     1] loss: 1232.631
[6,     1] loss: 1226.033
[7,     1] loss: 1223.406
[8,     1] loss: 1216.212
[9,     1] loss: 1205.236
[10,     1] loss: 1188.553
[11,     1] loss: 1149.224
[12,     1] loss: 1114.277
[13,     1] loss: 1067.787
[14,     1] loss: 1057.765
[15,     1] loss: 1037.607
[16,     1] loss: 1040.459
[17,     1] loss: 1003.972
[18,     1] loss: 1093.101
[19,     1] loss: 994.310
[20,     1] loss: 1021.386
[21,     1] loss: 1003.636
[22,     1] loss: 984.517
[23,     1] loss: 1019.544
[24,     1] loss: 1010.638
[25,     1] loss: 989.912
[26,     1] loss: 1033.655
[27,     1] loss: 973.967
[28,     1] loss: 1003.911
[29,     1] loss: 1007.944
[30,     1] loss: 959.452
[31,     1] loss: 910.788
[32,     1] loss: 969.236
[33,     1] loss: 938.634
[34,     1] loss: 934.903
[35,     1] loss: 944.224
[36,     1] loss: 891.540
[37,     1] loss: 915.420
[38,     1] loss: 876.944
[39,     1] loss: 893.631
[40,     1] loss: 878.412
[41,     1] loss: 917.556
[42,     1] loss: 850.346
[43,     1] loss: 875.362
[44,     1] loss: 831.934
[45,     1] loss: 908.725
[46,     1] loss: 807.359
[47,     1] loss: 847.985
[48,     1] loss: 784.193
[49,     1] loss: 834.373
[50,     1] loss: 775.603
[51,     1] loss: 722.950
[52,     1] loss: 722.704
[53,     1] loss: 737.138
[54,     1] loss: 714.273
[55,     1] loss: 729.362
[56,     1] loss: 799.451
[57,     1] loss: 859.956
[58,     1] loss: 735.136
[59,     1] loss: 910.209
[60,     1] loss: 766.145
[61,     1] loss: 807.770
[62,     1] loss: 795.946
[63,     1] loss: 744.980
[64,     1] loss: 776.062
[65,     1] loss: 729.921
[66,     1] loss: 667.607
[67,     1] loss: 716.134
[68,     1] loss: 686.813
Early stopping applied (best metric=0.8228600025177002)
Finished Training
Total time taken: 11.390013933181763
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1232.312
[2,     1] loss: 1231.242
[3,     1] loss: 1232.939
[4,     1] loss: 1228.466
[5,     1] loss: 1223.512
[6,     1] loss: 1205.253
[7,     1] loss: 1171.235
[8,     1] loss: 1133.782
[9,     1] loss: 1091.624
[10,     1] loss: 1064.495
[11,     1] loss: 996.104
[12,     1] loss: 1028.332
[13,     1] loss: 948.166
[14,     1] loss: 978.965
[15,     1] loss: 958.399
[16,     1] loss: 994.555
[17,     1] loss: 943.525
[18,     1] loss: 955.919
[19,     1] loss: 951.606
[20,     1] loss: 914.376
[21,     1] loss: 928.755
[22,     1] loss: 885.950
[23,     1] loss: 918.467
[24,     1] loss: 891.478
[25,     1] loss: 857.572
[26,     1] loss: 823.472
[27,     1] loss: 833.899
[28,     1] loss: 850.753
[29,     1] loss: 821.536
[30,     1] loss: 798.337
[31,     1] loss: 857.968
[32,     1] loss: 836.329
[33,     1] loss: 782.834
[34,     1] loss: 760.049
[35,     1] loss: 817.662
[36,     1] loss: 735.386
[37,     1] loss: 714.449
[38,     1] loss: 760.987
[39,     1] loss: 780.927
[40,     1] loss: 763.803
[41,     1] loss: 791.702
[42,     1] loss: 751.700
[43,     1] loss: 727.654
[44,     1] loss: 702.069
[45,     1] loss: 717.470
[46,     1] loss: 692.449
[47,     1] loss: 818.725
[48,     1] loss: 718.483
[49,     1] loss: 711.305
[50,     1] loss: 698.347
[51,     1] loss: 640.275
[52,     1] loss: 671.686
[53,     1] loss: 607.500
[54,     1] loss: 595.065
[55,     1] loss: 626.392
[56,     1] loss: 615.038
[57,     1] loss: 582.275
[58,     1] loss: 668.443
[59,     1] loss: 537.229
[60,     1] loss: 625.053
[61,     1] loss: 642.817
[62,     1] loss: 572.386
[63,     1] loss: 650.400
[64,     1] loss: 575.471
[65,     1] loss: 644.240
[66,     1] loss: 633.015
[67,     1] loss: 508.142
[68,     1] loss: 577.490
[69,     1] loss: 511.473
[70,     1] loss: 531.520
[71,     1] loss: 527.359
[72,     1] loss: 488.061
[73,     1] loss: 552.095
[74,     1] loss: 608.252
Early stopping applied (best metric=0.8296838998794556)
Finished Training
Total time taken: 12.349012613296509
{'Hydroxylation-K Validation Accuracy': 0.7617316784869976, 'Hydroxylation-K Validation Sensitivity': 0.6955555555555556, 'Hydroxylation-K Validation Specificity': 0.7789473684210526, 'Hydroxylation-K Validation Precision': 0.4481226387991094, 'Hydroxylation-K AUC ROC': 0.8046978557504874, 'Hydroxylation-K AUC PR': 0.5927246742927714, 'Hydroxylation-K MCC': 0.41290284942080113, 'Hydroxylation-K F1': 0.5400538516139539, 'Validation Loss (Hydroxylation-K)': 0.42481128374735516, 'Hydroxylation-P Validation Accuracy': 0.796640965771619, 'Hydroxylation-P Validation Sensitivity': 0.7516931216931217, 'Hydroxylation-P Validation Specificity': 0.8062447004838147, 'Hydroxylation-P Validation Precision': 0.4613596946773842, 'Hydroxylation-P AUC ROC': 0.8500508080599357, 'Hydroxylation-P AUC PR': 0.5923459095152268, 'Hydroxylation-P MCC': 0.471666800135369, 'Hydroxylation-P F1': 0.5694705837443619, 'Validation Loss (Hydroxylation-P)': 0.3724084397157033, 'Validation Loss (total)': 0.797219717502594, 'TimeToTrain': 10.843214797973634}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002645877799439393,
 'learning_rate_Hydroxylation-K': 0.002786101737443364,
 'learning_rate_Hydroxylation-P': 0.0075873402436269465,
 'log_base': 2.9834139324579465,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 698046756,
 'sample_weights': [1.5234011444390232, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.525462409677011,
 'weight_decay_Hydroxylation-K': 0.43603877839230915,
 'weight_decay_Hydroxylation-P': 3.4150714459863925}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.613
[2,     1] loss: 1227.152
[3,     1] loss: 1229.765
[4,     1] loss: 1225.553
[5,     1] loss: 1214.836
[6,     1] loss: 1196.835
[7,     1] loss: 1142.958
[8,     1] loss: 1097.083
[9,     1] loss: 1088.476
[10,     1] loss: 1046.910
[11,     1] loss: 1030.523
[12,     1] loss: 988.778
[13,     1] loss: 1040.888
[14,     1] loss: 961.242
[15,     1] loss: 996.982
[16,     1] loss: 988.318
[17,     1] loss: 955.196
[18,     1] loss: 997.223
[19,     1] loss: 951.939
[20,     1] loss: 979.369
[21,     1] loss: 936.596
[22,     1] loss: 974.352
[23,     1] loss: 960.589
[24,     1] loss: 936.233
[25,     1] loss: 902.769
[26,     1] loss: 882.672
[27,     1] loss: 877.921
[28,     1] loss: 948.256
[29,     1] loss: 846.135
[30,     1] loss: 892.702
[31,     1] loss: 868.198
[32,     1] loss: 854.316
[33,     1] loss: 831.157
[34,     1] loss: 857.630
[35,     1] loss: 830.399
[36,     1] loss: 783.870
[37,     1] loss: 784.825
[38,     1] loss: 808.322
[39,     1] loss: 766.655
[40,     1] loss: 786.245
[41,     1] loss: 820.700
[42,     1] loss: 786.261
[43,     1] loss: 724.535
[44,     1] loss: 761.441
[45,     1] loss: 881.167
[46,     1] loss: 863.194
[47,     1] loss: 785.731
[48,     1] loss: 794.054
[49,     1] loss: 741.749
[50,     1] loss: 788.634
[51,     1] loss: 736.260
[52,     1] loss: 697.050
[53,     1] loss: 793.757
[54,     1] loss: 631.908
Early stopping applied (best metric=0.8298425674438477)
Finished Training
Total time taken: 8.86000919342041
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1233.207
[2,     1] loss: 1229.655
[3,     1] loss: 1227.237
[4,     1] loss: 1230.822
[5,     1] loss: 1229.531
[6,     1] loss: 1227.902
[7,     1] loss: 1218.141
[8,     1] loss: 1205.084
[9,     1] loss: 1179.072
[10,     1] loss: 1153.223
[11,     1] loss: 1126.649
[12,     1] loss: 1121.234
[13,     1] loss: 1069.611
[14,     1] loss: 1027.926
[15,     1] loss: 1012.728
[16,     1] loss: 1028.061
[17,     1] loss: 1026.243
[18,     1] loss: 981.658
[19,     1] loss: 992.893
[20,     1] loss: 1004.672
[21,     1] loss: 993.955
[22,     1] loss: 979.435
[23,     1] loss: 994.130
[24,     1] loss: 952.261
[25,     1] loss: 969.329
[26,     1] loss: 924.430
[27,     1] loss: 920.718
[28,     1] loss: 946.864
[29,     1] loss: 933.108
[30,     1] loss: 895.557
[31,     1] loss: 867.247
[32,     1] loss: 879.683
[33,     1] loss: 899.095
[34,     1] loss: 847.066
[35,     1] loss: 850.467
[36,     1] loss: 883.037
[37,     1] loss: 848.333
[38,     1] loss: 855.184
[39,     1] loss: 856.438
[40,     1] loss: 829.212
[41,     1] loss: 820.853
[42,     1] loss: 865.989
[43,     1] loss: 812.900
[44,     1] loss: 868.733
[45,     1] loss: 843.336
[46,     1] loss: 836.629
[47,     1] loss: 785.788
[48,     1] loss: 839.071
[49,     1] loss: 777.981
[50,     1] loss: 806.157
[51,     1] loss: 758.818
[52,     1] loss: 825.985
[53,     1] loss: 743.786
[54,     1] loss: 769.192
[55,     1] loss: 717.587
[56,     1] loss: 727.517
[57,     1] loss: 799.332
[58,     1] loss: 728.831
[59,     1] loss: 713.928
[60,     1] loss: 712.519
[61,     1] loss: 717.171
[62,     1] loss: 642.465
[63,     1] loss: 731.287
[64,     1] loss: 666.126
[65,     1] loss: 728.011
[66,     1] loss: 713.655
[67,     1] loss: 685.935
[68,     1] loss: 638.872
[69,     1] loss: 667.026
[70,     1] loss: 596.256
[71,     1] loss: 623.929
[72,     1] loss: 636.622
[73,     1] loss: 702.548
[74,     1] loss: 679.668
[75,     1] loss: 676.148
[76,     1] loss: 626.469
[77,     1] loss: 591.721
[78,     1] loss: 693.488
[79,     1] loss: 607.741
[80,     1] loss: 600.718
[81,     1] loss: 696.256
[82,     1] loss: 567.473
[83,     1] loss: 657.241
[84,     1] loss: 626.612
[85,     1] loss: 563.285
[86,     1] loss: 570.385
[87,     1] loss: 582.524
[88,     1] loss: 561.741
[89,     1] loss: 544.343
[90,     1] loss: 531.127
[91,     1] loss: 515.050
[92,     1] loss: 493.917
[93,     1] loss: 529.023
[94,     1] loss: 516.957
[95,     1] loss: 497.436
[96,     1] loss: 520.916
[97,     1] loss: 450.281
[98,     1] loss: 567.249
[99,     1] loss: 549.517
[100,     1] loss: 552.128
[101,     1] loss: 498.143
[102,     1] loss: 524.137
[103,     1] loss: 541.888
[104,     1] loss: 438.686
[105,     1] loss: 503.408
[106,     1] loss: 435.956
[107,     1] loss: 413.711
[108,     1] loss: 465.423
[109,     1] loss: 558.504
[110,     1] loss: 550.857
[111,     1] loss: 432.401
[112,     1] loss: 415.207
[113,     1] loss: 504.708
[114,     1] loss: 423.145
[115,     1] loss: 561.596
[116,     1] loss: 443.557
[117,     1] loss: 481.209
[118,     1] loss: 378.965
[119,     1] loss: 454.031
[120,     1] loss: 387.961
[121,     1] loss: 428.250
[122,     1] loss: 388.248
[123,     1] loss: 475.736
[124,     1] loss: 529.504
[125,     1] loss: 385.271
[126,     1] loss: 426.450
[127,     1] loss: 379.355
[128,     1] loss: 416.844
[129,     1] loss: 373.074
[130,     1] loss: 437.113
[131,     1] loss: 364.535
[132,     1] loss: 415.334
[133,     1] loss: 396.976
[134,     1] loss: 473.231
[135,     1] loss: 448.050
[136,     1] loss: 431.593
[137,     1] loss: 401.436
[138,     1] loss: 429.627
[139,     1] loss: 439.885
[140,     1] loss: 333.103
Early stopping applied (best metric=0.5771442651748657)
Finished Training
Total time taken: 21.722020149230957
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1229.126
[2,     1] loss: 1234.295
[3,     1] loss: 1226.371
[4,     1] loss: 1229.711
[5,     1] loss: 1232.254
[6,     1] loss: 1219.261
[7,     1] loss: 1199.895
[8,     1] loss: 1177.900
[9,     1] loss: 1139.974
[10,     1] loss: 1093.458
[11,     1] loss: 1117.251
[12,     1] loss: 1069.004
[13,     1] loss: 1072.395
[14,     1] loss: 1063.047
[15,     1] loss: 1011.109
[16,     1] loss: 997.235
[17,     1] loss: 984.011
[18,     1] loss: 1012.691
[19,     1] loss: 1024.994
[20,     1] loss: 987.013
[21,     1] loss: 964.866
[22,     1] loss: 959.719
[23,     1] loss: 935.896
[24,     1] loss: 938.953
[25,     1] loss: 948.201
[26,     1] loss: 894.162
[27,     1] loss: 959.396
[28,     1] loss: 913.889
[29,     1] loss: 901.677
[30,     1] loss: 920.287
[31,     1] loss: 888.128
[32,     1] loss: 912.961
[33,     1] loss: 918.184
[34,     1] loss: 878.694
[35,     1] loss: 872.557
[36,     1] loss: 821.803
[37,     1] loss: 874.531
[38,     1] loss: 828.419
[39,     1] loss: 875.333
[40,     1] loss: 808.420
[41,     1] loss: 845.038
[42,     1] loss: 792.111
[43,     1] loss: 778.591
[44,     1] loss: 752.302
[45,     1] loss: 774.055
[46,     1] loss: 810.286
[47,     1] loss: 755.954
[48,     1] loss: 718.071
[49,     1] loss: 720.380
[50,     1] loss: 691.168
Early stopping applied (best metric=0.917669415473938)
Finished Training
Total time taken: 8.44400930404663
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1234.420
[2,     1] loss: 1232.933
[3,     1] loss: 1232.779
[4,     1] loss: 1230.212
[5,     1] loss: 1234.447
[6,     1] loss: 1227.242
[7,     1] loss: 1224.671
[8,     1] loss: 1220.936
[9,     1] loss: 1211.383
[10,     1] loss: 1196.290
[11,     1] loss: 1172.852
[12,     1] loss: 1142.105
[13,     1] loss: 1098.208
[14,     1] loss: 1065.829
[15,     1] loss: 1041.865
[16,     1] loss: 1038.325
[17,     1] loss: 1050.377
[18,     1] loss: 989.372
[19,     1] loss: 1009.967
[20,     1] loss: 999.635
[21,     1] loss: 984.568
[22,     1] loss: 957.691
[23,     1] loss: 983.057
[24,     1] loss: 948.104
[25,     1] loss: 952.795
[26,     1] loss: 967.334
[27,     1] loss: 949.551
[28,     1] loss: 967.714
[29,     1] loss: 909.839
[30,     1] loss: 913.474
[31,     1] loss: 901.023
[32,     1] loss: 909.834
[33,     1] loss: 883.459
[34,     1] loss: 904.128
[35,     1] loss: 891.603
[36,     1] loss: 911.896
[37,     1] loss: 919.690
[38,     1] loss: 881.237
[39,     1] loss: 847.516
[40,     1] loss: 877.155
[41,     1] loss: 843.007
[42,     1] loss: 821.802
[43,     1] loss: 854.242
[44,     1] loss: 791.274
[45,     1] loss: 783.092
[46,     1] loss: 866.723
[47,     1] loss: 795.987
[48,     1] loss: 909.547
[49,     1] loss: 754.210
[50,     1] loss: 850.138
[51,     1] loss: 735.632
[52,     1] loss: 769.765
[53,     1] loss: 743.874
[54,     1] loss: 757.887
[55,     1] loss: 735.994
[56,     1] loss: 763.409
[57,     1] loss: 715.374
[58,     1] loss: 661.796
[59,     1] loss: 699.887
Early stopping applied (best metric=0.7836065292358398)
Finished Training
Total time taken: 9.511009454727173
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1230.714
[2,     1] loss: 1233.081
[3,     1] loss: 1231.950
[4,     1] loss: 1229.628
[5,     1] loss: 1227.440
[6,     1] loss: 1208.528
[7,     1] loss: 1193.283
[8,     1] loss: 1160.495
[9,     1] loss: 1110.863
[10,     1] loss: 1078.330
[11,     1] loss: 1046.395
[12,     1] loss: 1017.904
[13,     1] loss: 1018.317
[14,     1] loss: 1044.163
[15,     1] loss: 1025.104
[16,     1] loss: 979.514
[17,     1] loss: 972.254
[18,     1] loss: 962.727
[19,     1] loss: 994.870
[20,     1] loss: 930.475
[21,     1] loss: 992.285
[22,     1] loss: 942.790
[23,     1] loss: 943.570
[24,     1] loss: 882.836
[25,     1] loss: 901.805
[26,     1] loss: 899.947
[27,     1] loss: 901.137
[28,     1] loss: 923.384
[29,     1] loss: 923.886
[30,     1] loss: 840.816
[31,     1] loss: 905.015
[32,     1] loss: 866.885
[33,     1] loss: 795.630
[34,     1] loss: 831.982
[35,     1] loss: 840.068
[36,     1] loss: 816.899
[37,     1] loss: 754.335
[38,     1] loss: 778.602
[39,     1] loss: 772.840
[40,     1] loss: 789.777
[41,     1] loss: 717.488
[42,     1] loss: 771.400
[43,     1] loss: 776.596
[44,     1] loss: 748.127
[45,     1] loss: 743.509
[46,     1] loss: 729.154
[47,     1] loss: 721.416
[48,     1] loss: 691.298
[49,     1] loss: 737.263
Early stopping applied (best metric=0.8201160430908203)
Finished Training
Total time taken: 6.728008270263672
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1231.713
[2,     1] loss: 1232.659
[3,     1] loss: 1230.632
[4,     1] loss: 1224.735
[5,     1] loss: 1222.049
[6,     1] loss: 1206.713
[7,     1] loss: 1210.641
[8,     1] loss: 1183.903
[9,     1] loss: 1145.048
[10,     1] loss: 1136.087
[11,     1] loss: 1119.225
[12,     1] loss: 1054.585
[13,     1] loss: 1112.033
[14,     1] loss: 1032.080
[15,     1] loss: 1035.402
[16,     1] loss: 1043.620
[17,     1] loss: 1042.812
[18,     1] loss: 993.794
[19,     1] loss: 1022.670
[20,     1] loss: 994.232
[21,     1] loss: 1010.210
[22,     1] loss: 973.014
[23,     1] loss: 983.080
[24,     1] loss: 1034.730
[25,     1] loss: 927.271
[26,     1] loss: 977.897
[27,     1] loss: 920.754
[28,     1] loss: 998.547
[29,     1] loss: 945.808
[30,     1] loss: 919.732
[31,     1] loss: 915.675
[32,     1] loss: 905.607
[33,     1] loss: 924.761
[34,     1] loss: 927.706
[35,     1] loss: 906.142
[36,     1] loss: 892.366
[37,     1] loss: 875.156
[38,     1] loss: 836.041
[39,     1] loss: 873.142
[40,     1] loss: 856.348
[41,     1] loss: 785.825
[42,     1] loss: 824.043
[43,     1] loss: 829.319
[44,     1] loss: 770.107
[45,     1] loss: 822.664
[46,     1] loss: 828.158
[47,     1] loss: 769.881
[48,     1] loss: 787.088
[49,     1] loss: 740.450
[50,     1] loss: 741.806
[51,     1] loss: 742.821
[52,     1] loss: 704.111
[53,     1] loss: 764.785
[54,     1] loss: 747.965
[55,     1] loss: 717.006
[56,     1] loss: 711.129
[57,     1] loss: 708.965
[58,     1] loss: 661.888
[59,     1] loss: 656.935
[60,     1] loss: 655.086
[61,     1] loss: 691.419
[62,     1] loss: 628.522
[63,     1] loss: 693.797
[64,     1] loss: 783.704
[65,     1] loss: 699.238
[66,     1] loss: 607.526
[67,     1] loss: 622.597
[68,     1] loss: 629.773
[69,     1] loss: 613.944
[70,     1] loss: 568.831
[71,     1] loss: 549.875
[72,     1] loss: 532.493
[73,     1] loss: 577.373
[74,     1] loss: 610.527
[75,     1] loss: 528.479
[76,     1] loss: 520.808
[77,     1] loss: 454.105
[78,     1] loss: 521.150
[79,     1] loss: 586.373
[80,     1] loss: 545.594
[81,     1] loss: 508.210
[82,     1] loss: 490.021
[83,     1] loss: 548.849
[84,     1] loss: 502.985
[85,     1] loss: 527.975
[86,     1] loss: 730.962
[87,     1] loss: 589.373
Early stopping applied (best metric=0.7334766387939453)
Finished Training
Total time taken: 13.978014707565308
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1230.475
[2,     1] loss: 1229.820
[3,     1] loss: 1229.668
[4,     1] loss: 1227.941
[5,     1] loss: 1224.526
[6,     1] loss: 1224.255
[7,     1] loss: 1212.725
[8,     1] loss: 1192.117
[9,     1] loss: 1170.772
[10,     1] loss: 1138.082
[11,     1] loss: 1080.838
[12,     1] loss: 1057.921
[13,     1] loss: 1046.887
[14,     1] loss: 1038.918
[15,     1] loss: 1013.923
[16,     1] loss: 1034.916
[17,     1] loss: 1018.937
[18,     1] loss: 975.277
[19,     1] loss: 985.697
[20,     1] loss: 966.980
[21,     1] loss: 1007.809
[22,     1] loss: 938.942
[23,     1] loss: 938.523
[24,     1] loss: 958.974
[25,     1] loss: 935.699
[26,     1] loss: 907.942
[27,     1] loss: 875.560
[28,     1] loss: 897.183
[29,     1] loss: 878.104
[30,     1] loss: 899.005
[31,     1] loss: 839.978
[32,     1] loss: 850.379
[33,     1] loss: 857.658
[34,     1] loss: 853.132
[35,     1] loss: 827.387
[36,     1] loss: 835.367
[37,     1] loss: 836.421
[38,     1] loss: 799.220
[39,     1] loss: 745.276
[40,     1] loss: 766.406
[41,     1] loss: 756.982
[42,     1] loss: 789.569
[43,     1] loss: 822.836
[44,     1] loss: 683.103
[45,     1] loss: 737.193
[46,     1] loss: 706.430
[47,     1] loss: 727.926
[48,     1] loss: 701.447
[49,     1] loss: 712.262
[50,     1] loss: 701.789
[51,     1] loss: 637.214
[52,     1] loss: 646.081
[53,     1] loss: 587.618
[54,     1] loss: 598.322
[55,     1] loss: 634.681
[56,     1] loss: 642.598
[57,     1] loss: 597.586
Early stopping applied (best metric=0.9058988690376282)
Finished Training
Total time taken: 7.902007579803467
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.887
[2,     1] loss: 1241.508
[3,     1] loss: 1230.710
[4,     1] loss: 1235.264
[5,     1] loss: 1229.094
[6,     1] loss: 1228.008
[7,     1] loss: 1228.403
[8,     1] loss: 1224.978
[9,     1] loss: 1221.180
[10,     1] loss: 1213.325
[11,     1] loss: 1200.343
[12,     1] loss: 1182.837
[13,     1] loss: 1147.205
[14,     1] loss: 1132.868
[15,     1] loss: 1103.784
[16,     1] loss: 1063.426
[17,     1] loss: 1029.070
[18,     1] loss: 989.026
[19,     1] loss: 973.888
[20,     1] loss: 1018.417
[21,     1] loss: 986.165
[22,     1] loss: 1062.673
[23,     1] loss: 962.980
[24,     1] loss: 1079.726
[25,     1] loss: 941.190
[26,     1] loss: 992.995
[27,     1] loss: 959.944
[28,     1] loss: 911.041
[29,     1] loss: 985.417
[30,     1] loss: 945.474
[31,     1] loss: 976.327
[32,     1] loss: 921.419
[33,     1] loss: 923.314
[34,     1] loss: 867.695
[35,     1] loss: 922.958
[36,     1] loss: 905.074
[37,     1] loss: 901.157
[38,     1] loss: 864.539
[39,     1] loss: 849.948
[40,     1] loss: 879.581
[41,     1] loss: 831.960
[42,     1] loss: 845.316
[43,     1] loss: 831.500
[44,     1] loss: 793.262
[45,     1] loss: 850.901
[46,     1] loss: 805.273
[47,     1] loss: 766.331
[48,     1] loss: 780.252
[49,     1] loss: 799.296
[50,     1] loss: 786.191
[51,     1] loss: 809.963
[52,     1] loss: 748.793
[53,     1] loss: 726.289
[54,     1] loss: 801.421
[55,     1] loss: 733.916
[56,     1] loss: 703.154
[57,     1] loss: 740.256
[58,     1] loss: 743.758
[59,     1] loss: 710.194
[60,     1] loss: 703.782
[61,     1] loss: 663.285
[62,     1] loss: 725.942
[63,     1] loss: 700.243
[64,     1] loss: 646.921
[65,     1] loss: 801.102
[66,     1] loss: 621.972
[67,     1] loss: 646.921
[68,     1] loss: 627.687
[69,     1] loss: 703.447
[70,     1] loss: 632.865
[71,     1] loss: 613.241
[72,     1] loss: 585.131
Early stopping applied (best metric=0.8316981792449951)
Finished Training
Total time taken: 12.114011287689209
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1240.063
[2,     1] loss: 1230.806
[3,     1] loss: 1232.521
[4,     1] loss: 1226.844
[5,     1] loss: 1229.236
[6,     1] loss: 1225.291
[7,     1] loss: 1225.161
[8,     1] loss: 1216.500
[9,     1] loss: 1207.164
[10,     1] loss: 1181.691
[11,     1] loss: 1157.518
[12,     1] loss: 1130.254
[13,     1] loss: 1076.982
[14,     1] loss: 1070.539
[15,     1] loss: 1051.094
[16,     1] loss: 1044.635
[17,     1] loss: 1055.116
[18,     1] loss: 1041.381
[19,     1] loss: 1065.642
[20,     1] loss: 986.711
[21,     1] loss: 998.959
[22,     1] loss: 987.875
[23,     1] loss: 958.140
[24,     1] loss: 985.013
[25,     1] loss: 951.950
[26,     1] loss: 938.230
[27,     1] loss: 928.369
[28,     1] loss: 943.121
[29,     1] loss: 894.202
[30,     1] loss: 906.905
[31,     1] loss: 881.445
[32,     1] loss: 903.078
[33,     1] loss: 921.417
[34,     1] loss: 865.514
[35,     1] loss: 827.889
[36,     1] loss: 834.041
[37,     1] loss: 828.594
[38,     1] loss: 829.885
[39,     1] loss: 827.497
[40,     1] loss: 769.568
[41,     1] loss: 814.357
[42,     1] loss: 832.472
[43,     1] loss: 823.646
[44,     1] loss: 702.133
Early stopping applied (best metric=0.9103752374649048)
Finished Training
Total time taken: 7.468007326126099
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1230.991
[2,     1] loss: 1229.567
[3,     1] loss: 1233.373
[4,     1] loss: 1235.979
[5,     1] loss: 1227.040
[6,     1] loss: 1222.605
[7,     1] loss: 1205.480
[8,     1] loss: 1188.191
[9,     1] loss: 1157.739
[10,     1] loss: 1126.442
[11,     1] loss: 1071.831
[12,     1] loss: 1059.617
[13,     1] loss: 1060.099
[14,     1] loss: 1042.046
[15,     1] loss: 995.453
[16,     1] loss: 1041.880
[17,     1] loss: 1049.217
[18,     1] loss: 1033.984
[19,     1] loss: 986.183
[20,     1] loss: 1014.181
[21,     1] loss: 989.497
[22,     1] loss: 1007.713
[23,     1] loss: 968.985
[24,     1] loss: 991.712
[25,     1] loss: 992.466
[26,     1] loss: 939.465
[27,     1] loss: 939.473
[28,     1] loss: 941.444
[29,     1] loss: 907.006
[30,     1] loss: 947.382
[31,     1] loss: 925.884
[32,     1] loss: 916.747
[33,     1] loss: 872.720
[34,     1] loss: 874.219
[35,     1] loss: 881.253
[36,     1] loss: 875.929
[37,     1] loss: 906.181
[38,     1] loss: 896.561
[39,     1] loss: 867.209
[40,     1] loss: 886.075
[41,     1] loss: 839.083
[42,     1] loss: 873.381
[43,     1] loss: 786.236
[44,     1] loss: 841.100
[45,     1] loss: 803.125
[46,     1] loss: 792.425
[47,     1] loss: 760.312
[48,     1] loss: 807.541
[49,     1] loss: 770.265
[50,     1] loss: 819.949
[51,     1] loss: 774.800
[52,     1] loss: 776.727
[53,     1] loss: 689.539
[54,     1] loss: 716.373
[55,     1] loss: 710.178
[56,     1] loss: 704.035
[57,     1] loss: 738.561
[58,     1] loss: 745.727
[59,     1] loss: 690.216
[60,     1] loss: 702.169
[61,     1] loss: 666.513
[62,     1] loss: 672.800
[63,     1] loss: 670.045
[64,     1] loss: 611.848
[65,     1] loss: 598.419
[66,     1] loss: 604.263
[67,     1] loss: 613.234
[68,     1] loss: 562.341
[69,     1] loss: 641.698
[70,     1] loss: 774.340
[71,     1] loss: 706.884
[72,     1] loss: 576.915
[73,     1] loss: 644.899
[74,     1] loss: 589.729
[75,     1] loss: 709.473
[76,     1] loss: 588.124
[77,     1] loss: 607.399
[78,     1] loss: 579.281
[79,     1] loss: 556.585
[80,     1] loss: 633.333
[81,     1] loss: 543.744
[82,     1] loss: 606.715
[83,     1] loss: 537.356
[84,     1] loss: 537.164
[85,     1] loss: 516.795
[86,     1] loss: 490.293
[87,     1] loss: 533.453
[88,     1] loss: 506.191
[89,     1] loss: 604.402
[90,     1] loss: 469.134
[91,     1] loss: 531.010
[92,     1] loss: 449.037
[93,     1] loss: 529.559
[94,     1] loss: 488.893
[95,     1] loss: 540.764
[96,     1] loss: 515.592
[97,     1] loss: 507.612
[98,     1] loss: 472.781
[99,     1] loss: 487.335
Early stopping applied (best metric=0.6718816757202148)
Finished Training
Total time taken: 16.622015953063965
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1232.145
[2,     1] loss: 1237.697
[3,     1] loss: 1230.385
[4,     1] loss: 1225.723
[5,     1] loss: 1231.891
[6,     1] loss: 1225.071
[7,     1] loss: 1227.148
[8,     1] loss: 1212.359
[9,     1] loss: 1192.169
[10,     1] loss: 1186.189
[11,     1] loss: 1146.170
[12,     1] loss: 1118.980
[13,     1] loss: 1099.980
[14,     1] loss: 1037.954
[15,     1] loss: 1041.235
[16,     1] loss: 1002.570
[17,     1] loss: 993.534
[18,     1] loss: 989.987
[19,     1] loss: 1016.881
[20,     1] loss: 975.125
[21,     1] loss: 995.721
[22,     1] loss: 981.443
[23,     1] loss: 993.656
[24,     1] loss: 972.141
[25,     1] loss: 967.386
[26,     1] loss: 966.487
[27,     1] loss: 980.760
[28,     1] loss: 923.170
[29,     1] loss: 927.422
[30,     1] loss: 907.488
[31,     1] loss: 876.334
[32,     1] loss: 895.771
[33,     1] loss: 926.928
[34,     1] loss: 882.118
[35,     1] loss: 840.984
[36,     1] loss: 887.482
[37,     1] loss: 875.237
[38,     1] loss: 845.578
[39,     1] loss: 856.604
[40,     1] loss: 860.007
[41,     1] loss: 809.084
[42,     1] loss: 800.925
[43,     1] loss: 840.575
[44,     1] loss: 817.586
[45,     1] loss: 787.045
[46,     1] loss: 778.753
[47,     1] loss: 780.781
[48,     1] loss: 762.733
[49,     1] loss: 762.984
[50,     1] loss: 766.697
[51,     1] loss: 758.067
[52,     1] loss: 857.591
[53,     1] loss: 746.518
[54,     1] loss: 721.136
[55,     1] loss: 819.861
[56,     1] loss: 712.858
[57,     1] loss: 733.350
[58,     1] loss: 679.156
[59,     1] loss: 709.138
[60,     1] loss: 676.737
[61,     1] loss: 742.299
[62,     1] loss: 652.594
[63,     1] loss: 688.266
[64,     1] loss: 656.793
[65,     1] loss: 705.105
[66,     1] loss: 745.902
[67,     1] loss: 603.417
[68,     1] loss: 669.153
[69,     1] loss: 609.680
[70,     1] loss: 602.761
[71,     1] loss: 592.500
[72,     1] loss: 581.731
[73,     1] loss: 589.584
[74,     1] loss: 558.517
[75,     1] loss: 629.687
[76,     1] loss: 488.518
[77,     1] loss: 532.277
[78,     1] loss: 587.489
[79,     1] loss: 531.058
[80,     1] loss: 498.525
[81,     1] loss: 510.429
[82,     1] loss: 550.630
[83,     1] loss: 496.086
[84,     1] loss: 496.837
Early stopping applied (best metric=0.7823565602302551)
Finished Training
Total time taken: 12.531012773513794
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1246.486
[2,     1] loss: 1234.900
[3,     1] loss: 1226.700
[4,     1] loss: 1233.665
[5,     1] loss: 1227.810
[6,     1] loss: 1226.878
[7,     1] loss: 1222.859
[8,     1] loss: 1223.462
[9,     1] loss: 1212.447
[10,     1] loss: 1188.736
[11,     1] loss: 1159.227
[12,     1] loss: 1140.386
[13,     1] loss: 1117.754
[14,     1] loss: 1085.828
[15,     1] loss: 1030.870
[16,     1] loss: 1046.593
[17,     1] loss: 1058.113
[18,     1] loss: 1027.485
[19,     1] loss: 1004.891
[20,     1] loss: 985.908
[21,     1] loss: 1029.954
[22,     1] loss: 985.668
[23,     1] loss: 1009.832
[24,     1] loss: 966.392
[25,     1] loss: 995.352
[26,     1] loss: 950.549
[27,     1] loss: 961.835
[28,     1] loss: 935.548
[29,     1] loss: 950.429
[30,     1] loss: 932.695
[31,     1] loss: 917.546
[32,     1] loss: 911.745
[33,     1] loss: 883.216
[34,     1] loss: 863.406
[35,     1] loss: 905.024
[36,     1] loss: 873.487
[37,     1] loss: 835.292
[38,     1] loss: 859.592
[39,     1] loss: 899.483
[40,     1] loss: 789.387
[41,     1] loss: 856.470
[42,     1] loss: 836.435
[43,     1] loss: 818.297
[44,     1] loss: 863.297
[45,     1] loss: 820.553
[46,     1] loss: 862.497
[47,     1] loss: 774.720
[48,     1] loss: 825.437
[49,     1] loss: 721.582
[50,     1] loss: 779.442
[51,     1] loss: 756.067
[52,     1] loss: 841.202
[53,     1] loss: 733.504
[54,     1] loss: 800.823
[55,     1] loss: 743.181
[56,     1] loss: 811.395
[57,     1] loss: 701.714
[58,     1] loss: 741.025
[59,     1] loss: 681.445
[60,     1] loss: 709.096
[61,     1] loss: 672.983
[62,     1] loss: 641.797
[63,     1] loss: 641.786
[64,     1] loss: 658.719
[65,     1] loss: 614.835
[66,     1] loss: 612.058
[67,     1] loss: 638.017
[68,     1] loss: 554.246
[69,     1] loss: 594.494
[70,     1] loss: 584.813
[71,     1] loss: 620.741
[72,     1] loss: 566.051
[73,     1] loss: 570.437
[74,     1] loss: 590.104
[75,     1] loss: 531.976
[76,     1] loss: 554.234
[77,     1] loss: 618.307
[78,     1] loss: 586.455
[79,     1] loss: 530.320
[80,     1] loss: 596.358
[81,     1] loss: 582.780
[82,     1] loss: 524.388
[83,     1] loss: 555.396
[84,     1] loss: 605.272
[85,     1] loss: 481.833
[86,     1] loss: 544.875
[87,     1] loss: 497.115
[88,     1] loss: 646.067
[89,     1] loss: 522.115
[90,     1] loss: 529.547
[91,     1] loss: 516.309
[92,     1] loss: 525.988
[93,     1] loss: 471.939
[94,     1] loss: 477.657
[95,     1] loss: 489.128
[96,     1] loss: 449.789
Early stopping applied (best metric=0.6893208026885986)
Finished Training
Total time taken: 13.376012563705444
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1228.283
[2,     1] loss: 1233.789
[3,     1] loss: 1232.288
[4,     1] loss: 1225.036
[5,     1] loss: 1221.360
[6,     1] loss: 1203.880
[7,     1] loss: 1172.148
[8,     1] loss: 1137.518
[9,     1] loss: 1114.124
[10,     1] loss: 1074.397
[11,     1] loss: 1042.694
[12,     1] loss: 1069.221
[13,     1] loss: 1051.312
[14,     1] loss: 1039.195
[15,     1] loss: 1001.706
[16,     1] loss: 989.747
[17,     1] loss: 992.015
[18,     1] loss: 998.213
[19,     1] loss: 983.491
[20,     1] loss: 970.890
[21,     1] loss: 987.778
[22,     1] loss: 949.606
[23,     1] loss: 927.104
[24,     1] loss: 951.347
[25,     1] loss: 952.040
[26,     1] loss: 926.689
[27,     1] loss: 953.166
[28,     1] loss: 902.300
[29,     1] loss: 924.518
[30,     1] loss: 890.835
[31,     1] loss: 870.652
[32,     1] loss: 845.632
[33,     1] loss: 850.962
[34,     1] loss: 847.672
[35,     1] loss: 848.351
[36,     1] loss: 825.868
[37,     1] loss: 850.718
[38,     1] loss: 816.614
[39,     1] loss: 849.057
[40,     1] loss: 755.485
[41,     1] loss: 840.005
[42,     1] loss: 802.906
[43,     1] loss: 741.489
[44,     1] loss: 818.314
[45,     1] loss: 713.480
[46,     1] loss: 771.512
[47,     1] loss: 709.796
[48,     1] loss: 788.820
[49,     1] loss: 703.380
[50,     1] loss: 766.290
[51,     1] loss: 702.424
[52,     1] loss: 796.038
[53,     1] loss: 680.334
[54,     1] loss: 743.931
[55,     1] loss: 691.295
[56,     1] loss: 694.918
Early stopping applied (best metric=0.7516888380050659)
Finished Training
Total time taken: 8.357008934020996
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1237.004
[2,     1] loss: 1235.095
[3,     1] loss: 1229.086
[4,     1] loss: 1232.735
[5,     1] loss: 1230.909
[6,     1] loss: 1228.692
[7,     1] loss: 1229.519
[8,     1] loss: 1227.580
[9,     1] loss: 1219.379
[10,     1] loss: 1213.854
[11,     1] loss: 1206.421
[12,     1] loss: 1183.385
[13,     1] loss: 1152.892
[14,     1] loss: 1108.753
[15,     1] loss: 1084.609
[16,     1] loss: 1050.093
[17,     1] loss: 1039.255
[18,     1] loss: 1067.935
[19,     1] loss: 1035.537
[20,     1] loss: 1052.118
[21,     1] loss: 1031.111
[22,     1] loss: 977.797
[23,     1] loss: 987.011
[24,     1] loss: 969.784
[25,     1] loss: 974.232
[26,     1] loss: 1005.155
[27,     1] loss: 984.630
[28,     1] loss: 1000.199
[29,     1] loss: 962.794
[30,     1] loss: 930.236
[31,     1] loss: 955.032
[32,     1] loss: 942.736
[33,     1] loss: 894.902
[34,     1] loss: 871.260
[35,     1] loss: 850.421
[36,     1] loss: 885.185
[37,     1] loss: 913.367
[38,     1] loss: 868.032
[39,     1] loss: 884.838
[40,     1] loss: 846.928
[41,     1] loss: 849.578
[42,     1] loss: 825.413
[43,     1] loss: 814.146
[44,     1] loss: 818.523
[45,     1] loss: 831.617
[46,     1] loss: 842.363
[47,     1] loss: 769.701
[48,     1] loss: 777.304
[49,     1] loss: 797.193
[50,     1] loss: 750.132
[51,     1] loss: 814.865
[52,     1] loss: 784.711
[53,     1] loss: 738.466
[54,     1] loss: 779.405
[55,     1] loss: 698.539
[56,     1] loss: 715.541
[57,     1] loss: 690.638
[58,     1] loss: 725.951
[59,     1] loss: 645.330
Early stopping applied (best metric=0.8167185187339783)
Finished Training
Total time taken: 9.832011461257935
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1236.794
[2,     1] loss: 1234.433
[3,     1] loss: 1231.314
[4,     1] loss: 1232.527
[5,     1] loss: 1232.564
[6,     1] loss: 1226.101
[7,     1] loss: 1223.275
[8,     1] loss: 1215.270
[9,     1] loss: 1210.941
[10,     1] loss: 1192.644
[11,     1] loss: 1166.218
[12,     1] loss: 1139.602
[13,     1] loss: 1116.642
[14,     1] loss: 1057.261
[15,     1] loss: 1072.666
[16,     1] loss: 1077.126
[17,     1] loss: 1066.883
[18,     1] loss: 1026.510
[19,     1] loss: 1019.092
[20,     1] loss: 1039.428
[21,     1] loss: 1012.260
[22,     1] loss: 996.468
[23,     1] loss: 983.350
[24,     1] loss: 989.052
[25,     1] loss: 970.307
[26,     1] loss: 966.387
[27,     1] loss: 938.200
[28,     1] loss: 964.564
[29,     1] loss: 992.722
[30,     1] loss: 990.750
[31,     1] loss: 978.520
[32,     1] loss: 916.869
[33,     1] loss: 957.280
[34,     1] loss: 902.313
[35,     1] loss: 930.461
[36,     1] loss: 883.672
[37,     1] loss: 912.733
[38,     1] loss: 917.973
[39,     1] loss: 930.740
[40,     1] loss: 899.880
[41,     1] loss: 881.216
[42,     1] loss: 894.022
[43,     1] loss: 877.098
[44,     1] loss: 850.876
[45,     1] loss: 837.502
[46,     1] loss: 805.617
[47,     1] loss: 838.955
[48,     1] loss: 819.830
[49,     1] loss: 897.508
[50,     1] loss: 793.851
[51,     1] loss: 817.718
[52,     1] loss: 784.499
[53,     1] loss: 804.952
[54,     1] loss: 779.502
[55,     1] loss: 797.217
[56,     1] loss: 799.172
[57,     1] loss: 756.264
[58,     1] loss: 770.760
[59,     1] loss: 782.273
[60,     1] loss: 746.463
[61,     1] loss: 668.703
[62,     1] loss: 740.373
[63,     1] loss: 689.467
[64,     1] loss: 647.184
[65,     1] loss: 712.042
[66,     1] loss: 592.107
[67,     1] loss: 636.488
[68,     1] loss: 650.497
[69,     1] loss: 641.743
[70,     1] loss: 651.302
[71,     1] loss: 635.070
[72,     1] loss: 579.009
[73,     1] loss: 596.953
[74,     1] loss: 585.563
[75,     1] loss: 541.563
[76,     1] loss: 572.403
[77,     1] loss: 534.010
[78,     1] loss: 631.120
[79,     1] loss: 961.098
[80,     1] loss: 915.873
[81,     1] loss: 683.469
[82,     1] loss: 695.381
Early stopping applied (best metric=0.6602417230606079)
Finished Training
Total time taken: 13.25701355934143
{'Hydroxylation-K Validation Accuracy': 0.7856973995271868, 'Hydroxylation-K Validation Sensitivity': 0.7074074074074074, 'Hydroxylation-K Validation Specificity': 0.8052631578947368, 'Hydroxylation-K Validation Precision': 0.4902490249165441, 'Hydroxylation-K AUC ROC': 0.8266276803118908, 'Hydroxylation-K AUC PR': 0.600366973847703, 'Hydroxylation-K MCC': 0.4561893436705147, 'Hydroxylation-K F1': 0.574107932861556, 'Validation Loss (Hydroxylation-K)': 0.40594164927800497, 'Hydroxylation-P Validation Accuracy': 0.7972977513831785, 'Hydroxylation-P Validation Sensitivity': 0.7576719576719577, 'Hydroxylation-P Validation Specificity': 0.805838196418774, 'Hydroxylation-P Validation Precision': 0.46538255152433144, 'Hydroxylation-P AUC ROC': 0.8492490818130501, 'Hydroxylation-P AUC PR': 0.5988836592382907, 'Hydroxylation-P MCC': 0.47720122748442567, 'Hydroxylation-P F1': 0.5713590354387899, 'Validation Loss (Hydroxylation-P)': 0.3728607436021169, 'Validation Loss (total)': 0.7788023908933004, 'TimeToTrain': 11.380144834518433}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00568183099997084,
 'learning_rate_Hydroxylation-K': 0.009165649303551873,
 'learning_rate_Hydroxylation-P': 0.0053260651753274536,
 'log_base': 2.7476986930105594,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 427741616,
 'sample_weights': [1.5284329435223725, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.117140189778664,
 'weight_decay_Hydroxylation-K': 3.948483622345276,
 'weight_decay_Hydroxylation-P': 2.024680556724322}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1261.003
[2,     1] loss: 1256.575
[3,     1] loss: 1260.899
[4,     1] loss: 1255.849
[5,     1] loss: 1255.613
[6,     1] loss: 1248.278
[7,     1] loss: 1244.803
[8,     1] loss: 1224.573
[9,     1] loss: 1187.417
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006073557055323171,
 'learning_rate_Hydroxylation-K': 0.005714706843598426,
 'learning_rate_Hydroxylation-P': 0.009036738365214394,
 'log_base': 2.6786668279891175,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3451242740,
 'sample_weights': [1.65166508292689, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.053821552820972,
 'weight_decay_Hydroxylation-K': 4.4784067512692705,
 'weight_decay_Hydroxylation-P': 8.401379989271192}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1266.809
[2,     1] loss: 1266.749
[3,     1] loss: 1263.900
[4,     1] loss: 1265.552
[5,     1] loss: 1263.502
[6,     1] loss: 1264.057
[7,     1] loss: 1263.317
[8,     1] loss: 1263.880
[9,     1] loss: 1263.936
[10,     1] loss: 1261.222
[11,     1] loss: 1261.013
[12,     1] loss: 1260.004
[13,     1] loss: 1259.078
[14,     1] loss: 1254.138
[15,     1] loss: 1254.568
[16,     1] loss: 1253.497
[17,     1] loss: 1246.486
[18,     1] loss: 1239.476
[19,     1] loss: 1234.390
[20,     1] loss: 1221.514
[21,     1] loss: 1213.334
[22,     1] loss: 1185.894
[23,     1] loss: 1162.896
[24,     1] loss: 1145.088
[25,     1] loss: 1138.099
[26,     1] loss: 1127.472
[27,     1] loss: 1128.868
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004348384839332659,
 'learning_rate_Hydroxylation-K': 0.00229603342058667,
 'learning_rate_Hydroxylation-P': 0.0067732427464406286,
 'log_base': 2.701423366759345,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1606353360,
 'sample_weights': [1.6943170457479557, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.219439467751028,
 'weight_decay_Hydroxylation-K': 0.9559460053521939,
 'weight_decay_Hydroxylation-P': 3.7764548812124894}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1263.153
[2,     1] loss: 1273.283
[3,     1] loss: 1266.495
[4,     1] loss: 1258.694
[5,     1] loss: 1256.873
[6,     1] loss: 1259.382
[7,     1] loss: 1247.959
[8,     1] loss: 1229.273
[9,     1] loss: 1208.662
[10,     1] loss: 1156.778
[11,     1] loss: 1112.313
[12,     1] loss: 1077.625
[13,     1] loss: 1078.102
[14,     1] loss: 1110.001
[15,     1] loss: 1028.145
[16,     1] loss: 1031.068
[17,     1] loss: 1081.397
[18,     1] loss: 1040.518
[19,     1] loss: 1040.104
[20,     1] loss: 1019.525
[21,     1] loss: 986.366
[22,     1] loss: 1033.302
[23,     1] loss: 988.553
[24,     1] loss: 955.178
[25,     1] loss: 958.623
[26,     1] loss: 961.775
[27,     1] loss: 929.435
[28,     1] loss: 969.454
[29,     1] loss: 961.143
[30,     1] loss: 914.135
[31,     1] loss: 946.060
[32,     1] loss: 864.684
[33,     1] loss: 894.200
[34,     1] loss: 865.434
[35,     1] loss: 833.017
[36,     1] loss: 897.555
[37,     1] loss: 835.452
[38,     1] loss: 839.519
[39,     1] loss: 829.195
[40,     1] loss: 841.588
[41,     1] loss: 834.896
[42,     1] loss: 803.176
[43,     1] loss: 768.821
[44,     1] loss: 752.650
[45,     1] loss: 713.081
[46,     1] loss: 788.739
[47,     1] loss: 795.383
[48,     1] loss: 1006.309
[49,     1] loss: 926.120
[50,     1] loss: 765.842
[51,     1] loss: 823.438
[52,     1] loss: 844.976
[53,     1] loss: 769.135
[54,     1] loss: 781.485
[55,     1] loss: 807.355
[56,     1] loss: 741.467
[57,     1] loss: 778.329
[58,     1] loss: 678.369
[59,     1] loss: 723.177
[60,     1] loss: 638.313
[61,     1] loss: 689.753
[62,     1] loss: 702.433
[63,     1] loss: 614.056
[64,     1] loss: 597.692
Early stopping applied (best metric=0.6959060430526733)
Finished Training
Total time taken: 9.163012266159058
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1268.765
[2,     1] loss: 1270.258
[3,     1] loss: 1264.859
[4,     1] loss: 1264.069
[5,     1] loss: 1264.016
[6,     1] loss: 1267.568
[7,     1] loss: 1261.093
[8,     1] loss: 1262.202
[9,     1] loss: 1261.931
[10,     1] loss: 1259.299
[11,     1] loss: 1255.176
[12,     1] loss: 1252.181
[13,     1] loss: 1246.647
[14,     1] loss: 1228.839
[15,     1] loss: 1196.844
[16,     1] loss: 1162.763
[17,     1] loss: 1140.158
[18,     1] loss: 1093.174
[19,     1] loss: 1087.926
[20,     1] loss: 1069.147
[21,     1] loss: 1038.561
[22,     1] loss: 1021.073
[23,     1] loss: 1016.660
[24,     1] loss: 1017.059
[25,     1] loss: 1051.286
[26,     1] loss: 1014.697
[27,     1] loss: 1032.864
[28,     1] loss: 1008.854
[29,     1] loss: 1005.057
[30,     1] loss: 971.331
[31,     1] loss: 986.372
[32,     1] loss: 941.968
[33,     1] loss: 971.129
[34,     1] loss: 922.547
[35,     1] loss: 938.041
[36,     1] loss: 941.361
[37,     1] loss: 907.281
[38,     1] loss: 912.442
[39,     1] loss: 891.833
[40,     1] loss: 875.082
[41,     1] loss: 890.960
[42,     1] loss: 870.902
[43,     1] loss: 842.167
[44,     1] loss: 818.474
[45,     1] loss: 854.399
[46,     1] loss: 773.251
[47,     1] loss: 839.391
[48,     1] loss: 784.514
[49,     1] loss: 764.643
[50,     1] loss: 760.774
[51,     1] loss: 781.224
[52,     1] loss: 1094.751
[53,     1] loss: 1009.324
[54,     1] loss: 780.873
[55,     1] loss: 889.871
[56,     1] loss: 849.271
[57,     1] loss: 814.824
[58,     1] loss: 880.039
[59,     1] loss: 774.181
[60,     1] loss: 789.225
[61,     1] loss: 759.895
[62,     1] loss: 714.633
[63,     1] loss: 772.356
[64,     1] loss: 647.123
[65,     1] loss: 685.835
[66,     1] loss: 656.384
[67,     1] loss: 660.573
[68,     1] loss: 684.317
[69,     1] loss: 671.796
[70,     1] loss: 617.883
[71,     1] loss: 611.288
[72,     1] loss: 722.470
[73,     1] loss: 648.970
[74,     1] loss: 617.252
[75,     1] loss: 612.744
Early stopping applied (best metric=0.8038884401321411)
Finished Training
Total time taken: 12.000011920928955
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1275.951
[2,     1] loss: 1289.803
[3,     1] loss: 1260.716
[4,     1] loss: 1259.697
[5,     1] loss: 1263.493
[6,     1] loss: 1268.312
[7,     1] loss: 1263.842
[8,     1] loss: 1267.081
[9,     1] loss: 1261.704
[10,     1] loss: 1261.130
[11,     1] loss: 1264.865
[12,     1] loss: 1264.549
[13,     1] loss: 1262.592
[14,     1] loss: 1264.265
[15,     1] loss: 1263.572
[16,     1] loss: 1263.536
[17,     1] loss: 1261.776
[18,     1] loss: 1259.641
[19,     1] loss: 1260.897
[20,     1] loss: 1260.274
[21,     1] loss: 1260.954
[22,     1] loss: 1258.569
[23,     1] loss: 1258.158
[24,     1] loss: 1254.203
[25,     1] loss: 1251.090
[26,     1] loss: 1246.204
[27,     1] loss: 1228.617
[28,     1] loss: 1218.607
[29,     1] loss: 1196.021
[30,     1] loss: 1171.544
[31,     1] loss: 1165.639
[32,     1] loss: 1128.517
[33,     1] loss: 1122.425
[34,     1] loss: 1093.399
[35,     1] loss: 1074.277
[36,     1] loss: 1063.544
[37,     1] loss: 1063.155
[38,     1] loss: 1078.938
[39,     1] loss: 1085.546
[40,     1] loss: 1130.984
[41,     1] loss: 1028.880
[42,     1] loss: 1021.829
[43,     1] loss: 989.964
[44,     1] loss: 1006.456
[45,     1] loss: 985.293
[46,     1] loss: 957.756
[47,     1] loss: 960.765
[48,     1] loss: 937.669
[49,     1] loss: 960.420
[50,     1] loss: 948.893
[51,     1] loss: 918.921
[52,     1] loss: 914.656
[53,     1] loss: 941.944
[54,     1] loss: 948.315
Early stopping applied (best metric=0.8296476602554321)
Finished Training
Total time taken: 8.528007984161377
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1261.161
[2,     1] loss: 1265.076
[3,     1] loss: 1267.054
[4,     1] loss: 1262.470
[5,     1] loss: 1256.191
[6,     1] loss: 1256.023
[7,     1] loss: 1227.584
[8,     1] loss: 1206.960
[9,     1] loss: 1189.022
[10,     1] loss: 1105.351
[11,     1] loss: 1135.677
[12,     1] loss: 1111.938
[13,     1] loss: 1126.674
[14,     1] loss: 1070.956
[15,     1] loss: 1075.405
[16,     1] loss: 1058.746
[17,     1] loss: 1029.089
[18,     1] loss: 1021.938
[19,     1] loss: 1000.189
[20,     1] loss: 1012.346
[21,     1] loss: 1015.058
[22,     1] loss: 1003.603
[23,     1] loss: 979.780
[24,     1] loss: 1001.054
[25,     1] loss: 937.757
[26,     1] loss: 984.554
[27,     1] loss: 967.769
[28,     1] loss: 956.314
[29,     1] loss: 946.319
[30,     1] loss: 923.851
[31,     1] loss: 946.792
[32,     1] loss: 943.618
[33,     1] loss: 931.119
[34,     1] loss: 908.920
[35,     1] loss: 858.282
[36,     1] loss: 903.718
[37,     1] loss: 828.825
[38,     1] loss: 916.860
[39,     1] loss: 835.999
[40,     1] loss: 870.277
[41,     1] loss: 780.992
[42,     1] loss: 809.324
[43,     1] loss: 758.189
[44,     1] loss: 825.284
[45,     1] loss: 830.462
[46,     1] loss: 782.443
[47,     1] loss: 685.903
[48,     1] loss: 759.171
[49,     1] loss: 791.078
[50,     1] loss: 705.806
[51,     1] loss: 719.937
[52,     1] loss: 689.659
[53,     1] loss: 693.826
[54,     1] loss: 668.760
[55,     1] loss: 712.812
[56,     1] loss: 811.501
[57,     1] loss: 779.790
[58,     1] loss: 653.798
[59,     1] loss: 742.147
[60,     1] loss: 652.985
[61,     1] loss: 762.435
[62,     1] loss: 607.856
[63,     1] loss: 725.957
[64,     1] loss: 697.689
[65,     1] loss: 663.757
[66,     1] loss: 667.659
[67,     1] loss: 617.892
[68,     1] loss: 693.617
[69,     1] loss: 558.520
[70,     1] loss: 598.765
[71,     1] loss: 601.619
[72,     1] loss: 719.096
[73,     1] loss: 557.213
[74,     1] loss: 598.136
[75,     1] loss: 624.315
[76,     1] loss: 532.353
[77,     1] loss: 535.204
[78,     1] loss: 493.168
Early stopping applied (best metric=0.810987114906311)
Finished Training
Total time taken: 13.032013654708862
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1265.080
[2,     1] loss: 1265.439
[3,     1] loss: 1274.960
[4,     1] loss: 1262.737
[5,     1] loss: 1260.768
[6,     1] loss: 1256.528
[7,     1] loss: 1243.373
[8,     1] loss: 1209.263
[9,     1] loss: 1157.360
[10,     1] loss: 1096.224
[11,     1] loss: 1109.823
[12,     1] loss: 1130.377
[13,     1] loss: 1059.082
[14,     1] loss: 1144.243
[15,     1] loss: 1018.433
[16,     1] loss: 1056.624
[17,     1] loss: 1073.744
[18,     1] loss: 1046.402
[19,     1] loss: 1054.907
[20,     1] loss: 1038.009
[21,     1] loss: 1018.908
[22,     1] loss: 998.958
[23,     1] loss: 1013.434
[24,     1] loss: 1031.121
[25,     1] loss: 989.908
[26,     1] loss: 1017.610
[27,     1] loss: 1006.783
[28,     1] loss: 945.758
[29,     1] loss: 931.098
[30,     1] loss: 957.088
[31,     1] loss: 961.729
[32,     1] loss: 918.408
[33,     1] loss: 949.132
[34,     1] loss: 917.944
[35,     1] loss: 899.202
[36,     1] loss: 885.940
[37,     1] loss: 883.785
[38,     1] loss: 926.326
[39,     1] loss: 912.851
[40,     1] loss: 859.558
[41,     1] loss: 929.000
[42,     1] loss: 929.584
[43,     1] loss: 795.861
[44,     1] loss: 877.733
[45,     1] loss: 805.458
[46,     1] loss: 827.808
[47,     1] loss: 754.015
[48,     1] loss: 808.170
[49,     1] loss: 777.501
[50,     1] loss: 803.923
[51,     1] loss: 800.515
[52,     1] loss: 739.126
[53,     1] loss: 870.128
[54,     1] loss: 788.939
[55,     1] loss: 759.868
[56,     1] loss: 834.373
[57,     1] loss: 699.445
[58,     1] loss: 818.473
[59,     1] loss: 663.723
[60,     1] loss: 799.565
[61,     1] loss: 698.807
[62,     1] loss: 711.280
[63,     1] loss: 686.987
[64,     1] loss: 648.337
[65,     1] loss: 749.754
[66,     1] loss: 593.586
Early stopping applied (best metric=0.6841761469841003)
Finished Training
Total time taken: 9.382009267807007
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1263.934
[2,     1] loss: 1262.102
[3,     1] loss: 1267.457
[4,     1] loss: 1256.906
[5,     1] loss: 1263.851
[6,     1] loss: 1265.379
[7,     1] loss: 1257.217
[8,     1] loss: 1255.637
[9,     1] loss: 1245.570
[10,     1] loss: 1222.452
[11,     1] loss: 1200.229
[12,     1] loss: 1156.058
[13,     1] loss: 1124.595
[14,     1] loss: 1070.948
[15,     1] loss: 1054.221
[16,     1] loss: 1102.875
[17,     1] loss: 1038.685
[18,     1] loss: 1001.373
[19,     1] loss: 1047.140
[20,     1] loss: 1043.349
[21,     1] loss: 1059.484
[22,     1] loss: 1024.591
[23,     1] loss: 1016.011
[24,     1] loss: 1008.185
[25,     1] loss: 1013.795
[26,     1] loss: 1012.093
[27,     1] loss: 1008.430
[28,     1] loss: 975.943
[29,     1] loss: 952.512
[30,     1] loss: 958.791
[31,     1] loss: 946.846
[32,     1] loss: 895.293
[33,     1] loss: 963.335
[34,     1] loss: 827.516
[35,     1] loss: 927.040
[36,     1] loss: 915.602
[37,     1] loss: 889.495
[38,     1] loss: 857.295
[39,     1] loss: 846.565
[40,     1] loss: 819.367
[41,     1] loss: 798.200
[42,     1] loss: 857.951
[43,     1] loss: 792.305
[44,     1] loss: 805.190
[45,     1] loss: 740.383
[46,     1] loss: 710.565
[47,     1] loss: 750.129
[48,     1] loss: 944.865
[49,     1] loss: 1018.913
[50,     1] loss: 776.289
[51,     1] loss: 863.257
[52,     1] loss: 774.021
[53,     1] loss: 818.220
[54,     1] loss: 829.448
[55,     1] loss: 787.454
[56,     1] loss: 782.042
[57,     1] loss: 784.836
[58,     1] loss: 729.747
[59,     1] loss: 766.991
[60,     1] loss: 669.643
[61,     1] loss: 729.587
[62,     1] loss: 662.963
[63,     1] loss: 667.898
[64,     1] loss: 673.152
[65,     1] loss: 702.971
[66,     1] loss: 620.321
[67,     1] loss: 615.432
[68,     1] loss: 583.106
[69,     1] loss: 633.550
[70,     1] loss: 648.210
[71,     1] loss: 541.611
[72,     1] loss: 609.600
[73,     1] loss: 603.412
[74,     1] loss: 550.603
[75,     1] loss: 541.320
[76,     1] loss: 532.760
[77,     1] loss: 613.660
[78,     1] loss: 588.095
[79,     1] loss: 563.037
[80,     1] loss: 497.178
Early stopping applied (best metric=0.772250771522522)
Finished Training
Total time taken: 12.967012882232666
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1263.708
[2,     1] loss: 1270.612
[3,     1] loss: 1255.879
[4,     1] loss: 1268.060
[5,     1] loss: 1262.230
[6,     1] loss: 1257.363
[7,     1] loss: 1248.455
[8,     1] loss: 1235.626
[9,     1] loss: 1203.448
[10,     1] loss: 1171.147
[11,     1] loss: 1152.747
[12,     1] loss: 1124.343
[13,     1] loss: 1139.696
[14,     1] loss: 1104.030
[15,     1] loss: 1045.671
[16,     1] loss: 1052.616
[17,     1] loss: 1111.495
[18,     1] loss: 1043.315
[19,     1] loss: 1037.160
[20,     1] loss: 1078.253
[21,     1] loss: 1002.210
[22,     1] loss: 1047.155
[23,     1] loss: 1030.099
[24,     1] loss: 1037.820
[25,     1] loss: 998.256
[26,     1] loss: 989.012
[27,     1] loss: 1004.571
[28,     1] loss: 975.713
[29,     1] loss: 975.148
[30,     1] loss: 959.920
[31,     1] loss: 931.873
[32,     1] loss: 929.973
[33,     1] loss: 911.071
[34,     1] loss: 936.715
[35,     1] loss: 896.243
[36,     1] loss: 920.814
[37,     1] loss: 972.564
[38,     1] loss: 909.774
[39,     1] loss: 911.659
[40,     1] loss: 949.749
[41,     1] loss: 891.582
[42,     1] loss: 931.570
[43,     1] loss: 911.339
[44,     1] loss: 885.443
[45,     1] loss: 895.729
[46,     1] loss: 998.775
[47,     1] loss: 835.795
[48,     1] loss: 937.160
[49,     1] loss: 838.089
[50,     1] loss: 982.776
[51,     1] loss: 805.806
[52,     1] loss: 841.569
[53,     1] loss: 857.910
[54,     1] loss: 784.863
[55,     1] loss: 836.770
[56,     1] loss: 780.007
[57,     1] loss: 882.742
[58,     1] loss: 767.179
[59,     1] loss: 832.070
[60,     1] loss: 773.422
[61,     1] loss: 755.689
[62,     1] loss: 692.703
[63,     1] loss: 797.835
[64,     1] loss: 730.160
[65,     1] loss: 709.981
[66,     1] loss: 786.278
[67,     1] loss: 666.207
[68,     1] loss: 669.158
[69,     1] loss: 696.161
[70,     1] loss: 676.098
[71,     1] loss: 660.317
[72,     1] loss: 645.134
[73,     1] loss: 707.990
[74,     1] loss: 670.009
[75,     1] loss: 608.598
[76,     1] loss: 629.151
[77,     1] loss: 668.623
[78,     1] loss: 674.187
[79,     1] loss: 607.019
[80,     1] loss: 541.838
[81,     1] loss: 646.393
[82,     1] loss: 660.225
[83,     1] loss: 542.209
[84,     1] loss: 475.515
[85,     1] loss: 536.402
[86,     1] loss: 486.226
[87,     1] loss: 556.990
[88,     1] loss: 641.889
[89,     1] loss: 597.771
[90,     1] loss: 489.792
[91,     1] loss: 539.748
Early stopping applied (best metric=0.6618658304214478)
Finished Training
Total time taken: 13.073012828826904
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1261.901
[2,     1] loss: 1277.859
[3,     1] loss: 1273.734
[4,     1] loss: 1264.083
[5,     1] loss: 1263.743
[6,     1] loss: 1262.862
[7,     1] loss: 1259.961
[8,     1] loss: 1256.501
[9,     1] loss: 1258.880
[10,     1] loss: 1254.232
[11,     1] loss: 1248.112
[12,     1] loss: 1238.443
[13,     1] loss: 1227.486
[14,     1] loss: 1189.486
[15,     1] loss: 1180.762
[16,     1] loss: 1121.415
[17,     1] loss: 1102.887
[18,     1] loss: 1080.854
[19,     1] loss: 1040.977
[20,     1] loss: 1037.663
[21,     1] loss: 1039.323
[22,     1] loss: 1015.543
[23,     1] loss: 1005.294
[24,     1] loss: 1007.120
[25,     1] loss: 1001.445
[26,     1] loss: 956.277
[27,     1] loss: 955.748
[28,     1] loss: 960.267
[29,     1] loss: 926.667
[30,     1] loss: 953.684
[31,     1] loss: 930.328
[32,     1] loss: 896.843
[33,     1] loss: 887.803
[34,     1] loss: 894.995
[35,     1] loss: 916.028
[36,     1] loss: 855.232
[37,     1] loss: 911.737
[38,     1] loss: 878.150
[39,     1] loss: 841.721
[40,     1] loss: 863.992
[41,     1] loss: 840.058
[42,     1] loss: 757.302
[43,     1] loss: 851.057
[44,     1] loss: 826.525
[45,     1] loss: 770.998
[46,     1] loss: 778.299
[47,     1] loss: 763.808
[48,     1] loss: 752.149
[49,     1] loss: 744.251
[50,     1] loss: 736.849
[51,     1] loss: 714.821
[52,     1] loss: 716.457
[53,     1] loss: 717.256
[54,     1] loss: 706.002
[55,     1] loss: 661.099
[56,     1] loss: 806.711
[57,     1] loss: 951.072
[58,     1] loss: 799.105
[59,     1] loss: 832.147
[60,     1] loss: 765.051
[61,     1] loss: 821.794
[62,     1] loss: 719.410
[63,     1] loss: 731.929
[64,     1] loss: 675.587
[65,     1] loss: 692.253
[66,     1] loss: 617.500
[67,     1] loss: 623.203
[68,     1] loss: 594.526
[69,     1] loss: 618.794
[70,     1] loss: 571.022
[71,     1] loss: 598.380
[72,     1] loss: 606.550
[73,     1] loss: 599.925
[74,     1] loss: 648.685
[75,     1] loss: 685.297
[76,     1] loss: 620.948
[77,     1] loss: 598.292
[78,     1] loss: 591.637
Early stopping applied (best metric=0.8632609844207764)
Finished Training
Total time taken: 10.97400975227356
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1266.259
[2,     1] loss: 1262.008
[3,     1] loss: 1265.258
[4,     1] loss: 1260.292
[5,     1] loss: 1257.813
[6,     1] loss: 1249.046
[7,     1] loss: 1218.137
[8,     1] loss: 1174.078
[9,     1] loss: 1112.942
[10,     1] loss: 1090.478
[11,     1] loss: 1072.726
[12,     1] loss: 1141.415
[13,     1] loss: 1054.597
[14,     1] loss: 1090.733
[15,     1] loss: 996.378
[16,     1] loss: 1068.496
[17,     1] loss: 1013.480
[18,     1] loss: 1009.498
[19,     1] loss: 984.793
[20,     1] loss: 971.961
[21,     1] loss: 975.142
[22,     1] loss: 975.115
[23,     1] loss: 977.048
[24,     1] loss: 965.789
[25,     1] loss: 924.132
[26,     1] loss: 890.403
[27,     1] loss: 933.991
[28,     1] loss: 907.251
[29,     1] loss: 927.356
[30,     1] loss: 883.128
[31,     1] loss: 916.694
[32,     1] loss: 833.164
[33,     1] loss: 855.050
[34,     1] loss: 872.954
[35,     1] loss: 856.566
[36,     1] loss: 866.768
[37,     1] loss: 828.973
[38,     1] loss: 788.353
[39,     1] loss: 801.922
[40,     1] loss: 839.704
[41,     1] loss: 827.259
[42,     1] loss: 744.291
[43,     1] loss: 783.424
[44,     1] loss: 770.108
[45,     1] loss: 764.301
[46,     1] loss: 744.493
[47,     1] loss: 758.725
[48,     1] loss: 767.038
[49,     1] loss: 679.273
[50,     1] loss: 805.098
[51,     1] loss: 832.957
[52,     1] loss: 694.024
[53,     1] loss: 744.969
[54,     1] loss: 684.495
[55,     1] loss: 665.357
[56,     1] loss: 736.925
[57,     1] loss: 645.560
[58,     1] loss: 726.466
[59,     1] loss: 635.853
[60,     1] loss: 620.924
[61,     1] loss: 743.183
[62,     1] loss: 637.276
[63,     1] loss: 543.148
[64,     1] loss: 590.181
[65,     1] loss: 588.394
[66,     1] loss: 666.353
[67,     1] loss: 677.730
[68,     1] loss: 570.093
[69,     1] loss: 843.852
[70,     1] loss: 558.742
[71,     1] loss: 751.523
[72,     1] loss: 547.906
[73,     1] loss: 606.250
[74,     1] loss: 538.382
[75,     1] loss: 594.596
[76,     1] loss: 507.475
[77,     1] loss: 594.918
[78,     1] loss: 485.762
[79,     1] loss: 529.180
[80,     1] loss: 486.909
Early stopping applied (best metric=0.7239600419998169)
Finished Training
Total time taken: 12.096012115478516
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1265.840
[2,     1] loss: 1274.553
[3,     1] loss: 1269.317
[4,     1] loss: 1268.282
[5,     1] loss: 1268.383
[6,     1] loss: 1264.592
[7,     1] loss: 1261.257
[8,     1] loss: 1257.283
[9,     1] loss: 1257.895
[10,     1] loss: 1251.225
[11,     1] loss: 1237.922
[12,     1] loss: 1215.886
[13,     1] loss: 1209.603
[14,     1] loss: 1164.212
[15,     1] loss: 1142.881
[16,     1] loss: 1107.092
[17,     1] loss: 1072.777
[18,     1] loss: 1112.710
[19,     1] loss: 1086.841
[20,     1] loss: 1043.608
[21,     1] loss: 1070.976
[22,     1] loss: 998.474
[23,     1] loss: 1024.573
[24,     1] loss: 1030.615
[25,     1] loss: 1024.457
[26,     1] loss: 1017.797
[27,     1] loss: 991.278
[28,     1] loss: 953.876
[29,     1] loss: 960.478
[30,     1] loss: 931.370
[31,     1] loss: 971.068
[32,     1] loss: 951.892
[33,     1] loss: 923.988
[34,     1] loss: 939.526
[35,     1] loss: 857.378
[36,     1] loss: 872.205
[37,     1] loss: 891.716
[38,     1] loss: 873.116
[39,     1] loss: 915.903
[40,     1] loss: 822.624
[41,     1] loss: 796.815
[42,     1] loss: 821.475
[43,     1] loss: 777.819
[44,     1] loss: 862.360
[45,     1] loss: 839.146
[46,     1] loss: 887.232
[47,     1] loss: 787.478
[48,     1] loss: 751.765
[49,     1] loss: 733.460
[50,     1] loss: 764.167
[51,     1] loss: 809.491
[52,     1] loss: 730.971
[53,     1] loss: 738.494
[54,     1] loss: 668.090
[55,     1] loss: 721.789
[56,     1] loss: 680.416
[57,     1] loss: 654.418
[58,     1] loss: 619.450
[59,     1] loss: 732.628
[60,     1] loss: 831.535
[61,     1] loss: 713.191
[62,     1] loss: 731.160
[63,     1] loss: 670.371
[64,     1] loss: 699.745
[65,     1] loss: 704.510
[66,     1] loss: 649.630
[67,     1] loss: 616.988
[68,     1] loss: 666.272
Early stopping applied (best metric=0.8942922353744507)
Finished Training
Total time taken: 11.11600947380066
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1265.637
[2,     1] loss: 1270.812
[3,     1] loss: 1264.405
[4,     1] loss: 1260.963
[5,     1] loss: 1260.873
[6,     1] loss: 1262.385
[7,     1] loss: 1260.530
[8,     1] loss: 1252.365
[9,     1] loss: 1254.513
[10,     1] loss: 1235.630
[11,     1] loss: 1210.686
[12,     1] loss: 1179.868
[13,     1] loss: 1159.452
[14,     1] loss: 1101.394
[15,     1] loss: 1073.181
[16,     1] loss: 1059.504
[17,     1] loss: 1075.791
[18,     1] loss: 1046.382
[19,     1] loss: 1032.753
[20,     1] loss: 1039.309
[21,     1] loss: 1021.349
[22,     1] loss: 1088.936
[23,     1] loss: 1018.491
[24,     1] loss: 1000.943
[25,     1] loss: 983.075
[26,     1] loss: 1004.439
[27,     1] loss: 952.503
[28,     1] loss: 999.164
[29,     1] loss: 982.771
[30,     1] loss: 1023.729
[31,     1] loss: 937.686
[32,     1] loss: 955.464
[33,     1] loss: 976.521
[34,     1] loss: 930.613
[35,     1] loss: 928.536
[36,     1] loss: 853.087
[37,     1] loss: 892.044
[38,     1] loss: 921.823
[39,     1] loss: 836.770
[40,     1] loss: 838.612
[41,     1] loss: 854.168
[42,     1] loss: 814.997
[43,     1] loss: 787.489
[44,     1] loss: 840.486
[45,     1] loss: 760.196
[46,     1] loss: 776.852
[47,     1] loss: 879.107
[48,     1] loss: 1085.160
[49,     1] loss: 828.878
[50,     1] loss: 898.136
[51,     1] loss: 831.043
[52,     1] loss: 952.948
[53,     1] loss: 908.108
[54,     1] loss: 814.603
[55,     1] loss: 837.834
[56,     1] loss: 851.166
[57,     1] loss: 834.005
[58,     1] loss: 835.442
[59,     1] loss: 770.332
[60,     1] loss: 776.779
[61,     1] loss: 798.898
[62,     1] loss: 681.814
[63,     1] loss: 774.293
[64,     1] loss: 727.833
Early stopping applied (best metric=0.6952763795852661)
Finished Training
Total time taken: 9.536009550094604
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1267.958
[2,     1] loss: 1265.343
[3,     1] loss: 1265.925
[4,     1] loss: 1257.799
[5,     1] loss: 1263.696
[6,     1] loss: 1254.750
[7,     1] loss: 1252.491
[8,     1] loss: 1224.644
[9,     1] loss: 1194.264
[10,     1] loss: 1149.680
[11,     1] loss: 1112.981
[12,     1] loss: 1040.109
[13,     1] loss: 1072.462
[14,     1] loss: 1130.601
[15,     1] loss: 1090.659
[16,     1] loss: 1052.633
[17,     1] loss: 1014.433
[18,     1] loss: 996.826
[19,     1] loss: 1035.554
[20,     1] loss: 1031.301
[21,     1] loss: 999.722
[22,     1] loss: 990.885
[23,     1] loss: 994.503
[24,     1] loss: 986.140
[25,     1] loss: 990.466
[26,     1] loss: 977.075
[27,     1] loss: 948.678
[28,     1] loss: 962.342
[29,     1] loss: 892.267
[30,     1] loss: 952.228
[31,     1] loss: 913.415
[32,     1] loss: 902.402
[33,     1] loss: 896.219
[34,     1] loss: 911.523
[35,     1] loss: 901.639
[36,     1] loss: 899.508
[37,     1] loss: 879.968
[38,     1] loss: 847.264
[39,     1] loss: 891.092
[40,     1] loss: 870.930
[41,     1] loss: 843.147
[42,     1] loss: 806.984
[43,     1] loss: 834.946
[44,     1] loss: 823.508
[45,     1] loss: 818.554
[46,     1] loss: 809.038
[47,     1] loss: 797.504
[48,     1] loss: 820.146
[49,     1] loss: 739.332
[50,     1] loss: 703.319
[51,     1] loss: 757.122
[52,     1] loss: 785.939
[53,     1] loss: 768.018
[54,     1] loss: 721.507
[55,     1] loss: 685.430
[56,     1] loss: 752.384
[57,     1] loss: 698.076
[58,     1] loss: 760.268
[59,     1] loss: 865.311
[60,     1] loss: 688.554
[61,     1] loss: 725.082
[62,     1] loss: 689.666
[63,     1] loss: 722.425
[64,     1] loss: 720.525
[65,     1] loss: 654.886
[66,     1] loss: 665.740
[67,     1] loss: 612.537
[68,     1] loss: 731.180
Early stopping applied (best metric=0.7656578421592712)
Finished Training
Total time taken: 10.626010179519653
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1268.257
[2,     1] loss: 1267.642
[3,     1] loss: 1266.372
[4,     1] loss: 1270.115
[5,     1] loss: 1257.919
[6,     1] loss: 1258.767
[7,     1] loss: 1258.452
[8,     1] loss: 1253.422
[9,     1] loss: 1254.149
[10,     1] loss: 1245.578
[11,     1] loss: 1223.588
[12,     1] loss: 1207.955
[13,     1] loss: 1183.120
[14,     1] loss: 1168.041
[15,     1] loss: 1125.523
[16,     1] loss: 1082.279
[17,     1] loss: 1036.883
[18,     1] loss: 1003.720
[19,     1] loss: 1028.057
[20,     1] loss: 1100.674
[21,     1] loss: 1026.281
[22,     1] loss: 1045.041
[23,     1] loss: 971.041
[24,     1] loss: 1007.434
[25,     1] loss: 1004.803
[26,     1] loss: 988.426
[27,     1] loss: 975.433
[28,     1] loss: 931.966
[29,     1] loss: 935.473
[30,     1] loss: 944.990
[31,     1] loss: 942.230
[32,     1] loss: 919.209
[33,     1] loss: 923.146
[34,     1] loss: 896.965
[35,     1] loss: 903.617
[36,     1] loss: 903.336
[37,     1] loss: 931.437
[38,     1] loss: 879.706
[39,     1] loss: 884.656
[40,     1] loss: 839.946
[41,     1] loss: 868.635
[42,     1] loss: 814.524
[43,     1] loss: 867.552
Early stopping applied (best metric=0.9722680449485779)
Finished Training
Total time taken: 7.1490068435668945
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1266.679
[2,     1] loss: 1271.835
[3,     1] loss: 1264.680
[4,     1] loss: 1257.044
[5,     1] loss: 1262.900
[6,     1] loss: 1251.076
[7,     1] loss: 1236.395
[8,     1] loss: 1204.027
[9,     1] loss: 1184.565
[10,     1] loss: 1136.909
[11,     1] loss: 1082.356
[12,     1] loss: 1097.926
[13,     1] loss: 1045.689
[14,     1] loss: 1065.443
[15,     1] loss: 1032.828
[16,     1] loss: 1031.540
[17,     1] loss: 992.763
[18,     1] loss: 1005.229
[19,     1] loss: 972.620
[20,     1] loss: 1016.120
[21,     1] loss: 967.253
[22,     1] loss: 919.578
[23,     1] loss: 942.620
[24,     1] loss: 922.287
[25,     1] loss: 912.270
[26,     1] loss: 906.201
[27,     1] loss: 920.861
[28,     1] loss: 903.125
[29,     1] loss: 912.655
[30,     1] loss: 889.869
Early stopping applied (best metric=0.9294344186782837)
Finished Training
Total time taken: 5.078004598617554
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1261.616
[2,     1] loss: 1275.113
[3,     1] loss: 1262.951
[4,     1] loss: 1272.453
[5,     1] loss: 1251.065
[6,     1] loss: 1242.634
[7,     1] loss: 1212.234
[8,     1] loss: 1147.880
[9,     1] loss: 1104.682
[10,     1] loss: 1087.091
[11,     1] loss: 1105.020
[12,     1] loss: 1126.034
[13,     1] loss: 1063.200
[14,     1] loss: 1063.781
[15,     1] loss: 1031.450
[16,     1] loss: 1039.820
[17,     1] loss: 1046.284
[18,     1] loss: 1003.738
[19,     1] loss: 995.367
[20,     1] loss: 992.073
[21,     1] loss: 986.801
[22,     1] loss: 963.616
[23,     1] loss: 991.570
[24,     1] loss: 962.383
[25,     1] loss: 942.940
[26,     1] loss: 926.471
[27,     1] loss: 926.962
[28,     1] loss: 892.751
[29,     1] loss: 949.522
[30,     1] loss: 929.108
[31,     1] loss: 946.856
[32,     1] loss: 904.902
[33,     1] loss: 897.817
[34,     1] loss: 863.701
[35,     1] loss: 925.977
[36,     1] loss: 852.522
[37,     1] loss: 866.576
[38,     1] loss: 810.529
[39,     1] loss: 812.915
[40,     1] loss: 838.220
[41,     1] loss: 832.410
[42,     1] loss: 796.625
[43,     1] loss: 829.476
[44,     1] loss: 791.214
[45,     1] loss: 818.146
[46,     1] loss: 796.662
[47,     1] loss: 729.748
[48,     1] loss: 785.957
[49,     1] loss: 940.439
[50,     1] loss: 868.905
[51,     1] loss: 742.526
[52,     1] loss: 832.849
[53,     1] loss: 760.049
[54,     1] loss: 767.601
[55,     1] loss: 740.293
[56,     1] loss: 767.409
[57,     1] loss: 746.173
[58,     1] loss: 713.737
[59,     1] loss: 661.957
[60,     1] loss: 710.907
[61,     1] loss: 644.468
[62,     1] loss: 715.426
[63,     1] loss: 658.699
[64,     1] loss: 659.391
[65,     1] loss: 643.977
Early stopping applied (best metric=0.7588170766830444)
Finished Training
Total time taken: 9.71200942993164
{'Hydroxylation-K Validation Accuracy': 0.7671985815602836, 'Hydroxylation-K Validation Sensitivity': 0.6733333333333333, 'Hydroxylation-K Validation Specificity': 0.7912280701754386, 'Hydroxylation-K Validation Precision': 0.4677341260141772, 'Hydroxylation-K AUC ROC': 0.819775828460039, 'Hydroxylation-K AUC PR': 0.6331780066829367, 'Hydroxylation-K MCC': 0.41554748455592067, 'Hydroxylation-K F1': 0.5446086468550236, 'Validation Loss (Hydroxylation-K)': 0.41061677734057106, 'Hydroxylation-P Validation Accuracy': 0.7661301625974992, 'Hydroxylation-P Validation Sensitivity': 0.7782539682539683, 'Hydroxylation-P Validation Specificity': 0.7635542919846376, 'Hydroxylation-P Validation Precision': 0.4226112336749205, 'Hydroxylation-P AUC ROC': 0.8417818210463729, 'Hydroxylation-P AUC PR': 0.5864695187771407, 'Hydroxylation-P MCC': 0.4438324436973565, 'Hydroxylation-P F1': 0.5442045578787884, 'Validation Loss (Hydroxylation-P)': 0.38016248544057213, 'Validation Loss (total)': 0.7907792687416076, 'TimeToTrain': 10.295476849873861}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016585869186946153,
 'learning_rate_Hydroxylation-K': 0.002542148641612252,
 'learning_rate_Hydroxylation-P': 0.004620406446383632,
 'log_base': 2.6362828450929716,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1228037766,
 'sample_weights': [1.6811402355785607, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.173593470875526,
 'weight_decay_Hydroxylation-K': 2.4349140366834825,
 'weight_decay_Hydroxylation-P': 6.509360125925017}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1271.105
[2,     1] loss: 1277.194
[3,     1] loss: 1268.178
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025759620671781595,
 'learning_rate_Hydroxylation-K': 0.009450902611843162,
 'learning_rate_Hydroxylation-P': 0.0017038760617895407,
 'log_base': 2.832658204015638,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2129014220,
 'sample_weights': [1.7221941048317508, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.690606460761731,
 'weight_decay_Hydroxylation-K': 7.2603670067984964,
 'weight_decay_Hydroxylation-P': 0.9483467580664131}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1248.034
[2,     1] loss: 1244.704
[3,     1] loss: 1248.578
[4,     1] loss: 1239.764
[5,     1] loss: 1236.784
[6,     1] loss: 1221.408
[7,     1] loss: 1201.203
[8,     1] loss: 1161.741
[9,     1] loss: 1115.254
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004902523251409488,
 'learning_rate_Hydroxylation-K': 0.003169669898374844,
 'learning_rate_Hydroxylation-P': 0.006281650004754827,
 'log_base': 2.8447555444514,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2244821215,
 'sample_weights': [1.603359767891531, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.768684931995559,
 'weight_decay_Hydroxylation-K': 1.983711267552078,
 'weight_decay_Hydroxylation-P': 4.3866117759319625}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1246.703
[2,     1] loss: 1250.700
[3,     1] loss: 1250.523
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0038941014738252486,
 'learning_rate_Hydroxylation-K': 0.0005632812062778261,
 'learning_rate_Hydroxylation-P': 0.007874701480714317,
 'log_base': 1.1570589449861632,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 882933194,
 'sample_weights': [1.5968241530345475, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.533049336715622,
 'weight_decay_Hydroxylation-K': 2.975161852521837,
 'weight_decay_Hydroxylation-P': 5.710323097902383}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 3717.542
[2,     1] loss: 3706.650
[3,     1] loss: 3708.513
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002792308831841256,
 'learning_rate_Hydroxylation-K': 0.00569457977164765,
 'learning_rate_Hydroxylation-P': 0.007743767666366303,
 'log_base': 1.563984960526206,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2853387122,
 'sample_weights': [11.443838789083488, 1.430534956463482],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 6.559706009832324,
 'weight_decay_Hydroxylation-K': 0.6872790696030684,
 'weight_decay_Hydroxylation-P': 5.222707536616953}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1708.930
[2,     1] loss: 1697.696
[3,     1] loss: 1692.001
[4,     1] loss: 1696.043
[5,     1] loss: 1702.242
[6,     1] loss: 1693.272
[7,     1] loss: 1691.506
[8,     1] loss: 1682.944
[9,     1] loss: 1676.119
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002208907883375055,
 'learning_rate_Hydroxylation-K': 0.005421006817634553,
 'learning_rate_Hydroxylation-P': 0.002781392379774981,
 'log_base': 1.8585527478806314,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1715561638,
 'sample_weights': [3.7327927926421722, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.70526710726992,
 'weight_decay_Hydroxylation-K': 7.625073769338904,
 'weight_decay_Hydroxylation-P': 7.336351279789789}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1476.182
[2,     1] loss: 1476.305
[3,     1] loss: 1475.272
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006358374971828074,
 'learning_rate_Hydroxylation-K': 0.0025931167511734805,
 'learning_rate_Hydroxylation-P': 0.00816772894734222,
 'log_base': 1.933259862847262,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1898559651,
 'sample_weights': [2.693527405325791, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.728596437199311,
 'weight_decay_Hydroxylation-K': 4.198404694088803,
 'weight_decay_Hydroxylation-P': 2.627199250396353}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1443.358
[2,     1] loss: 1445.395
[3,     1] loss: 1462.318
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014167608402813696,
 'learning_rate_Hydroxylation-K': 0.0026404334565353245,
 'learning_rate_Hydroxylation-P': 0.002519639749681979,
 'log_base': 1.4765450803862445,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2565183046,
 'sample_weights': [2.5324997483434246, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 9.115858817916108,
 'weight_decay_Hydroxylation-K': 8.934029688566367,
 'weight_decay_Hydroxylation-P': 6.744685307946449}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1814.148
[2,     1] loss: 1810.313
[3,     1] loss: 1812.522
[4,     1] loss: 1811.294
[5,     1] loss: 1805.984
[6,     1] loss: 1810.750
[7,     1] loss: 1811.210
[8,     1] loss: 1809.844
[9,     1] loss: 1799.454
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003972069607910586,
 'learning_rate_Hydroxylation-K': 0.004137268534835254,
 'learning_rate_Hydroxylation-P': 0.006485743323330098,
 'log_base': 2.147037549704868,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2306963277,
 'sample_weights': [4.283864322853654, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2829308857676485,
 'weight_decay_Hydroxylation-K': 0.2251222301928264,
 'weight_decay_Hydroxylation-P': 4.149794906008706}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1374.102
[2,     1] loss: 1366.359
[3,     1] loss: 1379.188
[4,     1] loss: 1367.815
[5,     1] loss: 1374.918
[6,     1] loss: 1375.702
[7,     1] loss: 1365.165
[8,     1] loss: 1369.883
[9,     1] loss: 1369.970
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010058833813037776,
 'learning_rate_Hydroxylation-K': 0.006315887991921903,
 'learning_rate_Hydroxylation-P': 0.006538748424862783,
 'log_base': 2.228589663665275,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2371772004,
 'sample_weights': [2.184880465061309, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2763112947603457,
 'weight_decay_Hydroxylation-K': 7.601529591548658,
 'weight_decay_Hydroxylation-P': 9.375203573623054}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1349.125
[2,     1] loss: 1349.065
[3,     1] loss: 1347.347
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006963167714087236,
 'learning_rate_Hydroxylation-K': 0.005409268597762539,
 'learning_rate_Hydroxylation-P': 0.009901712934939268,
 'log_base': 2.947981587985321,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2388917061,
 'sample_weights': [2.0832391278247613, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.43729623667657,
 'weight_decay_Hydroxylation-K': 6.777933408393366,
 'weight_decay_Hydroxylation-P': 1.464843388693179}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1236.832
[2,     1] loss: 1239.905
[3,     1] loss: 1232.284
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003438365439638079,
 'learning_rate_Hydroxylation-K': 0.0034541294603645024,
 'learning_rate_Hydroxylation-P': 0.00945430594720188,
 'log_base': 2.889479073886915,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 847088389,
 'sample_weights': [1.5441782800816268, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.5885176332519055,
 'weight_decay_Hydroxylation-K': 1.9449395931196065,
 'weight_decay_Hydroxylation-P': 4.5141950127743735}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1239.208
[2,     1] loss: 1241.781
[3,     1] loss: 1251.332
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011998094784648411,
 'learning_rate_Hydroxylation-K': 0.0016901786995630115,
 'learning_rate_Hydroxylation-P': 0.006100454204603354,
 'log_base': 2.839836612651431,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3335282635,
 'sample_weights': [1.5733489196566943, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 5.455956151184684,
 'weight_decay_Hydroxylation-K': 0.015291790369314606,
 'weight_decay_Hydroxylation-P': 2.6323948989742645}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1253.803
[2,     1] loss: 1243.885
[3,     1] loss: 1244.887
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004417912726371405,
 'learning_rate_Hydroxylation-K': 0.002280449215694833,
 'learning_rate_Hydroxylation-P': 0.0076623311433733615,
 'log_base': 2.4896417088881058,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2226224338,
 'sample_weights': [1.5994718217646908, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 2.6583147814473174,
 'weight_decay_Hydroxylation-K': 3.811632242939872,
 'weight_decay_Hydroxylation-P': 2.7195721662717647}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1298.844
[2,     1] loss: 1309.613
[3,     1] loss: 1294.528
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004191469453042392,
 'learning_rate_Hydroxylation-K': 0.006134410345648838,
 'learning_rate_Hydroxylation-P': 0.00762194038391718,
 'log_base': 2.635240913591149,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1966831935,
 'sample_weights': [1.830251199246956, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 8.87092386939323,
 'weight_decay_Hydroxylation-K': 2.1775461253662867,
 'weight_decay_Hydroxylation-P': 7.8552218699950505}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1274.653
[2,     1] loss: 1274.868
[3,     1] loss: 1271.837
[4,     1] loss: 1275.993
[5,     1] loss: 1271.013
[6,     1] loss: 1266.882
[7,     1] loss: 1261.211
[8,     1] loss: 1248.578
[9,     1] loss: 1231.805
[10,     1] loss: 1200.110
[11,     1] loss: 1163.154
[12,     1] loss: 1112.155
[13,     1] loss: 1086.228
[14,     1] loss: 1070.266
[15,     1] loss: 1045.325
[16,     1] loss: 1054.105
[17,     1] loss: 1029.450
[18,     1] loss: 951.009
[19,     1] loss: 1034.276
[20,     1] loss: 1021.516
[21,     1] loss: 961.842
[22,     1] loss: 1019.153
[23,     1] loss: 971.837
[24,     1] loss: 928.867
[25,     1] loss: 986.640
[26,     1] loss: 937.511
[27,     1] loss: 913.894
[28,     1] loss: 914.746
[29,     1] loss: 864.411
[30,     1] loss: 932.970
[31,     1] loss: 984.927
[32,     1] loss: 892.354
[33,     1] loss: 875.502
[34,     1] loss: 907.693
[35,     1] loss: 873.318
[36,     1] loss: 890.665
[37,     1] loss: 993.861
[38,     1] loss: 856.986
[39,     1] loss: 947.095
[40,     1] loss: 839.805
[41,     1] loss: 902.140
[42,     1] loss: 875.065
[43,     1] loss: 818.923
[44,     1] loss: 857.954
[45,     1] loss: 824.194
[46,     1] loss: 811.743
[47,     1] loss: 884.843
[48,     1] loss: 776.530
[49,     1] loss: 815.235
[50,     1] loss: 777.548
[51,     1] loss: 790.131
[52,     1] loss: 763.931
[53,     1] loss: 835.057
[54,     1] loss: 765.550
[55,     1] loss: 776.067
[56,     1] loss: 830.459
[57,     1] loss: 684.773
[58,     1] loss: 774.940
[59,     1] loss: 685.331
[60,     1] loss: 744.630
[61,     1] loss: 701.876
Early stopping applied (best metric=0.8446375131607056)
Finished Training
Total time taken: 9.726009845733643
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1275.112
[2,     1] loss: 1273.452
[3,     1] loss: 1272.016
[4,     1] loss: 1267.399
[5,     1] loss: 1261.628
[6,     1] loss: 1250.095
[7,     1] loss: 1230.041
[8,     1] loss: 1194.228
[9,     1] loss: 1181.863
[10,     1] loss: 1128.671
[11,     1] loss: 1173.172
[12,     1] loss: 1090.024
[13,     1] loss: 1155.536
[14,     1] loss: 1084.477
[15,     1] loss: 1093.666
[16,     1] loss: 1034.147
[17,     1] loss: 1037.583
[18,     1] loss: 1062.324
[19,     1] loss: 1008.996
[20,     1] loss: 1007.710
[21,     1] loss: 1026.371
[22,     1] loss: 1013.922
[23,     1] loss: 960.867
[24,     1] loss: 968.889
[25,     1] loss: 967.831
[26,     1] loss: 960.800
[27,     1] loss: 964.539
[28,     1] loss: 915.929
[29,     1] loss: 896.937
[30,     1] loss: 891.798
[31,     1] loss: 896.304
[32,     1] loss: 1009.397
[33,     1] loss: 941.313
[34,     1] loss: 886.001
[35,     1] loss: 907.785
[36,     1] loss: 855.890
[37,     1] loss: 921.443
[38,     1] loss: 849.439
[39,     1] loss: 865.030
[40,     1] loss: 783.085
[41,     1] loss: 808.487
[42,     1] loss: 899.930
[43,     1] loss: 902.055
[44,     1] loss: 862.217
[45,     1] loss: 801.614
[46,     1] loss: 866.495
[47,     1] loss: 796.423
[48,     1] loss: 804.734
[49,     1] loss: 810.886
[50,     1] loss: 766.916
[51,     1] loss: 740.307
[52,     1] loss: 735.267
[53,     1] loss: 721.833
[54,     1] loss: 909.887
[55,     1] loss: 990.642
[56,     1] loss: 811.431
[57,     1] loss: 811.588
[58,     1] loss: 760.537
[59,     1] loss: 827.008
[60,     1] loss: 797.611
[61,     1] loss: 763.652
[62,     1] loss: 805.481
[63,     1] loss: 722.328
[64,     1] loss: 734.134
[65,     1] loss: 650.904
[66,     1] loss: 737.530
[67,     1] loss: 654.172
[68,     1] loss: 664.224
[69,     1] loss: 751.432
[70,     1] loss: 800.939
[71,     1] loss: 742.157
[72,     1] loss: 680.388
[73,     1] loss: 784.226
[74,     1] loss: 660.274
[75,     1] loss: 676.731
[76,     1] loss: 686.146
[77,     1] loss: 599.231
[78,     1] loss: 683.739
[79,     1] loss: 693.685
[80,     1] loss: 747.486
[81,     1] loss: 607.869
Early stopping applied (best metric=0.8260667324066162)
Finished Training
Total time taken: 12.114012002944946
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1270.697
[2,     1] loss: 1275.761
[3,     1] loss: 1271.117
[4,     1] loss: 1271.395
[5,     1] loss: 1265.409
[6,     1] loss: 1267.791
[7,     1] loss: 1256.761
[8,     1] loss: 1228.060
[9,     1] loss: 1202.536
[10,     1] loss: 1154.479
[11,     1] loss: 1124.516
[12,     1] loss: 1086.496
[13,     1] loss: 1061.684
[14,     1] loss: 1096.460
[15,     1] loss: 1088.880
[16,     1] loss: 1087.890
[17,     1] loss: 1002.564
[18,     1] loss: 1071.344
[19,     1] loss: 1012.419
[20,     1] loss: 1037.329
[21,     1] loss: 1020.654
[22,     1] loss: 964.826
[23,     1] loss: 978.232
[24,     1] loss: 1019.265
[25,     1] loss: 919.755
[26,     1] loss: 956.424
[27,     1] loss: 971.539
[28,     1] loss: 928.694
[29,     1] loss: 953.989
[30,     1] loss: 933.118
[31,     1] loss: 915.421
[32,     1] loss: 921.174
[33,     1] loss: 906.482
[34,     1] loss: 846.673
[35,     1] loss: 935.728
[36,     1] loss: 922.298
[37,     1] loss: 840.709
[38,     1] loss: 845.094
[39,     1] loss: 848.738
[40,     1] loss: 879.027
[41,     1] loss: 888.255
[42,     1] loss: 812.007
[43,     1] loss: 883.965
[44,     1] loss: 978.511
[45,     1] loss: 816.876
[46,     1] loss: 911.624
[47,     1] loss: 832.734
[48,     1] loss: 839.002
[49,     1] loss: 790.749
[50,     1] loss: 803.391
[51,     1] loss: 855.654
[52,     1] loss: 711.233
[53,     1] loss: 759.159
[54,     1] loss: 874.681
[55,     1] loss: 771.067
[56,     1] loss: 711.271
[57,     1] loss: 811.713
[58,     1] loss: 702.883
[59,     1] loss: 717.343
[60,     1] loss: 781.197
[61,     1] loss: 742.836
[62,     1] loss: 691.335
[63,     1] loss: 863.617
[64,     1] loss: 781.892
[65,     1] loss: 687.662
[66,     1] loss: 730.641
[67,     1] loss: 685.472
[68,     1] loss: 634.917
[69,     1] loss: 617.034
[70,     1] loss: 609.914
[71,     1] loss: 806.185
[72,     1] loss: 1236.849
[73,     1] loss: 690.296
[74,     1] loss: 843.914
[75,     1] loss: 772.638
[76,     1] loss: 870.858
[77,     1] loss: 785.203
[78,     1] loss: 752.467
[79,     1] loss: 837.724
[80,     1] loss: 697.958
[81,     1] loss: 727.866
[82,     1] loss: 697.597
[83,     1] loss: 667.082
[84,     1] loss: 653.884
Early stopping applied (best metric=0.7978031635284424)
Finished Training
Total time taken: 12.446012020111084
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1272.805
[2,     1] loss: 1294.848
[3,     1] loss: 1275.664
[4,     1] loss: 1273.305
[5,     1] loss: 1271.990
[6,     1] loss: 1270.886
[7,     1] loss: 1270.440
[8,     1] loss: 1271.422
[9,     1] loss: 1270.967
[10,     1] loss: 1270.094
[11,     1] loss: 1270.649
[12,     1] loss: 1269.583
[13,     1] loss: 1268.234
[14,     1] loss: 1266.426
[15,     1] loss: 1268.103
[16,     1] loss: 1258.865
[17,     1] loss: 1251.483
[18,     1] loss: 1237.709
[19,     1] loss: 1231.228
[20,     1] loss: 1212.161
[21,     1] loss: 1180.826
[22,     1] loss: 1164.082
[23,     1] loss: 1102.746
[24,     1] loss: 1107.619
[25,     1] loss: 1096.123
[26,     1] loss: 1055.587
[27,     1] loss: 1026.397
[28,     1] loss: 1077.541
[29,     1] loss: 1016.614
[30,     1] loss: 984.518
[31,     1] loss: 973.512
[32,     1] loss: 967.591
[33,     1] loss: 951.844
[34,     1] loss: 987.309
[35,     1] loss: 934.465
[36,     1] loss: 929.083
[37,     1] loss: 912.294
[38,     1] loss: 916.432
[39,     1] loss: 896.056
[40,     1] loss: 1089.879
[41,     1] loss: 1026.199
[42,     1] loss: 876.621
[43,     1] loss: 988.808
[44,     1] loss: 957.532
[45,     1] loss: 907.937
[46,     1] loss: 922.920
[47,     1] loss: 932.370
[48,     1] loss: 904.025
[49,     1] loss: 870.454
[50,     1] loss: 926.539
[51,     1] loss: 853.510
[52,     1] loss: 889.148
[53,     1] loss: 837.886
[54,     1] loss: 867.328
[55,     1] loss: 843.611
Early stopping applied (best metric=0.9330928325653076)
Finished Training
Total time taken: 8.878010511398315
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1279.043
[2,     1] loss: 1275.026
[3,     1] loss: 1273.008
[4,     1] loss: 1271.015
[5,     1] loss: 1272.879
[6,     1] loss: 1271.611
[7,     1] loss: 1266.488
[8,     1] loss: 1263.390
[9,     1] loss: 1246.569
[10,     1] loss: 1217.042
[11,     1] loss: 1189.189
[12,     1] loss: 1157.723
[13,     1] loss: 1123.437
[14,     1] loss: 1083.654
[15,     1] loss: 1059.975
[16,     1] loss: 1102.985
[17,     1] loss: 1112.912
[18,     1] loss: 1060.579
[19,     1] loss: 1048.833
[20,     1] loss: 1024.656
[21,     1] loss: 1001.344
[22,     1] loss: 1022.074
[23,     1] loss: 986.336
[24,     1] loss: 987.956
[25,     1] loss: 1035.796
[26,     1] loss: 1053.188
[27,     1] loss: 999.699
[28,     1] loss: 978.986
[29,     1] loss: 984.438
[30,     1] loss: 983.815
[31,     1] loss: 955.414
[32,     1] loss: 994.694
[33,     1] loss: 993.912
[34,     1] loss: 942.465
[35,     1] loss: 899.673
[36,     1] loss: 883.351
[37,     1] loss: 894.528
[38,     1] loss: 885.428
[39,     1] loss: 842.666
[40,     1] loss: 885.006
[41,     1] loss: 869.395
[42,     1] loss: 829.298
[43,     1] loss: 844.986
[44,     1] loss: 1116.702
[45,     1] loss: 943.364
[46,     1] loss: 849.563
[47,     1] loss: 899.008
[48,     1] loss: 904.805
[49,     1] loss: 909.638
[50,     1] loss: 807.385
[51,     1] loss: 854.166
[52,     1] loss: 815.763
[53,     1] loss: 839.281
[54,     1] loss: 847.178
[55,     1] loss: 787.840
[56,     1] loss: 798.031
[57,     1] loss: 763.761
[58,     1] loss: 774.971
[59,     1] loss: 777.500
[60,     1] loss: 695.715
[61,     1] loss: 728.202
[62,     1] loss: 716.697
[63,     1] loss: 852.039
[64,     1] loss: 751.505
[65,     1] loss: 686.072
[66,     1] loss: 697.598
[67,     1] loss: 712.548
[68,     1] loss: 669.157
[69,     1] loss: 630.797
[70,     1] loss: 739.893
[71,     1] loss: 855.287
[72,     1] loss: 600.150
[73,     1] loss: 681.872
[74,     1] loss: 774.930
[75,     1] loss: 682.268
[76,     1] loss: 797.179
[77,     1] loss: 669.789
[78,     1] loss: 705.904
[79,     1] loss: 658.737
[80,     1] loss: 707.983
Early stopping applied (best metric=0.7942615747451782)
Finished Training
Total time taken: 11.572011232376099
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1270.824
[2,     1] loss: 1279.073
[3,     1] loss: 1290.099
[4,     1] loss: 1270.110
[5,     1] loss: 1272.551
[6,     1] loss: 1271.636
[7,     1] loss: 1269.994
[8,     1] loss: 1265.616
[9,     1] loss: 1268.701
[10,     1] loss: 1262.793
[11,     1] loss: 1252.509
[12,     1] loss: 1238.658
[13,     1] loss: 1221.501
[14,     1] loss: 1182.515
[15,     1] loss: 1175.768
[16,     1] loss: 1122.316
[17,     1] loss: 1107.777
[18,     1] loss: 1076.022
[19,     1] loss: 1071.567
[20,     1] loss: 1085.941
[21,     1] loss: 1120.566
[22,     1] loss: 1022.994
[23,     1] loss: 1070.906
[24,     1] loss: 1011.995
[25,     1] loss: 1008.778
[26,     1] loss: 996.326
[27,     1] loss: 977.674
[28,     1] loss: 1004.967
[29,     1] loss: 1011.400
[30,     1] loss: 928.239
[31,     1] loss: 942.022
[32,     1] loss: 915.463
[33,     1] loss: 879.466
[34,     1] loss: 975.394
[35,     1] loss: 889.261
[36,     1] loss: 964.336
[37,     1] loss: 923.985
[38,     1] loss: 896.341
[39,     1] loss: 886.269
[40,     1] loss: 843.430
[41,     1] loss: 842.602
[42,     1] loss: 838.288
[43,     1] loss: 894.278
[44,     1] loss: 889.279
[45,     1] loss: 833.913
[46,     1] loss: 802.033
[47,     1] loss: 818.626
[48,     1] loss: 800.552
[49,     1] loss: 764.997
[50,     1] loss: 736.553
[51,     1] loss: 813.345
[52,     1] loss: 1463.445
[53,     1] loss: 1079.140
[54,     1] loss: 932.825
[55,     1] loss: 924.363
[56,     1] loss: 1018.614
[57,     1] loss: 1050.339
[58,     1] loss: 1073.128
[59,     1] loss: 1046.487
[60,     1] loss: 998.962
[61,     1] loss: 956.132
[62,     1] loss: 965.197
[63,     1] loss: 983.723
[64,     1] loss: 941.832
[65,     1] loss: 925.031
[66,     1] loss: 931.378
[67,     1] loss: 928.381
[68,     1] loss: 878.021
Early stopping applied (best metric=0.8156492710113525)
Finished Training
Total time taken: 10.878009796142578
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1267.350
[2,     1] loss: 1283.018
[3,     1] loss: 1268.260
[4,     1] loss: 1263.128
[5,     1] loss: 1235.636
[6,     1] loss: 1197.442
[7,     1] loss: 1187.742
[8,     1] loss: 1162.205
[9,     1] loss: 1073.898
[10,     1] loss: 1071.489
[11,     1] loss: 1030.245
[12,     1] loss: 1078.875
[13,     1] loss: 1070.968
[14,     1] loss: 1049.726
[15,     1] loss: 1038.750
[16,     1] loss: 1029.682
[17,     1] loss: 1026.583
[18,     1] loss: 988.195
[19,     1] loss: 963.942
[20,     1] loss: 964.333
[21,     1] loss: 964.361
[22,     1] loss: 957.993
[23,     1] loss: 940.462
[24,     1] loss: 913.740
[25,     1] loss: 936.038
[26,     1] loss: 939.790
[27,     1] loss: 948.148
[28,     1] loss: 920.653
[29,     1] loss: 894.048
[30,     1] loss: 866.285
[31,     1] loss: 910.201
[32,     1] loss: 925.609
[33,     1] loss: 878.695
[34,     1] loss: 886.438
[35,     1] loss: 903.984
[36,     1] loss: 877.767
[37,     1] loss: 902.702
[38,     1] loss: 860.443
[39,     1] loss: 862.390
[40,     1] loss: 894.609
[41,     1] loss: 783.110
[42,     1] loss: 817.143
[43,     1] loss: 815.463
[44,     1] loss: 802.695
[45,     1] loss: 889.724
[46,     1] loss: 770.398
[47,     1] loss: 802.263
[48,     1] loss: 860.549
[49,     1] loss: 898.264
[50,     1] loss: 786.715
[51,     1] loss: 783.686
[52,     1] loss: 757.702
[53,     1] loss: 760.776
[54,     1] loss: 676.545
[55,     1] loss: 721.100
[56,     1] loss: 947.481
[57,     1] loss: 825.918
[58,     1] loss: 721.486
[59,     1] loss: 778.973
[60,     1] loss: 788.190
[61,     1] loss: 728.486
[62,     1] loss: 765.983
[63,     1] loss: 655.583
[64,     1] loss: 739.621
[65,     1] loss: 681.220
[66,     1] loss: 689.083
[67,     1] loss: 676.362
[68,     1] loss: 570.760
[69,     1] loss: 597.674
[70,     1] loss: 581.519
[71,     1] loss: 715.104
[72,     1] loss: 1290.650
[73,     1] loss: 725.184
Early stopping applied (best metric=0.7695894241333008)
Finished Training
Total time taken: 12.23401165008545
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1272.379
[2,     1] loss: 1273.819
[3,     1] loss: 1272.848
[4,     1] loss: 1273.679
[5,     1] loss: 1269.640
[6,     1] loss: 1269.200
[7,     1] loss: 1269.074
[8,     1] loss: 1260.641
[9,     1] loss: 1255.639
[10,     1] loss: 1240.216
[11,     1] loss: 1212.074
[12,     1] loss: 1145.529
[13,     1] loss: 1132.645
[14,     1] loss: 1090.790
[15,     1] loss: 1083.682
[16,     1] loss: 1038.586
[17,     1] loss: 1111.417
[18,     1] loss: 1044.052
[19,     1] loss: 961.051
[20,     1] loss: 1050.216
[21,     1] loss: 1008.831
[22,     1] loss: 1039.055
[23,     1] loss: 989.172
[24,     1] loss: 995.410
[25,     1] loss: 954.369
[26,     1] loss: 961.655
[27,     1] loss: 955.612
[28,     1] loss: 926.069
[29,     1] loss: 922.151
[30,     1] loss: 927.652
[31,     1] loss: 878.933
[32,     1] loss: 875.994
[33,     1] loss: 976.946
[34,     1] loss: 1096.650
[35,     1] loss: 892.683
[36,     1] loss: 980.313
[37,     1] loss: 920.677
[38,     1] loss: 950.134
[39,     1] loss: 952.124
[40,     1] loss: 882.245
[41,     1] loss: 893.821
[42,     1] loss: 896.791
[43,     1] loss: 861.414
[44,     1] loss: 811.951
[45,     1] loss: 855.315
[46,     1] loss: 838.938
[47,     1] loss: 785.948
[48,     1] loss: 801.939
[49,     1] loss: 794.223
[50,     1] loss: 817.098
[51,     1] loss: 754.402
[52,     1] loss: 732.160
[53,     1] loss: 746.488
[54,     1] loss: 862.225
[55,     1] loss: 927.516
[56,     1] loss: 830.969
[57,     1] loss: 760.926
[58,     1] loss: 836.711
[59,     1] loss: 810.857
[60,     1] loss: 837.723
[61,     1] loss: 772.138
[62,     1] loss: 763.296
[63,     1] loss: 755.618
[64,     1] loss: 713.610
[65,     1] loss: 758.289
[66,     1] loss: 807.769
[67,     1] loss: 786.856
[68,     1] loss: 697.742
[69,     1] loss: 690.623
[70,     1] loss: 820.869
[71,     1] loss: 691.616
[72,     1] loss: 706.803
[73,     1] loss: 741.865
[74,     1] loss: 662.776
[75,     1] loss: 639.127
[76,     1] loss: 593.798
[77,     1] loss: 617.311
[78,     1] loss: 585.393
[79,     1] loss: 785.770
[80,     1] loss: 1130.661
[81,     1] loss: 646.333
[82,     1] loss: 887.323
[83,     1] loss: 770.920
[84,     1] loss: 816.027
[85,     1] loss: 832.672
[86,     1] loss: 725.831
[87,     1] loss: 777.571
[88,     1] loss: 705.256
[89,     1] loss: 716.912
[90,     1] loss: 681.766
[91,     1] loss: 642.854
[92,     1] loss: 675.258
[93,     1] loss: 605.125
[94,     1] loss: 677.870
Early stopping applied (best metric=0.8315914869308472)
Finished Training
Total time taken: 13.693015813827515
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1274.989
[2,     1] loss: 1276.735
[3,     1] loss: 1269.331
[4,     1] loss: 1274.178
[5,     1] loss: 1268.130
[6,     1] loss: 1261.430
[7,     1] loss: 1240.313
[8,     1] loss: 1202.842
[9,     1] loss: 1166.040
[10,     1] loss: 1153.381
[11,     1] loss: 1117.258
[12,     1] loss: 1044.578
[13,     1] loss: 1088.444
[14,     1] loss: 1037.086
[15,     1] loss: 1019.861
[16,     1] loss: 1054.287
[17,     1] loss: 1013.754
[18,     1] loss: 1029.287
[19,     1] loss: 1016.396
[20,     1] loss: 1009.857
[21,     1] loss: 1001.971
[22,     1] loss: 991.586
[23,     1] loss: 942.329
[24,     1] loss: 956.136
[25,     1] loss: 930.965
[26,     1] loss: 937.779
[27,     1] loss: 898.160
[28,     1] loss: 946.328
[29,     1] loss: 903.465
[30,     1] loss: 907.917
[31,     1] loss: 911.695
[32,     1] loss: 934.281
[33,     1] loss: 910.839
[34,     1] loss: 832.390
[35,     1] loss: 927.725
[36,     1] loss: 885.379
[37,     1] loss: 845.696
[38,     1] loss: 921.841
[39,     1] loss: 839.174
[40,     1] loss: 881.539
[41,     1] loss: 867.831
[42,     1] loss: 878.516
[43,     1] loss: 846.599
[44,     1] loss: 803.436
[45,     1] loss: 824.006
[46,     1] loss: 767.809
[47,     1] loss: 751.200
[48,     1] loss: 786.265
[49,     1] loss: 777.409
[50,     1] loss: 934.332
[51,     1] loss: 1148.686
[52,     1] loss: 777.184
[53,     1] loss: 932.474
Early stopping applied (best metric=0.7849586009979248)
Finished Training
Total time taken: 8.912009716033936
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1271.476
[2,     1] loss: 1276.518
[3,     1] loss: 1270.422
[4,     1] loss: 1269.092
[5,     1] loss: 1263.436
[6,     1] loss: 1257.341
[7,     1] loss: 1226.492
[8,     1] loss: 1191.312
[9,     1] loss: 1120.024
[10,     1] loss: 1076.414
[11,     1] loss: 1059.790
[12,     1] loss: 1094.860
[13,     1] loss: 1091.856
[14,     1] loss: 1024.071
[15,     1] loss: 1035.827
[16,     1] loss: 1055.689
[17,     1] loss: 1057.849
[18,     1] loss: 1036.772
[19,     1] loss: 1006.520
[20,     1] loss: 1015.565
[21,     1] loss: 998.699
[22,     1] loss: 968.230
[23,     1] loss: 1019.364
[24,     1] loss: 956.426
[25,     1] loss: 916.197
[26,     1] loss: 967.887
[27,     1] loss: 904.938
[28,     1] loss: 892.889
[29,     1] loss: 865.240
[30,     1] loss: 858.036
[31,     1] loss: 949.629
[32,     1] loss: 921.935
[33,     1] loss: 847.924
[34,     1] loss: 880.759
[35,     1] loss: 877.557
[36,     1] loss: 821.285
[37,     1] loss: 816.494
[38,     1] loss: 754.020
[39,     1] loss: 951.939
[40,     1] loss: 1070.576
[41,     1] loss: 813.681
[42,     1] loss: 861.078
[43,     1] loss: 852.925
[44,     1] loss: 855.826
[45,     1] loss: 848.192
[46,     1] loss: 806.166
[47,     1] loss: 819.575
Early stopping applied (best metric=0.8947197198867798)
Finished Training
Total time taken: 7.913006544113159
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1271.697
[2,     1] loss: 1277.461
[3,     1] loss: 1281.705
[4,     1] loss: 1272.055
[5,     1] loss: 1268.042
[6,     1] loss: 1271.566
[7,     1] loss: 1272.384
[8,     1] loss: 1267.049
[9,     1] loss: 1264.882
[10,     1] loss: 1255.019
[11,     1] loss: 1239.225
[12,     1] loss: 1220.405
[13,     1] loss: 1181.874
[14,     1] loss: 1157.511
[15,     1] loss: 1123.245
[16,     1] loss: 1095.773
[17,     1] loss: 1131.248
[18,     1] loss: 1073.734
[19,     1] loss: 1120.626
[20,     1] loss: 1061.763
[21,     1] loss: 1088.149
[22,     1] loss: 1053.729
[23,     1] loss: 1067.008
[24,     1] loss: 1038.986
[25,     1] loss: 1052.571
[26,     1] loss: 1016.967
[27,     1] loss: 1044.157
[28,     1] loss: 986.688
[29,     1] loss: 990.835
[30,     1] loss: 941.911
[31,     1] loss: 977.150
[32,     1] loss: 940.955
[33,     1] loss: 1013.946
[34,     1] loss: 938.645
[35,     1] loss: 871.114
[36,     1] loss: 930.332
[37,     1] loss: 880.968
[38,     1] loss: 981.299
Early stopping applied (best metric=0.9084267616271973)
Finished Training
Total time taken: 6.461005926132202
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1275.021
[2,     1] loss: 1279.455
[3,     1] loss: 1271.124
[4,     1] loss: 1272.820
[5,     1] loss: 1277.794
[6,     1] loss: 1271.637
[7,     1] loss: 1271.253
[8,     1] loss: 1272.021
[9,     1] loss: 1269.108
[10,     1] loss: 1268.775
[11,     1] loss: 1270.948
[12,     1] loss: 1265.231
[13,     1] loss: 1258.510
[14,     1] loss: 1253.024
[15,     1] loss: 1233.030
[16,     1] loss: 1210.119
[17,     1] loss: 1185.672
[18,     1] loss: 1161.014
[19,     1] loss: 1121.735
[20,     1] loss: 1077.079
[21,     1] loss: 1060.966
[22,     1] loss: 1085.505
[23,     1] loss: 1066.377
[24,     1] loss: 1007.718
[25,     1] loss: 1075.737
[26,     1] loss: 1086.207
[27,     1] loss: 1047.878
[28,     1] loss: 1054.584
[29,     1] loss: 1026.457
[30,     1] loss: 1038.175
[31,     1] loss: 1013.051
[32,     1] loss: 998.776
[33,     1] loss: 1020.246
[34,     1] loss: 942.628
[35,     1] loss: 983.295
[36,     1] loss: 963.683
[37,     1] loss: 975.829
[38,     1] loss: 934.076
[39,     1] loss: 984.743
[40,     1] loss: 901.061
[41,     1] loss: 916.125
[42,     1] loss: 921.128
[43,     1] loss: 903.162
[44,     1] loss: 903.950
[45,     1] loss: 907.726
[46,     1] loss: 906.132
[47,     1] loss: 1025.060
[48,     1] loss: 1081.103
[49,     1] loss: 887.449
[50,     1] loss: 965.330
[51,     1] loss: 989.745
[52,     1] loss: 883.690
[53,     1] loss: 911.360
[54,     1] loss: 961.057
[55,     1] loss: 891.566
[56,     1] loss: 869.152
[57,     1] loss: 899.228
[58,     1] loss: 842.188
[59,     1] loss: 887.059
[60,     1] loss: 835.763
[61,     1] loss: 893.027
[62,     1] loss: 860.854
[63,     1] loss: 846.908
[64,     1] loss: 774.321
[65,     1] loss: 814.835
[66,     1] loss: 802.295
[67,     1] loss: 762.112
[68,     1] loss: 740.374
[69,     1] loss: 874.428
[70,     1] loss: 838.239
[71,     1] loss: 726.682
[72,     1] loss: 759.016
[73,     1] loss: 766.517
[74,     1] loss: 706.934
[75,     1] loss: 711.486
[76,     1] loss: 755.883
[77,     1] loss: 659.876
[78,     1] loss: 788.050
[79,     1] loss: 1132.299
[80,     1] loss: 759.398
[81,     1] loss: 910.713
[82,     1] loss: 811.271
[83,     1] loss: 943.437
[84,     1] loss: 869.881
[85,     1] loss: 744.784
[86,     1] loss: 947.815
[87,     1] loss: 727.017
[88,     1] loss: 812.238
[89,     1] loss: 801.238
[90,     1] loss: 710.052
[91,     1] loss: 786.298
[92,     1] loss: 658.045
[93,     1] loss: 780.513
[94,     1] loss: 675.903
[95,     1] loss: 699.995
Early stopping applied (best metric=0.8044829368591309)
Finished Training
Total time taken: 15.800016164779663
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1270.796
[2,     1] loss: 1272.161
[3,     1] loss: 1269.010
[4,     1] loss: 1268.340
[5,     1] loss: 1258.781
[6,     1] loss: 1263.584
[7,     1] loss: 1243.672
[8,     1] loss: 1208.897
[9,     1] loss: 1154.617
[10,     1] loss: 1149.090
[11,     1] loss: 1084.431
[12,     1] loss: 1050.275
[13,     1] loss: 1133.014
[14,     1] loss: 1075.134
[15,     1] loss: 1065.954
[16,     1] loss: 1037.069
[17,     1] loss: 1072.810
[18,     1] loss: 1060.675
[19,     1] loss: 1003.799
[20,     1] loss: 1078.468
[21,     1] loss: 992.550
[22,     1] loss: 1025.023
[23,     1] loss: 995.323
[24,     1] loss: 939.796
[25,     1] loss: 972.832
[26,     1] loss: 997.283
[27,     1] loss: 935.424
[28,     1] loss: 925.467
[29,     1] loss: 940.751
[30,     1] loss: 934.474
[31,     1] loss: 943.209
[32,     1] loss: 934.509
[33,     1] loss: 965.814
[34,     1] loss: 911.922
[35,     1] loss: 879.916
[36,     1] loss: 926.401
[37,     1] loss: 839.776
[38,     1] loss: 905.995
[39,     1] loss: 1019.980
[40,     1] loss: 990.186
[41,     1] loss: 862.266
[42,     1] loss: 940.510
[43,     1] loss: 897.524
[44,     1] loss: 862.741
[45,     1] loss: 903.392
[46,     1] loss: 830.465
[47,     1] loss: 846.740
[48,     1] loss: 800.609
[49,     1] loss: 856.025
[50,     1] loss: 904.023
[51,     1] loss: 780.443
[52,     1] loss: 808.568
[53,     1] loss: 799.547
[54,     1] loss: 828.487
[55,     1] loss: 776.654
[56,     1] loss: 809.133
[57,     1] loss: 783.175
[58,     1] loss: 733.864
[59,     1] loss: 807.689
[60,     1] loss: 956.254
[61,     1] loss: 717.436
[62,     1] loss: 916.662
[63,     1] loss: 716.138
[64,     1] loss: 806.727
[65,     1] loss: 769.701
[66,     1] loss: 737.290
[67,     1] loss: 728.545
[68,     1] loss: 696.824
[69,     1] loss: 841.637
[70,     1] loss: 657.328
[71,     1] loss: 738.591
[72,     1] loss: 760.369
[73,     1] loss: 719.861
[74,     1] loss: 874.496
[75,     1] loss: 650.930
[76,     1] loss: 773.441
[77,     1] loss: 655.450
[78,     1] loss: 689.707
[79,     1] loss: 637.803
[80,     1] loss: 671.313
[81,     1] loss: 715.185
[82,     1] loss: 653.456
[83,     1] loss: 563.708
[84,     1] loss: 649.653
[85,     1] loss: 591.335
[86,     1] loss: 559.760
[87,     1] loss: 588.313
[88,     1] loss: 592.030
[89,     1] loss: 588.153
[90,     1] loss: 546.106
[91,     1] loss: 483.812
[92,     1] loss: 550.415
[93,     1] loss: 810.749
[94,     1] loss: 660.747
Early stopping applied (best metric=0.7942616939544678)
Finished Training
Total time taken: 14.085013628005981
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1270.025
[2,     1] loss: 1271.949
[3,     1] loss: 1276.245
[4,     1] loss: 1264.329
[5,     1] loss: 1260.369
[6,     1] loss: 1236.600
[7,     1] loss: 1209.024
[8,     1] loss: 1196.141
[9,     1] loss: 1162.168
[10,     1] loss: 1147.624
[11,     1] loss: 1103.499
[12,     1] loss: 1094.427
[13,     1] loss: 1058.827
[14,     1] loss: 1029.984
[15,     1] loss: 1001.509
[16,     1] loss: 1047.380
[17,     1] loss: 1008.894
[18,     1] loss: 993.792
[19,     1] loss: 978.134
[20,     1] loss: 1042.077
[21,     1] loss: 1021.505
[22,     1] loss: 972.258
[23,     1] loss: 967.640
[24,     1] loss: 968.575
[25,     1] loss: 937.054
[26,     1] loss: 1005.712
[27,     1] loss: 889.568
[28,     1] loss: 902.852
[29,     1] loss: 878.928
[30,     1] loss: 881.745
[31,     1] loss: 919.969
[32,     1] loss: 874.983
[33,     1] loss: 832.007
[34,     1] loss: 915.705
[35,     1] loss: 813.138
[36,     1] loss: 831.966
[37,     1] loss: 856.947
[38,     1] loss: 797.105
[39,     1] loss: 776.490
[40,     1] loss: 802.995
[41,     1] loss: 754.600
[42,     1] loss: 821.699
[43,     1] loss: 1195.889
[44,     1] loss: 1236.764
[45,     1] loss: 1020.323
[46,     1] loss: 1006.928
[47,     1] loss: 1034.523
[48,     1] loss: 1068.679
[49,     1] loss: 1052.856
[50,     1] loss: 1097.311
[51,     1] loss: 1053.760
[52,     1] loss: 979.517
[53,     1] loss: 953.704
[54,     1] loss: 950.876
[55,     1] loss: 1005.753
[56,     1] loss: 906.141
[57,     1] loss: 932.098
Early stopping applied (best metric=0.7851443290710449)
Finished Training
Total time taken: 9.618009090423584
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1281.992
[2,     1] loss: 1273.180
[3,     1] loss: 1280.861
[4,     1] loss: 1273.025
[5,     1] loss: 1273.962
[6,     1] loss: 1268.269
[7,     1] loss: 1273.051
[8,     1] loss: 1269.041
[9,     1] loss: 1268.468
[10,     1] loss: 1265.022
[11,     1] loss: 1258.863
[12,     1] loss: 1239.083
[13,     1] loss: 1214.862
[14,     1] loss: 1189.347
[15,     1] loss: 1135.381
[16,     1] loss: 1124.736
[17,     1] loss: 1100.775
[18,     1] loss: 1080.652
[19,     1] loss: 1050.245
[20,     1] loss: 1073.721
[21,     1] loss: 1047.347
[22,     1] loss: 990.502
[23,     1] loss: 973.376
[24,     1] loss: 1035.306
[25,     1] loss: 1034.442
[26,     1] loss: 979.365
[27,     1] loss: 955.240
[28,     1] loss: 970.251
[29,     1] loss: 975.444
[30,     1] loss: 927.281
[31,     1] loss: 928.310
[32,     1] loss: 946.289
[33,     1] loss: 899.827
[34,     1] loss: 947.707
[35,     1] loss: 930.113
[36,     1] loss: 913.781
[37,     1] loss: 903.522
[38,     1] loss: 954.812
[39,     1] loss: 899.046
[40,     1] loss: 853.406
[41,     1] loss: 876.280
[42,     1] loss: 860.114
[43,     1] loss: 914.692
[44,     1] loss: 842.482
[45,     1] loss: 870.348
[46,     1] loss: 845.702
[47,     1] loss: 856.672
[48,     1] loss: 825.379
[49,     1] loss: 813.836
[50,     1] loss: 776.088
[51,     1] loss: 1126.322
[52,     1] loss: 1380.749
[53,     1] loss: 892.631
[54,     1] loss: 925.035
[55,     1] loss: 1038.481
[56,     1] loss: 1058.910
[57,     1] loss: 1005.967
[58,     1] loss: 1003.874
[59,     1] loss: 993.821
[60,     1] loss: 991.252
[61,     1] loss: 942.206
Early stopping applied (best metric=0.7837047576904297)
Finished Training
Total time taken: 8.490006685256958
{'Hydroxylation-K Validation Accuracy': 0.773256501182033, 'Hydroxylation-K Validation Sensitivity': 0.617037037037037, 'Hydroxylation-K Validation Specificity': 0.8122807017543859, 'Hydroxylation-K Validation Precision': 0.46347259036113525, 'Hydroxylation-K AUC ROC': 0.7783430799220273, 'Hydroxylation-K AUC PR': 0.5917253130712519, 'Hydroxylation-K MCC': 0.39122066650391746, 'Hydroxylation-K F1': 0.5259204641700236, 'Validation Loss (Hydroxylation-K)': 0.4516729334990183, 'Hydroxylation-P Validation Accuracy': 0.8013279528957921, 'Hydroxylation-P Validation Sensitivity': 0.7711640211640212, 'Hydroxylation-P Validation Specificity': 0.8078757045239164, 'Hydroxylation-P Validation Precision': 0.471802895717466, 'Hydroxylation-P AUC ROC': 0.850759136148183, 'Hydroxylation-P AUC PR': 0.569306664339886, 'Hydroxylation-P MCC': 0.489493267698293, 'Hydroxylation-P F1': 0.5812844890377536, 'Validation Loss (Hydroxylation-P)': 0.372886461019516, 'Validation Loss (total)': 0.8245593865712484, 'TimeToTrain': 10.854677375157674}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004753789356650551,
 'learning_rate_Hydroxylation-K': 0.004904966399057331,
 'learning_rate_Hydroxylation-P': 0.007878885903464682,
 'log_base': 2.793895832710669,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3459584074,
 'sample_weights': [1.7241747380371801, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6106875305413633,
 'weight_decay_Hydroxylation-K': 0.7771559908070673,
 'weight_decay_Hydroxylation-P': 3.467589404684796}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1251.140
[2,     1] loss: 1259.713
[3,     1] loss: 1250.402
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0041386415782043474,
 'learning_rate_Hydroxylation-K': 0.008649410202240568,
 'learning_rate_Hydroxylation-P': 0.0034802070702333624,
 'log_base': 2.7469443286292154,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1221995628,
 'sample_weights': [1.624861849190617, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.671884512779899,
 'weight_decay_Hydroxylation-K': 3.4188423464185247,
 'weight_decay_Hydroxylation-P': 3.4628007759576844}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1259.325
[2,     1] loss: 1264.050
[3,     1] loss: 1256.702
[4,     1] loss: 1255.954
[5,     1] loss: 1252.118
[6,     1] loss: 1240.988
[7,     1] loss: 1221.957
[8,     1] loss: 1192.849
[9,     1] loss: 1140.064
[10,     1] loss: 1097.024
[11,     1] loss: 1077.036
[12,     1] loss: 1129.137
[13,     1] loss: 1089.887
[14,     1] loss: 1119.499
[15,     1] loss: 1071.665
[16,     1] loss: 1091.449
[17,     1] loss: 1038.761
[18,     1] loss: 1080.371
[19,     1] loss: 1040.613
[20,     1] loss: 1043.164
[21,     1] loss: 1038.292
[22,     1] loss: 1018.915
[23,     1] loss: 1046.876
[24,     1] loss: 957.128
[25,     1] loss: 1054.334
[26,     1] loss: 981.192
[27,     1] loss: 992.591
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009022964942653074,
 'learning_rate_Hydroxylation-K': 0.008935067372272763,
 'learning_rate_Hydroxylation-P': 0.009578145149266897,
 'log_base': 2.664276472711954,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1611687813,
 'sample_weights': [1.6521138924126888, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 4.296727187294926,
 'weight_decay_Hydroxylation-K': 6.536838462108155,
 'weight_decay_Hydroxylation-P': 9.891677939859598}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1268.450
[2,     1] loss: 1269.465
[3,     1] loss: 1267.933
[4,     1] loss: 1267.418
[5,     1] loss: 1265.551
[6,     1] loss: 1264.794
[7,     1] loss: 1264.262
[8,     1] loss: 1263.952
[9,     1] loss: 1259.915
[10,     1] loss: 1255.390
[11,     1] loss: 1249.869
[12,     1] loss: 1246.718
[13,     1] loss: 1237.226
[14,     1] loss: 1213.845
[15,     1] loss: 1195.772
[16,     1] loss: 1185.926
[17,     1] loss: 1158.376
[18,     1] loss: 1140.073
[19,     1] loss: 1128.375
[20,     1] loss: 1087.140
[21,     1] loss: 1121.863
[22,     1] loss: 1054.448
[23,     1] loss: 1103.802
[24,     1] loss: 1066.890
[25,     1] loss: 1081.676
[26,     1] loss: 1071.396
[27,     1] loss: 1042.093
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001509181239377869,
 'learning_rate_Hydroxylation-K': 0.001445050092525145,
 'learning_rate_Hydroxylation-P': 0.0070844971112866695,
 'log_base': 2.311825535070282,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 850686244,
 'sample_weights': [1.7036307083810112, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 1.261750250935198,
 'weight_decay_Hydroxylation-K': 0.19828485180598293,
 'weight_decay_Hydroxylation-P': 0.2999845642438179}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1325.964
[2,     1] loss: 1329.041
[3,     1] loss: 1328.736
{'CNNType': 'Musite',
 'CV_Repeats': 5,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-P': [1e-05, 0.01],
                  'log_base': [1.01, 3],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Hydroxylation-P': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 128,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (total)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample',
                      'oversample'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 20,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004884319121536182,
 'learning_rate_Hydroxylation-K': 0.003731690912553525,
 'learning_rate_Hydroxylation-P': 0.0043710434635619595,
 'log_base': 2.5184787258467276,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2717163546,
 'sample_weights': [1.9920864789671084, 1],
 'test_data_ratio': 0.2,
 'useLrWeight': True,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2210039170929328,
 'weight_decay_Hydroxylation-K': 4.372713172070321,
 'weight_decay_Hydroxylation-P': 2.338744649903835}
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1291.556
[2,     1] loss: 1313.847
[3,     1] loss: 1291.467
[4,     1] loss: 1293.578
[5,     1] loss: 1288.296
[6,     1] loss: 1293.796
[7,     1] loss: 1287.759
[8,     1] loss: 1289.210
[9,     1] loss: 1285.737
[10,     1] loss: 1290.730
[11,     1] loss: 1287.852
[12,     1] loss: 1282.656
[13,     1] loss: 1283.007
[14,     1] loss: 1281.249
[15,     1] loss: 1275.141
[16,     1] loss: 1263.560
[17,     1] loss: 1244.213
[18,     1] loss: 1228.979
[19,     1] loss: 1198.802
[20,     1] loss: 1163.388
[21,     1] loss: 1154.812
[22,     1] loss: 1121.634
[23,     1] loss: 1104.029
[24,     1] loss: 1098.762
[25,     1] loss: 1106.128
[26,     1] loss: 1067.900
[27,     1] loss: 1086.159
[28,     1] loss: 1096.328
[29,     1] loss: 1069.589
[30,     1] loss: 1123.312
[31,     1] loss: 1042.287
[32,     1] loss: 1044.795
[33,     1] loss: 1044.071
[34,     1] loss: 1075.311
[35,     1] loss: 1016.583
[36,     1] loss: 1001.707
[37,     1] loss: 965.286
[38,     1] loss: 945.731
[39,     1] loss: 972.278
[40,     1] loss: 968.009
[41,     1] loss: 989.672
[42,     1] loss: 951.971
[43,     1] loss: 881.824
[44,     1] loss: 1008.059
[45,     1] loss: 907.455
[46,     1] loss: 919.605
[47,     1] loss: 918.518
[48,     1] loss: 939.825
[49,     1] loss: 915.592
[50,     1] loss: 880.301
[51,     1] loss: 896.603
[52,     1] loss: 867.395
[53,     1] loss: 858.797
[54,     1] loss: 805.004
[55,     1] loss: 836.491
[56,     1] loss: 849.515
[57,     1] loss: 847.660
[58,     1] loss: 871.521
[59,     1] loss: 796.088
[60,     1] loss: 852.495
[61,     1] loss: 789.484
[62,     1] loss: 729.690
[63,     1] loss: 789.185
[64,     1] loss: 784.890
[65,     1] loss: 721.489
[66,     1] loss: 732.663
[67,     1] loss: 704.871
[68,     1] loss: 746.235
[69,     1] loss: 763.914
[70,     1] loss: 870.978
[71,     1] loss: 689.763
[72,     1] loss: 775.724
[73,     1] loss: 695.411
[74,     1] loss: 757.386
[75,     1] loss: 700.082
[76,     1] loss: 766.125
[77,     1] loss: 677.709
[78,     1] loss: 693.460
[79,     1] loss: 676.950
[80,     1] loss: 713.463
Early stopping applied (best metric=0.8371211886405945)
Finished Training
Total time taken: 12.197010040283203
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1289.704
[2,     1] loss: 1295.525
[3,     1] loss: 1290.032
[4,     1] loss: 1287.387
[5,     1] loss: 1291.134
[6,     1] loss: 1282.499
[7,     1] loss: 1266.055
[8,     1] loss: 1248.460
[9,     1] loss: 1211.783
[10,     1] loss: 1185.085
[11,     1] loss: 1129.536
[12,     1] loss: 1106.053
[13,     1] loss: 1106.464
[14,     1] loss: 1067.560
[15,     1] loss: 1055.558
[16,     1] loss: 1073.935
[17,     1] loss: 1070.239
[18,     1] loss: 1073.918
[19,     1] loss: 1070.076
[20,     1] loss: 1030.086
[21,     1] loss: 1044.069
[22,     1] loss: 1029.620
[23,     1] loss: 1025.471
[24,     1] loss: 972.805
[25,     1] loss: 1003.057
[26,     1] loss: 992.259
[27,     1] loss: 995.822
[28,     1] loss: 929.671
[29,     1] loss: 968.857
[30,     1] loss: 975.563
[31,     1] loss: 921.294
[32,     1] loss: 926.227
[33,     1] loss: 948.162
[34,     1] loss: 922.522
[35,     1] loss: 906.912
[36,     1] loss: 871.205
[37,     1] loss: 878.088
[38,     1] loss: 812.512
[39,     1] loss: 840.934
[40,     1] loss: 834.831
[41,     1] loss: 823.864
[42,     1] loss: 799.525
[43,     1] loss: 835.917
[44,     1] loss: 871.234
[45,     1] loss: 845.304
[46,     1] loss: 793.668
[47,     1] loss: 797.197
[48,     1] loss: 710.025
[49,     1] loss: 787.696
[50,     1] loss: 847.224
[51,     1] loss: 720.216
[52,     1] loss: 732.050
[53,     1] loss: 730.878
[54,     1] loss: 688.478
[55,     1] loss: 864.211
Early stopping applied (best metric=0.7828992009162903)
Finished Training
Total time taken: 8.412006855010986
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1286.701
[2,     1] loss: 1290.879
[3,     1] loss: 1282.635
[4,     1] loss: 1297.162
[5,     1] loss: 1288.202
[6,     1] loss: 1284.187
[7,     1] loss: 1274.051
[8,     1] loss: 1250.450
[9,     1] loss: 1204.931
[10,     1] loss: 1167.185
[11,     1] loss: 1139.477
[12,     1] loss: 1103.171
[13,     1] loss: 1147.485
[14,     1] loss: 1094.973
[15,     1] loss: 1072.765
[16,     1] loss: 1026.702
[17,     1] loss: 1059.818
[18,     1] loss: 1030.682
[19,     1] loss: 1023.921
[20,     1] loss: 1046.070
[21,     1] loss: 1020.386
[22,     1] loss: 995.963
[23,     1] loss: 953.178
[24,     1] loss: 1010.594
[25,     1] loss: 957.439
[26,     1] loss: 1003.614
[27,     1] loss: 969.121
[28,     1] loss: 948.382
[29,     1] loss: 959.428
[30,     1] loss: 962.998
[31,     1] loss: 919.867
[32,     1] loss: 959.631
[33,     1] loss: 918.371
[34,     1] loss: 916.826
[35,     1] loss: 964.714
[36,     1] loss: 925.323
[37,     1] loss: 895.268
[38,     1] loss: 917.768
[39,     1] loss: 892.433
[40,     1] loss: 896.053
[41,     1] loss: 936.619
[42,     1] loss: 848.980
[43,     1] loss: 911.012
[44,     1] loss: 833.645
[45,     1] loss: 922.927
[46,     1] loss: 809.744
[47,     1] loss: 834.380
[48,     1] loss: 858.604
[49,     1] loss: 828.979
[50,     1] loss: 730.331
[51,     1] loss: 747.915
[52,     1] loss: 705.286
[53,     1] loss: 815.343
[54,     1] loss: 719.969
[55,     1] loss: 699.181
[56,     1] loss: 675.104
[57,     1] loss: 701.628
[58,     1] loss: 652.123
[59,     1] loss: 612.346
[60,     1] loss: 616.920
[61,     1] loss: 709.890
[62,     1] loss: 888.097
[63,     1] loss: 920.862
[64,     1] loss: 638.934
[65,     1] loss: 755.046
[66,     1] loss: 755.762
[67,     1] loss: 655.151
[68,     1] loss: 768.814
[69,     1] loss: 714.840
Early stopping applied (best metric=0.8111224174499512)
Finished Training
Total time taken: 10.788010120391846
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1295.052
[2,     1] loss: 1289.809
[3,     1] loss: 1292.584
[4,     1] loss: 1287.827
[5,     1] loss: 1291.014
[6,     1] loss: 1287.723
[7,     1] loss: 1287.063
[8,     1] loss: 1280.250
[9,     1] loss: 1272.993
[10,     1] loss: 1257.538
[11,     1] loss: 1216.485
[12,     1] loss: 1190.085
[13,     1] loss: 1149.852
[14,     1] loss: 1097.719
[15,     1] loss: 1085.195
[16,     1] loss: 1080.705
[17,     1] loss: 1088.742
[18,     1] loss: 1061.622
[19,     1] loss: 1054.728
[20,     1] loss: 1028.129
[21,     1] loss: 1045.007
[22,     1] loss: 1033.388
[23,     1] loss: 1030.856
[24,     1] loss: 1007.936
[25,     1] loss: 969.355
[26,     1] loss: 1039.944
[27,     1] loss: 944.001
[28,     1] loss: 950.963
[29,     1] loss: 971.210
[30,     1] loss: 952.724
[31,     1] loss: 933.420
[32,     1] loss: 946.638
[33,     1] loss: 951.983
[34,     1] loss: 915.698
[35,     1] loss: 929.674
[36,     1] loss: 897.097
[37,     1] loss: 912.279
[38,     1] loss: 871.697
[39,     1] loss: 904.828
[40,     1] loss: 879.061
[41,     1] loss: 843.003
[42,     1] loss: 832.568
[43,     1] loss: 845.715
[44,     1] loss: 836.073
[45,     1] loss: 795.698
[46,     1] loss: 793.918
[47,     1] loss: 816.070
[48,     1] loss: 826.163
[49,     1] loss: 824.833
[50,     1] loss: 813.358
[51,     1] loss: 768.169
[52,     1] loss: 761.621
[53,     1] loss: 837.512
[54,     1] loss: 808.875
[55,     1] loss: 724.708
[56,     1] loss: 763.140
[57,     1] loss: 715.478
[58,     1] loss: 736.216
[59,     1] loss: 758.968
[60,     1] loss: 744.000
[61,     1] loss: 743.175
[62,     1] loss: 711.417
[63,     1] loss: 735.604
[64,     1] loss: 679.298
[65,     1] loss: 799.119
[66,     1] loss: 733.272
[67,     1] loss: 711.441
[68,     1] loss: 697.582
[69,     1] loss: 625.076
Early stopping applied (best metric=0.8110430240631104)
Finished Training
Total time taken: 10.637011766433716
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1290.346
[2,     1] loss: 1295.491
[3,     1] loss: 1293.874
[4,     1] loss: 1290.484
[5,     1] loss: 1288.427
[6,     1] loss: 1285.531
[7,     1] loss: 1274.709
[8,     1] loss: 1262.722
[9,     1] loss: 1231.479
[10,     1] loss: 1192.611
[11,     1] loss: 1165.167
[12,     1] loss: 1148.256
[13,     1] loss: 1140.377
[14,     1] loss: 1080.579
[15,     1] loss: 1094.731
[16,     1] loss: 1096.750
[17,     1] loss: 1132.682
[18,     1] loss: 1055.941
[19,     1] loss: 1036.730
[20,     1] loss: 1065.105
[21,     1] loss: 1028.948
[22,     1] loss: 1055.110
[23,     1] loss: 1009.663
[24,     1] loss: 989.356
[25,     1] loss: 957.777
[26,     1] loss: 958.273
[27,     1] loss: 974.882
[28,     1] loss: 962.042
[29,     1] loss: 934.754
[30,     1] loss: 931.075
[31,     1] loss: 930.311
[32,     1] loss: 892.122
[33,     1] loss: 976.662
[34,     1] loss: 908.804
[35,     1] loss: 924.980
[36,     1] loss: 912.716
[37,     1] loss: 874.206
[38,     1] loss: 883.474
[39,     1] loss: 855.876
[40,     1] loss: 837.717
[41,     1] loss: 815.764
[42,     1] loss: 797.748
[43,     1] loss: 820.885
[44,     1] loss: 885.388
[45,     1] loss: 867.096
[46,     1] loss: 764.019
[47,     1] loss: 847.223
[48,     1] loss: 832.424
[49,     1] loss: 739.159
[50,     1] loss: 850.932
[51,     1] loss: 709.642
[52,     1] loss: 714.173
[53,     1] loss: 738.745
[54,     1] loss: 738.346
Early stopping applied (best metric=0.8174565434455872)
Finished Training
Total time taken: 8.373007535934448
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1288.765
[2,     1] loss: 1295.200
[3,     1] loss: 1287.379
[4,     1] loss: 1289.913
[5,     1] loss: 1281.599
[6,     1] loss: 1265.205
[7,     1] loss: 1240.185
[8,     1] loss: 1211.911
[9,     1] loss: 1166.078
[10,     1] loss: 1136.683
[11,     1] loss: 1093.965
[12,     1] loss: 1132.486
[13,     1] loss: 1082.673
[14,     1] loss: 1126.264
[15,     1] loss: 1073.487
[16,     1] loss: 1093.096
[17,     1] loss: 1108.700
[18,     1] loss: 1093.542
[19,     1] loss: 1071.338
[20,     1] loss: 1045.715
[21,     1] loss: 1081.993
[22,     1] loss: 1073.228
[23,     1] loss: 1010.462
[24,     1] loss: 1030.996
[25,     1] loss: 1009.905
[26,     1] loss: 1058.893
[27,     1] loss: 1032.809
[28,     1] loss: 994.811
[29,     1] loss: 994.406
[30,     1] loss: 985.238
[31,     1] loss: 994.614
[32,     1] loss: 956.106
[33,     1] loss: 969.577
[34,     1] loss: 895.844
[35,     1] loss: 977.292
[36,     1] loss: 952.739
[37,     1] loss: 945.898
[38,     1] loss: 914.661
[39,     1] loss: 926.518
[40,     1] loss: 948.565
[41,     1] loss: 912.940
[42,     1] loss: 870.137
[43,     1] loss: 839.108
[44,     1] loss: 809.973
[45,     1] loss: 838.247
[46,     1] loss: 849.956
[47,     1] loss: 817.425
[48,     1] loss: 842.045
[49,     1] loss: 843.370
[50,     1] loss: 814.117
[51,     1] loss: 899.357
[52,     1] loss: 834.988
[53,     1] loss: 782.886
[54,     1] loss: 819.847
[55,     1] loss: 735.285
[56,     1] loss: 752.115
[57,     1] loss: 736.796
[58,     1] loss: 723.789
[59,     1] loss: 720.503
[60,     1] loss: 659.379
[61,     1] loss: 647.428
[62,     1] loss: 660.115
[63,     1] loss: 627.712
[64,     1] loss: 661.818
[65,     1] loss: 636.620
[66,     1] loss: 670.669
[67,     1] loss: 664.493
[68,     1] loss: 595.920
[69,     1] loss: 579.251
[70,     1] loss: 636.982
[71,     1] loss: 604.272
[72,     1] loss: 582.492
[73,     1] loss: 626.975
[74,     1] loss: 597.720
[75,     1] loss: 645.223
[76,     1] loss: 611.332
[77,     1] loss: 542.778
[78,     1] loss: 579.681
[79,     1] loss: 658.899
[80,     1] loss: 544.372
[81,     1] loss: 603.467
Early stopping applied (best metric=0.7175822854042053)
Finished Training
Total time taken: 12.670012950897217
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1289.861
[2,     1] loss: 1287.726
[3,     1] loss: 1292.866
[4,     1] loss: 1284.461
[5,     1] loss: 1278.050
[6,     1] loss: 1250.939
[7,     1] loss: 1209.753
[8,     1] loss: 1194.984
[9,     1] loss: 1237.870
[10,     1] loss: 1131.485
[11,     1] loss: 1175.907
[12,     1] loss: 1094.900
[13,     1] loss: 1081.820
[14,     1] loss: 1113.296
[15,     1] loss: 1061.247
[16,     1] loss: 1086.047
[17,     1] loss: 1091.580
[18,     1] loss: 1064.539
[19,     1] loss: 1008.467
[20,     1] loss: 1108.710
[21,     1] loss: 1002.181
[22,     1] loss: 1063.958
[23,     1] loss: 1040.206
[24,     1] loss: 1001.399
[25,     1] loss: 988.302
[26,     1] loss: 1006.261
[27,     1] loss: 993.386
[28,     1] loss: 930.571
[29,     1] loss: 967.835
[30,     1] loss: 962.828
[31,     1] loss: 956.942
[32,     1] loss: 916.173
[33,     1] loss: 897.472
[34,     1] loss: 860.789
[35,     1] loss: 867.904
[36,     1] loss: 873.914
[37,     1] loss: 845.448
[38,     1] loss: 844.377
[39,     1] loss: 810.633
[40,     1] loss: 811.208
[41,     1] loss: 837.165
[42,     1] loss: 787.749
[43,     1] loss: 780.215
[44,     1] loss: 800.401
[45,     1] loss: 769.582
[46,     1] loss: 733.188
[47,     1] loss: 755.420
[48,     1] loss: 778.656
[49,     1] loss: 707.634
[50,     1] loss: 742.674
[51,     1] loss: 700.874
[52,     1] loss: 685.669
[53,     1] loss: 677.525
[54,     1] loss: 748.059
[55,     1] loss: 901.842
[56,     1] loss: 821.449
[57,     1] loss: 704.557
[58,     1] loss: 755.168
[59,     1] loss: 703.705
[60,     1] loss: 649.210
[61,     1] loss: 672.458
[62,     1] loss: 613.559
[63,     1] loss: 634.661
[64,     1] loss: 619.394
[65,     1] loss: 621.472
[66,     1] loss: 601.358
[67,     1] loss: 516.308
[68,     1] loss: 572.139
Early stopping applied (best metric=0.710688591003418)
Finished Training
Total time taken: 10.768012285232544
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1291.709
[2,     1] loss: 1298.864
[3,     1] loss: 1303.783
[4,     1] loss: 1291.945
[5,     1] loss: 1287.596
[6,     1] loss: 1289.812
[7,     1] loss: 1290.223
[8,     1] loss: 1287.352
[9,     1] loss: 1285.523
[10,     1] loss: 1290.053
[11,     1] loss: 1285.465
[12,     1] loss: 1284.800
[13,     1] loss: 1282.782
[14,     1] loss: 1278.519
[15,     1] loss: 1275.195
[16,     1] loss: 1262.658
[17,     1] loss: 1246.316
[18,     1] loss: 1238.181
[19,     1] loss: 1203.132
[20,     1] loss: 1182.653
[21,     1] loss: 1171.405
[22,     1] loss: 1141.863
[23,     1] loss: 1170.523
[24,     1] loss: 1110.149
[25,     1] loss: 1107.620
[26,     1] loss: 1111.849
[27,     1] loss: 1092.186
[28,     1] loss: 1110.947
[29,     1] loss: 1108.338
[30,     1] loss: 1073.391
[31,     1] loss: 1066.958
[32,     1] loss: 1083.872
[33,     1] loss: 1054.263
[34,     1] loss: 1075.373
[35,     1] loss: 1041.018
[36,     1] loss: 1014.376
[37,     1] loss: 1025.543
[38,     1] loss: 1031.990
[39,     1] loss: 1009.782
[40,     1] loss: 979.571
[41,     1] loss: 947.578
[42,     1] loss: 973.773
[43,     1] loss: 1018.397
[44,     1] loss: 945.487
[45,     1] loss: 907.675
[46,     1] loss: 905.543
[47,     1] loss: 869.099
[48,     1] loss: 963.919
[49,     1] loss: 886.884
[50,     1] loss: 841.910
[51,     1] loss: 923.587
[52,     1] loss: 920.959
[53,     1] loss: 872.319
[54,     1] loss: 879.890
[55,     1] loss: 912.110
[56,     1] loss: 820.961
[57,     1] loss: 862.933
[58,     1] loss: 888.060
[59,     1] loss: 803.448
Early stopping applied (best metric=0.6749684810638428)
Finished Training
Total time taken: 9.392008304595947
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1292.511
[2,     1] loss: 1287.804
[3,     1] loss: 1286.312
[4,     1] loss: 1293.668
[5,     1] loss: 1284.506
[6,     1] loss: 1281.760
[7,     1] loss: 1271.945
[8,     1] loss: 1247.245
[9,     1] loss: 1209.333
[10,     1] loss: 1171.899
[11,     1] loss: 1145.060
[12,     1] loss: 1223.089
[13,     1] loss: 1132.859
[14,     1] loss: 1127.823
[15,     1] loss: 1128.233
[16,     1] loss: 1120.478
[17,     1] loss: 1100.690
[18,     1] loss: 1081.393
[19,     1] loss: 1060.994
[20,     1] loss: 1043.841
[21,     1] loss: 1038.830
[22,     1] loss: 1017.204
[23,     1] loss: 1081.301
[24,     1] loss: 999.804
[25,     1] loss: 1038.420
[26,     1] loss: 1004.287
[27,     1] loss: 998.838
[28,     1] loss: 973.271
[29,     1] loss: 979.294
[30,     1] loss: 957.312
[31,     1] loss: 982.208
[32,     1] loss: 935.665
[33,     1] loss: 955.218
[34,     1] loss: 937.783
[35,     1] loss: 946.881
[36,     1] loss: 878.243
[37,     1] loss: 878.156
[38,     1] loss: 861.684
[39,     1] loss: 873.461
[40,     1] loss: 891.544
[41,     1] loss: 921.802
[42,     1] loss: 841.274
[43,     1] loss: 786.710
[44,     1] loss: 833.391
[45,     1] loss: 791.181
[46,     1] loss: 825.275
[47,     1] loss: 805.635
[48,     1] loss: 755.009
[49,     1] loss: 774.363
[50,     1] loss: 733.451
[51,     1] loss: 787.635
Early stopping applied (best metric=0.8025197982788086)
Finished Training
Total time taken: 8.261008977890015
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1291.683
[2,     1] loss: 1306.539
[3,     1] loss: 1294.455
[4,     1] loss: 1294.436
[5,     1] loss: 1286.675
[6,     1] loss: 1298.862
[7,     1] loss: 1288.988
[8,     1] loss: 1286.638
[9,     1] loss: 1286.353
[10,     1] loss: 1287.119
[11,     1] loss: 1280.708
[12,     1] loss: 1278.368
[13,     1] loss: 1270.315
[14,     1] loss: 1260.060
[15,     1] loss: 1219.998
[16,     1] loss: 1201.006
[17,     1] loss: 1158.552
[18,     1] loss: 1164.168
[19,     1] loss: 1098.104
[20,     1] loss: 1095.592
[21,     1] loss: 1038.952
[22,     1] loss: 1063.569
[23,     1] loss: 1046.850
[24,     1] loss: 1059.205
[25,     1] loss: 1105.211
[26,     1] loss: 1012.814
[27,     1] loss: 1045.124
[28,     1] loss: 1019.036
[29,     1] loss: 1012.783
[30,     1] loss: 1022.109
[31,     1] loss: 978.742
[32,     1] loss: 977.393
[33,     1] loss: 992.337
[34,     1] loss: 947.568
[35,     1] loss: 965.393
[36,     1] loss: 975.377
[37,     1] loss: 927.845
[38,     1] loss: 991.782
[39,     1] loss: 967.739
[40,     1] loss: 904.808
[41,     1] loss: 934.402
[42,     1] loss: 880.046
[43,     1] loss: 855.642
[44,     1] loss: 941.853
[45,     1] loss: 912.807
[46,     1] loss: 814.264
[47,     1] loss: 851.318
[48,     1] loss: 852.497
[49,     1] loss: 816.099
[50,     1] loss: 899.538
[51,     1] loss: 831.822
[52,     1] loss: 811.292
[53,     1] loss: 857.790
[54,     1] loss: 821.357
[55,     1] loss: 807.044
[56,     1] loss: 796.619
[57,     1] loss: 816.712
[58,     1] loss: 859.557
[59,     1] loss: 730.969
[60,     1] loss: 766.573
[61,     1] loss: 737.080
[62,     1] loss: 697.580
[63,     1] loss: 737.016
[64,     1] loss: 725.711
[65,     1] loss: 697.186
[66,     1] loss: 648.464
[67,     1] loss: 638.521
[68,     1] loss: 694.560
[69,     1] loss: 644.103
[70,     1] loss: 619.603
[71,     1] loss: 594.488
[72,     1] loss: 591.392
[73,     1] loss: 605.216
[74,     1] loss: 771.574
[75,     1] loss: 1132.884
[76,     1] loss: 1032.072
[77,     1] loss: 860.225
[78,     1] loss: 704.664
[79,     1] loss: 897.588
Early stopping applied (best metric=0.7864574193954468)
Finished Training
Total time taken: 12.770011901855469
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1291.148
[2,     1] loss: 1284.765
[3,     1] loss: 1294.791
[4,     1] loss: 1285.227
[5,     1] loss: 1277.964
[6,     1] loss: 1279.395
[7,     1] loss: 1260.646
[8,     1] loss: 1216.779
[9,     1] loss: 1142.743
[10,     1] loss: 1190.022
[11,     1] loss: 1144.168
[12,     1] loss: 1089.970
[13,     1] loss: 1112.850
[14,     1] loss: 1058.932
[15,     1] loss: 1045.458
[16,     1] loss: 1035.801
[17,     1] loss: 1030.512
[18,     1] loss: 1049.527
[19,     1] loss: 984.824
[20,     1] loss: 1003.253
[21,     1] loss: 1041.342
[22,     1] loss: 980.827
[23,     1] loss: 988.967
[24,     1] loss: 986.833
[25,     1] loss: 959.161
[26,     1] loss: 988.939
[27,     1] loss: 951.888
[28,     1] loss: 1016.827
[29,     1] loss: 978.943
[30,     1] loss: 939.126
[31,     1] loss: 882.962
[32,     1] loss: 992.504
[33,     1] loss: 964.255
[34,     1] loss: 871.911
[35,     1] loss: 902.972
[36,     1] loss: 909.232
[37,     1] loss: 858.493
[38,     1] loss: 881.514
[39,     1] loss: 944.934
[40,     1] loss: 903.404
[41,     1] loss: 829.145
[42,     1] loss: 877.312
[43,     1] loss: 849.912
[44,     1] loss: 804.345
[45,     1] loss: 866.720
[46,     1] loss: 769.971
[47,     1] loss: 812.040
[48,     1] loss: 751.457
[49,     1] loss: 803.364
[50,     1] loss: 795.370
[51,     1] loss: 707.899
[52,     1] loss: 765.822
[53,     1] loss: 713.371
[54,     1] loss: 725.586
[55,     1] loss: 718.660
[56,     1] loss: 680.296
[57,     1] loss: 675.645
[58,     1] loss: 663.604
[59,     1] loss: 657.172
[60,     1] loss: 697.794
[61,     1] loss: 708.232
[62,     1] loss: 706.979
[63,     1] loss: 618.519
[64,     1] loss: 578.226
[65,     1] loss: 573.289
[66,     1] loss: 626.941
[67,     1] loss: 645.911
[68,     1] loss: 654.344
[69,     1] loss: 647.590
[70,     1] loss: 601.242
[71,     1] loss: 644.490
Early stopping applied (best metric=0.805864691734314)
Finished Training
Total time taken: 11.49500846862793
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1289.909
[2,     1] loss: 1299.940
[3,     1] loss: 1295.977
[4,     1] loss: 1287.436
[5,     1] loss: 1286.132
[6,     1] loss: 1278.817
[7,     1] loss: 1273.719
[8,     1] loss: 1263.827
[9,     1] loss: 1241.055
[10,     1] loss: 1227.210
[11,     1] loss: 1179.445
[12,     1] loss: 1131.178
[13,     1] loss: 1058.983
[14,     1] loss: 1081.477
[15,     1] loss: 1087.571
[16,     1] loss: 1101.122
[17,     1] loss: 1061.202
[18,     1] loss: 1030.789
[19,     1] loss: 1048.780
[20,     1] loss: 1025.580
[21,     1] loss: 1017.392
[22,     1] loss: 1023.890
[23,     1] loss: 1023.190
[24,     1] loss: 1012.070
[25,     1] loss: 1047.937
[26,     1] loss: 984.763
[27,     1] loss: 1023.507
[28,     1] loss: 943.025
[29,     1] loss: 976.186
[30,     1] loss: 926.940
[31,     1] loss: 927.000
[32,     1] loss: 899.338
[33,     1] loss: 928.360
[34,     1] loss: 822.925
[35,     1] loss: 960.011
[36,     1] loss: 866.982
[37,     1] loss: 872.764
[38,     1] loss: 860.807
[39,     1] loss: 844.892
[40,     1] loss: 875.998
[41,     1] loss: 804.274
[42,     1] loss: 807.438
[43,     1] loss: 783.355
[44,     1] loss: 875.672
[45,     1] loss: 919.730
[46,     1] loss: 781.814
[47,     1] loss: 866.170
Early stopping applied (best metric=0.8612107634544373)
Finished Training
Total time taken: 7.8880064487457275
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1293.650
[2,     1] loss: 1301.505
[3,     1] loss: 1290.507
[4,     1] loss: 1297.530
[5,     1] loss: 1284.459
[6,     1] loss: 1289.834
[7,     1] loss: 1282.940
[8,     1] loss: 1282.893
[9,     1] loss: 1282.474
[10,     1] loss: 1268.766
[11,     1] loss: 1260.945
[12,     1] loss: 1213.695
[13,     1] loss: 1193.174
[14,     1] loss: 1140.659
[15,     1] loss: 1106.589
[16,     1] loss: 1094.458
[17,     1] loss: 1063.313
[18,     1] loss: 1058.898
[19,     1] loss: 1054.978
[20,     1] loss: 1069.761
[21,     1] loss: 1050.566
[22,     1] loss: 1068.198
[23,     1] loss: 1037.580
[24,     1] loss: 1038.646
[25,     1] loss: 995.704
[26,     1] loss: 1000.810
[27,     1] loss: 1000.753
[28,     1] loss: 952.907
[29,     1] loss: 906.159
[30,     1] loss: 951.695
[31,     1] loss: 918.285
[32,     1] loss: 846.477
[33,     1] loss: 872.489
[34,     1] loss: 839.915
[35,     1] loss: 877.679
[36,     1] loss: 910.740
[37,     1] loss: 831.822
[38,     1] loss: 812.122
[39,     1] loss: 824.074
[40,     1] loss: 835.189
[41,     1] loss: 798.004
[42,     1] loss: 779.177
[43,     1] loss: 728.159
[44,     1] loss: 742.811
[45,     1] loss: 716.337
[46,     1] loss: 760.149
[47,     1] loss: 744.529
Early stopping applied (best metric=0.8466101288795471)
Finished Training
Total time taken: 7.8140058517456055
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1289.533
[2,     1] loss: 1296.931
[3,     1] loss: 1296.757
[4,     1] loss: 1294.704
[5,     1] loss: 1290.622
[6,     1] loss: 1295.674
[7,     1] loss: 1288.654
[8,     1] loss: 1287.189
[9,     1] loss: 1285.439
[10,     1] loss: 1286.831
[11,     1] loss: 1284.618
[12,     1] loss: 1277.704
[13,     1] loss: 1270.084
[14,     1] loss: 1247.642
[15,     1] loss: 1224.252
[16,     1] loss: 1175.812
[17,     1] loss: 1159.516
[18,     1] loss: 1124.789
[19,     1] loss: 1130.966
[20,     1] loss: 1046.843
[21,     1] loss: 1080.487
[22,     1] loss: 1088.432
[23,     1] loss: 1055.102
[24,     1] loss: 1021.385
[25,     1] loss: 1032.187
[26,     1] loss: 1049.819
[27,     1] loss: 1007.023
[28,     1] loss: 1018.880
[29,     1] loss: 1008.516
[30,     1] loss: 1010.216
[31,     1] loss: 1011.624
[32,     1] loss: 957.706
[33,     1] loss: 969.708
[34,     1] loss: 959.051
[35,     1] loss: 900.865
[36,     1] loss: 965.382
[37,     1] loss: 962.098
[38,     1] loss: 929.241
[39,     1] loss: 893.687
[40,     1] loss: 1007.016
[41,     1] loss: 920.152
[42,     1] loss: 884.324
[43,     1] loss: 873.943
[44,     1] loss: 866.506
[45,     1] loss: 839.412
[46,     1] loss: 878.434
[47,     1] loss: 835.286
[48,     1] loss: 776.654
[49,     1] loss: 845.633
[50,     1] loss: 906.613
[51,     1] loss: 790.518
[52,     1] loss: 794.342
[53,     1] loss: 814.586
[54,     1] loss: 790.553
[55,     1] loss: 767.694
[56,     1] loss: 796.750
[57,     1] loss: 735.310
[58,     1] loss: 721.520
[59,     1] loss: 792.490
[60,     1] loss: 715.101
[61,     1] loss: 798.038
[62,     1] loss: 753.427
Early stopping applied (best metric=0.8672164678573608)
Finished Training
Total time taken: 10.136006832122803
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1291.047
[2,     1] loss: 1306.647
[3,     1] loss: 1295.029
[4,     1] loss: 1297.091
[5,     1] loss: 1289.985
[6,     1] loss: 1289.581
[7,     1] loss: 1288.725
[8,     1] loss: 1287.493
[9,     1] loss: 1287.142
[10,     1] loss: 1286.735
[11,     1] loss: 1279.326
[12,     1] loss: 1280.142
[13,     1] loss: 1264.709
[14,     1] loss: 1243.791
[15,     1] loss: 1222.750
[16,     1] loss: 1191.528
[17,     1] loss: 1149.519
[18,     1] loss: 1121.810
[19,     1] loss: 1095.195
[20,     1] loss: 1057.870
[21,     1] loss: 1105.200
[22,     1] loss: 1105.645
[23,     1] loss: 1033.604
[24,     1] loss: 1049.618
[25,     1] loss: 1029.221
[26,     1] loss: 1032.265
[27,     1] loss: 1023.450
[28,     1] loss: 1016.596
[29,     1] loss: 1038.479
[30,     1] loss: 998.701
[31,     1] loss: 991.981
[32,     1] loss: 940.017
[33,     1] loss: 922.876
[34,     1] loss: 911.137
[35,     1] loss: 913.487
Early stopping applied (best metric=0.9846686720848083)
Finished Training
Total time taken: 5.8600029945373535
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1290.440
[2,     1] loss: 1298.068
[3,     1] loss: 1294.900
[4,     1] loss: 1289.727
[5,     1] loss: 1288.595
[6,     1] loss: 1289.114
[7,     1] loss: 1290.230
[8,     1] loss: 1287.459
[9,     1] loss: 1288.022
[10,     1] loss: 1288.514
[11,     1] loss: 1287.021
[12,     1] loss: 1292.280
[13,     1] loss: 1286.375
[14,     1] loss: 1287.430
[15,     1] loss: 1283.992
[16,     1] loss: 1285.822
[17,     1] loss: 1281.974
[18,     1] loss: 1281.078
[19,     1] loss: 1272.732
[20,     1] loss: 1255.863
[21,     1] loss: 1236.762
[22,     1] loss: 1206.988
[23,     1] loss: 1185.815
[24,     1] loss: 1159.589
[25,     1] loss: 1160.516
[26,     1] loss: 1110.198
[27,     1] loss: 1089.891
[28,     1] loss: 1107.109
[29,     1] loss: 1087.645
[30,     1] loss: 1086.195
[31,     1] loss: 1070.955
[32,     1] loss: 1057.943
[33,     1] loss: 1056.525
[34,     1] loss: 1039.534
[35,     1] loss: 1039.061
[36,     1] loss: 1072.441
[37,     1] loss: 1006.068
[38,     1] loss: 1025.691
[39,     1] loss: 938.093
[40,     1] loss: 1007.179
[41,     1] loss: 914.944
[42,     1] loss: 966.251
[43,     1] loss: 966.003
[44,     1] loss: 914.851
[45,     1] loss: 905.911
[46,     1] loss: 905.505
[47,     1] loss: 887.601
[48,     1] loss: 919.257
[49,     1] loss: 874.465
[50,     1] loss: 926.875
[51,     1] loss: 809.367
[52,     1] loss: 885.552
[53,     1] loss: 782.829
[54,     1] loss: 882.427
[55,     1] loss: 832.600
[56,     1] loss: 835.120
[57,     1] loss: 813.298
[58,     1] loss: 898.940
[59,     1] loss: 762.801
[60,     1] loss: 812.604
[61,     1] loss: 723.028
[62,     1] loss: 749.894
Early stopping applied (best metric=0.6968574523925781)
Finished Training
Total time taken: 10.542009592056274
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1293.119
[2,     1] loss: 1288.900
[3,     1] loss: 1296.635
[4,     1] loss: 1291.306
[5,     1] loss: 1282.307
[6,     1] loss: 1265.272
[7,     1] loss: 1229.116
[8,     1] loss: 1168.239
[9,     1] loss: 1220.854
[10,     1] loss: 1152.986
[11,     1] loss: 1138.199
[12,     1] loss: 1093.521
[13,     1] loss: 1132.681
[14,     1] loss: 1051.748
[15,     1] loss: 1069.444
[16,     1] loss: 1049.117
[17,     1] loss: 1069.364
[18,     1] loss: 1051.876
[19,     1] loss: 1016.981
[20,     1] loss: 1028.579
[21,     1] loss: 1064.287
[22,     1] loss: 979.045
[23,     1] loss: 974.508
[24,     1] loss: 974.234
[25,     1] loss: 991.689
[26,     1] loss: 958.819
[27,     1] loss: 1003.989
[28,     1] loss: 964.729
[29,     1] loss: 944.916
[30,     1] loss: 960.334
[31,     1] loss: 901.369
[32,     1] loss: 912.673
[33,     1] loss: 889.893
[34,     1] loss: 882.785
[35,     1] loss: 853.832
[36,     1] loss: 861.081
[37,     1] loss: 792.970
[38,     1] loss: 817.275
[39,     1] loss: 862.401
[40,     1] loss: 1025.325
[41,     1] loss: 810.357
[42,     1] loss: 900.433
[43,     1] loss: 818.096
[44,     1] loss: 849.950
[45,     1] loss: 781.777
Early stopping applied (best metric=0.8098786473274231)
Finished Training
Total time taken: 7.648005962371826
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1294.672
[2,     1] loss: 1293.544
[3,     1] loss: 1288.193
[4,     1] loss: 1288.573
[5,     1] loss: 1280.749
[6,     1] loss: 1280.598
[7,     1] loss: 1258.093
[8,     1] loss: 1233.017
[9,     1] loss: 1200.960
[10,     1] loss: 1206.718
[11,     1] loss: 1132.870
[12,     1] loss: 1114.317
[13,     1] loss: 1069.034
[14,     1] loss: 1101.206
[15,     1] loss: 1044.001
[16,     1] loss: 1055.953
[17,     1] loss: 1038.096
[18,     1] loss: 1088.967
[19,     1] loss: 1062.697
[20,     1] loss: 1023.255
[21,     1] loss: 1052.298
[22,     1] loss: 1009.875
[23,     1] loss: 973.104
[24,     1] loss: 960.095
[25,     1] loss: 980.291
[26,     1] loss: 1001.270
[27,     1] loss: 998.959
[28,     1] loss: 951.588
[29,     1] loss: 977.013
[30,     1] loss: 901.325
[31,     1] loss: 925.911
[32,     1] loss: 897.668
[33,     1] loss: 925.419
[34,     1] loss: 882.412
[35,     1] loss: 885.317
[36,     1] loss: 915.723
[37,     1] loss: 841.752
[38,     1] loss: 844.428
[39,     1] loss: 870.750
[40,     1] loss: 837.511
[41,     1] loss: 792.371
[42,     1] loss: 767.782
Early stopping applied (best metric=0.8124173283576965)
Finished Training
Total time taken: 7.259005308151245
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1297.754
[2,     1] loss: 1294.747
[3,     1] loss: 1291.317
[4,     1] loss: 1288.809
[5,     1] loss: 1289.291
[6,     1] loss: 1282.010
[7,     1] loss: 1285.961
[8,     1] loss: 1281.023
[9,     1] loss: 1263.276
[10,     1] loss: 1242.524
[11,     1] loss: 1210.724
[12,     1] loss: 1188.192
[13,     1] loss: 1167.823
[14,     1] loss: 1155.097
[15,     1] loss: 1100.134
[16,     1] loss: 1141.875
[17,     1] loss: 1091.207
[18,     1] loss: 1108.896
[19,     1] loss: 1065.829
[20,     1] loss: 1071.754
[21,     1] loss: 1030.777
[22,     1] loss: 1074.366
[23,     1] loss: 1088.850
[24,     1] loss: 1021.376
[25,     1] loss: 1029.005
[26,     1] loss: 1035.549
[27,     1] loss: 976.604
[28,     1] loss: 992.460
[29,     1] loss: 935.518
[30,     1] loss: 953.241
[31,     1] loss: 977.881
[32,     1] loss: 922.102
[33,     1] loss: 920.312
[34,     1] loss: 969.124
[35,     1] loss: 893.528
[36,     1] loss: 902.718
[37,     1] loss: 941.475
[38,     1] loss: 814.429
[39,     1] loss: 977.867
[40,     1] loss: 899.045
[41,     1] loss: 865.916
[42,     1] loss: 869.957
[43,     1] loss: 848.987
[44,     1] loss: 816.475
[45,     1] loss: 774.534
[46,     1] loss: 812.037
[47,     1] loss: 821.882
[48,     1] loss: 822.442
[49,     1] loss: 751.541
[50,     1] loss: 750.299
[51,     1] loss: 735.055
[52,     1] loss: 691.434
Early stopping applied (best metric=0.7263687252998352)
Finished Training
Total time taken: 8.95200777053833
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1286.823
[2,     1] loss: 1298.053
[3,     1] loss: 1293.254
[4,     1] loss: 1300.181
[5,     1] loss: 1297.048
[6,     1] loss: 1288.778
[7,     1] loss: 1284.266
[8,     1] loss: 1284.782
[9,     1] loss: 1277.941
[10,     1] loss: 1265.893
[11,     1] loss: 1244.442
[12,     1] loss: 1201.885
[13,     1] loss: 1184.824
[14,     1] loss: 1196.110
[15,     1] loss: 1092.158
[16,     1] loss: 1155.479
[17,     1] loss: 1082.257
[18,     1] loss: 1104.862
[19,     1] loss: 1107.708
[20,     1] loss: 1058.664
[21,     1] loss: 1095.204
[22,     1] loss: 1044.771
[23,     1] loss: 1053.414
[24,     1] loss: 1037.695
[25,     1] loss: 1007.451
[26,     1] loss: 1031.607
[27,     1] loss: 984.227
[28,     1] loss: 954.852
[29,     1] loss: 994.105
[30,     1] loss: 1011.575
[31,     1] loss: 1010.610
[32,     1] loss: 965.282
[33,     1] loss: 969.646
[34,     1] loss: 953.918
[35,     1] loss: 945.773
[36,     1] loss: 959.852
[37,     1] loss: 917.900
[38,     1] loss: 924.378
[39,     1] loss: 908.999
[40,     1] loss: 920.739
[41,     1] loss: 897.310
[42,     1] loss: 903.096
[43,     1] loss: 860.830
[44,     1] loss: 852.485
[45,     1] loss: 841.626
[46,     1] loss: 852.981
[47,     1] loss: 822.851
[48,     1] loss: 826.750
[49,     1] loss: 815.865
[50,     1] loss: 812.497
[51,     1] loss: 797.637
[52,     1] loss: 796.272
[53,     1] loss: 774.991
[54,     1] loss: 856.772
[55,     1] loss: 1050.147
[56,     1] loss: 904.856
[57,     1] loss: 922.339
[58,     1] loss: 800.481
Early stopping applied (best metric=0.754815936088562)
Finished Training
Total time taken: 10.026008129119873
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1289.357
[2,     1] loss: 1294.933
[3,     1] loss: 1293.716
[4,     1] loss: 1285.298
[5,     1] loss: 1279.209
[6,     1] loss: 1280.360
[7,     1] loss: 1253.225
[8,     1] loss: 1220.854
[9,     1] loss: 1196.214
[10,     1] loss: 1182.603
[11,     1] loss: 1117.379
[12,     1] loss: 1088.248
[13,     1] loss: 1114.305
[14,     1] loss: 1040.007
[15,     1] loss: 1071.218
[16,     1] loss: 1015.664
[17,     1] loss: 1029.365
[18,     1] loss: 1067.584
[19,     1] loss: 1045.198
[20,     1] loss: 1061.748
[21,     1] loss: 1015.310
[22,     1] loss: 1016.810
[23,     1] loss: 995.087
[24,     1] loss: 955.292
[25,     1] loss: 938.431
[26,     1] loss: 971.771
[27,     1] loss: 946.587
[28,     1] loss: 963.587
[29,     1] loss: 969.652
[30,     1] loss: 928.647
[31,     1] loss: 903.213
[32,     1] loss: 906.098
[33,     1] loss: 1004.771
[34,     1] loss: 993.203
[35,     1] loss: 903.114
[36,     1] loss: 951.170
[37,     1] loss: 904.965
[38,     1] loss: 887.241
[39,     1] loss: 930.443
[40,     1] loss: 851.622
[41,     1] loss: 900.020
[42,     1] loss: 805.129
[43,     1] loss: 819.278
[44,     1] loss: 790.233
[45,     1] loss: 795.255
[46,     1] loss: 782.757
[47,     1] loss: 749.162
[48,     1] loss: 730.135
[49,     1] loss: 756.809
Early stopping applied (best metric=0.7992441654205322)
Finished Training
Total time taken: 8.530006170272827
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1293.245
[2,     1] loss: 1303.088
[3,     1] loss: 1289.001
[4,     1] loss: 1288.293
[5,     1] loss: 1293.102
[6,     1] loss: 1288.791
[7,     1] loss: 1284.256
[8,     1] loss: 1294.502
[9,     1] loss: 1290.507
[10,     1] loss: 1280.325
[11,     1] loss: 1281.547
[12,     1] loss: 1268.411
[13,     1] loss: 1270.358
[14,     1] loss: 1251.263
[15,     1] loss: 1231.185
[16,     1] loss: 1207.866
[17,     1] loss: 1200.707
[18,     1] loss: 1162.409
[19,     1] loss: 1120.167
[20,     1] loss: 1132.433
[21,     1] loss: 1137.259
[22,     1] loss: 1141.330
[23,     1] loss: 1137.470
[24,     1] loss: 1075.255
[25,     1] loss: 1111.113
[26,     1] loss: 1061.968
[27,     1] loss: 1080.061
[28,     1] loss: 1036.264
[29,     1] loss: 1032.443
[30,     1] loss: 989.657
[31,     1] loss: 1011.086
[32,     1] loss: 1035.936
[33,     1] loss: 979.507
[34,     1] loss: 1013.369
[35,     1] loss: 1012.435
[36,     1] loss: 1000.426
[37,     1] loss: 947.223
[38,     1] loss: 917.680
[39,     1] loss: 928.135
[40,     1] loss: 906.131
[41,     1] loss: 923.550
[42,     1] loss: 904.281
[43,     1] loss: 844.502
[44,     1] loss: 867.635
[45,     1] loss: 866.745
[46,     1] loss: 838.105
[47,     1] loss: 856.397
[48,     1] loss: 845.223
[49,     1] loss: 764.610
[50,     1] loss: 787.126
[51,     1] loss: 799.157
[52,     1] loss: 864.382
[53,     1] loss: 786.200
[54,     1] loss: 756.497
Early stopping applied (best metric=0.7144930958747864)
Finished Training
Total time taken: 9.44700837135315
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1293.957
[2,     1] loss: 1300.506
[3,     1] loss: 1292.427
[4,     1] loss: 1284.885
[5,     1] loss: 1289.915
[6,     1] loss: 1290.383
[7,     1] loss: 1286.378
[8,     1] loss: 1284.218
[9,     1] loss: 1275.015
[10,     1] loss: 1264.105
[11,     1] loss: 1245.024
[12,     1] loss: 1201.474
[13,     1] loss: 1158.272
[14,     1] loss: 1099.445
[15,     1] loss: 1093.834
[16,     1] loss: 1128.182
[17,     1] loss: 1089.698
[18,     1] loss: 1127.981
[19,     1] loss: 1045.540
[20,     1] loss: 1059.133
[21,     1] loss: 1027.895
[22,     1] loss: 1018.515
[23,     1] loss: 1060.740
[24,     1] loss: 1001.941
[25,     1] loss: 986.670
[26,     1] loss: 1000.201
[27,     1] loss: 999.031
[28,     1] loss: 952.902
[29,     1] loss: 966.099
[30,     1] loss: 901.942
[31,     1] loss: 944.246
[32,     1] loss: 961.408
[33,     1] loss: 946.536
[34,     1] loss: 911.232
[35,     1] loss: 905.137
[36,     1] loss: 900.639
[37,     1] loss: 856.369
[38,     1] loss: 874.401
[39,     1] loss: 868.335
[40,     1] loss: 844.097
[41,     1] loss: 848.847
[42,     1] loss: 809.688
[43,     1] loss: 827.091
[44,     1] loss: 844.783
[45,     1] loss: 805.189
[46,     1] loss: 854.179
[47,     1] loss: 801.950
[48,     1] loss: 777.817
[49,     1] loss: 802.784
[50,     1] loss: 788.154
[51,     1] loss: 770.126
[52,     1] loss: 776.182
[53,     1] loss: 714.465
[54,     1] loss: 670.869
[55,     1] loss: 679.430
[56,     1] loss: 679.160
[57,     1] loss: 696.287
[58,     1] loss: 760.084
[59,     1] loss: 852.899
[60,     1] loss: 628.813
[61,     1] loss: 677.146
[62,     1] loss: 693.431
[63,     1] loss: 719.844
[64,     1] loss: 694.252
[65,     1] loss: 673.466
[66,     1] loss: 657.396
[67,     1] loss: 683.942
[68,     1] loss: 659.100
[69,     1] loss: 582.319
[70,     1] loss: 608.143
[71,     1] loss: 601.838
[72,     1] loss: 655.855
[73,     1] loss: 517.120
Early stopping applied (best metric=0.685350775718689)
Finished Training
Total time taken: 12.890011310577393
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1310
[1,     1] loss: 1293.302
[2,     1] loss: 1299.234
[3,     1] loss: 1294.281
[4,     1] loss: 1291.293
[5,     1] loss: 1289.347
[6,     1] loss: 1293.654
[7,     1] loss: 1285.201
[8,     1] loss: 1289.670
[9,     1] loss: 1288.071
[10,     1] loss: 1286.566
[11,     1] loss: 1290.229
[12,     1] loss: 1283.047
[13,     1] loss: 1280.931
[14,     1] loss: 1277.871
[15,     1] loss: 1263.457
[16,     1] loss: 1254.284
[17,     1] loss: 1229.886
[18,     1] loss: 1212.323
[19,     1] loss: 1174.550
[20,     1] loss: 1149.870
[21,     1] loss: 1118.452
[22,     1] loss: 1110.466
[23,     1] loss: 1087.682
[24,     1] loss: 1163.674
[25,     1] loss: 1065.322
[26,     1] loss: 1095.724
[27,     1] loss: 1030.985
[28,     1] loss: 1107.004
[29,     1] loss: 1026.571
[30,     1] loss: 1067.992
[31,     1] loss: 1079.515
[32,     1] loss: 1004.579
[33,     1] loss: 1038.953
[34,     1] loss: 1044.875
[35,     1] loss: 1007.629
[36,     1] loss: 1017.679
[37,     1] loss: 989.410
[38,     1] loss: 895.375
[39,     1] loss: 970.377
[40,     1] loss: 969.601
[41,     1] loss: 966.715
[42,     1] loss: 986.576
[43,     1] loss: 893.128
[44,     1] loss: 962.553
[45,     1] loss: 907.360
[46,     1] loss: 924.437
[47,     1] loss: 888.213
[48,     1] loss: 911.541
[49,     1] loss: 925.580
[50,     1] loss: 923.378
[51,     1] loss: 939.381
[52,     1] loss: 850.867
[53,     1] loss: 844.741
[54,     1] loss: 841.524
[55,     1] loss: 897.164
[56,     1] loss: 827.236
[57,     1] loss: 784.749
[58,     1] loss: 849.198
[59,     1] loss: 889.966
[60,     1] loss: 790.043
Early stopping applied (best metric=0.8549529910087585)
Finished Training
Total time taken: 10.600009441375732
(48, 33)
(190, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(176, 33)
(819, 33)
Loaded folder code/Thesis/dataset/train/Hydroxylation-P/indices (995 samples)
386 304
1663 1312
[1,     1] loss: 1292.747
[2,     1] loss: 1299.157
[3,     1] loss: 1295.788
[4,     1] loss: 1292.280
[5,     1] loss: 1287.633
[6,     1] loss: 1277.735
[7,     1] loss: 1260.938
[8,     1] loss: 1226.443
[9,     1] loss: 1170.096
[10,     1] loss: 1168.907
[11,     1] loss: 1097.491
[12,     1] loss: 1124.596
[13,     1] loss: 1139.133
[14,     1] loss: 1067.812
[15,     1] loss: 1087.155
[16,     1] loss: 1041.249
[17,     1] loss: 1087.468
[18,     1] loss: 1059.854
[19,     1] loss: 1068.770
[20,     1] loss: 1021.470
[21,     1] loss: 1026.993
[22,     1] loss: 976.920
[23,     1] loss: 988.343
[24,     1] loss: 1016.755
[25,     1] loss: 954.712
[26,     1] loss: 963.419
[27,     1] loss: 937.897
[28,     1] loss: 1011.248
[29,     1] loss: 977.694
[30,     1] loss: 906.337
[31,     1] loss: 920.519
[32,     1] loss: 916.256
[33,     1] loss: 935.086
[34,     1] loss: 883.950
[35,     1] loss: 840.203
[36,     1] loss: 866.730
[37,     1] loss: 889.541
[38,     1] loss: 878.636
[39,     1] loss: 848.951
[40,     1] loss: 837.607
[41,     1] loss: 832.739
[42,     1] loss: 804.670
[43,     1] loss: 838.928
[44,     1] loss: 783.993
[45,     1] loss: 764.578
[46,     1] loss: 785.729
[47,     1] loss: 897.315
[48,     1] loss: 1285.341
[49,     1] loss: 844.195
[50,     1] loss: 990.022
[51,     1] loss: 874.415
[52,     1] loss: 875.405
[53,     1] loss: 907.537
[54,     1] loss: 870.860
[55,     1] loss: 823.355
[56,     1] loss: 861.090
[57,     1] loss: 789.455
[58,     1] loss: 791.630
[59,     1] loss: 784.833
[60,     1] loss: 758.013
[61,     1] loss: 738.041
[62,     1] loss: 724.841
[63,     1] loss: 683.341
[64,     1] loss: 688.388
Early stopping applied (best metric=0.7223137617111206)
Finished Training
Total time taken: 11.245008707046509
results!
{'gpu_mode': True, 'epochs': 200, 'batch_size': 2048, 'learning_rate': 0.004884319121536182, 'test_data_ratio': 0.2, 'data_sample_mode': ['oversample', 'oversample', 'oversample', 'oversample', 'oversample', 'oversample', 'oversample', 'oversample', 'oversample', 'oversample', 'oversample', 'oversample', 'oversample'], 'crossValidation': True, 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'folds': 5, 'earlyStopping': True, 'ValidationMetric': 'Validation Loss (total)', 'earlyStoppingPatience': 20, 'CV_Repeats': 5, 'Experiment Name': 'Model architecture - added max, ranges, bceloss', 'CreateFigures': False, 'weight_decay': 3.2210039170929328, 'embeddingType': 'adaptiveEmbedding', 'LSTM_layers': 1, 'LSTM_hidden_size': 128, 'LSTM_dropout': 0, 'MultiTask': True, 'MultiTask_sample_method': 'balanced', 'UseUncertaintyBasedLoss': False, 'useLrWeight': True, 'CNNType': 'Musite', 'FCType': 'Adapt', 'layerToSplitOn': 'FC', 'dontAverageLoss': False, 'useWeightDecayWeight': False, 'SeperateTuningLRandWD': True, 'aminoAcid': ['Hydroxylation-K', 'Hydroxylation-P'], 'n_trials': 500, 'FloatsToTune': {'learning_rate': [1e-05, 0.01], 'weight_decay': [0, 10], 'log_base': [1.01, 3], 'learning_rate_Hydroxylation-K': [1e-05, 0.01], 'learning_rate_Hydroxylation-P': [1e-05, 0.01], 'weight_decay_Hydroxylation-P': [0, 10], 'weight_decay_Hydroxylation-K': [0, 10]}, 'IntsToTune': {}, 'log_base': 2.5184787258467276, 'learning_rate_Hydroxylation-K': 0.003731690912553525, 'learning_rate_Hydroxylation-P': 0.0043710434635619595, 'weight_decay_Hydroxylation-P': 2.338744649903835, 'weight_decay_Hydroxylation-K': 4.372713172070321, 'random_state': 2717163571, 'current_CV_Repeat': 5, 'sample_weights': [1.8087721791195317, 1], 'WeightDecayWeights': [], 'currentFold': 4}
{'Hydroxylation-K Validation Accuracy': 0.7881028368794326, 'Hydroxylation-K Validation Sensitivity': 0.6777777777777778, 'Hydroxylation-K Validation Specificity': 0.8157894736842105, 'Hydroxylation-K Validation Precision': 0.4923247863247863, 'Hydroxylation-K AUC ROC': 0.8162222222222223, 'Hydroxylation-K AUC PR': 0.6334213500126453, 'Hydroxylation-K MCC': 0.44504813239978297, 'Hydroxylation-K F1': 0.5646138834969151, 'Validation Loss (Hydroxylation-K)': 0.41683208584785464, 'Hydroxylation-P Validation Accuracy': 0.7955656464138876, 'Hydroxylation-P Validation Sensitivity': 0.7771111111111111, 'Hydroxylation-P Validation Specificity': 0.7994942391141703, 'Hydroxylation-P Validation Precision': 0.4609179855577971, 'Hydroxylation-P AUC ROC': 0.8504339463552392, 'Hydroxylation-P AUC PR': 0.5787797660765297, 'Hydroxylation-P MCC': 0.48270172233454184, 'Hydroxylation-P F1': 0.5763440825794244, 'Validation Loss (Hydroxylation-P)': 0.37093281745910645, 'Validation Loss (total)': 0.7877649021148682, 'TimeToTrain': 9.78400848388672}
{'Hydroxylation-K Validation Accuracy': 0.05718879372879081, 'Hydroxylation-K Validation Sensitivity': 0.13709958532503408, 'Hydroxylation-K Validation Specificity': 0.06264410902230569, 'Hydroxylation-K Validation Precision': 0.11148306619619903, 'Hydroxylation-K AUC ROC': 0.08751829309430902, 'Hydroxylation-K AUC PR': 0.15354972804828107, 'Hydroxylation-K MCC': 0.13932768882042057, 'Hydroxylation-K F1': 0.10477300978878147, 'Validation Loss (Hydroxylation-K)': 0.06906796821245356, 'Hydroxylation-P Validation Accuracy': 0.040950810636710626, 'Hydroxylation-P Validation Sensitivity': 0.06556338590384589, 'Hydroxylation-P Validation Specificity': 0.048915896669698304, 'Hydroxylation-P Validation Precision': 0.06122409354491608, 'Hydroxylation-P AUC ROC': 0.030212551223574254, 'Hydroxylation-P AUC PR': 0.06253199454517896, 'Hydroxylation-P MCC': 0.07324986415660888, 'Hydroxylation-P F1': 0.05678062030337153, 'Validation Loss (Hydroxylation-P)': 0.035204549572063655, 'Validation Loss (total)': 0.07115393839187482, 'TimeToTrain': 1.8757267365518315}
