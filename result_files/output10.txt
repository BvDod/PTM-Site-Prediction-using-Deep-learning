{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007985139418633843,
 'learning_rate_Hydroxylation-K': 0.005109272633158075,
 'learning_rate_Methylation-K': 0.008925706222571215,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.41960132022984614,
 'loss_weight_Methylation-K': 0.11036646661942616,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1529292013,
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.035644617736715,
 'weight_decay_Hydroxylation-K': 9.479252489835936,
 'weight_decay_Methylation-K': 4.936329965786483}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.389
[3,     4] loss: 1.386
[4,     4] loss: 1.387
[5,     4] loss: 1.384
[6,     4] loss: 1.385
[7,     4] loss: 1.388
[8,     4] loss: 1.387
[9,     4] loss: 1.386
[10,     4] loss: 1.387
[11,     4] loss: 1.387
[12,     4] loss: 1.387
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.387
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.387
[21,     4] loss: 1.387
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.387
[32,     4] loss: 1.386
[33,     4] loss: 1.387
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.385
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.385
[42,     4] loss: 1.385
[43,     4] loss: 1.387
[44,     4] loss: 1.386
[45,     4] loss: 1.387
[46,     4] loss: 1.386
[47,     4] loss: 1.387
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
Early stopping applied (best metric=0.5628811120986938)
Finished Training
Total time taken: 37.64146137237549
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.378
[2,     4] loss: 1.386
[3,     4] loss: 1.386
[4,     4] loss: 1.387
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.387
[18,     4] loss: 1.387
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.387
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.385
[29,     4] loss: 1.388
[30,     4] loss: 1.387
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.387
[41,     4] loss: 1.387
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.386
[53,     4] loss: 1.387
Early stopping applied (best metric=0.5628477931022644)
Finished Training
Total time taken: 28.16693425178528
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.378
[2,     4] loss: 1.382
[3,     4] loss: 1.386
[4,     4] loss: 1.386
[5,     4] loss: 1.386
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.386
[9,     4] loss: 1.386
[10,     4] loss: 1.386
[11,     4] loss: 1.385
[12,     4] loss: 1.386
[13,     4] loss: 1.378
[14,     4] loss: 1.345
[15,     4] loss: 1.311
[16,     4] loss: 1.319
[17,     4] loss: 1.267
[18,     4] loss: 1.234
[19,     4] loss: 1.203
[20,     4] loss: 1.373
[21,     4] loss: 1.300
[22,     4] loss: 1.225
[23,     4] loss: 1.155
[24,     4] loss: 1.060
[25,     4] loss: 1.146
[26,     4] loss: 1.180
[27,     4] loss: 1.149
[28,     4] loss: 1.077
[29,     4] loss: 0.994
[30,     4] loss: 1.121
[31,     4] loss: 1.175
[32,     4] loss: 1.144
[33,     4] loss: 1.072
[34,     4] loss: 1.083
[35,     4] loss: 1.043
[36,     4] loss: 1.035
[37,     4] loss: 1.009
[38,     4] loss: 1.082
[39,     4] loss: 0.967
[40,     4] loss: 1.043
[41,     4] loss: 0.988
[42,     4] loss: 0.999
[43,     4] loss: 1.010
[44,     4] loss: 1.008
[45,     4] loss: 0.936
[46,     4] loss: 1.047
[47,     4] loss: 0.970
[48,     4] loss: 0.954
[49,     4] loss: 1.012
[50,     4] loss: 1.031
[51,     4] loss: 1.030
[52,     4] loss: 1.054
[53,     4] loss: 1.042
[54,     4] loss: 0.960
[55,     4] loss: 1.017
[56,     4] loss: 0.944
[57,     4] loss: 1.024
[58,     4] loss: 1.001
[59,     4] loss: 1.064
[60,     4] loss: 1.009
[61,     4] loss: 0.975
[62,     4] loss: 0.924
[63,     4] loss: 1.235
[64,     4] loss: 1.146
[65,     4] loss: 1.226
[66,     4] loss: 1.187
[67,     4] loss: 1.088
[68,     4] loss: 0.973
[69,     4] loss: 1.194
[70,     4] loss: 1.273
[71,     4] loss: 1.236
[72,     4] loss: 1.382
[73,     4] loss: 1.393
[74,     4] loss: 1.384
[75,     4] loss: 1.385
[76,     4] loss: 1.385
[77,     4] loss: 1.386
[78,     4] loss: 1.387
[79,     4] loss: 1.386
[80,     4] loss: 1.386
[81,     4] loss: 1.386
[82,     4] loss: 1.386
[83,     4] loss: 1.386
[84,     4] loss: 1.386
[85,     4] loss: 1.386
Early stopping applied (best metric=0.43616145849227905)
Finished Training
Total time taken: 50.49508881568909
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.389
[3,     4] loss: 1.387
[4,     4] loss: 1.383
[5,     4] loss: 1.387
[6,     4] loss: 1.385
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.385
[10,     4] loss: 1.388
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.378
[18,     4] loss: 1.360
[19,     4] loss: 1.356
[20,     4] loss: 1.345
[21,     4] loss: 1.344
[22,     4] loss: 1.332
[23,     4] loss: 1.333
[24,     4] loss: 1.250
[25,     4] loss: 1.182
[26,     4] loss: 1.348
[27,     4] loss: 1.250
[28,     4] loss: 1.222
[29,     4] loss: 1.189
[30,     4] loss: 1.144
[31,     4] loss: 1.154
[32,     4] loss: 1.172
[33,     4] loss: 1.087
[34,     4] loss: 1.094
[35,     4] loss: 1.083
[36,     4] loss: 1.100
[37,     4] loss: 1.036
[38,     4] loss: 1.122
[39,     4] loss: 1.293
[40,     4] loss: 1.259
[41,     4] loss: 1.164
[42,     4] loss: 1.107
[43,     4] loss: 1.163
[44,     4] loss: 1.264
[45,     4] loss: 1.272
[46,     4] loss: 1.206
[47,     4] loss: 1.121
[48,     4] loss: 1.280
[49,     4] loss: 1.275
[50,     4] loss: 1.371
[51,     4] loss: 1.288
[52,     4] loss: 1.164
[53,     4] loss: 1.230
[54,     4] loss: 1.171
[55,     4] loss: 1.141
[56,     4] loss: 1.095
[57,     4] loss: 1.186
[58,     4] loss: 1.168
[59,     4] loss: 1.106
[60,     4] loss: 0.985
[61,     4] loss: 1.154
[62,     4] loss: 1.090
[63,     4] loss: 1.071
[64,     4] loss: 1.063
[65,     4] loss: 1.113
[66,     4] loss: 1.031
[67,     4] loss: 1.007
[68,     4] loss: 0.955
[69,     4] loss: 0.967
[70,     4] loss: 1.311
[71,     4] loss: 1.330
[72,     4] loss: 1.370
[73,     4] loss: 1.375
[74,     4] loss: 1.371
[75,     4] loss: 1.370
[76,     4] loss: 1.349
[77,     4] loss: 1.326
[78,     4] loss: 1.296
[79,     4] loss: 1.328
[80,     4] loss: 1.253
[81,     4] loss: 1.225
[82,     4] loss: 1.146
[83,     4] loss: 1.177
[84,     4] loss: 1.070
[85,     4] loss: 1.146
[86,     4] loss: 1.104
[87,     4] loss: 1.099
[88,     4] loss: 1.140
[89,     4] loss: 1.119
[90,     4] loss: 1.082
[91,     4] loss: 1.078
[92,     4] loss: 1.062
[93,     4] loss: 1.212
[94,     4] loss: 1.243
[95,     4] loss: 1.208
[96,     4] loss: 1.092
[97,     4] loss: 0.966
[98,     4] loss: 1.030
[99,     4] loss: 1.090
[100,     4] loss: 1.069
[101,     4] loss: 0.993
[102,     4] loss: 0.981
[103,     4] loss: 1.206
[104,     4] loss: 1.214
[105,     4] loss: 1.209
[106,     4] loss: 1.188
[107,     4] loss: 1.224
[108,     4] loss: 1.134
[109,     4] loss: 1.066
[110,     4] loss: 1.013
[111,     4] loss: 1.245
[112,     4] loss: 1.218
[113,     4] loss: 1.168
[114,     4] loss: 1.104
[115,     4] loss: 1.104
Early stopping applied (best metric=0.3766578435897827)
Finished Training
Total time taken: 61.064186096191406
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.391
[2,     4] loss: 1.385
[3,     4] loss: 1.388
[4,     4] loss: 1.384
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.385
[8,     4] loss: 1.384
[9,     4] loss: 1.385
[10,     4] loss: 1.383
[11,     4] loss: 1.368
[12,     4] loss: 1.350
[13,     4] loss: 1.317
[14,     4] loss: 1.308
[15,     4] loss: 1.237
[16,     4] loss: 1.343
[17,     4] loss: 1.291
[18,     4] loss: 1.240
[19,     4] loss: 1.169
[20,     4] loss: 1.225
[21,     4] loss: 1.209
[22,     4] loss: 1.168
[23,     4] loss: 1.154
[24,     4] loss: 1.209
[25,     4] loss: 1.089
[26,     4] loss: 1.048
[27,     4] loss: 1.065
[28,     4] loss: 1.077
[29,     4] loss: 1.073
[30,     4] loss: 0.967
[31,     4] loss: 0.981
[32,     4] loss: 1.210
[33,     4] loss: 1.303
[34,     4] loss: 1.333
[35,     4] loss: 1.324
[36,     4] loss: 1.289
[37,     4] loss: 1.253
[38,     4] loss: 1.180
[39,     4] loss: 1.151
[40,     4] loss: 1.155
[41,     4] loss: 1.171
[42,     4] loss: 1.120
[43,     4] loss: 1.085
[44,     4] loss: 1.211
[45,     4] loss: 1.305
[46,     4] loss: 1.322
[47,     4] loss: 1.304
[48,     4] loss: 1.249
[49,     4] loss: 1.182
[50,     4] loss: 1.187
[51,     4] loss: 1.103
[52,     4] loss: 1.217
[53,     4] loss: 1.467
[54,     4] loss: 1.382
[55,     4] loss: 1.379
[56,     4] loss: 1.379
[57,     4] loss: 1.375
[58,     4] loss: 1.354
[59,     4] loss: 1.330
[60,     4] loss: 1.289
[61,     4] loss: 1.262
[62,     4] loss: 1.258
[63,     4] loss: 1.236
[64,     4] loss: 1.266
[65,     4] loss: 1.258
[66,     4] loss: 1.276
[67,     4] loss: 1.136
[68,     4] loss: 1.219
[69,     4] loss: 1.174
[70,     4] loss: 1.251
[71,     4] loss: 1.284
[72,     4] loss: 1.256
[73,     4] loss: 1.197
[74,     4] loss: 1.184
[75,     4] loss: 1.169
[76,     4] loss: 1.204
[77,     4] loss: 1.279
[78,     4] loss: 1.203
[79,     4] loss: 1.199
[80,     4] loss: 1.218
Early stopping applied (best metric=0.35104990005493164)
Finished Training
Total time taken: 43.96009278297424
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.386
[3,     4] loss: 1.379
[4,     4] loss: 1.394
[5,     4] loss: 1.387
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.386
[10,     4] loss: 1.387
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.387
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.387
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.387
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.387
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.386
[53,     4] loss: 1.386
[54,     4] loss: 1.386
Early stopping applied (best metric=0.5626248717308044)
Finished Training
Total time taken: 29.769397258758545
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.385
[9,     4] loss: 1.386
[10,     4] loss: 1.388
[11,     4] loss: 1.387
[12,     4] loss: 1.386
[13,     4] loss: 1.387
[14,     4] loss: 1.387
[15,     4] loss: 1.386
[16,     4] loss: 1.387
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.387
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.387
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.385
[26,     4] loss: 1.385
[27,     4] loss: 1.387
[28,     4] loss: 1.385
[29,     4] loss: 1.388
[30,     4] loss: 1.386
[31,     4] loss: 1.387
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.387
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.385
[42,     4] loss: 1.387
[43,     4] loss: 1.385
[44,     4] loss: 1.386
[45,     4] loss: 1.385
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.387
[49,     4] loss: 1.387
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.386
[53,     4] loss: 1.386
[54,     4] loss: 1.387
[55,     4] loss: 1.386
[56,     4] loss: 1.386
[57,     4] loss: 1.386
[58,     4] loss: 1.386
[59,     4] loss: 1.386
[60,     4] loss: 1.386
[61,     4] loss: 1.387
[62,     4] loss: 1.386
[63,     4] loss: 1.387
[64,     4] loss: 1.386
[65,     4] loss: 1.386
[66,     4] loss: 1.386
[67,     4] loss: 1.386
[68,     4] loss: 1.386
[69,     4] loss: 1.387
[70,     4] loss: 1.386
[71,     4] loss: 1.386
[72,     4] loss: 1.387
[73,     4] loss: 1.386
[74,     4] loss: 1.386
[75,     4] loss: 1.386
[76,     4] loss: 1.386
[77,     4] loss: 1.385
[78,     4] loss: 1.387
Early stopping applied (best metric=0.5629448890686035)
Finished Training
Total time taken: 40.376309633255005
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.390
[3,     4] loss: 1.388
[4,     4] loss: 1.387
[5,     4] loss: 1.387
[6,     4] loss: 1.388
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.384
[17,     4] loss: 1.363
[18,     4] loss: 1.347
[19,     4] loss: 1.326
[20,     4] loss: 1.290
[21,     4] loss: 1.236
[22,     4] loss: 1.322
[23,     4] loss: 1.201
[24,     4] loss: 1.216
[25,     4] loss: 1.134
[26,     4] loss: 1.317
[27,     4] loss: 1.272
[28,     4] loss: 1.295
[29,     4] loss: 1.187
[30,     4] loss: 1.312
[31,     4] loss: 1.278
[32,     4] loss: 1.269
[33,     4] loss: 1.228
[34,     4] loss: 1.182
[35,     4] loss: 1.089
[36,     4] loss: 1.241
[37,     4] loss: 1.205
[38,     4] loss: 1.180
[39,     4] loss: 1.198
[40,     4] loss: 1.213
[41,     4] loss: 1.204
[42,     4] loss: 1.194
[43,     4] loss: 1.136
[44,     4] loss: 1.206
[45,     4] loss: 1.389
[46,     4] loss: 1.290
[47,     4] loss: 1.253
[48,     4] loss: 1.270
[49,     4] loss: 1.275
[50,     4] loss: 1.252
[51,     4] loss: 1.181
[52,     4] loss: 1.146
[53,     4] loss: 1.169
[54,     4] loss: 1.221
[55,     4] loss: 1.260
[56,     4] loss: 1.191
[57,     4] loss: 1.180
[58,     4] loss: 1.133
[59,     4] loss: 1.195
[60,     4] loss: 1.153
[61,     4] loss: 1.154
[62,     4] loss: 1.174
[63,     4] loss: 1.130
[64,     4] loss: 1.193
[65,     4] loss: 1.157
[66,     4] loss: 1.152
[67,     4] loss: 1.111
[68,     4] loss: 1.133
[69,     4] loss: 1.187
[70,     4] loss: 1.166
[71,     4] loss: 1.139
[72,     4] loss: 1.127
[73,     4] loss: 1.127
[74,     4] loss: 1.133
[75,     4] loss: 1.091
[76,     4] loss: 1.098
[77,     4] loss: 1.158
[78,     4] loss: 1.107
[79,     4] loss: 1.106
Early stopping applied (best metric=0.5070398449897766)
Finished Training
Total time taken: 40.82192254066467
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.392
[3,     4] loss: 1.389
[4,     4] loss: 1.388
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.388
[8,     4] loss: 1.387
[9,     4] loss: 1.386
[10,     4] loss: 1.387
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.387
[21,     4] loss: 1.387
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.387
[27,     4] loss: 1.387
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.387
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.387
[40,     4] loss: 1.387
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.387
[45,     4] loss: 1.387
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.387
[53,     4] loss: 1.386
Early stopping applied (best metric=0.5453734993934631)
Finished Training
Total time taken: 27.87757158279419
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.393
[2,     4] loss: 1.388
[3,     4] loss: 1.388
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.385
[9,     4] loss: 1.387
[10,     4] loss: 1.387
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.387
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.387
[33,     4] loss: 1.387
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.387
[37,     4] loss: 1.387
[38,     4] loss: 1.386
[39,     4] loss: 1.387
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.385
[46,     4] loss: 1.387
[47,     4] loss: 1.385
[48,     4] loss: 1.386
[49,     4] loss: 1.387
[50,     4] loss: 1.387
[51,     4] loss: 1.386
[52,     4] loss: 1.386
[53,     4] loss: 1.386
[54,     4] loss: 1.386
[55,     4] loss: 1.386
Early stopping applied (best metric=0.5453745722770691)
Finished Training
Total time taken: 28.485925912857056
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.381
[5,     4] loss: 1.384
[6,     4] loss: 1.369
[7,     4] loss: 1.339
[8,     4] loss: 1.268
[9,     4] loss: 1.233
[10,     4] loss: 1.161
[11,     4] loss: 1.165
[12,     4] loss: 1.078
[13,     4] loss: 1.094
[14,     4] loss: 1.030
[15,     4] loss: 0.975
[16,     4] loss: 1.083
[17,     4] loss: 1.130
[18,     4] loss: 1.089
[19,     4] loss: 1.008
[20,     4] loss: 1.209
[21,     4] loss: 1.143
[22,     4] loss: 1.099
[23,     4] loss: 1.073
[24,     4] loss: 1.075
[25,     4] loss: 1.109
[26,     4] loss: 1.244
[27,     4] loss: 1.154
[28,     4] loss: 1.097
[29,     4] loss: 1.023
[30,     4] loss: 1.083
[31,     4] loss: 1.105
[32,     4] loss: 1.139
[33,     4] loss: 1.096
[34,     4] loss: 1.041
[35,     4] loss: 1.157
[36,     4] loss: 1.117
[37,     4] loss: 1.065
[38,     4] loss: 1.187
[39,     4] loss: 1.084
[40,     4] loss: 1.004
[41,     4] loss: 0.977
[42,     4] loss: 0.925
[43,     4] loss: 1.093
[44,     4] loss: 1.124
[45,     4] loss: 1.104
[46,     4] loss: 1.019
[47,     4] loss: 1.048
[48,     4] loss: 1.101
[49,     4] loss: 1.050
[50,     4] loss: 0.937
[51,     4] loss: 1.141
[52,     4] loss: 1.117
[53,     4] loss: 1.101
[54,     4] loss: 1.015
[55,     4] loss: 0.937
[56,     4] loss: 0.941
[57,     4] loss: 1.071
[58,     4] loss: 1.203
[59,     4] loss: 1.197
[60,     4] loss: 1.127
[61,     4] loss: 1.050
[62,     4] loss: 0.954
[63,     4] loss: 1.008
[64,     4] loss: 0.947
[65,     4] loss: 1.235
[66,     4] loss: 1.117
[67,     4] loss: 1.142
[68,     4] loss: 1.062
[69,     4] loss: 0.982
[70,     4] loss: 1.037
[71,     4] loss: 1.127
[72,     4] loss: 1.078
[73,     4] loss: 0.946
[74,     4] loss: 1.049
[75,     4] loss: 0.955
[76,     4] loss: 1.025
[77,     4] loss: 0.991
[78,     4] loss: 1.252
[79,     4] loss: 1.124
[80,     4] loss: 1.054
[81,     4] loss: 1.101
[82,     4] loss: 0.994
[83,     4] loss: 0.944
[84,     4] loss: 1.190
[85,     4] loss: 1.094
[86,     4] loss: 1.054
[87,     4] loss: 0.948
[88,     4] loss: 1.003
[89,     4] loss: 1.122
[90,     4] loss: 1.065
[91,     4] loss: 1.018
[92,     4] loss: 1.004
[93,     4] loss: 1.030
[94,     4] loss: 1.006
[95,     4] loss: 1.009
[96,     4] loss: 1.129
[97,     4] loss: 1.154
[98,     4] loss: 1.153
[99,     4] loss: 1.037
[100,     4] loss: 0.979
[101,     4] loss: 0.959
[102,     4] loss: 1.019
[103,     4] loss: 0.980
[104,     4] loss: 1.018
[105,     4] loss: 1.108
[106,     4] loss: 1.158
[107,     4] loss: 1.157
[108,     4] loss: 1.067
[109,     4] loss: 0.951
[110,     4] loss: 0.947
[111,     4] loss: 1.043
[112,     4] loss: 1.067
[113,     4] loss: 0.998
[114,     4] loss: 1.108
[115,     4] loss: 1.209
[116,     4] loss: 1.127
[117,     4] loss: 1.099
[118,     4] loss: 1.059
[119,     4] loss: 1.046
[120,     4] loss: 1.160
[121,     4] loss: 1.171
[122,     4] loss: 1.172
[123,     4] loss: 1.099
[124,     4] loss: 0.979
[125,     4] loss: 1.174
[126,     4] loss: 1.125
[127,     4] loss: 1.131
[128,     4] loss: 1.106
[129,     4] loss: 1.027
[130,     4] loss: 0.974
[131,     4] loss: 1.121
[132,     4] loss: 1.184
[133,     4] loss: 1.125
[134,     4] loss: 1.124
[135,     4] loss: 1.083
[136,     4] loss: 0.972
[137,     4] loss: 0.991
[138,     4] loss: 0.983
[139,     4] loss: 0.964
[140,     4] loss: 1.059
[141,     4] loss: 1.091
Early stopping applied (best metric=0.3549167811870575)
Finished Training
Total time taken: 74.85852313041687
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.388
[5,     4] loss: 1.385
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.388
[9,     4] loss: 1.386
[10,     4] loss: 1.387
[11,     4] loss: 1.386
[12,     4] loss: 1.387
[13,     4] loss: 1.386
[14,     4] loss: 1.387
[15,     4] loss: 1.387
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.387
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.385
[26,     4] loss: 1.387
[27,     4] loss: 1.385
[28,     4] loss: 1.386
[29,     4] loss: 1.388
[30,     4] loss: 1.387
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.387
[36,     4] loss: 1.387
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.387
[45,     4] loss: 1.387
[46,     4] loss: 1.386
[47,     4] loss: 1.387
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
Early stopping applied (best metric=0.562703549861908)
Finished Training
Total time taken: 26.992299556732178
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.387
[3,     4] loss: 1.389
[4,     4] loss: 1.387
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.387
[9,     4] loss: 1.387
[10,     4] loss: 1.387
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.387
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.387
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.387
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.387
[35,     4] loss: 1.387
[36,     4] loss: 1.387
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.387
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.387
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.385
[48,     4] loss: 1.387
[49,     4] loss: 1.386
[50,     4] loss: 1.388
[51,     4] loss: 1.386
[52,     4] loss: 1.386
[53,     4] loss: 1.386
[54,     4] loss: 1.387
[55,     4] loss: 1.386
[56,     4] loss: 1.386
[57,     4] loss: 1.386
[58,     4] loss: 1.386
[59,     4] loss: 1.386
[60,     4] loss: 1.386
[61,     4] loss: 1.386
[62,     4] loss: 1.386
[63,     4] loss: 1.386
[64,     4] loss: 1.386
[65,     4] loss: 1.386
[66,     4] loss: 1.386
[67,     4] loss: 1.387
[68,     4] loss: 1.386
[69,     4] loss: 1.386
[70,     4] loss: 1.386
[71,     4] loss: 1.386
[72,     4] loss: 1.386
[73,     4] loss: 1.386
[74,     4] loss: 1.386
[75,     4] loss: 1.386
[76,     4] loss: 1.386
[77,     4] loss: 1.386
[78,     4] loss: 1.386
[79,     4] loss: 1.387
[80,     4] loss: 1.386
[81,     4] loss: 1.386
[82,     4] loss: 1.386
[83,     4] loss: 1.386
[84,     4] loss: 1.386
[85,     4] loss: 1.386
[86,     4] loss: 1.386
[87,     4] loss: 1.387
[88,     4] loss: 1.387
[89,     4] loss: 1.386
[90,     4] loss: 1.386
[91,     4] loss: 1.386
[92,     4] loss: 1.386
[93,     4] loss: 1.386
[94,     4] loss: 1.386
[95,     4] loss: 1.387
[96,     4] loss: 1.386
[97,     4] loss: 1.386
[98,     4] loss: 1.386
Early stopping applied (best metric=0.5629544258117676)
Finished Training
Total time taken: 51.26985025405884
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.390
[3,     4] loss: 1.385
[4,     4] loss: 1.386
[5,     4] loss: 1.388
[6,     4] loss: 1.386
[7,     4] loss: 1.387
[8,     4] loss: 1.386
[9,     4] loss: 1.386
[10,     4] loss: 1.387
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.385
[15,     4] loss: 1.387
[16,     4] loss: 1.386
[17,     4] loss: 1.387
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.387
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.387
[25,     4] loss: 1.386
[26,     4] loss: 1.387
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.385
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.387
[35,     4] loss: 1.385
[36,     4] loss: 1.387
[37,     4] loss: 1.387
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.387
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.385
[51,     4] loss: 1.387
[52,     4] loss: 1.386
Early stopping applied (best metric=0.5453861951828003)
Finished Training
Total time taken: 26.87204647064209
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.394
[2,     4] loss: 1.387
[3,     4] loss: 1.387
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.384
[8,     4] loss: 1.386
[9,     4] loss: 1.379
[10,     4] loss: 1.352
[11,     4] loss: 1.257
[12,     4] loss: 1.272
[13,     4] loss: 1.249
[14,     4] loss: 1.193
[15,     4] loss: 1.232
[16,     4] loss: 1.226
[17,     4] loss: 1.191
[18,     4] loss: 1.152
[19,     4] loss: 1.255
[20,     4] loss: 1.268
[21,     4] loss: 1.212
[22,     4] loss: 1.197
[23,     4] loss: 1.122
[24,     4] loss: 1.093
[25,     4] loss: 1.198
[26,     4] loss: 1.176
[27,     4] loss: 1.160
[28,     4] loss: 1.136
[29,     4] loss: 1.116
[30,     4] loss: 1.014
[31,     4] loss: 1.181
[32,     4] loss: 1.102
[33,     4] loss: 1.139
[34,     4] loss: 1.132
[35,     4] loss: 1.206
[36,     4] loss: 1.129
[37,     4] loss: 1.081
[38,     4] loss: 1.192
[39,     4] loss: 1.095
[40,     4] loss: 1.056
[41,     4] loss: 1.023
[42,     4] loss: 0.955
[43,     4] loss: 1.046
[44,     4] loss: 1.616
[45,     4] loss: 1.369
[46,     4] loss: 1.317
[47,     4] loss: 1.344
[48,     4] loss: 1.363
[49,     4] loss: 1.326
[50,     4] loss: 1.236
[51,     4] loss: 1.306
[52,     4] loss: 1.270
[53,     4] loss: 1.253
[54,     4] loss: 1.220
[55,     4] loss: 1.230
[56,     4] loss: 1.154
[57,     4] loss: 1.113
[58,     4] loss: 1.289
[59,     4] loss: 1.174
[60,     4] loss: 1.178
[61,     4] loss: 1.180
[62,     4] loss: 1.106
[63,     4] loss: 1.142
[64,     4] loss: 0.991
[65,     4] loss: 1.103
[66,     4] loss: 1.151
[67,     4] loss: 1.122
[68,     4] loss: 1.080
[69,     4] loss: 1.223
[70,     4] loss: 1.171
[71,     4] loss: 1.141
[72,     4] loss: 1.064
[73,     4] loss: 1.027
[74,     4] loss: 1.036
[75,     4] loss: 1.209
[76,     4] loss: 1.148
[77,     4] loss: 1.106
[78,     4] loss: 1.061
[79,     4] loss: 1.073
[80,     4] loss: 1.053
[81,     4] loss: 0.994
[82,     4] loss: 1.101
[83,     4] loss: 1.068
[84,     4] loss: 1.024
[85,     4] loss: 1.034
[86,     4] loss: 0.996
[87,     4] loss: 1.087
[88,     4] loss: 0.996
[89,     4] loss: 1.073
[90,     4] loss: 1.029
[91,     4] loss: 1.137
[92,     4] loss: 1.084
[93,     4] loss: 1.062
[94,     4] loss: 1.042
[95,     4] loss: 1.044
[96,     4] loss: 1.041
[97,     4] loss: 1.102
[98,     4] loss: 1.037
[99,     4] loss: 1.027
[100,     4] loss: 0.998
[101,     4] loss: 0.947
[102,     4] loss: 1.038
[103,     4] loss: 1.102
[104,     4] loss: 1.207
[105,     4] loss: 1.105
[106,     4] loss: 1.023
[107,     4] loss: 1.058
[108,     4] loss: 1.203
[109,     4] loss: 1.225
[110,     4] loss: 1.144
[111,     4] loss: 1.038
[112,     4] loss: 1.097
[113,     4] loss: 1.129
[114,     4] loss: 1.062
[115,     4] loss: 1.038
[116,     4] loss: 1.084
[117,     4] loss: 0.970
[118,     4] loss: 1.005
[119,     4] loss: 0.904
[120,     4] loss: 1.019
[121,     4] loss: 1.038
[122,     4] loss: 1.057
[123,     4] loss: 1.105
[124,     4] loss: 1.147
Early stopping applied (best metric=0.4297151565551758)
Finished Training
Total time taken: 66.73554539680481
{'Hydroxylation-K Validation Accuracy': 0.684869976359338, 'Hydroxylation-K Validation Sensitivity': 0.5014814814814815, 'Hydroxylation-K Validation Specificity': 0.7368421052631579, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.7140350877192982, 'Hydroxylation-K AUC PR': 0.48977041152043027, 'Hydroxylation-K MCC': 0.2170819121599576, 'Hydroxylation-K F1': 0.320753776550878, 'Validation Loss (Hydroxylation-K)': 0.4979087928930918, 'Methylation-K Validation Accuracy': 0.7041725194451943, 'Methylation-K Validation Sensitivity': 0.2501439496490766, 'Methylation-K Validation Specificity': 0.7534187171242438, 'Methylation-K Validation Precision': nan, 'Methylation-K AUC ROC': 0.5284342935044122, 'Methylation-K AUC PR': 0.16653773757401424, 'Methylation-K MCC': 0.0037818839731347175, 'Methylation-K F1': 0.07992712823003988, 'Validation Loss (Methylation-K)': 0.6502751072247823, 'Validation Loss (total)': 1.1481839100519815, 'TimeToTrain': 42.35914367039998}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035798344606138613,
 'learning_rate_Hydroxylation-K': 0.00287343269682682,
 'learning_rate_Methylation-K': 0.00139688345907432,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.45296758866319475,
 'loss_weight_Methylation-K': 0.8392510083040104,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 848890903,
 'sample_weights': [0.41960132022984614, 0.11036646661942616],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.16423528056162,
 'weight_decay_Hydroxylation-K': 9.200962952080957,
 'weight_decay_Methylation-K': 2.9705869403907306}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.390
[3,     4] loss: 1.385
[4,     4] loss: 1.386
[5,     4] loss: 1.388
[6,     4] loss: 1.385
[7,     4] loss: 1.383
[8,     4] loss: 1.382
[9,     4] loss: 1.387
[10,     4] loss: 1.374
[11,     4] loss: 1.354
[12,     4] loss: 1.334
[13,     4] loss: 1.244
[14,     4] loss: 1.267
[15,     4] loss: 1.204
[16,     4] loss: 1.179
[17,     4] loss: 1.140
[18,     4] loss: 1.173
[19,     4] loss: 1.110
[20,     4] loss: 1.091
[21,     4] loss: 0.930
[22,     4] loss: 1.150
[23,     4] loss: 0.965
[24,     4] loss: 1.049
[25,     4] loss: 1.007
[26,     4] loss: 0.959
[27,     4] loss: 0.984
[28,     4] loss: 0.918
[29,     4] loss: 0.915
[30,     4] loss: 0.959
[31,     4] loss: 0.986
[32,     4] loss: 0.944
[33,     4] loss: 0.933
[34,     4] loss: 0.929
[35,     4] loss: 0.901
[36,     4] loss: 0.945
[37,     4] loss: 0.980
[38,     4] loss: 0.846
[39,     4] loss: 0.883
[40,     4] loss: 0.887
[41,     4] loss: 1.003
[42,     4] loss: 0.915
[43,     4] loss: 0.897
[44,     4] loss: 0.853
[45,     4] loss: 0.851
[46,     4] loss: 0.953
[47,     4] loss: 0.932
[48,     4] loss: 0.902
[49,     4] loss: 0.833
[50,     4] loss: 0.836
[51,     4] loss: 0.935
[52,     4] loss: 0.914
[53,     4] loss: 0.891
[54,     4] loss: 0.822
[55,     4] loss: 0.950
[56,     4] loss: 0.892
[57,     4] loss: 0.880
[58,     4] loss: 0.898
[59,     4] loss: 0.903
[60,     4] loss: 1.109
[61,     4] loss: 0.986
[62,     4] loss: 0.950
[63,     4] loss: 0.891
[64,     4] loss: 0.907
[65,     4] loss: 0.831
[66,     4] loss: 0.846
[67,     4] loss: 0.804
[68,     4] loss: 0.806
[69,     4] loss: 0.896
Early stopping applied (best metric=0.40427547693252563)
Finished Training
Total time taken: 37.24953770637512
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.383
[3,     4] loss: 1.386
[4,     4] loss: 1.389
[5,     4] loss: 1.385
[6,     4] loss: 1.383
[7,     4] loss: 1.379
[8,     4] loss: 1.366
[9,     4] loss: 1.322
[10,     4] loss: 1.269
[11,     4] loss: 1.186
[12,     4] loss: 1.137
[13,     4] loss: 1.145
[14,     4] loss: 1.060
[15,     4] loss: 1.015
[16,     4] loss: 0.998
[17,     4] loss: 0.959
[18,     4] loss: 0.930
[19,     4] loss: 0.957
[20,     4] loss: 0.907
[21,     4] loss: 0.912
[22,     4] loss: 0.879
[23,     4] loss: 0.881
[24,     4] loss: 0.906
[25,     4] loss: 1.043
[26,     4] loss: 0.909
[27,     4] loss: 0.928
[28,     4] loss: 0.902
[29,     4] loss: 0.856
[30,     4] loss: 0.829
[31,     4] loss: 0.798
[32,     4] loss: 0.785
[33,     4] loss: 0.929
[34,     4] loss: 1.218
[35,     4] loss: 1.108
[36,     4] loss: 1.076
[37,     4] loss: 1.030
[38,     4] loss: 0.978
[39,     4] loss: 0.965
[40,     4] loss: 1.018
[41,     4] loss: 0.919
[42,     4] loss: 0.944
[43,     4] loss: 0.919
[44,     4] loss: 0.936
[45,     4] loss: 0.956
[46,     4] loss: 0.877
[47,     4] loss: 0.941
[48,     4] loss: 0.911
[49,     4] loss: 0.874
[50,     4] loss: 0.909
[51,     4] loss: 0.876
[52,     4] loss: 0.985
[53,     4] loss: 0.914
[54,     4] loss: 0.845
[55,     4] loss: 0.847
[56,     4] loss: 0.812
[57,     4] loss: 0.965
[58,     4] loss: 0.866
[59,     4] loss: 0.882
[60,     4] loss: 0.854
[61,     4] loss: 0.899
[62,     4] loss: 0.913
Early stopping applied (best metric=0.42196565866470337)
Finished Training
Total time taken: 33.56557893753052
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.400
[3,     4] loss: 1.385
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.389
[7,     4] loss: 1.384
[8,     4] loss: 1.383
[9,     4] loss: 1.376
[10,     4] loss: 1.359
[11,     4] loss: 1.323
[12,     4] loss: 1.266
[13,     4] loss: 1.227
[14,     4] loss: 1.167
[15,     4] loss: 1.194
[16,     4] loss: 1.123
[17,     4] loss: 1.073
[18,     4] loss: 1.132
[19,     4] loss: 1.021
[20,     4] loss: 0.999
[21,     4] loss: 0.942
[22,     4] loss: 0.917
[23,     4] loss: 0.907
[24,     4] loss: 0.970
[25,     4] loss: 1.035
[26,     4] loss: 1.041
[27,     4] loss: 0.975
[28,     4] loss: 0.967
[29,     4] loss: 0.954
[30,     4] loss: 0.991
[31,     4] loss: 0.954
[32,     4] loss: 0.899
[33,     4] loss: 0.933
[34,     4] loss: 0.934
[35,     4] loss: 0.945
[36,     4] loss: 0.849
[37,     4] loss: 0.899
[38,     4] loss: 0.887
[39,     4] loss: 0.910
[40,     4] loss: 0.870
[41,     4] loss: 0.936
[42,     4] loss: 0.922
[43,     4] loss: 0.908
[44,     4] loss: 1.052
[45,     4] loss: 0.995
[46,     4] loss: 0.950
[47,     4] loss: 0.893
[48,     4] loss: 0.957
[49,     4] loss: 0.925
[50,     4] loss: 0.913
[51,     4] loss: 0.880
[52,     4] loss: 0.862
[53,     4] loss: 0.879
[54,     4] loss: 1.037
[55,     4] loss: 1.023
[56,     4] loss: 1.051
[57,     4] loss: 0.994
[58,     4] loss: 0.984
[59,     4] loss: 1.029
[60,     4] loss: 1.002
[61,     4] loss: 0.952
[62,     4] loss: 0.916
[63,     4] loss: 0.890
[64,     4] loss: 0.898
[65,     4] loss: 0.883
[66,     4] loss: 0.898
[67,     4] loss: 0.901
[68,     4] loss: 0.882
[69,     4] loss: 0.889
[70,     4] loss: 0.971
[71,     4] loss: 0.846
[72,     4] loss: 0.928
[73,     4] loss: 1.024
[74,     4] loss: 1.012
[75,     4] loss: 1.004
[76,     4] loss: 1.053
[77,     4] loss: 1.000
[78,     4] loss: 0.966
[79,     4] loss: 0.937
[80,     4] loss: 0.947
[81,     4] loss: 1.033
[82,     4] loss: 1.057
[83,     4] loss: 1.009
[84,     4] loss: 0.966
[85,     4] loss: 0.980
[86,     4] loss: 0.996
[87,     4] loss: 0.912
[88,     4] loss: 0.879
[89,     4] loss: 0.882
[90,     4] loss: 0.890
[91,     4] loss: 1.228
[92,     4] loss: 1.166
[93,     4] loss: 1.089
[94,     4] loss: 1.075
[95,     4] loss: 0.990
[96,     4] loss: 1.057
[97,     4] loss: 0.946
[98,     4] loss: 0.877
[99,     4] loss: 1.273
[100,     4] loss: 1.165
[101,     4] loss: 1.083
[102,     4] loss: 1.010
[103,     4] loss: 0.982
Early stopping applied (best metric=0.515625536441803)
Finished Training
Total time taken: 54.609344482421875
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.387
[3,     4] loss: 1.389
[4,     4] loss: 1.381
[5,     4] loss: 1.380
[6,     4] loss: 1.371
[7,     4] loss: 1.337
[8,     4] loss: 1.262
[9,     4] loss: 1.188
[10,     4] loss: 1.160
[11,     4] loss: 1.188
[12,     4] loss: 1.141
[13,     4] loss: 1.072
[14,     4] loss: 1.025
[15,     4] loss: 1.064
[16,     4] loss: 0.950
[17,     4] loss: 1.016
[18,     4] loss: 1.033
[19,     4] loss: 1.064
[20,     4] loss: 0.950
[21,     4] loss: 0.980
[22,     4] loss: 0.994
[23,     4] loss: 0.909
[24,     4] loss: 0.920
[25,     4] loss: 1.100
[26,     4] loss: 0.955
[27,     4] loss: 0.972
[28,     4] loss: 0.986
[29,     4] loss: 0.915
[30,     4] loss: 0.877
[31,     4] loss: 0.880
[32,     4] loss: 0.822
[33,     4] loss: 0.923
[34,     4] loss: 0.874
[35,     4] loss: 0.939
[36,     4] loss: 0.868
[37,     4] loss: 0.960
[38,     4] loss: 0.873
[39,     4] loss: 0.853
[40,     4] loss: 0.867
[41,     4] loss: 0.857
[42,     4] loss: 0.834
[43,     4] loss: 0.945
[44,     4] loss: 1.100
[45,     4] loss: 1.059
[46,     4] loss: 1.035
[47,     4] loss: 0.942
[48,     4] loss: 0.938
[49,     4] loss: 0.935
[50,     4] loss: 0.886
[51,     4] loss: 0.844
[52,     4] loss: 0.810
[53,     4] loss: 0.835
[54,     4] loss: 0.822
[55,     4] loss: 0.854
[56,     4] loss: 0.840
[57,     4] loss: 0.905
Early stopping applied (best metric=0.5185209512710571)
Finished Training
Total time taken: 30.183410167694092
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.380
[2,     4] loss: 1.390
[3,     4] loss: 1.386
[4,     4] loss: 1.383
[5,     4] loss: 1.380
[6,     4] loss: 1.378
[7,     4] loss: 1.342
[8,     4] loss: 1.295
[9,     4] loss: 1.198
[10,     4] loss: 1.156
[11,     4] loss: 1.228
[12,     4] loss: 1.173
[13,     4] loss: 1.115
[14,     4] loss: 1.187
[15,     4] loss: 1.184
[16,     4] loss: 1.182
[17,     4] loss: 1.148
[18,     4] loss: 1.084
[19,     4] loss: 1.038
[20,     4] loss: 0.942
[21,     4] loss: 0.929
[22,     4] loss: 0.912
[23,     4] loss: 0.937
[24,     4] loss: 0.982
[25,     4] loss: 0.988
[26,     4] loss: 0.967
[27,     4] loss: 0.921
[28,     4] loss: 0.883
[29,     4] loss: 0.944
[30,     4] loss: 0.962
[31,     4] loss: 0.992
[32,     4] loss: 0.911
[33,     4] loss: 0.887
[34,     4] loss: 0.877
[35,     4] loss: 0.882
[36,     4] loss: 0.865
[37,     4] loss: 0.965
[38,     4] loss: 0.892
[39,     4] loss: 0.881
[40,     4] loss: 0.937
[41,     4] loss: 1.126
[42,     4] loss: 1.068
[43,     4] loss: 1.080
[44,     4] loss: 0.973
[45,     4] loss: 0.904
[46,     4] loss: 0.998
[47,     4] loss: 0.983
[48,     4] loss: 0.955
[49,     4] loss: 0.990
[50,     4] loss: 0.915
[51,     4] loss: 0.899
[52,     4] loss: 0.891
[53,     4] loss: 0.860
[54,     4] loss: 0.960
[55,     4] loss: 0.835
[56,     4] loss: 0.854
[57,     4] loss: 1.085
[58,     4] loss: 1.272
[59,     4] loss: 1.183
[60,     4] loss: 1.123
[61,     4] loss: 1.067
[62,     4] loss: 0.982
Early stopping applied (best metric=0.35351496934890747)
Finished Training
Total time taken: 33.41547966003418
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.387
[5,     4] loss: 1.388
[6,     4] loss: 1.386
[7,     4] loss: 1.383
[8,     4] loss: 1.380
[9,     4] loss: 1.371
[10,     4] loss: 1.348
[11,     4] loss: 1.289
[12,     4] loss: 1.199
[13,     4] loss: 1.184
[14,     4] loss: 1.178
[15,     4] loss: 1.186
[16,     4] loss: 1.206
[17,     4] loss: 1.162
[18,     4] loss: 1.072
[19,     4] loss: 1.030
[20,     4] loss: 1.036
[21,     4] loss: 0.990
[22,     4] loss: 0.978
[23,     4] loss: 0.962
[24,     4] loss: 0.964
[25,     4] loss: 1.069
[26,     4] loss: 0.945
[27,     4] loss: 0.916
[28,     4] loss: 0.959
[29,     4] loss: 0.992
[30,     4] loss: 0.947
[31,     4] loss: 0.925
[32,     4] loss: 0.877
[33,     4] loss: 0.880
[34,     4] loss: 0.848
[35,     4] loss: 0.905
[36,     4] loss: 1.001
[37,     4] loss: 0.904
[38,     4] loss: 0.892
[39,     4] loss: 0.892
[40,     4] loss: 0.867
[41,     4] loss: 0.854
[42,     4] loss: 0.861
[43,     4] loss: 0.816
[44,     4] loss: 0.901
[45,     4] loss: 0.857
[46,     4] loss: 0.848
[47,     4] loss: 0.924
[48,     4] loss: 0.888
[49,     4] loss: 0.926
[50,     4] loss: 0.882
[51,     4] loss: 0.850
[52,     4] loss: 0.829
[53,     4] loss: 0.821
[54,     4] loss: 1.008
[55,     4] loss: 1.025
[56,     4] loss: 1.088
[57,     4] loss: 1.020
[58,     4] loss: 0.991
[59,     4] loss: 0.915
[60,     4] loss: 0.840
[61,     4] loss: 0.859
[62,     4] loss: 0.799
[63,     4] loss: 0.876
[64,     4] loss: 1.030
[65,     4] loss: 1.126
[66,     4] loss: 1.048
Early stopping applied (best metric=0.4742175340652466)
Finished Training
Total time taken: 36.94331383705139
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.390
[3,     4] loss: 1.387
[4,     4] loss: 1.388
[5,     4] loss: 1.385
[6,     4] loss: 1.386
[7,     4] loss: 1.387
[8,     4] loss: 1.384
[9,     4] loss: 1.384
[10,     4] loss: 1.388
[11,     4] loss: 1.386
[12,     4] loss: 1.383
[13,     4] loss: 1.381
[14,     4] loss: 1.371
[15,     4] loss: 1.343
[16,     4] loss: 1.311
[17,     4] loss: 1.236
[18,     4] loss: 1.142
[19,     4] loss: 1.112
[20,     4] loss: 1.370
[21,     4] loss: 1.198
[22,     4] loss: 1.167
[23,     4] loss: 1.159
[24,     4] loss: 1.093
[25,     4] loss: 1.040
[26,     4] loss: 1.034
[27,     4] loss: 1.037
[28,     4] loss: 0.998
[29,     4] loss: 1.034
[30,     4] loss: 0.980
[31,     4] loss: 1.017
[32,     4] loss: 1.040
[33,     4] loss: 0.981
[34,     4] loss: 0.902
[35,     4] loss: 0.906
[36,     4] loss: 0.889
[37,     4] loss: 0.892
[38,     4] loss: 0.915
[39,     4] loss: 0.946
[40,     4] loss: 0.905
[41,     4] loss: 0.999
[42,     4] loss: 0.937
[43,     4] loss: 0.897
[44,     4] loss: 0.877
[45,     4] loss: 0.910
[46,     4] loss: 0.861
[47,     4] loss: 0.878
[48,     4] loss: 0.910
[49,     4] loss: 0.925
[50,     4] loss: 0.896
[51,     4] loss: 0.861
[52,     4] loss: 0.908
[53,     4] loss: 0.908
[54,     4] loss: 0.896
[55,     4] loss: 0.871
[56,     4] loss: 0.896
[57,     4] loss: 0.835
[58,     4] loss: 0.846
[59,     4] loss: 0.845
[60,     4] loss: 1.024
[61,     4] loss: 0.937
[62,     4] loss: 0.906
[63,     4] loss: 0.912
[64,     4] loss: 0.925
[65,     4] loss: 0.856
[66,     4] loss: 0.833
[67,     4] loss: 0.909
[68,     4] loss: 0.841
[69,     4] loss: 0.870
[70,     4] loss: 0.948
[71,     4] loss: 0.938
[72,     4] loss: 0.938
[73,     4] loss: 0.978
[74,     4] loss: 1.053
[75,     4] loss: 0.936
[76,     4] loss: 0.961
[77,     4] loss: 0.923
[78,     4] loss: 0.868
[79,     4] loss: 0.840
[80,     4] loss: 0.846
[81,     4] loss: 0.819
[82,     4] loss: 0.785
[83,     4] loss: 0.941
[84,     4] loss: 1.143
[85,     4] loss: 1.062
[86,     4] loss: 0.991
[87,     4] loss: 0.976
[88,     4] loss: 0.910
[89,     4] loss: 0.929
[90,     4] loss: 0.864
[91,     4] loss: 0.847
[92,     4] loss: 0.974
[93,     4] loss: 0.905
[94,     4] loss: 0.884
[95,     4] loss: 0.957
[96,     4] loss: 1.031
[97,     4] loss: 0.986
[98,     4] loss: 0.973
[99,     4] loss: 0.918
[100,     4] loss: 0.862
[101,     4] loss: 0.835
[102,     4] loss: 1.011
[103,     4] loss: 1.232
[104,     4] loss: 1.148
[105,     4] loss: 1.143
[106,     4] loss: 1.088
[107,     4] loss: 1.042
[108,     4] loss: 1.013
[109,     4] loss: 0.995
[110,     4] loss: 0.910
[111,     4] loss: 0.929
[112,     4] loss: 0.928
[113,     4] loss: 0.897
[114,     4] loss: 0.876
[115,     4] loss: 0.927
[116,     4] loss: 0.866
[117,     4] loss: 0.840
[118,     4] loss: 0.928
[119,     4] loss: 0.970
[120,     4] loss: 0.907
[121,     4] loss: 0.831
[122,     4] loss: 0.903
[123,     4] loss: 0.903
[124,     4] loss: 0.913
[125,     4] loss: 0.889
[126,     4] loss: 0.873
[127,     4] loss: 0.900
[128,     4] loss: 0.946
Early stopping applied (best metric=0.3226870894432068)
Finished Training
Total time taken: 68.28724813461304
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.391
[3,     4] loss: 1.385
[4,     4] loss: 1.389
[5,     4] loss: 1.382
[6,     4] loss: 1.379
[7,     4] loss: 1.369
[8,     4] loss: 1.343
[9,     4] loss: 1.303
[10,     4] loss: 1.269
[11,     4] loss: 1.174
[12,     4] loss: 1.128
[13,     4] loss: 1.182
[14,     4] loss: 1.208
[15,     4] loss: 1.159
[16,     4] loss: 1.088
[17,     4] loss: 1.017
[18,     4] loss: 1.043
[19,     4] loss: 1.077
[20,     4] loss: 1.038
[21,     4] loss: 1.019
[22,     4] loss: 1.001
[23,     4] loss: 0.992
[24,     4] loss: 0.986
[25,     4] loss: 0.895
[26,     4] loss: 0.866
[27,     4] loss: 0.844
[28,     4] loss: 0.857
[29,     4] loss: 0.983
[30,     4] loss: 1.176
[31,     4] loss: 1.061
[32,     4] loss: 1.035
[33,     4] loss: 0.956
[34,     4] loss: 0.886
[35,     4] loss: 0.836
[36,     4] loss: 0.853
[37,     4] loss: 1.016
[38,     4] loss: 0.893
[39,     4] loss: 0.881
[40,     4] loss: 0.893
[41,     4] loss: 0.909
[42,     4] loss: 0.882
[43,     4] loss: 0.875
[44,     4] loss: 0.919
[45,     4] loss: 1.065
[46,     4] loss: 1.063
[47,     4] loss: 0.968
[48,     4] loss: 0.920
[49,     4] loss: 0.906
[50,     4] loss: 0.918
[51,     4] loss: 0.878
[52,     4] loss: 0.832
[53,     4] loss: 0.837
[54,     4] loss: 0.806
[55,     4] loss: 0.916
[56,     4] loss: 1.104
[57,     4] loss: 1.022
[58,     4] loss: 0.954
[59,     4] loss: 0.997
[60,     4] loss: 0.923
[61,     4] loss: 0.882
[62,     4] loss: 0.889
[63,     4] loss: 0.956
[64,     4] loss: 0.949
[65,     4] loss: 0.944
[66,     4] loss: 0.972
[67,     4] loss: 0.908
[68,     4] loss: 0.968
Early stopping applied (best metric=0.31127113103866577)
Finished Training
Total time taken: 36.337480783462524
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.390
[3,     4] loss: 1.387
[4,     4] loss: 1.386
[5,     4] loss: 1.387
[6,     4] loss: 1.383
[7,     4] loss: 1.377
[8,     4] loss: 1.358
[9,     4] loss: 1.298
[10,     4] loss: 1.276
[11,     4] loss: 1.230
[12,     4] loss: 1.185
[13,     4] loss: 1.228
[14,     4] loss: 1.117
[15,     4] loss: 1.143
[16,     4] loss: 1.161
[17,     4] loss: 1.184
[18,     4] loss: 1.083
[19,     4] loss: 0.975
[20,     4] loss: 1.088
[21,     4] loss: 0.936
[22,     4] loss: 1.029
[23,     4] loss: 0.952
[24,     4] loss: 0.880
[25,     4] loss: 0.882
[26,     4] loss: 0.844
[27,     4] loss: 0.907
[28,     4] loss: 0.920
[29,     4] loss: 1.042
[30,     4] loss: 0.977
[31,     4] loss: 0.886
[32,     4] loss: 0.884
[33,     4] loss: 0.827
[34,     4] loss: 0.811
[35,     4] loss: 0.806
[36,     4] loss: 1.020
[37,     4] loss: 0.997
[38,     4] loss: 1.007
[39,     4] loss: 0.963
[40,     4] loss: 0.886
[41,     4] loss: 0.878
[42,     4] loss: 0.991
[43,     4] loss: 0.907
[44,     4] loss: 0.838
[45,     4] loss: 0.956
[46,     4] loss: 0.970
[47,     4] loss: 0.957
[48,     4] loss: 0.896
[49,     4] loss: 0.845
[50,     4] loss: 0.942
[51,     4] loss: 0.900
[52,     4] loss: 0.872
[53,     4] loss: 0.913
[54,     4] loss: 0.937
[55,     4] loss: 0.909
[56,     4] loss: 0.891
[57,     4] loss: 0.835
[58,     4] loss: 0.841
[59,     4] loss: 1.135
[60,     4] loss: 1.049
[61,     4] loss: 1.057
[62,     4] loss: 0.974
[63,     4] loss: 0.917
[64,     4] loss: 0.887
[65,     4] loss: 0.960
[66,     4] loss: 1.106
[67,     4] loss: 1.143
[68,     4] loss: 1.063
[69,     4] loss: 0.956
[70,     4] loss: 0.880
[71,     4] loss: 0.842
[72,     4] loss: 0.862
[73,     4] loss: 0.911
[74,     4] loss: 0.898
[75,     4] loss: 0.899
[76,     4] loss: 1.001
[77,     4] loss: 0.959
[78,     4] loss: 0.982
[79,     4] loss: 0.913
[80,     4] loss: 0.915
[81,     4] loss: 0.837
[82,     4] loss: 0.840
[83,     4] loss: 0.872
[84,     4] loss: 0.874
[85,     4] loss: 0.904
[86,     4] loss: 0.909
[87,     4] loss: 0.865
[88,     4] loss: 0.828
[89,     4] loss: 0.825
[90,     4] loss: 0.809
[91,     4] loss: 0.807
[92,     4] loss: 0.855
[93,     4] loss: 0.948
[94,     4] loss: 0.923
[95,     4] loss: 0.902
[96,     4] loss: 0.922
[97,     4] loss: 0.942
[98,     4] loss: 0.892
[99,     4] loss: 0.927
[100,     4] loss: 0.879
[101,     4] loss: 0.871
[102,     4] loss: 0.836
[103,     4] loss: 0.794
[104,     4] loss: 0.810
[105,     4] loss: 0.828
[106,     4] loss: 0.839
[107,     4] loss: 0.898
[108,     4] loss: 0.975
[109,     4] loss: 0.883
[110,     4] loss: 0.896
[111,     4] loss: 0.905
[112,     4] loss: 0.883
[113,     4] loss: 0.861
[114,     4] loss: 0.819
[115,     4] loss: 0.828
[116,     4] loss: 0.863
[117,     4] loss: 1.052
[118,     4] loss: 0.980
[119,     4] loss: 0.905
[120,     4] loss: 0.905
[121,     4] loss: 0.867
[122,     4] loss: 0.839
[123,     4] loss: 0.805
[124,     4] loss: 0.803
[125,     4] loss: 0.784
[126,     4] loss: 1.105
[127,     4] loss: 1.052
[128,     4] loss: 0.998
[129,     4] loss: 0.894
[130,     4] loss: 0.869
[131,     4] loss: 0.942
[132,     4] loss: 0.850
[133,     4] loss: 0.846
[134,     4] loss: 0.823
[135,     4] loss: 0.801
Early stopping applied (best metric=0.36611589789390564)
Finished Training
Total time taken: 70.64753317832947
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.388
[2,     4] loss: 1.383
[3,     4] loss: 1.387
[4,     4] loss: 1.385
[5,     4] loss: 1.384
[6,     4] loss: 1.381
[7,     4] loss: 1.377
[8,     4] loss: 1.356
[9,     4] loss: 1.318
[10,     4] loss: 1.256
[11,     4] loss: 1.186
[12,     4] loss: 1.086
[13,     4] loss: 1.147
[14,     4] loss: 1.075
[15,     4] loss: 1.057
[16,     4] loss: 0.983
[17,     4] loss: 0.923
[18,     4] loss: 1.002
[19,     4] loss: 1.037
[20,     4] loss: 1.033
[21,     4] loss: 1.020
[22,     4] loss: 0.951
[23,     4] loss: 0.890
[24,     4] loss: 0.862
[25,     4] loss: 0.828
[26,     4] loss: 0.819
[27,     4] loss: 0.836
[28,     4] loss: 0.810
[29,     4] loss: 0.920
[30,     4] loss: 0.824
[31,     4] loss: 0.840
[32,     4] loss: 0.826
[33,     4] loss: 0.867
[34,     4] loss: 0.976
[35,     4] loss: 1.024
[36,     4] loss: 0.951
[37,     4] loss: 0.875
[38,     4] loss: 0.836
[39,     4] loss: 0.812
[40,     4] loss: 0.777
[41,     4] loss: 0.772
[42,     4] loss: 0.766
[43,     4] loss: 0.823
[44,     4] loss: 0.867
[45,     4] loss: 0.878
[46,     4] loss: 0.860
[47,     4] loss: 0.869
[48,     4] loss: 0.890
[49,     4] loss: 0.829
[50,     4] loss: 0.885
[51,     4] loss: 0.909
[52,     4] loss: 0.982
[53,     4] loss: 0.903
[54,     4] loss: 0.848
[55,     4] loss: 0.814
[56,     4] loss: 0.802
[57,     4] loss: 0.829
[58,     4] loss: 0.828
[59,     4] loss: 0.796
[60,     4] loss: 1.115
[61,     4] loss: 1.101
[62,     4] loss: 1.041
Early stopping applied (best metric=0.43568873405456543)
Finished Training
Total time taken: 33.618170499801636
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.404
[2,     4] loss: 1.388
[3,     4] loss: 1.384
[4,     4] loss: 1.388
[5,     4] loss: 1.383
[6,     4] loss: 1.382
[7,     4] loss: 1.371
[8,     4] loss: 1.351
[9,     4] loss: 1.282
[10,     4] loss: 1.254
[11,     4] loss: 1.160
[12,     4] loss: 1.188
[13,     4] loss: 1.138
[14,     4] loss: 1.116
[15,     4] loss: 1.088
[16,     4] loss: 1.035
[17,     4] loss: 1.020
[18,     4] loss: 0.960
[19,     4] loss: 0.946
[20,     4] loss: 0.897
[21,     4] loss: 0.890
[22,     4] loss: 0.824
[23,     4] loss: 0.938
[24,     4] loss: 0.985
[25,     4] loss: 0.895
[26,     4] loss: 0.896
[27,     4] loss: 0.980
[28,     4] loss: 0.999
[29,     4] loss: 0.953
[30,     4] loss: 0.899
[31,     4] loss: 0.863
[32,     4] loss: 0.846
[33,     4] loss: 0.797
[34,     4] loss: 0.793
[35,     4] loss: 0.793
[36,     4] loss: 0.836
[37,     4] loss: 0.827
[38,     4] loss: 0.798
[39,     4] loss: 0.826
[40,     4] loss: 0.919
[41,     4] loss: 0.903
[42,     4] loss: 0.876
[43,     4] loss: 0.951
[44,     4] loss: 1.081
[45,     4] loss: 1.036
[46,     4] loss: 1.059
[47,     4] loss: 1.004
[48,     4] loss: 0.906
[49,     4] loss: 0.895
[50,     4] loss: 0.971
[51,     4] loss: 0.881
[52,     4] loss: 0.872
[53,     4] loss: 0.815
[54,     4] loss: 1.001
[55,     4] loss: 0.917
[56,     4] loss: 0.919
[57,     4] loss: 0.933
[58,     4] loss: 0.845
[59,     4] loss: 0.826
[60,     4] loss: 0.874
[61,     4] loss: 0.936
[62,     4] loss: 0.946
Early stopping applied (best metric=0.44220614433288574)
Finished Training
Total time taken: 31.612735748291016
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.384
[3,     4] loss: 1.389
[4,     4] loss: 1.386
[5,     4] loss: 1.387
[6,     4] loss: 1.385
[7,     4] loss: 1.388
[8,     4] loss: 1.385
[9,     4] loss: 1.389
[10,     4] loss: 1.385
[11,     4] loss: 1.386
[12,     4] loss: 1.385
[13,     4] loss: 1.385
[14,     4] loss: 1.381
[15,     4] loss: 1.376
[16,     4] loss: 1.346
[17,     4] loss: 1.308
[18,     4] loss: 1.261
[19,     4] loss: 1.227
[20,     4] loss: 1.183
[21,     4] loss: 1.179
[22,     4] loss: 1.125
[23,     4] loss: 1.069
[24,     4] loss: 1.169
[25,     4] loss: 1.150
[26,     4] loss: 1.105
[27,     4] loss: 1.063
[28,     4] loss: 1.027
[29,     4] loss: 1.010
[30,     4] loss: 0.952
[31,     4] loss: 0.956
[32,     4] loss: 0.978
[33,     4] loss: 1.031
[34,     4] loss: 1.055
[35,     4] loss: 1.001
[36,     4] loss: 0.971
[37,     4] loss: 1.146
[38,     4] loss: 1.036
[39,     4] loss: 1.058
[40,     4] loss: 1.000
[41,     4] loss: 1.092
[42,     4] loss: 1.034
[43,     4] loss: 1.014
[44,     4] loss: 1.028
[45,     4] loss: 0.995
[46,     4] loss: 0.978
[47,     4] loss: 0.992
[48,     4] loss: 1.095
[49,     4] loss: 1.093
[50,     4] loss: 1.065
[51,     4] loss: 0.979
[52,     4] loss: 0.953
[53,     4] loss: 0.941
[54,     4] loss: 1.077
[55,     4] loss: 0.986
[56,     4] loss: 1.020
[57,     4] loss: 0.954
[58,     4] loss: 0.998
[59,     4] loss: 0.989
[60,     4] loss: 1.128
[61,     4] loss: 1.101
[62,     4] loss: 1.058
[63,     4] loss: 0.978
[64,     4] loss: 0.983
[65,     4] loss: 0.982
[66,     4] loss: 1.047
[67,     4] loss: 1.082
[68,     4] loss: 0.976
[69,     4] loss: 0.916
Early stopping applied (best metric=0.42031800746917725)
Finished Training
Total time taken: 35.156254529953
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.382
[5,     4] loss: 1.387
[6,     4] loss: 1.381
[7,     4] loss: 1.375
[8,     4] loss: 1.348
[9,     4] loss: 1.316
[10,     4] loss: 1.211
[11,     4] loss: 1.182
[12,     4] loss: 1.213
[13,     4] loss: 1.175
[14,     4] loss: 1.098
[15,     4] loss: 1.106
[16,     4] loss: 1.089
[17,     4] loss: 1.101
[18,     4] loss: 1.029
[19,     4] loss: 0.985
[20,     4] loss: 0.999
[21,     4] loss: 0.989
[22,     4] loss: 1.018
[23,     4] loss: 0.957
[24,     4] loss: 0.954
[25,     4] loss: 0.970
[26,     4] loss: 0.960
[27,     4] loss: 0.881
[28,     4] loss: 0.944
[29,     4] loss: 1.002
[30,     4] loss: 1.053
[31,     4] loss: 1.000
[32,     4] loss: 0.994
[33,     4] loss: 0.868
[34,     4] loss: 0.887
[35,     4] loss: 0.883
[36,     4] loss: 0.916
[37,     4] loss: 0.964
[38,     4] loss: 0.928
[39,     4] loss: 0.960
[40,     4] loss: 0.970
[41,     4] loss: 0.925
[42,     4] loss: 0.871
[43,     4] loss: 0.901
[44,     4] loss: 1.051
[45,     4] loss: 0.933
[46,     4] loss: 0.871
[47,     4] loss: 0.904
[48,     4] loss: 0.843
[49,     4] loss: 1.013
[50,     4] loss: 0.952
[51,     4] loss: 0.897
[52,     4] loss: 0.858
[53,     4] loss: 0.810
[54,     4] loss: 0.822
[55,     4] loss: 0.831
[56,     4] loss: 0.877
[57,     4] loss: 0.840
[58,     4] loss: 0.863
[59,     4] loss: 0.869
[60,     4] loss: 0.981
Early stopping applied (best metric=0.4672544002532959)
Finished Training
Total time taken: 31.750074863433838
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.388
[5,     4] loss: 1.384
[6,     4] loss: 1.386
[7,     4] loss: 1.384
[8,     4] loss: 1.381
[9,     4] loss: 1.366
[10,     4] loss: 1.321
[11,     4] loss: 1.329
[12,     4] loss: 1.277
[13,     4] loss: 1.179
[14,     4] loss: 1.155
[15,     4] loss: 1.097
[16,     4] loss: 1.099
[17,     4] loss: 1.116
[18,     4] loss: 1.111
[19,     4] loss: 1.029
[20,     4] loss: 1.008
[21,     4] loss: 1.026
[22,     4] loss: 1.044
[23,     4] loss: 1.102
[24,     4] loss: 1.005
[25,     4] loss: 0.981
[26,     4] loss: 0.927
[27,     4] loss: 0.925
[28,     4] loss: 0.909
[29,     4] loss: 0.964
[30,     4] loss: 1.039
[31,     4] loss: 1.048
[32,     4] loss: 0.949
[33,     4] loss: 0.906
[34,     4] loss: 0.864
[35,     4] loss: 0.893
[36,     4] loss: 0.913
[37,     4] loss: 0.893
[38,     4] loss: 0.842
[39,     4] loss: 1.070
[40,     4] loss: 1.129
[41,     4] loss: 1.009
[42,     4] loss: 0.968
[43,     4] loss: 0.900
[44,     4] loss: 0.850
[45,     4] loss: 0.840
[46,     4] loss: 0.814
[47,     4] loss: 0.822
[48,     4] loss: 0.900
[49,     4] loss: 0.878
[50,     4] loss: 0.829
[51,     4] loss: 0.837
[52,     4] loss: 0.832
[53,     4] loss: 0.837
[54,     4] loss: 1.090
[55,     4] loss: 0.957
[56,     4] loss: 0.899
[57,     4] loss: 0.891
[58,     4] loss: 0.854
[59,     4] loss: 0.843
[60,     4] loss: 0.840
[61,     4] loss: 0.865
[62,     4] loss: 0.825
[63,     4] loss: 0.894
[64,     4] loss: 0.853
[65,     4] loss: 0.850
[66,     4] loss: 0.820
[67,     4] loss: 0.859
[68,     4] loss: 0.872
[69,     4] loss: 0.919
[70,     4] loss: 0.979
[71,     4] loss: 0.967
[72,     4] loss: 0.982
[73,     4] loss: 0.944
[74,     4] loss: 0.877
[75,     4] loss: 0.845
[76,     4] loss: 0.813
[77,     4] loss: 0.831
[78,     4] loss: 0.833
[79,     4] loss: 0.826
[80,     4] loss: 0.813
[81,     4] loss: 0.807
[82,     4] loss: 0.853
[83,     4] loss: 0.821
[84,     4] loss: 0.893
[85,     4] loss: 0.888
[86,     4] loss: 1.010
[87,     4] loss: 0.948
[88,     4] loss: 0.929
[89,     4] loss: 0.825
[90,     4] loss: 0.894
[91,     4] loss: 0.849
Early stopping applied (best metric=0.3781401813030243)
Finished Training
Total time taken: 48.251672983169556
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.382
[2,     4] loss: 1.389
[3,     4] loss: 1.384
[4,     4] loss: 1.381
[5,     4] loss: 1.373
[6,     4] loss: 1.353
[7,     4] loss: 1.317
[8,     4] loss: 1.247
[9,     4] loss: 1.198
[10,     4] loss: 1.076
[11,     4] loss: 1.066
[12,     4] loss: 0.989
[13,     4] loss: 1.045
[14,     4] loss: 1.087
[15,     4] loss: 0.992
[16,     4] loss: 0.957
[17,     4] loss: 0.899
[18,     4] loss: 0.948
[19,     4] loss: 1.041
[20,     4] loss: 1.062
[21,     4] loss: 1.024
[22,     4] loss: 0.979
[23,     4] loss: 0.915
[24,     4] loss: 0.897
[25,     4] loss: 0.867
[26,     4] loss: 0.884
[27,     4] loss: 0.912
[28,     4] loss: 0.909
[29,     4] loss: 0.894
[30,     4] loss: 1.009
[31,     4] loss: 0.932
[32,     4] loss: 0.830
[33,     4] loss: 0.901
[34,     4] loss: 0.821
[35,     4] loss: 0.882
[36,     4] loss: 0.856
[37,     4] loss: 0.879
[38,     4] loss: 0.806
[39,     4] loss: 0.839
[40,     4] loss: 0.811
[41,     4] loss: 0.809
[42,     4] loss: 0.801
[43,     4] loss: 1.061
[44,     4] loss: 0.986
[45,     4] loss: 0.936
[46,     4] loss: 0.914
[47,     4] loss: 0.830
[48,     4] loss: 0.867
[49,     4] loss: 0.872
[50,     4] loss: 0.912
[51,     4] loss: 0.875
Early stopping applied (best metric=0.5447783470153809)
Finished Training
Total time taken: 26.547874927520752
{'Hydroxylation-K Validation Accuracy': 0.7278368794326241, 'Hydroxylation-K Validation Sensitivity': 0.7570370370370371, 'Hydroxylation-K Validation Specificity': 0.7210526315789474, 'Hydroxylation-K Validation Precision': 0.4539990163269262, 'Hydroxylation-K AUC ROC': 0.8045808966861598, 'Hydroxylation-K AUC PR': 0.5884659493543131, 'Hydroxylation-K MCC': 0.41820697888798164, 'Hydroxylation-K F1': 0.5523121484601561, 'Validation Loss (Hydroxylation-K)': 0.42510533730189004, 'Methylation-K Validation Accuracy': 0.7384090389783077, 'Methylation-K Validation Sensitivity': 0.24001823543436912, 'Methylation-K Validation Specificity': 0.7924692551755045, 'Methylation-K Validation Precision': 0.11778938067552969, 'Methylation-K AUC ROC': 0.5484771904532811, 'Methylation-K AUC PR': 0.11334243593587737, 'Methylation-K MCC': 0.027084079539805527, 'Methylation-K F1': 0.14169080693931393, 'Validation Loss (Methylation-K)': 0.7449944317340851, 'Validation Loss (total)': 1.1700997829437256, 'TimeToTrain': 40.54504736264547}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008713514714774271,
 'learning_rate_Hydroxylation-K': 0.004404547003961857,
 'learning_rate_Methylation-K': 0.007821828289474345,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8025573529325304,
 'loss_weight_Methylation-K': 0.7681612021787622,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 349163237,
 'sample_weights': [0.45296758866319475, 0.8392510083040104],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9057041960436694,
 'weight_decay_Hydroxylation-K': 0.11278443585668652,
 'weight_decay_Methylation-K': 3.476714358029004}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.392
[3,     4] loss: 1.394
[4,     4] loss: 1.390
[5,     4] loss: 1.386
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.385
[9,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023779763686739164,
 'learning_rate_Hydroxylation-K': 0.0014234859622438579,
 'learning_rate_Methylation-K': 0.00511455942360356,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7712587186895689,
 'loss_weight_Methylation-K': 0.9560813643100781,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2205230471,
 'sample_weights': [0.8025573529325304, 0.7681612021787622],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.6836419459635685,
 'weight_decay_Hydroxylation-K': 6.809508101750005,
 'weight_decay_Methylation-K': 0.9102445507469747}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.385
[5,     4] loss: 1.383
[6,     4] loss: 1.386
[7,     4] loss: 1.383
[8,     4] loss: 1.375
[9,     4] loss: 1.364
[10,     4] loss: 1.329
[11,     4] loss: 1.268
[12,     4] loss: 1.204
[13,     4] loss: 1.198
[14,     4] loss: 1.134
[15,     4] loss: 1.069
[16,     4] loss: 1.091
[17,     4] loss: 1.075
[18,     4] loss: 1.017
[19,     4] loss: 1.027
[20,     4] loss: 1.053
[21,     4] loss: 1.004
[22,     4] loss: 0.958
[23,     4] loss: 0.921
[24,     4] loss: 0.944
[25,     4] loss: 0.967
[26,     4] loss: 0.942
[27,     4] loss: 0.932
[28,     4] loss: 0.898
[29,     4] loss: 0.861
[30,     4] loss: 0.854
[31,     4] loss: 0.826
[32,     4] loss: 0.808
[33,     4] loss: 0.773
[34,     4] loss: 0.794
[35,     4] loss: 0.756
[36,     4] loss: 0.771
[37,     4] loss: 0.843
[38,     4] loss: 0.786
[39,     4] loss: 0.777
[40,     4] loss: 0.806
[41,     4] loss: 0.785
[42,     4] loss: 0.792
[43,     4] loss: 0.802
[44,     4] loss: 0.801
[45,     4] loss: 0.836
[46,     4] loss: 0.791
[47,     4] loss: 0.796
[48,     4] loss: 0.760
[49,     4] loss: 0.764
[50,     4] loss: 0.757
[51,     4] loss: 0.735
[52,     4] loss: 0.748
[53,     4] loss: 0.805
[54,     4] loss: 0.838
[55,     4] loss: 0.806
[56,     4] loss: 0.762
[57,     4] loss: 0.755
[58,     4] loss: 0.781
[59,     4] loss: 0.753
[60,     4] loss: 0.814
[61,     4] loss: 0.763
[62,     4] loss: 0.755
[63,     4] loss: 0.757
[64,     4] loss: 0.767
[65,     4] loss: 0.769
[66,     4] loss: 0.767
[67,     4] loss: 0.782
[68,     4] loss: 0.763
Early stopping applied (best metric=0.39708781242370605)
Finished Training
Total time taken: 37.700849533081055
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.377
[5,     4] loss: 1.358
[6,     4] loss: 1.328
[7,     4] loss: 1.268
[8,     4] loss: 1.234
[9,     4] loss: 1.149
[10,     4] loss: 1.073
[11,     4] loss: 1.142
[12,     4] loss: 1.037
[13,     4] loss: 0.997
[14,     4] loss: 0.958
[15,     4] loss: 0.912
[16,     4] loss: 0.977
[17,     4] loss: 0.866
[18,     4] loss: 0.940
[19,     4] loss: 0.900
[20,     4] loss: 0.863
[21,     4] loss: 0.850
[22,     4] loss: 0.819
[23,     4] loss: 0.825
[24,     4] loss: 0.805
[25,     4] loss: 0.861
[26,     4] loss: 0.864
[27,     4] loss: 0.882
[28,     4] loss: 0.812
[29,     4] loss: 0.811
[30,     4] loss: 0.839
[31,     4] loss: 0.836
[32,     4] loss: 0.806
[33,     4] loss: 0.804
[34,     4] loss: 0.773
[35,     4] loss: 0.800
[36,     4] loss: 0.806
[37,     4] loss: 0.809
[38,     4] loss: 0.790
[39,     4] loss: 0.777
[40,     4] loss: 0.783
[41,     4] loss: 0.748
[42,     4] loss: 0.801
[43,     4] loss: 0.736
[44,     4] loss: 0.770
[45,     4] loss: 0.746
[46,     4] loss: 0.766
[47,     4] loss: 0.740
[48,     4] loss: 0.732
[49,     4] loss: 0.754
[50,     4] loss: 0.780
[51,     4] loss: 0.723
[52,     4] loss: 0.756
[53,     4] loss: 0.745
[54,     4] loss: 0.781
[55,     4] loss: 0.801
[56,     4] loss: 0.764
Early stopping applied (best metric=0.5241684317588806)
Finished Training
Total time taken: 29.481788635253906
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.385
[3,     4] loss: 1.383
[4,     4] loss: 1.389
[5,     4] loss: 1.384
[6,     4] loss: 1.385
[7,     4] loss: 1.382
[8,     4] loss: 1.376
[9,     4] loss: 1.365
[10,     4] loss: 1.345
[11,     4] loss: 1.296
[12,     4] loss: 1.244
[13,     4] loss: 1.224
[14,     4] loss: 1.142
[15,     4] loss: 1.127
[16,     4] loss: 1.121
[17,     4] loss: 1.138
[18,     4] loss: 1.132
[19,     4] loss: 1.056
[20,     4] loss: 0.996
[21,     4] loss: 1.001
[22,     4] loss: 1.008
[23,     4] loss: 0.994
[24,     4] loss: 1.020
[25,     4] loss: 1.065
[26,     4] loss: 1.008
[27,     4] loss: 0.989
[28,     4] loss: 0.991
[29,     4] loss: 0.894
[30,     4] loss: 0.920
[31,     4] loss: 0.867
[32,     4] loss: 0.816
[33,     4] loss: 0.811
[34,     4] loss: 0.794
[35,     4] loss: 0.852
[36,     4] loss: 0.864
[37,     4] loss: 0.848
[38,     4] loss: 0.867
[39,     4] loss: 0.828
[40,     4] loss: 0.797
[41,     4] loss: 0.833
[42,     4] loss: 0.807
[43,     4] loss: 0.766
[44,     4] loss: 0.790
[45,     4] loss: 0.957
[46,     4] loss: 0.896
[47,     4] loss: 0.799
[48,     4] loss: 0.895
[49,     4] loss: 0.888
[50,     4] loss: 0.817
[51,     4] loss: 0.821
[52,     4] loss: 0.795
[53,     4] loss: 0.800
[54,     4] loss: 0.789
[55,     4] loss: 0.767
[56,     4] loss: 0.747
[57,     4] loss: 0.749
[58,     4] loss: 0.737
[59,     4] loss: 0.736
[60,     4] loss: 0.732
[61,     4] loss: 0.729
[62,     4] loss: 0.742
[63,     4] loss: 0.732
[64,     4] loss: 0.747
[65,     4] loss: 0.729
[66,     4] loss: 0.746
[67,     4] loss: 0.764
[68,     4] loss: 0.755
Early stopping applied (best metric=0.42578959465026855)
Finished Training
Total time taken: 37.739444971084595
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.380
[2,     4] loss: 1.382
[3,     4] loss: 1.385
[4,     4] loss: 1.378
[5,     4] loss: 1.368
[6,     4] loss: 1.341
[7,     4] loss: 1.325
[8,     4] loss: 1.285
[9,     4] loss: 1.226
[10,     4] loss: 1.168
[11,     4] loss: 1.096
[12,     4] loss: 1.084
[13,     4] loss: 1.013
[14,     4] loss: 0.982
[15,     4] loss: 0.886
[16,     4] loss: 0.931
[17,     4] loss: 0.894
[18,     4] loss: 0.893
[19,     4] loss: 0.892
[20,     4] loss: 0.939
[21,     4] loss: 0.896
[22,     4] loss: 0.916
[23,     4] loss: 0.901
[24,     4] loss: 0.854
[25,     4] loss: 0.837
[26,     4] loss: 0.861
[27,     4] loss: 0.862
[28,     4] loss: 0.816
[29,     4] loss: 0.800
[30,     4] loss: 0.773
[31,     4] loss: 0.783
[32,     4] loss: 0.817
[33,     4] loss: 0.924
[34,     4] loss: 0.854
[35,     4] loss: 0.929
[36,     4] loss: 0.855
[37,     4] loss: 0.876
[38,     4] loss: 0.861
[39,     4] loss: 0.827
[40,     4] loss: 0.777
[41,     4] loss: 0.769
[42,     4] loss: 0.747
[43,     4] loss: 0.743
[44,     4] loss: 0.749
[45,     4] loss: 0.764
[46,     4] loss: 0.763
[47,     4] loss: 0.748
[48,     4] loss: 0.745
[49,     4] loss: 0.789
[50,     4] loss: 0.771
[51,     4] loss: 0.738
[52,     4] loss: 0.739
[53,     4] loss: 0.778
[54,     4] loss: 0.763
[55,     4] loss: 0.766
[56,     4] loss: 0.741
Early stopping applied (best metric=0.5209664702415466)
Finished Training
Total time taken: 31.05691623687744
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.390
[2,     4] loss: 1.390
[3,     4] loss: 1.395
[4,     4] loss: 1.386
[5,     4] loss: 1.387
[6,     4] loss: 1.388
[7,     4] loss: 1.385
[8,     4] loss: 1.386
[9,     4] loss: 1.385
[10,     4] loss: 1.384
[11,     4] loss: 1.382
[12,     4] loss: 1.381
[13,     4] loss: 1.374
[14,     4] loss: 1.356
[15,     4] loss: 1.322
[16,     4] loss: 1.291
[17,     4] loss: 1.229
[18,     4] loss: 1.100
[19,     4] loss: 1.103
[20,     4] loss: 1.119
[21,     4] loss: 1.044
[22,     4] loss: 1.008
[23,     4] loss: 1.078
[24,     4] loss: 1.015
[25,     4] loss: 0.954
[26,     4] loss: 0.974
[27,     4] loss: 0.899
[28,     4] loss: 0.905
[29,     4] loss: 0.873
[30,     4] loss: 0.849
[31,     4] loss: 0.844
[32,     4] loss: 0.859
[33,     4] loss: 0.852
[34,     4] loss: 0.885
[35,     4] loss: 0.875
[36,     4] loss: 0.854
[37,     4] loss: 0.810
[38,     4] loss: 0.803
[39,     4] loss: 0.853
[40,     4] loss: 0.883
[41,     4] loss: 0.850
[42,     4] loss: 0.839
[43,     4] loss: 0.797
[44,     4] loss: 0.837
[45,     4] loss: 0.796
[46,     4] loss: 0.798
[47,     4] loss: 0.776
[48,     4] loss: 0.754
[49,     4] loss: 0.740
[50,     4] loss: 0.738
[51,     4] loss: 0.767
[52,     4] loss: 0.748
[53,     4] loss: 0.809
[54,     4] loss: 0.843
[55,     4] loss: 0.860
[56,     4] loss: 0.817
[57,     4] loss: 0.825
[58,     4] loss: 0.845
[59,     4] loss: 0.830
[60,     4] loss: 0.809
[61,     4] loss: 0.795
[62,     4] loss: 0.777
[63,     4] loss: 0.760
[64,     4] loss: 0.773
[65,     4] loss: 0.743
[66,     4] loss: 0.749
[67,     4] loss: 0.748
[68,     4] loss: 0.750
[69,     4] loss: 0.744
[70,     4] loss: 0.730
[71,     4] loss: 0.802
Early stopping applied (best metric=0.4525216519832611)
Finished Training
Total time taken: 38.06519794464111
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.385
[3,     4] loss: 1.382
[4,     4] loss: 1.376
[5,     4] loss: 1.367
[6,     4] loss: 1.329
[7,     4] loss: 1.312
[8,     4] loss: 1.218
[9,     4] loss: 1.183
[10,     4] loss: 1.134
[11,     4] loss: 1.143
[12,     4] loss: 1.068
[13,     4] loss: 1.018
[14,     4] loss: 1.047
[15,     4] loss: 1.073
[16,     4] loss: 1.009
[17,     4] loss: 1.000
[18,     4] loss: 0.971
[19,     4] loss: 0.931
[20,     4] loss: 0.926
[21,     4] loss: 0.907
[22,     4] loss: 0.881
[23,     4] loss: 0.821
[24,     4] loss: 0.877
[25,     4] loss: 0.813
[26,     4] loss: 0.803
[27,     4] loss: 0.883
[28,     4] loss: 0.827
[29,     4] loss: 0.821
[30,     4] loss: 0.813
[31,     4] loss: 0.805
[32,     4] loss: 0.987
[33,     4] loss: 0.965
[34,     4] loss: 0.974
[35,     4] loss: 0.978
[36,     4] loss: 1.002
[37,     4] loss: 0.883
[38,     4] loss: 0.856
[39,     4] loss: 0.835
[40,     4] loss: 0.811
[41,     4] loss: 0.803
[42,     4] loss: 0.833
[43,     4] loss: 0.797
[44,     4] loss: 0.787
[45,     4] loss: 0.781
[46,     4] loss: 0.764
[47,     4] loss: 0.788
[48,     4] loss: 0.800
[49,     4] loss: 0.784
[50,     4] loss: 0.769
[51,     4] loss: 0.792
[52,     4] loss: 0.789
[53,     4] loss: 0.774
[54,     4] loss: 0.777
[55,     4] loss: 0.794
[56,     4] loss: 0.770
[57,     4] loss: 0.743
Early stopping applied (best metric=0.46608424186706543)
Finished Training
Total time taken: 31.450994968414307
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.396
[3,     4] loss: 1.386
[4,     4] loss: 1.388
[5,     4] loss: 1.383
[6,     4] loss: 1.392
[7,     4] loss: 1.385
[8,     4] loss: 1.386
[9,     4] loss: 1.385
[10,     4] loss: 1.384
[11,     4] loss: 1.380
[12,     4] loss: 1.377
[13,     4] loss: 1.362
[14,     4] loss: 1.343
[15,     4] loss: 1.282
[16,     4] loss: 1.253
[17,     4] loss: 1.176
[18,     4] loss: 1.154
[19,     4] loss: 1.116
[20,     4] loss: 1.071
[21,     4] loss: 1.049
[22,     4] loss: 1.019
[23,     4] loss: 1.045
[24,     4] loss: 1.007
[25,     4] loss: 1.084
[26,     4] loss: 1.163
[27,     4] loss: 1.082
[28,     4] loss: 1.027
[29,     4] loss: 1.020
[30,     4] loss: 0.999
[31,     4] loss: 0.893
[32,     4] loss: 0.883
[33,     4] loss: 0.913
[34,     4] loss: 0.952
[35,     4] loss: 0.915
[36,     4] loss: 0.886
[37,     4] loss: 0.886
[38,     4] loss: 0.849
[39,     4] loss: 0.804
[40,     4] loss: 0.835
[41,     4] loss: 0.797
[42,     4] loss: 0.764
[43,     4] loss: 0.764
[44,     4] loss: 0.752
[45,     4] loss: 0.848
[46,     4] loss: 0.791
[47,     4] loss: 0.760
[48,     4] loss: 0.779
[49,     4] loss: 0.779
[50,     4] loss: 0.787
[51,     4] loss: 0.796
[52,     4] loss: 0.778
[53,     4] loss: 0.818
[54,     4] loss: 0.879
[55,     4] loss: 0.825
[56,     4] loss: 0.793
[57,     4] loss: 0.805
[58,     4] loss: 0.790
[59,     4] loss: 0.777
[60,     4] loss: 0.779
[61,     4] loss: 0.758
[62,     4] loss: 0.764
[63,     4] loss: 0.742
[64,     4] loss: 0.734
[65,     4] loss: 0.750
[66,     4] loss: 0.734
[67,     4] loss: 0.746
[68,     4] loss: 0.865
[69,     4] loss: 0.768
[70,     4] loss: 0.772
[71,     4] loss: 0.737
[72,     4] loss: 0.740
[73,     4] loss: 0.751
[74,     4] loss: 0.766
[75,     4] loss: 0.787
[76,     4] loss: 0.753
[77,     4] loss: 0.739
[78,     4] loss: 0.745
[79,     4] loss: 0.752
[80,     4] loss: 0.733
[81,     4] loss: 0.743
[82,     4] loss: 0.744
[83,     4] loss: 0.737
[84,     4] loss: 0.728
[85,     4] loss: 0.725
[86,     4] loss: 0.729
[87,     4] loss: 0.740
[88,     4] loss: 0.736
[89,     4] loss: 0.724
[90,     4] loss: 0.741
[91,     4] loss: 0.762
[92,     4] loss: 0.805
[93,     4] loss: 0.799
[94,     4] loss: 0.743
[95,     4] loss: 0.759
[96,     4] loss: 0.747
[97,     4] loss: 0.744
[98,     4] loss: 0.774
[99,     4] loss: 0.771
[100,     4] loss: 0.732
[101,     4] loss: 0.757
[102,     4] loss: 0.757
[103,     4] loss: 0.742
[104,     4] loss: 0.747
[105,     4] loss: 0.736
[106,     4] loss: 0.761
[107,     4] loss: 0.796
[108,     4] loss: 0.873
[109,     4] loss: 0.958
[110,     4] loss: 0.804
[111,     4] loss: 0.852
[112,     4] loss: 0.806
[113,     4] loss: 0.750
[114,     4] loss: 0.727
[115,     4] loss: 0.727
[116,     4] loss: 0.712
[117,     4] loss: 0.739
[118,     4] loss: 0.727
[119,     4] loss: 0.758
[120,     4] loss: 0.748
[121,     4] loss: 0.740
[122,     4] loss: 0.740
[123,     4] loss: 0.732
[124,     4] loss: 0.715
[125,     4] loss: 0.722
[126,     4] loss: 0.715
[127,     4] loss: 0.745
[128,     4] loss: 0.733
[129,     4] loss: 0.729
[130,     4] loss: 0.740
[131,     4] loss: 0.785
[132,     4] loss: 0.798
[133,     4] loss: 0.741
[134,     4] loss: 0.731
[135,     4] loss: 0.777
[136,     4] loss: 0.788
[137,     4] loss: 0.768
[138,     4] loss: 0.726
[139,     4] loss: 0.729
[140,     4] loss: 0.714
[141,     4] loss: 0.739
[142,     4] loss: 0.708
[143,     4] loss: 0.709
[144,     4] loss: 0.737
[145,     4] loss: 0.731
[146,     4] loss: 0.711
[147,     4] loss: 0.703
[148,     4] loss: 0.703
[149,     4] loss: 0.694
[150,     4] loss: 0.688
[151,     4] loss: 0.693
[152,     4] loss: 0.732
[153,     4] loss: 0.724
[154,     4] loss: 0.790
[155,     4] loss: 0.745
[156,     4] loss: 0.726
[157,     4] loss: 0.769
[158,     4] loss: 0.710
[159,     4] loss: 0.706
[160,     4] loss: 0.700
[161,     4] loss: 0.709
[162,     4] loss: 0.784
[163,     4] loss: 0.715
[164,     4] loss: 0.719
[165,     4] loss: 0.733
[166,     4] loss: 0.760
[167,     4] loss: 0.733
[168,     4] loss: 0.706
[169,     4] loss: 0.714
[170,     4] loss: 0.717
[171,     4] loss: 0.702
[172,     4] loss: 0.720
[173,     4] loss: 0.698
[174,     4] loss: 0.700
[175,     4] loss: 0.694
[176,     4] loss: 0.689
[177,     4] loss: 0.724
[178,     4] loss: 0.714
[179,     4] loss: 0.701
[180,     4] loss: 0.710
[181,     4] loss: 0.700
Early stopping applied (best metric=0.2143726646900177)
Finished Training
Total time taken: 98.63870668411255
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.400
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.388
[5,     4] loss: 1.388
[6,     4] loss: 1.385
[7,     4] loss: 1.385
[8,     4] loss: 1.387
[9,     4] loss: 1.385
[10,     4] loss: 1.384
[11,     4] loss: 1.383
[12,     4] loss: 1.377
[13,     4] loss: 1.368
[14,     4] loss: 1.354
[15,     4] loss: 1.307
[16,     4] loss: 1.259
[17,     4] loss: 1.235
[18,     4] loss: 1.146
[19,     4] loss: 1.143
[20,     4] loss: 1.188
[21,     4] loss: 1.085
[22,     4] loss: 1.032
[23,     4] loss: 0.977
[24,     4] loss: 0.989
[25,     4] loss: 0.907
[26,     4] loss: 1.002
[27,     4] loss: 0.941
[28,     4] loss: 0.887
[29,     4] loss: 0.868
[30,     4] loss: 0.845
[31,     4] loss: 0.866
[32,     4] loss: 0.837
[33,     4] loss: 0.906
[34,     4] loss: 0.888
[35,     4] loss: 0.888
[36,     4] loss: 0.864
[37,     4] loss: 0.866
[38,     4] loss: 0.838
[39,     4] loss: 0.820
[40,     4] loss: 0.823
[41,     4] loss: 0.792
[42,     4] loss: 0.770
[43,     4] loss: 0.776
[44,     4] loss: 0.791
[45,     4] loss: 0.770
[46,     4] loss: 0.753
[47,     4] loss: 0.766
[48,     4] loss: 0.742
[49,     4] loss: 0.766
[50,     4] loss: 0.748
[51,     4] loss: 0.746
[52,     4] loss: 0.754
[53,     4] loss: 0.794
[54,     4] loss: 0.773
[55,     4] loss: 0.774
[56,     4] loss: 0.790
[57,     4] loss: 0.766
[58,     4] loss: 0.778
[59,     4] loss: 0.790
[60,     4] loss: 0.761
[61,     4] loss: 0.796
[62,     4] loss: 0.828
[63,     4] loss: 0.780
[64,     4] loss: 0.755
[65,     4] loss: 0.747
[66,     4] loss: 0.734
[67,     4] loss: 0.751
[68,     4] loss: 0.729
[69,     4] loss: 0.755
[70,     4] loss: 0.896
[71,     4] loss: 0.849
[72,     4] loss: 0.826
[73,     4] loss: 0.863
[74,     4] loss: 0.791
[75,     4] loss: 0.831
[76,     4] loss: 0.825
[77,     4] loss: 0.784
[78,     4] loss: 0.755
[79,     4] loss: 0.752
[80,     4] loss: 0.764
[81,     4] loss: 0.740
[82,     4] loss: 0.726
[83,     4] loss: 0.759
[84,     4] loss: 0.733
[85,     4] loss: 0.740
[86,     4] loss: 0.729
[87,     4] loss: 0.742
[88,     4] loss: 0.720
[89,     4] loss: 0.740
[90,     4] loss: 0.728
[91,     4] loss: 0.733
[92,     4] loss: 0.728
[93,     4] loss: 0.721
[94,     4] loss: 0.716
[95,     4] loss: 0.716
[96,     4] loss: 0.731
[97,     4] loss: 0.729
[98,     4] loss: 0.729
[99,     4] loss: 0.748
[100,     4] loss: 0.718
[101,     4] loss: 0.730
[102,     4] loss: 0.734
[103,     4] loss: 0.707
[104,     4] loss: 0.750
[105,     4] loss: 0.743
[106,     4] loss: 0.724
[107,     4] loss: 0.741
[108,     4] loss: 0.755
[109,     4] loss: 0.741
[110,     4] loss: 0.760
[111,     4] loss: 0.782
[112,     4] loss: 0.779
[113,     4] loss: 0.752
[114,     4] loss: 0.747
[115,     4] loss: 0.788
[116,     4] loss: 0.803
[117,     4] loss: 0.731
[118,     4] loss: 0.723
[119,     4] loss: 0.706
[120,     4] loss: 0.714
[121,     4] loss: 0.744
[122,     4] loss: 0.766
[123,     4] loss: 0.746
[124,     4] loss: 0.795
[125,     4] loss: 0.747
[126,     4] loss: 0.754
[127,     4] loss: 0.777
[128,     4] loss: 0.750
[129,     4] loss: 0.780
[130,     4] loss: 0.736
[131,     4] loss: 0.746
[132,     4] loss: 0.724
Early stopping applied (best metric=0.2960784435272217)
Finished Training
Total time taken: 77.92829918861389
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.393
[3,     4] loss: 1.387
[4,     4] loss: 1.387
[5,     4] loss: 1.388
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.384
[9,     4] loss: 1.387
[10,     4] loss: 1.383
[11,     4] loss: 1.383
[12,     4] loss: 1.381
[13,     4] loss: 1.374
[14,     4] loss: 1.368
[15,     4] loss: 1.353
[16,     4] loss: 1.304
[17,     4] loss: 1.262
[18,     4] loss: 1.211
[19,     4] loss: 1.128
[20,     4] loss: 1.152
[21,     4] loss: 1.075
[22,     4] loss: 1.069
[23,     4] loss: 1.043
[24,     4] loss: 1.031
[25,     4] loss: 1.005
[26,     4] loss: 0.928
[27,     4] loss: 0.922
[28,     4] loss: 0.953
[29,     4] loss: 1.011
[30,     4] loss: 0.940
[31,     4] loss: 0.975
[32,     4] loss: 0.937
[33,     4] loss: 0.917
[34,     4] loss: 0.869
[35,     4] loss: 0.843
[36,     4] loss: 0.807
[37,     4] loss: 0.799
[38,     4] loss: 0.826
[39,     4] loss: 0.849
[40,     4] loss: 0.840
[41,     4] loss: 0.818
[42,     4] loss: 0.829
[43,     4] loss: 0.850
[44,     4] loss: 0.837
[45,     4] loss: 0.777
[46,     4] loss: 0.783
[47,     4] loss: 0.820
[48,     4] loss: 0.786
[49,     4] loss: 0.774
[50,     4] loss: 0.787
[51,     4] loss: 0.757
[52,     4] loss: 0.795
[53,     4] loss: 0.778
[54,     4] loss: 0.896
[55,     4] loss: 0.937
[56,     4] loss: 0.883
[57,     4] loss: 0.839
[58,     4] loss: 0.875
[59,     4] loss: 0.809
[60,     4] loss: 0.772
[61,     4] loss: 0.778
[62,     4] loss: 0.764
[63,     4] loss: 0.743
[64,     4] loss: 0.746
[65,     4] loss: 0.737
[66,     4] loss: 0.778
[67,     4] loss: 0.783
[68,     4] loss: 0.764
[69,     4] loss: 0.744
[70,     4] loss: 0.736
[71,     4] loss: 0.756
[72,     4] loss: 0.753
[73,     4] loss: 0.747
[74,     4] loss: 0.763
[75,     4] loss: 0.774
[76,     4] loss: 0.774
[77,     4] loss: 0.748
[78,     4] loss: 0.749
[79,     4] loss: 0.742
[80,     4] loss: 0.753
[81,     4] loss: 0.734
[82,     4] loss: 0.725
[83,     4] loss: 0.725
[84,     4] loss: 0.740
[85,     4] loss: 0.744
[86,     4] loss: 0.733
[87,     4] loss: 0.754
[88,     4] loss: 0.737
[89,     4] loss: 0.798
[90,     4] loss: 0.772
[91,     4] loss: 0.780
[92,     4] loss: 0.810
Early stopping applied (best metric=0.2616596519947052)
Finished Training
Total time taken: 50.14913868904114
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.393
[2,     4] loss: 1.382
[3,     4] loss: 1.381
[4,     4] loss: 1.378
[5,     4] loss: 1.368
[6,     4] loss: 1.349
[7,     4] loss: 1.319
[8,     4] loss: 1.259
[9,     4] loss: 1.280
[10,     4] loss: 1.202
[11,     4] loss: 1.158
[12,     4] loss: 1.073
[13,     4] loss: 1.056
[14,     4] loss: 0.985
[15,     4] loss: 0.984
[16,     4] loss: 1.032
[17,     4] loss: 1.023
[18,     4] loss: 1.001
[19,     4] loss: 0.959
[20,     4] loss: 0.960
[21,     4] loss: 0.915
[22,     4] loss: 0.944
[23,     4] loss: 0.906
[24,     4] loss: 0.948
[25,     4] loss: 0.992
[26,     4] loss: 0.932
[27,     4] loss: 0.916
[28,     4] loss: 0.898
[29,     4] loss: 0.869
[30,     4] loss: 0.829
[31,     4] loss: 0.802
[32,     4] loss: 0.776
[33,     4] loss: 0.816
[34,     4] loss: 0.773
[35,     4] loss: 0.796
[36,     4] loss: 0.772
[37,     4] loss: 0.791
[38,     4] loss: 0.775
[39,     4] loss: 0.815
[40,     4] loss: 0.774
[41,     4] loss: 0.829
[42,     4] loss: 0.778
[43,     4] loss: 0.837
[44,     4] loss: 0.816
[45,     4] loss: 0.781
[46,     4] loss: 0.759
[47,     4] loss: 0.763
[48,     4] loss: 0.781
[49,     4] loss: 0.728
[50,     4] loss: 0.745
[51,     4] loss: 0.755
[52,     4] loss: 0.747
[53,     4] loss: 0.778
[54,     4] loss: 0.769
[55,     4] loss: 0.755
[56,     4] loss: 0.779
[57,     4] loss: 0.758
[58,     4] loss: 0.764
[59,     4] loss: 0.765
[60,     4] loss: 0.789
[61,     4] loss: 0.877
Early stopping applied (best metric=0.4320066273212433)
Finished Training
Total time taken: 32.08547329902649
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.386
[3,     4] loss: 1.382
[4,     4] loss: 1.387
[5,     4] loss: 1.381
[6,     4] loss: 1.380
[7,     4] loss: 1.371
[8,     4] loss: 1.363
[9,     4] loss: 1.335
[10,     4] loss: 1.280
[11,     4] loss: 1.236
[12,     4] loss: 1.194
[13,     4] loss: 1.156
[14,     4] loss: 1.135
[15,     4] loss: 1.100
[16,     4] loss: 1.071
[17,     4] loss: 1.064
[18,     4] loss: 1.064
[19,     4] loss: 1.020
[20,     4] loss: 1.059
[21,     4] loss: 1.064
[22,     4] loss: 0.976
[23,     4] loss: 0.899
[24,     4] loss: 0.883
[25,     4] loss: 0.859
[26,     4] loss: 0.897
[27,     4] loss: 0.850
[28,     4] loss: 0.860
[29,     4] loss: 0.854
[30,     4] loss: 0.812
[31,     4] loss: 0.808
[32,     4] loss: 0.925
[33,     4] loss: 0.812
[34,     4] loss: 0.866
[35,     4] loss: 0.840
[36,     4] loss: 0.908
[37,     4] loss: 0.893
[38,     4] loss: 0.909
[39,     4] loss: 0.854
[40,     4] loss: 0.864
[41,     4] loss: 0.853
[42,     4] loss: 0.798
[43,     4] loss: 0.793
[44,     4] loss: 0.867
[45,     4] loss: 0.772
[46,     4] loss: 0.761
[47,     4] loss: 0.769
[48,     4] loss: 0.740
[49,     4] loss: 0.747
[50,     4] loss: 0.737
[51,     4] loss: 0.714
[52,     4] loss: 0.743
[53,     4] loss: 0.741
[54,     4] loss: 0.731
[55,     4] loss: 0.709
[56,     4] loss: 0.750
[57,     4] loss: 0.704
[58,     4] loss: 0.744
[59,     4] loss: 0.786
[60,     4] loss: 0.726
[61,     4] loss: 0.856
[62,     4] loss: 0.927
[63,     4] loss: 0.842
[64,     4] loss: 0.798
[65,     4] loss: 0.794
[66,     4] loss: 0.761
[67,     4] loss: 0.748
[68,     4] loss: 0.741
Early stopping applied (best metric=0.32696449756622314)
Finished Training
Total time taken: 35.6410186290741
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.392
[3,     4] loss: 1.385
[4,     4] loss: 1.387
[5,     4] loss: 1.382
[6,     4] loss: 1.382
[7,     4] loss: 1.379
[8,     4] loss: 1.380
[9,     4] loss: 1.364
[10,     4] loss: 1.346
[11,     4] loss: 1.324
[12,     4] loss: 1.299
[13,     4] loss: 1.234
[14,     4] loss: 1.241
[15,     4] loss: 1.201
[16,     4] loss: 1.104
[17,     4] loss: 1.121
[18,     4] loss: 1.165
[19,     4] loss: 1.070
[20,     4] loss: 1.081
[21,     4] loss: 1.063
[22,     4] loss: 0.938
[23,     4] loss: 0.991
[24,     4] loss: 1.054
[25,     4] loss: 1.047
[26,     4] loss: 1.014
[27,     4] loss: 0.955
[28,     4] loss: 0.948
[29,     4] loss: 0.921
[30,     4] loss: 0.925
[31,     4] loss: 0.852
[32,     4] loss: 0.888
[33,     4] loss: 0.868
[34,     4] loss: 0.842
[35,     4] loss: 0.861
[36,     4] loss: 0.847
[37,     4] loss: 0.846
[38,     4] loss: 0.811
[39,     4] loss: 0.820
[40,     4] loss: 0.806
[41,     4] loss: 0.801
[42,     4] loss: 0.790
[43,     4] loss: 0.845
[44,     4] loss: 0.818
[45,     4] loss: 0.834
[46,     4] loss: 0.817
[47,     4] loss: 0.800
[48,     4] loss: 0.784
[49,     4] loss: 0.755
[50,     4] loss: 0.792
[51,     4] loss: 0.762
[52,     4] loss: 0.784
[53,     4] loss: 0.751
[54,     4] loss: 0.801
[55,     4] loss: 0.763
[56,     4] loss: 0.805
[57,     4] loss: 0.753
[58,     4] loss: 0.766
[59,     4] loss: 0.775
[60,     4] loss: 0.788
[61,     4] loss: 0.773
[62,     4] loss: 0.767
[63,     4] loss: 0.749
[64,     4] loss: 0.765
Early stopping applied (best metric=0.40695783495903015)
Finished Training
Total time taken: 33.3474555015564
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.388
[3,     4] loss: 1.390
[4,     4] loss: 1.388
[5,     4] loss: 1.388
[6,     4] loss: 1.387
[7,     4] loss: 1.389
[8,     4] loss: 1.390
[9,     4] loss: 1.383
[10,     4] loss: 1.384
[11,     4] loss: 1.383
[12,     4] loss: 1.385
[13,     4] loss: 1.381
[14,     4] loss: 1.380
[15,     4] loss: 1.374
[16,     4] loss: 1.359
[17,     4] loss: 1.317
[18,     4] loss: 1.263
[19,     4] loss: 1.201
[20,     4] loss: 1.157
[21,     4] loss: 1.136
[22,     4] loss: 1.049
[23,     4] loss: 1.168
[24,     4] loss: 1.073
[25,     4] loss: 1.073
[26,     4] loss: 0.998
[27,     4] loss: 0.950
[28,     4] loss: 0.944
[29,     4] loss: 0.974
[30,     4] loss: 0.990
[31,     4] loss: 0.978
[32,     4] loss: 1.011
[33,     4] loss: 1.026
[34,     4] loss: 0.923
[35,     4] loss: 0.914
[36,     4] loss: 0.874
[37,     4] loss: 0.908
[38,     4] loss: 0.876
[39,     4] loss: 0.897
[40,     4] loss: 0.906
[41,     4] loss: 0.840
[42,     4] loss: 0.840
[43,     4] loss: 0.820
[44,     4] loss: 0.860
[45,     4] loss: 0.877
[46,     4] loss: 0.874
[47,     4] loss: 0.783
[48,     4] loss: 0.813
[49,     4] loss: 0.788
[50,     4] loss: 0.776
[51,     4] loss: 0.786
[52,     4] loss: 0.761
[53,     4] loss: 0.765
[54,     4] loss: 0.789
[55,     4] loss: 0.752
[56,     4] loss: 0.789
[57,     4] loss: 0.807
[58,     4] loss: 0.845
[59,     4] loss: 0.863
[60,     4] loss: 0.847
[61,     4] loss: 0.811
[62,     4] loss: 0.808
[63,     4] loss: 0.794
[64,     4] loss: 0.776
[65,     4] loss: 0.780
[66,     4] loss: 0.762
[67,     4] loss: 0.785
[68,     4] loss: 0.778
[69,     4] loss: 0.778
[70,     4] loss: 0.744
[71,     4] loss: 0.752
[72,     4] loss: 0.789
[73,     4] loss: 0.747
[74,     4] loss: 0.758
[75,     4] loss: 0.734
[76,     4] loss: 0.757
[77,     4] loss: 0.755
[78,     4] loss: 0.795
[79,     4] loss: 0.793
[80,     4] loss: 0.768
[81,     4] loss: 0.775
[82,     4] loss: 0.769
[83,     4] loss: 0.759
[84,     4] loss: 0.752
[85,     4] loss: 0.737
[86,     4] loss: 0.805
[87,     4] loss: 0.829
[88,     4] loss: 0.811
[89,     4] loss: 0.850
[90,     4] loss: 0.841
[91,     4] loss: 0.820
[92,     4] loss: 0.772
[93,     4] loss: 0.813
[94,     4] loss: 0.782
[95,     4] loss: 0.746
[96,     4] loss: 0.770
[97,     4] loss: 0.765
Early stopping applied (best metric=0.40635913610458374)
Finished Training
Total time taken: 53.05489683151245
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.383
[5,     4] loss: 1.384
[6,     4] loss: 1.389
[7,     4] loss: 1.387
[8,     4] loss: 1.382
[9,     4] loss: 1.380
[10,     4] loss: 1.371
[11,     4] loss: 1.357
[12,     4] loss: 1.311
[13,     4] loss: 1.259
[14,     4] loss: 1.126
[15,     4] loss: 1.047
[16,     4] loss: 1.090
[17,     4] loss: 1.035
[18,     4] loss: 1.034
[19,     4] loss: 1.059
[20,     4] loss: 0.965
[21,     4] loss: 0.992
[22,     4] loss: 0.945
[23,     4] loss: 0.925
[24,     4] loss: 0.924
[25,     4] loss: 0.948
[26,     4] loss: 0.917
[27,     4] loss: 0.831
[28,     4] loss: 0.886
[29,     4] loss: 0.852
[30,     4] loss: 0.879
[31,     4] loss: 0.895
[32,     4] loss: 0.845
[33,     4] loss: 0.781
[34,     4] loss: 0.825
[35,     4] loss: 0.824
[36,     4] loss: 0.817
[37,     4] loss: 0.809
[38,     4] loss: 0.774
[39,     4] loss: 0.744
[40,     4] loss: 0.762
[41,     4] loss: 0.763
[42,     4] loss: 0.792
[43,     4] loss: 0.779
[44,     4] loss: 0.766
[45,     4] loss: 0.799
[46,     4] loss: 0.743
[47,     4] loss: 0.806
[48,     4] loss: 0.802
[49,     4] loss: 0.756
[50,     4] loss: 0.774
[51,     4] loss: 0.771
[52,     4] loss: 0.793
[53,     4] loss: 0.805
[54,     4] loss: 0.773
[55,     4] loss: 0.757
[56,     4] loss: 0.747
[57,     4] loss: 0.751
[58,     4] loss: 0.731
[59,     4] loss: 0.757
[60,     4] loss: 0.740
[61,     4] loss: 0.734
[62,     4] loss: 0.739
[63,     4] loss: 0.711
[64,     4] loss: 0.736
Early stopping applied (best metric=0.48091456294059753)
Finished Training
Total time taken: 34.1790976524353
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.392
[2,     4] loss: 1.383
[3,     4] loss: 1.381
[4,     4] loss: 1.365
[5,     4] loss: 1.348
[6,     4] loss: 1.321
[7,     4] loss: 1.257
[8,     4] loss: 1.212
[9,     4] loss: 1.146
[10,     4] loss: 1.098
[11,     4] loss: 1.171
[12,     4] loss: 1.137
[13,     4] loss: 1.068
[14,     4] loss: 1.059
[15,     4] loss: 1.020
[16,     4] loss: 1.068
[17,     4] loss: 0.975
[18,     4] loss: 1.025
[19,     4] loss: 0.924
[20,     4] loss: 0.973
[21,     4] loss: 0.928
[22,     4] loss: 0.876
[23,     4] loss: 0.940
[24,     4] loss: 0.871
[25,     4] loss: 0.873
[26,     4] loss: 0.867
[27,     4] loss: 0.826
[28,     4] loss: 0.798
[29,     4] loss: 0.770
[30,     4] loss: 0.761
[31,     4] loss: 0.765
[32,     4] loss: 0.837
[33,     4] loss: 0.786
[34,     4] loss: 0.797
[35,     4] loss: 0.827
[36,     4] loss: 0.771
[37,     4] loss: 0.820
[38,     4] loss: 0.857
[39,     4] loss: 0.804
[40,     4] loss: 0.791
[41,     4] loss: 0.797
[42,     4] loss: 0.766
[43,     4] loss: 0.849
[44,     4] loss: 0.798
[45,     4] loss: 0.774
[46,     4] loss: 0.754
[47,     4] loss: 0.749
[48,     4] loss: 0.757
[49,     4] loss: 0.787
[50,     4] loss: 0.743
[51,     4] loss: 0.758
[52,     4] loss: 0.830
[53,     4] loss: 0.791
[54,     4] loss: 0.763
[55,     4] loss: 0.772
[56,     4] loss: 0.765
[57,     4] loss: 0.812
[58,     4] loss: 0.767
Early stopping applied (best metric=0.3774365186691284)
Finished Training
Total time taken: 30.03281831741333
{'Hydroxylation-K Validation Accuracy': 0.7996158392434988, 'Hydroxylation-K Validation Sensitivity': 0.7422222222222222, 'Hydroxylation-K Validation Specificity': 0.8140350877192982, 'Hydroxylation-K Validation Precision': 0.5186487787574744, 'Hydroxylation-K AUC ROC': 0.8289863547758285, 'Hydroxylation-K AUC PR': 0.6108854264253407, 'Hydroxylation-K MCC': 0.4968354722058452, 'Hydroxylation-K F1': 0.6030474308300395, 'Validation Loss (Hydroxylation-K)': 0.3992912093798319, 'Methylation-K Validation Accuracy': 0.8055800207038772, 'Methylation-K Validation Sensitivity': 0.1642179305267229, 'Methylation-K Validation Specificity': 0.8751358362100654, 'Methylation-K Validation Precision': 0.12418123196761116, 'Methylation-K AUC ROC': 0.5503629090509067, 'Methylation-K AUC PR': 0.11558131324245144, 'Methylation-K MCC': 0.03401073185255891, 'Methylation-K F1': 0.13528147678200317, 'Validation Loss (Methylation-K)': 0.9299560944239299, 'Validation Loss (total)': 1.3292472918828329, 'TimeToTrain': 43.37013980547587}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00011126350874812698,
 'learning_rate_Hydroxylation-K': 0.009652407542565753,
 'learning_rate_Methylation-K': 0.007677884168604765,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3368101720616371,
 'loss_weight_Methylation-K': 0.5008738111002604,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4091224467,
 'sample_weights': [0.7712587186895689, 0.9560813643100781],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.9485512733887065,
 'weight_decay_Hydroxylation-K': 0.15007174178131688,
 'weight_decay_Methylation-K': 0.576295341253803}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.386
[3,     4] loss: 1.383
[4,     4] loss: 1.386
[5,     4] loss: 1.381
[6,     4] loss: 1.381
[7,     4] loss: 1.378
[8,     4] loss: 1.381
[9,     4] loss: 1.379
[10,     4] loss: 1.379
[11,     4] loss: 1.370
[12,     4] loss: 1.362
[13,     4] loss: 1.371
[14,     4] loss: 1.359
[15,     4] loss: 1.361
[16,     4] loss: 1.353
[17,     4] loss: 1.347
[18,     4] loss: 1.346
[19,     4] loss: 1.329
[20,     4] loss: 1.327
[21,     4] loss: 1.308
[22,     4] loss: 1.292
[23,     4] loss: 1.299
[24,     4] loss: 1.272
[25,     4] loss: 1.278
[26,     4] loss: 1.255
[27,     4] loss: 1.257
[28,     4] loss: 1.231
[29,     4] loss: 1.252
[30,     4] loss: 1.226
[31,     4] loss: 1.235
[32,     4] loss: 1.205
[33,     4] loss: 1.196
[34,     4] loss: 1.201
[35,     4] loss: 1.170
[36,     4] loss: 1.188
[37,     4] loss: 1.117
[38,     4] loss: 1.130
[39,     4] loss: 1.118
[40,     4] loss: 1.093
[41,     4] loss: 1.091
[42,     4] loss: 1.102
[43,     4] loss: 1.020
[44,     4] loss: 1.045
[45,     4] loss: 0.983
[46,     4] loss: 0.976
[47,     4] loss: 0.976
[48,     4] loss: 0.934
[49,     4] loss: 0.904
[50,     4] loss: 0.938
[51,     4] loss: 0.885
[52,     4] loss: 0.936
[53,     4] loss: 0.904
[54,     4] loss: 0.906
[55,     4] loss: 0.892
[56,     4] loss: 0.859
[57,     4] loss: 0.871
[58,     4] loss: 0.857
[59,     4] loss: 0.834
[60,     4] loss: 0.851
[61,     4] loss: 0.848
[62,     4] loss: 0.835
[63,     4] loss: 0.809
[64,     4] loss: 0.840
[65,     4] loss: 0.859
[66,     4] loss: 0.777
[67,     4] loss: 0.817
[68,     4] loss: 0.791
[69,     4] loss: 0.786
[70,     4] loss: 0.798
[71,     4] loss: 0.772
[72,     4] loss: 0.781
[73,     4] loss: 0.777
[74,     4] loss: 0.753
[75,     4] loss: 0.785
[76,     4] loss: 0.777
[77,     4] loss: 0.772
[78,     4] loss: 0.769
[79,     4] loss: 0.750
[80,     4] loss: 0.736
[81,     4] loss: 0.746
[82,     4] loss: 0.753
[83,     4] loss: 0.737
[84,     4] loss: 0.739
[85,     4] loss: 0.727
[86,     4] loss: 0.738
[87,     4] loss: 0.735
[88,     4] loss: 0.749
[89,     4] loss: 0.723
[90,     4] loss: 0.724
[91,     4] loss: 0.725
[92,     4] loss: 0.727
[93,     4] loss: 0.724
[94,     4] loss: 0.742
[95,     4] loss: 0.735
[96,     4] loss: 0.717
[97,     4] loss: 0.724
[98,     4] loss: 0.724
Early stopping applied (best metric=0.3962392210960388)
Finished Training
Total time taken: 51.69932460784912
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.389
[5,     4] loss: 1.391
[6,     4] loss: 1.388
[7,     4] loss: 1.379
[8,     4] loss: 1.385
[9,     4] loss: 1.380
[10,     4] loss: 1.381
[11,     4] loss: 1.384
[12,     4] loss: 1.378
[13,     4] loss: 1.377
[14,     4] loss: 1.378
[15,     4] loss: 1.374
[16,     4] loss: 1.365
[17,     4] loss: 1.363
[18,     4] loss: 1.359
[19,     4] loss: 1.353
[20,     4] loss: 1.342
[21,     4] loss: 1.325
[22,     4] loss: 1.328
[23,     4] loss: 1.311
[24,     4] loss: 1.285
[25,     4] loss: 1.315
[26,     4] loss: 1.298
[27,     4] loss: 1.274
[28,     4] loss: 1.274
[29,     4] loss: 1.229
[30,     4] loss: 1.224
[31,     4] loss: 1.219
[32,     4] loss: 1.205
[33,     4] loss: 1.186
[34,     4] loss: 1.159
[35,     4] loss: 1.126
[36,     4] loss: 1.130
[37,     4] loss: 1.113
[38,     4] loss: 1.065
[39,     4] loss: 1.048
[40,     4] loss: 1.047
[41,     4] loss: 1.044
[42,     4] loss: 0.980
[43,     4] loss: 1.004
[44,     4] loss: 0.954
[45,     4] loss: 0.948
[46,     4] loss: 0.945
[47,     4] loss: 0.922
[48,     4] loss: 0.927
[49,     4] loss: 0.901
[50,     4] loss: 0.907
[51,     4] loss: 0.878
[52,     4] loss: 0.847
[53,     4] loss: 0.852
[54,     4] loss: 0.839
[55,     4] loss: 0.827
[56,     4] loss: 0.815
[57,     4] loss: 0.836
[58,     4] loss: 0.811
[59,     4] loss: 0.795
[60,     4] loss: 0.798
[61,     4] loss: 0.809
[62,     4] loss: 0.797
[63,     4] loss: 0.768
[64,     4] loss: 0.780
[65,     4] loss: 0.763
[66,     4] loss: 0.766
[67,     4] loss: 0.765
[68,     4] loss: 0.753
[69,     4] loss: 0.770
[70,     4] loss: 0.744
[71,     4] loss: 0.740
[72,     4] loss: 0.744
[73,     4] loss: 0.750
[74,     4] loss: 0.742
[75,     4] loss: 0.732
[76,     4] loss: 0.744
[77,     4] loss: 0.747
[78,     4] loss: 0.733
[79,     4] loss: 0.730
[80,     4] loss: 0.730
[81,     4] loss: 0.725
[82,     4] loss: 0.728
[83,     4] loss: 0.725
Early stopping applied (best metric=0.4870198667049408)
Finished Training
Total time taken: 43.647249698638916
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.385
[3,     4] loss: 1.384
[4,     4] loss: 1.381
[5,     4] loss: 1.386
[6,     4] loss: 1.383
[7,     4] loss: 1.385
[8,     4] loss: 1.381
[9,     4] loss: 1.382
[10,     4] loss: 1.380
[11,     4] loss: 1.378
[12,     4] loss: 1.377
[13,     4] loss: 1.376
[14,     4] loss: 1.366
[15,     4] loss: 1.364
[16,     4] loss: 1.357
[17,     4] loss: 1.349
[18,     4] loss: 1.337
[19,     4] loss: 1.334
[20,     4] loss: 1.329
[21,     4] loss: 1.327
[22,     4] loss: 1.305
[23,     4] loss: 1.287
[24,     4] loss: 1.276
[25,     4] loss: 1.243
[26,     4] loss: 1.251
[27,     4] loss: 1.230
[28,     4] loss: 1.215
[29,     4] loss: 1.198
[30,     4] loss: 1.183
[31,     4] loss: 1.180
[32,     4] loss: 1.135
[33,     4] loss: 1.119
[34,     4] loss: 1.124
[35,     4] loss: 1.092
[36,     4] loss: 1.069
[37,     4] loss: 1.030
[38,     4] loss: 1.045
[39,     4] loss: 0.976
[40,     4] loss: 1.004
[41,     4] loss: 0.960
[42,     4] loss: 0.941
[43,     4] loss: 0.953
[44,     4] loss: 0.949
[45,     4] loss: 0.930
[46,     4] loss: 0.919
[47,     4] loss: 0.861
[48,     4] loss: 0.908
[49,     4] loss: 0.835
[50,     4] loss: 0.836
[51,     4] loss: 0.857
[52,     4] loss: 0.871
[53,     4] loss: 0.849
[54,     4] loss: 0.831
[55,     4] loss: 0.833
[56,     4] loss: 0.851
[57,     4] loss: 0.870
[58,     4] loss: 0.784
[59,     4] loss: 0.776
[60,     4] loss: 0.798
[61,     4] loss: 0.794
[62,     4] loss: 0.793
[63,     4] loss: 0.791
[64,     4] loss: 0.797
[65,     4] loss: 0.785
[66,     4] loss: 0.790
[67,     4] loss: 0.793
[68,     4] loss: 0.752
[69,     4] loss: 0.765
[70,     4] loss: 0.770
[71,     4] loss: 0.755
[72,     4] loss: 0.750
[73,     4] loss: 0.755
Early stopping applied (best metric=0.5308138132095337)
Finished Training
Total time taken: 39.3640022277832
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.388
[3,     4] loss: 1.388
[4,     4] loss: 1.387
[5,     4] loss: 1.385
[6,     4] loss: 1.386
[7,     4] loss: 1.381
[8,     4] loss: 1.381
[9,     4] loss: 1.380
[10,     4] loss: 1.384
[11,     4] loss: 1.390
[12,     4] loss: 1.383
[13,     4] loss: 1.383
[14,     4] loss: 1.379
[15,     4] loss: 1.380
[16,     4] loss: 1.378
[17,     4] loss: 1.374
[18,     4] loss: 1.374
[19,     4] loss: 1.368
[20,     4] loss: 1.365
[21,     4] loss: 1.365
[22,     4] loss: 1.351
[23,     4] loss: 1.352
[24,     4] loss: 1.332
[25,     4] loss: 1.331
[26,     4] loss: 1.327
[27,     4] loss: 1.320
[28,     4] loss: 1.302
[29,     4] loss: 1.298
[30,     4] loss: 1.256
[31,     4] loss: 1.272
[32,     4] loss: 1.302
[33,     4] loss: 1.238
[34,     4] loss: 1.263
[35,     4] loss: 1.223
[36,     4] loss: 1.223
[37,     4] loss: 1.186
[38,     4] loss: 1.172
[39,     4] loss: 1.205
[40,     4] loss: 1.155
[41,     4] loss: 1.170
[42,     4] loss: 1.090
[43,     4] loss: 1.109
[44,     4] loss: 1.069
[45,     4] loss: 1.048
[46,     4] loss: 1.094
[47,     4] loss: 1.024
[48,     4] loss: 1.041
[49,     4] loss: 1.016
[50,     4] loss: 0.971
[51,     4] loss: 0.994
[52,     4] loss: 0.944
[53,     4] loss: 0.926
[54,     4] loss: 0.935
[55,     4] loss: 0.904
[56,     4] loss: 0.916
[57,     4] loss: 0.871
[58,     4] loss: 0.875
[59,     4] loss: 0.885
[60,     4] loss: 0.855
[61,     4] loss: 0.830
[62,     4] loss: 0.827
[63,     4] loss: 0.826
[64,     4] loss: 0.815
[65,     4] loss: 0.803
[66,     4] loss: 0.801
[67,     4] loss: 0.806
[68,     4] loss: 0.781
[69,     4] loss: 0.761
[70,     4] loss: 0.763
[71,     4] loss: 0.766
[72,     4] loss: 0.782
[73,     4] loss: 0.765
[74,     4] loss: 0.748
[75,     4] loss: 0.748
[76,     4] loss: 0.727
[77,     4] loss: 0.730
[78,     4] loss: 0.730
[79,     4] loss: 0.728
[80,     4] loss: 0.736
[81,     4] loss: 0.730
[82,     4] loss: 0.724
[83,     4] loss: 0.719
[84,     4] loss: 0.716
[85,     4] loss: 0.704
[86,     4] loss: 0.713
[87,     4] loss: 0.703
[88,     4] loss: 0.715
[89,     4] loss: 0.705
[90,     4] loss: 0.710
[91,     4] loss: 0.715
[92,     4] loss: 0.698
[93,     4] loss: 0.707
[94,     4] loss: 0.701
[95,     4] loss: 0.684
[96,     4] loss: 0.702
Early stopping applied (best metric=0.4001176655292511)
Finished Training
Total time taken: 49.67817997932434
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.386
[2,     4] loss: 1.386
[3,     4] loss: 1.388
[4,     4] loss: 1.383
[5,     4] loss: 1.385
[6,     4] loss: 1.386
[7,     4] loss: 1.381
[8,     4] loss: 1.387
[9,     4] loss: 1.383
[10,     4] loss: 1.380
[11,     4] loss: 1.382
[12,     4] loss: 1.377
[13,     4] loss: 1.380
[14,     4] loss: 1.379
[15,     4] loss: 1.372
[16,     4] loss: 1.373
[17,     4] loss: 1.365
[18,     4] loss: 1.366
[19,     4] loss: 1.361
[20,     4] loss: 1.352
[21,     4] loss: 1.347
[22,     4] loss: 1.343
[23,     4] loss: 1.335
[24,     4] loss: 1.329
[25,     4] loss: 1.323
[26,     4] loss: 1.316
[27,     4] loss: 1.297
[28,     4] loss: 1.297
[29,     4] loss: 1.299
[30,     4] loss: 1.253
[31,     4] loss: 1.262
[32,     4] loss: 1.233
[33,     4] loss: 1.212
[34,     4] loss: 1.214
[35,     4] loss: 1.186
[36,     4] loss: 1.166
[37,     4] loss: 1.139
[38,     4] loss: 1.137
[39,     4] loss: 1.100
[40,     4] loss: 1.128
[41,     4] loss: 1.067
[42,     4] loss: 1.083
[43,     4] loss: 1.047
[44,     4] loss: 1.042
[45,     4] loss: 1.028
[46,     4] loss: 0.988
[47,     4] loss: 0.983
[48,     4] loss: 0.985
[49,     4] loss: 0.928
[50,     4] loss: 0.936
[51,     4] loss: 0.904
[52,     4] loss: 0.869
[53,     4] loss: 0.965
[54,     4] loss: 0.872
[55,     4] loss: 0.854
[56,     4] loss: 0.886
[57,     4] loss: 0.852
[58,     4] loss: 0.829
[59,     4] loss: 0.845
[60,     4] loss: 0.857
[61,     4] loss: 0.802
[62,     4] loss: 0.824
[63,     4] loss: 0.802
[64,     4] loss: 0.792
[65,     4] loss: 0.796
[66,     4] loss: 0.756
[67,     4] loss: 0.756
[68,     4] loss: 0.757
[69,     4] loss: 0.751
[70,     4] loss: 0.764
[71,     4] loss: 0.750
[72,     4] loss: 0.729
[73,     4] loss: 0.738
[74,     4] loss: 0.746
[75,     4] loss: 0.733
[76,     4] loss: 0.730
[77,     4] loss: 0.728
[78,     4] loss: 0.717
[79,     4] loss: 0.715
[80,     4] loss: 0.703
[81,     4] loss: 0.719
[82,     4] loss: 0.712
[83,     4] loss: 0.709
[84,     4] loss: 0.700
[85,     4] loss: 0.698
[86,     4] loss: 0.724
[87,     4] loss: 0.702
[88,     4] loss: 0.722
[89,     4] loss: 0.707
[90,     4] loss: 0.699
[91,     4] loss: 0.709
[92,     4] loss: 0.688
[93,     4] loss: 0.688
[94,     4] loss: 0.686
Early stopping applied (best metric=0.40903395414352417)
Finished Training
Total time taken: 48.355754137039185
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.387
[3,     4] loss: 1.387
[4,     4] loss: 1.384
[5,     4] loss: 1.382
[6,     4] loss: 1.383
[7,     4] loss: 1.384
[8,     4] loss: 1.385
[9,     4] loss: 1.383
[10,     4] loss: 1.378
[11,     4] loss: 1.378
[12,     4] loss: 1.377
[13,     4] loss: 1.375
[14,     4] loss: 1.375
[15,     4] loss: 1.372
[16,     4] loss: 1.365
[17,     4] loss: 1.362
[18,     4] loss: 1.357
[19,     4] loss: 1.343
[20,     4] loss: 1.335
[21,     4] loss: 1.332
[22,     4] loss: 1.327
[23,     4] loss: 1.293
[24,     4] loss: 1.303
[25,     4] loss: 1.275
[26,     4] loss: 1.288
[27,     4] loss: 1.278
[28,     4] loss: 1.236
[29,     4] loss: 1.245
[30,     4] loss: 1.227
[31,     4] loss: 1.221
[32,     4] loss: 1.211
[33,     4] loss: 1.171
[34,     4] loss: 1.200
[35,     4] loss: 1.173
[36,     4] loss: 1.167
[37,     4] loss: 1.138
[38,     4] loss: 1.140
[39,     4] loss: 1.093
[40,     4] loss: 1.062
[41,     4] loss: 1.057
[42,     4] loss: 1.040
[43,     4] loss: 0.992
[44,     4] loss: 0.983
[45,     4] loss: 0.981
[46,     4] loss: 0.998
[47,     4] loss: 0.956
[48,     4] loss: 0.975
[49,     4] loss: 0.925
[50,     4] loss: 0.960
[51,     4] loss: 0.929
[52,     4] loss: 0.910
[53,     4] loss: 0.901
[54,     4] loss: 0.874
[55,     4] loss: 0.906
[56,     4] loss: 0.869
[57,     4] loss: 0.856
[58,     4] loss: 0.886
[59,     4] loss: 0.884
[60,     4] loss: 0.829
[61,     4] loss: 0.857
[62,     4] loss: 0.834
[63,     4] loss: 0.817
[64,     4] loss: 0.811
[65,     4] loss: 0.829
[66,     4] loss: 0.818
[67,     4] loss: 0.784
[68,     4] loss: 0.816
[69,     4] loss: 0.780
[70,     4] loss: 0.781
[71,     4] loss: 0.765
[72,     4] loss: 0.771
[73,     4] loss: 0.749
[74,     4] loss: 0.752
[75,     4] loss: 0.748
[76,     4] loss: 0.753
[77,     4] loss: 0.728
[78,     4] loss: 0.723
[79,     4] loss: 0.734
[80,     4] loss: 0.730
[81,     4] loss: 0.724
[82,     4] loss: 0.712
[83,     4] loss: 0.709
Early stopping applied (best metric=0.44061335921287537)
Finished Training
Total time taken: 45.48508834838867
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.386
[5,     4] loss: 1.386
[6,     4] loss: 1.388
[7,     4] loss: 1.383
[8,     4] loss: 1.384
[9,     4] loss: 1.383
[10,     4] loss: 1.384
[11,     4] loss: 1.381
[12,     4] loss: 1.383
[13,     4] loss: 1.378
[14,     4] loss: 1.381
[15,     4] loss: 1.377
[16,     4] loss: 1.378
[17,     4] loss: 1.370
[18,     4] loss: 1.370
[19,     4] loss: 1.369
[20,     4] loss: 1.360
[21,     4] loss: 1.360
[22,     4] loss: 1.341
[23,     4] loss: 1.336
[24,     4] loss: 1.327
[25,     4] loss: 1.327
[26,     4] loss: 1.300
[27,     4] loss: 1.285
[28,     4] loss: 1.277
[29,     4] loss: 1.244
[30,     4] loss: 1.245
[31,     4] loss: 1.271
[32,     4] loss: 1.187
[33,     4] loss: 1.195
[34,     4] loss: 1.173
[35,     4] loss: 1.177
[36,     4] loss: 1.160
[37,     4] loss: 1.129
[38,     4] loss: 1.142
[39,     4] loss: 1.099
[40,     4] loss: 1.095
[41,     4] loss: 1.064
[42,     4] loss: 1.055
[43,     4] loss: 1.034
[44,     4] loss: 1.053
[45,     4] loss: 1.009
[46,     4] loss: 0.967
[47,     4] loss: 0.955
[48,     4] loss: 0.941
[49,     4] loss: 0.930
[50,     4] loss: 0.925
[51,     4] loss: 0.905
[52,     4] loss: 0.907
[53,     4] loss: 0.942
[54,     4] loss: 0.956
[55,     4] loss: 0.942
[56,     4] loss: 0.874
[57,     4] loss: 0.867
[58,     4] loss: 0.862
[59,     4] loss: 0.817
[60,     4] loss: 0.848
[61,     4] loss: 0.793
[62,     4] loss: 0.855
[63,     4] loss: 0.826
[64,     4] loss: 0.801
[65,     4] loss: 0.846
[66,     4] loss: 0.814
[67,     4] loss: 0.840
[68,     4] loss: 0.814
[69,     4] loss: 0.804
[70,     4] loss: 0.800
[71,     4] loss: 0.793
[72,     4] loss: 0.834
[73,     4] loss: 0.788
[74,     4] loss: 0.818
[75,     4] loss: 0.782
[76,     4] loss: 0.795
[77,     4] loss: 0.792
[78,     4] loss: 0.792
[79,     4] loss: 0.775
[80,     4] loss: 0.754
[81,     4] loss: 0.756
[82,     4] loss: 0.766
[83,     4] loss: 0.739
[84,     4] loss: 0.739
[85,     4] loss: 0.741
[86,     4] loss: 0.743
Early stopping applied (best metric=0.3865984082221985)
Finished Training
Total time taken: 45.64942383766174
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.387
[3,     4] loss: 1.387
[4,     4] loss: 1.383
[5,     4] loss: 1.386
[6,     4] loss: 1.388
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.383
[10,     4] loss: 1.384
[11,     4] loss: 1.384
[12,     4] loss: 1.382
[13,     4] loss: 1.377
[14,     4] loss: 1.377
[15,     4] loss: 1.380
[16,     4] loss: 1.376
[17,     4] loss: 1.369
[18,     4] loss: 1.359
[19,     4] loss: 1.363
[20,     4] loss: 1.353
[21,     4] loss: 1.347
[22,     4] loss: 1.346
[23,     4] loss: 1.337
[24,     4] loss: 1.324
[25,     4] loss: 1.313
[26,     4] loss: 1.310
[27,     4] loss: 1.296
[28,     4] loss: 1.263
[29,     4] loss: 1.259
[30,     4] loss: 1.257
[31,     4] loss: 1.229
[32,     4] loss: 1.244
[33,     4] loss: 1.224
[34,     4] loss: 1.195
[35,     4] loss: 1.183
[36,     4] loss: 1.152
[37,     4] loss: 1.127
[38,     4] loss: 1.109
[39,     4] loss: 1.106
[40,     4] loss: 1.064
[41,     4] loss: 1.027
[42,     4] loss: 1.042
[43,     4] loss: 1.014
[44,     4] loss: 1.008
[45,     4] loss: 0.984
[46,     4] loss: 0.963
[47,     4] loss: 0.953
[48,     4] loss: 0.912
[49,     4] loss: 0.921
[50,     4] loss: 0.907
[51,     4] loss: 0.896
[52,     4] loss: 0.889
[53,     4] loss: 0.864
[54,     4] loss: 0.860
[55,     4] loss: 0.865
[56,     4] loss: 0.846
[57,     4] loss: 0.848
[58,     4] loss: 0.862
[59,     4] loss: 0.870
[60,     4] loss: 0.791
[61,     4] loss: 0.837
[62,     4] loss: 0.819
[63,     4] loss: 0.825
[64,     4] loss: 0.831
[65,     4] loss: 0.787
[66,     4] loss: 0.774
[67,     4] loss: 0.805
[68,     4] loss: 0.762
[69,     4] loss: 0.779
[70,     4] loss: 0.764
[71,     4] loss: 0.779
[72,     4] loss: 0.752
[73,     4] loss: 0.742
[74,     4] loss: 0.785
[75,     4] loss: 0.748
[76,     4] loss: 0.760
[77,     4] loss: 0.748
[78,     4] loss: 0.787
[79,     4] loss: 0.720
[80,     4] loss: 0.725
[81,     4] loss: 0.733
[82,     4] loss: 0.718
[83,     4] loss: 0.720
[84,     4] loss: 0.729
[85,     4] loss: 0.712
Early stopping applied (best metric=0.4720514416694641)
Finished Training
Total time taken: 45.33571004867554
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.384
[3,     4] loss: 1.385
[4,     4] loss: 1.386
[5,     4] loss: 1.382
[6,     4] loss: 1.386
[7,     4] loss: 1.384
[8,     4] loss: 1.384
[9,     4] loss: 1.380
[10,     4] loss: 1.380
[11,     4] loss: 1.380
[12,     4] loss: 1.378
[13,     4] loss: 1.369
[14,     4] loss: 1.366
[15,     4] loss: 1.362
[16,     4] loss: 1.358
[17,     4] loss: 1.354
[18,     4] loss: 1.326
[19,     4] loss: 1.327
[20,     4] loss: 1.308
[21,     4] loss: 1.300
[22,     4] loss: 1.280
[23,     4] loss: 1.287
[24,     4] loss: 1.276
[25,     4] loss: 1.237
[26,     4] loss: 1.234
[27,     4] loss: 1.194
[28,     4] loss: 1.216
[29,     4] loss: 1.168
[30,     4] loss: 1.183
[31,     4] loss: 1.166
[32,     4] loss: 1.127
[33,     4] loss: 1.120
[34,     4] loss: 1.106
[35,     4] loss: 1.111
[36,     4] loss: 1.075
[37,     4] loss: 1.064
[38,     4] loss: 1.064
[39,     4] loss: 1.037
[40,     4] loss: 1.006
[41,     4] loss: 0.985
[42,     4] loss: 0.975
[43,     4] loss: 0.973
[44,     4] loss: 0.948
[45,     4] loss: 0.918
[46,     4] loss: 0.936
[47,     4] loss: 0.889
[48,     4] loss: 0.923
[49,     4] loss: 0.899
[50,     4] loss: 0.886
[51,     4] loss: 0.864
[52,     4] loss: 0.838
[53,     4] loss: 0.835
[54,     4] loss: 0.844
[55,     4] loss: 0.805
[56,     4] loss: 0.800
[57,     4] loss: 0.830
[58,     4] loss: 0.785
[59,     4] loss: 0.791
[60,     4] loss: 0.789
[61,     4] loss: 0.780
[62,     4] loss: 0.771
[63,     4] loss: 0.770
[64,     4] loss: 0.777
[65,     4] loss: 0.778
[66,     4] loss: 0.778
[67,     4] loss: 0.774
[68,     4] loss: 0.779
Early stopping applied (best metric=0.5337955951690674)
Finished Training
Total time taken: 34.770546197891235
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.407
[2,     4] loss: 1.385
[3,     4] loss: 1.389
[4,     4] loss: 1.382
[5,     4] loss: 1.387
[6,     4] loss: 1.385
[7,     4] loss: 1.383
[8,     4] loss: 1.392
[9,     4] loss: 1.383
[10,     4] loss: 1.383
[11,     4] loss: 1.381
[12,     4] loss: 1.376
[13,     4] loss: 1.378
[14,     4] loss: 1.375
[15,     4] loss: 1.368
[16,     4] loss: 1.366
[17,     4] loss: 1.359
[18,     4] loss: 1.358
[19,     4] loss: 1.342
[20,     4] loss: 1.339
[21,     4] loss: 1.322
[22,     4] loss: 1.320
[23,     4] loss: 1.301
[24,     4] loss: 1.290
[25,     4] loss: 1.300
[26,     4] loss: 1.271
[27,     4] loss: 1.273
[28,     4] loss: 1.264
[29,     4] loss: 1.246
[30,     4] loss: 1.194
[31,     4] loss: 1.236
[32,     4] loss: 1.202
[33,     4] loss: 1.167
[34,     4] loss: 1.151
[35,     4] loss: 1.129
[36,     4] loss: 1.142
[37,     4] loss: 1.107
[38,     4] loss: 1.075
[39,     4] loss: 1.104
[40,     4] loss: 1.037
[41,     4] loss: 1.054
[42,     4] loss: 1.008
[43,     4] loss: 1.007
[44,     4] loss: 1.001
[45,     4] loss: 0.986
[46,     4] loss: 0.966
[47,     4] loss: 0.964
[48,     4] loss: 0.942
[49,     4] loss: 0.956
[50,     4] loss: 0.940
[51,     4] loss: 0.861
[52,     4] loss: 0.969
[53,     4] loss: 0.889
[54,     4] loss: 0.910
[55,     4] loss: 0.908
[56,     4] loss: 0.878
[57,     4] loss: 0.883
[58,     4] loss: 0.915
[59,     4] loss: 0.876
[60,     4] loss: 0.827
[61,     4] loss: 0.875
[62,     4] loss: 0.878
[63,     4] loss: 0.814
[64,     4] loss: 0.867
[65,     4] loss: 0.835
[66,     4] loss: 0.812
[67,     4] loss: 0.780
[68,     4] loss: 0.770
[69,     4] loss: 0.792
[70,     4] loss: 0.774
[71,     4] loss: 0.759
[72,     4] loss: 0.788
[73,     4] loss: 0.769
[74,     4] loss: 0.749
[75,     4] loss: 0.747
[76,     4] loss: 0.731
[77,     4] loss: 0.733
[78,     4] loss: 0.765
[79,     4] loss: 0.750
[80,     4] loss: 0.736
[81,     4] loss: 0.742
[82,     4] loss: 0.740
[83,     4] loss: 0.740
[84,     4] loss: 0.730
Early stopping applied (best metric=0.45045599341392517)
Finished Training
Total time taken: 44.199978828430176
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.390
[3,     4] loss: 1.389
[4,     4] loss: 1.387
[5,     4] loss: 1.384
[6,     4] loss: 1.389
[7,     4] loss: 1.386
[8,     4] loss: 1.383
[9,     4] loss: 1.387
[10,     4] loss: 1.384
[11,     4] loss: 1.381
[12,     4] loss: 1.378
[13,     4] loss: 1.382
[14,     4] loss: 1.378
[15,     4] loss: 1.376
[16,     4] loss: 1.377
[17,     4] loss: 1.376
[18,     4] loss: 1.371
[19,     4] loss: 1.358
[20,     4] loss: 1.363
[21,     4] loss: 1.354
[22,     4] loss: 1.350
[23,     4] loss: 1.342
[24,     4] loss: 1.349
[25,     4] loss: 1.336
[26,     4] loss: 1.318
[27,     4] loss: 1.303
[28,     4] loss: 1.308
[29,     4] loss: 1.281
[30,     4] loss: 1.278
[31,     4] loss: 1.285
[32,     4] loss: 1.295
[33,     4] loss: 1.245
[34,     4] loss: 1.268
[35,     4] loss: 1.236
[36,     4] loss: 1.224
[37,     4] loss: 1.174
[38,     4] loss: 1.199
[39,     4] loss: 1.170
[40,     4] loss: 1.156
[41,     4] loss: 1.129
[42,     4] loss: 1.137
[43,     4] loss: 1.100
[44,     4] loss: 1.080
[45,     4] loss: 1.050
[46,     4] loss: 1.026
[47,     4] loss: 0.998
[48,     4] loss: 1.016
[49,     4] loss: 0.990
[50,     4] loss: 0.966
[51,     4] loss: 0.958
[52,     4] loss: 0.966
[53,     4] loss: 0.912
[54,     4] loss: 0.992
[55,     4] loss: 0.887
[56,     4] loss: 0.909
[57,     4] loss: 0.869
[58,     4] loss: 0.850
[59,     4] loss: 0.834
[60,     4] loss: 0.860
[61,     4] loss: 0.818
[62,     4] loss: 0.830
[63,     4] loss: 0.829
[64,     4] loss: 0.796
[65,     4] loss: 0.791
[66,     4] loss: 0.831
[67,     4] loss: 0.838
[68,     4] loss: 0.818
[69,     4] loss: 0.800
[70,     4] loss: 0.799
[71,     4] loss: 0.809
[72,     4] loss: 0.807
[73,     4] loss: 0.758
[74,     4] loss: 0.760
[75,     4] loss: 0.779
[76,     4] loss: 0.785
[77,     4] loss: 0.766
[78,     4] loss: 0.781
[79,     4] loss: 0.789
[80,     4] loss: 0.748
[81,     4] loss: 0.766
[82,     4] loss: 0.734
[83,     4] loss: 0.740
[84,     4] loss: 0.731
[85,     4] loss: 0.714
[86,     4] loss: 0.735
[87,     4] loss: 0.718
[88,     4] loss: 0.710
[89,     4] loss: 0.711
[90,     4] loss: 0.719
[91,     4] loss: 0.702
[92,     4] loss: 0.701
[93,     4] loss: 0.706
[94,     4] loss: 0.700
[95,     4] loss: 0.702
[96,     4] loss: 0.710
[97,     4] loss: 0.689
[98,     4] loss: 0.688
[99,     4] loss: 0.699
Early stopping applied (best metric=0.35115036368370056)
Finished Training
Total time taken: 51.999945402145386
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.389
[3,     4] loss: 1.386
[4,     4] loss: 1.385
[5,     4] loss: 1.385
[6,     4] loss: 1.382
[7,     4] loss: 1.383
[8,     4] loss: 1.382
[9,     4] loss: 1.382
[10,     4] loss: 1.382
[11,     4] loss: 1.379
[12,     4] loss: 1.380
[13,     4] loss: 1.378
[14,     4] loss: 1.376
[15,     4] loss: 1.377
[16,     4] loss: 1.374
[17,     4] loss: 1.368
[18,     4] loss: 1.362
[19,     4] loss: 1.357
[20,     4] loss: 1.355
[21,     4] loss: 1.339
[22,     4] loss: 1.343
[23,     4] loss: 1.333
[24,     4] loss: 1.318
[25,     4] loss: 1.314
[26,     4] loss: 1.305
[27,     4] loss: 1.303
[28,     4] loss: 1.275
[29,     4] loss: 1.260
[30,     4] loss: 1.251
[31,     4] loss: 1.225
[32,     4] loss: 1.225
[33,     4] loss: 1.220
[34,     4] loss: 1.192
[35,     4] loss: 1.162
[36,     4] loss: 1.148
[37,     4] loss: 1.126
[38,     4] loss: 1.119
[39,     4] loss: 1.077
[40,     4] loss: 1.097
[41,     4] loss: 1.065
[42,     4] loss: 1.007
[43,     4] loss: 1.042
[44,     4] loss: 0.951
[45,     4] loss: 0.981
[46,     4] loss: 0.979
[47,     4] loss: 0.957
[48,     4] loss: 0.965
[49,     4] loss: 0.889
[50,     4] loss: 0.917
[51,     4] loss: 0.920
[52,     4] loss: 0.910
[53,     4] loss: 0.860
[54,     4] loss: 0.838
[55,     4] loss: 0.910
[56,     4] loss: 0.863
[57,     4] loss: 0.870
[58,     4] loss: 0.852
[59,     4] loss: 0.864
[60,     4] loss: 0.826
[61,     4] loss: 0.842
[62,     4] loss: 0.856
[63,     4] loss: 0.825
[64,     4] loss: 0.815
[65,     4] loss: 0.828
[66,     4] loss: 0.790
[67,     4] loss: 0.805
[68,     4] loss: 0.796
[69,     4] loss: 0.767
[70,     4] loss: 0.805
[71,     4] loss: 0.778
[72,     4] loss: 0.758
[73,     4] loss: 0.776
[74,     4] loss: 0.761
[75,     4] loss: 0.748
[76,     4] loss: 0.767
[77,     4] loss: 0.751
[78,     4] loss: 0.737
[79,     4] loss: 0.829
[80,     4] loss: 0.720
[81,     4] loss: 0.748
[82,     4] loss: 0.761
[83,     4] loss: 0.778
[84,     4] loss: 0.721
[85,     4] loss: 0.735
[86,     4] loss: 0.735
[87,     4] loss: 0.720
[88,     4] loss: 0.736
[89,     4] loss: 0.704
[90,     4] loss: 0.733
Early stopping applied (best metric=0.4614660143852234)
Finished Training
Total time taken: 49.604286670684814
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.385
[3,     4] loss: 1.387
[4,     4] loss: 1.388
[5,     4] loss: 1.387
[6,     4] loss: 1.382
[7,     4] loss: 1.384
[8,     4] loss: 1.385
[9,     4] loss: 1.386
[10,     4] loss: 1.382
[11,     4] loss: 1.383
[12,     4] loss: 1.379
[13,     4] loss: 1.377
[14,     4] loss: 1.379
[15,     4] loss: 1.378
[16,     4] loss: 1.371
[17,     4] loss: 1.370
[18,     4] loss: 1.359
[19,     4] loss: 1.355
[20,     4] loss: 1.357
[21,     4] loss: 1.348
[22,     4] loss: 1.339
[23,     4] loss: 1.327
[24,     4] loss: 1.327
[25,     4] loss: 1.313
[26,     4] loss: 1.307
[27,     4] loss: 1.299
[28,     4] loss: 1.293
[29,     4] loss: 1.285
[30,     4] loss: 1.268
[31,     4] loss: 1.267
[32,     4] loss: 1.240
[33,     4] loss: 1.217
[34,     4] loss: 1.206
[35,     4] loss: 1.163
[36,     4] loss: 1.195
[37,     4] loss: 1.170
[38,     4] loss: 1.159
[39,     4] loss: 1.132
[40,     4] loss: 1.097
[41,     4] loss: 1.074
[42,     4] loss: 1.098
[43,     4] loss: 1.081
[44,     4] loss: 1.006
[45,     4] loss: 1.015
[46,     4] loss: 0.987
[47,     4] loss: 0.990
[48,     4] loss: 1.029
[49,     4] loss: 0.978
[50,     4] loss: 1.001
[51,     4] loss: 0.999
[52,     4] loss: 0.941
[53,     4] loss: 0.959
[54,     4] loss: 0.873
[55,     4] loss: 0.899
[56,     4] loss: 0.887
[57,     4] loss: 0.877
[58,     4] loss: 0.860
[59,     4] loss: 0.838
[60,     4] loss: 0.849
[61,     4] loss: 0.821
[62,     4] loss: 0.819
[63,     4] loss: 0.815
[64,     4] loss: 0.826
[65,     4] loss: 0.801
[66,     4] loss: 0.782
[67,     4] loss: 0.778
[68,     4] loss: 0.761
[69,     4] loss: 0.767
[70,     4] loss: 0.770
[71,     4] loss: 0.752
[72,     4] loss: 0.743
[73,     4] loss: 0.752
[74,     4] loss: 0.731
[75,     4] loss: 0.751
[76,     4] loss: 0.747
[77,     4] loss: 0.727
[78,     4] loss: 0.746
[79,     4] loss: 0.728
[80,     4] loss: 0.730
[81,     4] loss: 0.721
[82,     4] loss: 0.717
[83,     4] loss: 0.723
[84,     4] loss: 0.714
[85,     4] loss: 0.724
[86,     4] loss: 0.720
[87,     4] loss: 0.716
[88,     4] loss: 0.715
[89,     4] loss: 0.714
[90,     4] loss: 0.718
[91,     4] loss: 0.703
[92,     4] loss: 0.708
[93,     4] loss: 0.703
[94,     4] loss: 0.703
[95,     4] loss: 0.701
[96,     4] loss: 0.701
[97,     4] loss: 0.703
[98,     4] loss: 0.710
[99,     4] loss: 0.702
[100,     4] loss: 0.704
Early stopping applied (best metric=0.3341031074523926)
Finished Training
Total time taken: 55.37196063995361
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.388
[3,     4] loss: 1.390
[4,     4] loss: 1.386
[5,     4] loss: 1.383
[6,     4] loss: 1.388
[7,     4] loss: 1.387
[8,     4] loss: 1.385
[9,     4] loss: 1.386
[10,     4] loss: 1.384
[11,     4] loss: 1.383
[12,     4] loss: 1.381
[13,     4] loss: 1.379
[14,     4] loss: 1.384
[15,     4] loss: 1.380
[16,     4] loss: 1.376
[17,     4] loss: 1.377
[18,     4] loss: 1.371
[19,     4] loss: 1.371
[20,     4] loss: 1.370
[21,     4] loss: 1.367
[22,     4] loss: 1.359
[23,     4] loss: 1.354
[24,     4] loss: 1.337
[25,     4] loss: 1.338
[26,     4] loss: 1.323
[27,     4] loss: 1.312
[28,     4] loss: 1.303
[29,     4] loss: 1.298
[30,     4] loss: 1.267
[31,     4] loss: 1.252
[32,     4] loss: 1.243
[33,     4] loss: 1.213
[34,     4] loss: 1.210
[35,     4] loss: 1.179
[36,     4] loss: 1.148
[37,     4] loss: 1.126
[38,     4] loss: 1.111
[39,     4] loss: 1.055
[40,     4] loss: 1.037
[41,     4] loss: 1.058
[42,     4] loss: 0.999
[43,     4] loss: 0.989
[44,     4] loss: 1.007
[45,     4] loss: 0.963
[46,     4] loss: 0.961
[47,     4] loss: 0.913
[48,     4] loss: 0.993
[49,     4] loss: 0.913
[50,     4] loss: 0.908
[51,     4] loss: 0.882
[52,     4] loss: 0.840
[53,     4] loss: 0.898
[54,     4] loss: 0.882
[55,     4] loss: 0.851
[56,     4] loss: 0.880
[57,     4] loss: 0.840
[58,     4] loss: 0.808
[59,     4] loss: 0.805
[60,     4] loss: 0.876
[61,     4] loss: 0.821
[62,     4] loss: 0.867
[63,     4] loss: 0.861
[64,     4] loss: 0.833
[65,     4] loss: 0.777
[66,     4] loss: 0.818
[67,     4] loss: 0.777
[68,     4] loss: 0.797
[69,     4] loss: 0.767
[70,     4] loss: 0.804
[71,     4] loss: 0.766
[72,     4] loss: 0.784
[73,     4] loss: 0.743
[74,     4] loss: 0.769
[75,     4] loss: 0.763
[76,     4] loss: 0.742
[77,     4] loss: 0.747
[78,     4] loss: 0.749
[79,     4] loss: 0.730
[80,     4] loss: 0.741
[81,     4] loss: 0.720
[82,     4] loss: 0.723
[83,     4] loss: 0.724
[84,     4] loss: 0.729
[85,     4] loss: 0.737
[86,     4] loss: 0.745
[87,     4] loss: 0.734
[88,     4] loss: 0.735
[89,     4] loss: 0.716
[90,     4] loss: 0.731
[91,     4] loss: 0.717
[92,     4] loss: 0.716
[93,     4] loss: 0.706
Early stopping applied (best metric=0.38961952924728394)
Finished Training
Total time taken: 49.742289304733276
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.415
[2,     4] loss: 1.392
[3,     4] loss: 1.385
[4,     4] loss: 1.388
[5,     4] loss: 1.389
[6,     4] loss: 1.388
[7,     4] loss: 1.388
[8,     4] loss: 1.383
[9,     4] loss: 1.383
[10,     4] loss: 1.381
[11,     4] loss: 1.385
[12,     4] loss: 1.381
[13,     4] loss: 1.383
[14,     4] loss: 1.380
[15,     4] loss: 1.377
[16,     4] loss: 1.371
[17,     4] loss: 1.369
[18,     4] loss: 1.364
[19,     4] loss: 1.359
[20,     4] loss: 1.358
[21,     4] loss: 1.347
[22,     4] loss: 1.345
[23,     4] loss: 1.325
[24,     4] loss: 1.329
[25,     4] loss: 1.315
[26,     4] loss: 1.284
[27,     4] loss: 1.269
[28,     4] loss: 1.269
[29,     4] loss: 1.259
[30,     4] loss: 1.264
[31,     4] loss: 1.230
[32,     4] loss: 1.219
[33,     4] loss: 1.205
[34,     4] loss: 1.183
[35,     4] loss: 1.180
[36,     4] loss: 1.149
[37,     4] loss: 1.114
[38,     4] loss: 1.100
[39,     4] loss: 1.115
[40,     4] loss: 1.061
[41,     4] loss: 1.056
[42,     4] loss: 1.004
[43,     4] loss: 1.012
[44,     4] loss: 0.984
[45,     4] loss: 0.964
[46,     4] loss: 0.952
[47,     4] loss: 0.914
[48,     4] loss: 0.938
[49,     4] loss: 0.927
[50,     4] loss: 0.861
[51,     4] loss: 0.847
[52,     4] loss: 0.886
[53,     4] loss: 0.851
[54,     4] loss: 0.829
[55,     4] loss: 0.822
[56,     4] loss: 0.853
[57,     4] loss: 0.802
[58,     4] loss: 0.801
[59,     4] loss: 0.821
[60,     4] loss: 0.796
[61,     4] loss: 0.786
[62,     4] loss: 0.775
[63,     4] loss: 0.779
[64,     4] loss: 0.782
[65,     4] loss: 0.782
[66,     4] loss: 0.764
[67,     4] loss: 0.754
[68,     4] loss: 0.742
[69,     4] loss: 0.748
[70,     4] loss: 0.751
[71,     4] loss: 0.756
[72,     4] loss: 0.735
[73,     4] loss: 0.725
[74,     4] loss: 0.727
[75,     4] loss: 0.721
[76,     4] loss: 0.718
[77,     4] loss: 0.712
[78,     4] loss: 0.705
[79,     4] loss: 0.718
Early stopping applied (best metric=0.46244651079177856)
Finished Training
Total time taken: 42.188111305236816
{'Hydroxylation-K Validation Accuracy': 0.7813534278959811, 'Hydroxylation-K Validation Sensitivity': 0.6651851851851852, 'Hydroxylation-K Validation Specificity': 0.8105263157894737, 'Hydroxylation-K Validation Precision': 0.48490196078431375, 'Hydroxylation-K AUC ROC': 0.8041910331384016, 'Hydroxylation-K AUC PR': 0.5351616562291014, 'Hydroxylation-K MCC': 0.43016222960701667, 'Hydroxylation-K F1': 0.553573858343455, 'Validation Loss (Hydroxylation-K)': 0.43370165626207985, 'Methylation-K Validation Accuracy': 0.8263892188550975, 'Methylation-K Validation Sensitivity': 0.12265387701022752, 'Methylation-K Validation Specificity': 0.902711540628851, 'Methylation-K Validation Precision': 0.11886696502634796, 'Methylation-K AUC ROC': 0.5424385206126657, 'Methylation-K AUC PR': 0.11219316574237588, 'Methylation-K MCC': 0.02409378881025933, 'Methylation-K F1': 0.11591872850825226, 'Validation Loss (Methylation-K)': 0.7084979097048442, 'Validation Loss (total)': 1.1421995639801026, 'TimeToTrain': 46.47279008229574}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0029043806585750684,
 'learning_rate_Hydroxylation-K': 0.006986374295789537,
 'learning_rate_Methylation-K': 0.007883489664051481,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5458253547513418,
 'loss_weight_Methylation-K': 0.7554522614944563,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2807091919,
 'sample_weights': [0.3368101720616371, 0.5008738111002604],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.322397882765031,
 'weight_decay_Hydroxylation-K': 1.8681832498421136,
 'weight_decay_Methylation-K': 8.521569124972503}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.389
[5,     4] loss: 1.392
[6,     4] loss: 1.381
[7,     4] loss: 1.379
[8,     4] loss: 1.373
[9,     4] loss: 1.323
[10,     4] loss: 1.301
[11,     4] loss: 1.207
[12,     4] loss: 1.164
[13,     4] loss: 1.063
[14,     4] loss: 1.121
[15,     4] loss: 1.080
[16,     4] loss: 1.048
[17,     4] loss: 1.020
[18,     4] loss: 0.973
[19,     4] loss: 1.043
[20,     4] loss: 1.015
[21,     4] loss: 0.978
[22,     4] loss: 0.910
[23,     4] loss: 0.867
[24,     4] loss: 0.988
[25,     4] loss: 1.012
[26,     4] loss: 1.059
[27,     4] loss: 1.045
[28,     4] loss: 0.926
[29,     4] loss: 0.914
[30,     4] loss: 1.038
[31,     4] loss: 0.909
[32,     4] loss: 0.813
[33,     4] loss: 0.859
[34,     4] loss: 1.054
[35,     4] loss: 0.929
[36,     4] loss: 0.933
[37,     4] loss: 0.885
[38,     4] loss: 0.889
[39,     4] loss: 0.808
[40,     4] loss: 0.791
[41,     4] loss: 0.862
[42,     4] loss: 0.850
[43,     4] loss: 0.860
[44,     4] loss: 0.882
[45,     4] loss: 0.837
[46,     4] loss: 1.041
[47,     4] loss: 1.113
[48,     4] loss: 1.118
[49,     4] loss: 1.040
[50,     4] loss: 0.945
[51,     4] loss: 0.962
[52,     4] loss: 0.901
[53,     4] loss: 0.826
[54,     4] loss: 0.760
[55,     4] loss: 0.774
[56,     4] loss: 0.762
[57,     4] loss: 0.771
[58,     4] loss: 0.788
[59,     4] loss: 0.979
[60,     4] loss: 1.031
[61,     4] loss: 0.931
[62,     4] loss: 0.909
[63,     4] loss: 0.825
[64,     4] loss: 0.792
[65,     4] loss: 0.789
[66,     4] loss: 0.871
[67,     4] loss: 0.861
[68,     4] loss: 0.841
[69,     4] loss: 0.881
[70,     4] loss: 0.878
[71,     4] loss: 0.822
[72,     4] loss: 0.825
[73,     4] loss: 0.789
[74,     4] loss: 0.794
[75,     4] loss: 0.845
[76,     4] loss: 0.917
[77,     4] loss: 0.924
[78,     4] loss: 0.879
[79,     4] loss: 0.801
[80,     4] loss: 0.876
[81,     4] loss: 0.797
[82,     4] loss: 0.899
[83,     4] loss: 0.842
[84,     4] loss: 0.790
[85,     4] loss: 0.778
[86,     4] loss: 0.783
[87,     4] loss: 0.786
[88,     4] loss: 0.843
[89,     4] loss: 0.789
[90,     4] loss: 0.774
[91,     4] loss: 0.793
[92,     4] loss: 0.811
[93,     4] loss: 0.824
[94,     4] loss: 0.818
[95,     4] loss: 0.763
[96,     4] loss: 0.746
[97,     4] loss: 0.788
[98,     4] loss: 0.918
[99,     4] loss: 1.069
[100,     4] loss: 0.976
[101,     4] loss: 0.917
[102,     4] loss: 0.810
[103,     4] loss: 0.861
[104,     4] loss: 0.908
[105,     4] loss: 0.846
[106,     4] loss: 0.791
[107,     4] loss: 0.790
[108,     4] loss: 0.799
[109,     4] loss: 0.767
[110,     4] loss: 0.762
Early stopping applied (best metric=0.34659260511398315)
Finished Training
Total time taken: 57.424859046936035
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.388
[3,     4] loss: 1.391
[4,     4] loss: 1.384
[5,     4] loss: 1.384
[6,     4] loss: 1.372
[7,     4] loss: 1.369
[8,     4] loss: 1.320
[9,     4] loss: 1.292
[10,     4] loss: 1.293
[11,     4] loss: 1.240
[12,     4] loss: 1.165
[13,     4] loss: 1.065
[14,     4] loss: 1.164
[15,     4] loss: 1.239
[16,     4] loss: 1.170
[17,     4] loss: 1.212
[18,     4] loss: 1.107
[19,     4] loss: 1.022
[20,     4] loss: 1.002
[21,     4] loss: 0.990
[22,     4] loss: 0.945
[23,     4] loss: 0.971
[24,     4] loss: 0.913
[25,     4] loss: 0.882
[26,     4] loss: 0.939
[27,     4] loss: 0.888
[28,     4] loss: 0.934
[29,     4] loss: 0.867
[30,     4] loss: 0.820
[31,     4] loss: 0.771
[32,     4] loss: 0.839
[33,     4] loss: 0.870
[34,     4] loss: 0.858
[35,     4] loss: 0.831
[36,     4] loss: 0.779
[37,     4] loss: 0.838
[38,     4] loss: 0.960
[39,     4] loss: 0.949
[40,     4] loss: 0.892
[41,     4] loss: 0.900
[42,     4] loss: 0.852
[43,     4] loss: 0.855
[44,     4] loss: 0.798
[45,     4] loss: 0.757
[46,     4] loss: 0.864
[47,     4] loss: 0.803
[48,     4] loss: 0.879
[49,     4] loss: 0.828
[50,     4] loss: 1.019
[51,     4] loss: 0.913
[52,     4] loss: 0.900
[53,     4] loss: 0.846
[54,     4] loss: 0.785
[55,     4] loss: 0.769
[56,     4] loss: 0.742
[57,     4] loss: 0.746
[58,     4] loss: 0.824
[59,     4] loss: 1.060
[60,     4] loss: 1.154
[61,     4] loss: 1.103
[62,     4] loss: 1.074
Early stopping applied (best metric=0.36790549755096436)
Finished Training
Total time taken: 34.53239059448242
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.379
[3,     4] loss: 1.362
[4,     4] loss: 1.352
[5,     4] loss: 1.329
[6,     4] loss: 1.238
[7,     4] loss: 1.241
[8,     4] loss: 1.198
[9,     4] loss: 1.118
[10,     4] loss: 1.086
[11,     4] loss: 1.048
[12,     4] loss: 1.015
[13,     4] loss: 1.037
[14,     4] loss: 0.913
[15,     4] loss: 0.937
[16,     4] loss: 1.085
[17,     4] loss: 1.005
[18,     4] loss: 0.971
[19,     4] loss: 0.942
[20,     4] loss: 0.901
[21,     4] loss: 0.863
[22,     4] loss: 1.064
[23,     4] loss: 0.952
[24,     4] loss: 0.928
[25,     4] loss: 0.866
[26,     4] loss: 0.827
[27,     4] loss: 0.807
[28,     4] loss: 0.902
[29,     4] loss: 0.928
[30,     4] loss: 0.843
[31,     4] loss: 0.871
[32,     4] loss: 0.954
[33,     4] loss: 0.926
[34,     4] loss: 0.910
[35,     4] loss: 0.811
[36,     4] loss: 0.867
[37,     4] loss: 0.782
[38,     4] loss: 0.819
[39,     4] loss: 0.831
[40,     4] loss: 0.891
[41,     4] loss: 0.861
[42,     4] loss: 0.998
[43,     4] loss: 0.888
[44,     4] loss: 0.854
[45,     4] loss: 0.815
[46,     4] loss: 0.881
[47,     4] loss: 0.850
[48,     4] loss: 0.807
[49,     4] loss: 0.758
[50,     4] loss: 0.788
[51,     4] loss: 0.779
[52,     4] loss: 0.806
[53,     4] loss: 0.796
[54,     4] loss: 0.759
[55,     4] loss: 0.801
[56,     4] loss: 0.762
[57,     4] loss: 0.793
[58,     4] loss: 1.007
[59,     4] loss: 0.897
Early stopping applied (best metric=0.526969850063324)
Finished Training
Total time taken: 31.48635220527649
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.386
[3,     4] loss: 1.383
[4,     4] loss: 1.382
[5,     4] loss: 1.378
[6,     4] loss: 1.338
[7,     4] loss: 1.299
[8,     4] loss: 1.239
[9,     4] loss: 1.188
[10,     4] loss: 1.144
[11,     4] loss: 1.076
[12,     4] loss: 1.197
[13,     4] loss: 1.068
[14,     4] loss: 1.063
[15,     4] loss: 0.987
[16,     4] loss: 0.995
[17,     4] loss: 0.996
[18,     4] loss: 0.907
[19,     4] loss: 0.959
[20,     4] loss: 1.004
[21,     4] loss: 0.921
[22,     4] loss: 0.850
[23,     4] loss: 0.915
[24,     4] loss: 0.820
[25,     4] loss: 0.841
[26,     4] loss: 0.847
[27,     4] loss: 0.940
[28,     4] loss: 0.856
[29,     4] loss: 0.818
[30,     4] loss: 0.869
[31,     4] loss: 0.774
[32,     4] loss: 0.807
[33,     4] loss: 0.773
[34,     4] loss: 0.798
[35,     4] loss: 0.778
[36,     4] loss: 0.788
[37,     4] loss: 0.914
[38,     4] loss: 0.890
[39,     4] loss: 0.870
[40,     4] loss: 0.898
[41,     4] loss: 0.807
[42,     4] loss: 0.777
[43,     4] loss: 0.760
[44,     4] loss: 0.797
[45,     4] loss: 0.758
[46,     4] loss: 0.796
[47,     4] loss: 1.269
[48,     4] loss: 1.277
[49,     4] loss: 1.229
[50,     4] loss: 1.151
[51,     4] loss: 1.107
[52,     4] loss: 0.976
[53,     4] loss: 0.990
[54,     4] loss: 0.863
[55,     4] loss: 0.871
[56,     4] loss: 1.079
[57,     4] loss: 0.931
[58,     4] loss: 0.943
[59,     4] loss: 0.831
[60,     4] loss: 0.803
[61,     4] loss: 0.781
[62,     4] loss: 0.818
[63,     4] loss: 0.858
Early stopping applied (best metric=0.3345624804496765)
Finished Training
Total time taken: 33.83829665184021
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.385
[2,     4] loss: 1.387
[3,     4] loss: 1.384
[4,     4] loss: 1.387
[5,     4] loss: 1.387
[6,     4] loss: 1.383
[7,     4] loss: 1.379
[8,     4] loss: 1.361
[9,     4] loss: 1.329
[10,     4] loss: 1.260
[11,     4] loss: 1.232
[12,     4] loss: 1.278
[13,     4] loss: 1.117
[14,     4] loss: 1.122
[15,     4] loss: 1.074
[16,     4] loss: 1.074
[17,     4] loss: 1.050
[18,     4] loss: 0.995
[19,     4] loss: 0.942
[20,     4] loss: 1.032
[21,     4] loss: 0.997
[22,     4] loss: 0.999
[23,     4] loss: 0.977
[24,     4] loss: 0.934
[25,     4] loss: 0.815
[26,     4] loss: 0.811
[27,     4] loss: 0.852
[28,     4] loss: 0.958
[29,     4] loss: 0.924
[30,     4] loss: 0.919
[31,     4] loss: 0.869
[32,     4] loss: 0.843
[33,     4] loss: 0.803
[34,     4] loss: 0.803
[35,     4] loss: 0.735
[36,     4] loss: 0.818
[37,     4] loss: 0.972
[38,     4] loss: 0.975
[39,     4] loss: 0.891
[40,     4] loss: 0.836
[41,     4] loss: 0.838
[42,     4] loss: 0.803
[43,     4] loss: 0.812
[44,     4] loss: 0.780
[45,     4] loss: 1.085
[46,     4] loss: 1.089
[47,     4] loss: 0.983
[48,     4] loss: 0.983
[49,     4] loss: 0.958
[50,     4] loss: 0.950
[51,     4] loss: 0.907
[52,     4] loss: 0.789
[53,     4] loss: 0.795
[54,     4] loss: 0.850
[55,     4] loss: 0.846
[56,     4] loss: 0.809
[57,     4] loss: 0.753
[58,     4] loss: 0.870
[59,     4] loss: 0.866
[60,     4] loss: 0.828
[61,     4] loss: 0.775
[62,     4] loss: 0.845
[63,     4] loss: 0.788
[64,     4] loss: 0.801
[65,     4] loss: 0.783
[66,     4] loss: 0.823
[67,     4] loss: 0.806
[68,     4] loss: 0.798
Early stopping applied (best metric=0.38609325885772705)
Finished Training
Total time taken: 36.95253014564514
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.398
[3,     4] loss: 1.385
[4,     4] loss: 1.385
[5,     4] loss: 1.379
[6,     4] loss: 1.373
[7,     4] loss: 1.358
[8,     4] loss: 1.311
[9,     4] loss: 1.225
[10,     4] loss: 1.170
[11,     4] loss: 1.121
[12,     4] loss: 1.139
[13,     4] loss: 1.096
[14,     4] loss: 1.061
[15,     4] loss: 1.058
[16,     4] loss: 1.143
[17,     4] loss: 1.042
[18,     4] loss: 1.054
[19,     4] loss: 1.012
[20,     4] loss: 1.002
[21,     4] loss: 0.915
[22,     4] loss: 0.919
[23,     4] loss: 0.877
[24,     4] loss: 0.931
[25,     4] loss: 0.995
[26,     4] loss: 0.927
[27,     4] loss: 0.951
[28,     4] loss: 0.993
[29,     4] loss: 0.907
[30,     4] loss: 0.822
[31,     4] loss: 0.774
[32,     4] loss: 0.851
[33,     4] loss: 0.850
[34,     4] loss: 0.915
[35,     4] loss: 0.896
[36,     4] loss: 0.819
[37,     4] loss: 0.805
[38,     4] loss: 0.805
[39,     4] loss: 0.785
[40,     4] loss: 0.911
[41,     4] loss: 0.871
[42,     4] loss: 0.896
[43,     4] loss: 0.908
[44,     4] loss: 0.846
[45,     4] loss: 0.817
[46,     4] loss: 0.806
[47,     4] loss: 0.784
[48,     4] loss: 0.784
[49,     4] loss: 0.793
[50,     4] loss: 0.785
[51,     4] loss: 0.783
[52,     4] loss: 0.742
[53,     4] loss: 0.882
[54,     4] loss: 0.815
[55,     4] loss: 0.770
[56,     4] loss: 0.799
[57,     4] loss: 1.287
[58,     4] loss: 1.103
[59,     4] loss: 1.107
[60,     4] loss: 1.065
[61,     4] loss: 0.946
[62,     4] loss: 0.909
[63,     4] loss: 0.953
[64,     4] loss: 1.040
[65,     4] loss: 0.993
[66,     4] loss: 0.949
[67,     4] loss: 0.834
[68,     4] loss: 0.903
[69,     4] loss: 0.935
[70,     4] loss: 0.849
[71,     4] loss: 0.812
[72,     4] loss: 0.853
[73,     4] loss: 0.830
[74,     4] loss: 0.775
[75,     4] loss: 0.752
[76,     4] loss: 0.885
[77,     4] loss: 0.963
[78,     4] loss: 0.926
[79,     4] loss: 0.879
[80,     4] loss: 0.852
[81,     4] loss: 0.800
[82,     4] loss: 0.800
[83,     4] loss: 0.761
[84,     4] loss: 0.768
[85,     4] loss: 0.793
[86,     4] loss: 0.857
[87,     4] loss: 0.838
[88,     4] loss: 0.805
[89,     4] loss: 0.772
[90,     4] loss: 0.857
[91,     4] loss: 0.902
[92,     4] loss: 0.901
[93,     4] loss: 0.824
[94,     4] loss: 0.811
[95,     4] loss: 0.771
[96,     4] loss: 0.757
[97,     4] loss: 0.836
[98,     4] loss: 0.884
[99,     4] loss: 0.976
[100,     4] loss: 0.942
[101,     4] loss: 0.896
[102,     4] loss: 0.833
[103,     4] loss: 0.818
[104,     4] loss: 0.781
[105,     4] loss: 0.747
[106,     4] loss: 0.731
[107,     4] loss: 0.771
[108,     4] loss: 0.821
[109,     4] loss: 0.846
[110,     4] loss: 0.851
[111,     4] loss: 0.794
[112,     4] loss: 0.817
[113,     4] loss: 0.953
[114,     4] loss: 0.881
[115,     4] loss: 0.845
[116,     4] loss: 0.820
[117,     4] loss: 0.737
[118,     4] loss: 0.762
[119,     4] loss: 0.758
[120,     4] loss: 0.777
[121,     4] loss: 0.838
[122,     4] loss: 0.998
[123,     4] loss: 1.039
[124,     4] loss: 0.935
[125,     4] loss: 0.815
[126,     4] loss: 0.760
[127,     4] loss: 0.855
[128,     4] loss: 0.907
[129,     4] loss: 0.867
[130,     4] loss: 0.817
Early stopping applied (best metric=0.3309992551803589)
Finished Training
Total time taken: 68.0543487071991
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.380
[3,     4] loss: 1.382
[4,     4] loss: 1.380
[5,     4] loss: 1.366
[6,     4] loss: 1.343
[7,     4] loss: 1.306
[8,     4] loss: 1.265
[9,     4] loss: 1.154
[10,     4] loss: 1.134
[11,     4] loss: 1.063
[12,     4] loss: 1.072
[13,     4] loss: 0.971
[14,     4] loss: 0.958
[15,     4] loss: 0.980
[16,     4] loss: 1.034
[17,     4] loss: 1.008
[18,     4] loss: 0.996
[19,     4] loss: 0.983
[20,     4] loss: 0.982
[21,     4] loss: 0.917
[22,     4] loss: 0.900
[23,     4] loss: 0.833
[24,     4] loss: 0.878
[25,     4] loss: 0.771
[26,     4] loss: 0.864
[27,     4] loss: 0.814
[28,     4] loss: 0.826
[29,     4] loss: 0.783
[30,     4] loss: 0.804
[31,     4] loss: 0.876
[32,     4] loss: 0.887
[33,     4] loss: 0.931
[34,     4] loss: 0.988
[35,     4] loss: 0.929
[36,     4] loss: 0.820
[37,     4] loss: 0.898
[38,     4] loss: 0.828
[39,     4] loss: 0.847
[40,     4] loss: 0.783
[41,     4] loss: 0.745
[42,     4] loss: 1.386
[43,     4] loss: 1.149
[44,     4] loss: 1.201
[45,     4] loss: 1.136
[46,     4] loss: 1.175
[47,     4] loss: 1.087
[48,     4] loss: 1.018
[49,     4] loss: 0.969
[50,     4] loss: 0.984
[51,     4] loss: 0.897
[52,     4] loss: 0.947
[53,     4] loss: 0.964
[54,     4] loss: 0.893
[55,     4] loss: 0.922
[56,     4] loss: 0.899
[57,     4] loss: 0.876
[58,     4] loss: 0.856
[59,     4] loss: 0.817
[60,     4] loss: 0.800
[61,     4] loss: 0.816
[62,     4] loss: 0.918
[63,     4] loss: 0.854
[64,     4] loss: 0.866
[65,     4] loss: 0.797
[66,     4] loss: 0.761
[67,     4] loss: 0.763
[68,     4] loss: 1.354
[69,     4] loss: 1.284
[70,     4] loss: 1.286
[71,     4] loss: 1.249
[72,     4] loss: 1.222
[73,     4] loss: 1.189
[74,     4] loss: 1.124
[75,     4] loss: 1.169
[76,     4] loss: 1.072
[77,     4] loss: 1.004
[78,     4] loss: 0.938
[79,     4] loss: 1.143
[80,     4] loss: 1.172
[81,     4] loss: 1.155
[82,     4] loss: 1.128
[83,     4] loss: 1.137
[84,     4] loss: 1.034
[85,     4] loss: 0.956
[86,     4] loss: 0.938
[87,     4] loss: 0.945
[88,     4] loss: 0.967
[89,     4] loss: 1.031
[90,     4] loss: 1.087
[91,     4] loss: 1.081
[92,     4] loss: 1.010
[93,     4] loss: 0.929
[94,     4] loss: 0.979
[95,     4] loss: 0.877
[96,     4] loss: 0.950
[97,     4] loss: 0.824
[98,     4] loss: 0.841
[99,     4] loss: 0.873
[100,     4] loss: 1.567
[101,     4] loss: 1.213
[102,     4] loss: 1.173
[103,     4] loss: 1.153
[104,     4] loss: 1.107
[105,     4] loss: 1.051
[106,     4] loss: 1.037
[107,     4] loss: 1.033
[108,     4] loss: 1.001
[109,     4] loss: 0.966
[110,     4] loss: 0.958
[111,     4] loss: 0.965
[112,     4] loss: 0.910
[113,     4] loss: 0.925
[114,     4] loss: 0.909
[115,     4] loss: 0.881
[116,     4] loss: 0.914
[117,     4] loss: 0.884
[118,     4] loss: 0.908
[119,     4] loss: 0.828
[120,     4] loss: 0.929
[121,     4] loss: 0.897
[122,     4] loss: 0.889
[123,     4] loss: 0.887
[124,     4] loss: 0.995
[125,     4] loss: 0.905
[126,     4] loss: 0.917
[127,     4] loss: 0.843
[128,     4] loss: 0.815
[129,     4] loss: 0.842
[130,     4] loss: 0.918
[131,     4] loss: 0.911
Early stopping applied (best metric=0.4954086244106293)
Finished Training
Total time taken: 67.63578653335571
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.385
[3,     4] loss: 1.375
[4,     4] loss: 1.377
[5,     4] loss: 1.376
[6,     4] loss: 1.362
[7,     4] loss: 1.332
[8,     4] loss: 1.279
[9,     4] loss: 1.206
[10,     4] loss: 1.194
[11,     4] loss: 1.110
[12,     4] loss: 1.090
[13,     4] loss: 1.003
[14,     4] loss: 1.028
[15,     4] loss: 0.990
[16,     4] loss: 0.998
[17,     4] loss: 1.021
[18,     4] loss: 1.008
[19,     4] loss: 1.071
[20,     4] loss: 1.033
[21,     4] loss: 0.925
[22,     4] loss: 0.904
[23,     4] loss: 0.845
[24,     4] loss: 0.847
[25,     4] loss: 0.855
[26,     4] loss: 0.916
[27,     4] loss: 0.912
[28,     4] loss: 0.885
[29,     4] loss: 0.893
[30,     4] loss: 0.834
[31,     4] loss: 0.819
[32,     4] loss: 0.794
[33,     4] loss: 0.802
[34,     4] loss: 0.825
[35,     4] loss: 0.843
[36,     4] loss: 0.849
[37,     4] loss: 0.866
[38,     4] loss: 0.870
[39,     4] loss: 0.820
[40,     4] loss: 0.945
[41,     4] loss: 0.936
[42,     4] loss: 1.015
[43,     4] loss: 0.907
[44,     4] loss: 0.868
[45,     4] loss: 0.811
[46,     4] loss: 0.845
[47,     4] loss: 0.841
[48,     4] loss: 0.743
[49,     4] loss: 0.978
[50,     4] loss: 0.992
[51,     4] loss: 0.952
[52,     4] loss: 0.892
[53,     4] loss: 0.825
[54,     4] loss: 0.800
[55,     4] loss: 0.789
[56,     4] loss: 0.800
[57,     4] loss: 0.803
[58,     4] loss: 0.806
[59,     4] loss: 0.908
[60,     4] loss: 0.931
[61,     4] loss: 0.978
[62,     4] loss: 0.897
[63,     4] loss: 0.834
[64,     4] loss: 0.865
[65,     4] loss: 0.841
[66,     4] loss: 0.876
[67,     4] loss: 0.786
[68,     4] loss: 0.811
[69,     4] loss: 0.840
[70,     4] loss: 0.802
[71,     4] loss: 0.865
[72,     4] loss: 0.824
[73,     4] loss: 0.797
[74,     4] loss: 0.786
[75,     4] loss: 0.755
[76,     4] loss: 1.043
[77,     4] loss: 1.176
[78,     4] loss: 1.170
[79,     4] loss: 1.127
[80,     4] loss: 0.983
[81,     4] loss: 0.911
[82,     4] loss: 1.017
[83,     4] loss: 0.889
[84,     4] loss: 0.877
[85,     4] loss: 0.818
[86,     4] loss: 0.820
[87,     4] loss: 0.780
[88,     4] loss: 0.828
[89,     4] loss: 0.859
[90,     4] loss: 0.840
[91,     4] loss: 0.840
[92,     4] loss: 0.788
[93,     4] loss: 0.897
[94,     4] loss: 0.937
[95,     4] loss: 0.902
[96,     4] loss: 0.833
[97,     4] loss: 0.814
[98,     4] loss: 0.758
[99,     4] loss: 0.826
[100,     4] loss: 0.839
[101,     4] loss: 0.809
[102,     4] loss: 0.793
Early stopping applied (best metric=0.39565926790237427)
Finished Training
Total time taken: 53.643847942352295
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.386
[3,     4] loss: 1.378
[4,     4] loss: 1.371
[5,     4] loss: 1.322
[6,     4] loss: 1.251
[7,     4] loss: 1.212
[8,     4] loss: 1.188
[9,     4] loss: 1.121
[10,     4] loss: 1.239
[11,     4] loss: 1.175
[12,     4] loss: 1.113
[13,     4] loss: 1.002
[14,     4] loss: 0.990
[15,     4] loss: 1.019
[16,     4] loss: 1.184
[17,     4] loss: 1.094
[18,     4] loss: 1.147
[19,     4] loss: 1.087
[20,     4] loss: 1.003
[21,     4] loss: 0.988
[22,     4] loss: 0.880
[23,     4] loss: 0.884
[24,     4] loss: 0.967
[25,     4] loss: 0.860
[26,     4] loss: 0.772
[27,     4] loss: 0.827
[28,     4] loss: 0.967
[29,     4] loss: 0.959
[30,     4] loss: 0.948
[31,     4] loss: 0.955
[32,     4] loss: 0.864
[33,     4] loss: 0.924
[34,     4] loss: 0.824
[35,     4] loss: 0.790
[36,     4] loss: 0.823
[37,     4] loss: 0.931
[38,     4] loss: 0.909
[39,     4] loss: 0.861
[40,     4] loss: 0.898
[41,     4] loss: 0.890
[42,     4] loss: 0.850
[43,     4] loss: 0.835
[44,     4] loss: 0.869
[45,     4] loss: 0.912
[46,     4] loss: 0.979
[47,     4] loss: 0.940
[48,     4] loss: 0.947
[49,     4] loss: 0.889
[50,     4] loss: 0.876
[51,     4] loss: 0.829
[52,     4] loss: 0.844
[53,     4] loss: 0.815
[54,     4] loss: 0.783
[55,     4] loss: 0.784
[56,     4] loss: 0.915
[57,     4] loss: 0.880
[58,     4] loss: 0.842
[59,     4] loss: 0.873
[60,     4] loss: 0.793
[61,     4] loss: 0.867
[62,     4] loss: 0.785
[63,     4] loss: 0.801
[64,     4] loss: 0.802
[65,     4] loss: 0.745
[66,     4] loss: 0.778
[67,     4] loss: 1.108
[68,     4] loss: 1.048
[69,     4] loss: 1.068
[70,     4] loss: 1.040
[71,     4] loss: 0.971
[72,     4] loss: 0.938
[73,     4] loss: 0.953
[74,     4] loss: 0.842
[75,     4] loss: 0.784
[76,     4] loss: 0.809
[77,     4] loss: 0.771
[78,     4] loss: 0.802
[79,     4] loss: 0.776
[80,     4] loss: 0.793
[81,     4] loss: 0.991
[82,     4] loss: 1.032
[83,     4] loss: 0.992
[84,     4] loss: 0.911
[85,     4] loss: 0.853
[86,     4] loss: 0.792
[87,     4] loss: 0.810
[88,     4] loss: 0.872
[89,     4] loss: 0.864
[90,     4] loss: 0.918
[91,     4] loss: 0.858
[92,     4] loss: 0.847
[93,     4] loss: 0.779
[94,     4] loss: 0.767
[95,     4] loss: 0.745
[96,     4] loss: 0.743
[97,     4] loss: 0.785
[98,     4] loss: 0.778
Early stopping applied (best metric=0.4055866003036499)
Finished Training
Total time taken: 52.87993049621582
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.393
[2,     4] loss: 1.386
[3,     4] loss: 1.386
[4,     4] loss: 1.390
[5,     4] loss: 1.378
[6,     4] loss: 1.382
[7,     4] loss: 1.377
[8,     4] loss: 1.335
[9,     4] loss: 1.262
[10,     4] loss: 1.252
[11,     4] loss: 1.225
[12,     4] loss: 1.190
[13,     4] loss: 1.198
[14,     4] loss: 1.223
[15,     4] loss: 1.172
[16,     4] loss: 1.105
[17,     4] loss: 1.113
[18,     4] loss: 1.054
[19,     4] loss: 1.098
[20,     4] loss: 1.118
[21,     4] loss: 1.062
[22,     4] loss: 0.983
[23,     4] loss: 0.970
[24,     4] loss: 0.940
[25,     4] loss: 0.912
[26,     4] loss: 0.933
[27,     4] loss: 0.833
[28,     4] loss: 0.837
[29,     4] loss: 0.987
[30,     4] loss: 0.968
[31,     4] loss: 0.978
[32,     4] loss: 0.965
[33,     4] loss: 0.957
[34,     4] loss: 0.863
[35,     4] loss: 0.843
[36,     4] loss: 0.850
[37,     4] loss: 0.819
[38,     4] loss: 0.804
[39,     4] loss: 0.864
[40,     4] loss: 1.033
[41,     4] loss: 0.967
[42,     4] loss: 0.943
[43,     4] loss: 0.877
[44,     4] loss: 0.942
[45,     4] loss: 1.042
[46,     4] loss: 1.041
[47,     4] loss: 0.905
[48,     4] loss: 0.810
[49,     4] loss: 0.755
[50,     4] loss: 0.853
[51,     4] loss: 0.902
[52,     4] loss: 0.860
[53,     4] loss: 0.823
[54,     4] loss: 0.880
[55,     4] loss: 0.896
[56,     4] loss: 0.845
[57,     4] loss: 0.855
[58,     4] loss: 0.882
[59,     4] loss: 0.901
[60,     4] loss: 0.945
[61,     4] loss: 0.855
[62,     4] loss: 0.790
[63,     4] loss: 0.764
[64,     4] loss: 0.782
[65,     4] loss: 0.880
[66,     4] loss: 0.981
[67,     4] loss: 0.940
[68,     4] loss: 0.885
[69,     4] loss: 0.828
[70,     4] loss: 0.803
[71,     4] loss: 0.789
[72,     4] loss: 0.793
[73,     4] loss: 0.799
[74,     4] loss: 0.826
[75,     4] loss: 0.907
[76,     4] loss: 0.866
[77,     4] loss: 0.830
[78,     4] loss: 0.789
[79,     4] loss: 0.768
[80,     4] loss: 0.793
[81,     4] loss: 0.800
[82,     4] loss: 0.767
[83,     4] loss: 0.868
[84,     4] loss: 0.955
[85,     4] loss: 0.914
[86,     4] loss: 0.953
[87,     4] loss: 0.916
[88,     4] loss: 0.852
[89,     4] loss: 0.787
[90,     4] loss: 0.800
[91,     4] loss: 0.823
[92,     4] loss: 0.833
[93,     4] loss: 0.821
[94,     4] loss: 0.770
[95,     4] loss: 0.767
[96,     4] loss: 0.829
[97,     4] loss: 1.072
[98,     4] loss: 0.988
[99,     4] loss: 0.959
[100,     4] loss: 0.900
[101,     4] loss: 0.784
[102,     4] loss: 0.796
[103,     4] loss: 0.866
[104,     4] loss: 0.844
[105,     4] loss: 0.877
[106,     4] loss: 0.786
[107,     4] loss: 0.793
[108,     4] loss: 0.829
[109,     4] loss: 0.809
[110,     4] loss: 0.790
[111,     4] loss: 0.762
[112,     4] loss: 0.770
[113,     4] loss: 0.740
[114,     4] loss: 0.735
[115,     4] loss: 0.739
[116,     4] loss: 0.972
[117,     4] loss: 1.247
[118,     4] loss: 1.178
[119,     4] loss: 1.153
[120,     4] loss: 1.083
[121,     4] loss: 1.045
[122,     4] loss: 1.007
[123,     4] loss: 0.982
[124,     4] loss: 0.964
[125,     4] loss: 0.868
[126,     4] loss: 0.965
[127,     4] loss: 0.910
[128,     4] loss: 0.874
[129,     4] loss: 0.818
[130,     4] loss: 0.783
[131,     4] loss: 0.794
[132,     4] loss: 0.806
[133,     4] loss: 0.860
[134,     4] loss: 0.817
[135,     4] loss: 0.782
[136,     4] loss: 0.739
[137,     4] loss: 1.197
[138,     4] loss: 1.125
Early stopping applied (best metric=0.2523418366909027)
Finished Training
Total time taken: 73.39876413345337
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.400
[3,     4] loss: 1.375
[4,     4] loss: 1.358
[5,     4] loss: 1.364
[6,     4] loss: 1.274
[7,     4] loss: 1.287
[8,     4] loss: 1.242
[9,     4] loss: 1.200
[10,     4] loss: 1.224
[11,     4] loss: 1.289
[12,     4] loss: 1.195
[13,     4] loss: 1.158
[14,     4] loss: 1.134
[15,     4] loss: 1.097
[16,     4] loss: 1.036
[17,     4] loss: 0.926
[18,     4] loss: 1.012
[19,     4] loss: 1.024
[20,     4] loss: 0.977
[21,     4] loss: 0.950
[22,     4] loss: 0.994
[23,     4] loss: 0.997
[24,     4] loss: 0.927
[25,     4] loss: 0.850
[26,     4] loss: 0.850
[27,     4] loss: 0.791
[28,     4] loss: 0.794
[29,     4] loss: 0.857
[30,     4] loss: 0.972
[31,     4] loss: 1.010
[32,     4] loss: 0.907
[33,     4] loss: 0.831
[34,     4] loss: 0.940
[35,     4] loss: 0.905
[36,     4] loss: 0.978
[37,     4] loss: 0.896
[38,     4] loss: 0.817
[39,     4] loss: 0.838
[40,     4] loss: 0.787
[41,     4] loss: 0.773
[42,     4] loss: 0.797
[43,     4] loss: 0.952
[44,     4] loss: 1.011
[45,     4] loss: 0.980
[46,     4] loss: 1.034
[47,     4] loss: 0.938
[48,     4] loss: 1.002
[49,     4] loss: 0.920
[50,     4] loss: 0.870
[51,     4] loss: 0.832
[52,     4] loss: 0.768
[53,     4] loss: 0.745
[54,     4] loss: 0.783
[55,     4] loss: 0.772
[56,     4] loss: 0.799
[57,     4] loss: 1.059
[58,     4] loss: 1.012
[59,     4] loss: 0.960
[60,     4] loss: 0.891
[61,     4] loss: 0.978
[62,     4] loss: 0.918
[63,     4] loss: 0.817
[64,     4] loss: 0.798
[65,     4] loss: 0.763
Early stopping applied (best metric=0.41225045919418335)
Finished Training
Total time taken: 34.8727650642395
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.389
[3,     4] loss: 1.383
[4,     4] loss: 1.384
[5,     4] loss: 1.346
[6,     4] loss: 1.255
[7,     4] loss: 1.202
[8,     4] loss: 1.124
[9,     4] loss: 1.099
[10,     4] loss: 1.045
[11,     4] loss: 1.042
[12,     4] loss: 0.967
[13,     4] loss: 1.002
[14,     4] loss: 1.025
[15,     4] loss: 1.010
[16,     4] loss: 0.978
[17,     4] loss: 0.974
[18,     4] loss: 0.930
[19,     4] loss: 0.951
[20,     4] loss: 0.960
[21,     4] loss: 1.091
[22,     4] loss: 1.007
[23,     4] loss: 0.965
[24,     4] loss: 0.912
[25,     4] loss: 0.812
[26,     4] loss: 0.839
[27,     4] loss: 0.787
[28,     4] loss: 0.767
[29,     4] loss: 0.751
[30,     4] loss: 0.874
[31,     4] loss: 0.775
[32,     4] loss: 0.782
[33,     4] loss: 0.777
[34,     4] loss: 0.833
[35,     4] loss: 1.199
[36,     4] loss: 1.019
[37,     4] loss: 0.967
[38,     4] loss: 0.912
[39,     4] loss: 0.899
[40,     4] loss: 0.884
[41,     4] loss: 0.816
[42,     4] loss: 0.832
[43,     4] loss: 0.857
[44,     4] loss: 0.820
[45,     4] loss: 0.776
[46,     4] loss: 0.833
[47,     4] loss: 1.024
[48,     4] loss: 1.032
[49,     4] loss: 0.953
[50,     4] loss: 0.908
[51,     4] loss: 0.969
[52,     4] loss: 1.053
[53,     4] loss: 1.113
[54,     4] loss: 1.083
[55,     4] loss: 1.000
[56,     4] loss: 0.920
[57,     4] loss: 0.809
[58,     4] loss: 0.778
[59,     4] loss: 0.763
[60,     4] loss: 0.744
[61,     4] loss: 0.778
[62,     4] loss: 0.866
[63,     4] loss: 0.991
[64,     4] loss: 0.984
[65,     4] loss: 0.939
[66,     4] loss: 0.929
[67,     4] loss: 0.898
[68,     4] loss: 0.822
[69,     4] loss: 0.794
[70,     4] loss: 0.755
[71,     4] loss: 0.892
[72,     4] loss: 0.865
[73,     4] loss: 0.849
[74,     4] loss: 0.814
[75,     4] loss: 0.786
[76,     4] loss: 0.948
[77,     4] loss: 0.991
[78,     4] loss: 0.951
[79,     4] loss: 0.820
[80,     4] loss: 0.765
[81,     4] loss: 0.745
[82,     4] loss: 0.868
[83,     4] loss: 0.898
[84,     4] loss: 0.890
[85,     4] loss: 0.848
[86,     4] loss: 0.806
[87,     4] loss: 0.760
[88,     4] loss: 0.736
[89,     4] loss: 1.216
[90,     4] loss: 1.231
[91,     4] loss: 1.186
[92,     4] loss: 1.125
[93,     4] loss: 1.044
[94,     4] loss: 0.941
[95,     4] loss: 0.934
[96,     4] loss: 1.018
[97,     4] loss: 0.909
[98,     4] loss: 0.871
[99,     4] loss: 0.793
[100,     4] loss: 0.772
[101,     4] loss: 0.745
[102,     4] loss: 0.742
[103,     4] loss: 0.749
[104,     4] loss: 0.798
[105,     4] loss: 0.810
[106,     4] loss: 0.835
[107,     4] loss: 0.756
[108,     4] loss: 1.075
[109,     4] loss: 0.993
[110,     4] loss: 0.984
[111,     4] loss: 0.906
[112,     4] loss: 0.814
[113,     4] loss: 0.840
[114,     4] loss: 0.762
[115,     4] loss: 0.757
[116,     4] loss: 0.832
[117,     4] loss: 0.788
[118,     4] loss: 0.779
[119,     4] loss: 0.762
[120,     4] loss: 0.822
[121,     4] loss: 0.873
[122,     4] loss: 0.834
[123,     4] loss: 0.825
[124,     4] loss: 0.839
[125,     4] loss: 0.887
[126,     4] loss: 0.886
[127,     4] loss: 0.842
[128,     4] loss: 0.842
[129,     4] loss: 0.804
[130,     4] loss: 0.826
[131,     4] loss: 0.808
[132,     4] loss: 0.786
[133,     4] loss: 0.758
[134,     4] loss: 0.769
[135,     4] loss: 0.796
[136,     4] loss: 0.785
[137,     4] loss: 0.780
[138,     4] loss: 0.784
[139,     4] loss: 0.926
[140,     4] loss: 0.903
[141,     4] loss: 0.845
[142,     4] loss: 0.817
Early stopping applied (best metric=0.4122544229030609)
Finished Training
Total time taken: 75.63645505905151
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.389
[3,     4] loss: 1.386
[4,     4] loss: 1.382
[5,     4] loss: 1.384
[6,     4] loss: 1.378
[7,     4] loss: 1.359
[8,     4] loss: 1.308
[9,     4] loss: 1.249
[10,     4] loss: 1.125
[11,     4] loss: 1.023
[12,     4] loss: 0.997
[13,     4] loss: 0.988
[14,     4] loss: 1.003
[15,     4] loss: 0.941
[16,     4] loss: 0.905
[17,     4] loss: 0.974
[18,     4] loss: 1.065
[19,     4] loss: 1.010
[20,     4] loss: 0.929
[21,     4] loss: 0.912
[22,     4] loss: 0.889
[23,     4] loss: 0.891
[24,     4] loss: 0.827
[25,     4] loss: 0.840
[26,     4] loss: 0.788
[27,     4] loss: 0.795
[28,     4] loss: 0.851
[29,     4] loss: 0.892
[30,     4] loss: 0.888
[31,     4] loss: 0.907
[32,     4] loss: 0.807
[33,     4] loss: 0.776
[34,     4] loss: 0.753
[35,     4] loss: 0.856
[36,     4] loss: 1.035
[37,     4] loss: 0.964
[38,     4] loss: 0.899
[39,     4] loss: 0.814
[40,     4] loss: 0.814
[41,     4] loss: 0.821
[42,     4] loss: 0.883
[43,     4] loss: 0.880
[44,     4] loss: 0.783
[45,     4] loss: 0.918
[46,     4] loss: 0.835
[47,     4] loss: 0.858
[48,     4] loss: 0.772
[49,     4] loss: 0.808
[50,     4] loss: 0.868
[51,     4] loss: 0.899
[52,     4] loss: 0.874
[53,     4] loss: 0.790
[54,     4] loss: 0.794
[55,     4] loss: 0.792
[56,     4] loss: 0.789
[57,     4] loss: 0.805
[58,     4] loss: 0.866
Early stopping applied (best metric=0.5083492994308472)
Finished Training
Total time taken: 30.63903498649597
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.385
[3,     4] loss: 1.394
[4,     4] loss: 1.384
[5,     4] loss: 1.386
[6,     4] loss: 1.385
[7,     4] loss: 1.383
[8,     4] loss: 1.382
[9,     4] loss: 1.384
[10,     4] loss: 1.371
[11,     4] loss: 1.328
[12,     4] loss: 1.246
[13,     4] loss: 1.174
[14,     4] loss: 1.147
[15,     4] loss: 1.095
[16,     4] loss: 1.210
[17,     4] loss: 1.079
[18,     4] loss: 1.057
[19,     4] loss: 1.018
[20,     4] loss: 1.018
[21,     4] loss: 0.956
[22,     4] loss: 0.985
[23,     4] loss: 0.911
[24,     4] loss: 0.834
[25,     4] loss: 0.904
[26,     4] loss: 0.979
[27,     4] loss: 1.004
[28,     4] loss: 0.965
[29,     4] loss: 0.866
[30,     4] loss: 0.836
[31,     4] loss: 0.801
[32,     4] loss: 0.897
[33,     4] loss: 1.032
[34,     4] loss: 0.987
[35,     4] loss: 0.962
[36,     4] loss: 0.946
[37,     4] loss: 0.954
[38,     4] loss: 0.842
[39,     4] loss: 0.952
[40,     4] loss: 0.911
[41,     4] loss: 0.812
[42,     4] loss: 0.874
[43,     4] loss: 0.859
[44,     4] loss: 0.820
[45,     4] loss: 0.773
[46,     4] loss: 0.808
[47,     4] loss: 0.985
[48,     4] loss: 1.021
[49,     4] loss: 0.971
[50,     4] loss: 0.842
[51,     4] loss: 0.798
[52,     4] loss: 0.840
[53,     4] loss: 0.876
[54,     4] loss: 1.058
[55,     4] loss: 1.007
[56,     4] loss: 0.987
[57,     4] loss: 0.874
[58,     4] loss: 0.810
[59,     4] loss: 0.854
[60,     4] loss: 0.878
[61,     4] loss: 0.892
[62,     4] loss: 0.796
Early stopping applied (best metric=0.3939085006713867)
Finished Training
Total time taken: 33.94616341590881
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.396
[2,     4] loss: 1.393
[3,     4] loss: 1.381
[4,     4] loss: 1.387
[5,     4] loss: 1.383
[6,     4] loss: 1.384
[7,     4] loss: 1.371
[8,     4] loss: 1.330
[9,     4] loss: 1.286
[10,     4] loss: 1.241
[11,     4] loss: 1.102
[12,     4] loss: 1.196
[13,     4] loss: 1.156
[14,     4] loss: 1.100
[15,     4] loss: 1.010
[16,     4] loss: 1.009
[17,     4] loss: 1.012
[18,     4] loss: 1.046
[19,     4] loss: 0.972
[20,     4] loss: 0.909
[21,     4] loss: 1.201
[22,     4] loss: 0.996
[23,     4] loss: 0.996
[24,     4] loss: 0.926
[25,     4] loss: 0.860
[26,     4] loss: 0.862
[27,     4] loss: 0.870
[28,     4] loss: 0.842
[29,     4] loss: 0.836
[30,     4] loss: 0.824
[31,     4] loss: 0.872
[32,     4] loss: 0.808
[33,     4] loss: 0.914
[34,     4] loss: 0.899
[35,     4] loss: 0.868
[36,     4] loss: 0.807
[37,     4] loss: 0.801
[38,     4] loss: 1.040
[39,     4] loss: 1.043
[40,     4] loss: 1.044
[41,     4] loss: 1.002
[42,     4] loss: 0.971
[43,     4] loss: 0.915
[44,     4] loss: 0.914
[45,     4] loss: 0.882
[46,     4] loss: 0.798
[47,     4] loss: 0.777
[48,     4] loss: 1.223
[49,     4] loss: 1.122
[50,     4] loss: 1.168
[51,     4] loss: 1.213
[52,     4] loss: 1.206
[53,     4] loss: 1.117
[54,     4] loss: 1.006
[55,     4] loss: 1.048
[56,     4] loss: 1.066
[57,     4] loss: 0.947
[58,     4] loss: 0.865
[59,     4] loss: 0.866
[60,     4] loss: 0.949
[61,     4] loss: 1.012
[62,     4] loss: 0.967
[63,     4] loss: 0.857
[64,     4] loss: 0.837
[65,     4] loss: 0.809
[66,     4] loss: 0.782
[67,     4] loss: 0.876
[68,     4] loss: 1.041
[69,     4] loss: 1.072
[70,     4] loss: 1.005
[71,     4] loss: 0.960
[72,     4] loss: 0.868
[73,     4] loss: 0.922
[74,     4] loss: 0.953
[75,     4] loss: 1.000
[76,     4] loss: 0.956
[77,     4] loss: 0.846
[78,     4] loss: 0.830
[79,     4] loss: 0.824
[80,     4] loss: 0.849
[81,     4] loss: 0.877
[82,     4] loss: 0.845
[83,     4] loss: 0.815
[84,     4] loss: 0.790
[85,     4] loss: 0.797
[86,     4] loss: 0.785
[87,     4] loss: 0.964
[88,     4] loss: 0.881
[89,     4] loss: 0.840
[90,     4] loss: 0.824
[91,     4] loss: 0.851
[92,     4] loss: 0.891
[93,     4] loss: 0.961
[94,     4] loss: 0.905
[95,     4] loss: 0.877
[96,     4] loss: 0.821
[97,     4] loss: 0.777
[98,     4] loss: 0.810
[99,     4] loss: 0.803
[100,     4] loss: 0.777
[101,     4] loss: 0.830
[102,     4] loss: 0.898
[103,     4] loss: 0.892
[104,     4] loss: 0.964
[105,     4] loss: 0.868
[106,     4] loss: 0.846
[107,     4] loss: 0.802
[108,     4] loss: 0.862
[109,     4] loss: 0.895
[110,     4] loss: 0.814
[111,     4] loss: 0.852
[112,     4] loss: 0.769
[113,     4] loss: 0.783
[114,     4] loss: 0.829
[115,     4] loss: 0.866
[116,     4] loss: 0.845
[117,     4] loss: 0.884
[118,     4] loss: 0.816
[119,     4] loss: 0.847
[120,     4] loss: 0.832
[121,     4] loss: 0.815
[122,     4] loss: 0.788
[123,     4] loss: 0.747
[124,     4] loss: 0.925
[125,     4] loss: 0.985
Early stopping applied (best metric=0.3432261645793915)
Finished Training
Total time taken: 66.3277587890625
{'Hydroxylation-K Validation Accuracy': 0.7564716312056737, 'Hydroxylation-K Validation Sensitivity': 0.7474074074074074, 'Hydroxylation-K Validation Specificity': 0.7596491228070176, 'Hydroxylation-K Validation Precision': 0.43984547530213164, 'Hydroxylation-K AUC ROC': 0.8449707602339182, 'Hydroxylation-K AUC PR': 0.6345121285297723, 'Hydroxylation-K MCC': 0.4288092317816036, 'Hydroxylation-K F1': 0.5505914804835345, 'Validation Loss (Hydroxylation-K)': 0.3941405415534973, 'Methylation-K Validation Accuracy': 0.7722836372698755, 'Methylation-K Validation Sensitivity': 0.18745436287427103, 'Methylation-K Validation Specificity': 0.8357088181578042, 'Methylation-K Validation Precision': 0.11140568684359618, 'Methylation-K AUC ROC': 0.5267572859157904, 'Methylation-K AUC PR': 0.10771448449660856, 'Methylation-K MCC': 0.018862330097645166, 'Methylation-K F1': 0.13097398168746213, 'Validation Loss (Methylation-K)': 0.9210353652636211, 'Validation Loss (total)': 1.3151759028434753, 'TimeToTrain': 50.08461891810099}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00200666942164169,
 'learning_rate_Hydroxylation-K': 0.003303873451288002,
 'learning_rate_Methylation-K': 0.009619223751588975,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21715509543850964,
 'loss_weight_Methylation-K': 0.9526479894918399,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2977115995,
 'sample_weights': [0.5458253547513418, 0.7554522614944563],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.934593556061085,
 'weight_decay_Hydroxylation-K': 7.481070317950386,
 'weight_decay_Methylation-K': 9.491239924891858}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.388
[3,     4] loss: 1.390
[4,     4] loss: 1.385
[5,     4] loss: 1.384
[6,     4] loss: 1.387
[7,     4] loss: 1.388
[8,     4] loss: 1.385
[9,     4] loss: 1.385
[10,     4] loss: 1.384
[11,     4] loss: 1.386
[12,     4] loss: 1.387
[13,     4] loss: 1.382
[14,     4] loss: 1.378
[15,     4] loss: 1.379
[16,     4] loss: 1.366
[17,     4] loss: 1.348
[18,     4] loss: 1.315
[19,     4] loss: 1.236
[20,     4] loss: 1.180
[21,     4] loss: 1.153
[22,     4] loss: 1.128
[23,     4] loss: 1.110
[24,     4] loss: 1.039
[25,     4] loss: 1.033
[26,     4] loss: 1.038
[27,     4] loss: 0.968
[28,     4] loss: 0.967
[29,     4] loss: 0.969
[30,     4] loss: 0.956
[31,     4] loss: 0.919
[32,     4] loss: 0.940
[33,     4] loss: 0.900
[34,     4] loss: 0.897
[35,     4] loss: 0.889
[36,     4] loss: 0.878
[37,     4] loss: 0.865
[38,     4] loss: 0.867
[39,     4] loss: 0.806
[40,     4] loss: 0.851
[41,     4] loss: 0.889
[42,     4] loss: 0.923
[43,     4] loss: 0.871
[44,     4] loss: 0.882
[45,     4] loss: 0.859
[46,     4] loss: 0.868
[47,     4] loss: 0.797
[48,     4] loss: 0.791
[49,     4] loss: 0.789
[50,     4] loss: 0.800
[51,     4] loss: 0.744
[52,     4] loss: 0.742
[53,     4] loss: 0.761
[54,     4] loss: 0.762
[55,     4] loss: 0.754
[56,     4] loss: 0.755
[57,     4] loss: 0.747
[58,     4] loss: 0.730
[59,     4] loss: 0.733
[60,     4] loss: 0.749
[61,     4] loss: 0.734
[62,     4] loss: 0.747
[63,     4] loss: 0.735
[64,     4] loss: 0.737
[65,     4] loss: 0.725
[66,     4] loss: 0.740
[67,     4] loss: 0.729
[68,     4] loss: 0.738
[69,     4] loss: 0.807
[70,     4] loss: 0.811
[71,     4] loss: 0.771
[72,     4] loss: 0.805
[73,     4] loss: 0.807
[74,     4] loss: 0.787
[75,     4] loss: 0.769
[76,     4] loss: 0.758
[77,     4] loss: 0.753
[78,     4] loss: 0.753
[79,     4] loss: 0.746
[80,     4] loss: 0.743
[81,     4] loss: 0.720
[82,     4] loss: 0.748
[83,     4] loss: 0.738
[84,     4] loss: 0.722
[85,     4] loss: 0.755
[86,     4] loss: 0.742
[87,     4] loss: 0.759
[88,     4] loss: 0.731
[89,     4] loss: 0.724
[90,     4] loss: 0.724
[91,     4] loss: 0.759
[92,     4] loss: 0.758
[93,     4] loss: 0.735
[94,     4] loss: 0.728
[95,     4] loss: 0.737
[96,     4] loss: 0.723
[97,     4] loss: 0.721
[98,     4] loss: 0.741
[99,     4] loss: 0.777
[100,     4] loss: 0.733
[101,     4] loss: 0.720
[102,     4] loss: 0.761
[103,     4] loss: 0.779
[104,     4] loss: 0.749
[105,     4] loss: 0.738
[106,     4] loss: 0.735
[107,     4] loss: 0.733
[108,     4] loss: 0.771
[109,     4] loss: 0.792
[110,     4] loss: 0.748
[111,     4] loss: 0.756
[112,     4] loss: 0.817
[113,     4] loss: 0.805
[114,     4] loss: 0.803
[115,     4] loss: 0.836
[116,     4] loss: 0.809
[117,     4] loss: 0.765
[118,     4] loss: 0.748
[119,     4] loss: 0.769
[120,     4] loss: 0.777
[121,     4] loss: 0.745
[122,     4] loss: 0.735
[123,     4] loss: 0.739
[124,     4] loss: 0.749
Early stopping applied (best metric=0.24947267770767212)
Finished Training
Total time taken: 68.75826644897461
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.383
[3,     4] loss: 1.392
[4,     4] loss: 1.388
[5,     4] loss: 1.385
[6,     4] loss: 1.387
[7,     4] loss: 1.388
[8,     4] loss: 1.386
[9,     4] loss: 1.386
[10,     4] loss: 1.385
[11,     4] loss: 1.383
[12,     4] loss: 1.382
[13,     4] loss: 1.380
[14,     4] loss: 1.371
[15,     4] loss: 1.361
[16,     4] loss: 1.340
[17,     4] loss: 1.303
[18,     4] loss: 1.208
[19,     4] loss: 1.158
[20,     4] loss: 1.122
[21,     4] loss: 1.066
[22,     4] loss: 1.039
[23,     4] loss: 1.051
[24,     4] loss: 1.032
[25,     4] loss: 1.019
[26,     4] loss: 0.982
[27,     4] loss: 0.999
[28,     4] loss: 0.963
[29,     4] loss: 0.926
[30,     4] loss: 0.866
[31,     4] loss: 0.945
[32,     4] loss: 0.875
[33,     4] loss: 0.867
[34,     4] loss: 0.855
[35,     4] loss: 0.858
[36,     4] loss: 0.844
[37,     4] loss: 0.893
[38,     4] loss: 0.857
[39,     4] loss: 0.858
[40,     4] loss: 0.841
[41,     4] loss: 0.843
[42,     4] loss: 0.795
[43,     4] loss: 0.848
[44,     4] loss: 0.792
[45,     4] loss: 0.770
[46,     4] loss: 0.790
[47,     4] loss: 0.793
[48,     4] loss: 0.816
[49,     4] loss: 0.789
[50,     4] loss: 0.813
[51,     4] loss: 0.778
[52,     4] loss: 0.798
[53,     4] loss: 0.789
[54,     4] loss: 0.830
[55,     4] loss: 0.863
[56,     4] loss: 0.818
[57,     4] loss: 0.804
[58,     4] loss: 0.812
[59,     4] loss: 0.814
[60,     4] loss: 0.757
[61,     4] loss: 0.745
[62,     4] loss: 0.726
[63,     4] loss: 0.742
[64,     4] loss: 0.723
[65,     4] loss: 0.728
[66,     4] loss: 0.723
[67,     4] loss: 0.736
[68,     4] loss: 0.725
[69,     4] loss: 0.718
[70,     4] loss: 0.717
Early stopping applied (best metric=0.3803905248641968)
Finished Training
Total time taken: 36.636990547180176
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.383
[5,     4] loss: 1.385
[6,     4] loss: 1.385
[7,     4] loss: 1.381
[8,     4] loss: 1.382
[9,     4] loss: 1.379
[10,     4] loss: 1.372
[11,     4] loss: 1.368
[12,     4] loss: 1.347
[13,     4] loss: 1.323
[14,     4] loss: 1.285
[15,     4] loss: 1.246
[16,     4] loss: 1.258
[17,     4] loss: 1.210
[18,     4] loss: 1.210
[19,     4] loss: 1.095
[20,     4] loss: 1.168
[21,     4] loss: 1.075
[22,     4] loss: 1.061
[23,     4] loss: 1.014
[24,     4] loss: 1.005
[25,     4] loss: 0.942
[26,     4] loss: 0.876
[27,     4] loss: 0.884
[28,     4] loss: 0.862
[29,     4] loss: 0.903
[30,     4] loss: 0.904
[31,     4] loss: 0.859
[32,     4] loss: 0.925
[33,     4] loss: 0.874
[34,     4] loss: 0.861
[35,     4] loss: 0.843
[36,     4] loss: 0.802
[37,     4] loss: 0.843
[38,     4] loss: 0.795
[39,     4] loss: 0.768
[40,     4] loss: 0.814
[41,     4] loss: 0.871
[42,     4] loss: 0.865
[43,     4] loss: 0.837
[44,     4] loss: 0.835
[45,     4] loss: 0.793
[46,     4] loss: 0.810
[47,     4] loss: 0.781
[48,     4] loss: 0.797
[49,     4] loss: 0.756
[50,     4] loss: 0.768
[51,     4] loss: 0.779
[52,     4] loss: 0.767
[53,     4] loss: 0.774
[54,     4] loss: 0.754
[55,     4] loss: 0.743
[56,     4] loss: 0.740
[57,     4] loss: 0.752
[58,     4] loss: 0.796
[59,     4] loss: 0.790
[60,     4] loss: 0.780
[61,     4] loss: 0.806
[62,     4] loss: 0.780
[63,     4] loss: 0.766
[64,     4] loss: 0.748
[65,     4] loss: 0.781
[66,     4] loss: 0.755
[67,     4] loss: 0.746
[68,     4] loss: 0.784
[69,     4] loss: 0.809
[70,     4] loss: 0.784
Early stopping applied (best metric=0.2790986895561218)
Finished Training
Total time taken: 39.80707669258118
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.380
[3,     4] loss: 1.366
[4,     4] loss: 1.347
[5,     4] loss: 1.331
[6,     4] loss: 1.279
[7,     4] loss: 1.253
[8,     4] loss: 1.205
[9,     4] loss: 1.151
[10,     4] loss: 1.140
[11,     4] loss: 1.146
[12,     4] loss: 1.068
[13,     4] loss: 1.041
[14,     4] loss: 0.975
[15,     4] loss: 1.040
[16,     4] loss: 0.966
[17,     4] loss: 0.951
[18,     4] loss: 1.014
[19,     4] loss: 0.916
[20,     4] loss: 0.883
[21,     4] loss: 0.950
[22,     4] loss: 0.873
[23,     4] loss: 0.892
[24,     4] loss: 0.812
[25,     4] loss: 0.841
[26,     4] loss: 0.811
[27,     4] loss: 0.816
[28,     4] loss: 0.796
[29,     4] loss: 0.804
[30,     4] loss: 0.825
[31,     4] loss: 0.763
[32,     4] loss: 0.770
[33,     4] loss: 0.781
[34,     4] loss: 0.786
[35,     4] loss: 0.774
[36,     4] loss: 0.779
[37,     4] loss: 0.790
[38,     4] loss: 0.799
[39,     4] loss: 0.778
[40,     4] loss: 0.763
[41,     4] loss: 0.755
[42,     4] loss: 0.757
[43,     4] loss: 0.758
[44,     4] loss: 0.751
[45,     4] loss: 0.749
[46,     4] loss: 0.747
[47,     4] loss: 0.741
[48,     4] loss: 0.768
[49,     4] loss: 0.759
[50,     4] loss: 0.756
[51,     4] loss: 0.779
[52,     4] loss: 0.750
[53,     4] loss: 0.769
[54,     4] loss: 0.780
[55,     4] loss: 0.774
Early stopping applied (best metric=0.5108347535133362)
Finished Training
Total time taken: 29.559747219085693
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.386
[2,     4] loss: 1.390
[3,     4] loss: 1.382
[4,     4] loss: 1.383
[5,     4] loss: 1.381
[6,     4] loss: 1.380
[7,     4] loss: 1.369
[8,     4] loss: 1.359
[9,     4] loss: 1.333
[10,     4] loss: 1.289
[11,     4] loss: 1.288
[12,     4] loss: 1.245
[13,     4] loss: 1.189
[14,     4] loss: 1.153
[15,     4] loss: 1.057
[16,     4] loss: 1.068
[17,     4] loss: 1.012
[18,     4] loss: 0.977
[19,     4] loss: 1.017
[20,     4] loss: 0.936
[21,     4] loss: 0.952
[22,     4] loss: 0.951
[23,     4] loss: 0.991
[24,     4] loss: 0.941
[25,     4] loss: 0.906
[26,     4] loss: 0.880
[27,     4] loss: 0.841
[28,     4] loss: 0.851
[29,     4] loss: 0.819
[30,     4] loss: 0.793
[31,     4] loss: 0.830
[32,     4] loss: 0.780
[33,     4] loss: 0.787
[34,     4] loss: 0.810
[35,     4] loss: 0.791
[36,     4] loss: 0.771
[37,     4] loss: 0.768
[38,     4] loss: 0.759
[39,     4] loss: 0.760
[40,     4] loss: 0.790
[41,     4] loss: 0.801
[42,     4] loss: 0.810
[43,     4] loss: 0.819
[44,     4] loss: 0.800
[45,     4] loss: 0.798
[46,     4] loss: 0.800
[47,     4] loss: 0.778
[48,     4] loss: 0.802
[49,     4] loss: 0.793
[50,     4] loss: 0.831
[51,     4] loss: 0.741
[52,     4] loss: 0.760
[53,     4] loss: 0.753
[54,     4] loss: 0.737
[55,     4] loss: 0.766
[56,     4] loss: 0.751
[57,     4] loss: 0.759
[58,     4] loss: 0.748
[59,     4] loss: 0.766
[60,     4] loss: 0.730
[61,     4] loss: 0.765
[62,     4] loss: 0.748
[63,     4] loss: 0.757
[64,     4] loss: 0.775
[65,     4] loss: 0.751
Early stopping applied (best metric=0.4270758032798767)
Finished Training
Total time taken: 35.87891459465027
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.390
[3,     4] loss: 1.383
[4,     4] loss: 1.384
[5,     4] loss: 1.382
[6,     4] loss: 1.389
[7,     4] loss: 1.388
[8,     4] loss: 1.381
[9,     4] loss: 1.382
[10,     4] loss: 1.371
[11,     4] loss: 1.356
[12,     4] loss: 1.333
[13,     4] loss: 1.310
[14,     4] loss: 1.256
[15,     4] loss: 1.201
[16,     4] loss: 1.234
[17,     4] loss: 1.188
[18,     4] loss: 1.118
[19,     4] loss: 1.058
[20,     4] loss: 1.026
[21,     4] loss: 1.025
[22,     4] loss: 0.973
[23,     4] loss: 0.953
[24,     4] loss: 0.933
[25,     4] loss: 0.931
[26,     4] loss: 0.913
[27,     4] loss: 0.842
[28,     4] loss: 0.907
[29,     4] loss: 0.818
[30,     4] loss: 0.871
[31,     4] loss: 0.881
[32,     4] loss: 0.856
[33,     4] loss: 0.864
[34,     4] loss: 0.877
[35,     4] loss: 0.849
[36,     4] loss: 0.827
[37,     4] loss: 0.832
[38,     4] loss: 0.897
[39,     4] loss: 0.817
[40,     4] loss: 0.830
[41,     4] loss: 0.871
[42,     4] loss: 0.822
[43,     4] loss: 0.855
[44,     4] loss: 0.780
[45,     4] loss: 0.858
[46,     4] loss: 0.831
[47,     4] loss: 0.837
[48,     4] loss: 0.830
[49,     4] loss: 0.936
[50,     4] loss: 0.842
[51,     4] loss: 0.858
[52,     4] loss: 0.832
[53,     4] loss: 0.816
[54,     4] loss: 0.828
[55,     4] loss: 0.818
[56,     4] loss: 0.825
[57,     4] loss: 0.824
[58,     4] loss: 0.836
[59,     4] loss: 0.785
[60,     4] loss: 0.821
[61,     4] loss: 0.814
Early stopping applied (best metric=0.528542160987854)
Finished Training
Total time taken: 33.631269693374634
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.387
[3,     4] loss: 1.383
[4,     4] loss: 1.393
[5,     4] loss: 1.379
[6,     4] loss: 1.383
[7,     4] loss: 1.381
[8,     4] loss: 1.374
[9,     4] loss: 1.364
[10,     4] loss: 1.347
[11,     4] loss: 1.311
[12,     4] loss: 1.269
[13,     4] loss: 1.198
[14,     4] loss: 1.155
[15,     4] loss: 1.174
[16,     4] loss: 1.063
[17,     4] loss: 1.073
[18,     4] loss: 1.061
[19,     4] loss: 0.982
[20,     4] loss: 0.970
[21,     4] loss: 0.942
[22,     4] loss: 0.954
[23,     4] loss: 0.952
[24,     4] loss: 0.916
[25,     4] loss: 0.904
[26,     4] loss: 0.867
[27,     4] loss: 0.872
[28,     4] loss: 0.871
[29,     4] loss: 0.859
[30,     4] loss: 0.852
[31,     4] loss: 0.807
[32,     4] loss: 0.874
[33,     4] loss: 0.846
[34,     4] loss: 0.820
[35,     4] loss: 0.787
[36,     4] loss: 0.801
[37,     4] loss: 0.774
[38,     4] loss: 0.790
[39,     4] loss: 0.816
[40,     4] loss: 0.859
[41,     4] loss: 0.853
[42,     4] loss: 0.798
[43,     4] loss: 0.784
[44,     4] loss: 0.781
[45,     4] loss: 0.786
[46,     4] loss: 0.773
[47,     4] loss: 0.792
[48,     4] loss: 0.750
[49,     4] loss: 0.742
[50,     4] loss: 0.750
[51,     4] loss: 0.757
[52,     4] loss: 0.766
[53,     4] loss: 0.781
[54,     4] loss: 0.839
[55,     4] loss: 0.813
[56,     4] loss: 0.816
[57,     4] loss: 0.899
[58,     4] loss: 0.853
[59,     4] loss: 0.821
[60,     4] loss: 0.808
[61,     4] loss: 0.784
[62,     4] loss: 0.812
Early stopping applied (best metric=0.4863126277923584)
Finished Training
Total time taken: 32.27593421936035
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.384
[5,     4] loss: 1.385
[6,     4] loss: 1.380
[7,     4] loss: 1.385
[8,     4] loss: 1.379
[9,     4] loss: 1.374
[10,     4] loss: 1.368
[11,     4] loss: 1.342
[12,     4] loss: 1.305
[13,     4] loss: 1.252
[14,     4] loss: 1.213
[15,     4] loss: 1.178
[16,     4] loss: 1.091
[17,     4] loss: 1.007
[18,     4] loss: 1.073
[19,     4] loss: 1.060
[20,     4] loss: 1.053
[21,     4] loss: 1.017
[22,     4] loss: 0.975
[23,     4] loss: 1.012
[24,     4] loss: 0.947
[25,     4] loss: 0.961
[26,     4] loss: 0.934
[27,     4] loss: 0.927
[28,     4] loss: 0.958
[29,     4] loss: 0.935
[30,     4] loss: 0.934
[31,     4] loss: 0.933
[32,     4] loss: 0.838
[33,     4] loss: 0.832
[34,     4] loss: 0.819
[35,     4] loss: 0.795
[36,     4] loss: 0.800
[37,     4] loss: 0.799
[38,     4] loss: 0.878
[39,     4] loss: 0.766
[40,     4] loss: 0.810
[41,     4] loss: 0.861
[42,     4] loss: 0.873
[43,     4] loss: 0.834
[44,     4] loss: 0.836
[45,     4] loss: 0.834
[46,     4] loss: 0.764
[47,     4] loss: 0.800
[48,     4] loss: 0.821
[49,     4] loss: 0.801
[50,     4] loss: 0.874
[51,     4] loss: 0.965
[52,     4] loss: 0.899
[53,     4] loss: 0.862
[54,     4] loss: 0.867
[55,     4] loss: 0.840
[56,     4] loss: 0.807
[57,     4] loss: 0.834
[58,     4] loss: 0.837
[59,     4] loss: 0.796
[60,     4] loss: 0.779
[61,     4] loss: 0.801
[62,     4] loss: 0.801
[63,     4] loss: 0.811
[64,     4] loss: 0.778
[65,     4] loss: 0.817
[66,     4] loss: 0.797
[67,     4] loss: 0.791
[68,     4] loss: 0.804
[69,     4] loss: 0.763
[70,     4] loss: 0.784
[71,     4] loss: 0.748
[72,     4] loss: 0.738
[73,     4] loss: 0.730
[74,     4] loss: 0.746
[75,     4] loss: 0.727
[76,     4] loss: 0.727
[77,     4] loss: 0.736
[78,     4] loss: 0.720
[79,     4] loss: 0.747
[80,     4] loss: 0.737
[81,     4] loss: 0.758
[82,     4] loss: 0.730
[83,     4] loss: 0.753
[84,     4] loss: 0.795
[85,     4] loss: 0.751
[86,     4] loss: 0.744
[87,     4] loss: 0.759
[88,     4] loss: 0.754
[89,     4] loss: 0.730
[90,     4] loss: 0.721
[91,     4] loss: 0.728
[92,     4] loss: 0.734
[93,     4] loss: 0.762
[94,     4] loss: 0.730
[95,     4] loss: 0.724
[96,     4] loss: 0.732
[97,     4] loss: 0.727
[98,     4] loss: 0.718
[99,     4] loss: 0.751
[100,     4] loss: 0.774
[101,     4] loss: 0.745
[102,     4] loss: 0.787
[103,     4] loss: 0.803
Early stopping applied (best metric=0.4565301835536957)
Finished Training
Total time taken: 56.75740170478821
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.383
[3,     4] loss: 1.391
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.379
[7,     4] loss: 1.381
[8,     4] loss: 1.373
[9,     4] loss: 1.365
[10,     4] loss: 1.348
[11,     4] loss: 1.337
[12,     4] loss: 1.290
[13,     4] loss: 1.238
[14,     4] loss: 1.167
[15,     4] loss: 1.186
[16,     4] loss: 1.153
[17,     4] loss: 1.159
[18,     4] loss: 1.125
[19,     4] loss: 1.068
[20,     4] loss: 1.015
[21,     4] loss: 1.011
[22,     4] loss: 0.977
[23,     4] loss: 0.969
[24,     4] loss: 0.915
[25,     4] loss: 0.913
[26,     4] loss: 0.883
[27,     4] loss: 0.858
[28,     4] loss: 0.838
[29,     4] loss: 0.898
[30,     4] loss: 0.877
[31,     4] loss: 0.866
[32,     4] loss: 0.894
[33,     4] loss: 0.844
[34,     4] loss: 0.858
[35,     4] loss: 0.834
[36,     4] loss: 0.889
[37,     4] loss: 0.829
[38,     4] loss: 0.826
[39,     4] loss: 0.780
[40,     4] loss: 0.765
[41,     4] loss: 0.840
[42,     4] loss: 0.812
[43,     4] loss: 0.792
[44,     4] loss: 0.802
[45,     4] loss: 0.822
[46,     4] loss: 0.845
[47,     4] loss: 0.801
[48,     4] loss: 0.853
[49,     4] loss: 0.803
[50,     4] loss: 0.806
[51,     4] loss: 0.756
[52,     4] loss: 0.759
[53,     4] loss: 0.748
[54,     4] loss: 0.732
[55,     4] loss: 0.732
[56,     4] loss: 0.734
[57,     4] loss: 0.724
[58,     4] loss: 0.730
[59,     4] loss: 0.730
[60,     4] loss: 0.745
Early stopping applied (best metric=0.5231988430023193)
Finished Training
Total time taken: 30.60162615776062
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.398
[2,     4] loss: 1.384
[3,     4] loss: 1.380
[4,     4] loss: 1.378
[5,     4] loss: 1.378
[6,     4] loss: 1.361
[7,     4] loss: 1.333
[8,     4] loss: 1.307
[9,     4] loss: 1.267
[10,     4] loss: 1.208
[11,     4] loss: 1.238
[12,     4] loss: 1.207
[13,     4] loss: 1.197
[14,     4] loss: 1.145
[15,     4] loss: 1.068
[16,     4] loss: 1.014
[17,     4] loss: 1.032
[18,     4] loss: 0.980
[19,     4] loss: 0.978
[20,     4] loss: 0.976
[21,     4] loss: 0.935
[22,     4] loss: 0.935
[23,     4] loss: 0.990
[24,     4] loss: 0.999
[25,     4] loss: 0.942
[26,     4] loss: 0.942
[27,     4] loss: 0.892
[28,     4] loss: 0.892
[29,     4] loss: 0.869
[30,     4] loss: 0.917
[31,     4] loss: 0.871
[32,     4] loss: 0.930
[33,     4] loss: 0.916
[34,     4] loss: 0.914
[35,     4] loss: 0.886
[36,     4] loss: 0.894
[37,     4] loss: 0.824
[38,     4] loss: 0.820
[39,     4] loss: 0.795
[40,     4] loss: 0.790
[41,     4] loss: 0.779
[42,     4] loss: 0.773
[43,     4] loss: 0.796
[44,     4] loss: 0.781
[45,     4] loss: 0.789
[46,     4] loss: 0.830
[47,     4] loss: 0.773
[48,     4] loss: 0.774
[49,     4] loss: 0.837
[50,     4] loss: 0.819
[51,     4] loss: 0.785
[52,     4] loss: 0.783
[53,     4] loss: 0.758
[54,     4] loss: 0.746
[55,     4] loss: 0.753
[56,     4] loss: 0.735
[57,     4] loss: 0.753
[58,     4] loss: 0.739
[59,     4] loss: 0.758
[60,     4] loss: 0.729
[61,     4] loss: 0.741
[62,     4] loss: 0.734
[63,     4] loss: 0.751
[64,     4] loss: 0.772
[65,     4] loss: 0.749
[66,     4] loss: 0.734
[67,     4] loss: 0.770
[68,     4] loss: 0.739
[69,     4] loss: 0.726
[70,     4] loss: 0.733
[71,     4] loss: 0.730
[72,     4] loss: 0.728
[73,     4] loss: 0.733
[74,     4] loss: 0.717
[75,     4] loss: 0.732
[76,     4] loss: 0.728
[77,     4] loss: 0.719
[78,     4] loss: 0.740
[79,     4] loss: 0.794
[80,     4] loss: 0.750
[81,     4] loss: 0.755
[82,     4] loss: 0.767
[83,     4] loss: 0.753
[84,     4] loss: 0.733
Early stopping applied (best metric=0.40319693088531494)
Finished Training
Total time taken: 42.83322215080261
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.387
[3,     4] loss: 1.381
[4,     4] loss: 1.385
[5,     4] loss: 1.374
[6,     4] loss: 1.367
[7,     4] loss: 1.354
[8,     4] loss: 1.326
[9,     4] loss: 1.297
[10,     4] loss: 1.280
[11,     4] loss: 1.235
[12,     4] loss: 1.204
[13,     4] loss: 1.167
[14,     4] loss: 1.105
[15,     4] loss: 1.052
[16,     4] loss: 1.034
[17,     4] loss: 0.976
[18,     4] loss: 0.941
[19,     4] loss: 0.954
[20,     4] loss: 1.030
[21,     4] loss: 1.060
[22,     4] loss: 1.024
[23,     4] loss: 0.968
[24,     4] loss: 1.082
[25,     4] loss: 1.049
[26,     4] loss: 0.936
[27,     4] loss: 0.944
[28,     4] loss: 0.924
[29,     4] loss: 0.923
[30,     4] loss: 0.923
[31,     4] loss: 0.858
[32,     4] loss: 0.823
[33,     4] loss: 0.934
[34,     4] loss: 0.918
[35,     4] loss: 0.865
[36,     4] loss: 0.878
[37,     4] loss: 0.864
[38,     4] loss: 0.831
[39,     4] loss: 0.829
[40,     4] loss: 0.874
[41,     4] loss: 0.812
[42,     4] loss: 0.829
[43,     4] loss: 0.812
[44,     4] loss: 0.852
[45,     4] loss: 0.822
[46,     4] loss: 0.832
[47,     4] loss: 0.848
[48,     4] loss: 0.858
[49,     4] loss: 0.852
[50,     4] loss: 0.805
[51,     4] loss: 0.822
[52,     4] loss: 0.773
[53,     4] loss: 0.800
[54,     4] loss: 0.779
[55,     4] loss: 0.771
[56,     4] loss: 0.751
[57,     4] loss: 0.759
[58,     4] loss: 0.795
[59,     4] loss: 0.828
[60,     4] loss: 0.778
[61,     4] loss: 0.814
[62,     4] loss: 0.792
[63,     4] loss: 0.821
[64,     4] loss: 0.791
[65,     4] loss: 0.801
[66,     4] loss: 0.803
[67,     4] loss: 0.788
[68,     4] loss: 0.750
[69,     4] loss: 0.779
[70,     4] loss: 0.756
[71,     4] loss: 0.744
[72,     4] loss: 0.745
[73,     4] loss: 0.728
Early stopping applied (best metric=0.3991639018058777)
Finished Training
Total time taken: 37.08504772186279
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.389
[5,     4] loss: 1.384
[6,     4] loss: 1.384
[7,     4] loss: 1.380
[8,     4] loss: 1.380
[9,     4] loss: 1.376
[10,     4] loss: 1.364
[11,     4] loss: 1.357
[12,     4] loss: 1.345
[13,     4] loss: 1.312
[14,     4] loss: 1.305
[15,     4] loss: 1.232
[16,     4] loss: 1.243
[17,     4] loss: 1.146
[18,     4] loss: 1.154
[19,     4] loss: 1.091
[20,     4] loss: 1.168
[21,     4] loss: 1.056
[22,     4] loss: 1.069
[23,     4] loss: 1.032
[24,     4] loss: 0.978
[25,     4] loss: 1.013
[26,     4] loss: 0.924
[27,     4] loss: 0.949
[28,     4] loss: 0.862
[29,     4] loss: 0.840
[30,     4] loss: 0.885
[31,     4] loss: 0.907
[32,     4] loss: 0.853
[33,     4] loss: 0.851
[34,     4] loss: 0.854
[35,     4] loss: 0.862
[36,     4] loss: 0.877
[37,     4] loss: 0.834
[38,     4] loss: 0.884
[39,     4] loss: 0.813
[40,     4] loss: 0.863
[41,     4] loss: 0.849
[42,     4] loss: 0.861
[43,     4] loss: 0.839
[44,     4] loss: 0.882
[45,     4] loss: 0.850
[46,     4] loss: 0.822
[47,     4] loss: 0.799
[48,     4] loss: 0.827
[49,     4] loss: 0.807
[50,     4] loss: 0.774
[51,     4] loss: 0.774
[52,     4] loss: 0.760
[53,     4] loss: 0.774
[54,     4] loss: 0.758
[55,     4] loss: 0.774
[56,     4] loss: 0.759
[57,     4] loss: 0.763
[58,     4] loss: 0.756
[59,     4] loss: 0.756
[60,     4] loss: 0.769
[61,     4] loss: 0.742
[62,     4] loss: 0.738
[63,     4] loss: 0.762
[64,     4] loss: 0.761
[65,     4] loss: 0.747
[66,     4] loss: 0.739
[67,     4] loss: 0.738
Early stopping applied (best metric=0.3615373373031616)
Finished Training
Total time taken: 34.02236819267273
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.388
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.383
[6,     4] loss: 1.389
[7,     4] loss: 1.382
[8,     4] loss: 1.383
[9,     4] loss: 1.381
[10,     4] loss: 1.375
[11,     4] loss: 1.366
[12,     4] loss: 1.345
[13,     4] loss: 1.310
[14,     4] loss: 1.274
[15,     4] loss: 1.204
[16,     4] loss: 1.187
[17,     4] loss: 1.130
[18,     4] loss: 1.150
[19,     4] loss: 1.055
[20,     4] loss: 0.994
[21,     4] loss: 1.024
[22,     4] loss: 0.957
[23,     4] loss: 0.925
[24,     4] loss: 0.903
[25,     4] loss: 0.899
[26,     4] loss: 0.957
[27,     4] loss: 0.933
[28,     4] loss: 0.863
[29,     4] loss: 0.901
[30,     4] loss: 0.883
[31,     4] loss: 0.836
[32,     4] loss: 0.931
[33,     4] loss: 0.914
[34,     4] loss: 0.870
[35,     4] loss: 0.878
[36,     4] loss: 0.891
[37,     4] loss: 0.872
[38,     4] loss: 0.856
[39,     4] loss: 0.842
[40,     4] loss: 0.838
[41,     4] loss: 0.828
[42,     4] loss: 0.835
[43,     4] loss: 0.864
[44,     4] loss: 0.815
[45,     4] loss: 0.797
[46,     4] loss: 0.887
[47,     4] loss: 0.858
[48,     4] loss: 0.846
[49,     4] loss: 0.827
[50,     4] loss: 0.825
[51,     4] loss: 0.805
[52,     4] loss: 0.804
[53,     4] loss: 0.809
[54,     4] loss: 0.843
[55,     4] loss: 0.801
[56,     4] loss: 0.802
[57,     4] loss: 0.790
[58,     4] loss: 0.778
[59,     4] loss: 0.804
[60,     4] loss: 0.793
[61,     4] loss: 0.802
[62,     4] loss: 0.772
[63,     4] loss: 0.769
[64,     4] loss: 0.845
[65,     4] loss: 0.757
[66,     4] loss: 0.812
[67,     4] loss: 0.795
[68,     4] loss: 0.804
Early stopping applied (best metric=0.44056475162506104)
Finished Training
Total time taken: 34.54233527183533
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.388
[3,     4] loss: 1.387
[4,     4] loss: 1.383
[5,     4] loss: 1.387
[6,     4] loss: 1.388
[7,     4] loss: 1.384
[8,     4] loss: 1.385
[9,     4] loss: 1.381
[10,     4] loss: 1.381
[11,     4] loss: 1.384
[12,     4] loss: 1.373
[13,     4] loss: 1.358
[14,     4] loss: 1.341
[15,     4] loss: 1.296
[16,     4] loss: 1.252
[17,     4] loss: 1.220
[18,     4] loss: 1.142
[19,     4] loss: 1.102
[20,     4] loss: 1.043
[21,     4] loss: 1.050
[22,     4] loss: 1.071
[23,     4] loss: 0.940
[24,     4] loss: 0.968
[25,     4] loss: 1.001
[26,     4] loss: 0.891
[27,     4] loss: 0.889
[28,     4] loss: 0.837
[29,     4] loss: 0.858
[30,     4] loss: 0.884
[31,     4] loss: 0.918
[32,     4] loss: 0.930
[33,     4] loss: 0.848
[34,     4] loss: 0.863
[35,     4] loss: 0.827
[36,     4] loss: 0.810
[37,     4] loss: 0.807
[38,     4] loss: 0.767
[39,     4] loss: 0.766
[40,     4] loss: 0.757
[41,     4] loss: 0.775
[42,     4] loss: 0.753
[43,     4] loss: 0.754
[44,     4] loss: 0.747
[45,     4] loss: 0.734
[46,     4] loss: 0.774
[47,     4] loss: 0.755
[48,     4] loss: 0.750
[49,     4] loss: 0.809
[50,     4] loss: 0.798
[51,     4] loss: 0.817
[52,     4] loss: 0.809
[53,     4] loss: 0.829
[54,     4] loss: 0.855
[55,     4] loss: 0.830
[56,     4] loss: 0.770
[57,     4] loss: 0.776
[58,     4] loss: 0.766
[59,     4] loss: 0.749
[60,     4] loss: 0.735
[61,     4] loss: 0.733
[62,     4] loss: 0.732
[63,     4] loss: 0.732
[64,     4] loss: 0.716
[65,     4] loss: 0.733
[66,     4] loss: 0.726
[67,     4] loss: 0.740
Early stopping applied (best metric=0.42625126242637634)
Finished Training
Total time taken: 33.460015535354614
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.401
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.388
[5,     4] loss: 1.384
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.382
[9,     4] loss: 1.380
[10,     4] loss: 1.382
[11,     4] loss: 1.382
[12,     4] loss: 1.378
[13,     4] loss: 1.362
[14,     4] loss: 1.342
[15,     4] loss: 1.347
[16,     4] loss: 1.299
[17,     4] loss: 1.264
[18,     4] loss: 1.274
[19,     4] loss: 1.184
[20,     4] loss: 1.105
[21,     4] loss: 1.135
[22,     4] loss: 1.076
[23,     4] loss: 1.111
[24,     4] loss: 1.071
[25,     4] loss: 1.054
[26,     4] loss: 1.117
[27,     4] loss: 1.023
[28,     4] loss: 0.973
[29,     4] loss: 1.029
[30,     4] loss: 0.887
[31,     4] loss: 0.976
[32,     4] loss: 0.895
[33,     4] loss: 0.911
[34,     4] loss: 0.896
[35,     4] loss: 0.865
[36,     4] loss: 0.914
[37,     4] loss: 0.855
[38,     4] loss: 0.826
[39,     4] loss: 0.864
[40,     4] loss: 0.821
[41,     4] loss: 0.778
[42,     4] loss: 0.786
[43,     4] loss: 0.769
[44,     4] loss: 0.746
[45,     4] loss: 0.746
[46,     4] loss: 0.736
[47,     4] loss: 0.756
[48,     4] loss: 0.783
[49,     4] loss: 0.764
[50,     4] loss: 0.766
[51,     4] loss: 0.799
[52,     4] loss: 0.758
[53,     4] loss: 0.777
[54,     4] loss: 0.764
[55,     4] loss: 0.749
[56,     4] loss: 0.749
[57,     4] loss: 0.836
[58,     4] loss: 0.799
[59,     4] loss: 0.774
[60,     4] loss: 0.769
[61,     4] loss: 0.774
[62,     4] loss: 0.786
[63,     4] loss: 0.818
[64,     4] loss: 0.790
[65,     4] loss: 0.768
[66,     4] loss: 0.775
[67,     4] loss: 0.780
[68,     4] loss: 0.769
[69,     4] loss: 0.741
[70,     4] loss: 0.741
[71,     4] loss: 0.736
[72,     4] loss: 0.762
[73,     4] loss: 0.726
[74,     4] loss: 0.757
[75,     4] loss: 0.755
[76,     4] loss: 0.764
[77,     4] loss: 0.783
[78,     4] loss: 0.780
[79,     4] loss: 0.793
[80,     4] loss: 0.854
Early stopping applied (best metric=0.21719276905059814)
Finished Training
Total time taken: 40.64863729476929
{'Hydroxylation-K Validation Accuracy': 0.7882387706855792, 'Hydroxylation-K Validation Sensitivity': 0.7570370370370371, 'Hydroxylation-K Validation Specificity': 0.7964912280701755, 'Hydroxylation-K Validation Precision': 0.5110919069513766, 'Hydroxylation-K AUC ROC': 0.8296491228070175, 'Hydroxylation-K AUC PR': 0.5945187043831767, 'Hydroxylation-K MCC': 0.4923670361260015, 'Hydroxylation-K F1': 0.6003168560008205, 'Validation Loss (Hydroxylation-K)': 0.40595754782358806, 'Methylation-K Validation Accuracy': 0.8217091100459235, 'Methylation-K Validation Sensitivity': 0.12588818137267466, 'Methylation-K Validation Specificity': 0.8971728231631743, 'Methylation-K Validation Precision': 0.12379914481796347, 'Methylation-K AUC ROC': 0.5399738001536344, 'Methylation-K AUC PR': 0.11215114684612551, 'Methylation-K MCC': 0.024012563796909314, 'Methylation-K F1': 0.11283319912529106, 'Validation Loss (Methylation-K)': 0.9195790708065033, 'Validation Loss (total)': 1.3255366086959839, 'TimeToTrain': 39.09992356300354}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007280174130730078,
 'learning_rate_Hydroxylation-K': 0.0012400410303956037,
 'learning_rate_Methylation-K': 0.00820416444533853,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.00016424892117893871,
 'loss_weight_Methylation-K': 0.15069798950006538,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2279715161,
 'sample_weights': [0.21715509543850964, 0.9526479894918399],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.38179114865684,
 'weight_decay_Hydroxylation-K': 1.1734856547189976,
 'weight_decay_Methylation-K': 9.90387561152836}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.394
[3,     4] loss: 1.397
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0046146821103567786,
 'learning_rate_Hydroxylation-K': 0.003920199409471939,
 'learning_rate_Methylation-K': 0.006296553506071944,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.41333657527152323,
 'loss_weight_Methylation-K': 0.7367767054159261,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2689359743,
 'sample_weights': [0.00016424892117893871, 0.15069798950006538],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.5173063886588665,
 'weight_decay_Hydroxylation-K': 2.6775227663089507,
 'weight_decay_Methylation-K': 5.029462660467658}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.391
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008438493062097312,
 'learning_rate_Hydroxylation-K': 0.0021491936306608306,
 'learning_rate_Methylation-K': 0.0021625623045169696,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8045086566403353,
 'loss_weight_Methylation-K': 0.5678952958684672,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 473537578,
 'sample_weights': [0.41333657527152323, 0.7367767054159261],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.9234640329794814,
 'weight_decay_Hydroxylation-K': 9.850914054723614,
 'weight_decay_Methylation-K': 0.3663610037031628}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.390
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006930935274831551,
 'learning_rate_Hydroxylation-K': 0.008257487289105222,
 'learning_rate_Methylation-K': 0.007239845284110873,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.04425310545718448,
 'loss_weight_Methylation-K': 0.79326201485983,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1236586272,
 'sample_weights': [0.8045086566403353, 0.5678952958684672],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.155205787172346,
 'weight_decay_Hydroxylation-K': 1.4309125493763974,
 'weight_decay_Methylation-K': 3.794908844997551}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.389
[3,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014414094031738975,
 'learning_rate_Hydroxylation-K': 0.005729973488955159,
 'learning_rate_Methylation-K': 0.005902966459436096,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3656096722397338,
 'loss_weight_Methylation-K': 0.49531805896867037,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2171200924,
 'sample_weights': [0.04425310545718448, 0.79326201485983],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.758306272749471,
 'weight_decay_Hydroxylation-K': 9.433468428426561,
 'weight_decay_Methylation-K': 1.5021740952551332}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.387
[3,     4] loss: 1.383
[4,     4] loss: 1.378
[5,     4] loss: 1.374
[6,     4] loss: 1.370
[7,     4] loss: 1.354
[8,     4] loss: 1.330
[9,     4] loss: 1.308
[10,     4] loss: 1.263
[11,     4] loss: 1.218
[12,     4] loss: 1.127
[13,     4] loss: 1.118
[14,     4] loss: 1.100
[15,     4] loss: 1.018
[16,     4] loss: 1.032
[17,     4] loss: 1.001
[18,     4] loss: 1.018
[19,     4] loss: 0.960
[20,     4] loss: 0.907
[21,     4] loss: 0.894
[22,     4] loss: 0.932
[23,     4] loss: 0.959
[24,     4] loss: 0.968
[25,     4] loss: 0.964
[26,     4] loss: 0.928
[27,     4] loss: 0.932
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00859753420961543,
 'learning_rate_Hydroxylation-K': 0.004929590053114138,
 'learning_rate_Methylation-K': 0.006405742225324502,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8559166612190735,
 'loss_weight_Methylation-K': 0.1354189687140547,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2272236357,
 'sample_weights': [0.3656096722397338, 0.49531805896867037],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.52529491354925,
 'weight_decay_Hydroxylation-K': 7.005467293493521,
 'weight_decay_Methylation-K': 3.11151816899501}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.376
[2,     4] loss: 1.387
[3,     4] loss: 1.387
[4,     4] loss: 1.386
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.388
[9,     4] loss: 1.387
[10,     4] loss: 1.387
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.387
[15,     4] loss: 1.385
[16,     4] loss: 1.385
[17,     4] loss: 1.386
[18,     4] loss: 1.387
[19,     4] loss: 1.386
[20,     4] loss: 1.379
[21,     4] loss: 1.364
[22,     4] loss: 1.333
[23,     4] loss: 1.332
[24,     4] loss: 1.345
[25,     4] loss: 1.319
[26,     4] loss: 1.238
[27,     4] loss: 1.169
[28,     4] loss: 1.164
[29,     4] loss: 1.415
[30,     4] loss: 1.242
[31,     4] loss: 1.160
[32,     4] loss: 1.091
[33,     4] loss: 1.078
[34,     4] loss: 0.947
[35,     4] loss: 0.917
[36,     4] loss: 1.044
[37,     4] loss: 1.064
[38,     4] loss: 1.043
[39,     4] loss: 1.014
[40,     4] loss: 1.014
[41,     4] loss: 0.950
[42,     4] loss: 0.932
[43,     4] loss: 0.974
[44,     4] loss: 0.898
[45,     4] loss: 0.932
[46,     4] loss: 1.036
[47,     4] loss: 0.925
[48,     4] loss: 0.938
[49,     4] loss: 0.886
[50,     4] loss: 0.937
[51,     4] loss: 1.006
[52,     4] loss: 0.914
[53,     4] loss: 0.905
[54,     4] loss: 0.841
[55,     4] loss: 0.880
[56,     4] loss: 1.028
[57,     4] loss: 1.076
[58,     4] loss: 0.996
[59,     4] loss: 0.927
[60,     4] loss: 0.876
[61,     4] loss: 0.863
[62,     4] loss: 0.897
[63,     4] loss: 1.121
[64,     4] loss: 1.081
[65,     4] loss: 1.132
[66,     4] loss: 1.056
[67,     4] loss: 1.098
[68,     4] loss: 1.125
[69,     4] loss: 0.986
[70,     4] loss: 0.883
[71,     4] loss: 0.889
[72,     4] loss: 0.982
[73,     4] loss: 0.977
[74,     4] loss: 0.922
[75,     4] loss: 1.064
[76,     4] loss: 1.043
[77,     4] loss: 0.961
[78,     4] loss: 1.002
[79,     4] loss: 1.020
[80,     4] loss: 0.954
[81,     4] loss: 0.958
[82,     4] loss: 1.018
[83,     4] loss: 1.009
[84,     4] loss: 1.038
[85,     4] loss: 1.051
[86,     4] loss: 0.922
[87,     4] loss: 0.912
[88,     4] loss: 0.828
[89,     4] loss: 0.992
[90,     4] loss: 1.092
[91,     4] loss: 1.145
[92,     4] loss: 1.047
[93,     4] loss: 0.992
[94,     4] loss: 1.034
[95,     4] loss: 0.959
[96,     4] loss: 0.902
[97,     4] loss: 1.200
[98,     4] loss: 1.046
[99,     4] loss: 1.097
[100,     4] loss: 1.157
[101,     4] loss: 1.059
[102,     4] loss: 0.991
[103,     4] loss: 0.992
[104,     4] loss: 0.952
[105,     4] loss: 0.965
[106,     4] loss: 0.974
[107,     4] loss: 0.894
[108,     4] loss: 0.846
[109,     4] loss: 0.852
[110,     4] loss: 1.039
[111,     4] loss: 0.929
[112,     4] loss: 0.958
[113,     4] loss: 0.940
[114,     4] loss: 0.937
[115,     4] loss: 0.960
[116,     4] loss: 0.971
[117,     4] loss: 0.912
[118,     4] loss: 0.842
[119,     4] loss: 0.854
[120,     4] loss: 0.892
[121,     4] loss: 0.872
[122,     4] loss: 1.020
[123,     4] loss: 1.045
[124,     4] loss: 1.059
[125,     4] loss: 0.962
[126,     4] loss: 0.956
[127,     4] loss: 0.935
[128,     4] loss: 0.966
[129,     4] loss: 0.953
[130,     4] loss: 1.064
[131,     4] loss: 0.977
[132,     4] loss: 0.881
[133,     4] loss: 0.891
[134,     4] loss: 0.839
[135,     4] loss: 0.851
[136,     4] loss: 0.841
[137,     4] loss: 0.957
[138,     4] loss: 0.881
[139,     4] loss: 0.857
[140,     4] loss: 0.940
[141,     4] loss: 1.005
[142,     4] loss: 1.049
[143,     4] loss: 0.916
[144,     4] loss: 0.911
[145,     4] loss: 0.910
[146,     4] loss: 1.201
[147,     4] loss: 1.072
[148,     4] loss: 0.984
[149,     4] loss: 0.927
[150,     4] loss: 0.887
[151,     4] loss: 1.018
[152,     4] loss: 1.031
[153,     4] loss: 0.959
[154,     4] loss: 0.932
[155,     4] loss: 0.953
[156,     4] loss: 0.899
[157,     4] loss: 0.894
[158,     4] loss: 0.989
[159,     4] loss: 0.962
[160,     4] loss: 0.935
[161,     4] loss: 0.865
[162,     4] loss: 0.974
[163,     4] loss: 0.931
[164,     4] loss: 0.904
[165,     4] loss: 0.975
[166,     4] loss: 0.959
[167,     4] loss: 1.056
[168,     4] loss: 0.984
[169,     4] loss: 0.961
[170,     4] loss: 0.847
[171,     4] loss: 0.799
[172,     4] loss: 1.121
[173,     4] loss: 1.099
[174,     4] loss: 1.095
[175,     4] loss: 1.412
[176,     4] loss: 1.292
[177,     4] loss: 1.259
[178,     4] loss: 1.157
[179,     4] loss: 1.081
[180,     4] loss: 1.060
[181,     4] loss: 1.012
[182,     4] loss: 0.934
[183,     4] loss: 0.842
[184,     4] loss: 0.858
[185,     4] loss: 0.893
[186,     4] loss: 1.093
[187,     4] loss: 1.057
[188,     4] loss: 0.985
[189,     4] loss: 0.906
[190,     4] loss: 0.934
[191,     4] loss: 0.960
[192,     4] loss: 1.021
[193,     4] loss: 0.978
[194,     4] loss: 0.933
[195,     4] loss: 1.018
[196,     4] loss: 0.938
[197,     4] loss: 0.932
[198,     4] loss: 0.872
[199,     4] loss: 0.839
[200,     4] loss: 0.910
Finished Training
Total time taken: 100.84840607643127
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.399
[3,     4] loss: 1.387
[4,     4] loss: 1.386
[5,     4] loss: 1.388
[6,     4] loss: 1.388
[7,     4] loss: 1.386
[8,     4] loss: 1.387
[9,     4] loss: 1.386
[10,     4] loss: 1.387
[11,     4] loss: 1.387
[12,     4] loss: 1.386
[13,     4] loss: 1.387
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.387
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.387
[29,     4] loss: 1.387
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.387
[34,     4] loss: 1.386
[35,     4] loss: 1.387
[36,     4] loss: 1.386
[37,     4] loss: 1.387
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.387
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.387
[48,     4] loss: 1.386
[49,     4] loss: 1.387
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.386
Early stopping applied (best metric=0.5629463195800781)
Finished Training
Total time taken: 26.268775701522827
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.380
[2,     4] loss: 1.390
[3,     4] loss: 1.387
[4,     4] loss: 1.387
[5,     4] loss: 1.383
[6,     4] loss: 1.390
[7,     4] loss: 1.388
[8,     4] loss: 1.383
[9,     4] loss: 1.392
[10,     4] loss: 1.384
[11,     4] loss: 1.386
[12,     4] loss: 1.385
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.387
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.387
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.387
[34,     4] loss: 1.387
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.387
[41,     4] loss: 1.386
[42,     4] loss: 1.387
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.387
[46,     4] loss: 1.386
[47,     4] loss: 1.387
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.387
Early stopping applied (best metric=0.5607117414474487)
Finished Training
Total time taken: 26.68144917488098
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.410
[2,     4] loss: 1.386
[3,     4] loss: 1.376
[4,     4] loss: 1.392
[5,     4] loss: 1.388
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.386
[10,     4] loss: 1.384
[11,     4] loss: 1.389
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.387
[19,     4] loss: 1.387
[20,     4] loss: 1.386
[21,     4] loss: 1.387
[22,     4] loss: 1.387
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.387
[28,     4] loss: 1.387
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.387
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.387
[37,     4] loss: 1.386
[38,     4] loss: 1.387
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.386
[53,     4] loss: 1.386
[54,     4] loss: 1.386
[55,     4] loss: 1.386
[56,     4] loss: 1.386
[57,     4] loss: 1.385
[58,     4] loss: 1.387
[59,     4] loss: 1.386
[60,     4] loss: 1.387
[61,     4] loss: 1.387
Early stopping applied (best metric=0.5453335046768188)
Finished Training
Total time taken: 31.102060079574585
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.388
[2,     4] loss: 1.386
[3,     4] loss: 1.390
[4,     4] loss: 1.388
[5,     4] loss: 1.385
[6,     4] loss: 1.384
[7,     4] loss: 1.384
[8,     4] loss: 1.387
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.385
[13,     4] loss: 1.386
[14,     4] loss: 1.384
[15,     4] loss: 1.368
[16,     4] loss: 1.342
[17,     4] loss: 1.327
[18,     4] loss: 1.264
[19,     4] loss: 1.280
[20,     4] loss: 1.233
[21,     4] loss: 1.188
[22,     4] loss: 1.256
[23,     4] loss: 1.198
[24,     4] loss: 1.164
[25,     4] loss: 1.178
[26,     4] loss: 1.201
[27,     4] loss: 1.124
[28,     4] loss: 1.096
[29,     4] loss: 1.173
[30,     4] loss: 1.087
[31,     4] loss: 1.206
[32,     4] loss: 1.179
[33,     4] loss: 1.167
[34,     4] loss: 1.116
[35,     4] loss: 1.106
[36,     4] loss: 1.031
[37,     4] loss: 0.999
[38,     4] loss: 0.981
[39,     4] loss: 0.991
[40,     4] loss: 1.080
[41,     4] loss: 1.123
[42,     4] loss: 1.012
[43,     4] loss: 0.880
[44,     4] loss: 0.920
[45,     4] loss: 0.818
[46,     4] loss: 1.275
[47,     4] loss: 1.292
[48,     4] loss: 1.293
[49,     4] loss: 1.218
[50,     4] loss: 1.182
[51,     4] loss: 1.073
[52,     4] loss: 0.961
[53,     4] loss: 0.933
[54,     4] loss: 0.911
[55,     4] loss: 1.526
[56,     4] loss: 1.383
[57,     4] loss: 1.375
[58,     4] loss: 1.378
[59,     4] loss: 1.372
[60,     4] loss: 1.358
[61,     4] loss: 1.311
[62,     4] loss: 1.320
[63,     4] loss: 1.331
[64,     4] loss: 1.381
[65,     4] loss: 1.381
[66,     4] loss: 1.378
[67,     4] loss: 1.355
[68,     4] loss: 1.322
[69,     4] loss: 1.268
[70,     4] loss: 1.343
[71,     4] loss: 1.373
[72,     4] loss: 1.330
[73,     4] loss: 1.295
[74,     4] loss: 1.217
[75,     4] loss: 1.238
[76,     4] loss: 1.172
[77,     4] loss: 1.111
[78,     4] loss: 1.280
[79,     4] loss: 1.247
[80,     4] loss: 1.211
[81,     4] loss: 1.152
[82,     4] loss: 1.121
[83,     4] loss: 1.058
[84,     4] loss: 1.377
[85,     4] loss: 1.297
[86,     4] loss: 1.318
[87,     4] loss: 1.260
[88,     4] loss: 1.191
[89,     4] loss: 1.117
[90,     4] loss: 1.056
[91,     4] loss: 1.051
[92,     4] loss: 1.145
[93,     4] loss: 1.134
[94,     4] loss: 1.086
[95,     4] loss: 1.097
[96,     4] loss: 1.064
[97,     4] loss: 1.028
[98,     4] loss: 1.087
[99,     4] loss: 1.128
[100,     4] loss: 1.086
[101,     4] loss: 1.026
[102,     4] loss: 1.010
[103,     4] loss: 1.004
[104,     4] loss: 0.937
[105,     4] loss: 0.959
[106,     4] loss: 1.278
[107,     4] loss: 1.183
[108,     4] loss: 1.220
[109,     4] loss: 1.235
[110,     4] loss: 1.201
[111,     4] loss: 1.133
[112,     4] loss: 1.127
[113,     4] loss: 1.064
[114,     4] loss: 1.209
[115,     4] loss: 1.080
[116,     4] loss: 1.045
[117,     4] loss: 1.107
[118,     4] loss: 1.120
[119,     4] loss: 1.083
[120,     4] loss: 1.058
[121,     4] loss: 1.142
[122,     4] loss: 1.120
[123,     4] loss: 1.107
[124,     4] loss: 1.024
[125,     4] loss: 0.991
[126,     4] loss: 1.134
[127,     4] loss: 1.046
[128,     4] loss: 1.116
[129,     4] loss: 1.004
[130,     4] loss: 0.926
[131,     4] loss: 1.068
[132,     4] loss: 1.132
[133,     4] loss: 1.153
[134,     4] loss: 1.052
[135,     4] loss: 1.015
[136,     4] loss: 1.014
[137,     4] loss: 1.302
[138,     4] loss: 1.205
[139,     4] loss: 1.124
[140,     4] loss: 1.036
[141,     4] loss: 1.209
[142,     4] loss: 1.218
[143,     4] loss: 1.276
[144,     4] loss: 1.216
[145,     4] loss: 1.207
[146,     4] loss: 1.143
[147,     4] loss: 1.133
Early stopping applied (best metric=0.25941845774650574)
Finished Training
Total time taken: 77.51722931861877
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.389
[3,     4] loss: 1.387
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.387
[9,     4] loss: 1.386
[10,     4] loss: 1.385
[11,     4] loss: 1.386
[12,     4] loss: 1.385
[13,     4] loss: 1.388
[14,     4] loss: 1.387
[15,     4] loss: 1.386
[16,     4] loss: 1.387
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.387
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.387
[42,     4] loss: 1.387
[43,     4] loss: 1.386
[44,     4] loss: 1.387
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.387
[48,     4] loss: 1.387
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.386
[53,     4] loss: 1.386
[54,     4] loss: 1.387
[55,     4] loss: 1.385
[56,     4] loss: 1.386
[57,     4] loss: 1.387
[58,     4] loss: 1.387
[59,     4] loss: 1.386
[60,     4] loss: 1.386
[61,     4] loss: 1.386
Early stopping applied (best metric=0.5629297494888306)
Finished Training
Total time taken: 32.235536098480225
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.390
[3,     4] loss: 1.383
[4,     4] loss: 1.382
[5,     4] loss: 1.388
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.387
[10,     4] loss: 1.385
[11,     4] loss: 1.385
[12,     4] loss: 1.387
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.387
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.387
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.387
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.387
[29,     4] loss: 1.387
[30,     4] loss: 1.387
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.387
[34,     4] loss: 1.387
[35,     4] loss: 1.387
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.387
[44,     4] loss: 1.386
[45,     4] loss: 1.387
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.387
Early stopping applied (best metric=0.5624357461929321)
Finished Training
Total time taken: 26.919440984725952
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.387
[5,     4] loss: 1.388
[6,     4] loss: 1.389
[7,     4] loss: 1.385
[8,     4] loss: 1.385
[9,     4] loss: 1.389
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.387
[15,     4] loss: 1.386
[16,     4] loss: 1.385
[17,     4] loss: 1.387
[18,     4] loss: 1.386
[19,     4] loss: 1.387
[20,     4] loss: 1.386
[21,     4] loss: 1.387
[22,     4] loss: 1.387
[23,     4] loss: 1.386
[24,     4] loss: 1.387
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.387
[33,     4] loss: 1.387
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.387
[37,     4] loss: 1.387
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.387
[41,     4] loss: 1.386
[42,     4] loss: 1.387
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.387
[46,     4] loss: 1.387
[47,     4] loss: 1.387
[48,     4] loss: 1.386
[49,     4] loss: 1.387
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.387
Early stopping applied (best metric=0.5624472498893738)
Finished Training
Total time taken: 27.10094165802002
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.388
[5,     4] loss: 1.388
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.386
[9,     4] loss: 1.386
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.387
[14,     4] loss: 1.387
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.387
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.387
[34,     4] loss: 1.387
[35,     4] loss: 1.387
[36,     4] loss: 1.386
[37,     4] loss: 1.387
[38,     4] loss: 1.387
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.387
[45,     4] loss: 1.387
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.387
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.387
[52,     4] loss: 1.386
[53,     4] loss: 1.386
[54,     4] loss: 1.386
Early stopping applied (best metric=0.5453929305076599)
Finished Training
Total time taken: 29.197101593017578
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.390
[2,     4] loss: 1.391
[3,     4] loss: 1.387
[4,     4] loss: 1.386
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.386
[10,     4] loss: 1.387
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.387
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.387
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.387
[31,     4] loss: 1.387
[32,     4] loss: 1.386
[33,     4] loss: 1.387
[34,     4] loss: 1.386
[35,     4] loss: 1.387
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.387
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.387
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.387
[51,     4] loss: 1.386
Early stopping applied (best metric=0.5446364283561707)
Finished Training
Total time taken: 27.357441425323486
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.386
[3,     4] loss: 1.387
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.387
[9,     4] loss: 1.386
[10,     4] loss: 1.385
[11,     4] loss: 1.386
[12,     4] loss: 1.388
[13,     4] loss: 1.387
[14,     4] loss: 1.386
[15,     4] loss: 1.387
[16,     4] loss: 1.386
[17,     4] loss: 1.387
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.387
[22,     4] loss: 1.387
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.387
[27,     4] loss: 1.387
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.387
[31,     4] loss: 1.387
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.387
[44,     4] loss: 1.386
[45,     4] loss: 1.387
[46,     4] loss: 1.386
[47,     4] loss: 1.387
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.387
Early stopping applied (best metric=0.5624606609344482)
Finished Training
Total time taken: 28.15892505645752
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.386
[3,     4] loss: 1.387
[4,     4] loss: 1.388
[5,     4] loss: 1.388
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.386
[10,     4] loss: 1.387
[11,     4] loss: 1.387
[12,     4] loss: 1.387
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.387
[19,     4] loss: 1.387
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.387
[23,     4] loss: 1.387
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.387
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.387
[30,     4] loss: 1.386
[31,     4] loss: 1.387
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.387
[35,     4] loss: 1.387
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.387
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.387
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.387
Early stopping applied (best metric=0.5610636472702026)
Finished Training
Total time taken: 28.853776931762695
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.388
[3,     4] loss: 1.389
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.387
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.387
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.387
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.387
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.387
[48,     4] loss: 1.386
[49,     4] loss: 1.387
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.387
[53,     4] loss: 1.386
Early stopping applied (best metric=0.5625871419906616)
Finished Training
Total time taken: 27.856239080429077
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.387
[3,     4] loss: 1.383
[4,     4] loss: 1.386
[5,     4] loss: 1.390
[6,     4] loss: 1.386
[7,     4] loss: 1.387
[8,     4] loss: 1.386
[9,     4] loss: 1.385
[10,     4] loss: 1.385
[11,     4] loss: 1.390
[12,     4] loss: 1.385
[13,     4] loss: 1.385
[14,     4] loss: 1.387
[15,     4] loss: 1.385
[16,     4] loss: 1.385
[17,     4] loss: 1.387
[18,     4] loss: 1.386
[19,     4] loss: 1.387
[20,     4] loss: 1.387
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.387
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.387
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.387
[37,     4] loss: 1.386
[38,     4] loss: 1.388
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.387
[47,     4] loss: 1.387
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.387
[52,     4] loss: 1.387
[53,     4] loss: 1.386
[54,     4] loss: 1.386
[55,     4] loss: 1.386
Early stopping applied (best metric=0.545017421245575)
Finished Training
Total time taken: 29.382352590560913
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.387
[2,     4] loss: 1.390
[3,     4] loss: 1.388
[4,     4] loss: 1.386
[5,     4] loss: 1.386
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.387
[9,     4] loss: 1.386
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.387
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.387
[20,     4] loss: 1.387
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.387
[26,     4] loss: 1.386
[27,     4] loss: 1.387
[28,     4] loss: 1.387
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.387
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.387
[36,     4] loss: 1.387
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.387
[40,     4] loss: 1.387
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.387
[49,     4] loss: 1.387
[50,     4] loss: 1.387
[51,     4] loss: 1.386
Early stopping applied (best metric=0.5452165007591248)
Finished Training
Total time taken: 28.695225954055786
{'Hydroxylation-K Validation Accuracy': 0.5803486997635934, 'Hydroxylation-K Validation Sensitivity': 0.5125925925925926, 'Hydroxylation-K Validation Specificity': 0.6052631578947368, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.7326413255360624, 'Hydroxylation-K AUC PR': 0.4754959812224577, 'Hydroxylation-K MCC': 0.10740800675940744, 'Hydroxylation-K F1': 0.23619737750172534, 'Validation Loss (Hydroxylation-K)': 0.5215682884057363, 'Methylation-K Validation Accuracy': 0.5883595151604616, 'Methylation-K Validation Sensitivity': 0.3980723095550414, 'Methylation-K Validation Specificity': 0.6090088161356815, 'Methylation-K Validation Precision': nan, 'Methylation-K AUC ROC': 0.5175541888277818, 'Methylation-K AUC PR': 0.10429656877169668, 'Methylation-K MCC': 0.005434443993974409, 'Methylation-K F1': 0.08997533303962107, 'Validation Loss (Methylation-K)': 0.5490848422050476, 'Validation Loss (total)': 1.0706531325976054, 'TimeToTrain': 36.54499344825744}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008596486339431915,
 'learning_rate_Hydroxylation-K': 0.0064672031115964755,
 'learning_rate_Methylation-K': 0.005715476477962104,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6524812722854966,
 'loss_weight_Methylation-K': 0.4646688143238731,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1047439761,
 'sample_weights': [0.8559166612190735, 0.1354189687140547],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.791304732597904,
 'weight_decay_Hydroxylation-K': 8.40976553474895,
 'weight_decay_Methylation-K': 0.9111662471795412}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.387
[3,     4] loss: 1.387
[4,     4] loss: 1.388
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.387
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009929574670858323,
 'learning_rate_Hydroxylation-K': 0.0034613100498246917,
 'learning_rate_Methylation-K': 0.006295367077886243,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6287634251202946,
 'loss_weight_Methylation-K': 0.7908102814668085,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2008463739,
 'sample_weights': [0.6524812722854966, 0.4646688143238731],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.99368979378134,
 'weight_decay_Hydroxylation-K': 3.7420281403273457,
 'weight_decay_Methylation-K': 9.070855814809315}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.390
[3,     4] loss: 1.388
[4,     4] loss: 1.377
[5,     4] loss: 1.378
[6,     4] loss: 1.359
[7,     4] loss: 1.335
[8,     4] loss: 1.289
[9,     4] loss: 1.243
[10,     4] loss: 1.219
[11,     4] loss: 1.160
[12,     4] loss: 1.071
[13,     4] loss: 0.995
[14,     4] loss: 0.945
[15,     4] loss: 1.046
[16,     4] loss: 1.003
[17,     4] loss: 1.030
[18,     4] loss: 0.941
[19,     4] loss: 0.975
[20,     4] loss: 0.976
[21,     4] loss: 0.954
[22,     4] loss: 0.948
[23,     4] loss: 1.004
[24,     4] loss: 0.919
[25,     4] loss: 0.931
[26,     4] loss: 0.863
[27,     4] loss: 0.877
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010635884511809,
 'learning_rate_Hydroxylation-K': 0.0007868338777456059,
 'learning_rate_Methylation-K': 0.001482172733742314,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.04119708831990528,
 'loss_weight_Methylation-K': 0.6012126637142239,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 327705272,
 'sample_weights': [0.6287634251202946, 0.7908102814668085],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.787393088119668,
 'weight_decay_Hydroxylation-K': 1.9497579964619405,
 'weight_decay_Methylation-K': 8.54886539915338}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.387
[3,     4] loss: 1.383
[4,     4] loss: 1.377
[5,     4] loss: 1.375
[6,     4] loss: 1.374
[7,     4] loss: 1.355
[8,     4] loss: 1.311
[9,     4] loss: 1.279
[10,     4] loss: 1.240
[11,     4] loss: 1.200
[12,     4] loss: 1.170
[13,     4] loss: 1.063
[14,     4] loss: 1.003
[15,     4] loss: 1.062
[16,     4] loss: 0.980
[17,     4] loss: 0.997
[18,     4] loss: 0.952
[19,     4] loss: 1.001
[20,     4] loss: 0.872
[21,     4] loss: 0.886
[22,     4] loss: 0.955
[23,     4] loss: 0.875
[24,     4] loss: 0.836
[25,     4] loss: 0.826
[26,     4] loss: 0.787
[27,     4] loss: 0.833
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022332383576268867,
 'learning_rate_Hydroxylation-K': 0.0028750245228064894,
 'learning_rate_Methylation-K': 0.005404575959078919,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7163734674857337,
 'loss_weight_Methylation-K': 0.27514956911063276,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4111882318,
 'sample_weights': [0.04119708831990528, 0.6012126637142239],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.613199538393531,
 'weight_decay_Hydroxylation-K': 6.605317067304135,
 'weight_decay_Methylation-K': 5.4951850864835095}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.384
[5,     4] loss: 1.377
[6,     4] loss: 1.368
[7,     4] loss: 1.351
[8,     4] loss: 1.334
[9,     4] loss: 1.269
[10,     4] loss: 1.192
[11,     4] loss: 1.113
[12,     4] loss: 1.091
[13,     4] loss: 1.143
[14,     4] loss: 1.113
[15,     4] loss: 1.098
[16,     4] loss: 1.101
[17,     4] loss: 1.057
[18,     4] loss: 0.989
[19,     4] loss: 0.967
[20,     4] loss: 0.944
[21,     4] loss: 0.969
[22,     4] loss: 0.940
[23,     4] loss: 0.932
[24,     4] loss: 0.939
[25,     4] loss: 0.957
[26,     4] loss: 1.014
[27,     4] loss: 1.004
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007210010991449707,
 'learning_rate_Hydroxylation-K': 0.00570025942791089,
 'learning_rate_Methylation-K': 0.002062660582097055,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.026092992897334594,
 'loss_weight_Methylation-K': 0.9797469554286368,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4138688954,
 'sample_weights': [0.7163734674857337, 0.27514956911063276],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.579913081123651,
 'weight_decay_Hydroxylation-K': 9.736453588361517,
 'weight_decay_Methylation-K': 9.588260321809686}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.411
[2,     4] loss: 1.389
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008130062630028296,
 'learning_rate_Hydroxylation-K': 6.180645249200309e-05,
 'learning_rate_Methylation-K': 0.00847654761262151,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5183724454692016,
 'loss_weight_Methylation-K': 0.18533677178950447,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1735773091,
 'sample_weights': [0.026092992897334594, 0.9797469554286368],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.114202044952043,
 'weight_decay_Hydroxylation-K': 9.144131835357456,
 'weight_decay_Methylation-K': 6.65730293795952}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.389
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00024582551157935264,
 'learning_rate_Hydroxylation-K': 0.004098393144011711,
 'learning_rate_Methylation-K': 0.006997530620842094,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.34924965090797083,
 'loss_weight_Methylation-K': 0.3084134956748384,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3949417042,
 'sample_weights': [0.5183724454692016, 0.18533677178950447],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.1914941663687704,
 'weight_decay_Hydroxylation-K': 8.422360256649936,
 'weight_decay_Methylation-K': 8.54178450175678}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.385
[3,     4] loss: 1.388
[4,     4] loss: 1.382
[5,     4] loss: 1.389
[6,     4] loss: 1.391
[7,     4] loss: 1.379
[8,     4] loss: 1.376
[9,     4] loss: 1.374
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009141994962997764,
 'learning_rate_Hydroxylation-K': 0.009159531376707638,
 'learning_rate_Methylation-K': 0.0059244988359184155,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7790433332644504,
 'loss_weight_Methylation-K': 0.16645039776662224,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2340259641,
 'sample_weights': [0.34924965090797083, 0.3084134956748384],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.151843568271997,
 'weight_decay_Hydroxylation-K': 8.719533496821612,
 'weight_decay_Methylation-K': 6.231551719746424}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.383
[3,     4] loss: 1.387
[4,     4] loss: 1.384
[5,     4] loss: 1.389
[6,     4] loss: 1.389
[7,     4] loss: 1.388
[8,     4] loss: 1.386
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005721534655448695,
 'learning_rate_Hydroxylation-K': 0.0015572831589989963,
 'learning_rate_Methylation-K': 0.00637925509440841,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8891693755822588,
 'loss_weight_Methylation-K': 0.7266672300663342,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1219904524,
 'sample_weights': [0.7790433332644504, 0.16645039776662224],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.29163202990333814,
 'weight_decay_Hydroxylation-K': 8.79887215149852,
 'weight_decay_Methylation-K': 1.4898715817972696}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.386
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0004015768403189857,
 'learning_rate_Hydroxylation-K': 0.0045788306448827564,
 'learning_rate_Methylation-K': 0.004488421452619679,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7530448168141166,
 'loss_weight_Methylation-K': 0.1623095780202046,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2956050069,
 'sample_weights': [0.8891693755822588, 0.7266672300663342],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.990610615390514,
 'weight_decay_Hydroxylation-K': 4.367230027827002,
 'weight_decay_Methylation-K': 4.16480065978419}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.384
[3,     4] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017731076693529425,
 'learning_rate_Hydroxylation-K': 0.001063758663990807,
 'learning_rate_Methylation-K': 0.009528639534355775,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.05081344575505728,
 'loss_weight_Methylation-K': 0.9304894237669109,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1017071030,
 'sample_weights': [0.7530448168141166, 0.1623095780202046],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7313110089210009,
 'weight_decay_Hydroxylation-K': 9.426122503757686,
 'weight_decay_Methylation-K': 6.99691334086242}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.386
[5,     4] loss: 1.385
[6,     4] loss: 1.384
[7,     4] loss: 1.385
[8,     4] loss: 1.386
[9,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009594601780720417,
 'learning_rate_Hydroxylation-K': 0.002254825109282564,
 'learning_rate_Methylation-K': 0.009262583987330273,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5030309470307427,
 'loss_weight_Methylation-K': 0.30248262951544164,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3054825961,
 'sample_weights': [0.05081344575505728, 0.9304894237669109],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.950799147678034,
 'weight_decay_Hydroxylation-K': 5.815994768386577,
 'weight_decay_Methylation-K': 7.030028861124142}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.384
[3,     4] loss: 1.396
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001563132055372919,
 'learning_rate_Hydroxylation-K': 0.0009018282203741808,
 'learning_rate_Methylation-K': 0.0010068471169058875,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1006927502991238,
 'loss_weight_Methylation-K': 0.6641925702440867,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1417024653,
 'sample_weights': [0.5030309470307427, 0.30248262951544164],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.197257296883347,
 'weight_decay_Hydroxylation-K': 4.1666851508128815,
 'weight_decay_Methylation-K': 8.314130550385373}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.418
[2,     4] loss: 1.387
[3,     4] loss: 1.387
[4,     4] loss: 1.383
[5,     4] loss: 1.377
[6,     4] loss: 1.365
[7,     4] loss: 1.339
[8,     4] loss: 1.300
[9,     4] loss: 1.274
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006435872975856198,
 'learning_rate_Hydroxylation-K': 0.006211272498986091,
 'learning_rate_Methylation-K': 0.009693584335511055,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.13615785977276304,
 'loss_weight_Methylation-K': 0.8290122398930262,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 125891402,
 'sample_weights': [0.1006927502991238, 0.6641925702440867],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.3205144749475854,
 'weight_decay_Hydroxylation-K': 8.483935971308577,
 'weight_decay_Methylation-K': 9.626686912213696}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.383
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011863984996163947,
 'learning_rate_Hydroxylation-K': 0.0036834208598372077,
 'learning_rate_Methylation-K': 0.002484784390456778,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.10354238135448096,
 'loss_weight_Methylation-K': 0.7644115148713047,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1452045638,
 'sample_weights': [0.13615785977276304, 0.8290122398930262],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.573493038637401,
 'weight_decay_Hydroxylation-K': 2.0183243203847776,
 'weight_decay_Methylation-K': 6.497930224779091}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.378
[2,     4] loss: 1.377
[3,     4] loss: 1.385
[4,     4] loss: 1.371
[5,     4] loss: 1.356
[6,     4] loss: 1.311
[7,     4] loss: 1.295
[8,     4] loss: 1.271
[9,     4] loss: 1.267
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00046660614830383324,
 'learning_rate_Hydroxylation-K': 0.002723232487948715,
 'learning_rate_Methylation-K': 0.009580963428422741,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5439602823673023,
 'loss_weight_Methylation-K': 0.4357622610180595,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 368998418,
 'sample_weights': [0.10354238135448096, 0.7644115148713047],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.91528368530221,
 'weight_decay_Hydroxylation-K': 7.729575550632655,
 'weight_decay_Methylation-K': 9.80644044197058}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.388
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004080459454874015,
 'learning_rate_Hydroxylation-K': 0.00900474805135022,
 'learning_rate_Methylation-K': 0.0009664744547657567,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.27696328238608225,
 'loss_weight_Methylation-K': 0.9540265115905064,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3946804543,
 'sample_weights': [0.5439602823673023, 0.4357622610180595],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.275755324206864,
 'weight_decay_Hydroxylation-K': 1.69594693986849,
 'weight_decay_Methylation-K': 8.312267504895859}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.383
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001912482157757321,
 'learning_rate_Hydroxylation-K': 0.0032487998290780485,
 'learning_rate_Methylation-K': 0.009169910538997239,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.18729870695097178,
 'loss_weight_Methylation-K': 0.8854600667595552,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 949606910,
 'sample_weights': [0.27696328238608225, 0.9540265115905064],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.557374933937881,
 'weight_decay_Hydroxylation-K': 5.678305062671719,
 'weight_decay_Methylation-K': 9.808750040336111}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.386
[3,     4] loss: 1.383
[4,     4] loss: 1.383
[5,     4] loss: 1.376
[6,     4] loss: 1.367
[7,     4] loss: 1.342
[8,     4] loss: 1.337
[9,     4] loss: 1.279
[10,     4] loss: 1.254
[11,     4] loss: 1.217
[12,     4] loss: 1.167
[13,     4] loss: 1.157
[14,     4] loss: 1.090
[15,     4] loss: 1.070
[16,     4] loss: 1.052
[17,     4] loss: 0.955
[18,     4] loss: 0.978
[19,     4] loss: 0.872
[20,     4] loss: 0.897
[21,     4] loss: 0.903
[22,     4] loss: 0.911
[23,     4] loss: 0.859
[24,     4] loss: 0.935
[25,     4] loss: 0.943
[26,     4] loss: 0.915
[27,     4] loss: 0.900
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001081309585755222,
 'learning_rate_Hydroxylation-K': 0.0008150064792453297,
 'learning_rate_Methylation-K': 0.007910860464397616,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.029495091992247785,
 'loss_weight_Methylation-K': 0.8928849359025208,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1958042591,
 'sample_weights': [0.18729870695097178, 0.8854600667595552],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.350261181827205,
 'weight_decay_Hydroxylation-K': 8.35630073331425,
 'weight_decay_Methylation-K': 9.71841399180359}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.385
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006973205109626222,
 'learning_rate_Hydroxylation-K': 0.007384186054989429,
 'learning_rate_Methylation-K': 0.007533173582502365,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9453487692454915,
 'loss_weight_Methylation-K': 0.27910646214138923,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2638529010,
 'sample_weights': [0.029495091992247785, 0.8928849359025208],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1718556885000906,
 'weight_decay_Hydroxylation-K': 1.3780505571833912,
 'weight_decay_Methylation-K': 3.0422408938167544}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.388
[3,     4] loss: 1.391
[4,     4] loss: 1.389
[5,     4] loss: 1.389
[6,     4] loss: 1.387
[7,     4] loss: 1.382
[8,     4] loss: 1.382
[9,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008460711900332974,
 'learning_rate_Hydroxylation-K': 0.003501384086371249,
 'learning_rate_Methylation-K': 0.003167076651269257,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.13916050813068434,
 'loss_weight_Methylation-K': 0.7422678998361736,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 937917901,
 'sample_weights': [0.9453487692454915, 0.27910646214138923],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.591573433708594,
 'weight_decay_Hydroxylation-K': 0.4783776698596798,
 'weight_decay_Methylation-K': 6.855419582245032}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.392
[3,     4] loss: 1.388
[4,     4] loss: 1.386
[5,     4] loss: 1.388
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.367
[9,     4] loss: 1.315
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003229728304670166,
 'learning_rate_Hydroxylation-K': 0.005348171835966706,
 'learning_rate_Methylation-K': 0.004676613054953649,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.29148109701646907,
 'loss_weight_Methylation-K': 0.960414452183805,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1347785786,
 'sample_weights': [0.13916050813068434, 0.7422678998361736],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.0574962362000733,
 'weight_decay_Hydroxylation-K': 6.048943101619147,
 'weight_decay_Methylation-K': 6.820266111884818}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.384
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006788516075546769,
 'learning_rate_Hydroxylation-K': 0.007712162305267539,
 'learning_rate_Methylation-K': 0.0028218663996989945,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8953792783711072,
 'loss_weight_Methylation-K': 0.2577285804480586,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1880322303,
 'sample_weights': [0.29148109701646907, 0.960414452183805],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.359936424846334,
 'weight_decay_Hydroxylation-K': 7.943922978320356,
 'weight_decay_Methylation-K': 2.0975451689661084}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.391
[3,     4] loss: 1.383
[4,     4] loss: 1.383
[5,     4] loss: 1.377
[6,     4] loss: 1.371
[7,     4] loss: 1.364
[8,     4] loss: 1.344
[9,     4] loss: 1.325
[10,     4] loss: 1.300
[11,     4] loss: 1.273
[12,     4] loss: 1.191
[13,     4] loss: 1.183
[14,     4] loss: 1.097
[15,     4] loss: 1.055
[16,     4] loss: 0.977
[17,     4] loss: 0.955
[18,     4] loss: 0.955
[19,     4] loss: 0.975
[20,     4] loss: 0.936
[21,     4] loss: 0.945
[22,     4] loss: 0.905
[23,     4] loss: 0.917
[24,     4] loss: 0.891
[25,     4] loss: 0.921
[26,     4] loss: 0.867
[27,     4] loss: 0.846
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004896513950161616,
 'learning_rate_Hydroxylation-K': 0.004180547639791491,
 'learning_rate_Methylation-K': 0.008366427615755205,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.061773848141208315,
 'loss_weight_Methylation-K': 0.9476067378686546,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3806512506,
 'sample_weights': [0.8953792783711072, 0.2577285804480586],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9565251744214466,
 'weight_decay_Hydroxylation-K': 4.351061302682693,
 'weight_decay_Methylation-K': 9.083102945062972}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.384
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023539583168016623,
 'learning_rate_Hydroxylation-K': 0.008467846932833636,
 'learning_rate_Methylation-K': 0.0044551426517232635,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2853843151116679,
 'loss_weight_Methylation-K': 0.26117977427245814,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1609160587,
 'sample_weights': [0.061773848141208315, 0.9476067378686546],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.04273621036001,
 'weight_decay_Hydroxylation-K': 4.301689006170749,
 'weight_decay_Methylation-K': 7.610977274247813}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.380
[2,     4] loss: 1.399
[3,     4] loss: 1.388
[4,     4] loss: 1.385
[5,     4] loss: 1.385
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.386
[9,     4] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008576031196481124,
 'learning_rate_Hydroxylation-K': 0.004500644681160842,
 'learning_rate_Methylation-K': 0.008925794094003575,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3358748233614913,
 'loss_weight_Methylation-K': 0.3995593636531827,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3439726483,
 'sample_weights': [0.2853843151116679, 0.26117977427245814],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.184341986311576,
 'weight_decay_Hydroxylation-K': 8.946103503037131,
 'weight_decay_Methylation-K': 4.827896343759279}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.388
[3,     4] loss: 1.387
[4,     4] loss: 1.387
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.390
[8,     4] loss: 1.386
[9,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008466955429770855,
 'learning_rate_Hydroxylation-K': 0.0053228226948031435,
 'learning_rate_Methylation-K': 0.008831634413748355,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6284086365006892,
 'loss_weight_Methylation-K': 0.18270380452346832,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2885876881,
 'sample_weights': [0.3358748233614913, 0.3995593636531827],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8789032855625423,
 'weight_decay_Hydroxylation-K': 9.037379791621383,
 'weight_decay_Methylation-K': 5.7222700842384135}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.385
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019954576172057,
 'learning_rate_Hydroxylation-K': 0.006558408863800615,
 'learning_rate_Methylation-K': 0.009989502699595133,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.09664072810080178,
 'loss_weight_Methylation-K': 0.7837161486993474,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 734566494,
 'sample_weights': [0.6284086365006892, 0.18270380452346832],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.095863966036974,
 'weight_decay_Hydroxylation-K': 8.807157817415042,
 'weight_decay_Methylation-K': 6.164094985235657}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.381
[2,     4] loss: 1.386
[3,     4] loss: 1.386
[4,     4] loss: 1.378
[5,     4] loss: 1.359
[6,     4] loss: 1.314
[7,     4] loss: 1.282
[8,     4] loss: 1.180
[9,     4] loss: 1.162
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027534286931021846,
 'learning_rate_Hydroxylation-K': 0.00412318397572801,
 'learning_rate_Methylation-K': 0.009665877343675612,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.12280303914013836,
 'loss_weight_Methylation-K': 0.9530689390445913,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 225820437,
 'sample_weights': [0.09664072810080178, 0.7837161486993474],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.365500354421431,
 'weight_decay_Hydroxylation-K': 0.7728072000842845,
 'weight_decay_Methylation-K': 7.469666224633268}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.381
[3,     4] loss: 1.396
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007104799082657657,
 'learning_rate_Hydroxylation-K': 0.0039136900413708695,
 'learning_rate_Methylation-K': 0.008694264496843825,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9140668019102653,
 'loss_weight_Methylation-K': 0.16145325288911683,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 934265732,
 'sample_weights': [0.12280303914013836, 0.9530689390445913],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6004686072820524,
 'weight_decay_Hydroxylation-K': 9.397500197652256,
 'weight_decay_Methylation-K': 1.316877420766681}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.402
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.384
[7,     4] loss: 1.385
[8,     4] loss: 1.389
[9,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00035328334066709563,
 'learning_rate_Hydroxylation-K': 0.003983937267589616,
 'learning_rate_Methylation-K': 0.006262808591793683,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1998619546589311,
 'loss_weight_Methylation-K': 0.4312419801476216,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4264317465,
 'sample_weights': [0.9140668019102653, 0.16145325288911683],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.081382553653423,
 'weight_decay_Hydroxylation-K': 6.123768717254162,
 'weight_decay_Methylation-K': 9.97580579113457}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.382
[5,     4] loss: 1.380
[6,     4] loss: 1.372
[7,     4] loss: 1.369
[8,     4] loss: 1.353
[9,     4] loss: 1.336
[10,     4] loss: 1.317
[11,     4] loss: 1.303
[12,     4] loss: 1.293
[13,     4] loss: 1.273
[14,     4] loss: 1.223
[15,     4] loss: 1.206
[16,     4] loss: 1.195
[17,     4] loss: 1.152
[18,     4] loss: 1.096
[19,     4] loss: 1.095
[20,     4] loss: 1.106
[21,     4] loss: 1.009
[22,     4] loss: 0.962
[23,     4] loss: 0.970
[24,     4] loss: 0.962
[25,     4] loss: 0.965
[26,     4] loss: 0.911
[27,     4] loss: 0.919
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006993306716472496,
 'learning_rate_Hydroxylation-K': 0.002710788260910294,
 'learning_rate_Methylation-K': 0.00482712599890704,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8211914004786208,
 'loss_weight_Methylation-K': 0.35961904857330457,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2457200090,
 'sample_weights': [0.1998619546589311, 0.4312419801476216],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.824027337237708,
 'weight_decay_Hydroxylation-K': 5.853272918435025,
 'weight_decay_Methylation-K': 3.328078414637444}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.385
[3,     4] loss: 1.390
[4,     4] loss: 1.386
[5,     4] loss: 1.388
[6,     4] loss: 1.391
[7,     4] loss: 1.389
[8,     4] loss: 1.387
[9,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007918723192508832,
 'learning_rate_Hydroxylation-K': 0.006637317066984997,
 'learning_rate_Methylation-K': 0.008519890980165153,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.07525327740020271,
 'loss_weight_Methylation-K': 0.7501398751906543,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3904335034,
 'sample_weights': [0.8211914004786208, 0.35961904857330457],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.103569421525071,
 'weight_decay_Hydroxylation-K': 8.245790305154262,
 'weight_decay_Methylation-K': 9.68764695913846}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.385
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004967488090839184,
 'learning_rate_Hydroxylation-K': 0.0006452126022472963,
 'learning_rate_Methylation-K': 0.008205620290239917,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.16483770550934265,
 'loss_weight_Methylation-K': 0.6034704617416917,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3127629167,
 'sample_weights': [0.07525327740020271, 0.7501398751906543],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.769236211497004,
 'weight_decay_Hydroxylation-K': 6.473660065105561,
 'weight_decay_Methylation-K': 9.367043299294526}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.387
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006457414492170947,
 'learning_rate_Hydroxylation-K': 0.0009337230897205086,
 'learning_rate_Methylation-K': 0.0060839245809632524,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8913318884590771,
 'loss_weight_Methylation-K': 0.17622390446891573,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1772991673,
 'sample_weights': [0.16483770550934265, 0.6034704617416917],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1136143506764293,
 'weight_decay_Hydroxylation-K': 0.9541667349377592,
 'weight_decay_Methylation-K': 0.7282147627898949}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.396
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031688554937817507,
 'learning_rate_Hydroxylation-K': 0.0038004984142561127,
 'learning_rate_Methylation-K': 0.0012037939306507892,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2233508137498622,
 'loss_weight_Methylation-K': 0.31882213138443327,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4277657992,
 'sample_weights': [0.8913318884590771, 0.17622390446891573],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.936808684116142,
 'weight_decay_Hydroxylation-K': 1.2833435680709089,
 'weight_decay_Methylation-K': 8.409595296175675}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.388
[3,     4] loss: 1.378
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008845567554648493,
 'learning_rate_Hydroxylation-K': 0.0021062579699659104,
 'learning_rate_Methylation-K': 0.0034806641072567743,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5654407878399274,
 'loss_weight_Methylation-K': 0.03593883236563591,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 726859927,
 'sample_weights': [0.2233508137498622, 0.31882213138443327],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.369629423516121,
 'weight_decay_Hydroxylation-K': 2.9462860390007783,
 'weight_decay_Methylation-K': 6.749519193299802}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.382
[3,     4] loss: 1.380
[4,     4] loss: 1.379
[5,     4] loss: 1.359
[6,     4] loss: 1.337
[7,     4] loss: 1.322
[8,     4] loss: 1.260
[9,     4] loss: 1.241
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009810668088437247,
 'learning_rate_Hydroxylation-K': 0.008724028960339303,
 'learning_rate_Methylation-K': 0.008633448601419708,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.005762869689448391,
 'loss_weight_Methylation-K': 0.12505649090201165,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 547643665,
 'sample_weights': [0.5654407878399274, 0.03593883236563591],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.952523864501251,
 'weight_decay_Hydroxylation-K': 9.52978722039465,
 'weight_decay_Methylation-K': 4.273268672180437}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.385
[3,     4] loss: 1.383
[4,     4] loss: 1.385
[5,     4] loss: 1.388
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008834524623552985,
 'learning_rate_Hydroxylation-K': 0.006890618815091926,
 'learning_rate_Methylation-K': 0.008880257562037024,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.652571941995201,
 'loss_weight_Methylation-K': 0.015552177388342678,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 373613913,
 'sample_weights': [0.005762869689448391, 0.12505649090201165],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.668613095544853,
 'weight_decay_Hydroxylation-K': 9.06199777939551,
 'weight_decay_Methylation-K': 6.80771631489506}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.387
[3,     4] loss: 1.388
[4,     4] loss: 1.386
[5,     4] loss: 1.388
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.387
[9,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017158982331378838,
 'learning_rate_Hydroxylation-K': 0.002541115500832793,
 'learning_rate_Methylation-K': 0.009700536389106895,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4452161976164079,
 'loss_weight_Methylation-K': 0.8847928324445544,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2952918273,
 'sample_weights': [0.652571941995201, 0.015552177388342678],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.65710311856327,
 'weight_decay_Hydroxylation-K': 7.999089385828474,
 'weight_decay_Methylation-K': 9.795813109128444}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.384
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 1.885459201870208e-05,
 'learning_rate_Hydroxylation-K': 0.0009143284021004465,
 'learning_rate_Methylation-K': 0.0013477416235931096,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.18298675370019118,
 'loss_weight_Methylation-K': 0.4561672673858238,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2117414209,
 'sample_weights': [0.4452161976164079, 0.8847928324445544],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.251217389798297,
 'weight_decay_Hydroxylation-K': 0.8280351507508328,
 'weight_decay_Methylation-K': 6.989677595708225}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.388
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00031210392414599475,
 'learning_rate_Hydroxylation-K': 0.003160587165956646,
 'learning_rate_Methylation-K': 0.006048976869090553,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.06150001849672055,
 'loss_weight_Methylation-K': 0.3646117261204373,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2223626631,
 'sample_weights': [0.18298675370019118, 0.4561672673858238],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.524095730904823,
 'weight_decay_Hydroxylation-K': 5.026144292704394,
 'weight_decay_Methylation-K': 7.833962803913866}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.385
[3,     4] loss: 1.383
[4,     4] loss: 1.384
[5,     4] loss: 1.381
[6,     4] loss: 1.377
[7,     4] loss: 1.379
[8,     4] loss: 1.371
[9,     4] loss: 1.365
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005613384752105393,
 'learning_rate_Hydroxylation-K': 0.0034238651124898533,
 'learning_rate_Methylation-K': 0.007258664957456985,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.16319406355672902,
 'loss_weight_Methylation-K': 0.7194552392275316,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2871711833,
 'sample_weights': [0.06150001849672055, 0.3646117261204373],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.062562261921447,
 'weight_decay_Hydroxylation-K': 5.018819993296705,
 'weight_decay_Methylation-K': 8.681285941952058}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.387
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020746717629861033,
 'learning_rate_Hydroxylation-K': 0.004823586187111247,
 'learning_rate_Methylation-K': 0.009645581910201685,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.07332959754620152,
 'loss_weight_Methylation-K': 0.9520308660464744,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1015387108,
 'sample_weights': [0.16319406355672902, 0.7194552392275316],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6159805980342137,
 'weight_decay_Hydroxylation-K': 6.270803881934052,
 'weight_decay_Methylation-K': 7.250325130557199}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.388
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016095164316920155,
 'learning_rate_Hydroxylation-K': 0.002967325167930605,
 'learning_rate_Methylation-K': 0.009777144248657905,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8116072447875973,
 'loss_weight_Methylation-K': 0.7930415180858192,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2950235773,
 'sample_weights': [0.07332959754620152, 0.9520308660464744],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7349784320845947,
 'weight_decay_Hydroxylation-K': 8.228053542843082,
 'weight_decay_Methylation-K': 1.0850923962918957}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.382
[5,     4] loss: 1.379
[6,     4] loss: 1.396
[7,     4] loss: 1.382
[8,     4] loss: 1.379
[9,     4] loss: 1.377
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004521446005148286,
 'learning_rate_Hydroxylation-K': 0.0038280561850935545,
 'learning_rate_Methylation-K': 0.009983299225642195,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.45883832391740376,
 'loss_weight_Methylation-K': 0.8969461078078657,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2742983674,
 'sample_weights': [0.8116072447875973, 0.7930415180858192],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.789413369754923,
 'weight_decay_Hydroxylation-K': 4.6607484913850605,
 'weight_decay_Methylation-K': 7.624731084851421}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.373
[2,     4] loss: 1.402
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006992508379164695,
 'learning_rate_Hydroxylation-K': 0.004588000103857941,
 'learning_rate_Methylation-K': 0.007954563777698691,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.25170565930019906,
 'loss_weight_Methylation-K': 0.911346842537661,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3521073176,
 'sample_weights': [0.45883832391740376, 0.8969461078078657],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.8286137637091398,
 'weight_decay_Hydroxylation-K': 9.59771983668676,
 'weight_decay_Methylation-K': 9.368748202675029}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.385
[3,     4] loss: 1.383
[4,     4] loss: 1.376
[5,     4] loss: 1.367
[6,     4] loss: 1.366
[7,     4] loss: 1.343
[8,     4] loss: 1.311
[9,     4] loss: 1.314
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009379829302259784,
 'learning_rate_Hydroxylation-K': 0.004145467645439339,
 'learning_rate_Methylation-K': 0.007231380588242454,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.02503627229768468,
 'loss_weight_Methylation-K': 0.06881928193706899,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1588531852,
 'sample_weights': [0.25170565930019906, 0.911346842537661],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.135135494633921,
 'weight_decay_Hydroxylation-K': 6.43462227981557,
 'weight_decay_Methylation-K': 9.536787914828107}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.390
[3,     4] loss: 1.389
[4,     4] loss: 1.388
[5,     4] loss: 1.388
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.387
[9,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004402683493064612,
 'learning_rate_Hydroxylation-K': 0.0009354219732525895,
 'learning_rate_Methylation-K': 0.0014474018125749041,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.36178078138075476,
 'loss_weight_Methylation-K': 0.9917346151796319,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 475888649,
 'sample_weights': [0.02503627229768468, 0.06881928193706899],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.333314424794768,
 'weight_decay_Hydroxylation-K': 8.505445808274867,
 'weight_decay_Methylation-K': 3.435049964782253}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.387
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002531002608037358,
 'learning_rate_Hydroxylation-K': 0.00559997584591725,
 'learning_rate_Methylation-K': 0.005029837063344562,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6320729416131761,
 'loss_weight_Methylation-K': 0.7806532557873712,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1956452662,
 'sample_weights': [0.36178078138075476, 0.9917346151796319],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.9852865221620295,
 'weight_decay_Hydroxylation-K': 3.510700885774942,
 'weight_decay_Methylation-K': 7.925310734449422}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.386
[3,     4] loss: 1.383
[4,     4] loss: 1.383
[5,     4] loss: 1.386
[6,     4] loss: 1.377
[7,     4] loss: 1.367
[8,     4] loss: 1.333
[9,     4] loss: 1.294
[10,     4] loss: 1.236
[11,     4] loss: 1.206
[12,     4] loss: 1.187
[13,     4] loss: 1.119
[14,     4] loss: 1.108
[15,     4] loss: 1.121
[16,     4] loss: 1.000
[17,     4] loss: 0.947
[18,     4] loss: 1.031
[19,     4] loss: 1.111
[20,     4] loss: 1.017
[21,     4] loss: 0.979
[22,     4] loss: 0.916
[23,     4] loss: 0.996
[24,     4] loss: 0.966
[25,     4] loss: 0.918
[26,     4] loss: 0.886
[27,     4] loss: 0.853
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0021438594381792595,
 'learning_rate_Hydroxylation-K': 0.0017919730928819644,
 'learning_rate_Methylation-K': 0.003585363435375242,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6928735917155555,
 'loss_weight_Methylation-K': 0.8269345518920997,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2289875490,
 'sample_weights': [0.6320729416131761, 0.7806532557873712],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.270967846366539,
 'weight_decay_Hydroxylation-K': 9.119324291996284,
 'weight_decay_Methylation-K': 0.7671850577807666}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.390
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001777229078208452,
 'learning_rate_Hydroxylation-K': 0.003667104666587343,
 'learning_rate_Methylation-K': 0.0061436464900848356,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5810423364687691,
 'loss_weight_Methylation-K': 0.7240931915653736,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4082638986,
 'sample_weights': [0.6928735917155555, 0.8269345518920997],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.775268048716969,
 'weight_decay_Hydroxylation-K': 8.297435737009556,
 'weight_decay_Methylation-K': 5.328476200039079}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.385
[3,     4] loss: 1.385
[4,     4] loss: 1.374
[5,     4] loss: 1.358
[6,     4] loss: 1.327
[7,     4] loss: 1.308
[8,     4] loss: 1.229
[9,     4] loss: 1.257
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037451986834095797,
 'learning_rate_Hydroxylation-K': 0.005851197486053385,
 'learning_rate_Methylation-K': 0.004462527745095751,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6867009836906645,
 'loss_weight_Methylation-K': 0.8406958458513778,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 757786517,
 'sample_weights': [0.5810423364687691, 0.7240931915653736],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.723185930411379,
 'weight_decay_Hydroxylation-K': 2.1541017971787917,
 'weight_decay_Methylation-K': 9.43970924817664}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.408
[2,     4] loss: 1.393
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00046938495604922047,
 'learning_rate_Hydroxylation-K': 0.007005689721575703,
 'learning_rate_Methylation-K': 0.003712643427921845,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5273106287661763,
 'loss_weight_Methylation-K': 0.6476250867712712,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1898077071,
 'sample_weights': [0.6867009836906645, 0.8406958458513778],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.964131914380629,
 'weight_decay_Hydroxylation-K': 4.9450311617233,
 'weight_decay_Methylation-K': 8.129460318837795}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.390
[3,     4] loss: 1.377
[4,     4] loss: 1.382
[5,     4] loss: 1.382
[6,     4] loss: 1.379
[7,     4] loss: 1.369
[8,     4] loss: 1.362
[9,     4] loss: 1.324
[10,     4] loss: 1.316
[11,     4] loss: 1.287
[12,     4] loss: 1.276
[13,     4] loss: 1.202
[14,     4] loss: 1.192
[15,     4] loss: 1.163
[16,     4] loss: 1.125
[17,     4] loss: 1.058
[18,     4] loss: 1.023
[19,     4] loss: 1.098
[20,     4] loss: 1.043
[21,     4] loss: 1.007
[22,     4] loss: 1.010
[23,     4] loss: 0.938
[24,     4] loss: 0.945
[25,     4] loss: 0.947
[26,     4] loss: 0.919
[27,     4] loss: 0.881
[28,     4] loss: 0.901
[29,     4] loss: 0.868
[30,     4] loss: 0.878
[31,     4] loss: 0.909
[32,     4] loss: 0.846
[33,     4] loss: 0.879
[34,     4] loss: 0.882
[35,     4] loss: 0.841
[36,     4] loss: 0.850
[37,     4] loss: 0.852
[38,     4] loss: 0.861
[39,     4] loss: 0.866
[40,     4] loss: 0.894
[41,     4] loss: 0.885
[42,     4] loss: 0.873
[43,     4] loss: 0.864
[44,     4] loss: 0.804
[45,     4] loss: 0.837
[46,     4] loss: 0.816
[47,     4] loss: 0.818
[48,     4] loss: 0.816
[49,     4] loss: 0.798
[50,     4] loss: 0.816
[51,     4] loss: 0.773
[52,     4] loss: 0.782
[53,     4] loss: 0.768
[54,     4] loss: 0.767
[55,     4] loss: 0.750
[56,     4] loss: 0.753
[57,     4] loss: 0.730
[58,     4] loss: 0.740
[59,     4] loss: 0.743
[60,     4] loss: 0.734
[61,     4] loss: 0.736
[62,     4] loss: 0.752
[63,     4] loss: 0.730
[64,     4] loss: 0.729
[65,     4] loss: 0.728
Early stopping applied (best metric=0.35703083872795105)
Finished Training
Total time taken: 34.56753754615784
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.386
[3,     4] loss: 1.391
[4,     4] loss: 1.383
[5,     4] loss: 1.380
[6,     4] loss: 1.378
[7,     4] loss: 1.370
[8,     4] loss: 1.366
[9,     4] loss: 1.347
[10,     4] loss: 1.333
[11,     4] loss: 1.315
[12,     4] loss: 1.280
[13,     4] loss: 1.252
[14,     4] loss: 1.209
[15,     4] loss: 1.203
[16,     4] loss: 1.135
[17,     4] loss: 1.100
[18,     4] loss: 1.108
[19,     4] loss: 1.102
[20,     4] loss: 1.044
[21,     4] loss: 0.974
[22,     4] loss: 0.941
[23,     4] loss: 0.914
[24,     4] loss: 0.963
[25,     4] loss: 0.901
[26,     4] loss: 0.938
[27,     4] loss: 0.916
[28,     4] loss: 0.979
[29,     4] loss: 0.998
[30,     4] loss: 0.906
[31,     4] loss: 0.878
[32,     4] loss: 0.888
[33,     4] loss: 0.836
[34,     4] loss: 0.846
[35,     4] loss: 0.802
[36,     4] loss: 0.818
[37,     4] loss: 0.830
[38,     4] loss: 0.797
[39,     4] loss: 0.771
[40,     4] loss: 0.804
[41,     4] loss: 0.774
[42,     4] loss: 0.776
[43,     4] loss: 0.755
[44,     4] loss: 0.851
[45,     4] loss: 0.860
[46,     4] loss: 0.819
[47,     4] loss: 0.810
[48,     4] loss: 0.756
[49,     4] loss: 0.765
[50,     4] loss: 0.753
[51,     4] loss: 0.741
[52,     4] loss: 0.758
[53,     4] loss: 0.749
[54,     4] loss: 0.737
[55,     4] loss: 0.742
[56,     4] loss: 0.743
[57,     4] loss: 0.760
[58,     4] loss: 0.741
[59,     4] loss: 0.729
[60,     4] loss: 0.744
[61,     4] loss: 0.730
[62,     4] loss: 0.735
[63,     4] loss: 0.721
[64,     4] loss: 0.714
[65,     4] loss: 0.707
[66,     4] loss: 0.720
[67,     4] loss: 0.710
[68,     4] loss: 0.726
[69,     4] loss: 0.748
[70,     4] loss: 0.691
[71,     4] loss: 0.728
[72,     4] loss: 0.742
[73,     4] loss: 0.736
Early stopping applied (best metric=0.3121805787086487)
Finished Training
Total time taken: 40.56922459602356
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.388
[3,     4] loss: 1.385
[4,     4] loss: 1.382
[5,     4] loss: 1.379
[6,     4] loss: 1.381
[7,     4] loss: 1.378
[8,     4] loss: 1.363
[9,     4] loss: 1.353
[10,     4] loss: 1.329
[11,     4] loss: 1.320
[12,     4] loss: 1.297
[13,     4] loss: 1.265
[14,     4] loss: 1.237
[15,     4] loss: 1.232
[16,     4] loss: 1.166
[17,     4] loss: 1.167
[18,     4] loss: 1.097
[19,     4] loss: 1.042
[20,     4] loss: 1.048
[21,     4] loss: 0.978
[22,     4] loss: 1.025
[23,     4] loss: 0.959
[24,     4] loss: 0.939
[25,     4] loss: 0.870
[26,     4] loss: 0.920
[27,     4] loss: 0.932
[28,     4] loss: 0.839
[29,     4] loss: 0.801
[30,     4] loss: 0.837
[31,     4] loss: 0.800
[32,     4] loss: 0.812
[33,     4] loss: 0.828
[34,     4] loss: 0.795
[35,     4] loss: 0.787
[36,     4] loss: 0.808
[37,     4] loss: 0.842
[38,     4] loss: 0.854
[39,     4] loss: 0.828
[40,     4] loss: 0.794
[41,     4] loss: 0.791
[42,     4] loss: 0.751
[43,     4] loss: 0.755
[44,     4] loss: 0.774
[45,     4] loss: 0.788
[46,     4] loss: 0.760
[47,     4] loss: 0.746
[48,     4] loss: 0.742
[49,     4] loss: 0.749
[50,     4] loss: 0.749
[51,     4] loss: 0.753
[52,     4] loss: 0.732
[53,     4] loss: 0.748
[54,     4] loss: 0.749
[55,     4] loss: 0.725
[56,     4] loss: 0.755
[57,     4] loss: 0.737
[58,     4] loss: 0.778
[59,     4] loss: 0.746
[60,     4] loss: 0.755
[61,     4] loss: 0.731
[62,     4] loss: 0.761
[63,     4] loss: 0.749
[64,     4] loss: 0.747
[65,     4] loss: 0.742
[66,     4] loss: 0.753
Early stopping applied (best metric=0.4423052668571472)
Finished Training
Total time taken: 37.56105947494507
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.384
[3,     4] loss: 1.384
[4,     4] loss: 1.383
[5,     4] loss: 1.380
[6,     4] loss: 1.378
[7,     4] loss: 1.371
[8,     4] loss: 1.361
[9,     4] loss: 1.345
[10,     4] loss: 1.309
[11,     4] loss: 1.282
[12,     4] loss: 1.258
[13,     4] loss: 1.221
[14,     4] loss: 1.164
[15,     4] loss: 1.083
[16,     4] loss: 1.078
[17,     4] loss: 1.091
[18,     4] loss: 1.000
[19,     4] loss: 1.012
[20,     4] loss: 0.943
[21,     4] loss: 0.882
[22,     4] loss: 0.904
[23,     4] loss: 0.909
[24,     4] loss: 0.858
[25,     4] loss: 0.910
[26,     4] loss: 0.879
[27,     4] loss: 0.862
[28,     4] loss: 0.839
[29,     4] loss: 0.865
[30,     4] loss: 0.840
[31,     4] loss: 0.851
[32,     4] loss: 0.806
[33,     4] loss: 0.809
[34,     4] loss: 0.799
[35,     4] loss: 0.774
[36,     4] loss: 0.824
[37,     4] loss: 0.828
[38,     4] loss: 0.841
[39,     4] loss: 0.823
[40,     4] loss: 0.793
[41,     4] loss: 0.758
[42,     4] loss: 0.784
[43,     4] loss: 0.806
[44,     4] loss: 0.771
[45,     4] loss: 0.790
[46,     4] loss: 0.752
[47,     4] loss: 0.792
[48,     4] loss: 0.760
[49,     4] loss: 0.747
[50,     4] loss: 0.721
[51,     4] loss: 0.720
[52,     4] loss: 0.746
[53,     4] loss: 0.751
[54,     4] loss: 0.770
[55,     4] loss: 0.750
[56,     4] loss: 0.765
[57,     4] loss: 0.734
[58,     4] loss: 0.726
[59,     4] loss: 0.731
[60,     4] loss: 0.730
Early stopping applied (best metric=0.5136480331420898)
Finished Training
Total time taken: 34.79371380805969
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.386
[2,     4] loss: 1.389
[3,     4] loss: 1.384
[4,     4] loss: 1.383
[5,     4] loss: 1.386
[6,     4] loss: 1.380
[7,     4] loss: 1.383
[8,     4] loss: 1.376
[9,     4] loss: 1.364
[10,     4] loss: 1.353
[11,     4] loss: 1.337
[12,     4] loss: 1.314
[13,     4] loss: 1.288
[14,     4] loss: 1.261
[15,     4] loss: 1.184
[16,     4] loss: 1.129
[17,     4] loss: 1.091
[18,     4] loss: 1.064
[19,     4] loss: 1.065
[20,     4] loss: 1.030
[21,     4] loss: 0.999
[22,     4] loss: 1.001
[23,     4] loss: 0.976
[24,     4] loss: 1.001
[25,     4] loss: 0.954
[26,     4] loss: 0.929
[27,     4] loss: 0.863
[28,     4] loss: 0.932
[29,     4] loss: 0.873
[30,     4] loss: 0.882
[31,     4] loss: 0.899
[32,     4] loss: 0.862
[33,     4] loss: 0.839
[34,     4] loss: 0.880
[35,     4] loss: 0.817
[36,     4] loss: 0.861
[37,     4] loss: 0.779
[38,     4] loss: 0.789
[39,     4] loss: 0.860
[40,     4] loss: 0.802
[41,     4] loss: 0.780
[42,     4] loss: 0.783
[43,     4] loss: 0.772
[44,     4] loss: 0.748
[45,     4] loss: 0.745
[46,     4] loss: 0.760
[47,     4] loss: 0.764
[48,     4] loss: 0.747
[49,     4] loss: 0.748
[50,     4] loss: 0.758
[51,     4] loss: 0.805
[52,     4] loss: 0.733
[53,     4] loss: 0.793
[54,     4] loss: 0.767
[55,     4] loss: 0.762
[56,     4] loss: 0.779
[57,     4] loss: 0.770
[58,     4] loss: 0.778
[59,     4] loss: 0.742
[60,     4] loss: 0.777
[61,     4] loss: 0.760
[62,     4] loss: 0.770
[63,     4] loss: 0.768
[64,     4] loss: 0.758
[65,     4] loss: 0.764
[66,     4] loss: 0.732
Early stopping applied (best metric=0.3877660036087036)
Finished Training
Total time taken: 37.44233274459839
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.399
[2,     4] loss: 1.387
[3,     4] loss: 1.385
[4,     4] loss: 1.382
[5,     4] loss: 1.377
[6,     4] loss: 1.377
[7,     4] loss: 1.362
[8,     4] loss: 1.350
[9,     4] loss: 1.332
[10,     4] loss: 1.317
[11,     4] loss: 1.304
[12,     4] loss: 1.291
[13,     4] loss: 1.236
[14,     4] loss: 1.186
[15,     4] loss: 1.149
[16,     4] loss: 1.147
[17,     4] loss: 1.084
[18,     4] loss: 1.064
[19,     4] loss: 1.051
[20,     4] loss: 1.021
[21,     4] loss: 0.989
[22,     4] loss: 0.942
[23,     4] loss: 0.986
[24,     4] loss: 0.948
[25,     4] loss: 1.023
[26,     4] loss: 0.870
[27,     4] loss: 0.906
[28,     4] loss: 0.874
[29,     4] loss: 0.852
[30,     4] loss: 0.798
[31,     4] loss: 0.797
[32,     4] loss: 0.797
[33,     4] loss: 0.772
[34,     4] loss: 0.768
[35,     4] loss: 0.798
[36,     4] loss: 0.766
[37,     4] loss: 0.757
[38,     4] loss: 0.759
[39,     4] loss: 0.760
[40,     4] loss: 0.749
[41,     4] loss: 0.752
[42,     4] loss: 0.737
[43,     4] loss: 0.736
[44,     4] loss: 0.755
[45,     4] loss: 0.833
[46,     4] loss: 0.729
[47,     4] loss: 0.794
[48,     4] loss: 0.774
[49,     4] loss: 0.789
[50,     4] loss: 0.761
[51,     4] loss: 0.744
[52,     4] loss: 0.734
[53,     4] loss: 0.735
[54,     4] loss: 0.720
[55,     4] loss: 0.734
[56,     4] loss: 0.732
[57,     4] loss: 0.732
[58,     4] loss: 0.734
[59,     4] loss: 0.726
[60,     4] loss: 0.713
[61,     4] loss: 0.723
[62,     4] loss: 0.705
[63,     4] loss: 0.718
[64,     4] loss: 0.695
[65,     4] loss: 0.705
[66,     4] loss: 0.716
[67,     4] loss: 0.707
[68,     4] loss: 0.716
[69,     4] loss: 0.693
[70,     4] loss: 0.694
Early stopping applied (best metric=0.35069140791893005)
Finished Training
Total time taken: 40.905282735824585
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.385
[3,     4] loss: 1.383
[4,     4] loss: 1.384
[5,     4] loss: 1.375
[6,     4] loss: 1.372
[7,     4] loss: 1.365
[8,     4] loss: 1.348
[9,     4] loss: 1.334
[10,     4] loss: 1.303
[11,     4] loss: 1.288
[12,     4] loss: 1.271
[13,     4] loss: 1.224
[14,     4] loss: 1.227
[15,     4] loss: 1.179
[16,     4] loss: 1.174
[17,     4] loss: 1.108
[18,     4] loss: 1.112
[19,     4] loss: 1.034
[20,     4] loss: 1.045
[21,     4] loss: 1.046
[22,     4] loss: 1.004
[23,     4] loss: 1.038
[24,     4] loss: 0.998
[25,     4] loss: 0.956
[26,     4] loss: 0.906
[27,     4] loss: 0.982
[28,     4] loss: 0.897
[29,     4] loss: 0.908
[30,     4] loss: 0.930
[31,     4] loss: 0.943
[32,     4] loss: 0.834
[33,     4] loss: 0.890
[34,     4] loss: 0.830
[35,     4] loss: 0.870
[36,     4] loss: 0.830
[37,     4] loss: 0.795
[38,     4] loss: 0.828
[39,     4] loss: 0.789
[40,     4] loss: 0.853
[41,     4] loss: 0.840
[42,     4] loss: 0.793
[43,     4] loss: 0.779
[44,     4] loss: 0.777
[45,     4] loss: 0.772
[46,     4] loss: 0.769
[47,     4] loss: 0.799
[48,     4] loss: 0.775
[49,     4] loss: 0.811
[50,     4] loss: 0.769
[51,     4] loss: 0.835
[52,     4] loss: 0.807
[53,     4] loss: 0.769
[54,     4] loss: 0.781
[55,     4] loss: 0.774
[56,     4] loss: 0.735
[57,     4] loss: 0.746
[58,     4] loss: 0.759
[59,     4] loss: 0.738
[60,     4] loss: 0.739
[61,     4] loss: 0.741
[62,     4] loss: 0.723
[63,     4] loss: 0.770
[64,     4] loss: 0.740
[65,     4] loss: 0.740
[66,     4] loss: 0.759
[67,     4] loss: 0.769
[68,     4] loss: 0.781
[69,     4] loss: 0.781
[70,     4] loss: 0.763
[71,     4] loss: 0.760
[72,     4] loss: 0.755
[73,     4] loss: 0.739
[74,     4] loss: 0.740
[75,     4] loss: 0.725
[76,     4] loss: 0.741
[77,     4] loss: 0.719
[78,     4] loss: 0.729
[79,     4] loss: 0.723
[80,     4] loss: 0.718
[81,     4] loss: 0.727
[82,     4] loss: 0.736
[83,     4] loss: 0.737
[84,     4] loss: 0.736
[85,     4] loss: 0.725
[86,     4] loss: 0.730
[87,     4] loss: 0.732
[88,     4] loss: 0.733
[89,     4] loss: 0.728
[90,     4] loss: 0.722
[91,     4] loss: 0.719
[92,     4] loss: 0.726
[93,     4] loss: 0.723
[94,     4] loss: 0.733
[95,     4] loss: 0.714
[96,     4] loss: 0.721
[97,     4] loss: 0.723
[98,     4] loss: 0.742
[99,     4] loss: 0.732
[100,     4] loss: 0.732
[101,     4] loss: 0.736
[102,     4] loss: 0.728
[103,     4] loss: 0.723
[104,     4] loss: 0.711
Early stopping applied (best metric=0.30968841910362244)
Finished Training
Total time taken: 57.86388182640076
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.386
[3,     4] loss: 1.386
[4,     4] loss: 1.389
[5,     4] loss: 1.381
[6,     4] loss: 1.380
[7,     4] loss: 1.376
[8,     4] loss: 1.366
[9,     4] loss: 1.355
[10,     4] loss: 1.326
[11,     4] loss: 1.298
[12,     4] loss: 1.275
[13,     4] loss: 1.261
[14,     4] loss: 1.223
[15,     4] loss: 1.196
[16,     4] loss: 1.132
[17,     4] loss: 1.080
[18,     4] loss: 1.057
[19,     4] loss: 1.017
[20,     4] loss: 0.982
[21,     4] loss: 0.937
[22,     4] loss: 0.929
[23,     4] loss: 0.908
[24,     4] loss: 0.866
[25,     4] loss: 0.874
[26,     4] loss: 0.863
[27,     4] loss: 0.934
[28,     4] loss: 0.850
[29,     4] loss: 0.829
[30,     4] loss: 0.795
[31,     4] loss: 0.801
[32,     4] loss: 0.802
[33,     4] loss: 0.799
[34,     4] loss: 0.784
[35,     4] loss: 0.780
[36,     4] loss: 0.778
[37,     4] loss: 0.786
[38,     4] loss: 0.759
[39,     4] loss: 0.803
[40,     4] loss: 0.757
[41,     4] loss: 0.795
[42,     4] loss: 0.750
[43,     4] loss: 0.751
[44,     4] loss: 0.732
[45,     4] loss: 0.749
[46,     4] loss: 0.741
[47,     4] loss: 0.736
[48,     4] loss: 0.782
[49,     4] loss: 0.758
[50,     4] loss: 0.754
[51,     4] loss: 0.742
[52,     4] loss: 0.761
[53,     4] loss: 0.772
[54,     4] loss: 0.733
[55,     4] loss: 0.745
[56,     4] loss: 0.766
[57,     4] loss: 0.776
[58,     4] loss: 0.793
[59,     4] loss: 0.740
[60,     4] loss: 0.796
[61,     4] loss: 0.742
Early stopping applied (best metric=0.5323981046676636)
Finished Training
Total time taken: 33.26976656913757
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.385
[3,     4] loss: 1.386
[4,     4] loss: 1.382
[5,     4] loss: 1.378
[6,     4] loss: 1.374
[7,     4] loss: 1.362
[8,     4] loss: 1.348
[9,     4] loss: 1.322
[10,     4] loss: 1.285
[11,     4] loss: 1.269
[12,     4] loss: 1.209
[13,     4] loss: 1.207
[14,     4] loss: 1.186
[15,     4] loss: 1.153
[16,     4] loss: 1.118
[17,     4] loss: 1.031
[18,     4] loss: 0.995
[19,     4] loss: 0.989
[20,     4] loss: 0.958
[21,     4] loss: 0.988
[22,     4] loss: 0.926
[23,     4] loss: 0.903
[24,     4] loss: 0.911
[25,     4] loss: 0.915
[26,     4] loss: 0.895
[27,     4] loss: 0.989
[28,     4] loss: 0.883
[29,     4] loss: 0.861
[30,     4] loss: 0.875
[31,     4] loss: 0.842
[32,     4] loss: 0.885
[33,     4] loss: 0.901
[34,     4] loss: 0.819
[35,     4] loss: 0.851
[36,     4] loss: 0.801
[37,     4] loss: 0.822
[38,     4] loss: 0.825
[39,     4] loss: 0.825
[40,     4] loss: 0.794
[41,     4] loss: 0.795
[42,     4] loss: 0.772
[43,     4] loss: 0.779
[44,     4] loss: 0.761
[45,     4] loss: 0.766
[46,     4] loss: 0.763
[47,     4] loss: 0.799
[48,     4] loss: 0.776
[49,     4] loss: 0.780
[50,     4] loss: 0.764
[51,     4] loss: 0.761
[52,     4] loss: 0.750
[53,     4] loss: 0.750
[54,     4] loss: 0.750
[55,     4] loss: 0.761
[56,     4] loss: 0.734
[57,     4] loss: 0.758
[58,     4] loss: 0.735
[59,     4] loss: 0.724
[60,     4] loss: 0.742
[61,     4] loss: 0.731
Early stopping applied (best metric=0.4871765673160553)
Finished Training
Total time taken: 34.81676411628723
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.387
[2,     4] loss: 1.384
[3,     4] loss: 1.384
[4,     4] loss: 1.385
[5,     4] loss: 1.378
[6,     4] loss: 1.374
[7,     4] loss: 1.367
[8,     4] loss: 1.350
[9,     4] loss: 1.323
[10,     4] loss: 1.293
[11,     4] loss: 1.299
[12,     4] loss: 1.247
[13,     4] loss: 1.273
[14,     4] loss: 1.190
[15,     4] loss: 1.159
[16,     4] loss: 1.102
[17,     4] loss: 1.100
[18,     4] loss: 0.995
[19,     4] loss: 1.065
[20,     4] loss: 0.991
[21,     4] loss: 0.947
[22,     4] loss: 0.962
[23,     4] loss: 0.905
[24,     4] loss: 0.862
[25,     4] loss: 0.877
[26,     4] loss: 0.870
[27,     4] loss: 0.841
[28,     4] loss: 0.792
[29,     4] loss: 0.793
[30,     4] loss: 0.808
[31,     4] loss: 0.814
[32,     4] loss: 0.795
[33,     4] loss: 0.763
[34,     4] loss: 0.790
[35,     4] loss: 0.809
[36,     4] loss: 0.797
[37,     4] loss: 0.780
[38,     4] loss: 0.771
[39,     4] loss: 0.793
[40,     4] loss: 0.801
[41,     4] loss: 0.735
[42,     4] loss: 0.803
[43,     4] loss: 0.800
[44,     4] loss: 0.751
[45,     4] loss: 0.764
[46,     4] loss: 0.804
[47,     4] loss: 0.763
[48,     4] loss: 0.760
[49,     4] loss: 0.748
[50,     4] loss: 0.760
[51,     4] loss: 0.726
[52,     4] loss: 0.748
[53,     4] loss: 0.731
[54,     4] loss: 0.730
[55,     4] loss: 0.765
[56,     4] loss: 0.753
[57,     4] loss: 0.729
[58,     4] loss: 0.737
[59,     4] loss: 0.732
[60,     4] loss: 0.741
[61,     4] loss: 0.734
[62,     4] loss: 0.756
[63,     4] loss: 0.745
[64,     4] loss: 0.739
[65,     4] loss: 0.781
Early stopping applied (best metric=0.5162193179130554)
Finished Training
Total time taken: 35.45345187187195
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.386
[3,     4] loss: 1.387
[4,     4] loss: 1.381
[5,     4] loss: 1.386
[6,     4] loss: 1.378
[7,     4] loss: 1.376
[8,     4] loss: 1.364
[9,     4] loss: 1.348
[10,     4] loss: 1.325
[11,     4] loss: 1.325
[12,     4] loss: 1.305
[13,     4] loss: 1.264
[14,     4] loss: 1.230
[15,     4] loss: 1.207
[16,     4] loss: 1.138
[17,     4] loss: 1.113
[18,     4] loss: 1.118
[19,     4] loss: 1.047
[20,     4] loss: 1.007
[21,     4] loss: 0.994
[22,     4] loss: 1.036
[23,     4] loss: 0.926
[24,     4] loss: 0.948
[25,     4] loss: 0.916
[26,     4] loss: 0.808
[27,     4] loss: 0.891
[28,     4] loss: 0.877
[29,     4] loss: 0.871
[30,     4] loss: 0.843
[31,     4] loss: 0.864
[32,     4] loss: 0.860
[33,     4] loss: 0.852
[34,     4] loss: 0.879
[35,     4] loss: 0.886
[36,     4] loss: 0.838
[37,     4] loss: 0.860
[38,     4] loss: 0.798
[39,     4] loss: 0.796
[40,     4] loss: 0.780
[41,     4] loss: 0.798
[42,     4] loss: 0.797
[43,     4] loss: 0.773
[44,     4] loss: 0.755
[45,     4] loss: 0.753
[46,     4] loss: 0.752
[47,     4] loss: 0.786
[48,     4] loss: 0.772
[49,     4] loss: 0.812
[50,     4] loss: 0.773
[51,     4] loss: 0.762
[52,     4] loss: 0.753
[53,     4] loss: 0.735
[54,     4] loss: 0.746
[55,     4] loss: 0.765
[56,     4] loss: 0.773
[57,     4] loss: 0.752
[58,     4] loss: 0.731
[59,     4] loss: 0.728
[60,     4] loss: 0.741
[61,     4] loss: 0.754
[62,     4] loss: 0.733
[63,     4] loss: 0.725
[64,     4] loss: 0.731
[65,     4] loss: 0.734
[66,     4] loss: 0.750
[67,     4] loss: 0.754
[68,     4] loss: 0.712
[69,     4] loss: 0.737
[70,     4] loss: 0.724
[71,     4] loss: 0.737
[72,     4] loss: 0.750
[73,     4] loss: 0.725
[74,     4] loss: 0.722
[75,     4] loss: 0.728
[76,     4] loss: 0.724
[77,     4] loss: 0.722
[78,     4] loss: 0.717
[79,     4] loss: 0.712
[80,     4] loss: 0.730
[81,     4] loss: 0.712
[82,     4] loss: 0.710
[83,     4] loss: 0.712
[84,     4] loss: 0.712
[85,     4] loss: 0.733
[86,     4] loss: 0.733
[87,     4] loss: 0.738
[88,     4] loss: 0.718
[89,     4] loss: 0.705
[90,     4] loss: 0.722
[91,     4] loss: 0.732
[92,     4] loss: 0.722
[93,     4] loss: 0.729
[94,     4] loss: 0.701
[95,     4] loss: 0.725
[96,     4] loss: 0.734
[97,     4] loss: 0.720
[98,     4] loss: 0.717
[99,     4] loss: 0.699
[100,     4] loss: 0.701
[101,     4] loss: 0.710
[102,     4] loss: 0.701
[103,     4] loss: 0.686
[104,     4] loss: 0.692
[105,     4] loss: 0.720
[106,     4] loss: 0.699
[107,     4] loss: 0.717
[108,     4] loss: 0.738
[109,     4] loss: 0.728
[110,     4] loss: 0.724
[111,     4] loss: 0.731
[112,     4] loss: 0.739
[113,     4] loss: 0.717
[114,     4] loss: 0.707
[115,     4] loss: 0.699
[116,     4] loss: 0.694
[117,     4] loss: 0.705
[118,     4] loss: 0.698
[119,     4] loss: 0.705
[120,     4] loss: 0.694
[121,     4] loss: 0.687
[122,     4] loss: 0.689
[123,     4] loss: 0.690
[124,     4] loss: 0.697
[125,     4] loss: 0.700
[126,     4] loss: 0.699
[127,     4] loss: 0.689
[128,     4] loss: 0.698
[129,     4] loss: 0.713
Early stopping applied (best metric=0.2773047089576721)
Finished Training
Total time taken: 76.45465731620789
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.403
[2,     4] loss: 1.384
[3,     4] loss: 1.386
[4,     4] loss: 1.382
[5,     4] loss: 1.386
[6,     4] loss: 1.383
[7,     4] loss: 1.378
[8,     4] loss: 1.371
[9,     4] loss: 1.360
[10,     4] loss: 1.350
[11,     4] loss: 1.330
[12,     4] loss: 1.296
[13,     4] loss: 1.285
[14,     4] loss: 1.246
[15,     4] loss: 1.216
[16,     4] loss: 1.178
[17,     4] loss: 1.131
[18,     4] loss: 1.091
[19,     4] loss: 1.095
[20,     4] loss: 1.022
[21,     4] loss: 1.025
[22,     4] loss: 0.967
[23,     4] loss: 0.944
[24,     4] loss: 0.961
[25,     4] loss: 0.932
[26,     4] loss: 0.930
[27,     4] loss: 0.862
[28,     4] loss: 0.854
[29,     4] loss: 0.850
[30,     4] loss: 0.846
[31,     4] loss: 0.861
[32,     4] loss: 0.778
[33,     4] loss: 0.803
[34,     4] loss: 0.792
[35,     4] loss: 0.779
[36,     4] loss: 0.788
[37,     4] loss: 0.785
[38,     4] loss: 0.743
[39,     4] loss: 0.741
[40,     4] loss: 0.779
[41,     4] loss: 0.738
[42,     4] loss: 0.775
[43,     4] loss: 0.774
[44,     4] loss: 0.770
[45,     4] loss: 0.749
[46,     4] loss: 0.751
[47,     4] loss: 0.733
[48,     4] loss: 0.763
[49,     4] loss: 0.727
[50,     4] loss: 0.720
[51,     4] loss: 0.707
[52,     4] loss: 0.724
[53,     4] loss: 0.699
[54,     4] loss: 0.725
[55,     4] loss: 0.693
[56,     4] loss: 0.682
[57,     4] loss: 0.686
[58,     4] loss: 0.691
[59,     4] loss: 0.681
[60,     4] loss: 0.701
[61,     4] loss: 0.693
[62,     4] loss: 0.684
[63,     4] loss: 0.675
[64,     4] loss: 0.691
[65,     4] loss: 0.684
[66,     4] loss: 0.686
[67,     4] loss: 0.690
[68,     4] loss: 0.701
[69,     4] loss: 0.679
[70,     4] loss: 0.680
[71,     4] loss: 0.675
[72,     4] loss: 0.698
Early stopping applied (best metric=0.35815200209617615)
Finished Training
Total time taken: 38.062023639678955
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.387
[3,     4] loss: 1.382
[4,     4] loss: 1.382
[5,     4] loss: 1.377
[6,     4] loss: 1.377
[7,     4] loss: 1.365
[8,     4] loss: 1.353
[9,     4] loss: 1.334
[10,     4] loss: 1.294
[11,     4] loss: 1.286
[12,     4] loss: 1.248
[13,     4] loss: 1.228
[14,     4] loss: 1.205
[15,     4] loss: 1.146
[16,     4] loss: 1.127
[17,     4] loss: 1.104
[18,     4] loss: 1.051
[19,     4] loss: 1.033
[20,     4] loss: 0.949
[21,     4] loss: 0.904
[22,     4] loss: 0.914
[23,     4] loss: 0.927
[24,     4] loss: 0.850
[25,     4] loss: 0.879
[26,     4] loss: 0.825
[27,     4] loss: 0.808
[28,     4] loss: 0.817
[29,     4] loss: 0.838
[30,     4] loss: 0.814
[31,     4] loss: 0.868
[32,     4] loss: 0.854
[33,     4] loss: 0.797
[34,     4] loss: 0.797
[35,     4] loss: 0.752
[36,     4] loss: 0.752
[37,     4] loss: 0.785
[38,     4] loss: 0.783
[39,     4] loss: 0.803
[40,     4] loss: 0.762
[41,     4] loss: 0.742
[42,     4] loss: 0.753
[43,     4] loss: 0.737
[44,     4] loss: 0.759
[45,     4] loss: 0.711
[46,     4] loss: 0.717
[47,     4] loss: 0.740
[48,     4] loss: 0.703
[49,     4] loss: 0.705
[50,     4] loss: 0.734
[51,     4] loss: 0.700
[52,     4] loss: 0.718
[53,     4] loss: 0.736
[54,     4] loss: 0.719
[55,     4] loss: 0.712
[56,     4] loss: 0.711
[57,     4] loss: 0.696
[58,     4] loss: 0.718
[59,     4] loss: 0.710
[60,     4] loss: 0.695
[61,     4] loss: 0.691
[62,     4] loss: 0.710
[63,     4] loss: 0.680
[64,     4] loss: 0.694
[65,     4] loss: 0.693
Early stopping applied (best metric=0.47316980361938477)
Finished Training
Total time taken: 34.141037702560425
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.379
[3,     4] loss: 1.386
[4,     4] loss: 1.382
[5,     4] loss: 1.387
[6,     4] loss: 1.383
[7,     4] loss: 1.380
[8,     4] loss: 1.370
[9,     4] loss: 1.361
[10,     4] loss: 1.352
[11,     4] loss: 1.322
[12,     4] loss: 1.309
[13,     4] loss: 1.303
[14,     4] loss: 1.258
[15,     4] loss: 1.188
[16,     4] loss: 1.189
[17,     4] loss: 1.122
[18,     4] loss: 1.098
[19,     4] loss: 1.039
[20,     4] loss: 1.068
[21,     4] loss: 0.990
[22,     4] loss: 0.982
[23,     4] loss: 0.932
[24,     4] loss: 0.984
[25,     4] loss: 0.957
[26,     4] loss: 0.928
[27,     4] loss: 0.909
[28,     4] loss: 0.995
[29,     4] loss: 0.908
[30,     4] loss: 0.846
[31,     4] loss: 0.846
[32,     4] loss: 0.923
[33,     4] loss: 0.901
[34,     4] loss: 0.947
[35,     4] loss: 0.947
[36,     4] loss: 0.928
[37,     4] loss: 0.863
[38,     4] loss: 0.841
[39,     4] loss: 0.820
[40,     4] loss: 0.785
[41,     4] loss: 0.787
[42,     4] loss: 0.767
[43,     4] loss: 0.774
[44,     4] loss: 0.776
[45,     4] loss: 0.746
[46,     4] loss: 0.766
[47,     4] loss: 0.757
[48,     4] loss: 0.739
[49,     4] loss: 0.794
[50,     4] loss: 0.776
[51,     4] loss: 0.753
[52,     4] loss: 0.793
[53,     4] loss: 0.771
[54,     4] loss: 0.738
[55,     4] loss: 0.742
[56,     4] loss: 0.747
[57,     4] loss: 0.743
[58,     4] loss: 0.749
[59,     4] loss: 0.747
[60,     4] loss: 0.722
[61,     4] loss: 0.735
[62,     4] loss: 0.726
[63,     4] loss: 0.718
[64,     4] loss: 0.720
[65,     4] loss: 0.732
[66,     4] loss: 0.722
[67,     4] loss: 0.721
[68,     4] loss: 0.727
[69,     4] loss: 0.727
[70,     4] loss: 0.735
[71,     4] loss: 0.733
[72,     4] loss: 0.730
[73,     4] loss: 0.749
Early stopping applied (best metric=0.3376638889312744)
Finished Training
Total time taken: 38.58981728553772
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.393
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.386
[5,     4] loss: 1.383
[6,     4] loss: 1.382
[7,     4] loss: 1.375
[8,     4] loss: 1.375
[9,     4] loss: 1.361
[10,     4] loss: 1.339
[11,     4] loss: 1.335
[12,     4] loss: 1.300
[13,     4] loss: 1.267
[14,     4] loss: 1.223
[15,     4] loss: 1.199
[16,     4] loss: 1.160
[17,     4] loss: 1.118
[18,     4] loss: 1.085
[19,     4] loss: 1.061
[20,     4] loss: 0.995
[21,     4] loss: 0.970
[22,     4] loss: 1.009
[23,     4] loss: 0.957
[24,     4] loss: 0.889
[25,     4] loss: 0.888
[26,     4] loss: 0.939
[27,     4] loss: 0.874
[28,     4] loss: 0.906
[29,     4] loss: 0.875
[30,     4] loss: 0.891
[31,     4] loss: 0.893
[32,     4] loss: 0.822
[33,     4] loss: 0.815
[34,     4] loss: 0.808
[35,     4] loss: 0.811
[36,     4] loss: 0.775
[37,     4] loss: 0.768
[38,     4] loss: 0.760
[39,     4] loss: 0.748
[40,     4] loss: 0.735
[41,     4] loss: 0.736
[42,     4] loss: 0.730
[43,     4] loss: 0.763
[44,     4] loss: 0.735
[45,     4] loss: 0.727
[46,     4] loss: 0.745
[47,     4] loss: 0.748
[48,     4] loss: 0.779
[49,     4] loss: 0.740
[50,     4] loss: 0.765
[51,     4] loss: 0.772
[52,     4] loss: 0.752
[53,     4] loss: 0.705
[54,     4] loss: 0.721
[55,     4] loss: 0.714
[56,     4] loss: 0.711
[57,     4] loss: 0.728
[58,     4] loss: 0.695
[59,     4] loss: 0.677
[60,     4] loss: 0.684
[61,     4] loss: 0.691
[62,     4] loss: 0.692
[63,     4] loss: 0.698
[64,     4] loss: 0.694
[65,     4] loss: 0.671
[66,     4] loss: 0.694
[67,     4] loss: 0.679
[68,     4] loss: 0.678
Early stopping applied (best metric=0.3496365547180176)
Finished Training
Total time taken: 35.978803634643555
{'Hydroxylation-K Validation Accuracy': 0.7924645390070922, 'Hydroxylation-K Validation Sensitivity': 0.7392592592592593, 'Hydroxylation-K Validation Specificity': 0.8052631578947368, 'Hydroxylation-K Validation Precision': 0.493815184643358, 'Hydroxylation-K AUC ROC': 0.8341715399610137, 'Hydroxylation-K AUC PR': 0.5998739460732717, 'Hydroxylation-K MCC': 0.47788663656420083, 'Hydroxylation-K F1': 0.588681178700327, 'Validation Loss (Hydroxylation-K)': 0.4003354330857595, 'Methylation-K Validation Accuracy': 0.82217367274513, 'Methylation-K Validation Sensitivity': 0.13552795388019445, 'Methylation-K Validation Specificity': 0.8966423779141106, 'Methylation-K Validation Precision': 0.125093701132416, 'Methylation-K AUC ROC': 0.5517928978653875, 'Methylation-K AUC PR': 0.11477106544203812, 'Methylation-K MCC': 0.030853300978372012, 'Methylation-K F1': 0.1250495516918407, 'Validation Loss (Methylation-K)': 0.8943899591763814, 'Validation Loss (total)': 1.2947253942489625, 'TimeToTrain': 40.69795699119568}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00023405454451799225,
 'learning_rate_Hydroxylation-K': 0.006986921914127761,
 'learning_rate_Methylation-K': 0.003664556401341045,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7651386280312866,
 'loss_weight_Methylation-K': 0.7424632782131767,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 425818267,
 'sample_weights': [0.5273106287661763, 0.6476250867712712],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.0959158375192235,
 'weight_decay_Hydroxylation-K': 7.698374537723234,
 'weight_decay_Methylation-K': 6.8682057028111885}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.390
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00012415542223255527,
 'learning_rate_Hydroxylation-K': 0.0038718450732962216,
 'learning_rate_Methylation-K': 0.0009545751257188057,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.18081438872137312,
 'loss_weight_Methylation-K': 0.6084667300881265,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1222533651,
 'sample_weights': [0.7651386280312866, 0.7424632782131767],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.337985430726253,
 'weight_decay_Hydroxylation-K': 7.880305788612164,
 'weight_decay_Methylation-K': 0.5268773344391358}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.389
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009090011717769578,
 'learning_rate_Hydroxylation-K': 0.005294318547339434,
 'learning_rate_Methylation-K': 0.0055444508203234995,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6400650866497871,
 'loss_weight_Methylation-K': 0.006474330580427199,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3254289087,
 'sample_weights': [0.18081438872137312, 0.6084667300881265],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.6804497888673415,
 'weight_decay_Hydroxylation-K': 6.510906460328204,
 'weight_decay_Methylation-K': 7.148963037017596}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.378
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.385
[9,     4] loss: 1.388
[10,     4] loss: 1.385
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.384
[14,     4] loss: 1.382
[15,     4] loss: 1.365
[16,     4] loss: 1.372
[17,     4] loss: 1.370
[18,     4] loss: 1.290
[19,     4] loss: 1.280
[20,     4] loss: 1.252
[21,     4] loss: 1.230
[22,     4] loss: 1.221
[23,     4] loss: 1.180
[24,     4] loss: 1.193
[25,     4] loss: 1.026
[26,     4] loss: 1.263
[27,     4] loss: 1.153
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002939736538587342,
 'learning_rate_Hydroxylation-K': 0.0038735525791468357,
 'learning_rate_Methylation-K': 0.006237686955741768,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.876448515882746,
 'loss_weight_Methylation-K': 0.6429612660593997,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1838203928,
 'sample_weights': [0.6400650866497871, 0.006474330580427199],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2545554598978137,
 'weight_decay_Hydroxylation-K': 3.2395696748440868,
 'weight_decay_Methylation-K': 1.0342368178466532}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.388
[3,     4] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0061874361572027215,
 'learning_rate_Hydroxylation-K': 0.0014341635635627737,
 'learning_rate_Methylation-K': 0.0038600851374806155,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3209011226840859,
 'loss_weight_Methylation-K': 0.07177147146290913,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3652701297,
 'sample_weights': [0.876448515882746, 0.6429612660593997],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.122936235213674,
 'weight_decay_Hydroxylation-K': 8.246576673633298,
 'weight_decay_Methylation-K': 5.41166414052769}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.387
[3,     4] loss: 1.385
[4,     4] loss: 1.388
[5,     4] loss: 1.389
[6,     4] loss: 1.386
[7,     4] loss: 1.387
[8,     4] loss: 1.387
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013782736053636667,
 'learning_rate_Hydroxylation-K': 0.006323779314011127,
 'learning_rate_Methylation-K': 0.003263309149662056,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5340885705973163,
 'loss_weight_Methylation-K': 0.5044812455619225,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 391661876,
 'sample_weights': [0.3209011226840859, 0.07177147146290913],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.76438128291678,
 'weight_decay_Hydroxylation-K': 4.135251034368103,
 'weight_decay_Methylation-K': 9.422320262067737}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.389
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014222953350552575,
 'learning_rate_Hydroxylation-K': 0.007124095253783336,
 'learning_rate_Methylation-K': 0.002402779745576739,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.45359944871144436,
 'loss_weight_Methylation-K': 0.8578327772739792,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 336227181,
 'sample_weights': [0.5340885705973163, 0.5044812455619225],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.075375782541993,
 'weight_decay_Hydroxylation-K': 3.8872726143263443,
 'weight_decay_Methylation-K': 4.099253273012893}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.390
[3,     4] loss: 1.381
[4,     4] loss: 1.381
[5,     4] loss: 1.375
[6,     4] loss: 1.366
[7,     4] loss: 1.332
[8,     4] loss: 1.307
[9,     4] loss: 1.253
[10,     4] loss: 1.226
[11,     4] loss: 1.149
[12,     4] loss: 1.119
[13,     4] loss: 1.129
[14,     4] loss: 1.080
[15,     4] loss: 1.018
[16,     4] loss: 1.079
[17,     4] loss: 0.971
[18,     4] loss: 1.011
[19,     4] loss: 0.960
[20,     4] loss: 0.853
[21,     4] loss: 0.856
[22,     4] loss: 0.877
[23,     4] loss: 0.828
[24,     4] loss: 0.834
[25,     4] loss: 0.878
[26,     4] loss: 0.800
[27,     4] loss: 0.798
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004778218284887417,
 'learning_rate_Hydroxylation-K': 0.0019182269126751146,
 'learning_rate_Methylation-K': 0.0066636139264666,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2395613817533646,
 'loss_weight_Methylation-K': 0.8573598729314482,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1858556377,
 'sample_weights': [0.45359944871144436, 0.8578327772739792],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.3615823385560066,
 'weight_decay_Hydroxylation-K': 8.102897291288507,
 'weight_decay_Methylation-K': 2.787606666053459}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.401
[2,     4] loss: 1.377
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024231450628019475,
 'learning_rate_Hydroxylation-K': 0.006935846707846234,
 'learning_rate_Methylation-K': 0.0002653781596992882,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5080673038415915,
 'loss_weight_Methylation-K': 0.9817452231003463,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 681591956,
 'sample_weights': [0.2395613817533646, 0.8573598729314482],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.366602192901914,
 'weight_decay_Hydroxylation-K': 9.699404210414684,
 'weight_decay_Methylation-K': 0.86032428217788}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.378
[2,     4] loss: 1.392
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00041735838982930864,
 'learning_rate_Hydroxylation-K': 0.000786437893985177,
 'learning_rate_Methylation-K': 0.008417928714113806,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5322948130455595,
 'loss_weight_Methylation-K': 0.9994368370071516,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1977048439,
 'sample_weights': [0.5080673038415915, 0.9817452231003463],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.747007445443934,
 'weight_decay_Hydroxylation-K': 4.024448365716485,
 'weight_decay_Methylation-K': 5.2345243417921985}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.386
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008623098213347665,
 'learning_rate_Hydroxylation-K': 0.0033824442880481197,
 'learning_rate_Methylation-K': 0.0022466778899595677,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8663396182188908,
 'loss_weight_Methylation-K': 0.08797763746484273,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1780301285,
 'sample_weights': [0.5322948130455595, 0.9994368370071516],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.289521054050171,
 'weight_decay_Hydroxylation-K': 2.8942407306443476,
 'weight_decay_Methylation-K': 3.421031128750978}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.383
[3,     4] loss: 1.392
[4,     4] loss: 1.384
[5,     4] loss: 1.387
[6,     4] loss: 1.387
[7,     4] loss: 1.378
[8,     4] loss: 1.350
[9,     4] loss: 1.269
[10,     4] loss: 1.284
[11,     4] loss: 1.345
[12,     4] loss: 1.326
[13,     4] loss: 1.354
[14,     4] loss: 1.257
[15,     4] loss: 1.229
[16,     4] loss: 1.213
[17,     4] loss: 1.158
[18,     4] loss: 1.226
[19,     4] loss: 1.184
[20,     4] loss: 1.174
[21,     4] loss: 1.238
[22,     4] loss: 1.091
[23,     4] loss: 1.126
[24,     4] loss: 1.122
[25,     4] loss: 1.222
[26,     4] loss: 1.147
[27,     4] loss: 1.072
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007841261605136673,
 'learning_rate_Hydroxylation-K': 0.005946771489787322,
 'learning_rate_Methylation-K': 0.0003046735294742215,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.42809186247523,
 'loss_weight_Methylation-K': 0.9633424184466253,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 137044089,
 'sample_weights': [0.8663396182188908, 0.08797763746484273],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.542386644994069,
 'weight_decay_Hydroxylation-K': 1.4930539911070002,
 'weight_decay_Methylation-K': 2.381556269776899}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.387
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014499343695371103,
 'learning_rate_Hydroxylation-K': 0.00548817511587003,
 'learning_rate_Methylation-K': 0.00035824017228023187,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5615906697877281,
 'loss_weight_Methylation-K': 0.7219178561483062,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 240206694,
 'sample_weights': [0.42809186247523, 0.9633424184466253],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.543037365410929,
 'weight_decay_Hydroxylation-K': 6.095641949695407,
 'weight_decay_Methylation-K': 3.91704360168123}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.375
[2,     4] loss: 1.390
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012914193347038098,
 'learning_rate_Hydroxylation-K': 0.008344685615685118,
 'learning_rate_Methylation-K': 0.004349729812780771,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5786277521983034,
 'loss_weight_Methylation-K': 0.6999762171850321,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1972859520,
 'sample_weights': [0.5615906697877281, 0.7219178561483062],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.86440771362848,
 'weight_decay_Hydroxylation-K': 4.511429654142728,
 'weight_decay_Methylation-K': 4.901831363015737}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.388
[3,     4] loss: 1.383
[4,     4] loss: 1.386
[5,     4] loss: 1.380
[6,     4] loss: 1.365
[7,     4] loss: 1.368
[8,     4] loss: 1.324
[9,     4] loss: 1.273
[10,     4] loss: 1.227
[11,     4] loss: 1.189
[12,     4] loss: 1.136
[13,     4] loss: 1.045
[14,     4] loss: 1.104
[15,     4] loss: 1.051
[16,     4] loss: 1.037
[17,     4] loss: 1.007
[18,     4] loss: 0.998
[19,     4] loss: 0.929
[20,     4] loss: 0.969
[21,     4] loss: 0.978
[22,     4] loss: 0.921
[23,     4] loss: 0.904
[24,     4] loss: 0.930
[25,     4] loss: 0.890
[26,     4] loss: 0.872
[27,     4] loss: 0.879
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002224102050510731,
 'learning_rate_Hydroxylation-K': 0.00030979533074212886,
 'learning_rate_Methylation-K': 0.0025375679898300843,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9732715012809487,
 'loss_weight_Methylation-K': 0.9604862920556305,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4229877786,
 'sample_weights': [0.5786277521983034, 0.6999762171850321],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.182157413401829,
 'weight_decay_Hydroxylation-K': 5.309428656870464,
 'weight_decay_Methylation-K': 1.514002826654394}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.383
[3,     4] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0053392911393399835,
 'learning_rate_Hydroxylation-K': 0.0072706499306765425,
 'learning_rate_Methylation-K': 0.004729269655853915,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6502247003831129,
 'loss_weight_Methylation-K': 0.3252073241374803,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3121411618,
 'sample_weights': [0.9732715012809487, 0.9604862920556305],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.895141411110735,
 'weight_decay_Hydroxylation-K': 6.637806072953461,
 'weight_decay_Methylation-K': 8.360402316623745}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.390
[3,     4] loss: 1.388
[4,     4] loss: 1.388
[5,     4] loss: 1.387
[6,     4] loss: 1.385
[7,     4] loss: 1.385
[8,     4] loss: 1.386
[9,     4] loss: 1.382
[10,     4] loss: 1.372
[11,     4] loss: 1.333
[12,     4] loss: 1.315
[13,     4] loss: 1.320
[14,     4] loss: 1.217
[15,     4] loss: 1.145
[16,     4] loss: 1.081
[17,     4] loss: 1.344
[18,     4] loss: 1.217
[19,     4] loss: 1.232
[20,     4] loss: 1.164
[21,     4] loss: 1.140
[22,     4] loss: 1.125
[23,     4] loss: 1.032
[24,     4] loss: 1.123
[25,     4] loss: 1.182
[26,     4] loss: 1.187
[27,     4] loss: 1.147
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0083331836501675,
 'learning_rate_Hydroxylation-K': 0.0073273790983249525,
 'learning_rate_Methylation-K': 0.004039036480828624,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.0024658729002946713,
 'loss_weight_Methylation-K': 0.7118337490298847,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3884705352,
 'sample_weights': [0.6502247003831129, 0.3252073241374803],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.27530579160887,
 'weight_decay_Hydroxylation-K': 4.951219629085299,
 'weight_decay_Methylation-K': 6.374050182961532}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.390
[3,     4] loss: 1.390
[4,     4] loss: 1.385
[5,     4] loss: 1.386
[6,     4] loss: 1.382
[7,     4] loss: 1.387
[8,     4] loss: 1.389
[9,     4] loss: 1.385
[10,     4] loss: 1.388
[11,     4] loss: 1.385
[12,     4] loss: 1.388
[13,     4] loss: 1.386
[14,     4] loss: 1.385
[15,     4] loss: 1.374
[16,     4] loss: 1.367
[17,     4] loss: 1.373
[18,     4] loss: 1.371
[19,     4] loss: 1.374
[20,     4] loss: 1.344
[21,     4] loss: 1.293
[22,     4] loss: 1.298
[23,     4] loss: 1.212
[24,     4] loss: 1.196
[25,     4] loss: 1.129
[26,     4] loss: 1.133
[27,     4] loss: 1.194
[28,     4] loss: 1.237
[29,     4] loss: 1.168
[30,     4] loss: 1.290
[31,     4] loss: 1.350
[32,     4] loss: 1.318
[33,     4] loss: 1.301
[34,     4] loss: 1.267
[35,     4] loss: 1.204
[36,     4] loss: 1.160
[37,     4] loss: 1.158
[38,     4] loss: 1.042
[39,     4] loss: 1.058
[40,     4] loss: 1.122
[41,     4] loss: 1.134
[42,     4] loss: 1.104
[43,     4] loss: 1.092
[44,     4] loss: 1.320
[45,     4] loss: 1.202
[46,     4] loss: 1.158
[47,     4] loss: 1.108
[48,     4] loss: 1.142
[49,     4] loss: 1.028
[50,     4] loss: 1.145
[51,     4] loss: 1.159
[52,     4] loss: 1.114
[53,     4] loss: 0.984
[54,     4] loss: 1.336
[55,     4] loss: 1.223
[56,     4] loss: 1.254
[57,     4] loss: 1.222
[58,     4] loss: 1.239
[59,     4] loss: 1.166
[60,     4] loss: 1.149
[61,     4] loss: 1.107
[62,     4] loss: 1.119
[63,     4] loss: 1.094
[64,     4] loss: 1.126
[65,     4] loss: 1.553
[66,     4] loss: 1.381
[67,     4] loss: 1.384
[68,     4] loss: 1.383
[69,     4] loss: 1.386
[70,     4] loss: 1.386
[71,     4] loss: 1.386
[72,     4] loss: 1.386
[73,     4] loss: 1.386
[74,     4] loss: 1.386
[75,     4] loss: 1.386
[76,     4] loss: 1.386
[77,     4] loss: 1.387
[78,     4] loss: 1.386
[79,     4] loss: 1.387
[80,     4] loss: 1.387
[81,     4] loss: 1.386
[82,     4] loss: 1.386
[83,     4] loss: 1.387
[84,     4] loss: 1.387
[85,     4] loss: 1.386
[86,     4] loss: 1.386
[87,     4] loss: 1.387
[88,     4] loss: 1.386
[89,     4] loss: 1.386
[90,     4] loss: 1.386
[91,     4] loss: 1.386
[92,     4] loss: 1.386
[93,     4] loss: 1.387
[94,     4] loss: 1.386
[95,     4] loss: 1.386
[96,     4] loss: 1.387
[97,     4] loss: 1.386
[98,     4] loss: 1.386
[99,     4] loss: 1.386
[100,     4] loss: 1.387
[101,     4] loss: 1.386
[102,     4] loss: 1.386
[103,     4] loss: 1.386
[104,     4] loss: 1.386
[105,     4] loss: 1.386
[106,     4] loss: 1.386
[107,     4] loss: 1.386
[108,     4] loss: 1.386
[109,     4] loss: 1.386
[110,     4] loss: 1.386
[111,     4] loss: 1.386
[112,     4] loss: 1.386
[113,     4] loss: 1.387
Early stopping applied (best metric=0.23568618297576904)
Finished Training
Total time taken: 57.74116778373718
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.380
[2,     4] loss: 1.386
[3,     4] loss: 1.387
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.385
[7,     4] loss: 1.387
[8,     4] loss: 1.383
[9,     4] loss: 1.376
[10,     4] loss: 1.319
[11,     4] loss: 1.249
[12,     4] loss: 1.227
[13,     4] loss: 1.276
[14,     4] loss: 1.203
[15,     4] loss: 1.262
[16,     4] loss: 1.224
[17,     4] loss: 1.189
[18,     4] loss: 1.121
[19,     4] loss: 1.049
[20,     4] loss: 1.133
[21,     4] loss: 1.155
[22,     4] loss: 1.136
[23,     4] loss: 1.045
[24,     4] loss: 1.309
[25,     4] loss: 1.171
[26,     4] loss: 1.229
[27,     4] loss: 1.177
[28,     4] loss: 1.049
[29,     4] loss: 1.282
[30,     4] loss: 1.207
[31,     4] loss: 1.241
[32,     4] loss: 1.141
[33,     4] loss: 1.137
[34,     4] loss: 1.323
[35,     4] loss: 1.262
[36,     4] loss: 1.293
[37,     4] loss: 1.235
[38,     4] loss: 1.147
[39,     4] loss: 1.137
[40,     4] loss: 1.098
[41,     4] loss: 1.084
[42,     4] loss: 1.045
[43,     4] loss: 1.010
[44,     4] loss: 1.101
[45,     4] loss: 0.994
[46,     4] loss: 1.191
[47,     4] loss: 1.082
[48,     4] loss: 1.225
[49,     4] loss: 1.115
[50,     4] loss: 1.047
[51,     4] loss: 1.040
[52,     4] loss: 0.975
[53,     4] loss: 1.019
[54,     4] loss: 0.906
[55,     4] loss: 0.958
[56,     4] loss: 0.918
[57,     4] loss: 0.924
[58,     4] loss: 1.027
[59,     4] loss: 1.001
[60,     4] loss: 0.962
[61,     4] loss: 0.975
[62,     4] loss: 0.978
[63,     4] loss: 1.016
[64,     4] loss: 0.932
[65,     4] loss: 0.942
[66,     4] loss: 0.960
[67,     4] loss: 0.987
[68,     4] loss: 1.000
[69,     4] loss: 0.958
[70,     4] loss: 0.955
[71,     4] loss: 0.915
[72,     4] loss: 1.025
[73,     4] loss: 0.988
[74,     4] loss: 1.048
[75,     4] loss: 1.003
[76,     4] loss: 0.963
[77,     4] loss: 0.965
[78,     4] loss: 0.937
[79,     4] loss: 0.863
[80,     4] loss: 1.150
[81,     4] loss: 1.236
[82,     4] loss: 1.230
[83,     4] loss: 1.264
[84,     4] loss: 1.224
[85,     4] loss: 1.319
[86,     4] loss: 1.211
[87,     4] loss: 1.139
[88,     4] loss: 1.094
[89,     4] loss: 1.109
Early stopping applied (best metric=0.4390406012535095)
Finished Training
Total time taken: 45.228904485702515
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.391
[3,     4] loss: 1.386
[4,     4] loss: 1.390
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.388
[8,     4] loss: 1.385
[9,     4] loss: 1.384
[10,     4] loss: 1.375
[11,     4] loss: 1.302
[12,     4] loss: 1.253
[13,     4] loss: 1.253
[14,     4] loss: 1.200
[15,     4] loss: 1.190
[16,     4] loss: 1.112
[17,     4] loss: 1.164
[18,     4] loss: 1.069
[19,     4] loss: 1.015
[20,     4] loss: 1.216
[21,     4] loss: 1.187
[22,     4] loss: 1.121
[23,     4] loss: 1.098
[24,     4] loss: 1.180
[25,     4] loss: 1.114
[26,     4] loss: 1.039
[27,     4] loss: 1.251
[28,     4] loss: 1.302
[29,     4] loss: 1.289
[30,     4] loss: 1.302
[31,     4] loss: 1.264
[32,     4] loss: 1.172
[33,     4] loss: 1.388
[34,     4] loss: 1.244
[35,     4] loss: 1.289
[36,     4] loss: 1.202
[37,     4] loss: 1.214
[38,     4] loss: 1.333
[39,     4] loss: 1.292
[40,     4] loss: 1.191
[41,     4] loss: 1.266
[42,     4] loss: 1.196
[43,     4] loss: 1.142
[44,     4] loss: 1.101
[45,     4] loss: 1.008
[46,     4] loss: 1.229
[47,     4] loss: 1.581
[48,     4] loss: 1.389
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.386
[53,     4] loss: 1.386
[54,     4] loss: 1.386
[55,     4] loss: 1.386
[56,     4] loss: 1.386
[57,     4] loss: 1.386
[58,     4] loss: 1.385
[59,     4] loss: 1.387
[60,     4] loss: 1.387
[61,     4] loss: 1.387
[62,     4] loss: 1.386
[63,     4] loss: 1.386
[64,     4] loss: 1.387
[65,     4] loss: 1.386
[66,     4] loss: 1.386
[67,     4] loss: 1.386
[68,     4] loss: 1.386
[69,     4] loss: 1.387
[70,     4] loss: 1.386
[71,     4] loss: 1.386
[72,     4] loss: 1.386
Early stopping applied (best metric=0.43034887313842773)
Finished Training
Total time taken: 36.18185377120972
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.384
[3,     4] loss: 1.390
[4,     4] loss: 1.386
[5,     4] loss: 1.385
[6,     4] loss: 1.390
[7,     4] loss: 1.388
[8,     4] loss: 1.385
[9,     4] loss: 1.386
[10,     4] loss: 1.384
[11,     4] loss: 1.386
[12,     4] loss: 1.375
[13,     4] loss: 1.320
[14,     4] loss: 1.269
[15,     4] loss: 1.324
[16,     4] loss: 1.284
[17,     4] loss: 1.264
[18,     4] loss: 1.296
[19,     4] loss: 1.251
[20,     4] loss: 1.185
[21,     4] loss: 1.098
[22,     4] loss: 1.128
[23,     4] loss: 1.021
[24,     4] loss: 1.240
[25,     4] loss: 1.228
[26,     4] loss: 1.254
[27,     4] loss: 1.194
[28,     4] loss: 1.091
[29,     4] loss: 1.196
[30,     4] loss: 1.270
[31,     4] loss: 1.215
[32,     4] loss: 1.221
[33,     4] loss: 1.146
[34,     4] loss: 1.207
[35,     4] loss: 1.096
[36,     4] loss: 0.985
[37,     4] loss: 0.992
[38,     4] loss: 1.322
[39,     4] loss: 1.297
[40,     4] loss: 1.222
[41,     4] loss: 1.211
[42,     4] loss: 1.151
[43,     4] loss: 1.069
[44,     4] loss: 1.021
[45,     4] loss: 1.050
[46,     4] loss: 1.067
[47,     4] loss: 0.967
[48,     4] loss: 1.033
[49,     4] loss: 0.967
[50,     4] loss: 0.940
[51,     4] loss: 1.261
[52,     4] loss: 1.159
[53,     4] loss: 1.047
[54,     4] loss: 0.995
[55,     4] loss: 1.003
[56,     4] loss: 1.085
[57,     4] loss: 1.096
[58,     4] loss: 1.071
[59,     4] loss: 1.108
[60,     4] loss: 1.046
[61,     4] loss: 1.107
[62,     4] loss: 1.057
[63,     4] loss: 1.079
[64,     4] loss: 1.007
[65,     4] loss: 0.933
[66,     4] loss: 0.916
[67,     4] loss: 0.949
[68,     4] loss: 1.145
[69,     4] loss: 1.127
[70,     4] loss: 1.039
[71,     4] loss: 1.043
[72,     4] loss: 1.470
[73,     4] loss: 1.397
[74,     4] loss: 1.387
[75,     4] loss: 1.387
[76,     4] loss: 1.387
[77,     4] loss: 1.387
[78,     4] loss: 1.386
[79,     4] loss: 1.386
[80,     4] loss: 1.386
[81,     4] loss: 1.387
[82,     4] loss: 1.386
[83,     4] loss: 1.387
[84,     4] loss: 1.387
[85,     4] loss: 1.387
[86,     4] loss: 1.387
[87,     4] loss: 1.386
[88,     4] loss: 1.386
[89,     4] loss: 1.387
[90,     4] loss: 1.386
[91,     4] loss: 1.386
Early stopping applied (best metric=0.4407029449939728)
Finished Training
Total time taken: 46.021217823028564
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.382
[2,     4] loss: 1.384
[3,     4] loss: 1.389
[4,     4] loss: 1.388
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.387
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.387
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.387
[30,     4] loss: 1.387
[31,     4] loss: 1.387
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.387
[36,     4] loss: 1.387
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.387
[41,     4] loss: 1.386
[42,     4] loss: 1.387
[43,     4] loss: 1.386
[44,     4] loss: 1.387
[45,     4] loss: 1.386
[46,     4] loss: 1.387
[47,     4] loss: 1.387
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.385
[51,     4] loss: 1.386
[52,     4] loss: 1.386
[53,     4] loss: 1.387
[54,     4] loss: 1.387
[55,     4] loss: 1.386
[56,     4] loss: 1.386
[57,     4] loss: 1.386
[58,     4] loss: 1.386
[59,     4] loss: 1.386
[60,     4] loss: 1.386
[61,     4] loss: 1.387
[62,     4] loss: 1.386
[63,     4] loss: 1.386
[64,     4] loss: 1.386
[65,     4] loss: 1.386
[66,     4] loss: 1.387
[67,     4] loss: 1.386
[68,     4] loss: 1.386
[69,     4] loss: 1.386
[70,     4] loss: 1.387
[71,     4] loss: 1.386
[72,     4] loss: 1.387
[73,     4] loss: 1.386
[74,     4] loss: 1.386
[75,     4] loss: 1.387
[76,     4] loss: 1.386
[77,     4] loss: 1.386
[78,     4] loss: 1.386
[79,     4] loss: 1.386
[80,     4] loss: 1.386
[81,     4] loss: 1.386
[82,     4] loss: 1.387
[83,     4] loss: 1.387
[84,     4] loss: 1.386
[85,     4] loss: 1.386
[86,     4] loss: 1.387
[87,     4] loss: 1.386
[88,     4] loss: 1.386
[89,     4] loss: 1.386
[90,     4] loss: 1.387
[91,     4] loss: 1.387
[92,     4] loss: 1.386
[93,     4] loss: 1.386
[94,     4] loss: 1.387
[95,     4] loss: 1.386
[96,     4] loss: 1.387
[97,     4] loss: 1.387
[98,     4] loss: 1.387
[99,     4] loss: 1.387
[100,     4] loss: 1.387
[101,     4] loss: 1.386
Early stopping applied (best metric=0.545448362827301)
Finished Training
Total time taken: 50.76481103897095
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.401
[3,     4] loss: 1.386
[4,     4] loss: 1.388
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.387
[8,     4] loss: 1.387
[9,     4] loss: 1.385
[10,     4] loss: 1.385
[11,     4] loss: 1.385
[12,     4] loss: 1.381
[13,     4] loss: 1.360
[14,     4] loss: 1.280
[15,     4] loss: 1.268
[16,     4] loss: 1.203
[17,     4] loss: 1.314
[18,     4] loss: 1.194
[19,     4] loss: 1.247
[20,     4] loss: 1.213
[21,     4] loss: 1.127
[22,     4] loss: 1.095
[23,     4] loss: 1.148
[24,     4] loss: 1.079
[25,     4] loss: 1.144
[26,     4] loss: 1.061
[27,     4] loss: 0.949
[28,     4] loss: 1.128
[29,     4] loss: 1.117
[30,     4] loss: 1.055
[31,     4] loss: 1.031
[32,     4] loss: 0.961
[33,     4] loss: 0.917
[34,     4] loss: 0.963
[35,     4] loss: 1.289
[36,     4] loss: 1.227
[37,     4] loss: 1.167
[38,     4] loss: 1.073
[39,     4] loss: 1.316
[40,     4] loss: 1.259
[41,     4] loss: 1.243
[42,     4] loss: 1.116
[43,     4] loss: 1.001
[44,     4] loss: 1.019
[45,     4] loss: 0.980
[46,     4] loss: 0.983
[47,     4] loss: 1.070
[48,     4] loss: 1.106
[49,     4] loss: 1.240
[50,     4] loss: 1.096
[51,     4] loss: 0.961
[52,     4] loss: 1.028
[53,     4] loss: 1.050
[54,     4] loss: 1.031
[55,     4] loss: 0.985
[56,     4] loss: 1.195
[57,     4] loss: 1.069
[58,     4] loss: 1.282
[59,     4] loss: 1.203
[60,     4] loss: 1.180
[61,     4] loss: 1.033
[62,     4] loss: 1.072
[63,     4] loss: 1.096
[64,     4] loss: 1.039
[65,     4] loss: 0.997
[66,     4] loss: 1.167
[67,     4] loss: 1.162
[68,     4] loss: 1.188
[69,     4] loss: 1.148
[70,     4] loss: 1.000
[71,     4] loss: 0.895
[72,     4] loss: 1.061
[73,     4] loss: 1.056
[74,     4] loss: 1.075
[75,     4] loss: 1.021
[76,     4] loss: 1.035
[77,     4] loss: 1.248
[78,     4] loss: 1.177
[79,     4] loss: 1.132
[80,     4] loss: 1.009
[81,     4] loss: 1.185
[82,     4] loss: 1.361
[83,     4] loss: 1.348
[84,     4] loss: 1.377
[85,     4] loss: 1.369
[86,     4] loss: 1.335
[87,     4] loss: 1.279
[88,     4] loss: 1.219
[89,     4] loss: 1.225
[90,     4] loss: 1.331
[91,     4] loss: 1.379
[92,     4] loss: 1.376
[93,     4] loss: 1.367
[94,     4] loss: 1.327
[95,     4] loss: 1.261
[96,     4] loss: 1.207
[97,     4] loss: 1.170
[98,     4] loss: 1.292
[99,     4] loss: 1.335
[100,     4] loss: 1.276
[101,     4] loss: 1.205
[102,     4] loss: 1.092
[103,     4] loss: 1.309
[104,     4] loss: 1.226
[105,     4] loss: 1.229
[106,     4] loss: 1.125
[107,     4] loss: 1.120
[108,     4] loss: 1.020
[109,     4] loss: 0.981
[110,     4] loss: 1.111
[111,     4] loss: 1.108
[112,     4] loss: 1.018
[113,     4] loss: 1.109
[114,     4] loss: 1.075
[115,     4] loss: 1.051
[116,     4] loss: 0.945
[117,     4] loss: 1.148
[118,     4] loss: 1.406
Early stopping applied (best metric=0.46037304401397705)
Finished Training
Total time taken: 59.594016551971436
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.401
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.387
[6,     4] loss: 1.385
[7,     4] loss: 1.384
[8,     4] loss: 1.385
[9,     4] loss: 1.379
[10,     4] loss: 1.359
[11,     4] loss: 1.356
[12,     4] loss: 1.370
[13,     4] loss: 1.285
[14,     4] loss: 1.231
[15,     4] loss: 1.236
[16,     4] loss: 1.183
[17,     4] loss: 1.178
[18,     4] loss: 1.230
[19,     4] loss: 1.132
[20,     4] loss: 1.060
[21,     4] loss: 1.120
[22,     4] loss: 1.287
[23,     4] loss: 1.217
[24,     4] loss: 1.163
[25,     4] loss: 1.178
[26,     4] loss: 1.050
[27,     4] loss: 1.065
[28,     4] loss: 1.017
[29,     4] loss: 1.012
[30,     4] loss: 1.004
[31,     4] loss: 1.146
[32,     4] loss: 1.046
[33,     4] loss: 1.044
[34,     4] loss: 1.040
[35,     4] loss: 0.932
[36,     4] loss: 1.011
[37,     4] loss: 1.087
[38,     4] loss: 0.974
[39,     4] loss: 0.900
[40,     4] loss: 0.993
[41,     4] loss: 1.095
[42,     4] loss: 1.052
[43,     4] loss: 1.132
[44,     4] loss: 1.072
[45,     4] loss: 1.023
[46,     4] loss: 1.015
[47,     4] loss: 1.021
[48,     4] loss: 0.973
[49,     4] loss: 0.995
[50,     4] loss: 1.059
[51,     4] loss: 0.990
[52,     4] loss: 0.978
[53,     4] loss: 1.221
[54,     4] loss: 1.142
[55,     4] loss: 1.040
[56,     4] loss: 0.930
[57,     4] loss: 0.891
[58,     4] loss: 0.963
[59,     4] loss: 1.145
[60,     4] loss: 1.173
[61,     4] loss: 1.096
[62,     4] loss: 1.030
[63,     4] loss: 0.948
[64,     4] loss: 1.011
Early stopping applied (best metric=0.4325292110443115)
Finished Training
Total time taken: 32.38474130630493
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.396
[3,     4] loss: 1.386
[4,     4] loss: 1.390
[5,     4] loss: 1.385
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.389
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.385
[14,     4] loss: 1.374
[15,     4] loss: 1.328
[16,     4] loss: 1.337
[17,     4] loss: 1.312
[18,     4] loss: 1.278
[19,     4] loss: 1.296
[20,     4] loss: 1.207
[21,     4] loss: 1.240
[22,     4] loss: 1.130
[23,     4] loss: 1.090
[24,     4] loss: 1.153
[25,     4] loss: 1.081
[26,     4] loss: 1.082
[27,     4] loss: 1.095
[28,     4] loss: 1.065
[29,     4] loss: 0.934
[30,     4] loss: 0.929
[31,     4] loss: 1.274
[32,     4] loss: 1.278
[33,     4] loss: 1.331
[34,     4] loss: 1.328
[35,     4] loss: 1.282
[36,     4] loss: 1.287
[37,     4] loss: 1.295
[38,     4] loss: 1.288
[39,     4] loss: 1.199
[40,     4] loss: 1.094
[41,     4] loss: 1.260
[42,     4] loss: 1.141
[43,     4] loss: 1.294
[44,     4] loss: 1.207
[45,     4] loss: 1.156
[46,     4] loss: 1.169
[47,     4] loss: 1.099
[48,     4] loss: 0.983
[49,     4] loss: 1.011
[50,     4] loss: 1.186
[51,     4] loss: 1.104
[52,     4] loss: 1.036
[53,     4] loss: 1.059
[54,     4] loss: 0.980
[55,     4] loss: 1.001
[56,     4] loss: 0.931
[57,     4] loss: 1.003
[58,     4] loss: 0.905
[59,     4] loss: 0.889
[60,     4] loss: 1.133
[61,     4] loss: 1.079
[62,     4] loss: 0.990
[63,     4] loss: 0.984
[64,     4] loss: 1.443
[65,     4] loss: 1.216
[66,     4] loss: 1.266
[67,     4] loss: 1.381
Early stopping applied (best metric=0.5467427968978882)
Finished Training
Total time taken: 33.94017219543457
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.380
[2,     4] loss: 1.390
[3,     4] loss: 1.388
[4,     4] loss: 1.387
[5,     4] loss: 1.385
[6,     4] loss: 1.385
[7,     4] loss: 1.386
[8,     4] loss: 1.381
[9,     4] loss: 1.366
[10,     4] loss: 1.324
[11,     4] loss: 1.294
[12,     4] loss: 1.167
[13,     4] loss: 1.320
[14,     4] loss: 1.277
[15,     4] loss: 1.280
[16,     4] loss: 1.169
[17,     4] loss: 1.255
[18,     4] loss: 1.330
[19,     4] loss: 1.308
[20,     4] loss: 1.283
[21,     4] loss: 1.178
[22,     4] loss: 1.092
[23,     4] loss: 1.168
[24,     4] loss: 1.151
[25,     4] loss: 1.153
[26,     4] loss: 1.112
[27,     4] loss: 0.997
[28,     4] loss: 0.998
[29,     4] loss: 0.987
[30,     4] loss: 1.037
[31,     4] loss: 1.027
[32,     4] loss: 1.102
[33,     4] loss: 0.992
[34,     4] loss: 0.926
[35,     4] loss: 1.108
[36,     4] loss: 1.078
[37,     4] loss: 1.108
[38,     4] loss: 1.241
[39,     4] loss: 1.269
[40,     4] loss: 1.221
[41,     4] loss: 1.112
[42,     4] loss: 1.092
[43,     4] loss: 0.974
[44,     4] loss: 1.078
[45,     4] loss: 1.068
[46,     4] loss: 1.013
[47,     4] loss: 0.978
[48,     4] loss: 1.294
[49,     4] loss: 1.419
[50,     4] loss: 1.372
[51,     4] loss: 1.385
[52,     4] loss: 1.385
[53,     4] loss: 1.386
[54,     4] loss: 1.386
[55,     4] loss: 1.386
[56,     4] loss: 1.385
[57,     4] loss: 1.385
[58,     4] loss: 1.385
[59,     4] loss: 1.383
[60,     4] loss: 1.382
[61,     4] loss: 1.386
[62,     4] loss: 1.385
[63,     4] loss: 1.387
Early stopping applied (best metric=0.49564576148986816)
Finished Training
Total time taken: 31.828858852386475
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.394
[2,     4] loss: 1.390
[3,     4] loss: 1.392
[4,     4] loss: 1.387
[5,     4] loss: 1.387
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.388
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.385
[17,     4] loss: 1.387
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.387
[21,     4] loss: 1.387
[22,     4] loss: 1.386
[23,     4] loss: 1.387
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.385
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.384
[30,     4] loss: 1.384
[31,     4] loss: 1.388
[32,     4] loss: 1.388
[33,     4] loss: 1.385
[34,     4] loss: 1.387
[35,     4] loss: 1.385
[36,     4] loss: 1.386
[37,     4] loss: 1.387
[38,     4] loss: 1.387
[39,     4] loss: 1.387
[40,     4] loss: 1.387
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.385
[51,     4] loss: 1.387
[52,     4] loss: 1.386
[53,     4] loss: 1.387
[54,     4] loss: 1.386
[55,     4] loss: 1.386
[56,     4] loss: 1.386
Early stopping applied (best metric=0.5454230904579163)
Finished Training
Total time taken: 28.118731021881104
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.390
[3,     4] loss: 1.389
[4,     4] loss: 1.385
[5,     4] loss: 1.393
[6,     4] loss: 1.385
[7,     4] loss: 1.387
[8,     4] loss: 1.388
[9,     4] loss: 1.386
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.387
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.387
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.385
[20,     4] loss: 1.387
[21,     4] loss: 1.385
[22,     4] loss: 1.387
[23,     4] loss: 1.384
[24,     4] loss: 1.386
[25,     4] loss: 1.389
[26,     4] loss: 1.387
[27,     4] loss: 1.387
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.385
[33,     4] loss: 1.388
[34,     4] loss: 1.388
[35,     4] loss: 1.387
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.385
[42,     4] loss: 1.388
[43,     4] loss: 1.386
[44,     4] loss: 1.387
[45,     4] loss: 1.387
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.386
Early stopping applied (best metric=0.5628345608711243)
Finished Training
Total time taken: 26.002172470092773
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.392
[3,     4] loss: 1.375
[4,     4] loss: 1.381
[5,     4] loss: 1.378
[6,     4] loss: 1.336
[7,     4] loss: 1.299
[8,     4] loss: 1.358
[9,     4] loss: 1.246
[10,     4] loss: 1.265
[11,     4] loss: 1.260
[12,     4] loss: 1.200
[13,     4] loss: 1.161
[14,     4] loss: 1.040
[15,     4] loss: 1.083
[16,     4] loss: 1.097
[17,     4] loss: 1.146
[18,     4] loss: 1.117
[19,     4] loss: 1.229
[20,     4] loss: 1.108
[21,     4] loss: 0.971
[22,     4] loss: 1.303
[23,     4] loss: 1.151
[24,     4] loss: 1.164
[25,     4] loss: 1.203
[26,     4] loss: 1.089
[27,     4] loss: 0.967
[28,     4] loss: 0.987
[29,     4] loss: 1.111
[30,     4] loss: 1.127
[31,     4] loss: 1.108
[32,     4] loss: 1.050
[33,     4] loss: 0.894
[34,     4] loss: 0.844
[35,     4] loss: 1.528
[36,     4] loss: 1.476
[37,     4] loss: 1.385
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.387
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.387
[52,     4] loss: 1.386
[53,     4] loss: 1.386
[54,     4] loss: 1.386
[55,     4] loss: 1.386
[56,     4] loss: 1.386
[57,     4] loss: 1.386
[58,     4] loss: 1.386
[59,     4] loss: 1.386
[60,     4] loss: 1.386
[61,     4] loss: 1.386
[62,     4] loss: 1.386
Early stopping applied (best metric=0.4025321900844574)
Finished Training
Total time taken: 31.25429677963257
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.411
[2,     4] loss: 1.390
[3,     4] loss: 1.384
[4,     4] loss: 1.390
[5,     4] loss: 1.382
[6,     4] loss: 1.386
[7,     4] loss: 1.388
[8,     4] loss: 1.385
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.387
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.387
[17,     4] loss: 1.387
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.387
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.387
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.387
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.387
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.387
[43,     4] loss: 1.387
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.387
[52,     4] loss: 1.386
[53,     4] loss: 1.386
[54,     4] loss: 1.387
[55,     4] loss: 1.386
[56,     4] loss: 1.387
[57,     4] loss: 1.386
[58,     4] loss: 1.386
Early stopping applied (best metric=0.5629284381866455)
Finished Training
Total time taken: 29.3791401386261
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.401
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.387
[5,     4] loss: 1.389
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.385
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.387
[12,     4] loss: 1.387
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.387
[16,     4] loss: 1.387
[17,     4] loss: 1.387
[18,     4] loss: 1.386
[19,     4] loss: 1.385
[20,     4] loss: 1.387
[21,     4] loss: 1.387
[22,     4] loss: 1.376
[23,     4] loss: 1.305
[24,     4] loss: 1.335
[25,     4] loss: 1.401
[26,     4] loss: 1.373
[27,     4] loss: 1.352
[28,     4] loss: 1.343
[29,     4] loss: 1.537
[30,     4] loss: 1.397
[31,     4] loss: 1.387
[32,     4] loss: 1.389
[33,     4] loss: 1.388
[34,     4] loss: 1.388
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.387
[50,     4] loss: 1.387
[51,     4] loss: 1.386
[52,     4] loss: 1.386
[53,     4] loss: 1.387
[54,     4] loss: 1.386
[55,     4] loss: 1.387
[56,     4] loss: 1.386
[57,     4] loss: 1.386
[58,     4] loss: 1.386
[59,     4] loss: 1.386
[60,     4] loss: 1.386
[61,     4] loss: 1.386
[62,     4] loss: 1.386
[63,     4] loss: 1.387
[64,     4] loss: 1.387
[65,     4] loss: 1.386
[66,     4] loss: 1.386
[67,     4] loss: 1.386
[68,     4] loss: 1.386
[69,     4] loss: 1.386
[70,     4] loss: 1.385
[71,     4] loss: 1.387
[72,     4] loss: 1.386
[73,     4] loss: 1.387
[74,     4] loss: 1.387
Early stopping applied (best metric=0.5201712846755981)
Finished Training
Total time taken: 37.693782329559326
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.393
[2,     4] loss: 1.385
[3,     4] loss: 1.392
[4,     4] loss: 1.388
[5,     4] loss: 1.385
[6,     4] loss: 1.385
[7,     4] loss: 1.386
[8,     4] loss: 1.387
[9,     4] loss: 1.385
[10,     4] loss: 1.387
[11,     4] loss: 1.384
[12,     4] loss: 1.387
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.387
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.385
[19,     4] loss: 1.387
[20,     4] loss: 1.385
[21,     4] loss: 1.383
[22,     4] loss: 1.369
[23,     4] loss: 1.348
[24,     4] loss: 1.311
[25,     4] loss: 1.360
[26,     4] loss: 1.339
[27,     4] loss: 1.274
[28,     4] loss: 1.206
[29,     4] loss: 1.273
[30,     4] loss: 1.236
[31,     4] loss: 1.200
[32,     4] loss: 1.199
[33,     4] loss: 1.121
[34,     4] loss: 1.251
[35,     4] loss: 1.233
[36,     4] loss: 1.314
[37,     4] loss: 1.325
[38,     4] loss: 1.193
[39,     4] loss: 1.172
[40,     4] loss: 1.214
[41,     4] loss: 1.054
[42,     4] loss: 1.273
[43,     4] loss: 1.374
[44,     4] loss: 1.373
[45,     4] loss: 1.361
[46,     4] loss: 1.346
[47,     4] loss: 1.303
[48,     4] loss: 1.271
[49,     4] loss: 1.249
[50,     4] loss: 1.145
[51,     4] loss: 1.291
[52,     4] loss: 1.264
[53,     4] loss: 1.408
[54,     4] loss: 1.254
[55,     4] loss: 1.266
[56,     4] loss: 1.222
[57,     4] loss: 1.330
[58,     4] loss: 1.191
[59,     4] loss: 1.171
[60,     4] loss: 1.149
[61,     4] loss: 1.232
[62,     4] loss: 1.158
[63,     4] loss: 1.142
[64,     4] loss: 1.101
[65,     4] loss: 1.090
[66,     4] loss: 1.022
[67,     4] loss: 1.064
[68,     4] loss: 1.035
[69,     4] loss: 1.127
[70,     4] loss: 1.046
[71,     4] loss: 0.981
[72,     4] loss: 1.058
[73,     4] loss: 1.135
[74,     4] loss: 1.089
[75,     4] loss: 1.000
[76,     4] loss: 1.012
[77,     4] loss: 1.058
[78,     4] loss: 1.046
Early stopping applied (best metric=0.3857780396938324)
Finished Training
Total time taken: 39.126887798309326
{'Hydroxylation-K Validation Accuracy': 0.6528664302600473, 'Hydroxylation-K Validation Sensitivity': 0.6859259259259259, 'Hydroxylation-K Validation Specificity': 0.6473684210526316, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.7179727095516569, 'Hydroxylation-K AUC PR': 0.47206469068953816, 'Hydroxylation-K MCC': 0.2767930869243418, 'Hydroxylation-K F1': 0.4195253496034429, 'Validation Loss (Hydroxylation-K)': 0.4670790255069733, 'Methylation-K Validation Accuracy': 0.6958658062344277, 'Methylation-K Validation Sensitivity': 0.27710505489657916, 'Methylation-K Validation Specificity': 0.7412973282280896, 'Methylation-K Validation Precision': nan, 'Methylation-K AUC ROC': 0.5362301975603543, 'Methylation-K AUC PR': 0.13955166659773036, 'Methylation-K MCC': 0.014284715442472638, 'Methylation-K F1': 0.12053534923601801, 'Validation Loss (Methylation-K)': 0.5929599483807881, 'Validation Loss (total)': 1.060038963953654, 'TimeToTrain': 39.017383623123166}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007102321579041673,
 'learning_rate_Hydroxylation-K': 0.006518610657651218,
 'learning_rate_Methylation-K': 0.0009678029037808709,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3296643527175875,
 'loss_weight_Methylation-K': 0.8386648375692537,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 948017931,
 'sample_weights': [0.0024658729002946713, 0.7118337490298847],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.9518317735631294,
 'weight_decay_Hydroxylation-K': 0.931144855658208,
 'weight_decay_Methylation-K': 6.099782991765872}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.396
[3,     4] loss: 1.388
[4,     4] loss: 1.388
[5,     4] loss: 1.391
[6,     4] loss: 1.386
[7,     4] loss: 1.387
[8,     4] loss: 1.386
[9,     4] loss: 1.386
[10,     4] loss: 1.391
[11,     4] loss: 1.386
[12,     4] loss: 1.387
[13,     4] loss: 1.387
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.385
[18,     4] loss: 1.387
[19,     4] loss: 1.387
[20,     4] loss: 1.383
[21,     4] loss: 1.389
[22,     4] loss: 1.385
[23,     4] loss: 1.387
[24,     4] loss: 1.386
[25,     4] loss: 1.387
[26,     4] loss: 1.383
[27,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003352778630395829,
 'learning_rate_Hydroxylation-K': 0.007837898760369812,
 'learning_rate_Methylation-K': 0.0014092735907852993,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.308356710687422,
 'loss_weight_Methylation-K': 0.8910782346522851,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3813369760,
 'sample_weights': [0.3296643527175875, 0.8386648375692537],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.055460336735827,
 'weight_decay_Hydroxylation-K': 5.607400569879031,
 'weight_decay_Methylation-K': 3.3806576222450415}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.387
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001568340484330231,
 'learning_rate_Hydroxylation-K': 0.008925623409351892,
 'learning_rate_Methylation-K': 0.004611599673206466,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6820112863435035,
 'loss_weight_Methylation-K': 0.5108394056202354,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4288776443,
 'sample_weights': [0.308356710687422, 0.8910782346522851],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.636727238270989,
 'weight_decay_Hydroxylation-K': 4.977675845766539,
 'weight_decay_Methylation-K': 6.907304285564501}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.388
[5,     4] loss: 1.376
[6,     4] loss: 1.377
[7,     4] loss: 1.369
[8,     4] loss: 1.360
[9,     4] loss: 1.316
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005807221286679355,
 'learning_rate_Hydroxylation-K': 0.00178661602884821,
 'learning_rate_Methylation-K': 0.0020968956081004768,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8368758304753712,
 'loss_weight_Methylation-K': 0.9128026394654587,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 442463644,
 'sample_weights': [0.6820112863435035, 0.5108394056202354],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.164473659747648,
 'weight_decay_Hydroxylation-K': 9.879528174032272,
 'weight_decay_Methylation-K': 0.18976814506911888}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.383
[3,     4] loss: 1.395
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 8.840708302016364e-05,
 'learning_rate_Hydroxylation-K': 0.008854822255773467,
 'learning_rate_Methylation-K': 0.0032249393729334233,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7305541266943192,
 'loss_weight_Methylation-K': 0.6961069261045656,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2016091112,
 'sample_weights': [0.8368758304753712, 0.9128026394654587],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.9206483439207425,
 'weight_decay_Hydroxylation-K': 2.533052264940384,
 'weight_decay_Methylation-K': 6.212378596615028}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.370
[2,     4] loss: 1.391
[3,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003485376333538035,
 'learning_rate_Hydroxylation-K': 0.000867577204168673,
 'learning_rate_Methylation-K': 0.0008449307018901901,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7489076395034777,
 'loss_weight_Methylation-K': 0.07647403923910095,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2523101671,
 'sample_weights': [0.7305541266943192, 0.6961069261045656],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.636451944610047,
 'weight_decay_Hydroxylation-K': 6.019194673925896,
 'weight_decay_Methylation-K': 8.8549716877015}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.389
[3,     4] loss: 1.387
[4,     4] loss: 1.386
[5,     4] loss: 1.386
[6,     4] loss: 1.383
[7,     4] loss: 1.386
[8,     4] loss: 1.382
[9,     4] loss: 1.383
[10,     4] loss: 1.387
[11,     4] loss: 1.380
[12,     4] loss: 1.367
[13,     4] loss: 1.336
[14,     4] loss: 1.285
[15,     4] loss: 1.241
[16,     4] loss: 1.222
[17,     4] loss: 1.245
[18,     4] loss: 1.136
[19,     4] loss: 1.191
[20,     4] loss: 1.056
[21,     4] loss: 1.062
[22,     4] loss: 0.988
[23,     4] loss: 1.032
[24,     4] loss: 0.954
[25,     4] loss: 0.955
[26,     4] loss: 0.902
[27,     4] loss: 0.984
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002585695975774342,
 'learning_rate_Hydroxylation-K': 0.003338519816469239,
 'learning_rate_Methylation-K': 0.005433715913339259,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.636261515776145,
 'loss_weight_Methylation-K': 0.7400288903595486,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2323617368,
 'sample_weights': [0.7489076395034777, 0.07647403923910095],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.663867933124921,
 'weight_decay_Hydroxylation-K': 5.201299408566463,
 'weight_decay_Methylation-K': 4.337387000505053}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.384
[3,     4] loss: 1.391
[4,     4] loss: 1.370
[5,     4] loss: 1.342
[6,     4] loss: 1.288
[7,     4] loss: 1.207
[8,     4] loss: 1.132
[9,     4] loss: 1.145
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023855704694465763,
 'learning_rate_Hydroxylation-K': 0.007447918926574341,
 'learning_rate_Methylation-K': 0.008855869353440746,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2037126968930017,
 'loss_weight_Methylation-K': 0.34865986240200747,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 636168914,
 'sample_weights': [0.636261515776145, 0.7400288903595486],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2092464459933954,
 'weight_decay_Hydroxylation-K': 8.908050163951355,
 'weight_decay_Methylation-K': 1.4718108984399023}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.383
[6,     4] loss: 1.379
[7,     4] loss: 1.375
[8,     4] loss: 1.366
[9,     4] loss: 1.350
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003872579920099965,
 'learning_rate_Hydroxylation-K': 0.005551609295317785,
 'learning_rate_Methylation-K': 0.004721065991734561,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1964956413726466,
 'loss_weight_Methylation-K': 0.31913897543294467,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4122231130,
 'sample_weights': [0.2037126968930017, 0.34865986240200747],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.6504418852345792,
 'weight_decay_Hydroxylation-K': 8.865243488180463,
 'weight_decay_Methylation-K': 4.128418554208767}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.381
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003053432853843307,
 'learning_rate_Hydroxylation-K': 0.005865853151929252,
 'learning_rate_Methylation-K': 0.007108905905612582,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8540293525173805,
 'loss_weight_Methylation-K': 0.5544861258068126,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3551845685,
 'sample_weights': [0.1964956413726466, 0.31913897543294467],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.06850723527397,
 'weight_decay_Hydroxylation-K': 1.4679640673714345,
 'weight_decay_Methylation-K': 6.729050012914598}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.381
[2,     4] loss: 1.383
[3,     4] loss: 1.388
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.377
[8,     4] loss: 1.374
[9,     4] loss: 1.328
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019232158987334772,
 'learning_rate_Hydroxylation-K': 0.008221805776731235,
 'learning_rate_Methylation-K': 0.004664266417652868,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24954869156891435,
 'loss_weight_Methylation-K': 0.5949228301734155,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1430611671,
 'sample_weights': [0.8540293525173805, 0.5544861258068126],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.611554281690848,
 'weight_decay_Hydroxylation-K': 1.4457665086328264,
 'weight_decay_Methylation-K': 4.259809749433871}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.401
[2,     4] loss: 1.385
[3,     4] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012552935783659406,
 'learning_rate_Hydroxylation-K': 0.008053059697967399,
 'learning_rate_Methylation-K': 0.003948373022916495,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5152829217023609,
 'loss_weight_Methylation-K': 0.511721432258023,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1043400924,
 'sample_weights': [0.24954869156891435, 0.5949228301734155],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.066653227749104,
 'weight_decay_Hydroxylation-K': 6.741194748891868,
 'weight_decay_Methylation-K': 2.1276911293620233}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.383
[3,     4] loss: 1.378
[4,     4] loss: 1.378
[5,     4] loss: 1.361
[6,     4] loss: 1.338
[7,     4] loss: 1.290
[8,     4] loss: 1.227
[9,     4] loss: 1.215
[10,     4] loss: 1.130
[11,     4] loss: 1.110
[12,     4] loss: 1.196
[13,     4] loss: 1.087
[14,     4] loss: 1.063
[15,     4] loss: 0.974
[16,     4] loss: 1.022
[17,     4] loss: 0.976
[18,     4] loss: 0.876
[19,     4] loss: 0.873
[20,     4] loss: 0.879
[21,     4] loss: 0.936
[22,     4] loss: 0.872
[23,     4] loss: 0.890
[24,     4] loss: 0.881
[25,     4] loss: 0.936
[26,     4] loss: 0.861
[27,     4] loss: 0.851
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0001835735458479476,
 'learning_rate_Hydroxylation-K': 0.006131924675745792,
 'learning_rate_Methylation-K': 0.003265300153820073,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.32539371998252115,
 'loss_weight_Methylation-K': 0.6820298845368437,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1683870769,
 'sample_weights': [0.5152829217023609, 0.511721432258023],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.562366387442722,
 'weight_decay_Hydroxylation-K': 4.038288718420573,
 'weight_decay_Methylation-K': 5.298197461974176}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.391
[3,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008661759726640711,
 'learning_rate_Hydroxylation-K': 0.008030830063868915,
 'learning_rate_Methylation-K': 0.009278288912191988,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6054571080429485,
 'loss_weight_Methylation-K': 0.12684495699585252,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3212706200,
 'sample_weights': [0.32539371998252115, 0.6820298845368437],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.627205598524268,
 'weight_decay_Hydroxylation-K': 5.552493704921204,
 'weight_decay_Methylation-K': 0.7857072261111986}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.393
[3,     4] loss: 1.388
[4,     4] loss: 1.385
[5,     4] loss: 1.390
[6,     4] loss: 1.389
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003157616727923373,
 'learning_rate_Hydroxylation-K': 0.006879697734403245,
 'learning_rate_Methylation-K': 0.006779634552984555,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6653294239979758,
 'loss_weight_Methylation-K': 0.7775868372052781,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2124578266,
 'sample_weights': [0.6054571080429485, 0.12684495699585252],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.176800241866006,
 'weight_decay_Hydroxylation-K': 5.453262448129785,
 'weight_decay_Methylation-K': 8.94904649459408}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.384
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00033637919626189187,
 'learning_rate_Hydroxylation-K': 0.0074357405233161315,
 'learning_rate_Methylation-K': 0.005237976886885548,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.44005298998771886,
 'loss_weight_Methylation-K': 0.5717965663254618,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3557439510,
 'sample_weights': [0.6653294239979758, 0.7775868372052781],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.081282008843092,
 'weight_decay_Hydroxylation-K': 6.752537144121364,
 'weight_decay_Methylation-K': 0.9551717958782724}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.389
[3,     4] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007435121207852547,
 'learning_rate_Hydroxylation-K': 0.004932856030590462,
 'learning_rate_Methylation-K': 0.005843695540136759,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7063047729893628,
 'loss_weight_Methylation-K': 0.35587634415308395,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1747376754,
 'sample_weights': [0.44005298998771886, 0.5717965663254618],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.669377676226036,
 'weight_decay_Hydroxylation-K': 5.303890173011867,
 'weight_decay_Methylation-K': 7.787110630782958}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.402
[2,     4] loss: 1.390
[3,     4] loss: 1.388
[4,     4] loss: 1.389
[5,     4] loss: 1.385
[6,     4] loss: 1.384
[7,     4] loss: 1.388
[8,     4] loss: 1.386
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002938325726944752,
 'learning_rate_Hydroxylation-K': 0.009056867192874086,
 'learning_rate_Methylation-K': 0.005359640088079805,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3661912526794945,
 'loss_weight_Methylation-K': 0.6665938381224007,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3988311411,
 'sample_weights': [0.7063047729893628, 0.35587634415308395],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.1750261419851356,
 'weight_decay_Hydroxylation-K': 6.261997351167594,
 'weight_decay_Methylation-K': 5.9175167268637345}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.380
[5,     4] loss: 1.370
[6,     4] loss: 1.345
[7,     4] loss: 1.305
[8,     4] loss: 1.224
[9,     4] loss: 1.159
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0004089058954034842,
 'learning_rate_Hydroxylation-K': 0.005862861296310643,
 'learning_rate_Methylation-K': 0.003141467058306179,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5368051548351103,
 'loss_weight_Methylation-K': 0.5799442486696333,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2002164927,
 'sample_weights': [0.3661912526794945, 0.6665938381224007],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.336283394368687,
 'weight_decay_Hydroxylation-K': 7.459466152538355,
 'weight_decay_Methylation-K': 9.880416396743728}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.393
[3,     4] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027895934110840227,
 'learning_rate_Hydroxylation-K': 0.00205055891598259,
 'learning_rate_Methylation-K': 0.009836321836040733,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2830339064041349,
 'loss_weight_Methylation-K': 0.020715978744173344,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4075877582,
 'sample_weights': [0.5368051548351103, 0.5799442486696333],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.680052822313787,
 'weight_decay_Hydroxylation-K': 8.420595830450564,
 'weight_decay_Methylation-K': 2.5950132737142546}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.386
[3,     4] loss: 1.389
[4,     4] loss: 1.382
[5,     4] loss: 1.385
[6,     4] loss: 1.385
[7,     4] loss: 1.382
[8,     4] loss: 1.378
[9,     4] loss: 1.368
[10,     4] loss: 1.340
[11,     4] loss: 1.312
[12,     4] loss: 1.264
[13,     4] loss: 1.193
[14,     4] loss: 1.189
[15,     4] loss: 1.222
[16,     4] loss: 1.123
[17,     4] loss: 1.131
[18,     4] loss: 1.001
[19,     4] loss: 1.027
[20,     4] loss: 0.984
[21,     4] loss: 0.948
[22,     4] loss: 0.946
[23,     4] loss: 0.960
[24,     4] loss: 0.961
[25,     4] loss: 0.944
[26,     4] loss: 0.922
[27,     4] loss: 0.839
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002642905078655067,
 'learning_rate_Hydroxylation-K': 0.0024808753191254986,
 'learning_rate_Methylation-K': 0.002023000342278348,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.29620999572036794,
 'loss_weight_Methylation-K': 0.5568101528210954,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 769150108,
 'sample_weights': [0.2830339064041349, 0.020715978744173344],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.754909284826479,
 'weight_decay_Hydroxylation-K': 6.096241135456285,
 'weight_decay_Methylation-K': 5.816248685742307}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.389
[3,     4] loss: 1.392
[4,     4] loss: 1.388
[5,     4] loss: 1.384
[6,     4] loss: 1.383
[7,     4] loss: 1.376
[8,     4] loss: 1.367
[9,     4] loss: 1.326
[10,     4] loss: 1.262
[11,     4] loss: 1.208
[12,     4] loss: 1.175
[13,     4] loss: 1.148
[14,     4] loss: 1.191
[15,     4] loss: 1.130
[16,     4] loss: 1.103
[17,     4] loss: 1.086
[18,     4] loss: 1.052
[19,     4] loss: 1.006
[20,     4] loss: 0.939
[21,     4] loss: 0.973
[22,     4] loss: 0.975
[23,     4] loss: 0.918
[24,     4] loss: 0.948
[25,     4] loss: 0.977
[26,     4] loss: 0.924
[27,     4] loss: 0.905
[28,     4] loss: 0.860
[29,     4] loss: 0.903
[30,     4] loss: 0.883
[31,     4] loss: 0.821
[32,     4] loss: 0.820
[33,     4] loss: 0.836
[34,     4] loss: 0.948
[35,     4] loss: 0.879
[36,     4] loss: 0.935
[37,     4] loss: 0.888
[38,     4] loss: 0.904
[39,     4] loss: 0.827
[40,     4] loss: 0.850
[41,     4] loss: 0.825
[42,     4] loss: 0.762
[43,     4] loss: 0.768
[44,     4] loss: 0.792
[45,     4] loss: 0.814
[46,     4] loss: 0.821
[47,     4] loss: 0.819
[48,     4] loss: 0.932
[49,     4] loss: 0.959
[50,     4] loss: 0.927
[51,     4] loss: 0.818
[52,     4] loss: 0.817
[53,     4] loss: 0.786
[54,     4] loss: 0.759
[55,     4] loss: 0.826
[56,     4] loss: 0.787
[57,     4] loss: 0.776
[58,     4] loss: 0.826
[59,     4] loss: 0.838
[60,     4] loss: 0.852
[61,     4] loss: 0.920
[62,     4] loss: 0.844
[63,     4] loss: 0.813
[64,     4] loss: 0.827
[65,     4] loss: 0.800
[66,     4] loss: 0.802
[67,     4] loss: 0.797
[68,     4] loss: 0.758
[69,     4] loss: 0.750
[70,     4] loss: 0.728
[71,     4] loss: 0.734
[72,     4] loss: 0.740
[73,     4] loss: 0.779
[74,     4] loss: 0.816
[75,     4] loss: 0.898
[76,     4] loss: 0.920
[77,     4] loss: 0.790
[78,     4] loss: 0.879
[79,     4] loss: 0.833
[80,     4] loss: 0.828
[81,     4] loss: 0.788
[82,     4] loss: 0.830
[83,     4] loss: 0.799
[84,     4] loss: 0.794
[85,     4] loss: 0.779
[86,     4] loss: 0.794
[87,     4] loss: 0.760
[88,     4] loss: 0.807
[89,     4] loss: 0.768
[90,     4] loss: 0.825
[91,     4] loss: 0.869
[92,     4] loss: 0.838
[93,     4] loss: 0.831
[94,     4] loss: 0.794
[95,     4] loss: 0.769
[96,     4] loss: 0.758
[97,     4] loss: 0.757
[98,     4] loss: 0.788
[99,     4] loss: 0.776
[100,     4] loss: 0.764
[101,     4] loss: 0.751
[102,     4] loss: 0.753
[103,     4] loss: 0.767
[104,     4] loss: 0.892
[105,     4] loss: 0.882
[106,     4] loss: 0.804
[107,     4] loss: 0.777
[108,     4] loss: 0.767
[109,     4] loss: 0.787
[110,     4] loss: 0.784
[111,     4] loss: 0.776
[112,     4] loss: 0.858
[113,     4] loss: 0.766
[114,     4] loss: 0.800
[115,     4] loss: 0.759
[116,     4] loss: 0.780
[117,     4] loss: 0.824
[118,     4] loss: 0.808
[119,     4] loss: 1.048
[120,     4] loss: 0.943
[121,     4] loss: 0.832
[122,     4] loss: 0.801
[123,     4] loss: 0.753
[124,     4] loss: 0.754
[125,     4] loss: 0.773
[126,     4] loss: 0.781
[127,     4] loss: 0.966
[128,     4] loss: 0.844
[129,     4] loss: 0.808
[130,     4] loss: 0.780
[131,     4] loss: 0.759
[132,     4] loss: 0.790
[133,     4] loss: 0.746
Early stopping applied (best metric=0.2895917296409607)
Finished Training
Total time taken: 67.32700538635254
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.385
[3,     4] loss: 1.385
[4,     4] loss: 1.382
[5,     4] loss: 1.382
[6,     4] loss: 1.378
[7,     4] loss: 1.369
[8,     4] loss: 1.344
[9,     4] loss: 1.317
[10,     4] loss: 1.272
[11,     4] loss: 1.174
[12,     4] loss: 1.097
[13,     4] loss: 1.008
[14,     4] loss: 1.050
[15,     4] loss: 1.098
[16,     4] loss: 1.082
[17,     4] loss: 1.052
[18,     4] loss: 0.995
[19,     4] loss: 0.983
[20,     4] loss: 1.003
[21,     4] loss: 0.974
[22,     4] loss: 0.995
[23,     4] loss: 1.046
[24,     4] loss: 0.946
[25,     4] loss: 0.911
[26,     4] loss: 0.961
[27,     4] loss: 0.898
[28,     4] loss: 0.880
[29,     4] loss: 0.917
[30,     4] loss: 0.921
[31,     4] loss: 0.896
[32,     4] loss: 0.895
[33,     4] loss: 0.841
[34,     4] loss: 0.840
[35,     4] loss: 0.829
[36,     4] loss: 0.873
[37,     4] loss: 0.851
[38,     4] loss: 0.866
[39,     4] loss: 0.894
[40,     4] loss: 0.841
[41,     4] loss: 0.851
[42,     4] loss: 0.813
[43,     4] loss: 0.822
[44,     4] loss: 0.873
[45,     4] loss: 0.824
[46,     4] loss: 0.805
[47,     4] loss: 0.820
[48,     4] loss: 0.835
[49,     4] loss: 0.777
[50,     4] loss: 0.779
[51,     4] loss: 0.748
[52,     4] loss: 0.764
[53,     4] loss: 0.752
[54,     4] loss: 0.768
[55,     4] loss: 0.774
[56,     4] loss: 0.833
[57,     4] loss: 0.835
[58,     4] loss: 0.801
[59,     4] loss: 0.993
[60,     4] loss: 0.930
[61,     4] loss: 0.984
[62,     4] loss: 0.892
[63,     4] loss: 0.861
[64,     4] loss: 0.793
[65,     4] loss: 0.790
[66,     4] loss: 0.776
[67,     4] loss: 0.773
[68,     4] loss: 0.763
[69,     4] loss: 0.827
[70,     4] loss: 0.788
[71,     4] loss: 0.794
[72,     4] loss: 0.785
[73,     4] loss: 0.805
[74,     4] loss: 0.799
[75,     4] loss: 0.770
[76,     4] loss: 0.768
[77,     4] loss: 0.761
[78,     4] loss: 0.769
[79,     4] loss: 0.795
[80,     4] loss: 0.797
[81,     4] loss: 0.801
[82,     4] loss: 0.772
[83,     4] loss: 0.764
[84,     4] loss: 0.771
[85,     4] loss: 0.816
[86,     4] loss: 0.765
[87,     4] loss: 0.784
[88,     4] loss: 0.794
[89,     4] loss: 0.963
[90,     4] loss: 1.013
[91,     4] loss: 0.870
[92,     4] loss: 0.821
[93,     4] loss: 0.815
[94,     4] loss: 0.806
[95,     4] loss: 0.770
[96,     4] loss: 0.779
[97,     4] loss: 0.841
Early stopping applied (best metric=0.3580304980278015)
Finished Training
Total time taken: 49.11991477012634
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.385
[3,     4] loss: 1.383
[4,     4] loss: 1.388
[5,     4] loss: 1.387
[6,     4] loss: 1.384
[7,     4] loss: 1.385
[8,     4] loss: 1.381
[9,     4] loss: 1.365
[10,     4] loss: 1.350
[11,     4] loss: 1.293
[12,     4] loss: 1.235
[13,     4] loss: 1.285
[14,     4] loss: 1.228
[15,     4] loss: 1.205
[16,     4] loss: 1.153
[17,     4] loss: 1.109
[18,     4] loss: 1.029
[19,     4] loss: 0.964
[20,     4] loss: 0.940
[21,     4] loss: 0.978
[22,     4] loss: 0.999
[23,     4] loss: 1.006
[24,     4] loss: 0.929
[25,     4] loss: 0.942
[26,     4] loss: 0.867
[27,     4] loss: 0.826
[28,     4] loss: 0.823
[29,     4] loss: 0.834
[30,     4] loss: 0.812
[31,     4] loss: 0.894
[32,     4] loss: 0.993
[33,     4] loss: 0.877
[34,     4] loss: 0.854
[35,     4] loss: 0.849
[36,     4] loss: 0.830
[37,     4] loss: 0.815
[38,     4] loss: 0.761
[39,     4] loss: 0.816
[40,     4] loss: 0.849
[41,     4] loss: 0.945
[42,     4] loss: 0.867
[43,     4] loss: 0.863
[44,     4] loss: 0.816
[45,     4] loss: 0.911
[46,     4] loss: 0.956
[47,     4] loss: 0.910
[48,     4] loss: 0.861
[49,     4] loss: 0.797
[50,     4] loss: 0.762
[51,     4] loss: 0.750
[52,     4] loss: 0.754
[53,     4] loss: 0.847
[54,     4] loss: 0.792
[55,     4] loss: 0.781
[56,     4] loss: 0.781
[57,     4] loss: 0.758
[58,     4] loss: 0.756
[59,     4] loss: 0.784
[60,     4] loss: 0.771
[61,     4] loss: 0.808
[62,     4] loss: 0.768
[63,     4] loss: 0.777
[64,     4] loss: 0.806
[65,     4] loss: 0.820
[66,     4] loss: 0.791
[67,     4] loss: 0.898
Early stopping applied (best metric=0.38839685916900635)
Finished Training
Total time taken: 33.592808961868286
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.388
[3,     4] loss: 1.385
[4,     4] loss: 1.385
[5,     4] loss: 1.378
[6,     4] loss: 1.376
[7,     4] loss: 1.355
[8,     4] loss: 1.316
[9,     4] loss: 1.262
[10,     4] loss: 1.280
[11,     4] loss: 1.178
[12,     4] loss: 1.227
[13,     4] loss: 1.134
[14,     4] loss: 1.115
[15,     4] loss: 1.177
[16,     4] loss: 1.047
[17,     4] loss: 1.027
[18,     4] loss: 0.960
[19,     4] loss: 0.950
[20,     4] loss: 0.983
[21,     4] loss: 0.980
[22,     4] loss: 1.006
[23,     4] loss: 1.007
[24,     4] loss: 0.946
[25,     4] loss: 0.918
[26,     4] loss: 0.897
[27,     4] loss: 0.858
[28,     4] loss: 0.857
[29,     4] loss: 0.854
[30,     4] loss: 0.831
[31,     4] loss: 0.942
[32,     4] loss: 0.947
[33,     4] loss: 0.925
[34,     4] loss: 0.863
[35,     4] loss: 0.819
[36,     4] loss: 0.789
[37,     4] loss: 0.819
[38,     4] loss: 0.841
[39,     4] loss: 0.808
[40,     4] loss: 0.915
[41,     4] loss: 0.857
[42,     4] loss: 0.801
[43,     4] loss: 0.797
[44,     4] loss: 0.789
[45,     4] loss: 0.757
[46,     4] loss: 0.784
[47,     4] loss: 0.874
[48,     4] loss: 0.934
[49,     4] loss: 0.911
[50,     4] loss: 0.832
[51,     4] loss: 0.795
[52,     4] loss: 0.780
[53,     4] loss: 0.735
[54,     4] loss: 0.738
[55,     4] loss: 0.774
[56,     4] loss: 0.816
[57,     4] loss: 0.823
[58,     4] loss: 0.782
[59,     4] loss: 0.796
[60,     4] loss: 0.847
[61,     4] loss: 0.841
[62,     4] loss: 0.802
[63,     4] loss: 0.823
[64,     4] loss: 0.785
[65,     4] loss: 0.784
Early stopping applied (best metric=0.3269196152687073)
Finished Training
Total time taken: 32.49923491477966
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.398
[2,     4] loss: 1.388
[3,     4] loss: 1.389
[4,     4] loss: 1.386
[5,     4] loss: 1.385
[6,     4] loss: 1.388
[7,     4] loss: 1.385
[8,     4] loss: 1.384
[9,     4] loss: 1.385
[10,     4] loss: 1.381
[11,     4] loss: 1.368
[12,     4] loss: 1.324
[13,     4] loss: 1.283
[14,     4] loss: 1.211
[15,     4] loss: 1.241
[16,     4] loss: 1.197
[17,     4] loss: 1.157
[18,     4] loss: 1.109
[19,     4] loss: 1.068
[20,     4] loss: 1.024
[21,     4] loss: 1.070
[22,     4] loss: 0.942
[23,     4] loss: 0.907
[24,     4] loss: 0.892
[25,     4] loss: 0.869
[26,     4] loss: 0.871
[27,     4] loss: 0.916
[28,     4] loss: 1.154
[29,     4] loss: 1.063
[30,     4] loss: 0.996
[31,     4] loss: 0.956
[32,     4] loss: 0.887
[33,     4] loss: 0.801
[34,     4] loss: 0.821
[35,     4] loss: 0.782
[36,     4] loss: 0.805
[37,     4] loss: 0.779
[38,     4] loss: 0.751
[39,     4] loss: 0.768
[40,     4] loss: 0.792
[41,     4] loss: 0.801
[42,     4] loss: 0.871
[43,     4] loss: 0.844
[44,     4] loss: 0.774
[45,     4] loss: 0.811
[46,     4] loss: 0.777
[47,     4] loss: 0.781
[48,     4] loss: 0.762
[49,     4] loss: 0.805
[50,     4] loss: 0.824
[51,     4] loss: 0.802
[52,     4] loss: 0.869
[53,     4] loss: 0.862
[54,     4] loss: 0.795
[55,     4] loss: 0.816
[56,     4] loss: 0.769
[57,     4] loss: 0.781
[58,     4] loss: 0.817
[59,     4] loss: 0.742
[60,     4] loss: 0.762
[61,     4] loss: 0.751
[62,     4] loss: 0.752
[63,     4] loss: 0.808
[64,     4] loss: 0.772
[65,     4] loss: 0.802
Early stopping applied (best metric=0.4590553045272827)
Finished Training
Total time taken: 32.915231704711914
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.384
[3,     4] loss: 1.385
[4,     4] loss: 1.371
[5,     4] loss: 1.365
[6,     4] loss: 1.334
[7,     4] loss: 1.273
[8,     4] loss: 1.215
[9,     4] loss: 1.235
[10,     4] loss: 1.180
[11,     4] loss: 1.157
[12,     4] loss: 1.146
[13,     4] loss: 1.046
[14,     4] loss: 1.080
[15,     4] loss: 1.027
[16,     4] loss: 1.061
[17,     4] loss: 1.053
[18,     4] loss: 1.058
[19,     4] loss: 0.984
[20,     4] loss: 0.946
[21,     4] loss: 0.984
[22,     4] loss: 0.917
[23,     4] loss: 0.883
[24,     4] loss: 0.851
[25,     4] loss: 0.848
[26,     4] loss: 0.878
[27,     4] loss: 1.019
[28,     4] loss: 0.893
[29,     4] loss: 0.910
[30,     4] loss: 0.877
[31,     4] loss: 0.897
[32,     4] loss: 0.857
[33,     4] loss: 0.863
[34,     4] loss: 0.874
[35,     4] loss: 0.838
[36,     4] loss: 0.857
[37,     4] loss: 0.865
[38,     4] loss: 0.839
[39,     4] loss: 0.901
[40,     4] loss: 0.958
[41,     4] loss: 0.890
[42,     4] loss: 0.903
[43,     4] loss: 0.890
[44,     4] loss: 0.827
[45,     4] loss: 0.800
[46,     4] loss: 0.812
[47,     4] loss: 0.783
[48,     4] loss: 0.835
[49,     4] loss: 0.767
[50,     4] loss: 0.790
[51,     4] loss: 0.778
[52,     4] loss: 0.787
[53,     4] loss: 0.760
[54,     4] loss: 0.786
[55,     4] loss: 1.054
[56,     4] loss: 0.893
[57,     4] loss: 0.923
[58,     4] loss: 0.823
[59,     4] loss: 0.788
[60,     4] loss: 0.839
[61,     4] loss: 0.778
[62,     4] loss: 0.747
[63,     4] loss: 0.794
[64,     4] loss: 0.771
[65,     4] loss: 0.785
[66,     4] loss: 0.795
[67,     4] loss: 0.757
[68,     4] loss: 0.764
[69,     4] loss: 0.791
[70,     4] loss: 0.807
[71,     4] loss: 0.784
[72,     4] loss: 0.785
[73,     4] loss: 0.774
[74,     4] loss: 0.835
[75,     4] loss: 0.867
[76,     4] loss: 0.838
[77,     4] loss: 0.813
[78,     4] loss: 0.792
[79,     4] loss: 0.814
[80,     4] loss: 0.817
[81,     4] loss: 0.856
[82,     4] loss: 0.799
[83,     4] loss: 0.842
[84,     4] loss: 0.829
[85,     4] loss: 0.886
[86,     4] loss: 0.812
[87,     4] loss: 0.848
[88,     4] loss: 0.836
[89,     4] loss: 0.772
[90,     4] loss: 0.774
[91,     4] loss: 0.757
[92,     4] loss: 0.761
[93,     4] loss: 0.788
[94,     4] loss: 0.768
[95,     4] loss: 0.806
[96,     4] loss: 0.796
[97,     4] loss: 0.799
[98,     4] loss: 0.786
[99,     4] loss: 0.763
[100,     4] loss: 0.779
[101,     4] loss: 0.766
[102,     4] loss: 0.784
[103,     4] loss: 0.788
[104,     4] loss: 0.762
[105,     4] loss: 0.744
[106,     4] loss: 0.768
[107,     4] loss: 0.758
[108,     4] loss: 0.748
[109,     4] loss: 0.776
[110,     4] loss: 0.753
[111,     4] loss: 0.746
[112,     4] loss: 0.744
[113,     4] loss: 0.746
[114,     4] loss: 0.840
[115,     4] loss: 0.869
[116,     4] loss: 0.843
[117,     4] loss: 0.920
[118,     4] loss: 0.898
[119,     4] loss: 0.848
[120,     4] loss: 0.798
[121,     4] loss: 0.805
[122,     4] loss: 0.757
[123,     4] loss: 0.754
[124,     4] loss: 0.756
[125,     4] loss: 0.744
[126,     4] loss: 0.738
[127,     4] loss: 0.731
[128,     4] loss: 0.729
[129,     4] loss: 0.741
[130,     4] loss: 1.098
[131,     4] loss: 1.188
Early stopping applied (best metric=0.47183817625045776)
Finished Training
Total time taken: 67.95606851577759
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.395
[3,     4] loss: 1.389
[4,     4] loss: 1.385
[5,     4] loss: 1.381
[6,     4] loss: 1.386
[7,     4] loss: 1.378
[8,     4] loss: 1.377
[9,     4] loss: 1.368
[10,     4] loss: 1.335
[11,     4] loss: 1.282
[12,     4] loss: 1.207
[13,     4] loss: 1.136
[14,     4] loss: 1.122
[15,     4] loss: 1.131
[16,     4] loss: 1.104
[17,     4] loss: 1.137
[18,     4] loss: 1.055
[19,     4] loss: 1.015
[20,     4] loss: 1.056
[21,     4] loss: 1.010
[22,     4] loss: 1.009
[23,     4] loss: 0.917
[24,     4] loss: 0.917
[25,     4] loss: 0.937
[26,     4] loss: 0.953
[27,     4] loss: 0.927
[28,     4] loss: 0.901
[29,     4] loss: 0.930
[30,     4] loss: 0.944
[31,     4] loss: 0.895
[32,     4] loss: 0.897
[33,     4] loss: 0.931
[34,     4] loss: 0.887
[35,     4] loss: 0.848
[36,     4] loss: 0.777
[37,     4] loss: 0.815
[38,     4] loss: 0.799
[39,     4] loss: 0.745
[40,     4] loss: 0.798
[41,     4] loss: 0.850
[42,     4] loss: 0.888
[43,     4] loss: 0.842
[44,     4] loss: 0.854
[45,     4] loss: 0.830
[46,     4] loss: 0.781
[47,     4] loss: 0.840
[48,     4] loss: 0.816
[49,     4] loss: 0.770
[50,     4] loss: 0.759
[51,     4] loss: 0.729
[52,     4] loss: 0.740
[53,     4] loss: 0.779
[54,     4] loss: 0.773
[55,     4] loss: 0.753
[56,     4] loss: 0.730
[57,     4] loss: 0.761
[58,     4] loss: 1.029
[59,     4] loss: 1.089
[60,     4] loss: 1.080
[61,     4] loss: 0.976
[62,     4] loss: 0.894
[63,     4] loss: 0.835
[64,     4] loss: 0.824
[65,     4] loss: 0.828
[66,     4] loss: 0.823
[67,     4] loss: 0.796
[68,     4] loss: 0.817
[69,     4] loss: 0.766
[70,     4] loss: 0.797
[71,     4] loss: 0.881
[72,     4] loss: 0.816
[73,     4] loss: 0.790
[74,     4] loss: 0.784
[75,     4] loss: 0.810
[76,     4] loss: 0.827
[77,     4] loss: 0.868
[78,     4] loss: 0.868
Early stopping applied (best metric=0.44055062532424927)
Finished Training
Total time taken: 41.22401738166809
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.399
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.385
[5,     4] loss: 1.389
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.384
[9,     4] loss: 1.384
[10,     4] loss: 1.374
[11,     4] loss: 1.368
[12,     4] loss: 1.341
[13,     4] loss: 1.320
[14,     4] loss: 1.262
[15,     4] loss: 1.218
[16,     4] loss: 1.192
[17,     4] loss: 1.164
[18,     4] loss: 1.151
[19,     4] loss: 1.151
[20,     4] loss: 0.982
[21,     4] loss: 1.089
[22,     4] loss: 1.015
[23,     4] loss: 0.976
[24,     4] loss: 0.904
[25,     4] loss: 0.948
[26,     4] loss: 0.909
[27,     4] loss: 0.883
[28,     4] loss: 0.915
[29,     4] loss: 0.889
[30,     4] loss: 0.854
[31,     4] loss: 0.875
[32,     4] loss: 0.847
[33,     4] loss: 0.832
[34,     4] loss: 0.961
[35,     4] loss: 0.908
[36,     4] loss: 0.822
[37,     4] loss: 0.783
[38,     4] loss: 0.842
[39,     4] loss: 0.846
[40,     4] loss: 0.792
[41,     4] loss: 0.823
[42,     4] loss: 0.771
[43,     4] loss: 0.827
[44,     4] loss: 0.885
[45,     4] loss: 0.817
[46,     4] loss: 0.828
[47,     4] loss: 0.795
[48,     4] loss: 0.781
[49,     4] loss: 0.773
[50,     4] loss: 0.817
[51,     4] loss: 0.769
[52,     4] loss: 0.741
[53,     4] loss: 0.787
[54,     4] loss: 0.845
[55,     4] loss: 0.970
[56,     4] loss: 0.895
[57,     4] loss: 0.864
[58,     4] loss: 0.810
[59,     4] loss: 0.858
[60,     4] loss: 0.768
[61,     4] loss: 0.768
[62,     4] loss: 0.768
[63,     4] loss: 0.754
[64,     4] loss: 0.762
[65,     4] loss: 0.749
[66,     4] loss: 0.734
[67,     4] loss: 0.775
[68,     4] loss: 0.797
[69,     4] loss: 0.814
[70,     4] loss: 0.809
[71,     4] loss: 0.775
[72,     4] loss: 0.843
[73,     4] loss: 0.940
[74,     4] loss: 0.944
[75,     4] loss: 0.970
[76,     4] loss: 0.918
[77,     4] loss: 0.835
[78,     4] loss: 0.766
[79,     4] loss: 0.752
Early stopping applied (best metric=0.28455275297164917)
Finished Training
Total time taken: 42.14838719367981
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.384
[3,     4] loss: 1.373
[4,     4] loss: 1.361
[5,     4] loss: 1.335
[6,     4] loss: 1.239
[7,     4] loss: 1.161
[8,     4] loss: 1.093
[9,     4] loss: 1.093
[10,     4] loss: 1.009
[11,     4] loss: 0.992
[12,     4] loss: 0.961
[13,     4] loss: 0.948
[14,     4] loss: 1.036
[15,     4] loss: 0.941
[16,     4] loss: 0.990
[17,     4] loss: 0.973
[18,     4] loss: 0.911
[19,     4] loss: 0.970
[20,     4] loss: 0.899
[21,     4] loss: 0.883
[22,     4] loss: 1.007
[23,     4] loss: 0.980
[24,     4] loss: 0.947
[25,     4] loss: 0.960
[26,     4] loss: 0.942
[27,     4] loss: 0.945
[28,     4] loss: 0.874
[29,     4] loss: 0.939
[30,     4] loss: 0.919
[31,     4] loss: 0.905
[32,     4] loss: 0.862
[33,     4] loss: 0.881
[34,     4] loss: 0.818
[35,     4] loss: 0.840
[36,     4] loss: 0.831
[37,     4] loss: 0.817
[38,     4] loss: 0.872
[39,     4] loss: 0.840
[40,     4] loss: 0.812
[41,     4] loss: 0.828
[42,     4] loss: 0.799
[43,     4] loss: 0.800
[44,     4] loss: 0.767
[45,     4] loss: 0.786
[46,     4] loss: 0.856
[47,     4] loss: 0.841
[48,     4] loss: 0.856
[49,     4] loss: 0.829
[50,     4] loss: 0.827
[51,     4] loss: 0.835
[52,     4] loss: 0.847
[53,     4] loss: 0.814
Early stopping applied (best metric=0.5417439937591553)
Finished Training
Total time taken: 29.998075246810913
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.387
[2,     4] loss: 1.385
[3,     4] loss: 1.393
[4,     4] loss: 1.386
[5,     4] loss: 1.387
[6,     4] loss: 1.383
[7,     4] loss: 1.387
[8,     4] loss: 1.385
[9,     4] loss: 1.385
[10,     4] loss: 1.383
[11,     4] loss: 1.378
[12,     4] loss: 1.364
[13,     4] loss: 1.325
[14,     4] loss: 1.295
[15,     4] loss: 1.207
[16,     4] loss: 1.182
[17,     4] loss: 1.281
[18,     4] loss: 1.162
[19,     4] loss: 1.138
[20,     4] loss: 1.062
[21,     4] loss: 1.062
[22,     4] loss: 1.031
[23,     4] loss: 1.044
[24,     4] loss: 0.961
[25,     4] loss: 0.986
[26,     4] loss: 0.996
[27,     4] loss: 0.956
[28,     4] loss: 1.018
[29,     4] loss: 1.007
[30,     4] loss: 0.956
[31,     4] loss: 0.968
[32,     4] loss: 1.018
[33,     4] loss: 0.987
[34,     4] loss: 0.948
[35,     4] loss: 0.985
[36,     4] loss: 0.977
[37,     4] loss: 0.936
[38,     4] loss: 0.873
[39,     4] loss: 0.912
[40,     4] loss: 0.912
[41,     4] loss: 0.872
[42,     4] loss: 0.847
[43,     4] loss: 0.868
[44,     4] loss: 0.852
[45,     4] loss: 0.963
[46,     4] loss: 0.890
[47,     4] loss: 0.847
[48,     4] loss: 0.846
[49,     4] loss: 0.821
[50,     4] loss: 0.805
[51,     4] loss: 0.816
[52,     4] loss: 0.831
[53,     4] loss: 0.824
[54,     4] loss: 0.865
[55,     4] loss: 0.842
[56,     4] loss: 0.907
[57,     4] loss: 0.815
[58,     4] loss: 0.899
[59,     4] loss: 0.820
[60,     4] loss: 0.828
[61,     4] loss: 0.904
[62,     4] loss: 0.823
[63,     4] loss: 0.816
[64,     4] loss: 0.817
[65,     4] loss: 0.786
[66,     4] loss: 0.755
[67,     4] loss: 0.768
[68,     4] loss: 0.792
[69,     4] loss: 0.779
[70,     4] loss: 0.819
[71,     4] loss: 0.924
[72,     4] loss: 0.919
[73,     4] loss: 0.856
Early stopping applied (best metric=0.22142177820205688)
Finished Training
Total time taken: 38.02626442909241
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.387
[3,     4] loss: 1.379
[4,     4] loss: 1.387
[5,     4] loss: 1.383
[6,     4] loss: 1.381
[7,     4] loss: 1.373
[8,     4] loss: 1.360
[9,     4] loss: 1.316
[10,     4] loss: 1.279
[11,     4] loss: 1.200
[12,     4] loss: 1.159
[13,     4] loss: 1.134
[14,     4] loss: 1.075
[15,     4] loss: 1.095
[16,     4] loss: 1.021
[17,     4] loss: 1.101
[18,     4] loss: 1.083
[19,     4] loss: 1.132
[20,     4] loss: 1.034
[21,     4] loss: 1.014
[22,     4] loss: 1.006
[23,     4] loss: 0.939
[24,     4] loss: 0.898
[25,     4] loss: 0.852
[26,     4] loss: 0.869
[27,     4] loss: 0.894
[28,     4] loss: 0.910
[29,     4] loss: 0.902
[30,     4] loss: 0.857
[31,     4] loss: 0.828
[32,     4] loss: 0.814
[33,     4] loss: 0.864
[34,     4] loss: 0.824
[35,     4] loss: 0.803
[36,     4] loss: 0.792
[37,     4] loss: 0.838
[38,     4] loss: 0.774
[39,     4] loss: 0.813
[40,     4] loss: 0.764
[41,     4] loss: 0.829
[42,     4] loss: 0.832
[43,     4] loss: 0.826
[44,     4] loss: 0.821
[45,     4] loss: 0.803
[46,     4] loss: 0.774
[47,     4] loss: 0.752
[48,     4] loss: 0.737
[49,     4] loss: 0.761
[50,     4] loss: 0.783
[51,     4] loss: 0.757
[52,     4] loss: 0.777
[53,     4] loss: 0.774
[54,     4] loss: 0.751
[55,     4] loss: 0.749
[56,     4] loss: 0.914
[57,     4] loss: 0.789
[58,     4] loss: 0.878
[59,     4] loss: 0.802
[60,     4] loss: 0.828
Early stopping applied (best metric=0.48319169878959656)
Finished Training
Total time taken: 30.34909200668335
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.387
[3,     4] loss: 1.390
[4,     4] loss: 1.387
[5,     4] loss: 1.384
[6,     4] loss: 1.385
[7,     4] loss: 1.384
[8,     4] loss: 1.377
[9,     4] loss: 1.370
[10,     4] loss: 1.337
[11,     4] loss: 1.303
[12,     4] loss: 1.277
[13,     4] loss: 1.226
[14,     4] loss: 1.193
[15,     4] loss: 1.231
[16,     4] loss: 1.283
[17,     4] loss: 1.158
[18,     4] loss: 1.099
[19,     4] loss: 1.084
[20,     4] loss: 1.049
[21,     4] loss: 0.965
[22,     4] loss: 1.064
[23,     4] loss: 1.032
[24,     4] loss: 0.993
[25,     4] loss: 1.015
[26,     4] loss: 1.010
[27,     4] loss: 0.947
[28,     4] loss: 0.998
[29,     4] loss: 0.986
[30,     4] loss: 0.933
[31,     4] loss: 0.921
[32,     4] loss: 0.900
[33,     4] loss: 0.925
[34,     4] loss: 0.856
[35,     4] loss: 0.857
[36,     4] loss: 0.843
[37,     4] loss: 0.915
[38,     4] loss: 0.885
[39,     4] loss: 0.826
[40,     4] loss: 0.957
[41,     4] loss: 0.917
[42,     4] loss: 1.027
[43,     4] loss: 0.995
[44,     4] loss: 0.974
[45,     4] loss: 0.880
[46,     4] loss: 0.851
[47,     4] loss: 0.800
[48,     4] loss: 0.827
[49,     4] loss: 0.764
[50,     4] loss: 0.751
[51,     4] loss: 0.748
[52,     4] loss: 0.756
[53,     4] loss: 0.764
[54,     4] loss: 0.792
[55,     4] loss: 0.794
[56,     4] loss: 0.848
[57,     4] loss: 0.766
[58,     4] loss: 0.785
[59,     4] loss: 0.790
[60,     4] loss: 0.822
[61,     4] loss: 0.959
[62,     4] loss: 1.064
[63,     4] loss: 0.929
[64,     4] loss: 0.840
[65,     4] loss: 0.851
[66,     4] loss: 0.814
Early stopping applied (best metric=0.5065826177597046)
Finished Training
Total time taken: 33.10309815406799
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.384
[3,     4] loss: 1.385
[4,     4] loss: 1.384
[5,     4] loss: 1.382
[6,     4] loss: 1.382
[7,     4] loss: 1.373
[8,     4] loss: 1.367
[9,     4] loss: 1.338
[10,     4] loss: 1.300
[11,     4] loss: 1.253
[12,     4] loss: 1.154
[13,     4] loss: 1.222
[14,     4] loss: 1.369
[15,     4] loss: 1.190
[16,     4] loss: 1.187
[17,     4] loss: 1.165
[18,     4] loss: 1.162
[19,     4] loss: 1.117
[20,     4] loss: 1.083
[21,     4] loss: 1.023
[22,     4] loss: 0.980
[23,     4] loss: 0.982
[24,     4] loss: 1.049
[25,     4] loss: 1.044
[26,     4] loss: 0.993
[27,     4] loss: 0.956
[28,     4] loss: 0.971
[29,     4] loss: 1.007
[30,     4] loss: 1.026
[31,     4] loss: 0.965
[32,     4] loss: 0.927
[33,     4] loss: 0.889
[34,     4] loss: 0.853
[35,     4] loss: 0.848
[36,     4] loss: 0.850
[37,     4] loss: 0.911
[38,     4] loss: 0.902
[39,     4] loss: 0.852
[40,     4] loss: 0.847
[41,     4] loss: 0.837
[42,     4] loss: 0.822
[43,     4] loss: 0.829
[44,     4] loss: 0.828
[45,     4] loss: 0.805
[46,     4] loss: 0.893
[47,     4] loss: 0.860
[48,     4] loss: 0.856
[49,     4] loss: 0.864
[50,     4] loss: 0.835
[51,     4] loss: 0.806
[52,     4] loss: 0.799
[53,     4] loss: 0.791
[54,     4] loss: 0.796
[55,     4] loss: 0.835
[56,     4] loss: 0.875
[57,     4] loss: 0.828
[58,     4] loss: 0.812
[59,     4] loss: 0.794
[60,     4] loss: 0.803
[61,     4] loss: 1.033
[62,     4] loss: 0.975
[63,     4] loss: 1.136
[64,     4] loss: 1.018
[65,     4] loss: 0.955
[66,     4] loss: 0.888
[67,     4] loss: 0.798
[68,     4] loss: 0.811
[69,     4] loss: 0.809
[70,     4] loss: 0.877
[71,     4] loss: 0.831
[72,     4] loss: 0.917
[73,     4] loss: 0.887
[74,     4] loss: 0.821
[75,     4] loss: 0.847
[76,     4] loss: 0.819
Early stopping applied (best metric=0.23435114324092865)
Finished Training
Total time taken: 38.51311469078064
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.387
[3,     4] loss: 1.392
[4,     4] loss: 1.388
[5,     4] loss: 1.386
[6,     4] loss: 1.382
[7,     4] loss: 1.377
[8,     4] loss: 1.371
[9,     4] loss: 1.361
[10,     4] loss: 1.325
[11,     4] loss: 1.290
[12,     4] loss: 1.200
[13,     4] loss: 1.160
[14,     4] loss: 1.129
[15,     4] loss: 1.163
[16,     4] loss: 1.110
[17,     4] loss: 1.052
[18,     4] loss: 1.050
[19,     4] loss: 0.981
[20,     4] loss: 0.995
[21,     4] loss: 0.990
[22,     4] loss: 0.903
[23,     4] loss: 1.001
[24,     4] loss: 0.887
[25,     4] loss: 0.948
[26,     4] loss: 1.005
[27,     4] loss: 0.973
[28,     4] loss: 0.961
[29,     4] loss: 0.868
[30,     4] loss: 0.856
[31,     4] loss: 0.825
[32,     4] loss: 0.871
[33,     4] loss: 0.899
[34,     4] loss: 0.894
[35,     4] loss: 0.886
[36,     4] loss: 0.829
[37,     4] loss: 0.829
[38,     4] loss: 0.788
[39,     4] loss: 0.834
[40,     4] loss: 0.813
[41,     4] loss: 0.787
[42,     4] loss: 0.805
[43,     4] loss: 0.777
[44,     4] loss: 0.839
[45,     4] loss: 0.849
[46,     4] loss: 0.801
[47,     4] loss: 0.803
[48,     4] loss: 0.770
[49,     4] loss: 0.768
[50,     4] loss: 0.780
[51,     4] loss: 0.777
[52,     4] loss: 0.779
[53,     4] loss: 0.755
[54,     4] loss: 0.792
[55,     4] loss: 0.797
[56,     4] loss: 0.769
[57,     4] loss: 0.747
[58,     4] loss: 0.903
[59,     4] loss: 0.791
[60,     4] loss: 0.837
[61,     4] loss: 0.774
Early stopping applied (best metric=0.4650591313838959)
Finished Training
Total time taken: 30.78009533882141
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.395
[2,     4] loss: 1.383
[3,     4] loss: 1.383
[4,     4] loss: 1.391
[5,     4] loss: 1.375
[6,     4] loss: 1.373
[7,     4] loss: 1.357
[8,     4] loss: 1.329
[9,     4] loss: 1.290
[10,     4] loss: 1.179
[11,     4] loss: 1.163
[12,     4] loss: 1.062
[13,     4] loss: 1.031
[14,     4] loss: 1.013
[15,     4] loss: 1.001
[16,     4] loss: 0.985
[17,     4] loss: 0.975
[18,     4] loss: 0.917
[19,     4] loss: 0.955
[20,     4] loss: 1.076
[21,     4] loss: 1.024
[22,     4] loss: 1.075
[23,     4] loss: 0.976
[24,     4] loss: 0.955
[25,     4] loss: 0.927
[26,     4] loss: 0.898
[27,     4] loss: 0.919
[28,     4] loss: 0.818
[29,     4] loss: 0.862
[30,     4] loss: 0.866
[31,     4] loss: 0.852
[32,     4] loss: 0.825
[33,     4] loss: 0.876
[34,     4] loss: 0.871
[35,     4] loss: 0.860
[36,     4] loss: 0.874
[37,     4] loss: 0.816
[38,     4] loss: 0.806
[39,     4] loss: 0.760
[40,     4] loss: 0.886
[41,     4] loss: 0.852
[42,     4] loss: 0.816
[43,     4] loss: 0.777
[44,     4] loss: 0.773
[45,     4] loss: 0.788
[46,     4] loss: 0.743
[47,     4] loss: 0.812
[48,     4] loss: 0.761
[49,     4] loss: 0.787
[50,     4] loss: 0.756
[51,     4] loss: 0.741
[52,     4] loss: 0.729
[53,     4] loss: 0.745
[54,     4] loss: 0.742
[55,     4] loss: 0.751
[56,     4] loss: 0.874
[57,     4] loss: 0.794
[58,     4] loss: 0.785
[59,     4] loss: 0.838
[60,     4] loss: 0.786
[61,     4] loss: 0.790
[62,     4] loss: 0.821
[63,     4] loss: 0.831
[64,     4] loss: 0.771
[65,     4] loss: 0.799
[66,     4] loss: 0.797
[67,     4] loss: 0.852
[68,     4] loss: 0.824
[69,     4] loss: 0.871
[70,     4] loss: 0.939
[71,     4] loss: 0.894
[72,     4] loss: 0.818
[73,     4] loss: 0.817
[74,     4] loss: 0.763
[75,     4] loss: 0.749
[76,     4] loss: 0.747
[77,     4] loss: 0.745
[78,     4] loss: 0.723
[79,     4] loss: 0.752
[80,     4] loss: 0.742
[81,     4] loss: 0.758
[82,     4] loss: 0.770
[83,     4] loss: 0.865
[84,     4] loss: 0.889
[85,     4] loss: 0.850
[86,     4] loss: 0.867
[87,     4] loss: 0.803
[88,     4] loss: 0.801
[89,     4] loss: 0.787
[90,     4] loss: 0.771
[91,     4] loss: 0.746
[92,     4] loss: 0.766
[93,     4] loss: 0.835
[94,     4] loss: 0.790
[95,     4] loss: 0.783
[96,     4] loss: 0.782
[97,     4] loss: 0.749
[98,     4] loss: 0.735
[99,     4] loss: 0.762
[100,     4] loss: 0.865
[101,     4] loss: 0.804
[102,     4] loss: 0.825
[103,     4] loss: 0.766
[104,     4] loss: 0.746
[105,     4] loss: 0.734
[106,     4] loss: 0.730
[107,     4] loss: 0.760
[108,     4] loss: 0.757
[109,     4] loss: 0.781
[110,     4] loss: 0.753
Early stopping applied (best metric=0.39248526096343994)
Finished Training
Total time taken: 56.59101605415344
{'Hydroxylation-K Validation Accuracy': 0.7640661938534279, 'Hydroxylation-K Validation Sensitivity': 0.8133333333333334, 'Hydroxylation-K Validation Specificity': 0.7526315789473684, 'Hydroxylation-K Validation Precision': 0.4991786903040773, 'Hydroxylation-K AUC ROC': 0.834775828460039, 'Hydroxylation-K AUC PR': 0.6152598841572056, 'Hydroxylation-K MCC': 0.49633952527648795, 'Hydroxylation-K F1': 0.6057667978371031, 'Validation Loss (Hydroxylation-K)': 0.3909180790185928, 'Methylation-K Validation Accuracy': 0.7744245104171776, 'Methylation-K Validation Sensitivity': 0.1975145289347726, 'Methylation-K Validation Specificity': 0.8369891614676886, 'Methylation-K Validation Precision': 0.11933871870223735, 'Methylation-K AUC ROC': 0.5449948825800581, 'Methylation-K AUC PR': 0.11220406710842021, 'Methylation-K MCC': 0.028775017289518187, 'Methylation-K F1': 0.13640383298851833, 'Validation Loss (Methylation-K)': 0.9068829953670502, 'Validation Loss (total)': 1.2978010733922323, 'TimeToTrain': 41.609561649958295}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00281034700613269,
 'learning_rate_Hydroxylation-K': 0.006554961867637183,
 'learning_rate_Methylation-K': 0.002319735190296094,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6921938833032832,
 'loss_weight_Methylation-K': 0.7649494358420166,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1715560308,
 'sample_weights': [0.29620999572036794, 0.5568101528210954],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.154382560091488,
 'weight_decay_Hydroxylation-K': 2.4739442003927685,
 'weight_decay_Methylation-K': 2.3043520081151216}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.386
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009249707262589871,
 'learning_rate_Hydroxylation-K': 0.0045972689812369795,
 'learning_rate_Methylation-K': 0.00320026616535961,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7877496020951471,
 'loss_weight_Methylation-K': 0.005171787050179233,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4008068980,
 'sample_weights': [0.6921938833032832, 0.7649494358420166],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.6187819668080135,
 'weight_decay_Hydroxylation-K': 1.128465731746858,
 'weight_decay_Methylation-K': 1.0386719103386524}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.388
[3,     4] loss: 1.390
[4,     4] loss: 1.388
[5,     4] loss: 1.391
[6,     4] loss: 1.387
[7,     4] loss: 1.385
[8,     4] loss: 1.390
[9,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008977719788702055,
 'learning_rate_Hydroxylation-K': 0.007918971375184436,
 'learning_rate_Methylation-K': 0.0061269436740631796,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5207328187826782,
 'loss_weight_Methylation-K': 0.8412043666586098,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3101975957,
 'sample_weights': [0.7877496020951471, 0.005171787050179233],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.422289697323182,
 'weight_decay_Hydroxylation-K': 4.315125660137256,
 'weight_decay_Methylation-K': 3.4254294303865787}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.387
[3,     4] loss: 1.385
[4,     4] loss: 1.384
[5,     4] loss: 1.381
[6,     4] loss: 1.383
[7,     4] loss: 1.375
[8,     4] loss: 1.357
[9,     4] loss: 1.339
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004343578381568693,
 'learning_rate_Hydroxylation-K': 9.122380282384959e-05,
 'learning_rate_Methylation-K': 0.009439675582133393,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.19372067140089336,
 'loss_weight_Methylation-K': 0.7887087865956994,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 555689415,
 'sample_weights': [0.5207328187826782, 0.8412043666586098],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.7532120803475202,
 'weight_decay_Hydroxylation-K': 7.503067317018708,
 'weight_decay_Methylation-K': 9.937892918417903}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.386
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012764712843057599,
 'learning_rate_Hydroxylation-K': 0.003947363647061072,
 'learning_rate_Methylation-K': 0.009907852139769918,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.41618425774613366,
 'loss_weight_Methylation-K': 0.8702822291920437,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2936879864,
 'sample_weights': [0.19372067140089336, 0.7887087865956994],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.1124633179782204,
 'weight_decay_Hydroxylation-K': 5.896936561234187,
 'weight_decay_Methylation-K': 9.082689740214576}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.382
[3,     4] loss: 1.370
[4,     4] loss: 1.365
[5,     4] loss: 1.352
[6,     4] loss: 1.349
[7,     4] loss: 1.296
[8,     4] loss: 1.294
[9,     4] loss: 1.217
[10,     4] loss: 1.197
[11,     4] loss: 1.192
[12,     4] loss: 1.142
[13,     4] loss: 1.136
[14,     4] loss: 1.153
[15,     4] loss: 1.068
[16,     4] loss: 1.032
[17,     4] loss: 1.047
[18,     4] loss: 1.051
[19,     4] loss: 1.007
[20,     4] loss: 0.980
[21,     4] loss: 0.896
[22,     4] loss: 0.845
[23,     4] loss: 0.862
[24,     4] loss: 0.831
[25,     4] loss: 0.844
[26,     4] loss: 0.846
[27,     4] loss: 0.916
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005808230666019532,
 'learning_rate_Hydroxylation-K': 0.002122935972718483,
 'learning_rate_Methylation-K': 0.009332405886789793,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2752682396699901,
 'loss_weight_Methylation-K': 0.7267956529702204,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1702699123,
 'sample_weights': [0.41618425774613366, 0.8702822291920437],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.117085823858268,
 'weight_decay_Hydroxylation-K': 5.253162542340059,
 'weight_decay_Methylation-K': 9.293177650516027}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.385
[3,     4] loss: 1.382
[4,     4] loss: 1.383
[5,     4] loss: 1.381
[6,     4] loss: 1.371
[7,     4] loss: 1.360
[8,     4] loss: 1.342
[9,     4] loss: 1.310
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000692422581997983,
 'learning_rate_Hydroxylation-K': 0.007031352799645439,
 'learning_rate_Methylation-K': 0.003967377758239692,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.25795642775203803,
 'loss_weight_Methylation-K': 0.9222127573647272,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3234784634,
 'sample_weights': [0.2752682396699901, 0.7267956529702204],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.710283202936523,
 'weight_decay_Hydroxylation-K': 2.220275016902382,
 'weight_decay_Methylation-K': 9.52973360826799}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.387
[3,     4] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0026759139059746675,
 'learning_rate_Hydroxylation-K': 0.005287904660876473,
 'learning_rate_Methylation-K': 0.0017278206710077794,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.23435999087988432,
 'loss_weight_Methylation-K': 0.3387944046889888,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 164006824,
 'sample_weights': [0.25795642775203803, 0.9222127573647272],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.470773951194871,
 'weight_decay_Hydroxylation-K': 7.57758451509336,
 'weight_decay_Methylation-K': 7.216664877637794}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.377
[2,     4] loss: 1.385
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002326407380953103,
 'learning_rate_Hydroxylation-K': 0.009378574988863865,
 'learning_rate_Methylation-K': 0.00513558469613053,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.675987647547601,
 'loss_weight_Methylation-K': 0.6680058875391242,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1715797242,
 'sample_weights': [0.23435999087988432, 0.3387944046889888],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.658122514984397,
 'weight_decay_Hydroxylation-K': 5.885477568013619,
 'weight_decay_Methylation-K': 4.55830105713664}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.392
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00398534110659985,
 'learning_rate_Hydroxylation-K': 0.0064458561682448085,
 'learning_rate_Methylation-K': 0.0022277020921486796,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4186318691836286,
 'loss_weight_Methylation-K': 0.9548816286442648,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3296524753,
 'sample_weights': [0.675987647547601, 0.6680058875391242],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.860381988784008,
 'weight_decay_Hydroxylation-K': 1.4835917416038158,
 'weight_decay_Methylation-K': 5.636070439312371}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.391
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00247139038817965,
 'learning_rate_Hydroxylation-K': 0.0031724835255433023,
 'learning_rate_Methylation-K': 0.009468148018080791,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3277600724262218,
 'loss_weight_Methylation-K': 0.9389387321886332,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3612402695,
 'sample_weights': [0.4186318691836286, 0.9548816286442648],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.957044770902004,
 'weight_decay_Hydroxylation-K': 4.467774429486006,
 'weight_decay_Methylation-K': 9.91600221447998}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.386
[3,     4] loss: 1.373
[4,     4] loss: 1.365
[5,     4] loss: 1.329
[6,     4] loss: 1.286
[7,     4] loss: 1.221
[8,     4] loss: 1.147
[9,     4] loss: 1.181
[10,     4] loss: 1.169
[11,     4] loss: 1.065
[12,     4] loss: 1.066
[13,     4] loss: 0.995
[14,     4] loss: 0.961
[15,     4] loss: 0.991
[16,     4] loss: 0.917
[17,     4] loss: 0.918
[18,     4] loss: 0.895
[19,     4] loss: 0.878
[20,     4] loss: 0.946
[21,     4] loss: 0.881
[22,     4] loss: 0.913
[23,     4] loss: 0.845
[24,     4] loss: 0.865
[25,     4] loss: 0.806
[26,     4] loss: 0.849
[27,     4] loss: 0.837
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00562787392515874,
 'learning_rate_Hydroxylation-K': 0.0009540933820988372,
 'learning_rate_Methylation-K': 0.0032911362085432877,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.40885694238743553,
 'loss_weight_Methylation-K': 0.2727987802245927,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4243576964,
 'sample_weights': [0.3277600724262218, 0.9389387321886332],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.718836765957324,
 'weight_decay_Hydroxylation-K': 6.495639476144794,
 'weight_decay_Methylation-K': 4.934173458615973}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.381
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009026544043989736,
 'learning_rate_Hydroxylation-K': 0.0024239478464631687,
 'learning_rate_Methylation-K': 0.00138133479408164,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6794848885827007,
 'loss_weight_Methylation-K': 0.2835680909371326,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3443361076,
 'sample_weights': [0.40885694238743553, 0.2727987802245927],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.115483413895351,
 'weight_decay_Hydroxylation-K': 4.58194074821929,
 'weight_decay_Methylation-K': 4.819010561343367}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.386
[3,     4] loss: 1.387
[4,     4] loss: 1.387
[5,     4] loss: 1.384
[6,     4] loss: 1.383
[7,     4] loss: 1.384
[8,     4] loss: 1.379
[9,     4] loss: 1.357
[10,     4] loss: 1.325
[11,     4] loss: 1.244
[12,     4] loss: 1.205
[13,     4] loss: 1.201
[14,     4] loss: 1.150
[15,     4] loss: 1.116
[16,     4] loss: 1.096
[17,     4] loss: 1.066
[18,     4] loss: 0.999
[19,     4] loss: 1.006
[20,     4] loss: 0.951
[21,     4] loss: 0.941
[22,     4] loss: 1.416
[23,     4] loss: 1.311
[24,     4] loss: 1.247
[25,     4] loss: 1.165
[26,     4] loss: 1.109
[27,     4] loss: 0.997
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008996675242422059,
 'learning_rate_Hydroxylation-K': 0.0059051486675522295,
 'learning_rate_Methylation-K': 0.008346213329183026,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6367135912325412,
 'loss_weight_Methylation-K': 0.7848837456327225,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4203264181,
 'sample_weights': [0.6794848885827007, 0.2835680909371326],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.185312214679147,
 'weight_decay_Hydroxylation-K': 1.990731812277453,
 'weight_decay_Methylation-K': 0.9807628032941587}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.376
[5,     4] loss: 1.364
[6,     4] loss: 1.339
[7,     4] loss: 1.314
[8,     4] loss: 1.277
[9,     4] loss: 1.229
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016258400383745107,
 'learning_rate_Hydroxylation-K': 0.008114525290853285,
 'learning_rate_Methylation-K': 0.005650348314082811,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6728777875720713,
 'loss_weight_Methylation-K': 0.2645949457938932,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1433030614,
 'sample_weights': [0.6367135912325412, 0.7848837456327225],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.307840490935686,
 'weight_decay_Hydroxylation-K': 3.4035705803426324,
 'weight_decay_Methylation-K': 2.3737958634485006}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.388
[3,     4] loss: 1.381
[4,     4] loss: 1.370
[5,     4] loss: 1.363
[6,     4] loss: 1.326
[7,     4] loss: 1.271
[8,     4] loss: 1.220
[9,     4] loss: 1.206
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017830984661756993,
 'learning_rate_Hydroxylation-K': 0.0075315054920820175,
 'learning_rate_Methylation-K': 0.009994921579348389,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.04311266021105603,
 'loss_weight_Methylation-K': 0.967052805001148,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 25245030,
 'sample_weights': [0.6728777875720713, 0.2645949457938932],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.089570672647453,
 'weight_decay_Hydroxylation-K': 4.32436039685911,
 'weight_decay_Methylation-K': 9.62211633322525}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.392
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003458724635905603,
 'learning_rate_Hydroxylation-K': 0.009202558927589416,
 'learning_rate_Methylation-K': 0.0035404148088889953,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.726982695098811,
 'loss_weight_Methylation-K': 0.4122157138825274,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4661215,
 'sample_weights': [0.04311266021105603, 0.967052805001148],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.865899865103607,
 'weight_decay_Hydroxylation-K': 9.495174677908668,
 'weight_decay_Methylation-K': 2.956227305898201}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.387
[3,     4] loss: 1.378
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0045784354362391685,
 'learning_rate_Hydroxylation-K': 0.0025292826033420698,
 'learning_rate_Methylation-K': 0.00036973568925280104,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.20974471997154354,
 'loss_weight_Methylation-K': 0.8060646612524089,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1901804468,
 'sample_weights': [0.726982695098811, 0.4122157138825274],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.055192493945279,
 'weight_decay_Hydroxylation-K': 4.9062059066208725,
 'weight_decay_Methylation-K': 9.246168940281152}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.385
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0057824599438675624,
 'learning_rate_Hydroxylation-K': 0.005590722005970549,
 'learning_rate_Methylation-K': 0.004961830243814537,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9220176590036981,
 'loss_weight_Methylation-K': 0.03003010002331799,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1505693639,
 'sample_weights': [0.20974471997154354, 0.8060646612524089],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.7254544661109374,
 'weight_decay_Hydroxylation-K': 6.774717911222883,
 'weight_decay_Methylation-K': 0.9386107132367996}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.392
[3,     4] loss: 1.387
[4,     4] loss: 1.385
[5,     4] loss: 1.390
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0032910548640664996,
 'learning_rate_Hydroxylation-K': 0.009647679424580818,
 'learning_rate_Methylation-K': 0.0015390734284982219,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4751555708062356,
 'loss_weight_Methylation-K': 0.5546267803970073,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 652014426,
 'sample_weights': [0.9220176590036981, 0.03003010002331799],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.756050139649274,
 'weight_decay_Hydroxylation-K': 3.935167676246149,
 'weight_decay_Methylation-K': 3.814140547464136}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.397
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00526345060292722,
 'learning_rate_Hydroxylation-K': 0.006486366254640402,
 'learning_rate_Methylation-K': 0.0033733542508900573,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6054666305593652,
 'loss_weight_Methylation-K': 0.16861714656736576,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1396276745,
 'sample_weights': [0.4751555708062356, 0.5546267803970073],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.11007201631980479,
 'weight_decay_Hydroxylation-K': 8.74870576029543,
 'weight_decay_Methylation-K': 7.319047655703235}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.399
[2,     4] loss: 1.383
[3,     4] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009676844792743167,
 'learning_rate_Hydroxylation-K': 0.004861741865845704,
 'learning_rate_Methylation-K': 0.0037772053950112564,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8357894172340588,
 'loss_weight_Methylation-K': 0.08551848404667162,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2224824710,
 'sample_weights': [0.6054666305593652, 0.16861714656736576],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.185735671274458,
 'weight_decay_Hydroxylation-K': 9.062713209734866,
 'weight_decay_Methylation-K': 2.7657748677350957}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.383
[3,     4] loss: 1.390
[4,     4] loss: 1.384
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023376818200632784,
 'learning_rate_Hydroxylation-K': 0.0015510627843427153,
 'learning_rate_Methylation-K': 0.0021705580649764335,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.33234622466058045,
 'loss_weight_Methylation-K': 0.8764937620289205,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3917858124,
 'sample_weights': [0.8357894172340588, 0.08551848404667162],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.709922287771413,
 'weight_decay_Hydroxylation-K': 8.35100276025492,
 'weight_decay_Methylation-K': 4.844842174292267}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.393
[3,     4] loss: 1.381
[4,     4] loss: 1.390
[5,     4] loss: 1.377
[6,     4] loss: 1.370
[7,     4] loss: 1.352
[8,     4] loss: 1.331
[9,     4] loss: 1.258
[10,     4] loss: 1.244
[11,     4] loss: 1.180
[12,     4] loss: 1.095
[13,     4] loss: 1.069
[14,     4] loss: 1.048
[15,     4] loss: 1.010
[16,     4] loss: 0.944
[17,     4] loss: 0.943
[18,     4] loss: 0.961
[19,     4] loss: 0.997
[20,     4] loss: 1.054
[21,     4] loss: 1.004
[22,     4] loss: 0.965
[23,     4] loss: 0.901
[24,     4] loss: 0.824
[25,     4] loss: 0.846
[26,     4] loss: 0.886
[27,     4] loss: 1.162
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0073936363619065215,
 'learning_rate_Hydroxylation-K': 0.003910768050610778,
 'learning_rate_Methylation-K': 0.004708783866840524,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7807786268045096,
 'loss_weight_Methylation-K': 0.17078429199137668,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3824380182,
 'sample_weights': [0.33234622466058045, 0.8764937620289205],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.1332606544115,
 'weight_decay_Hydroxylation-K': 0.7969449471431984,
 'weight_decay_Methylation-K': 3.7479428378502}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.391
[3,     4] loss: 1.384
[4,     4] loss: 1.388
[5,     4] loss: 1.390
[6,     4] loss: 1.384
[7,     4] loss: 1.387
[8,     4] loss: 1.387
[9,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006969409421986543,
 'learning_rate_Hydroxylation-K': 0.007745544417705067,
 'learning_rate_Methylation-K': 0.003713614994909767,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.46490246490583054,
 'loss_weight_Methylation-K': 0.7498744747540961,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3118860793,
 'sample_weights': [0.7807786268045096, 0.17078429199137668],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.4469272492573895,
 'weight_decay_Hydroxylation-K': 9.093919364277296,
 'weight_decay_Methylation-K': 1.6005715033393026}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.384
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007259730961044558,
 'learning_rate_Hydroxylation-K': 0.002564076240577253,
 'learning_rate_Methylation-K': 0.0014081968148160148,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4413096331814391,
 'loss_weight_Methylation-K': 0.6720452509652837,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3950480438,
 'sample_weights': [0.46490246490583054, 0.7498744747540961],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.264414826256223,
 'weight_decay_Hydroxylation-K': 4.595353191370328,
 'weight_decay_Methylation-K': 5.780765929686742}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.383
[3,     4] loss: 1.384
[4,     4] loss: 1.383
[5,     4] loss: 1.376
[6,     4] loss: 1.370
[7,     4] loss: 1.366
[8,     4] loss: 1.344
[9,     4] loss: 1.329
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001651095462969457,
 'learning_rate_Hydroxylation-K': 0.0007273945611994256,
 'learning_rate_Methylation-K': 0.004423054554586186,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4922448874245938,
 'loss_weight_Methylation-K': 0.3037496186393631,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3086530961,
 'sample_weights': [0.4413096331814391, 0.6720452509652837],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.877414724211127,
 'weight_decay_Hydroxylation-K': 7.456837270570702,
 'weight_decay_Methylation-K': 6.7075217644224}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.389
[3,     4] loss: 1.384
[4,     4] loss: 1.380
[5,     4] loss: 1.381
[6,     4] loss: 1.372
[7,     4] loss: 1.370
[8,     4] loss: 1.349
[9,     4] loss: 1.304
[10,     4] loss: 1.277
[11,     4] loss: 1.231
[12,     4] loss: 1.218
[13,     4] loss: 1.089
[14,     4] loss: 1.096
[15,     4] loss: 1.019
[16,     4] loss: 1.012
[17,     4] loss: 0.928
[18,     4] loss: 0.949
[19,     4] loss: 0.954
[20,     4] loss: 0.888
[21,     4] loss: 0.900
[22,     4] loss: 0.926
[23,     4] loss: 0.883
[24,     4] loss: 0.880
[25,     4] loss: 0.835
[26,     4] loss: 0.882
[27,     4] loss: 0.850
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00026186690550604463,
 'learning_rate_Hydroxylation-K': 0.0024851405436206522,
 'learning_rate_Methylation-K': 0.0006415148173559289,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5779337774036762,
 'loss_weight_Methylation-K': 0.9592178131375603,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1336293571,
 'sample_weights': [0.4922448874245938, 0.3037496186393631],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.744598288109164,
 'weight_decay_Hydroxylation-K': 9.270027902215105,
 'weight_decay_Methylation-K': 3.8583884869579537}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.391
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006853877962526336,
 'learning_rate_Hydroxylation-K': 0.009894493507905071,
 'learning_rate_Methylation-K': 0.004410078231558849,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21708094088412672,
 'loss_weight_Methylation-K': 0.5467197416617569,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 660223195,
 'sample_weights': [0.5779337774036762, 0.9592178131375603],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.569055407473304,
 'weight_decay_Hydroxylation-K': 5.589153579929396,
 'weight_decay_Methylation-K': 3.0079446705255872}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.387
[3,     4] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013493473187161775,
 'learning_rate_Hydroxylation-K': 0.008001073122115353,
 'learning_rate_Methylation-K': 0.0022065964268026426,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3911461963681603,
 'loss_weight_Methylation-K': 0.3745342368206166,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1764542686,
 'sample_weights': [0.21708094088412672, 0.5467197416617569],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.784200035989901,
 'weight_decay_Hydroxylation-K': 6.163668477343373,
 'weight_decay_Methylation-K': 2.5670159123518403}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.378
[3,     4] loss: 1.380
[4,     4] loss: 1.367
[5,     4] loss: 1.335
[6,     4] loss: 1.316
[7,     4] loss: 1.240
[8,     4] loss: 1.164
[9,     4] loss: 1.029
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004794945568209972,
 'learning_rate_Hydroxylation-K': 0.007843087366901744,
 'learning_rate_Methylation-K': 0.0052814608618438905,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4334465121185035,
 'loss_weight_Methylation-K': 0.9790862993247548,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 662545302,
 'sample_weights': [0.3911461963681603, 0.3745342368206166],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.423809407251555,
 'weight_decay_Hydroxylation-K': 3.5025931197272926,
 'weight_decay_Methylation-K': 7.005766749942536}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.394
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0029195254021481772,
 'learning_rate_Hydroxylation-K': 0.0027651816017022443,
 'learning_rate_Methylation-K': 0.0014792540449490715,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6095209714664609,
 'loss_weight_Methylation-K': 0.8154728005342807,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3999807589,
 'sample_weights': [0.4334465121185035, 0.9790862993247548],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.964107414114201,
 'weight_decay_Hydroxylation-K': 2.6770731259311695,
 'weight_decay_Methylation-K': 8.130185052163576}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.390
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005223017909406061,
 'learning_rate_Hydroxylation-K': 0.0014030464610715514,
 'learning_rate_Methylation-K': 0.0023944573298373007,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.0027504355914456033,
 'loss_weight_Methylation-K': 0.6937040895948251,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 466048462,
 'sample_weights': [0.6095209714664609, 0.8154728005342807],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.100276562633397,
 'weight_decay_Hydroxylation-K': 2.722237908812337,
 'weight_decay_Methylation-K': 9.282530373225141}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.384
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027561369830448176,
 'learning_rate_Hydroxylation-K': 0.0006862217919099624,
 'learning_rate_Methylation-K': 0.005233373916165687,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.002409891566030324,
 'loss_weight_Methylation-K': 0.5285600215951343,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1345960992,
 'sample_weights': [0.0027504355914456033, 0.6937040895948251],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.330219988071119,
 'weight_decay_Hydroxylation-K': 0.8464942108498787,
 'weight_decay_Methylation-K': 8.07681607595147}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.385
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009220686803219143,
 'learning_rate_Hydroxylation-K': 0.0016396431413437322,
 'learning_rate_Methylation-K': 0.00430460189695181,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9974076997966792,
 'loss_weight_Methylation-K': 0.014598757902443901,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3260311722,
 'sample_weights': [0.002409891566030324, 0.5285600215951343],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.836310868543558,
 'weight_decay_Hydroxylation-K': 5.052903480494026,
 'weight_decay_Methylation-K': 5.279808938323573}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.393
[3,     4] loss: 1.388
[4,     4] loss: 1.386
[5,     4] loss: 1.387
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006743861009716208,
 'learning_rate_Hydroxylation-K': 0.002960464496540594,
 'learning_rate_Methylation-K': 0.0021397034260949945,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.03567293940053886,
 'loss_weight_Methylation-K': 0.22192052280598074,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 707138293,
 'sample_weights': [0.9974076997966792, 0.014598757902443901],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.265261447534762,
 'weight_decay_Hydroxylation-K': 0.17819158601851237,
 'weight_decay_Methylation-K': 5.161966355588556}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.376
[5,     4] loss: 1.379
[6,     4] loss: 1.386
[7,     4] loss: 1.371
[8,     4] loss: 1.358
[9,     4] loss: 1.318
[10,     4] loss: 1.278
[11,     4] loss: 1.243
[12,     4] loss: 1.231
[13,     4] loss: 1.155
[14,     4] loss: 1.143
[15,     4] loss: 1.080
[16,     4] loss: 1.110
[17,     4] loss: 1.051
[18,     4] loss: 1.058
[19,     4] loss: 1.032
[20,     4] loss: 0.991
[21,     4] loss: 0.988
[22,     4] loss: 0.951
[23,     4] loss: 0.965
[24,     4] loss: 0.909
[25,     4] loss: 0.961
[26,     4] loss: 0.914
[27,     4] loss: 0.839
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028305443408003107,
 'learning_rate_Hydroxylation-K': 0.0022434977129033905,
 'learning_rate_Methylation-K': 0.00474867952694641,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5171789546367505,
 'loss_weight_Methylation-K': 0.355488945967889,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1596342107,
 'sample_weights': [0.03567293940053886, 0.22192052280598074],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.178433870900761,
 'weight_decay_Hydroxylation-K': 9.840200833974702,
 'weight_decay_Methylation-K': 7.101834163430758}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.366
[2,     4] loss: 1.387
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004885162352025801,
 'learning_rate_Hydroxylation-K': 0.005418084410171394,
 'learning_rate_Methylation-K': 0.006216417141911826,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21811206051988427,
 'loss_weight_Methylation-K': 0.1306037112103051,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1767215626,
 'sample_weights': [0.5171789546367505, 0.355488945967889],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.699054779436026,
 'weight_decay_Hydroxylation-K': 8.424734183185864,
 'weight_decay_Methylation-K': 2.9391196262782806}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.399
[2,     4] loss: 1.387
[3,     4] loss: 1.389
[4,     4] loss: 1.383
[5,     4] loss: 1.393
[6,     4] loss: 1.385
[7,     4] loss: 1.385
[8,     4] loss: 1.389
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003012874771949942,
 'learning_rate_Hydroxylation-K': 0.004397528878637737,
 'learning_rate_Methylation-K': 0.004261239354482496,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9454368913422592,
 'loss_weight_Methylation-K': 0.5100586536445416,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4107925868,
 'sample_weights': [0.21811206051988427, 0.1306037112103051],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.605728448318933,
 'weight_decay_Hydroxylation-K': 1.5027785159985128,
 'weight_decay_Methylation-K': 6.984975837839865}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.390
[3,     4] loss: 1.393
[4,     4] loss: 1.387
[5,     4] loss: 1.384
[6,     4] loss: 1.387
[7,     4] loss: 1.389
[8,     4] loss: 1.373
[9,     4] loss: 1.340
[10,     4] loss: 1.293
[11,     4] loss: 1.233
[12,     4] loss: 1.252
[13,     4] loss: 1.185
[14,     4] loss: 1.101
[15,     4] loss: 1.096
[16,     4] loss: 1.025
[17,     4] loss: 1.095
[18,     4] loss: 1.068
[19,     4] loss: 1.049
[20,     4] loss: 0.997
[21,     4] loss: 0.954
[22,     4] loss: 0.896
[23,     4] loss: 0.888
[24,     4] loss: 0.877
[25,     4] loss: 0.870
[26,     4] loss: 0.984
[27,     4] loss: 0.941
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014648778699923022,
 'learning_rate_Hydroxylation-K': 0.007309107126669255,
 'learning_rate_Methylation-K': 0.007271025513046802,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.45138770412566753,
 'loss_weight_Methylation-K': 0.5088399441250877,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 765600516,
 'sample_weights': [0.9454368913422592, 0.5100586536445416],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.944651624758622,
 'weight_decay_Hydroxylation-K': 0.07096459446187398,
 'weight_decay_Methylation-K': 1.173085752773967}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.390
[3,     4] loss: 1.383
[4,     4] loss: 1.382
[5,     4] loss: 1.382
[6,     4] loss: 1.365
[7,     4] loss: 1.338
[8,     4] loss: 1.295
[9,     4] loss: 1.269
[10,     4] loss: 1.208
[11,     4] loss: 1.138
[12,     4] loss: 1.085
[13,     4] loss: 1.004
[14,     4] loss: 0.965
[15,     4] loss: 1.054
[16,     4] loss: 1.043
[17,     4] loss: 1.003
[18,     4] loss: 0.972
[19,     4] loss: 0.948
[20,     4] loss: 0.917
[21,     4] loss: 0.846
[22,     4] loss: 0.915
[23,     4] loss: 0.863
[24,     4] loss: 0.873
[25,     4] loss: 0.854
[26,     4] loss: 0.841
[27,     4] loss: 0.876
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031719446397344146,
 'learning_rate_Hydroxylation-K': 0.002159523248169954,
 'learning_rate_Methylation-K': 0.003313753164654643,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.07891162602552734,
 'loss_weight_Methylation-K': 0.5915428693779241,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 463244412,
 'sample_weights': [0.45138770412566753, 0.5088399441250877],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.97247799789222,
 'weight_decay_Hydroxylation-K': 4.50744464999025,
 'weight_decay_Methylation-K': 4.554608468479692}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.389
[3,     4] loss: 1.383
[4,     4] loss: 1.394
[5,     4] loss: 1.386
[6,     4] loss: 1.382
[7,     4] loss: 1.378
[8,     4] loss: 1.373
[9,     4] loss: 1.336
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00041599412265913484,
 'learning_rate_Hydroxylation-K': 0.007693786718034364,
 'learning_rate_Methylation-K': 0.0035579382845866508,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.516065154931186,
 'loss_weight_Methylation-K': 0.8432562006163031,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1989939029,
 'sample_weights': [0.07891162602552734, 0.5915428693779241],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.038436679214492,
 'weight_decay_Hydroxylation-K': 4.835282948320216,
 'weight_decay_Methylation-K': 5.535267519556905}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.383
[3,     4] loss: 1.383
[4,     4] loss: 1.381
[5,     4] loss: 1.377
[6,     4] loss: 1.373
[7,     4] loss: 1.365
[8,     4] loss: 1.351
[9,     4] loss: 1.339
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00637401627996592,
 'learning_rate_Hydroxylation-K': 0.005189013430344249,
 'learning_rate_Methylation-K': 0.00918750986858787,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8796718416278551,
 'loss_weight_Methylation-K': 0.0697797464825505,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 94620486,
 'sample_weights': [0.516065154931186, 0.8432562006163031],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.058857615262804,
 'weight_decay_Hydroxylation-K': 7.2044391950746425,
 'weight_decay_Methylation-K': 5.2417576814311495}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.392
[3,     4] loss: 1.387
[4,     4] loss: 1.390
[5,     4] loss: 1.385
[6,     4] loss: 1.388
[7,     4] loss: 1.385
[8,     4] loss: 1.386
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0029838237426051783,
 'learning_rate_Hydroxylation-K': 0.00027227745225825246,
 'learning_rate_Methylation-K': 0.008136153545562175,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5675003789869235,
 'loss_weight_Methylation-K': 0.4146066891769607,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3507086361,
 'sample_weights': [0.8796718416278551, 0.0697797464825505],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.675655866137745,
 'weight_decay_Hydroxylation-K': 6.6533547591099715,
 'weight_decay_Methylation-K': 7.351486914517998}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.388
[3,     4] loss: 1.383
[4,     4] loss: 1.383
[5,     4] loss: 1.383
[6,     4] loss: 1.375
[7,     4] loss: 1.383
[8,     4] loss: 1.393
[9,     4] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005648971724875735,
 'learning_rate_Hydroxylation-K': 0.0006915470733401258,
 'learning_rate_Methylation-K': 0.0036476315376682313,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6826654124566776,
 'loss_weight_Methylation-K': 0.2529239348357546,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3272877454,
 'sample_weights': [0.5675003789869235, 0.4146066891769607],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2541210145210533,
 'weight_decay_Hydroxylation-K': 5.941482483850029,
 'weight_decay_Methylation-K': 7.281281088948657}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.383
[3,     4] loss: 1.384
[4,     4] loss: 1.377
[5,     4] loss: 1.379
[6,     4] loss: 1.369
[7,     4] loss: 1.349
[8,     4] loss: 1.332
[9,     4] loss: 1.322
[10,     4] loss: 1.272
[11,     4] loss: 1.230
[12,     4] loss: 1.186
[13,     4] loss: 1.141
[14,     4] loss: 1.102
[15,     4] loss: 1.056
[16,     4] loss: 0.977
[17,     4] loss: 1.011
[18,     4] loss: 0.977
[19,     4] loss: 1.008
[20,     4] loss: 0.952
[21,     4] loss: 0.875
[22,     4] loss: 0.930
[23,     4] loss: 0.896
[24,     4] loss: 0.897
[25,     4] loss: 0.838
[26,     4] loss: 0.918
[27,     4] loss: 0.827
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009182908533171114,
 'learning_rate_Hydroxylation-K': 0.005089849753934403,
 'learning_rate_Methylation-K': 0.0031556470294926207,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.37600059485797527,
 'loss_weight_Methylation-K': 0.5702729339953121,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3269080196,
 'sample_weights': [0.6826654124566776, 0.2529239348357546],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.351924405210204,
 'weight_decay_Hydroxylation-K': 5.102206498801251,
 'weight_decay_Methylation-K': 1.0060275109405092}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.386
[4,     4] loss: 1.378
[5,     4] loss: 1.379
[6,     4] loss: 1.363
[7,     4] loss: 1.345
[8,     4] loss: 1.316
[9,     4] loss: 1.296
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00033175823391602645,
 'learning_rate_Hydroxylation-K': 0.00038950247047042733,
 'learning_rate_Methylation-K': 0.0017895933955320434,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.01585347968861682,
 'loss_weight_Methylation-K': 0.5513826171171433,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1286842753,
 'sample_weights': [0.37600059485797527, 0.5702729339953121],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.383254005998702,
 'weight_decay_Hydroxylation-K': 4.428050297271458,
 'weight_decay_Methylation-K': 8.132532130259932}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.395
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004896086676667313,
 'learning_rate_Hydroxylation-K': 0.0019439370689018957,
 'learning_rate_Methylation-K': 0.002803927085917113,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7434964889096852,
 'loss_weight_Methylation-K': 0.03373334008783596,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 644547382,
 'sample_weights': [0.01585347968861682, 0.5513826171171433],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.926736829103884,
 'weight_decay_Hydroxylation-K': 3.4276954338606362,
 'weight_decay_Methylation-K': 2.1676346955221995}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.388
[3,     4] loss: 1.383
[4,     4] loss: 1.384
[5,     4] loss: 1.381
[6,     4] loss: 1.384
[7,     4] loss: 1.378
[8,     4] loss: 1.371
[9,     4] loss: 1.304
[10,     4] loss: 1.214
[11,     4] loss: 1.198
[12,     4] loss: 1.226
[13,     4] loss: 1.196
[14,     4] loss: 1.158
[15,     4] loss: 1.049
[16,     4] loss: 0.985
[17,     4] loss: 1.041
[18,     4] loss: 1.079
[19,     4] loss: 1.030
[20,     4] loss: 0.895
[21,     4] loss: 1.029
[22,     4] loss: 1.069
[23,     4] loss: 1.100
[24,     4] loss: 1.003
[25,     4] loss: 0.874
[26,     4] loss: 0.932
[27,     4] loss: 0.846
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018919180402867067,
 'learning_rate_Hydroxylation-K': 0.0014223434636502557,
 'learning_rate_Methylation-K': 0.0002786496441684659,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.048834942167106675,
 'loss_weight_Methylation-K': 0.8266867305402614,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2596872344,
 'sample_weights': [0.7434964889096852, 0.03373334008783596],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.3917258323230035,
 'weight_decay_Hydroxylation-K': 0.95744032424533,
 'weight_decay_Methylation-K': 8.501018017275298}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.389
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004380608317226791,
 'learning_rate_Hydroxylation-K': 0.004653335055820279,
 'learning_rate_Methylation-K': 0.008626177397231599,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.09556779830905515,
 'loss_weight_Methylation-K': 0.7656510860411776,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1503913042,
 'sample_weights': [0.048834942167106675, 0.8266867305402614],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.058109673388205,
 'weight_decay_Hydroxylation-K': 6.420831018478348,
 'weight_decay_Methylation-K': 9.934906079504952}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.386
[3,     4] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003986192801582233,
 'learning_rate_Hydroxylation-K': 0.006251578130219882,
 'learning_rate_Methylation-K': 0.003200688595938743,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5192639461397486,
 'loss_weight_Methylation-K': 0.6019355419175298,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3220386997,
 'sample_weights': [0.09556779830905515, 0.7656510860411776],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.187826386548545,
 'weight_decay_Hydroxylation-K': 4.049143131485514,
 'weight_decay_Methylation-K': 7.235935080799016}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.388
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007816255188428269,
 'learning_rate_Hydroxylation-K': 0.001837630585178419,
 'learning_rate_Methylation-K': 0.008555993967849047,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5760972325760844,
 'loss_weight_Methylation-K': 0.13230823986578238,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3256238748,
 'sample_weights': [0.5192639461397486, 0.6019355419175298],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.043293236005312,
 'weight_decay_Hydroxylation-K': 9.509028502723316,
 'weight_decay_Methylation-K': 4.985829454030575}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.391
[3,     4] loss: 1.389
[4,     4] loss: 1.386
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013923569985849374,
 'learning_rate_Hydroxylation-K': 0.00020322064464152847,
 'learning_rate_Methylation-K': 0.005177664170168136,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2944959541879772,
 'loss_weight_Methylation-K': 0.38989531182400317,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 689836121,
 'sample_weights': [0.5760972325760844, 0.13230823986578238],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.48679295067961,
 'weight_decay_Hydroxylation-K': 5.512555841923387,
 'weight_decay_Methylation-K': 6.443620648376759}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.385
[3,     4] loss: 1.384
[4,     4] loss: 1.380
[5,     4] loss: 1.379
[6,     4] loss: 1.369
[7,     4] loss: 1.352
[8,     4] loss: 1.338
[9,     4] loss: 1.277
[10,     4] loss: 1.230
[11,     4] loss: 1.197
[12,     4] loss: 1.159
[13,     4] loss: 1.077
[14,     4] loss: 1.077
[15,     4] loss: 0.981
[16,     4] loss: 1.108
[17,     4] loss: 1.146
[18,     4] loss: 1.122
[19,     4] loss: 1.048
[20,     4] loss: 1.025
[21,     4] loss: 0.981
[22,     4] loss: 1.025
[23,     4] loss: 0.953
[24,     4] loss: 0.908
[25,     4] loss: 0.942
[26,     4] loss: 0.931
[27,     4] loss: 0.942
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00036820777629599033,
 'learning_rate_Hydroxylation-K': 0.006283788316300743,
 'learning_rate_Methylation-K': 0.0054146978394951665,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5489918789005802,
 'loss_weight_Methylation-K': 0.5361751499262176,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2160324280,
 'sample_weights': [0.2944959541879772, 0.38989531182400317],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.613015440847031,
 'weight_decay_Hydroxylation-K': 2.290706185165357,
 'weight_decay_Methylation-K': 7.532730954407286}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.381
[3,     4] loss: 1.392
[4,     4] loss: 1.381
[5,     4] loss: 1.377
[6,     4] loss: 1.371
[7,     4] loss: 1.365
[8,     4] loss: 1.344
[9,     4] loss: 1.325
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033550492358429204,
 'learning_rate_Hydroxylation-K': 0.0015204850729102902,
 'learning_rate_Methylation-K': 0.009084174063436503,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4402306370890278,
 'loss_weight_Methylation-K': 0.16933438811780016,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2063537965,
 'sample_weights': [0.5489918789005802, 0.5361751499262176],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7150915596266767,
 'weight_decay_Hydroxylation-K': 8.537829329759425,
 'weight_decay_Methylation-K': 2.525880853365447}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.388
[3,     4] loss: 1.387
[4,     4] loss: 1.388
[5,     4] loss: 1.388
[6,     4] loss: 1.388
[7,     4] loss: 1.385
[8,     4] loss: 1.386
[9,     4] loss: 1.385
[10,     4] loss: 1.381
[11,     4] loss: 1.387
[12,     4] loss: 1.380
[13,     4] loss: 1.371
[14,     4] loss: 1.363
[15,     4] loss: 1.327
[16,     4] loss: 1.304
[17,     4] loss: 1.212
[18,     4] loss: 1.135
[19,     4] loss: 1.149
[20,     4] loss: 1.205
[21,     4] loss: 1.150
[22,     4] loss: 1.094
[23,     4] loss: 1.101
[24,     4] loss: 1.097
[25,     4] loss: 1.027
[26,     4] loss: 0.963
[27,     4] loss: 0.934
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 3.594480647036921e-05,
 'learning_rate_Hydroxylation-K': 0.0066976405293105905,
 'learning_rate_Methylation-K': 0.003202907537688044,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2603866148403664,
 'loss_weight_Methylation-K': 0.9202701086219595,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1775834171,
 'sample_weights': [0.4402306370890278, 0.16933438811780016],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.6285920425901,
 'weight_decay_Hydroxylation-K': 4.064482816117555,
 'weight_decay_Methylation-K': 1.6019289062067652}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.387
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035885821273072124,
 'learning_rate_Hydroxylation-K': 0.004045928761684227,
 'learning_rate_Methylation-K': 0.003336359301413994,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.701968224417792,
 'loss_weight_Methylation-K': 0.8722268703856593,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1410411159,
 'sample_weights': [0.2603866148403664, 0.9202701086219595],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.5803493217677484,
 'weight_decay_Hydroxylation-K': 6.1325403746602,
 'weight_decay_Methylation-K': 3.886188700328594}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.382
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004135151415534842,
 'learning_rate_Hydroxylation-K': 0.00212148427059281,
 'learning_rate_Methylation-K': 0.009206855532028074,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.220948475066559,
 'loss_weight_Methylation-K': 0.9651291793380945,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3693254549,
 'sample_weights': [0.701968224417792, 0.8722268703856593],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.08556328298409,
 'weight_decay_Hydroxylation-K': 3.6049556700393994,
 'weight_decay_Methylation-K': 9.377649435656336}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.375
[2,     4] loss: 1.390
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001110044390729597,
 'learning_rate_Hydroxylation-K': 0.003165502129553903,
 'learning_rate_Methylation-K': 0.009038355717135953,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2284615501827417,
 'loss_weight_Methylation-K': 0.8481013024232331,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3239606091,
 'sample_weights': [0.220948475066559, 0.9651291793380945],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.636620602082329,
 'weight_decay_Hydroxylation-K': 6.196672114994703,
 'weight_decay_Methylation-K': 9.961443572219107}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.387
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00281364772655568,
 'learning_rate_Hydroxylation-K': 0.0013728571007731263,
 'learning_rate_Methylation-K': 0.007153793235363732,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5802561928910748,
 'loss_weight_Methylation-K': 0.12791463874658882,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 245948465,
 'sample_weights': [0.2284615501827417, 0.8481013024232331],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.625124808904186,
 'weight_decay_Hydroxylation-K': 9.36195941613141,
 'weight_decay_Methylation-K': 3.4182962693276497}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.388
[5,     4] loss: 1.388
[6,     4] loss: 1.386
[7,     4] loss: 1.384
[8,     4] loss: 1.385
[9,     4] loss: 1.387
[10,     4] loss: 1.385
[11,     4] loss: 1.386
[12,     4] loss: 1.382
[13,     4] loss: 1.379
[14,     4] loss: 1.372
[15,     4] loss: 1.359
[16,     4] loss: 1.326
[17,     4] loss: 1.286
[18,     4] loss: 1.229
[19,     4] loss: 1.139
[20,     4] loss: 1.116
[21,     4] loss: 1.055
[22,     4] loss: 1.064
[23,     4] loss: 1.064
[24,     4] loss: 1.017
[25,     4] loss: 1.028
[26,     4] loss: 1.046
[27,     4] loss: 0.959
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00011420925747996567,
 'learning_rate_Hydroxylation-K': 0.008354134500566011,
 'learning_rate_Methylation-K': 0.0028535357214589654,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6929096597447724,
 'loss_weight_Methylation-K': 0.6862993636824618,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2281184835,
 'sample_weights': [0.5802561928910748, 0.12791463874658882],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.759040589100586,
 'weight_decay_Hydroxylation-K': 5.701852939327399,
 'weight_decay_Methylation-K': 9.543087210271946}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.384
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004055078492816484,
 'learning_rate_Hydroxylation-K': 0.001691636647872338,
 'learning_rate_Methylation-K': 0.0065814198672940315,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4800747319827104,
 'loss_weight_Methylation-K': 0.8038747309441681,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1160236131,
 'sample_weights': [0.6929096597447724, 0.6862993636824618],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.715868989854899,
 'weight_decay_Hydroxylation-K': 5.868312685573445,
 'weight_decay_Methylation-K': 9.551891593236416}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.414
[2,     4] loss: 1.389
[3,     4] loss: 1.396
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002002861592390813,
 'learning_rate_Hydroxylation-K': 0.009305184784538066,
 'learning_rate_Methylation-K': 0.0028482230383692314,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.45080387123188975,
 'loss_weight_Methylation-K': 0.8567430693081867,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2765855695,
 'sample_weights': [0.4800747319827104, 0.8038747309441681],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.0455550297807772,
 'weight_decay_Hydroxylation-K': 5.48640710591139,
 'weight_decay_Methylation-K': 2.594716794781938}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.385
[3,     4] loss: 1.384
[4,     4] loss: 1.378
[5,     4] loss: 1.366
[6,     4] loss: 1.359
[7,     4] loss: 1.328
[8,     4] loss: 1.292
[9,     4] loss: 1.242
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020748100864744637,
 'learning_rate_Hydroxylation-K': 0.006409320265757032,
 'learning_rate_Methylation-K': 0.006002932743972322,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6486155327718246,
 'loss_weight_Methylation-K': 0.618943330871055,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1560273494,
 'sample_weights': [0.45080387123188975, 0.8567430693081867],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.904882658963482,
 'weight_decay_Hydroxylation-K': 6.3354919889544545,
 'weight_decay_Methylation-K': 1.7109887515410354}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.391
[3,     4] loss: 1.379
[4,     4] loss: 1.360
[5,     4] loss: 1.326
[6,     4] loss: 1.254
[7,     4] loss: 1.199
[8,     4] loss: 1.120
[9,     4] loss: 1.137
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006734543690173617,
 'learning_rate_Hydroxylation-K': 0.006463539616536981,
 'learning_rate_Methylation-K': 0.008299200156570595,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7217060944296335,
 'loss_weight_Methylation-K': 0.8789490444100341,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 44328707,
 'sample_weights': [0.6486155327718246, 0.618943330871055],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.205454375189452,
 'weight_decay_Hydroxylation-K': 0.36977933187643,
 'weight_decay_Methylation-K': 9.955644113137405}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.390
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.386
[6,     4] loss: 1.376
[7,     4] loss: 1.361
[8,     4] loss: 1.287
[9,     4] loss: 1.288
[10,     4] loss: 1.222
[11,     4] loss: 1.120
[12,     4] loss: 1.196
[13,     4] loss: 1.107
[14,     4] loss: 1.073
[15,     4] loss: 1.015
[16,     4] loss: 0.976
[17,     4] loss: 1.119
[18,     4] loss: 1.116
[19,     4] loss: 0.959
[20,     4] loss: 1.285
[21,     4] loss: 1.147
[22,     4] loss: 1.319
[23,     4] loss: 1.247
[24,     4] loss: 1.289
[25,     4] loss: 1.262
[26,     4] loss: 1.179
[27,     4] loss: 1.227
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033629828009405613,
 'learning_rate_Hydroxylation-K': 0.0009612860563327787,
 'learning_rate_Methylation-K': 0.008795831502144188,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.41371756929822123,
 'loss_weight_Methylation-K': 0.8147896852742408,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3134850133,
 'sample_weights': [0.7217060944296335, 0.8789490444100341],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.1727246299232514,
 'weight_decay_Hydroxylation-K': 1.2907261455698857,
 'weight_decay_Methylation-K': 7.59149007727413}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.383
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0036492890791139983,
 'learning_rate_Hydroxylation-K': 0.003904449667353355,
 'learning_rate_Methylation-K': 0.008627088429225115,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.45939366300379286,
 'loss_weight_Methylation-K': 0.9519409272540187,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 574962073,
 'sample_weights': [0.41371756929822123, 0.8147896852742408],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.916150527392917,
 'weight_decay_Hydroxylation-K': 6.402704337973072,
 'weight_decay_Methylation-K': 9.747800947271855}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.383
[3,     4] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013702045779249883,
 'learning_rate_Hydroxylation-K': 0.00853561192773114,
 'learning_rate_Methylation-K': 0.009139791819893472,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.01922409781507628,
 'loss_weight_Methylation-K': 0.3530804538946621,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1462100027,
 'sample_weights': [0.45939366300379286, 0.9519409272540187],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.301473087086472,
 'weight_decay_Hydroxylation-K': 1.3847299813470062,
 'weight_decay_Methylation-K': 0.19962886715977501}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.384
[3,     4] loss: 1.380
[4,     4] loss: 1.361
[5,     4] loss: 1.331
[6,     4] loss: 1.270
[7,     4] loss: 1.168
[8,     4] loss: 1.164
[9,     4] loss: 1.036
[10,     4] loss: 0.992
[11,     4] loss: 1.023
[12,     4] loss: 0.995
[13,     4] loss: 0.956
[14,     4] loss: 0.852
[15,     4] loss: 0.894
[16,     4] loss: 0.900
[17,     4] loss: 0.903
[18,     4] loss: 0.883
[19,     4] loss: 0.926
[20,     4] loss: 0.968
[21,     4] loss: 0.832
[22,     4] loss: 0.838
[23,     4] loss: 0.813
[24,     4] loss: 0.789
[25,     4] loss: 0.779
[26,     4] loss: 0.792
[27,     4] loss: 0.782
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00950389209128021,
 'learning_rate_Hydroxylation-K': 0.0029816363285841987,
 'learning_rate_Methylation-K': 0.00124232328116162,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9107496175552435,
 'loss_weight_Methylation-K': 0.19006202890344023,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3629859297,
 'sample_weights': [0.01922409781507628, 0.3530804538946621],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.934806303070333,
 'weight_decay_Hydroxylation-K': 4.632805638204221,
 'weight_decay_Methylation-K': 1.564604963510468}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.387
[3,     4] loss: 1.384
[4,     4] loss: 1.389
[5,     4] loss: 1.382
[6,     4] loss: 1.389
[7,     4] loss: 1.386
[8,     4] loss: 1.385
[9,     4] loss: 1.377
[10,     4] loss: 1.354
[11,     4] loss: 1.315
[12,     4] loss: 1.310
[13,     4] loss: 1.311
[14,     4] loss: 1.231
[15,     4] loss: 1.224
[16,     4] loss: 1.241
[17,     4] loss: 1.124
[18,     4] loss: 1.157
[19,     4] loss: 1.106
[20,     4] loss: 1.127
[21,     4] loss: 1.186
[22,     4] loss: 1.095
[23,     4] loss: 1.002
[24,     4] loss: 1.101
[25,     4] loss: 1.134
[26,     4] loss: 1.004
[27,     4] loss: 1.249
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010174322489703807,
 'learning_rate_Hydroxylation-K': 0.008343239473476321,
 'learning_rate_Methylation-K': 0.0034186985743686945,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5011951724240259,
 'loss_weight_Methylation-K': 0.39660382712510367,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1092364913,
 'sample_weights': [0.9107496175552435, 0.19006202890344023],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.995992348461662,
 'weight_decay_Hydroxylation-K': 6.98930304413969,
 'weight_decay_Methylation-K': 0.4112156026114546}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019241681382704706,
 'learning_rate_Hydroxylation-K': 0.006496255402416283,
 'learning_rate_Methylation-K': 0.006204205868779391,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5869079065564717,
 'loss_weight_Methylation-K': 0.963793022245587,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3340063849,
 'sample_weights': [0.5011951724240259, 0.39660382712510367],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.714701868760033,
 'weight_decay_Hydroxylation-K': 5.630902120317009,
 'weight_decay_Methylation-K': 6.5770795701790234}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.385
[3,     4] loss: 1.389
[4,     4] loss: 1.387
[5,     4] loss: 1.384
[6,     4] loss: 1.379
[7,     4] loss: 1.376
[8,     4] loss: 1.356
[9,     4] loss: 1.329
[10,     4] loss: 1.269
[11,     4] loss: 1.187
[12,     4] loss: 1.171
[13,     4] loss: 1.143
[14,     4] loss: 1.077
[15,     4] loss: 1.110
[16,     4] loss: 1.044
[17,     4] loss: 1.016
[18,     4] loss: 0.977
[19,     4] loss: 0.920
[20,     4] loss: 0.951
[21,     4] loss: 0.919
[22,     4] loss: 1.028
[23,     4] loss: 0.975
[24,     4] loss: 0.945
[25,     4] loss: 0.890
[26,     4] loss: 0.899
[27,     4] loss: 0.874
[28,     4] loss: 0.952
[29,     4] loss: 0.969
[30,     4] loss: 1.063
[31,     4] loss: 0.989
[32,     4] loss: 0.962
[33,     4] loss: 0.890
[34,     4] loss: 0.866
[35,     4] loss: 0.898
[36,     4] loss: 0.868
[37,     4] loss: 0.848
[38,     4] loss: 0.862
[39,     4] loss: 0.837
[40,     4] loss: 0.839
[41,     4] loss: 0.827
[42,     4] loss: 0.806
[43,     4] loss: 0.807
[44,     4] loss: 0.812
[45,     4] loss: 0.812
[46,     4] loss: 0.797
[47,     4] loss: 0.784
[48,     4] loss: 0.850
[49,     4] loss: 0.810
[50,     4] loss: 0.794
[51,     4] loss: 0.838
[52,     4] loss: 0.895
[53,     4] loss: 0.890
[54,     4] loss: 0.985
[55,     4] loss: 0.899
[56,     4] loss: 0.837
[57,     4] loss: 0.797
[58,     4] loss: 0.803
[59,     4] loss: 0.803
[60,     4] loss: 0.770
[61,     4] loss: 0.761
[62,     4] loss: 0.759
[63,     4] loss: 0.755
[64,     4] loss: 0.814
[65,     4] loss: 0.775
[66,     4] loss: 0.794
[67,     4] loss: 0.802
[68,     4] loss: 0.811
Early stopping applied (best metric=0.356618732213974)
Finished Training
Total time taken: 34.25310134887695
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.390
[3,     4] loss: 1.381
[4,     4] loss: 1.377
[5,     4] loss: 1.348
[6,     4] loss: 1.348
[7,     4] loss: 1.310
[8,     4] loss: 1.239
[9,     4] loss: 1.191
[10,     4] loss: 1.128
[11,     4] loss: 1.121
[12,     4] loss: 1.078
[13,     4] loss: 1.161
[14,     4] loss: 1.094
[15,     4] loss: 1.066
[16,     4] loss: 1.045
[17,     4] loss: 1.008
[18,     4] loss: 0.948
[19,     4] loss: 0.903
[20,     4] loss: 0.904
[21,     4] loss: 0.843
[22,     4] loss: 0.992
[23,     4] loss: 0.983
[24,     4] loss: 1.047
[25,     4] loss: 0.956
[26,     4] loss: 1.100
[27,     4] loss: 1.007
[28,     4] loss: 0.962
[29,     4] loss: 0.881
[30,     4] loss: 0.885
[31,     4] loss: 0.873
[32,     4] loss: 0.897
[33,     4] loss: 0.878
[34,     4] loss: 0.803
[35,     4] loss: 0.786
[36,     4] loss: 0.816
[37,     4] loss: 0.880
[38,     4] loss: 0.964
[39,     4] loss: 0.951
[40,     4] loss: 0.925
[41,     4] loss: 0.900
[42,     4] loss: 0.819
[43,     4] loss: 0.865
[44,     4] loss: 0.811
[45,     4] loss: 0.786
[46,     4] loss: 0.785
[47,     4] loss: 0.797
[48,     4] loss: 0.904
[49,     4] loss: 0.852
[50,     4] loss: 0.879
[51,     4] loss: 0.846
[52,     4] loss: 0.839
[53,     4] loss: 0.813
[54,     4] loss: 0.792
[55,     4] loss: 0.841
[56,     4] loss: 0.839
[57,     4] loss: 0.772
[58,     4] loss: 0.795
[59,     4] loss: 0.799
[60,     4] loss: 0.785
[61,     4] loss: 0.832
[62,     4] loss: 0.787
[63,     4] loss: 0.784
[64,     4] loss: 0.826
[65,     4] loss: 0.874
[66,     4] loss: 0.879
[67,     4] loss: 0.847
Early stopping applied (best metric=0.4119724631309509)
Finished Training
Total time taken: 33.90310478210449
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.400
[2,     4] loss: 1.390
[3,     4] loss: 1.379
[4,     4] loss: 1.384
[5,     4] loss: 1.379
[6,     4] loss: 1.373
[7,     4] loss: 1.343
[8,     4] loss: 1.290
[9,     4] loss: 1.226
[10,     4] loss: 1.141
[11,     4] loss: 1.099
[12,     4] loss: 1.102
[13,     4] loss: 1.050
[14,     4] loss: 0.992
[15,     4] loss: 1.000
[16,     4] loss: 1.028
[17,     4] loss: 0.993
[18,     4] loss: 0.985
[19,     4] loss: 0.982
[20,     4] loss: 0.957
[21,     4] loss: 0.992
[22,     4] loss: 0.911
[23,     4] loss: 0.909
[24,     4] loss: 0.874
[25,     4] loss: 0.948
[26,     4] loss: 0.912
[27,     4] loss: 0.910
[28,     4] loss: 0.882
[29,     4] loss: 0.943
[30,     4] loss: 0.863
[31,     4] loss: 0.908
[32,     4] loss: 0.848
[33,     4] loss: 0.877
[34,     4] loss: 0.847
[35,     4] loss: 0.827
[36,     4] loss: 0.838
[37,     4] loss: 0.809
[38,     4] loss: 0.827
[39,     4] loss: 0.897
[40,     4] loss: 0.898
[41,     4] loss: 0.884
[42,     4] loss: 0.836
[43,     4] loss: 0.865
[44,     4] loss: 0.803
[45,     4] loss: 0.809
[46,     4] loss: 0.803
[47,     4] loss: 0.795
[48,     4] loss: 0.776
[49,     4] loss: 0.790
[50,     4] loss: 0.874
[51,     4] loss: 0.803
[52,     4] loss: 0.842
[53,     4] loss: 0.829
[54,     4] loss: 0.801
[55,     4] loss: 0.836
[56,     4] loss: 0.819
[57,     4] loss: 0.787
[58,     4] loss: 0.867
Early stopping applied (best metric=0.4860994517803192)
Finished Training
Total time taken: 29.359086990356445
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.389
[3,     4] loss: 1.394
[4,     4] loss: 1.385
[5,     4] loss: 1.381
[6,     4] loss: 1.374
[7,     4] loss: 1.364
[8,     4] loss: 1.333
[9,     4] loss: 1.280
[10,     4] loss: 1.216
[11,     4] loss: 1.242
[12,     4] loss: 1.166
[13,     4] loss: 1.072
[14,     4] loss: 1.029
[15,     4] loss: 1.045
[16,     4] loss: 0.920
[17,     4] loss: 0.958
[18,     4] loss: 1.113
[19,     4] loss: 1.015
[20,     4] loss: 0.985
[21,     4] loss: 1.031
[22,     4] loss: 0.922
[23,     4] loss: 0.955
[24,     4] loss: 0.857
[25,     4] loss: 0.927
[26,     4] loss: 0.881
[27,     4] loss: 0.901
[28,     4] loss: 0.942
[29,     4] loss: 0.876
[30,     4] loss: 0.867
[31,     4] loss: 0.858
[32,     4] loss: 0.851
[33,     4] loss: 0.816
[34,     4] loss: 0.831
[35,     4] loss: 0.830
[36,     4] loss: 0.814
[37,     4] loss: 0.828
[38,     4] loss: 0.824
[39,     4] loss: 0.835
[40,     4] loss: 0.878
[41,     4] loss: 0.840
[42,     4] loss: 0.799
[43,     4] loss: 0.840
[44,     4] loss: 0.889
[45,     4] loss: 0.895
[46,     4] loss: 0.853
[47,     4] loss: 0.827
[48,     4] loss: 0.763
[49,     4] loss: 0.774
[50,     4] loss: 0.778
[51,     4] loss: 0.767
[52,     4] loss: 0.796
[53,     4] loss: 0.811
[54,     4] loss: 0.829
[55,     4] loss: 0.844
[56,     4] loss: 0.815
[57,     4] loss: 0.827
[58,     4] loss: 0.827
[59,     4] loss: 0.818
[60,     4] loss: 0.826
Early stopping applied (best metric=0.4949294328689575)
Finished Training
Total time taken: 30.38809061050415
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.392
[2,     4] loss: 1.386
[3,     4] loss: 1.383
[4,     4] loss: 1.379
[5,     4] loss: 1.379
[6,     4] loss: 1.345
[7,     4] loss: 1.296
[8,     4] loss: 1.278
[9,     4] loss: 1.197
[10,     4] loss: 1.141
[11,     4] loss: 1.137
[12,     4] loss: 1.025
[13,     4] loss: 1.028
[14,     4] loss: 0.961
[15,     4] loss: 1.001
[16,     4] loss: 0.930
[17,     4] loss: 0.971
[18,     4] loss: 0.871
[19,     4] loss: 0.851
[20,     4] loss: 0.879
[21,     4] loss: 0.831
[22,     4] loss: 0.925
[23,     4] loss: 0.904
[24,     4] loss: 0.871
[25,     4] loss: 0.909
[26,     4] loss: 0.861
[27,     4] loss: 0.768
[28,     4] loss: 0.810
[29,     4] loss: 0.883
[30,     4] loss: 0.794
[31,     4] loss: 0.823
[32,     4] loss: 0.813
[33,     4] loss: 0.781
[34,     4] loss: 0.763
[35,     4] loss: 0.774
[36,     4] loss: 0.748
[37,     4] loss: 0.748
[38,     4] loss: 0.910
[39,     4] loss: 0.852
[40,     4] loss: 0.904
[41,     4] loss: 0.860
[42,     4] loss: 0.861
[43,     4] loss: 0.789
[44,     4] loss: 0.784
[45,     4] loss: 0.742
[46,     4] loss: 0.763
[47,     4] loss: 0.821
[48,     4] loss: 0.764
[49,     4] loss: 0.760
[50,     4] loss: 0.820
[51,     4] loss: 0.759
[52,     4] loss: 0.779
[53,     4] loss: 0.821
[54,     4] loss: 0.820
[55,     4] loss: 0.818
[56,     4] loss: 0.853
[57,     4] loss: 0.868
Early stopping applied (best metric=0.5090031027793884)
Finished Training
Total time taken: 28.888089418411255
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.388
[3,     4] loss: 1.383
[4,     4] loss: 1.384
[5,     4] loss: 1.384
[6,     4] loss: 1.387
[7,     4] loss: 1.382
[8,     4] loss: 1.379
[9,     4] loss: 1.372
[10,     4] loss: 1.333
[11,     4] loss: 1.286
[12,     4] loss: 1.228
[13,     4] loss: 1.304
[14,     4] loss: 1.226
[15,     4] loss: 1.165
[16,     4] loss: 1.112
[17,     4] loss: 1.107
[18,     4] loss: 1.021
[19,     4] loss: 1.048
[20,     4] loss: 1.040
[21,     4] loss: 1.098
[22,     4] loss: 1.042
[23,     4] loss: 1.042
[24,     4] loss: 0.924
[25,     4] loss: 0.929
[26,     4] loss: 1.037
[27,     4] loss: 0.971
[28,     4] loss: 0.902
[29,     4] loss: 0.927
[30,     4] loss: 0.928
[31,     4] loss: 0.898
[32,     4] loss: 0.891
[33,     4] loss: 0.968
[34,     4] loss: 0.924
[35,     4] loss: 0.962
[36,     4] loss: 0.899
[37,     4] loss: 0.823
[38,     4] loss: 0.838
[39,     4] loss: 0.807
[40,     4] loss: 0.833
[41,     4] loss: 0.833
[42,     4] loss: 0.876
[43,     4] loss: 0.898
[44,     4] loss: 0.899
[45,     4] loss: 0.877
[46,     4] loss: 0.830
[47,     4] loss: 0.857
[48,     4] loss: 0.783
[49,     4] loss: 0.807
[50,     4] loss: 0.818
[51,     4] loss: 0.830
[52,     4] loss: 0.781
[53,     4] loss: 0.905
[54,     4] loss: 0.893
[55,     4] loss: 0.842
[56,     4] loss: 0.865
[57,     4] loss: 0.812
[58,     4] loss: 0.803
[59,     4] loss: 0.836
[60,     4] loss: 0.837
[61,     4] loss: 0.805
[62,     4] loss: 0.796
[63,     4] loss: 0.912
[64,     4] loss: 1.267
[65,     4] loss: 1.064
[66,     4] loss: 1.090
[67,     4] loss: 1.003
[68,     4] loss: 0.997
[69,     4] loss: 0.869
[70,     4] loss: 0.859
[71,     4] loss: 0.840
[72,     4] loss: 0.821
[73,     4] loss: 0.817
[74,     4] loss: 0.806
[75,     4] loss: 0.800
[76,     4] loss: 0.785
[77,     4] loss: 0.801
[78,     4] loss: 0.805
[79,     4] loss: 0.865
[80,     4] loss: 1.050
[81,     4] loss: 1.150
[82,     4] loss: 1.157
Early stopping applied (best metric=0.196198970079422)
Finished Training
Total time taken: 41.46912169456482
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.388
[5,     4] loss: 1.386
[6,     4] loss: 1.388
[7,     4] loss: 1.384
[8,     4] loss: 1.385
[9,     4] loss: 1.386
[10,     4] loss: 1.384
[11,     4] loss: 1.381
[12,     4] loss: 1.361
[13,     4] loss: 1.330
[14,     4] loss: 1.279
[15,     4] loss: 1.220
[16,     4] loss: 1.138
[17,     4] loss: 1.137
[18,     4] loss: 1.142
[19,     4] loss: 1.155
[20,     4] loss: 1.064
[21,     4] loss: 1.062
[22,     4] loss: 1.029
[23,     4] loss: 1.052
[24,     4] loss: 1.051
[25,     4] loss: 1.008
[26,     4] loss: 0.945
[27,     4] loss: 1.007
[28,     4] loss: 0.931
[29,     4] loss: 0.870
[30,     4] loss: 0.881
[31,     4] loss: 0.885
[32,     4] loss: 0.900
[33,     4] loss: 0.923
[34,     4] loss: 0.910
[35,     4] loss: 0.850
[36,     4] loss: 0.827
[37,     4] loss: 0.829
[38,     4] loss: 0.828
[39,     4] loss: 0.890
[40,     4] loss: 0.931
[41,     4] loss: 0.884
[42,     4] loss: 0.883
[43,     4] loss: 0.820
[44,     4] loss: 0.849
[45,     4] loss: 0.840
[46,     4] loss: 0.779
[47,     4] loss: 0.775
[48,     4] loss: 0.836
[49,     4] loss: 0.862
[50,     4] loss: 0.848
[51,     4] loss: 0.859
[52,     4] loss: 0.821
[53,     4] loss: 0.800
[54,     4] loss: 0.835
[55,     4] loss: 0.889
[56,     4] loss: 0.843
[57,     4] loss: 0.792
[58,     4] loss: 0.822
[59,     4] loss: 0.890
[60,     4] loss: 0.836
[61,     4] loss: 0.803
[62,     4] loss: 0.786
[63,     4] loss: 0.838
[64,     4] loss: 0.948
[65,     4] loss: 1.107
[66,     4] loss: 1.129
[67,     4] loss: 1.038
[68,     4] loss: 0.976
[69,     4] loss: 0.870
[70,     4] loss: 0.852
[71,     4] loss: 0.894
[72,     4] loss: 0.845
[73,     4] loss: 0.913
[74,     4] loss: 0.937
[75,     4] loss: 0.983
Early stopping applied (best metric=0.24772357940673828)
Finished Training
Total time taken: 37.59311032295227
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.381
[3,     4] loss: 1.386
[4,     4] loss: 1.379
[5,     4] loss: 1.365
[6,     4] loss: 1.330
[7,     4] loss: 1.299
[8,     4] loss: 1.285
[9,     4] loss: 1.203
[10,     4] loss: 1.133
[11,     4] loss: 1.123
[12,     4] loss: 1.099
[13,     4] loss: 1.054
[14,     4] loss: 1.109
[15,     4] loss: 1.014
[16,     4] loss: 0.961
[17,     4] loss: 1.014
[18,     4] loss: 0.964
[19,     4] loss: 0.894
[20,     4] loss: 0.835
[21,     4] loss: 0.941
[22,     4] loss: 0.961
[23,     4] loss: 1.036
[24,     4] loss: 0.891
[25,     4] loss: 0.916
[26,     4] loss: 0.927
[27,     4] loss: 0.840
[28,     4] loss: 0.922
[29,     4] loss: 0.993
[30,     4] loss: 0.876
[31,     4] loss: 0.875
[32,     4] loss: 0.846
[33,     4] loss: 0.849
[34,     4] loss: 0.821
[35,     4] loss: 0.774
[36,     4] loss: 0.764
[37,     4] loss: 0.775
[38,     4] loss: 0.829
[39,     4] loss: 0.981
[40,     4] loss: 0.914
[41,     4] loss: 0.956
[42,     4] loss: 0.868
[43,     4] loss: 0.853
[44,     4] loss: 0.830
[45,     4] loss: 0.829
[46,     4] loss: 0.767
[47,     4] loss: 0.800
[48,     4] loss: 0.777
[49,     4] loss: 0.803
[50,     4] loss: 0.759
[51,     4] loss: 0.874
[52,     4] loss: 0.797
[53,     4] loss: 0.782
[54,     4] loss: 0.811
[55,     4] loss: 0.789
[56,     4] loss: 0.810
[57,     4] loss: 0.828
[58,     4] loss: 0.774
[59,     4] loss: 0.798
[60,     4] loss: 0.819
[61,     4] loss: 0.794
Early stopping applied (best metric=0.37492918968200684)
Finished Training
Total time taken: 30.892090797424316
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.386
[3,     4] loss: 1.390
[4,     4] loss: 1.388
[5,     4] loss: 1.381
[6,     4] loss: 1.383
[7,     4] loss: 1.371
[8,     4] loss: 1.356
[9,     4] loss: 1.340
[10,     4] loss: 1.295
[11,     4] loss: 1.314
[12,     4] loss: 1.222
[13,     4] loss: 1.203
[14,     4] loss: 1.179
[15,     4] loss: 1.118
[16,     4] loss: 1.161
[17,     4] loss: 1.071
[18,     4] loss: 0.970
[19,     4] loss: 0.993
[20,     4] loss: 0.929
[21,     4] loss: 0.905
[22,     4] loss: 1.016
[23,     4] loss: 1.207
[24,     4] loss: 1.034
[25,     4] loss: 1.066
[26,     4] loss: 1.029
[27,     4] loss: 0.987
[28,     4] loss: 0.863
[29,     4] loss: 0.860
[30,     4] loss: 0.870
[31,     4] loss: 0.954
[32,     4] loss: 0.867
[33,     4] loss: 0.853
[34,     4] loss: 0.840
[35,     4] loss: 0.803
[36,     4] loss: 0.785
[37,     4] loss: 0.793
[38,     4] loss: 0.791
[39,     4] loss: 0.786
[40,     4] loss: 0.800
[41,     4] loss: 0.840
[42,     4] loss: 0.821
[43,     4] loss: 0.895
[44,     4] loss: 0.824
[45,     4] loss: 0.795
[46,     4] loss: 0.787
[47,     4] loss: 0.760
[48,     4] loss: 0.791
[49,     4] loss: 0.778
[50,     4] loss: 0.786
[51,     4] loss: 0.817
[52,     4] loss: 0.805
[53,     4] loss: 1.074
[54,     4] loss: 0.943
[55,     4] loss: 0.953
[56,     4] loss: 0.884
[57,     4] loss: 0.916
[58,     4] loss: 0.861
[59,     4] loss: 0.840
[60,     4] loss: 0.847
[61,     4] loss: 0.814
[62,     4] loss: 0.768
[63,     4] loss: 0.758
[64,     4] loss: 0.747
[65,     4] loss: 0.748
[66,     4] loss: 0.760
[67,     4] loss: 0.797
[68,     4] loss: 0.895
[69,     4] loss: 0.849
[70,     4] loss: 0.812
[71,     4] loss: 0.758
[72,     4] loss: 0.820
[73,     4] loss: 0.816
[74,     4] loss: 0.819
[75,     4] loss: 0.796
[76,     4] loss: 0.801
[77,     4] loss: 0.786
[78,     4] loss: 0.787
[79,     4] loss: 0.772
[80,     4] loss: 0.757
[81,     4] loss: 0.772
Early stopping applied (best metric=0.32220402359962463)
Finished Training
Total time taken: 40.93112301826477
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.388
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.386
[5,     4] loss: 1.381
[6,     4] loss: 1.370
[7,     4] loss: 1.347
[8,     4] loss: 1.305
[9,     4] loss: 1.264
[10,     4] loss: 1.195
[11,     4] loss: 1.092
[12,     4] loss: 1.094
[13,     4] loss: 1.185
[14,     4] loss: 1.202
[15,     4] loss: 1.162
[16,     4] loss: 1.145
[17,     4] loss: 1.102
[18,     4] loss: 1.072
[19,     4] loss: 1.032
[20,     4] loss: 0.993
[21,     4] loss: 1.025
[22,     4] loss: 0.915
[23,     4] loss: 0.921
[24,     4] loss: 0.968
[25,     4] loss: 0.922
[26,     4] loss: 0.934
[27,     4] loss: 0.962
[28,     4] loss: 0.948
[29,     4] loss: 0.894
[30,     4] loss: 0.877
[31,     4] loss: 0.856
[32,     4] loss: 0.856
[33,     4] loss: 0.823
[34,     4] loss: 0.841
[35,     4] loss: 0.817
[36,     4] loss: 0.790
[37,     4] loss: 0.797
[38,     4] loss: 0.839
[39,     4] loss: 0.853
[40,     4] loss: 0.820
[41,     4] loss: 0.961
[42,     4] loss: 0.998
[43,     4] loss: 1.050
[44,     4] loss: 1.014
[45,     4] loss: 0.920
[46,     4] loss: 0.801
[47,     4] loss: 0.806
[48,     4] loss: 0.786
[49,     4] loss: 0.818
[50,     4] loss: 0.772
[51,     4] loss: 0.816
[52,     4] loss: 0.811
[53,     4] loss: 0.771
[54,     4] loss: 0.768
[55,     4] loss: 0.801
[56,     4] loss: 0.862
[57,     4] loss: 0.860
[58,     4] loss: 0.891
[59,     4] loss: 0.824
[60,     4] loss: 0.793
[61,     4] loss: 0.807
[62,     4] loss: 0.789
[63,     4] loss: 0.775
[64,     4] loss: 0.815
[65,     4] loss: 0.784
[66,     4] loss: 0.785
[67,     4] loss: 0.788
[68,     4] loss: 0.817
[69,     4] loss: 0.797
[70,     4] loss: 0.821
[71,     4] loss: 0.862
[72,     4] loss: 0.854
[73,     4] loss: 0.829
[74,     4] loss: 0.809
[75,     4] loss: 0.797
[76,     4] loss: 0.756
[77,     4] loss: 0.798
[78,     4] loss: 0.778
[79,     4] loss: 0.782
[80,     4] loss: 0.838
[81,     4] loss: 0.824
[82,     4] loss: 0.807
[83,     4] loss: 0.911
[84,     4] loss: 0.880
[85,     4] loss: 0.911
[86,     4] loss: 0.924
[87,     4] loss: 0.858
[88,     4] loss: 0.846
[89,     4] loss: 0.857
[90,     4] loss: 0.873
[91,     4] loss: 0.840
[92,     4] loss: 0.846
[93,     4] loss: 0.893
[94,     4] loss: 0.789
[95,     4] loss: 0.791
[96,     4] loss: 0.779
[97,     4] loss: 0.755
[98,     4] loss: 0.811
[99,     4] loss: 0.794
[100,     4] loss: 0.935
[101,     4] loss: 1.005
[102,     4] loss: 0.933
[103,     4] loss: 0.890
[104,     4] loss: 0.846
[105,     4] loss: 0.797
[106,     4] loss: 0.843
[107,     4] loss: 0.790
[108,     4] loss: 0.798
[109,     4] loss: 0.769
[110,     4] loss: 0.795
[111,     4] loss: 0.851
[112,     4] loss: 0.837
[113,     4] loss: 0.822
[114,     4] loss: 0.781
[115,     4] loss: 0.772
[116,     4] loss: 0.802
[117,     4] loss: 0.826
[118,     4] loss: 0.853
[119,     4] loss: 0.839
Early stopping applied (best metric=0.29503217339515686)
Finished Training
Total time taken: 60.02018070220947
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.382
[3,     4] loss: 1.384
[4,     4] loss: 1.383
[5,     4] loss: 1.368
[6,     4] loss: 1.357
[7,     4] loss: 1.300
[8,     4] loss: 1.293
[9,     4] loss: 1.262
[10,     4] loss: 1.173
[11,     4] loss: 1.190
[12,     4] loss: 1.051
[13,     4] loss: 0.953
[14,     4] loss: 0.925
[15,     4] loss: 1.024
[16,     4] loss: 1.065
[17,     4] loss: 1.055
[18,     4] loss: 0.990
[19,     4] loss: 0.957
[20,     4] loss: 0.907
[21,     4] loss: 0.893
[22,     4] loss: 0.856
[23,     4] loss: 0.903
[24,     4] loss: 0.911
[25,     4] loss: 0.863
[26,     4] loss: 0.855
[27,     4] loss: 0.840
[28,     4] loss: 0.899
[29,     4] loss: 0.921
[30,     4] loss: 0.917
[31,     4] loss: 1.000
[32,     4] loss: 0.941
[33,     4] loss: 0.904
[34,     4] loss: 0.839
[35,     4] loss: 0.805
[36,     4] loss: 0.828
[37,     4] loss: 0.771
[38,     4] loss: 0.772
[39,     4] loss: 0.773
[40,     4] loss: 0.802
[41,     4] loss: 0.855
[42,     4] loss: 0.768
[43,     4] loss: 0.779
[44,     4] loss: 0.776
[45,     4] loss: 0.773
[46,     4] loss: 0.779
[47,     4] loss: 0.782
[48,     4] loss: 0.799
[49,     4] loss: 0.796
[50,     4] loss: 0.773
[51,     4] loss: 0.771
[52,     4] loss: 0.805
[53,     4] loss: 0.773
[54,     4] loss: 0.844
[55,     4] loss: 0.966
[56,     4] loss: 0.916
[57,     4] loss: 0.927
[58,     4] loss: 0.900
[59,     4] loss: 0.892
[60,     4] loss: 0.919
[61,     4] loss: 0.824
Early stopping applied (best metric=0.42869052290916443)
Finished Training
Total time taken: 30.58709144592285
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.387
[3,     4] loss: 1.376
[4,     4] loss: 1.370
[5,     4] loss: 1.327
[6,     4] loss: 1.281
[7,     4] loss: 1.253
[8,     4] loss: 1.138
[9,     4] loss: 1.147
[10,     4] loss: 1.049
[11,     4] loss: 1.059
[12,     4] loss: 1.047
[13,     4] loss: 1.056
[14,     4] loss: 1.057
[15,     4] loss: 1.081
[16,     4] loss: 1.081
[17,     4] loss: 1.045
[18,     4] loss: 0.958
[19,     4] loss: 0.916
[20,     4] loss: 0.934
[21,     4] loss: 0.930
[22,     4] loss: 0.926
[23,     4] loss: 1.052
[24,     4] loss: 0.978
[25,     4] loss: 0.949
[26,     4] loss: 0.885
[27,     4] loss: 0.849
[28,     4] loss: 0.863
[29,     4] loss: 0.827
[30,     4] loss: 0.799
[31,     4] loss: 0.909
[32,     4] loss: 1.031
[33,     4] loss: 0.980
[34,     4] loss: 0.994
[35,     4] loss: 0.923
[36,     4] loss: 0.856
[37,     4] loss: 0.826
[38,     4] loss: 0.856
[39,     4] loss: 0.831
[40,     4] loss: 0.822
[41,     4] loss: 0.791
[42,     4] loss: 0.807
[43,     4] loss: 0.847
[44,     4] loss: 0.839
[45,     4] loss: 0.814
[46,     4] loss: 0.797
[47,     4] loss: 0.788
[48,     4] loss: 0.777
[49,     4] loss: 0.826
[50,     4] loss: 0.813
[51,     4] loss: 0.802
[52,     4] loss: 0.824
[53,     4] loss: 0.782
[54,     4] loss: 0.804
[55,     4] loss: 0.802
[56,     4] loss: 0.885
[57,     4] loss: 0.880
[58,     4] loss: 0.869
[59,     4] loss: 0.833
[60,     4] loss: 0.817
[61,     4] loss: 0.779
[62,     4] loss: 0.871
[63,     4] loss: 0.821
[64,     4] loss: 0.869
[65,     4] loss: 0.807
[66,     4] loss: 0.824
[67,     4] loss: 0.750
[68,     4] loss: 0.783
[69,     4] loss: 0.790
[70,     4] loss: 0.809
[71,     4] loss: 0.784
[72,     4] loss: 0.768
[73,     4] loss: 0.773
[74,     4] loss: 0.931
[75,     4] loss: 0.944
[76,     4] loss: 0.935
[77,     4] loss: 0.885
Early stopping applied (best metric=0.25553658604621887)
Finished Training
Total time taken: 39.05111765861511
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.384
[3,     4] loss: 1.384
[4,     4] loss: 1.383
[5,     4] loss: 1.363
[6,     4] loss: 1.345
[7,     4] loss: 1.301
[8,     4] loss: 1.237
[9,     4] loss: 1.209
[10,     4] loss: 1.122
[11,     4] loss: 1.089
[12,     4] loss: 1.137
[13,     4] loss: 1.091
[14,     4] loss: 1.110
[15,     4] loss: 0.996
[16,     4] loss: 1.002
[17,     4] loss: 0.915
[18,     4] loss: 0.958
[19,     4] loss: 0.910
[20,     4] loss: 0.951
[21,     4] loss: 1.015
[22,     4] loss: 0.969
[23,     4] loss: 0.924
[24,     4] loss: 0.926
[25,     4] loss: 0.863
[26,     4] loss: 0.826
[27,     4] loss: 0.903
[28,     4] loss: 0.818
[29,     4] loss: 0.820
[30,     4] loss: 0.832
[31,     4] loss: 0.823
[32,     4] loss: 0.831
[33,     4] loss: 0.827
[34,     4] loss: 0.840
[35,     4] loss: 0.872
[36,     4] loss: 0.903
[37,     4] loss: 0.848
[38,     4] loss: 0.824
[39,     4] loss: 0.850
[40,     4] loss: 0.770
[41,     4] loss: 0.748
[42,     4] loss: 0.741
[43,     4] loss: 0.791
[44,     4] loss: 0.925
[45,     4] loss: 0.924
[46,     4] loss: 0.895
[47,     4] loss: 0.857
[48,     4] loss: 0.806
[49,     4] loss: 0.784
[50,     4] loss: 0.827
[51,     4] loss: 0.790
[52,     4] loss: 0.829
[53,     4] loss: 0.827
[54,     4] loss: 0.794
[55,     4] loss: 0.924
[56,     4] loss: 0.873
[57,     4] loss: 0.888
[58,     4] loss: 0.833
[59,     4] loss: 0.794
[60,     4] loss: 0.767
[61,     4] loss: 0.774
[62,     4] loss: 0.795
[63,     4] loss: 0.786
[64,     4] loss: 0.773
[65,     4] loss: 0.760
[66,     4] loss: 0.775
[67,     4] loss: 0.762
[68,     4] loss: 0.800
[69,     4] loss: 0.793
[70,     4] loss: 0.812
[71,     4] loss: 0.783
[72,     4] loss: 0.821
[73,     4] loss: 0.779
[74,     4] loss: 0.788
[75,     4] loss: 0.885
[76,     4] loss: 1.022
[77,     4] loss: 1.006
[78,     4] loss: 0.935
[79,     4] loss: 0.860
[80,     4] loss: 0.789
[81,     4] loss: 0.774
[82,     4] loss: 0.789
[83,     4] loss: 0.785
[84,     4] loss: 0.766
[85,     4] loss: 0.864
[86,     4] loss: 0.933
[87,     4] loss: 0.976
[88,     4] loss: 0.904
[89,     4] loss: 0.865
[90,     4] loss: 0.827
[91,     4] loss: 0.817
[92,     4] loss: 0.790
[93,     4] loss: 0.807
[94,     4] loss: 0.761
[95,     4] loss: 0.792
[96,     4] loss: 0.777
[97,     4] loss: 0.811
[98,     4] loss: 0.796
[99,     4] loss: 0.812
[100,     4] loss: 0.786
[101,     4] loss: 0.965
[102,     4] loss: 0.849
[103,     4] loss: 0.903
[104,     4] loss: 0.865
[105,     4] loss: 0.838
[106,     4] loss: 0.792
[107,     4] loss: 0.775
[108,     4] loss: 0.792
[109,     4] loss: 0.758
[110,     4] loss: 0.780
[111,     4] loss: 0.772
[112,     4] loss: 0.786
[113,     4] loss: 0.767
[114,     4] loss: 0.758
[115,     4] loss: 0.791
[116,     4] loss: 0.808
[117,     4] loss: 0.806
[118,     4] loss: 0.842
[119,     4] loss: 0.890
[120,     4] loss: 0.834
[121,     4] loss: 0.804
[122,     4] loss: 0.756
[123,     4] loss: 0.765
[124,     4] loss: 0.765
[125,     4] loss: 0.921
[126,     4] loss: 0.823
[127,     4] loss: 0.864
[128,     4] loss: 0.812
[129,     4] loss: 0.809
[130,     4] loss: 0.763
[131,     4] loss: 0.756
[132,     4] loss: 0.765
[133,     4] loss: 0.755
[134,     4] loss: 0.754
[135,     4] loss: 0.779
[136,     4] loss: 0.845
[137,     4] loss: 0.926
[138,     4] loss: 0.894
Early stopping applied (best metric=0.3334217667579651)
Finished Training
Total time taken: 69.47621035575867
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.390
[4,     4] loss: 1.383
[5,     4] loss: 1.379
[6,     4] loss: 1.369
[7,     4] loss: 1.352
[8,     4] loss: 1.305
[9,     4] loss: 1.239
[10,     4] loss: 1.217
[11,     4] loss: 1.213
[12,     4] loss: 1.178
[13,     4] loss: 1.181
[14,     4] loss: 1.124
[15,     4] loss: 1.027
[16,     4] loss: 1.009
[17,     4] loss: 0.961
[18,     4] loss: 0.933
[19,     4] loss: 0.979
[20,     4] loss: 1.000
[21,     4] loss: 0.973
[22,     4] loss: 0.948
[23,     4] loss: 0.881
[24,     4] loss: 0.890
[25,     4] loss: 0.858
[26,     4] loss: 0.892
[27,     4] loss: 1.061
[28,     4] loss: 1.010
[29,     4] loss: 1.026
[30,     4] loss: 0.963
[31,     4] loss: 0.909
[32,     4] loss: 0.866
[33,     4] loss: 0.805
[34,     4] loss: 0.827
[35,     4] loss: 0.853
[36,     4] loss: 0.832
[37,     4] loss: 0.821
[38,     4] loss: 0.798
[39,     4] loss: 0.820
[40,     4] loss: 0.820
[41,     4] loss: 0.798
[42,     4] loss: 0.812
[43,     4] loss: 0.818
[44,     4] loss: 0.896
[45,     4] loss: 0.802
[46,     4] loss: 0.801
[47,     4] loss: 0.790
[48,     4] loss: 0.784
[49,     4] loss: 0.785
[50,     4] loss: 0.904
[51,     4] loss: 0.956
[52,     4] loss: 0.851
[53,     4] loss: 0.818
[54,     4] loss: 0.814
[55,     4] loss: 0.916
[56,     4] loss: 0.856
[57,     4] loss: 0.848
[58,     4] loss: 0.784
[59,     4] loss: 0.916
[60,     4] loss: 0.827
[61,     4] loss: 0.872
[62,     4] loss: 0.817
[63,     4] loss: 0.770
[64,     4] loss: 0.762
[65,     4] loss: 0.759
Early stopping applied (best metric=0.37851664423942566)
Finished Training
Total time taken: 33.00510263442993
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.385
[2,     4] loss: 1.391
[3,     4] loss: 1.383
[4,     4] loss: 1.380
[5,     4] loss: 1.384
[6,     4] loss: 1.382
[7,     4] loss: 1.370
[8,     4] loss: 1.353
[9,     4] loss: 1.311
[10,     4] loss: 1.249
[11,     4] loss: 1.175
[12,     4] loss: 1.140
[13,     4] loss: 1.057
[14,     4] loss: 1.089
[15,     4] loss: 1.136
[16,     4] loss: 1.073
[17,     4] loss: 1.096
[18,     4] loss: 1.039
[19,     4] loss: 0.977
[20,     4] loss: 0.919
[21,     4] loss: 0.870
[22,     4] loss: 0.863
[23,     4] loss: 0.819
[24,     4] loss: 0.954
[25,     4] loss: 1.096
[26,     4] loss: 0.881
[27,     4] loss: 0.909
[28,     4] loss: 0.879
[29,     4] loss: 0.946
[30,     4] loss: 1.008
[31,     4] loss: 0.887
[32,     4] loss: 0.898
[33,     4] loss: 0.907
[34,     4] loss: 0.861
[35,     4] loss: 0.851
[36,     4] loss: 0.876
[37,     4] loss: 0.880
[38,     4] loss: 0.887
[39,     4] loss: 0.906
[40,     4] loss: 0.850
[41,     4] loss: 0.837
[42,     4] loss: 0.824
[43,     4] loss: 0.775
[44,     4] loss: 0.769
[45,     4] loss: 0.789
[46,     4] loss: 0.785
[47,     4] loss: 0.782
[48,     4] loss: 0.803
[49,     4] loss: 0.791
[50,     4] loss: 0.839
[51,     4] loss: 0.859
[52,     4] loss: 0.800
[53,     4] loss: 0.832
[54,     4] loss: 0.822
[55,     4] loss: 0.819
[56,     4] loss: 0.939
[57,     4] loss: 0.837
[58,     4] loss: 0.879
[59,     4] loss: 0.873
[60,     4] loss: 0.839
Early stopping applied (best metric=0.472129762172699)
Finished Training
Total time taken: 30.46108865737915
{'Hydroxylation-K Validation Accuracy': 0.8021867612293144, 'Hydroxylation-K Validation Sensitivity': 0.8044444444444444, 'Hydroxylation-K Validation Specificity': 0.8017543859649123, 'Hydroxylation-K Validation Precision': 0.5222524448375842, 'Hydroxylation-K AUC ROC': 0.8499025341130604, 'Hydroxylation-K AUC PR': 0.6216018389573417, 'Hydroxylation-K MCC': 0.5296329618130394, 'Hydroxylation-K F1': 0.6287869357214685, 'Validation Loss (Hydroxylation-K)': 0.3708670934041341, 'Methylation-K Validation Accuracy': 0.7934388298601865, 'Methylation-K Validation Sensitivity': 0.16674114614520158, 'Methylation-K Validation Specificity': 0.861405268501613, 'Methylation-K Validation Precision': 0.11875078586850962, 'Methylation-K AUC ROC': 0.5417471602107842, 'Methylation-K AUC PR': 0.11173409571055899, 'Methylation-K MCC': 0.025435359554623102, 'Methylation-K F1': 0.13167381351764101, 'Validation Loss (Methylation-K)': 0.9111692905426025, 'Validation Loss (total)': 1.2820363918940225, 'TimeToTrain': 38.01851402918498}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025122956754066207,
 'learning_rate_Hydroxylation-K': 0.00041677801597538445,
 'learning_rate_Methylation-K': 0.008970866023657178,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.41887166700830175,
 'loss_weight_Methylation-K': 0.6012017466553621,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1534415496,
 'sample_weights': [0.5869079065564717, 0.963793022245587],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.2015019798008955,
 'weight_decay_Hydroxylation-K': 7.379860052276005,
 'weight_decay_Methylation-K': 2.1035428010760135}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.386
[3,     4] loss: 1.387
[4,     4] loss: 1.382
[5,     4] loss: 1.380
[6,     4] loss: 1.389
[7,     4] loss: 1.385
[8,     4] loss: 1.381
[9,     4] loss: 1.374
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004705089465680473,
 'learning_rate_Hydroxylation-K': 0.0021713721974117627,
 'learning_rate_Methylation-K': 0.0079264436847076,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.10378492922161653,
 'loss_weight_Methylation-K': 0.011138704199417454,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1130636985,
 'sample_weights': [0.41887166700830175, 0.6012017466553621],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.877521764154928,
 'weight_decay_Hydroxylation-K': 8.112507448958983,
 'weight_decay_Methylation-K': 1.7956077690955463}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.390
[3,     4] loss: 1.387
[4,     4] loss: 1.387
[5,     4] loss: 1.385
[6,     4] loss: 1.385
[7,     4] loss: 1.386
[8,     4] loss: 1.386
[9,     4] loss: 1.384
[10,     4] loss: 1.385
[11,     4] loss: 1.387
[12,     4] loss: 1.384
[13,     4] loss: 1.387
[14,     4] loss: 1.388
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.385
[18,     4] loss: 1.383
[19,     4] loss: 1.384
[20,     4] loss: 1.372
[21,     4] loss: 1.363
[22,     4] loss: 1.332
[23,     4] loss: 1.279
[24,     4] loss: 1.264
[25,     4] loss: 1.158
[26,     4] loss: 1.181
[27,     4] loss: 1.154
[28,     4] loss: 1.211
[29,     4] loss: 1.157
[30,     4] loss: 1.068
[31,     4] loss: 1.087
[32,     4] loss: 1.019
[33,     4] loss: 1.069
[34,     4] loss: 0.992
[35,     4] loss: 1.053
[36,     4] loss: 0.952
[37,     4] loss: 0.982
[38,     4] loss: 0.982
[39,     4] loss: 0.901
[40,     4] loss: 0.972
[41,     4] loss: 0.921
[42,     4] loss: 0.961
[43,     4] loss: 0.883
[44,     4] loss: 0.956
[45,     4] loss: 0.867
[46,     4] loss: 0.868
[47,     4] loss: 0.843
[48,     4] loss: 0.836
[49,     4] loss: 0.847
[50,     4] loss: 0.848
[51,     4] loss: 0.823
[52,     4] loss: 0.857
[53,     4] loss: 0.843
[54,     4] loss: 0.814
[55,     4] loss: 0.796
[56,     4] loss: 0.772
[57,     4] loss: 0.749
[58,     4] loss: 0.759
[59,     4] loss: 0.745
[60,     4] loss: 0.740
[61,     4] loss: 0.777
[62,     4] loss: 0.788
[63,     4] loss: 0.793
[64,     4] loss: 0.819
[65,     4] loss: 0.773
[66,     4] loss: 0.765
[67,     4] loss: 0.826
[68,     4] loss: 0.834
[69,     4] loss: 0.780
[70,     4] loss: 0.790
[71,     4] loss: 0.772
[72,     4] loss: 0.754
Early stopping applied (best metric=0.47094643115997314)
Finished Training
Total time taken: 36.30710482597351
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.392
[3,     4] loss: 1.386
[4,     4] loss: 1.386
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.383
[8,     4] loss: 1.383
[9,     4] loss: 1.384
[10,     4] loss: 1.385
[11,     4] loss: 1.384
[12,     4] loss: 1.383
[13,     4] loss: 1.383
[14,     4] loss: 1.375
[15,     4] loss: 1.364
[16,     4] loss: 1.345
[17,     4] loss: 1.303
[18,     4] loss: 1.226
[19,     4] loss: 1.253
[20,     4] loss: 1.202
[21,     4] loss: 1.209
[22,     4] loss: 1.119
[23,     4] loss: 1.142
[24,     4] loss: 1.061
[25,     4] loss: 1.111
[26,     4] loss: 1.048
[27,     4] loss: 1.047
[28,     4] loss: 1.009
[29,     4] loss: 0.986
[30,     4] loss: 0.970
[31,     4] loss: 0.955
[32,     4] loss: 0.934
[33,     4] loss: 0.930
[34,     4] loss: 0.939
[35,     4] loss: 0.967
[36,     4] loss: 0.939
[37,     4] loss: 0.849
[38,     4] loss: 0.910
[39,     4] loss: 0.936
[40,     4] loss: 0.941
[41,     4] loss: 0.895
[42,     4] loss: 0.870
[43,     4] loss: 0.855
[44,     4] loss: 0.878
[45,     4] loss: 0.883
[46,     4] loss: 0.857
[47,     4] loss: 0.834
[48,     4] loss: 0.863
[49,     4] loss: 0.804
[50,     4] loss: 0.828
[51,     4] loss: 0.810
[52,     4] loss: 0.821
[53,     4] loss: 0.794
[54,     4] loss: 0.775
[55,     4] loss: 0.789
[56,     4] loss: 0.808
[57,     4] loss: 0.772
[58,     4] loss: 0.756
[59,     4] loss: 0.741
[60,     4] loss: 0.789
[61,     4] loss: 0.751
[62,     4] loss: 0.728
[63,     4] loss: 0.748
[64,     4] loss: 0.736
[65,     4] loss: 0.731
[66,     4] loss: 0.751
[67,     4] loss: 0.755
[68,     4] loss: 0.726
[69,     4] loss: 0.749
[70,     4] loss: 0.730
Early stopping applied (best metric=0.45006197690963745)
Finished Training
Total time taken: 35.571096658706665
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.390
[3,     4] loss: 1.384
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.384
[7,     4] loss: 1.387
[8,     4] loss: 1.387
[9,     4] loss: 1.386
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.384
[13,     4] loss: 1.386
[14,     4] loss: 1.387
[15,     4] loss: 1.385
[16,     4] loss: 1.385
[17,     4] loss: 1.384
[18,     4] loss: 1.382
[19,     4] loss: 1.379
[20,     4] loss: 1.368
[21,     4] loss: 1.341
[22,     4] loss: 1.314
[23,     4] loss: 1.265
[24,     4] loss: 1.199
[25,     4] loss: 1.173
[26,     4] loss: 1.138
[27,     4] loss: 1.064
[28,     4] loss: 1.044
[29,     4] loss: 0.965
[30,     4] loss: 1.035
[31,     4] loss: 1.003
[32,     4] loss: 0.930
[33,     4] loss: 0.916
[34,     4] loss: 0.999
[35,     4] loss: 0.985
[36,     4] loss: 0.939
[37,     4] loss: 0.928
[38,     4] loss: 0.911
[39,     4] loss: 0.861
[40,     4] loss: 0.906
[41,     4] loss: 0.875
[42,     4] loss: 0.853
[43,     4] loss: 0.815
[44,     4] loss: 0.840
[45,     4] loss: 0.827
[46,     4] loss: 0.858
[47,     4] loss: 0.801
[48,     4] loss: 0.829
[49,     4] loss: 0.812
[50,     4] loss: 0.827
[51,     4] loss: 0.825
[52,     4] loss: 0.887
[53,     4] loss: 0.818
[54,     4] loss: 0.877
[55,     4] loss: 0.869
[56,     4] loss: 0.818
[57,     4] loss: 0.835
[58,     4] loss: 0.828
[59,     4] loss: 0.867
[60,     4] loss: 0.857
[61,     4] loss: 0.790
[62,     4] loss: 0.807
[63,     4] loss: 0.841
[64,     4] loss: 0.793
[65,     4] loss: 0.809
[66,     4] loss: 0.801
[67,     4] loss: 0.840
[68,     4] loss: 0.784
[69,     4] loss: 0.841
[70,     4] loss: 0.781
[71,     4] loss: 0.772
[72,     4] loss: 0.788
[73,     4] loss: 0.759
Early stopping applied (best metric=0.4356762766838074)
Finished Training
Total time taken: 36.76610326766968
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.388
[3,     4] loss: 1.387
[4,     4] loss: 1.386
[5,     4] loss: 1.384
[6,     4] loss: 1.385
[7,     4] loss: 1.383
[8,     4] loss: 1.382
[9,     4] loss: 1.382
[10,     4] loss: 1.382
[11,     4] loss: 1.380
[12,     4] loss: 1.378
[13,     4] loss: 1.373
[14,     4] loss: 1.363
[15,     4] loss: 1.340
[16,     4] loss: 1.298
[17,     4] loss: 1.263
[18,     4] loss: 1.229
[19,     4] loss: 1.183
[20,     4] loss: 1.175
[21,     4] loss: 1.160
[22,     4] loss: 1.127
[23,     4] loss: 1.078
[24,     4] loss: 1.036
[25,     4] loss: 0.991
[26,     4] loss: 1.032
[27,     4] loss: 1.034
[28,     4] loss: 1.055
[29,     4] loss: 1.065
[30,     4] loss: 1.027
[31,     4] loss: 0.971
[32,     4] loss: 0.975
[33,     4] loss: 0.916
[34,     4] loss: 0.970
[35,     4] loss: 0.969
[36,     4] loss: 0.933
[37,     4] loss: 0.879
[38,     4] loss: 0.851
[39,     4] loss: 0.857
[40,     4] loss: 0.859
[41,     4] loss: 0.863
[42,     4] loss: 0.898
[43,     4] loss: 0.833
[44,     4] loss: 0.851
[45,     4] loss: 0.889
[46,     4] loss: 0.828
[47,     4] loss: 0.838
[48,     4] loss: 0.827
[49,     4] loss: 0.906
[50,     4] loss: 0.855
[51,     4] loss: 0.830
[52,     4] loss: 0.772
[53,     4] loss: 0.842
[54,     4] loss: 0.801
[55,     4] loss: 0.820
[56,     4] loss: 0.841
[57,     4] loss: 0.838
[58,     4] loss: 0.804
[59,     4] loss: 0.779
[60,     4] loss: 0.801
[61,     4] loss: 0.835
[62,     4] loss: 0.859
[63,     4] loss: 0.824
[64,     4] loss: 0.828
[65,     4] loss: 0.826
[66,     4] loss: 0.812
[67,     4] loss: 0.867
[68,     4] loss: 0.815
[69,     4] loss: 0.866
[70,     4] loss: 0.827
[71,     4] loss: 0.794
[72,     4] loss: 0.767
[73,     4] loss: 0.794
[74,     4] loss: 0.821
[75,     4] loss: 0.871
[76,     4] loss: 0.872
[77,     4] loss: 0.853
[78,     4] loss: 0.821
[79,     4] loss: 0.823
Early stopping applied (best metric=0.4121183156967163)
Finished Training
Total time taken: 40.186107873916626
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.382
[2,     4] loss: 1.391
[3,     4] loss: 1.389
[4,     4] loss: 1.384
[5,     4] loss: 1.387
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.388
[9,     4] loss: 1.387
[10,     4] loss: 1.385
[11,     4] loss: 1.386
[12,     4] loss: 1.383
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.385
[16,     4] loss: 1.387
[17,     4] loss: 1.386
[18,     4] loss: 1.387
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.387
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.384
[36,     4] loss: 1.379
[37,     4] loss: 1.370
[38,     4] loss: 1.354
[39,     4] loss: 1.331
[40,     4] loss: 1.314
[41,     4] loss: 1.306
[42,     4] loss: 1.181
[43,     4] loss: 1.154
[44,     4] loss: 1.127
[45,     4] loss: 1.119
[46,     4] loss: 1.081
[47,     4] loss: 1.031
[48,     4] loss: 1.037
[49,     4] loss: 0.994
[50,     4] loss: 0.912
[51,     4] loss: 0.956
[52,     4] loss: 0.925
[53,     4] loss: 0.878
[54,     4] loss: 0.870
[55,     4] loss: 0.961
[56,     4] loss: 0.925
[57,     4] loss: 0.862
[58,     4] loss: 0.916
[59,     4] loss: 0.874
[60,     4] loss: 0.844
[61,     4] loss: 0.811
[62,     4] loss: 0.845
[63,     4] loss: 0.821
[64,     4] loss: 0.829
[65,     4] loss: 0.824
[66,     4] loss: 0.833
[67,     4] loss: 0.769
[68,     4] loss: 0.831
[69,     4] loss: 0.793
[70,     4] loss: 0.787
[71,     4] loss: 0.783
[72,     4] loss: 0.806
[73,     4] loss: 0.777
[74,     4] loss: 0.811
[75,     4] loss: 0.774
[76,     4] loss: 0.756
[77,     4] loss: 0.754
[78,     4] loss: 0.736
[79,     4] loss: 0.731
[80,     4] loss: 0.742
[81,     4] loss: 0.749
[82,     4] loss: 0.762
[83,     4] loss: 0.787
[84,     4] loss: 0.761
[85,     4] loss: 0.760
[86,     4] loss: 0.741
[87,     4] loss: 0.761
[88,     4] loss: 0.752
[89,     4] loss: 0.736
[90,     4] loss: 0.769
[91,     4] loss: 0.807
[92,     4] loss: 0.823
[93,     4] loss: 0.866
[94,     4] loss: 0.804
[95,     4] loss: 0.796
[96,     4] loss: 0.770
Early stopping applied (best metric=0.2991090714931488)
Finished Training
Total time taken: 48.5571346282959
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.386
[5,     4] loss: 1.385
[6,     4] loss: 1.390
[7,     4] loss: 1.387
[8,     4] loss: 1.389
[9,     4] loss: 1.386
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.385
[18,     4] loss: 1.385
[19,     4] loss: 1.384
[20,     4] loss: 1.387
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.388
[24,     4] loss: 1.386
[25,     4] loss: 1.387
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.387
[33,     4] loss: 1.386
[34,     4] loss: 1.388
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.387
[44,     4] loss: 1.386
[45,     4] loss: 1.387
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.386
[53,     4] loss: 1.385
[54,     4] loss: 1.382
[55,     4] loss: 1.368
[56,     4] loss: 1.353
[57,     4] loss: 1.301
[58,     4] loss: 1.294
[59,     4] loss: 1.219
[60,     4] loss: 1.223
[61,     4] loss: 1.223
[62,     4] loss: 1.222
[63,     4] loss: 1.160
[64,     4] loss: 1.063
[65,     4] loss: 1.078
[66,     4] loss: 1.112
[67,     4] loss: 1.064
[68,     4] loss: 1.070
[69,     4] loss: 1.095
[70,     4] loss: 1.090
[71,     4] loss: 0.956
[72,     4] loss: 0.945
[73,     4] loss: 0.905
[74,     4] loss: 0.868
[75,     4] loss: 0.845
[76,     4] loss: 0.820
[77,     4] loss: 0.845
[78,     4] loss: 0.838
[79,     4] loss: 0.890
[80,     4] loss: 0.857
[81,     4] loss: 0.887
[82,     4] loss: 0.796
[83,     4] loss: 0.834
[84,     4] loss: 0.816
[85,     4] loss: 0.806
[86,     4] loss: 0.793
[87,     4] loss: 0.788
[88,     4] loss: 0.754
[89,     4] loss: 0.761
[90,     4] loss: 0.753
[91,     4] loss: 0.766
[92,     4] loss: 0.806
[93,     4] loss: 0.804
[94,     4] loss: 0.773
[95,     4] loss: 0.750
[96,     4] loss: 0.788
[97,     4] loss: 0.759
[98,     4] loss: 0.734
[99,     4] loss: 0.730
[100,     4] loss: 0.727
[101,     4] loss: 0.729
[102,     4] loss: 0.746
[103,     4] loss: 0.730
[104,     4] loss: 0.763
[105,     4] loss: 0.774
[106,     4] loss: 0.796
[107,     4] loss: 0.795
[108,     4] loss: 0.800
[109,     4] loss: 0.763
[110,     4] loss: 0.746
[111,     4] loss: 0.757
Early stopping applied (best metric=0.4368351697921753)
Finished Training
Total time taken: 56.3221549987793
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.387
[3,     4] loss: 1.389
[4,     4] loss: 1.386
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.388
[8,     4] loss: 1.385
[9,     4] loss: 1.386
[10,     4] loss: 1.386
[11,     4] loss: 1.387
[12,     4] loss: 1.386
[13,     4] loss: 1.385
[14,     4] loss: 1.387
[15,     4] loss: 1.387
[16,     4] loss: 1.388
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.387
[22,     4] loss: 1.385
[23,     4] loss: 1.387
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.387
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.387
[33,     4] loss: 1.386
[34,     4] loss: 1.387
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.387
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.387
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.386
[52,     4] loss: 1.387
Early stopping applied (best metric=0.5623716115951538)
Finished Training
Total time taken: 26.299068212509155
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.388
[3,     4] loss: 1.388
[4,     4] loss: 1.386
[5,     4] loss: 1.387
[6,     4] loss: 1.385
[7,     4] loss: 1.385
[8,     4] loss: 1.388
[9,     4] loss: 1.388
[10,     4] loss: 1.387
[11,     4] loss: 1.387
[12,     4] loss: 1.386
[13,     4] loss: 1.387
[14,     4] loss: 1.386
[15,     4] loss: 1.387
[16,     4] loss: 1.387
[17,     4] loss: 1.387
[18,     4] loss: 1.386
[19,     4] loss: 1.385
[20,     4] loss: 1.385
[21,     4] loss: 1.387
[22,     4] loss: 1.387
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.385
[29,     4] loss: 1.385
[30,     4] loss: 1.387
[31,     4] loss: 1.384
[32,     4] loss: 1.388
[33,     4] loss: 1.383
[34,     4] loss: 1.389
[35,     4] loss: 1.387
[36,     4] loss: 1.387
[37,     4] loss: 1.386
[38,     4] loss: 1.387
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.387
[42,     4] loss: 1.387
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.385
[48,     4] loss: 1.382
[49,     4] loss: 1.367
[50,     4] loss: 1.330
[51,     4] loss: 1.324
[52,     4] loss: 1.232
[53,     4] loss: 1.154
[54,     4] loss: 1.252
[55,     4] loss: 1.235
[56,     4] loss: 1.194
[57,     4] loss: 1.097
[58,     4] loss: 1.046
[59,     4] loss: 0.983
[60,     4] loss: 1.002
[61,     4] loss: 0.970
[62,     4] loss: 0.933
[63,     4] loss: 0.881
[64,     4] loss: 0.876
[65,     4] loss: 0.885
[66,     4] loss: 0.917
[67,     4] loss: 0.875
[68,     4] loss: 0.879
[69,     4] loss: 0.903
[70,     4] loss: 0.931
[71,     4] loss: 0.955
[72,     4] loss: 0.903
[73,     4] loss: 0.862
[74,     4] loss: 0.852
[75,     4] loss: 0.838
[76,     4] loss: 0.877
[77,     4] loss: 0.852
[78,     4] loss: 0.825
[79,     4] loss: 0.805
[80,     4] loss: 0.815
[81,     4] loss: 0.796
[82,     4] loss: 0.803
[83,     4] loss: 0.804
[84,     4] loss: 0.818
[85,     4] loss: 0.791
[86,     4] loss: 0.809
[87,     4] loss: 0.800
[88,     4] loss: 0.829
[89,     4] loss: 0.803
[90,     4] loss: 0.819
[91,     4] loss: 0.819
[92,     4] loss: 0.811
[93,     4] loss: 0.806
[94,     4] loss: 0.822
[95,     4] loss: 0.763
[96,     4] loss: 0.744
[97,     4] loss: 0.763
[98,     4] loss: 0.766
[99,     4] loss: 0.746
[100,     4] loss: 0.808
[101,     4] loss: 0.813
[102,     4] loss: 0.821
[103,     4] loss: 0.808
[104,     4] loss: 0.784
[105,     4] loss: 0.782
[106,     4] loss: 0.793
Early stopping applied (best metric=0.48769164085388184)
Finished Training
Total time taken: 53.303144693374634
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.389
[3,     4] loss: 1.384
[4,     4] loss: 1.385
[5,     4] loss: 1.389
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.387
[9,     4] loss: 1.386
[10,     4] loss: 1.387
[11,     4] loss: 1.386
[12,     4] loss: 1.385
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.385
[21,     4] loss: 1.385
[22,     4] loss: 1.384
[23,     4] loss: 1.380
[24,     4] loss: 1.371
[25,     4] loss: 1.350
[26,     4] loss: 1.296
[27,     4] loss: 1.293
[28,     4] loss: 1.207
[29,     4] loss: 1.242
[30,     4] loss: 1.225
[31,     4] loss: 1.204
[32,     4] loss: 1.139
[33,     4] loss: 1.102
[34,     4] loss: 1.047
[35,     4] loss: 1.138
[36,     4] loss: 1.048
[37,     4] loss: 1.050
[38,     4] loss: 1.033
[39,     4] loss: 1.039
[40,     4] loss: 1.002
[41,     4] loss: 1.013
[42,     4] loss: 1.008
[43,     4] loss: 0.990
[44,     4] loss: 0.949
[45,     4] loss: 0.961
[46,     4] loss: 0.886
[47,     4] loss: 0.878
[48,     4] loss: 0.834
[49,     4] loss: 0.826
[50,     4] loss: 0.820
[51,     4] loss: 0.794
[52,     4] loss: 0.788
[53,     4] loss: 0.841
[54,     4] loss: 0.824
[55,     4] loss: 0.820
[56,     4] loss: 0.826
[57,     4] loss: 0.834
[58,     4] loss: 0.842
[59,     4] loss: 0.822
[60,     4] loss: 0.820
[61,     4] loss: 0.782
[62,     4] loss: 0.782
[63,     4] loss: 0.770
[64,     4] loss: 0.758
[65,     4] loss: 0.763
[66,     4] loss: 0.776
[67,     4] loss: 0.777
[68,     4] loss: 0.792
[69,     4] loss: 0.761
[70,     4] loss: 0.767
[71,     4] loss: 0.770
[72,     4] loss: 0.775
[73,     4] loss: 0.771
[74,     4] loss: 0.753
[75,     4] loss: 0.793
[76,     4] loss: 0.840
[77,     4] loss: 0.814
[78,     4] loss: 0.892
[79,     4] loss: 0.817
[80,     4] loss: 0.838
[81,     4] loss: 0.796
[82,     4] loss: 0.777
Early stopping applied (best metric=0.40493878722190857)
Finished Training
Total time taken: 41.136114835739136
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.401
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.388
[5,     4] loss: 1.382
[6,     4] loss: 1.394
[7,     4] loss: 1.389
[8,     4] loss: 1.386
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.387
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.387
[16,     4] loss: 1.387
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.386
[29,     4] loss: 1.387
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.385
[43,     4] loss: 1.384
[44,     4] loss: 1.380
[45,     4] loss: 1.366
[46,     4] loss: 1.329
[47,     4] loss: 1.255
[48,     4] loss: 1.298
[49,     4] loss: 1.227
[50,     4] loss: 1.278
[51,     4] loss: 1.240
[52,     4] loss: 1.186
[53,     4] loss: 1.155
[54,     4] loss: 1.116
[55,     4] loss: 1.008
[56,     4] loss: 1.081
[57,     4] loss: 1.048
[58,     4] loss: 1.009
[59,     4] loss: 1.068
[60,     4] loss: 0.947
[61,     4] loss: 0.964
[62,     4] loss: 0.962
[63,     4] loss: 0.977
[64,     4] loss: 0.941
[65,     4] loss: 0.885
[66,     4] loss: 0.970
[67,     4] loss: 0.861
[68,     4] loss: 0.856
[69,     4] loss: 0.845
[70,     4] loss: 0.890
[71,     4] loss: 1.072
[72,     4] loss: 0.925
[73,     4] loss: 0.939
[74,     4] loss: 0.940
[75,     4] loss: 0.936
[76,     4] loss: 0.833
[77,     4] loss: 0.888
[78,     4] loss: 0.910
[79,     4] loss: 0.885
[80,     4] loss: 0.836
[81,     4] loss: 0.860
[82,     4] loss: 0.861
[83,     4] loss: 0.837
[84,     4] loss: 0.868
[85,     4] loss: 0.815
[86,     4] loss: 0.817
[87,     4] loss: 0.823
[88,     4] loss: 0.833
[89,     4] loss: 0.794
[90,     4] loss: 0.791
[91,     4] loss: 0.812
[92,     4] loss: 0.788
[93,     4] loss: 0.793
[94,     4] loss: 0.784
[95,     4] loss: 0.797
[96,     4] loss: 0.804
[97,     4] loss: 0.821
[98,     4] loss: 0.793
[99,     4] loss: 0.838
[100,     4] loss: 0.815
[101,     4] loss: 0.840
[102,     4] loss: 0.824
[103,     4] loss: 0.826
[104,     4] loss: 0.804
[105,     4] loss: 0.810
[106,     4] loss: 0.793
[107,     4] loss: 0.796
Early stopping applied (best metric=0.34067606925964355)
Finished Training
Total time taken: 54.639912366867065
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.388
[3,     4] loss: 1.390
[4,     4] loss: 1.388
[5,     4] loss: 1.384
[6,     4] loss: 1.387
[7,     4] loss: 1.385
[8,     4] loss: 1.386
[9,     4] loss: 1.389
[10,     4] loss: 1.384
[11,     4] loss: 1.386
[12,     4] loss: 1.385
[13,     4] loss: 1.387
[14,     4] loss: 1.387
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.385
[21,     4] loss: 1.386
[22,     4] loss: 1.384
[23,     4] loss: 1.383
[24,     4] loss: 1.374
[25,     4] loss: 1.365
[26,     4] loss: 1.329
[27,     4] loss: 1.342
[28,     4] loss: 1.317
[29,     4] loss: 1.239
[30,     4] loss: 1.175
[31,     4] loss: 1.195
[32,     4] loss: 1.074
[33,     4] loss: 1.092
[34,     4] loss: 1.024
[35,     4] loss: 1.056
[36,     4] loss: 1.103
[37,     4] loss: 1.074
[38,     4] loss: 1.027
[39,     4] loss: 1.007
[40,     4] loss: 0.969
[41,     4] loss: 0.931
[42,     4] loss: 0.937
[43,     4] loss: 0.956
[44,     4] loss: 0.899
[45,     4] loss: 0.980
[46,     4] loss: 0.908
[47,     4] loss: 0.915
[48,     4] loss: 0.850
[49,     4] loss: 0.840
[50,     4] loss: 0.856
[51,     4] loss: 0.836
[52,     4] loss: 0.792
[53,     4] loss: 0.814
[54,     4] loss: 0.762
[55,     4] loss: 0.795
[56,     4] loss: 0.788
[57,     4] loss: 0.750
[58,     4] loss: 0.759
[59,     4] loss: 0.748
[60,     4] loss: 0.765
[61,     4] loss: 0.752
[62,     4] loss: 0.735
[63,     4] loss: 0.761
[64,     4] loss: 0.753
[65,     4] loss: 0.742
[66,     4] loss: 0.731
[67,     4] loss: 0.758
[68,     4] loss: 0.749
[69,     4] loss: 0.723
[70,     4] loss: 0.759
[71,     4] loss: 0.791
[72,     4] loss: 0.741
[73,     4] loss: 0.746
[74,     4] loss: 0.744
[75,     4] loss: 0.741
[76,     4] loss: 0.735
[77,     4] loss: 0.721
[78,     4] loss: 0.711
[79,     4] loss: 0.734
[80,     4] loss: 0.729
[81,     4] loss: 0.740
[82,     4] loss: 0.733
[83,     4] loss: 0.729
Early stopping applied (best metric=0.42446374893188477)
Finished Training
Total time taken: 42.74211549758911
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.394
[3,     4] loss: 1.388
[4,     4] loss: 1.385
[5,     4] loss: 1.387
[6,     4] loss: 1.391
[7,     4] loss: 1.387
[8,     4] loss: 1.386
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.387
[12,     4] loss: 1.386
[13,     4] loss: 1.387
[14,     4] loss: 1.387
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.387
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.387
[28,     4] loss: 1.386
[29,     4] loss: 1.387
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.387
[35,     4] loss: 1.387
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.385
[42,     4] loss: 1.381
[43,     4] loss: 1.371
[44,     4] loss: 1.353
[45,     4] loss: 1.312
[46,     4] loss: 1.252
[47,     4] loss: 1.270
[48,     4] loss: 1.228
[49,     4] loss: 1.177
[50,     4] loss: 1.118
[51,     4] loss: 1.128
[52,     4] loss: 1.207
[53,     4] loss: 1.136
[54,     4] loss: 1.087
[55,     4] loss: 1.065
[56,     4] loss: 1.046
[57,     4] loss: 1.000
[58,     4] loss: 1.061
[59,     4] loss: 0.989
[60,     4] loss: 0.967
[61,     4] loss: 0.950
[62,     4] loss: 0.963
[63,     4] loss: 0.903
[64,     4] loss: 0.909
[65,     4] loss: 0.912
[66,     4] loss: 0.891
[67,     4] loss: 0.965
[68,     4] loss: 0.944
[69,     4] loss: 0.939
[70,     4] loss: 0.919
[71,     4] loss: 0.889
[72,     4] loss: 0.831
[73,     4] loss: 0.832
[74,     4] loss: 0.857
[75,     4] loss: 0.793
[76,     4] loss: 0.837
[77,     4] loss: 0.812
[78,     4] loss: 0.806
[79,     4] loss: 0.823
[80,     4] loss: 0.783
[81,     4] loss: 0.838
[82,     4] loss: 0.796
[83,     4] loss: 0.793
[84,     4] loss: 0.766
[85,     4] loss: 0.764
[86,     4] loss: 0.785
[87,     4] loss: 0.780
[88,     4] loss: 0.843
[89,     4] loss: 0.773
[90,     4] loss: 0.732
[91,     4] loss: 0.760
[92,     4] loss: 0.747
[93,     4] loss: 0.721
[94,     4] loss: 0.715
[95,     4] loss: 0.710
[96,     4] loss: 0.719
[97,     4] loss: 0.744
[98,     4] loss: 0.692
[99,     4] loss: 0.742
[100,     4] loss: 0.724
[101,     4] loss: 0.723
[102,     4] loss: 0.710
[103,     4] loss: 0.705
Early stopping applied (best metric=0.5408036708831787)
Finished Training
Total time taken: 56.04690098762512
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.389
[3,     4] loss: 1.387
[4,     4] loss: 1.387
[5,     4] loss: 1.388
[6,     4] loss: 1.387
[7,     4] loss: 1.388
[8,     4] loss: 1.386
[9,     4] loss: 1.386
[10,     4] loss: 1.387
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.387
[15,     4] loss: 1.386
[16,     4] loss: 1.387
[17,     4] loss: 1.387
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.387
[23,     4] loss: 1.386
[24,     4] loss: 1.386
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.387
[29,     4] loss: 1.386
[30,     4] loss: 1.387
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.386
[38,     4] loss: 1.386
[39,     4] loss: 1.387
[40,     4] loss: 1.387
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.386
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.387
Early stopping applied (best metric=0.5621162056922913)
Finished Training
Total time taken: 25.686068534851074
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.385
[3,     4] loss: 1.389
[4,     4] loss: 1.387
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.387
[8,     4] loss: 1.387
[9,     4] loss: 1.385
[10,     4] loss: 1.387
[11,     4] loss: 1.386
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.387
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.387
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.387
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.385
[29,     4] loss: 1.386
[30,     4] loss: 1.383
[31,     4] loss: 1.379
[32,     4] loss: 1.370
[33,     4] loss: 1.356
[34,     4] loss: 1.339
[35,     4] loss: 1.297
[36,     4] loss: 1.299
[37,     4] loss: 1.208
[38,     4] loss: 1.187
[39,     4] loss: 1.107
[40,     4] loss: 1.107
[41,     4] loss: 1.121
[42,     4] loss: 1.059
[43,     4] loss: 1.036
[44,     4] loss: 0.990
[45,     4] loss: 1.018
[46,     4] loss: 0.931
[47,     4] loss: 0.932
[48,     4] loss: 0.928
[49,     4] loss: 0.916
[50,     4] loss: 0.867
[51,     4] loss: 0.858
[52,     4] loss: 0.834
[53,     4] loss: 0.808
[54,     4] loss: 0.773
[55,     4] loss: 0.867
[56,     4] loss: 0.856
[57,     4] loss: 0.853
[58,     4] loss: 0.856
[59,     4] loss: 0.817
[60,     4] loss: 0.841
[61,     4] loss: 0.795
[62,     4] loss: 0.810
[63,     4] loss: 0.824
[64,     4] loss: 0.840
[65,     4] loss: 0.841
[66,     4] loss: 0.770
[67,     4] loss: 0.784
[68,     4] loss: 0.735
[69,     4] loss: 0.780
[70,     4] loss: 0.800
[71,     4] loss: 0.768
[72,     4] loss: 0.755
[73,     4] loss: 0.762
[74,     4] loss: 0.806
[75,     4] loss: 0.789
[76,     4] loss: 0.776
[77,     4] loss: 0.741
[78,     4] loss: 0.756
[79,     4] loss: 0.761
[80,     4] loss: 0.755
[81,     4] loss: 0.745
[82,     4] loss: 0.723
[83,     4] loss: 0.713
[84,     4] loss: 0.710
[85,     4] loss: 0.733
[86,     4] loss: 0.804
[87,     4] loss: 0.755
[88,     4] loss: 0.747
[89,     4] loss: 0.756
[90,     4] loss: 0.750
[91,     4] loss: 0.717
[92,     4] loss: 0.726
[93,     4] loss: 0.726
[94,     4] loss: 0.795
[95,     4] loss: 0.745
[96,     4] loss: 0.758
[97,     4] loss: 0.740
[98,     4] loss: 0.763
[99,     4] loss: 0.746
[100,     4] loss: 0.712
[101,     4] loss: 0.718
[102,     4] loss: 0.730
[103,     4] loss: 0.732
[104,     4] loss: 0.735
[105,     4] loss: 0.750
[106,     4] loss: 0.710
[107,     4] loss: 0.731
[108,     4] loss: 0.732
[109,     4] loss: 0.718
[110,     4] loss: 0.721
[111,     4] loss: 0.690
[112,     4] loss: 0.725
[113,     4] loss: 0.713
[114,     4] loss: 0.726
[115,     4] loss: 0.693
[116,     4] loss: 0.688
[117,     4] loss: 0.676
[118,     4] loss: 0.690
[119,     4] loss: 0.689
[120,     4] loss: 0.675
[121,     4] loss: 0.686
[122,     4] loss: 0.697
[123,     4] loss: 0.697
[124,     4] loss: 0.692
[125,     4] loss: 0.678
[126,     4] loss: 0.711
[127,     4] loss: 0.704
[128,     4] loss: 0.714
[129,     4] loss: 0.716
[130,     4] loss: 0.703
[131,     4] loss: 0.737
[132,     4] loss: 0.710
[133,     4] loss: 0.733
[134,     4] loss: 0.728
[135,     4] loss: 0.714
[136,     4] loss: 0.686
[137,     4] loss: 0.690
[138,     4] loss: 0.692
[139,     4] loss: 0.919
[140,     4] loss: 0.775
[141,     4] loss: 0.825
[142,     4] loss: 0.841
[143,     4] loss: 0.816
[144,     4] loss: 0.778
[145,     4] loss: 0.753
[146,     4] loss: 0.722
[147,     4] loss: 0.728
[148,     4] loss: 0.710
[149,     4] loss: 0.723
[150,     4] loss: 0.753
[151,     4] loss: 0.721
[152,     4] loss: 0.714
[153,     4] loss: 0.714
[154,     4] loss: 0.707
[155,     4] loss: 0.681
[156,     4] loss: 0.680
[157,     4] loss: 0.696
[158,     4] loss: 0.691
[159,     4] loss: 0.690
[160,     4] loss: 0.678
[161,     4] loss: 0.683
[162,     4] loss: 0.672
[163,     4] loss: 0.709
[164,     4] loss: 0.688
[165,     4] loss: 0.709
[166,     4] loss: 0.723
[167,     4] loss: 0.705
[168,     4] loss: 0.761
[169,     4] loss: 0.766
[170,     4] loss: 0.735
[171,     4] loss: 0.737
[172,     4] loss: 0.757
[173,     4] loss: 0.716
[174,     4] loss: 0.677
[175,     4] loss: 0.680
[176,     4] loss: 0.692
[177,     4] loss: 0.686
[178,     4] loss: 0.728
[179,     4] loss: 0.728
[180,     4] loss: 0.728
[181,     4] loss: 0.904
[182,     4] loss: 0.798
[183,     4] loss: 0.833
[184,     4] loss: 0.756
[185,     4] loss: 0.714
[186,     4] loss: 0.703
[187,     4] loss: 0.680
[188,     4] loss: 0.673
[189,     4] loss: 0.671
[190,     4] loss: 0.691
[191,     4] loss: 0.723
[192,     4] loss: 0.730
[193,     4] loss: 0.708
[194,     4] loss: 0.726
[195,     4] loss: 0.688
[196,     4] loss: 0.710
[197,     4] loss: 0.693
[198,     4] loss: 0.708
[199,     4] loss: 0.675
[200,     4] loss: 0.689
Finished Training
Total time taken: 101.43127250671387
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.390
[2,     4] loss: 1.387
[3,     4] loss: 1.382
[4,     4] loss: 1.389
[5,     4] loss: 1.394
[6,     4] loss: 1.386
[7,     4] loss: 1.388
[8,     4] loss: 1.387
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.387
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.385
[20,     4] loss: 1.384
[21,     4] loss: 1.383
[22,     4] loss: 1.382
[23,     4] loss: 1.372
[24,     4] loss: 1.350
[25,     4] loss: 1.312
[26,     4] loss: 1.263
[27,     4] loss: 1.239
[28,     4] loss: 1.244
[29,     4] loss: 1.168
[30,     4] loss: 1.134
[31,     4] loss: 1.099
[32,     4] loss: 1.164
[33,     4] loss: 1.099
[34,     4] loss: 1.095
[35,     4] loss: 1.029
[36,     4] loss: 1.012
[37,     4] loss: 0.981
[38,     4] loss: 1.011
[39,     4] loss: 0.905
[40,     4] loss: 0.932
[41,     4] loss: 0.895
[42,     4] loss: 0.950
[43,     4] loss: 0.870
[44,     4] loss: 0.926
[45,     4] loss: 0.882
[46,     4] loss: 0.917
[47,     4] loss: 0.952
[48,     4] loss: 0.896
[49,     4] loss: 0.857
[50,     4] loss: 0.851
[51,     4] loss: 0.856
[52,     4] loss: 0.804
[53,     4] loss: 0.861
[54,     4] loss: 0.794
[55,     4] loss: 0.867
[56,     4] loss: 0.841
[57,     4] loss: 0.814
[58,     4] loss: 0.864
[59,     4] loss: 0.809
[60,     4] loss: 0.866
[61,     4] loss: 0.816
[62,     4] loss: 0.835
[63,     4] loss: 0.794
[64,     4] loss: 0.805
[65,     4] loss: 0.802
[66,     4] loss: 0.796
[67,     4] loss: 0.847
[68,     4] loss: 0.811
[69,     4] loss: 0.841
[70,     4] loss: 0.782
[71,     4] loss: 0.811
[72,     4] loss: 0.779
[73,     4] loss: 0.807
[74,     4] loss: 0.795
[75,     4] loss: 0.803
Early stopping applied (best metric=0.47255927324295044)
Finished Training
Total time taken: 38.06459665298462
{'Hydroxylation-K Validation Accuracy': 0.7361997635933806, 'Hydroxylation-K Validation Sensitivity': 0.6962962962962963, 'Hydroxylation-K Validation Specificity': 0.7456140350877193, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.825672514619883, 'Hydroxylation-K AUC PR': 0.5983841479365078, 'Hydroxylation-K MCC': 0.4031189003734069, 'Hydroxylation-K F1': 0.524535238182297, 'Validation Loss (Hydroxylation-K)': 0.43638458649317424, 'Methylation-K Validation Accuracy': 0.7877686667536125, 'Methylation-K Validation Sensitivity': 0.18995552200484156, 'Methylation-K Validation Specificity': 0.8525994908358812, 'Methylation-K Validation Precision': nan, 'Methylation-K AUC ROC': 0.5567322548097565, 'Methylation-K AUC PR': 0.11896016483732517, 'Methylation-K MCC': 0.03883806760478631, 'Methylation-K F1': 0.12827985592442204, 'Validation Loss (Methylation-K)': 0.795224529504776, 'Validation Loss (total)': 1.2316091060638428, 'TimeToTrain': 46.203926436106364}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006129503598787636,
 'learning_rate_Hydroxylation-K': 0.0005471326244275538,
 'learning_rate_Methylation-K': 0.005602750259901366,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4973501126283187,
 'loss_weight_Methylation-K': 0.3379756172717873,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1397643009,
 'sample_weights': [0.10378492922161653, 0.011138704199417454],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.923315515153888,
 'weight_decay_Hydroxylation-K': 8.611024388591893,
 'weight_decay_Methylation-K': 4.959609310129051}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.387
[3,     4] loss: 1.381
[4,     4] loss: 1.385
[5,     4] loss: 1.380
[6,     4] loss: 1.379
[7,     4] loss: 1.371
[8,     4] loss: 1.366
[9,     4] loss: 1.354
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0045125577433779845,
 'learning_rate_Hydroxylation-K': 0.0018806715432747494,
 'learning_rate_Methylation-K': 0.008732621881922548,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.012140139750567297,
 'loss_weight_Methylation-K': 0.10597666045328352,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 345701813,
 'sample_weights': [0.4973501126283187, 0.3379756172717873],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9128930169365375,
 'weight_decay_Hydroxylation-K': 7.736089153578279,
 'weight_decay_Methylation-K': 2.490485661793004}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.404
[2,     4] loss: 1.389
[3,     4] loss: 1.390
[4,     4] loss: 1.387
[5,     4] loss: 1.385
[6,     4] loss: 1.385
[7,     4] loss: 1.386
[8,     4] loss: 1.385
[9,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007484110328999011,
 'learning_rate_Hydroxylation-K': 0.009982747603919987,
 'learning_rate_Methylation-K': 0.005809658823986728,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.23127445857655343,
 'loss_weight_Methylation-K': 0.02627255480959617,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1404525951,
 'sample_weights': [0.012140139750567297, 0.10597666045328352],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9419944828323095,
 'weight_decay_Hydroxylation-K': 1.8955192950787754,
 'weight_decay_Methylation-K': 9.679560209625544}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.389
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004375201011396088,
 'learning_rate_Hydroxylation-K': 0.0032947879849500273,
 'learning_rate_Methylation-K': 0.004001412974761656,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.19405382742752614,
 'loss_weight_Methylation-K': 0.5941162666612227,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 13574512,
 'sample_weights': [0.23127445857655343, 0.02627255480959617],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.709344805118473,
 'weight_decay_Hydroxylation-K': 9.387223990969144,
 'weight_decay_Methylation-K': 3.399921540346693}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.393
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004679567933117744,
 'learning_rate_Hydroxylation-K': 0.0053020849143848095,
 'learning_rate_Methylation-K': 0.003023314543151661,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.38511507852189186,
 'loss_weight_Methylation-K': 0.8031974570891337,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2962580041,
 'sample_weights': [0.19405382742752614, 0.5941162666612227],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.838641010218083,
 'weight_decay_Hydroxylation-K': 9.64301003576233,
 'weight_decay_Methylation-K': 4.8619667052770765}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.393
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005880314091643187,
 'learning_rate_Hydroxylation-K': 0.0034763649620061735,
 'learning_rate_Methylation-K': 0.005193608086427033,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.20348127463051935,
 'loss_weight_Methylation-K': 0.04810416957604934,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1698777414,
 'sample_weights': [0.38511507852189186, 0.8031974570891337],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6815293523283599,
 'weight_decay_Hydroxylation-K': 9.075847265586107,
 'weight_decay_Methylation-K': 3.2517376818398844}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.413
[2,     4] loss: 1.384
[3,     4] loss: 1.389
[4,     4] loss: 1.384
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.385
[8,     4] loss: 1.385
[9,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002085285140217734,
 'learning_rate_Hydroxylation-K': 0.0043935281119818655,
 'learning_rate_Methylation-K': 0.005456261559510723,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7428034564046092,
 'loss_weight_Methylation-K': 0.9341719381709478,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 571592325,
 'sample_weights': [0.20348127463051935, 0.04810416957604934],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.949272004865619,
 'weight_decay_Hydroxylation-K': 4.000121757926924,
 'weight_decay_Methylation-K': 8.012893116646177}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.391
[3,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0026912919244434833,
 'learning_rate_Hydroxylation-K': 0.004321659699814576,
 'learning_rate_Methylation-K': 0.006596984198766545,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6593780839638611,
 'loss_weight_Methylation-K': 0.7492363432723296,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1040959958,
 'sample_weights': [0.7428034564046092, 0.9341719381709478],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.609408986175216,
 'weight_decay_Hydroxylation-K': 1.9255136766488996,
 'weight_decay_Methylation-K': 8.906604211686808}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.376
[2,     4] loss: 1.398
[3,     4] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00034246852315683704,
 'learning_rate_Hydroxylation-K': 0.003238051868544945,
 'learning_rate_Methylation-K': 0.007865195916146164,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6350319410346184,
 'loss_weight_Methylation-K': 0.6346500580313112,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1629946163,
 'sample_weights': [0.6593780839638611, 0.7492363432723296],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.043096361144635,
 'weight_decay_Hydroxylation-K': 5.680077951956734,
 'weight_decay_Methylation-K': 9.08431175955069}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00263921499801565,
 'learning_rate_Hydroxylation-K': 0.0007080669721324269,
 'learning_rate_Methylation-K': 0.0017385168995000186,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3219605374236652,
 'loss_weight_Methylation-K': 0.7742597924775629,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2510337335,
 'sample_weights': [0.6350319410346184, 0.6346500580313112],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.879889121697467,
 'weight_decay_Hydroxylation-K': 6.484650784652556,
 'weight_decay_Methylation-K': 5.133273826485045}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.386
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019584413205304455,
 'learning_rate_Hydroxylation-K': 0.0038147702941168948,
 'learning_rate_Methylation-K': 0.005843838494997751,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.39310455852381965,
 'loss_weight_Methylation-K': 0.9881580896095168,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 433847421,
 'sample_weights': [0.3219605374236652, 0.7742597924775629],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.118670481230986,
 'weight_decay_Hydroxylation-K': 2.031033508238433,
 'weight_decay_Methylation-K': 7.14865034302396}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.383
[6,     4] loss: 1.384
[7,     4] loss: 1.378
[8,     4] loss: 1.375
[9,     4] loss: 1.346
[10,     4] loss: 1.314
[11,     4] loss: 1.288
[12,     4] loss: 1.209
[13,     4] loss: 1.162
[14,     4] loss: 1.112
[15,     4] loss: 1.026
[16,     4] loss: 0.985
[17,     4] loss: 1.030
[18,     4] loss: 0.926
[19,     4] loss: 0.926
[20,     4] loss: 0.904
[21,     4] loss: 0.850
[22,     4] loss: 0.876
[23,     4] loss: 0.851
[24,     4] loss: 0.876
[25,     4] loss: 0.860
[26,     4] loss: 0.836
[27,     4] loss: 0.893
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003687350924784353,
 'learning_rate_Hydroxylation-K': 0.0007036824355494695,
 'learning_rate_Methylation-K': 0.007270494177627416,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3786501677597274,
 'loss_weight_Methylation-K': 0.9822097310505081,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 427262472,
 'sample_weights': [0.39310455852381965, 0.9881580896095168],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.9211581078570648,
 'weight_decay_Hydroxylation-K': 7.183963987706239,
 'weight_decay_Methylation-K': 7.837202974862041}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.384
[5,     4] loss: 1.383
[6,     4] loss: 1.376
[7,     4] loss: 1.372
[8,     4] loss: 1.367
[9,     4] loss: 1.358
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031381685593250396,
 'learning_rate_Hydroxylation-K': 0.004958066473130752,
 'learning_rate_Methylation-K': 0.009210846690937413,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.279694332814128,
 'loss_weight_Methylation-K': 0.8224145007875856,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3967928910,
 'sample_weights': [0.3786501677597274, 0.9822097310505081],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.861019503160969,
 'weight_decay_Hydroxylation-K': 1.6303842341060406,
 'weight_decay_Methylation-K': 9.762109352980358}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.380
[2,     4] loss: 1.391
[3,     4] loss: 1.379
[4,     4] loss: 1.383
[5,     4] loss: 1.370
[6,     4] loss: 1.333
[7,     4] loss: 1.272
[8,     4] loss: 1.221
[9,     4] loss: 1.228
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00897281170038799,
 'learning_rate_Hydroxylation-K': 0.005190895042234772,
 'learning_rate_Methylation-K': 0.006697092201972103,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9295027543432834,
 'loss_weight_Methylation-K': 0.3846344218265841,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3023813105,
 'sample_weights': [0.279694332814128, 0.8224145007875856],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.189907814296986,
 'weight_decay_Hydroxylation-K': 6.820796785172482,
 'weight_decay_Methylation-K': 4.71135209256904}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.385
[3,     4] loss: 1.386
[4,     4] loss: 1.385
[5,     4] loss: 1.389
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.387
[9,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010303637384744854,
 'learning_rate_Hydroxylation-K': 0.004482626911969195,
 'learning_rate_Methylation-K': 0.004264053563920063,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.59942835006569,
 'loss_weight_Methylation-K': 0.7387886773947914,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3185534289,
 'sample_weights': [0.9295027543432834, 0.3846344218265841],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.282476666717256,
 'weight_decay_Hydroxylation-K': 5.236545129695319,
 'weight_decay_Methylation-K': 7.42232830223093}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.386
[3,     4] loss: 1.380
[4,     4] loss: 1.369
[5,     4] loss: 1.356
[6,     4] loss: 1.336
[7,     4] loss: 1.292
[8,     4] loss: 1.223
[9,     4] loss: 1.180
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025989299139542116,
 'learning_rate_Hydroxylation-K': 0.0038325315384925627,
 'learning_rate_Methylation-K': 0.00842086117639524,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5341948880243794,
 'loss_weight_Methylation-K': 0.9139063277628072,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3591759096,
 'sample_weights': [0.59942835006569, 0.7387886773947914],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.488921425358783,
 'weight_decay_Hydroxylation-K': 3.5252094538684373,
 'weight_decay_Methylation-K': 8.486959277417558}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.380
[2,     4] loss: 1.382
[3,     4] loss: 1.384
[4,     4] loss: 1.379
[5,     4] loss: 1.381
[6,     4] loss: 1.371
[7,     4] loss: 1.344
[8,     4] loss: 1.311
[9,     4] loss: 1.271
[10,     4] loss: 1.262
[11,     4] loss: 1.228
[12,     4] loss: 1.184
[13,     4] loss: 1.123
[14,     4] loss: 1.032
[15,     4] loss: 1.096
[16,     4] loss: 0.991
[17,     4] loss: 1.014
[18,     4] loss: 0.975
[19,     4] loss: 1.032
[20,     4] loss: 0.985
[21,     4] loss: 0.898
[22,     4] loss: 0.900
[23,     4] loss: 0.863
[24,     4] loss: 0.840
[25,     4] loss: 0.926
[26,     4] loss: 0.876
[27,     4] loss: 0.855
[28,     4] loss: 0.880
[29,     4] loss: 0.838
[30,     4] loss: 0.858
[31,     4] loss: 0.816
[32,     4] loss: 0.797
[33,     4] loss: 0.828
[34,     4] loss: 0.866
[35,     4] loss: 0.810
[36,     4] loss: 0.795
[37,     4] loss: 0.776
[38,     4] loss: 0.774
[39,     4] loss: 0.752
[40,     4] loss: 0.786
[41,     4] loss: 0.765
[42,     4] loss: 0.789
[43,     4] loss: 0.857
[44,     4] loss: 0.858
[45,     4] loss: 0.848
[46,     4] loss: 0.826
[47,     4] loss: 0.787
[48,     4] loss: 0.750
[49,     4] loss: 0.774
[50,     4] loss: 0.798
[51,     4] loss: 0.811
[52,     4] loss: 0.823
[53,     4] loss: 0.818
[54,     4] loss: 0.896
[55,     4] loss: 0.948
[56,     4] loss: 0.817
[57,     4] loss: 0.780
[58,     4] loss: 0.762
[59,     4] loss: 0.774
[60,     4] loss: 0.850
[61,     4] loss: 0.905
[62,     4] loss: 0.838
[63,     4] loss: 0.805
[64,     4] loss: 0.827
[65,     4] loss: 0.823
[66,     4] loss: 0.793
Early stopping applied (best metric=0.32362663745880127)
Finished Training
Total time taken: 33.27508759498596
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.414
[2,     4] loss: 1.387
[3,     4] loss: 1.390
[4,     4] loss: 1.388
[5,     4] loss: 1.386
[6,     4] loss: 1.387
[7,     4] loss: 1.385
[8,     4] loss: 1.389
[9,     4] loss: 1.385
[10,     4] loss: 1.387
[11,     4] loss: 1.387
[12,     4] loss: 1.383
[13,     4] loss: 1.388
[14,     4] loss: 1.386
[15,     4] loss: 1.384
[16,     4] loss: 1.380
[17,     4] loss: 1.371
[18,     4] loss: 1.334
[19,     4] loss: 1.259
[20,     4] loss: 1.190
[21,     4] loss: 1.185
[22,     4] loss: 1.193
[23,     4] loss: 1.039
[24,     4] loss: 1.043
[25,     4] loss: 1.089
[26,     4] loss: 1.071
[27,     4] loss: 1.015
[28,     4] loss: 0.957
[29,     4] loss: 0.986
[30,     4] loss: 0.975
[31,     4] loss: 0.995
[32,     4] loss: 0.939
[33,     4] loss: 0.913
[34,     4] loss: 0.931
[35,     4] loss: 0.867
[36,     4] loss: 0.874
[37,     4] loss: 0.909
[38,     4] loss: 0.918
[39,     4] loss: 0.952
[40,     4] loss: 0.979
[41,     4] loss: 0.902
[42,     4] loss: 0.905
[43,     4] loss: 0.812
[44,     4] loss: 0.815
[45,     4] loss: 0.777
[46,     4] loss: 0.796
[47,     4] loss: 0.854
[48,     4] loss: 0.793
[49,     4] loss: 0.776
[50,     4] loss: 0.804
[51,     4] loss: 0.830
[52,     4] loss: 0.788
[53,     4] loss: 0.815
[54,     4] loss: 0.793
[55,     4] loss: 0.785
[56,     4] loss: 0.799
[57,     4] loss: 0.913
[58,     4] loss: 0.828
[59,     4] loss: 0.813
[60,     4] loss: 0.787
[61,     4] loss: 0.754
[62,     4] loss: 0.749
[63,     4] loss: 0.783
[64,     4] loss: 0.763
[65,     4] loss: 0.802
[66,     4] loss: 0.792
[67,     4] loss: 0.796
[68,     4] loss: 0.786
[69,     4] loss: 0.765
[70,     4] loss: 0.744
[71,     4] loss: 0.773
[72,     4] loss: 0.816
Early stopping applied (best metric=0.33806878328323364)
Finished Training
Total time taken: 36.271097898483276
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.376
[2,     4] loss: 1.391
[3,     4] loss: 1.386
[4,     4] loss: 1.383
[5,     4] loss: 1.388
[6,     4] loss: 1.387
[7,     4] loss: 1.385
[8,     4] loss: 1.385
[9,     4] loss: 1.379
[10,     4] loss: 1.362
[11,     4] loss: 1.333
[12,     4] loss: 1.300
[13,     4] loss: 1.194
[14,     4] loss: 1.153
[15,     4] loss: 1.181
[16,     4] loss: 1.161
[17,     4] loss: 1.036
[18,     4] loss: 0.952
[19,     4] loss: 1.009
[20,     4] loss: 0.969
[21,     4] loss: 0.964
[22,     4] loss: 0.917
[23,     4] loss: 0.917
[24,     4] loss: 0.905
[25,     4] loss: 0.861
[26,     4] loss: 0.883
[27,     4] loss: 0.881
[28,     4] loss: 0.876
[29,     4] loss: 0.861
[30,     4] loss: 0.898
[31,     4] loss: 0.899
[32,     4] loss: 0.864
[33,     4] loss: 0.851
[34,     4] loss: 0.783
[35,     4] loss: 0.768
[36,     4] loss: 0.769
[37,     4] loss: 0.775
[38,     4] loss: 0.766
[39,     4] loss: 0.750
[40,     4] loss: 0.793
[41,     4] loss: 0.844
[42,     4] loss: 0.879
[43,     4] loss: 0.847
[44,     4] loss: 0.815
[45,     4] loss: 0.796
[46,     4] loss: 0.806
[47,     4] loss: 0.771
[48,     4] loss: 0.744
[49,     4] loss: 0.728
[50,     4] loss: 0.740
[51,     4] loss: 0.728
[52,     4] loss: 0.787
[53,     4] loss: 0.775
[54,     4] loss: 0.756
[55,     4] loss: 0.726
[56,     4] loss: 0.780
[57,     4] loss: 0.794
[58,     4] loss: 0.748
[59,     4] loss: 0.754
[60,     4] loss: 0.746
[61,     4] loss: 0.919
[62,     4] loss: 0.841
[63,     4] loss: 0.813
[64,     4] loss: 0.825
[65,     4] loss: 0.811
[66,     4] loss: 0.806
Early stopping applied (best metric=0.4516157805919647)
Finished Training
Total time taken: 33.412089109420776
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.389
[3,     4] loss: 1.382
[4,     4] loss: 1.388
[5,     4] loss: 1.384
[6,     4] loss: 1.384
[7,     4] loss: 1.376
[8,     4] loss: 1.355
[9,     4] loss: 1.316
[10,     4] loss: 1.235
[11,     4] loss: 1.148
[12,     4] loss: 1.136
[13,     4] loss: 1.252
[14,     4] loss: 1.136
[15,     4] loss: 1.149
[16,     4] loss: 1.053
[17,     4] loss: 1.098
[18,     4] loss: 1.029
[19,     4] loss: 0.930
[20,     4] loss: 1.027
[21,     4] loss: 0.968
[22,     4] loss: 0.941
[23,     4] loss: 0.919
[24,     4] loss: 0.864
[25,     4] loss: 0.851
[26,     4] loss: 0.975
[27,     4] loss: 0.845
[28,     4] loss: 0.891
[29,     4] loss: 0.962
[30,     4] loss: 1.057
[31,     4] loss: 0.935
[32,     4] loss: 0.900
[33,     4] loss: 0.881
[34,     4] loss: 0.824
[35,     4] loss: 0.800
[36,     4] loss: 0.807
[37,     4] loss: 0.814
[38,     4] loss: 0.855
[39,     4] loss: 0.827
[40,     4] loss: 0.875
[41,     4] loss: 0.809
[42,     4] loss: 0.774
[43,     4] loss: 0.770
[44,     4] loss: 0.802
[45,     4] loss: 0.772
[46,     4] loss: 0.740
[47,     4] loss: 0.799
[48,     4] loss: 0.792
[49,     4] loss: 0.775
[50,     4] loss: 0.799
[51,     4] loss: 0.775
[52,     4] loss: 0.734
[53,     4] loss: 0.766
[54,     4] loss: 0.747
[55,     4] loss: 0.760
[56,     4] loss: 0.826
[57,     4] loss: 0.877
[58,     4] loss: 0.815
[59,     4] loss: 0.799
[60,     4] loss: 0.840
[61,     4] loss: 0.787
[62,     4] loss: 0.788
[63,     4] loss: 0.862
[64,     4] loss: 0.829
[65,     4] loss: 0.887
[66,     4] loss: 0.832
[67,     4] loss: 0.807
[68,     4] loss: 0.793
[69,     4] loss: 0.746
[70,     4] loss: 0.753
[71,     4] loss: 0.733
[72,     4] loss: 0.751
[73,     4] loss: 0.729
[74,     4] loss: 0.725
[75,     4] loss: 0.724
[76,     4] loss: 0.729
[77,     4] loss: 0.785
[78,     4] loss: 0.747
[79,     4] loss: 0.959
[80,     4] loss: 0.989
[81,     4] loss: 0.953
[82,     4] loss: 0.992
[83,     4] loss: 0.915
[84,     4] loss: 0.876
[85,     4] loss: 0.845
[86,     4] loss: 0.777
[87,     4] loss: 0.824
[88,     4] loss: 0.778
[89,     4] loss: 0.756
[90,     4] loss: 0.742
[91,     4] loss: 0.765
[92,     4] loss: 0.834
[93,     4] loss: 0.754
[94,     4] loss: 0.761
[95,     4] loss: 0.761
[96,     4] loss: 0.813
[97,     4] loss: 0.866
[98,     4] loss: 0.875
[99,     4] loss: 0.854
[100,     4] loss: 0.812
[101,     4] loss: 0.787
[102,     4] loss: 0.801
[103,     4] loss: 0.796
Early stopping applied (best metric=0.39116522669792175)
Finished Training
Total time taken: 51.74514055252075
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.391
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.388
[5,     4] loss: 1.389
[6,     4] loss: 1.381
[7,     4] loss: 1.393
[8,     4] loss: 1.369
[9,     4] loss: 1.351
[10,     4] loss: 1.313
[11,     4] loss: 1.262
[12,     4] loss: 1.207
[13,     4] loss: 1.110
[14,     4] loss: 1.066
[15,     4] loss: 1.106
[16,     4] loss: 1.131
[17,     4] loss: 1.149
[18,     4] loss: 1.033
[19,     4] loss: 1.044
[20,     4] loss: 0.975
[21,     4] loss: 0.930
[22,     4] loss: 0.951
[23,     4] loss: 1.023
[24,     4] loss: 0.886
[25,     4] loss: 0.934
[26,     4] loss: 0.884
[27,     4] loss: 0.904
[28,     4] loss: 0.923
[29,     4] loss: 0.894
[30,     4] loss: 0.863
[31,     4] loss: 0.803
[32,     4] loss: 0.889
[33,     4] loss: 0.814
[34,     4] loss: 0.850
[35,     4] loss: 0.982
[36,     4] loss: 1.029
[37,     4] loss: 0.922
[38,     4] loss: 0.938
[39,     4] loss: 0.881
[40,     4] loss: 0.786
[41,     4] loss: 0.759
[42,     4] loss: 0.770
[43,     4] loss: 0.765
[44,     4] loss: 0.742
[45,     4] loss: 0.761
[46,     4] loss: 0.768
[47,     4] loss: 0.750
[48,     4] loss: 0.735
[49,     4] loss: 0.758
[50,     4] loss: 0.878
[51,     4] loss: 0.831
[52,     4] loss: 0.827
[53,     4] loss: 0.830
[54,     4] loss: 0.782
[55,     4] loss: 0.815
[56,     4] loss: 0.811
[57,     4] loss: 0.746
[58,     4] loss: 0.735
[59,     4] loss: 0.732
[60,     4] loss: 0.756
[61,     4] loss: 0.754
[62,     4] loss: 0.744
[63,     4] loss: 0.740
[64,     4] loss: 0.761
[65,     4] loss: 0.774
[66,     4] loss: 0.746
[67,     4] loss: 0.872
Early stopping applied (best metric=0.39817923307418823)
Finished Training
Total time taken: 33.85708832740784
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.402
[2,     4] loss: 1.384
[3,     4] loss: 1.387
[4,     4] loss: 1.389
[5,     4] loss: 1.394
[6,     4] loss: 1.387
[7,     4] loss: 1.384
[8,     4] loss: 1.377
[9,     4] loss: 1.372
[10,     4] loss: 1.333
[11,     4] loss: 1.304
[12,     4] loss: 1.243
[13,     4] loss: 1.128
[14,     4] loss: 1.099
[15,     4] loss: 1.082
[16,     4] loss: 1.062
[17,     4] loss: 1.009
[18,     4] loss: 1.027
[19,     4] loss: 1.004
[20,     4] loss: 1.005
[21,     4] loss: 0.943
[22,     4] loss: 0.918
[23,     4] loss: 0.892
[24,     4] loss: 0.863
[25,     4] loss: 0.856
[26,     4] loss: 0.887
[27,     4] loss: 0.843
[28,     4] loss: 0.852
[29,     4] loss: 0.885
[30,     4] loss: 0.821
[31,     4] loss: 0.827
[32,     4] loss: 0.792
[33,     4] loss: 0.960
[34,     4] loss: 0.826
[35,     4] loss: 0.860
[36,     4] loss: 0.888
[37,     4] loss: 0.803
[38,     4] loss: 0.771
[39,     4] loss: 0.769
[40,     4] loss: 0.748
[41,     4] loss: 0.753
[42,     4] loss: 0.780
[43,     4] loss: 0.797
[44,     4] loss: 0.762
[45,     4] loss: 0.755
[46,     4] loss: 0.724
[47,     4] loss: 0.770
[48,     4] loss: 0.810
[49,     4] loss: 0.918
[50,     4] loss: 0.897
[51,     4] loss: 0.878
[52,     4] loss: 0.848
[53,     4] loss: 0.780
[54,     4] loss: 0.794
[55,     4] loss: 0.744
[56,     4] loss: 0.768
[57,     4] loss: 0.766
[58,     4] loss: 0.757
[59,     4] loss: 0.795
[60,     4] loss: 0.762
Early stopping applied (best metric=0.5424959659576416)
Finished Training
Total time taken: 30.349082231521606
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.396
[3,     4] loss: 1.382
[4,     4] loss: 1.377
[5,     4] loss: 1.387
[6,     4] loss: 1.393
[7,     4] loss: 1.387
[8,     4] loss: 1.386
[9,     4] loss: 1.384
[10,     4] loss: 1.386
[11,     4] loss: 1.381
[12,     4] loss: 1.381
[13,     4] loss: 1.369
[14,     4] loss: 1.344
[15,     4] loss: 1.281
[16,     4] loss: 1.232
[17,     4] loss: 1.241
[18,     4] loss: 1.097
[19,     4] loss: 1.113
[20,     4] loss: 1.127
[21,     4] loss: 1.075
[22,     4] loss: 0.997
[23,     4] loss: 0.965
[24,     4] loss: 0.941
[25,     4] loss: 0.939
[26,     4] loss: 0.940
[27,     4] loss: 0.917
[28,     4] loss: 0.940
[29,     4] loss: 0.925
[30,     4] loss: 0.873
[31,     4] loss: 0.859
[32,     4] loss: 0.948
[33,     4] loss: 0.871
[34,     4] loss: 0.895
[35,     4] loss: 0.890
[36,     4] loss: 0.860
[37,     4] loss: 0.892
[38,     4] loss: 0.823
[39,     4] loss: 0.868
[40,     4] loss: 0.837
[41,     4] loss: 0.881
[42,     4] loss: 0.888
[43,     4] loss: 0.816
[44,     4] loss: 0.833
[45,     4] loss: 0.794
[46,     4] loss: 0.796
[47,     4] loss: 0.745
[48,     4] loss: 0.755
[49,     4] loss: 0.758
[50,     4] loss: 0.754
[51,     4] loss: 0.794
[52,     4] loss: 0.826
[53,     4] loss: 0.809
[54,     4] loss: 0.879
[55,     4] loss: 0.829
[56,     4] loss: 0.824
[57,     4] loss: 0.842
[58,     4] loss: 0.825
[59,     4] loss: 0.796
[60,     4] loss: 0.805
[61,     4] loss: 0.854
[62,     4] loss: 0.835
[63,     4] loss: 0.807
[64,     4] loss: 0.785
[65,     4] loss: 0.815
[66,     4] loss: 0.842
[67,     4] loss: 0.839
[68,     4] loss: 0.823
[69,     4] loss: 0.810
[70,     4] loss: 0.793
[71,     4] loss: 0.794
[72,     4] loss: 0.760
[73,     4] loss: 0.744
[74,     4] loss: 0.761
[75,     4] loss: 0.807
[76,     4] loss: 0.764
[77,     4] loss: 0.760
[78,     4] loss: 0.779
[79,     4] loss: 0.798
[80,     4] loss: 0.803
[81,     4] loss: 0.777
[82,     4] loss: 0.833
Early stopping applied (best metric=0.4387736916542053)
Finished Training
Total time taken: 41.31311345100403
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.394
[3,     4] loss: 1.387
[4,     4] loss: 1.380
[5,     4] loss: 1.372
[6,     4] loss: 1.353
[7,     4] loss: 1.328
[8,     4] loss: 1.270
[9,     4] loss: 1.292
[10,     4] loss: 1.298
[11,     4] loss: 1.199
[12,     4] loss: 1.142
[13,     4] loss: 1.085
[14,     4] loss: 1.054
[15,     4] loss: 1.147
[16,     4] loss: 1.117
[17,     4] loss: 1.028
[18,     4] loss: 0.999
[19,     4] loss: 1.038
[20,     4] loss: 1.003
[21,     4] loss: 0.960
[22,     4] loss: 0.951
[23,     4] loss: 0.990
[24,     4] loss: 1.067
[25,     4] loss: 1.042
[26,     4] loss: 0.997
[27,     4] loss: 1.006
[28,     4] loss: 0.928
[29,     4] loss: 0.891
[30,     4] loss: 0.812
[31,     4] loss: 0.811
[32,     4] loss: 0.814
[33,     4] loss: 0.795
[34,     4] loss: 0.774
[35,     4] loss: 0.918
[36,     4] loss: 0.816
[37,     4] loss: 0.803
[38,     4] loss: 0.768
[39,     4] loss: 0.809
[40,     4] loss: 0.768
[41,     4] loss: 0.792
[42,     4] loss: 0.789
[43,     4] loss: 0.871
[44,     4] loss: 0.766
[45,     4] loss: 0.807
[46,     4] loss: 0.866
[47,     4] loss: 0.770
[48,     4] loss: 0.809
[49,     4] loss: 0.777
[50,     4] loss: 0.756
[51,     4] loss: 0.766
[52,     4] loss: 0.835
[53,     4] loss: 0.803
[54,     4] loss: 0.770
[55,     4] loss: 0.759
[56,     4] loss: 0.885
[57,     4] loss: 0.780
[58,     4] loss: 0.827
[59,     4] loss: 0.762
[60,     4] loss: 0.791
[61,     4] loss: 0.973
[62,     4] loss: 0.835
[63,     4] loss: 0.879
[64,     4] loss: 0.820
[65,     4] loss: 0.811
[66,     4] loss: 0.778
[67,     4] loss: 0.758
[68,     4] loss: 0.789
[69,     4] loss: 0.826
[70,     4] loss: 0.828
[71,     4] loss: 0.810
[72,     4] loss: 0.792
[73,     4] loss: 0.751
[74,     4] loss: 0.781
[75,     4] loss: 0.824
[76,     4] loss: 0.772
Early stopping applied (best metric=0.410764217376709)
Finished Training
Total time taken: 38.00962209701538
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.387
[3,     4] loss: 1.387
[4,     4] loss: 1.390
[5,     4] loss: 1.390
[6,     4] loss: 1.386
[7,     4] loss: 1.385
[8,     4] loss: 1.385
[9,     4] loss: 1.383
[10,     4] loss: 1.380
[11,     4] loss: 1.369
[12,     4] loss: 1.347
[13,     4] loss: 1.278
[14,     4] loss: 1.175
[15,     4] loss: 1.227
[16,     4] loss: 1.157
[17,     4] loss: 1.138
[18,     4] loss: 1.108
[19,     4] loss: 1.075
[20,     4] loss: 0.992
[21,     4] loss: 0.977
[22,     4] loss: 0.893
[23,     4] loss: 0.915
[24,     4] loss: 0.927
[25,     4] loss: 0.964
[26,     4] loss: 0.949
[27,     4] loss: 0.948
[28,     4] loss: 0.895
[29,     4] loss: 0.828
[30,     4] loss: 0.839
[31,     4] loss: 0.822
[32,     4] loss: 0.815
[33,     4] loss: 0.772
[34,     4] loss: 0.753
[35,     4] loss: 0.789
[36,     4] loss: 0.899
[37,     4] loss: 0.871
[38,     4] loss: 0.876
[39,     4] loss: 0.845
[40,     4] loss: 0.853
[41,     4] loss: 0.780
[42,     4] loss: 0.781
[43,     4] loss: 0.765
[44,     4] loss: 0.761
[45,     4] loss: 0.749
[46,     4] loss: 0.744
[47,     4] loss: 0.741
[48,     4] loss: 0.749
[49,     4] loss: 0.749
[50,     4] loss: 0.748
[51,     4] loss: 0.819
[52,     4] loss: 0.823
[53,     4] loss: 0.763
[54,     4] loss: 0.761
[55,     4] loss: 0.828
[56,     4] loss: 0.784
[57,     4] loss: 0.744
[58,     4] loss: 0.818
[59,     4] loss: 0.744
[60,     4] loss: 0.776
[61,     4] loss: 0.770
[62,     4] loss: 0.788
[63,     4] loss: 0.771
[64,     4] loss: 0.858
[65,     4] loss: 0.863
[66,     4] loss: 0.978
[67,     4] loss: 0.892
Early stopping applied (best metric=0.4268345832824707)
Finished Training
Total time taken: 33.57408952713013
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.385
[2,     4] loss: 1.389
[3,     4] loss: 1.381
[4,     4] loss: 1.378
[5,     4] loss: 1.372
[6,     4] loss: 1.379
[7,     4] loss: 1.357
[8,     4] loss: 1.305
[9,     4] loss: 1.285
[10,     4] loss: 1.205
[11,     4] loss: 1.184
[12,     4] loss: 1.167
[13,     4] loss: 1.119
[14,     4] loss: 0.990
[15,     4] loss: 0.960
[16,     4] loss: 1.018
[17,     4] loss: 1.058
[18,     4] loss: 1.022
[19,     4] loss: 0.986
[20,     4] loss: 1.072
[21,     4] loss: 1.063
[22,     4] loss: 1.019
[23,     4] loss: 0.996
[24,     4] loss: 0.967
[25,     4] loss: 0.878
[26,     4] loss: 0.866
[27,     4] loss: 0.789
[28,     4] loss: 0.781
[29,     4] loss: 0.831
[30,     4] loss: 0.815
[31,     4] loss: 0.902
[32,     4] loss: 0.943
[33,     4] loss: 0.944
[34,     4] loss: 0.879
[35,     4] loss: 0.886
[36,     4] loss: 0.822
[37,     4] loss: 0.817
[38,     4] loss: 0.804
[39,     4] loss: 0.785
[40,     4] loss: 0.781
[41,     4] loss: 0.747
[42,     4] loss: 0.858
[43,     4] loss: 0.913
[44,     4] loss: 0.959
[45,     4] loss: 0.866
[46,     4] loss: 0.834
[47,     4] loss: 0.828
[48,     4] loss: 0.817
[49,     4] loss: 0.772
[50,     4] loss: 0.773
[51,     4] loss: 0.779
[52,     4] loss: 0.750
[53,     4] loss: 0.756
[54,     4] loss: 0.778
[55,     4] loss: 0.900
[56,     4] loss: 0.798
[57,     4] loss: 0.828
[58,     4] loss: 0.822
[59,     4] loss: 0.798
[60,     4] loss: 0.771
[61,     4] loss: 0.765
[62,     4] loss: 0.752
[63,     4] loss: 0.789
[64,     4] loss: 0.829
[65,     4] loss: 0.799
[66,     4] loss: 0.769
[67,     4] loss: 0.746
[68,     4] loss: 0.760
[69,     4] loss: 0.830
[70,     4] loss: 0.778
[71,     4] loss: 0.834
[72,     4] loss: 0.811
[73,     4] loss: 0.948
[74,     4] loss: 0.873
[75,     4] loss: 0.792
[76,     4] loss: 0.813
[77,     4] loss: 0.797
[78,     4] loss: 0.898
[79,     4] loss: 0.868
[80,     4] loss: 0.813
[81,     4] loss: 0.825
[82,     4] loss: 0.799
[83,     4] loss: 0.757
[84,     4] loss: 0.746
[85,     4] loss: 0.748
[86,     4] loss: 0.775
[87,     4] loss: 0.761
[88,     4] loss: 0.765
[89,     4] loss: 0.756
[90,     4] loss: 0.811
[91,     4] loss: 0.840
[92,     4] loss: 0.949
[93,     4] loss: 0.837
[94,     4] loss: 0.780
[95,     4] loss: 0.801
[96,     4] loss: 0.840
[97,     4] loss: 0.791
[98,     4] loss: 0.779
[99,     4] loss: 0.749
[100,     4] loss: 0.804
[101,     4] loss: 0.798
[102,     4] loss: 0.785
[103,     4] loss: 0.774
[104,     4] loss: 0.812
[105,     4] loss: 0.833
[106,     4] loss: 0.806
[107,     4] loss: 0.784
[108,     4] loss: 0.766
[109,     4] loss: 0.730
[110,     4] loss: 0.730
Early stopping applied (best metric=0.39444196224212646)
Finished Training
Total time taken: 55.60015273094177
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.388
[5,     4] loss: 1.388
[6,     4] loss: 1.386
[7,     4] loss: 1.385
[8,     4] loss: 1.387
[9,     4] loss: 1.388
[10,     4] loss: 1.386
[11,     4] loss: 1.384
[12,     4] loss: 1.383
[13,     4] loss: 1.375
[14,     4] loss: 1.361
[15,     4] loss: 1.313
[16,     4] loss: 1.246
[17,     4] loss: 1.218
[18,     4] loss: 1.162
[19,     4] loss: 1.154
[20,     4] loss: 1.173
[21,     4] loss: 1.164
[22,     4] loss: 1.104
[23,     4] loss: 1.094
[24,     4] loss: 1.073
[25,     4] loss: 1.143
[26,     4] loss: 1.067
[27,     4] loss: 0.974
[28,     4] loss: 1.043
[29,     4] loss: 0.936
[30,     4] loss: 0.993
[31,     4] loss: 1.022
[32,     4] loss: 1.026
[33,     4] loss: 1.028
[34,     4] loss: 0.960
[35,     4] loss: 0.873
[36,     4] loss: 0.860
[37,     4] loss: 0.839
[38,     4] loss: 0.858
[39,     4] loss: 0.785
[40,     4] loss: 0.801
[41,     4] loss: 0.826
[42,     4] loss: 0.772
[43,     4] loss: 0.744
[44,     4] loss: 0.751
[45,     4] loss: 0.771
[46,     4] loss: 0.831
[47,     4] loss: 0.816
[48,     4] loss: 0.979
[49,     4] loss: 0.841
[50,     4] loss: 0.832
[51,     4] loss: 0.801
[52,     4] loss: 0.799
[53,     4] loss: 0.836
[54,     4] loss: 0.873
[55,     4] loss: 0.917
[56,     4] loss: 0.899
[57,     4] loss: 0.796
[58,     4] loss: 0.763
[59,     4] loss: 0.747
[60,     4] loss: 0.751
[61,     4] loss: 0.745
[62,     4] loss: 0.766
[63,     4] loss: 0.741
[64,     4] loss: 0.744
[65,     4] loss: 0.748
[66,     4] loss: 0.742
[67,     4] loss: 0.751
[68,     4] loss: 0.764
[69,     4] loss: 0.748
[70,     4] loss: 0.747
[71,     4] loss: 0.815
[72,     4] loss: 0.946
[73,     4] loss: 1.026
[74,     4] loss: 0.980
[75,     4] loss: 0.894
[76,     4] loss: 1.059
[77,     4] loss: 0.913
[78,     4] loss: 0.888
[79,     4] loss: 0.866
[80,     4] loss: 0.809
[81,     4] loss: 0.787
[82,     4] loss: 0.775
[83,     4] loss: 0.769
[84,     4] loss: 0.767
[85,     4] loss: 0.756
[86,     4] loss: 0.734
[87,     4] loss: 0.801
[88,     4] loss: 0.801
[89,     4] loss: 0.789
[90,     4] loss: 0.933
[91,     4] loss: 0.824
[92,     4] loss: 0.850
[93,     4] loss: 0.782
[94,     4] loss: 0.817
[95,     4] loss: 0.801
[96,     4] loss: 0.783
[97,     4] loss: 0.767
[98,     4] loss: 0.752
[99,     4] loss: 0.824
[100,     4] loss: 0.836
[101,     4] loss: 0.788
[102,     4] loss: 0.759
[103,     4] loss: 0.757
[104,     4] loss: 0.759
[105,     4] loss: 0.754
[106,     4] loss: 0.765
[107,     4] loss: 0.736
[108,     4] loss: 0.773
[109,     4] loss: 0.755
[110,     4] loss: 0.747
[111,     4] loss: 0.750
[112,     4] loss: 0.791
[113,     4] loss: 0.846
[114,     4] loss: 0.815
[115,     4] loss: 0.795
[116,     4] loss: 0.844
[117,     4] loss: 0.885
[118,     4] loss: 0.807
[119,     4] loss: 0.783
[120,     4] loss: 0.792
[121,     4] loss: 0.765
[122,     4] loss: 0.771
[123,     4] loss: 0.738
[124,     4] loss: 0.745
[125,     4] loss: 0.745
[126,     4] loss: 0.740
[127,     4] loss: 0.759
[128,     4] loss: 0.813
[129,     4] loss: 0.775
[130,     4] loss: 0.783
[131,     4] loss: 0.845
[132,     4] loss: 0.766
[133,     4] loss: 0.739
[134,     4] loss: 0.857
[135,     4] loss: 0.851
[136,     4] loss: 0.798
[137,     4] loss: 0.815
[138,     4] loss: 0.867
[139,     4] loss: 0.805
[140,     4] loss: 0.839
[141,     4] loss: 0.818
[142,     4] loss: 0.842
[143,     4] loss: 0.788
[144,     4] loss: 0.742
[145,     4] loss: 0.857
[146,     4] loss: 0.822
[147,     4] loss: 0.872
[148,     4] loss: 0.809
[149,     4] loss: 0.787
[150,     4] loss: 0.775
[151,     4] loss: 0.731
[152,     4] loss: 0.747
[153,     4] loss: 0.744
[154,     4] loss: 0.747
[155,     4] loss: 0.741
[156,     4] loss: 0.768
[157,     4] loss: 0.865
[158,     4] loss: 1.012
[159,     4] loss: 0.959
[160,     4] loss: 0.936
[161,     4] loss: 0.879
[162,     4] loss: 0.796
[163,     4] loss: 0.812
[164,     4] loss: 0.773
[165,     4] loss: 0.761
[166,     4] loss: 0.783
[167,     4] loss: 0.734
[168,     4] loss: 0.751
[169,     4] loss: 0.753
[170,     4] loss: 0.734
[171,     4] loss: 0.736
[172,     4] loss: 0.735
[173,     4] loss: 0.738
[174,     4] loss: 0.750
[175,     4] loss: 0.741
[176,     4] loss: 0.791
[177,     4] loss: 0.890
[178,     4] loss: 0.853
[179,     4] loss: 0.777
[180,     4] loss: 0.802
[181,     4] loss: 0.799
[182,     4] loss: 0.767
[183,     4] loss: 0.753
[184,     4] loss: 0.780
[185,     4] loss: 0.778
[186,     4] loss: 0.767
[187,     4] loss: 0.773
[188,     4] loss: 0.823
[189,     4] loss: 0.806
[190,     4] loss: 0.813
[191,     4] loss: 0.889
[192,     4] loss: 0.826
Early stopping applied (best metric=0.29295212030410767)
Finished Training
Total time taken: 97.17326259613037
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.389
[3,     4] loss: 1.395
[4,     4] loss: 1.386
[5,     4] loss: 1.381
[6,     4] loss: 1.386
[7,     4] loss: 1.382
[8,     4] loss: 1.377
[9,     4] loss: 1.374
[10,     4] loss: 1.378
[11,     4] loss: 1.330
[12,     4] loss: 1.298
[13,     4] loss: 1.270
[14,     4] loss: 1.186
[15,     4] loss: 1.166
[16,     4] loss: 1.167
[17,     4] loss: 1.069
[18,     4] loss: 1.038
[19,     4] loss: 1.022
[20,     4] loss: 1.009
[21,     4] loss: 0.951
[22,     4] loss: 0.947
[23,     4] loss: 0.999
[24,     4] loss: 0.988
[25,     4] loss: 0.941
[26,     4] loss: 1.084
[27,     4] loss: 1.001
[28,     4] loss: 0.953
[29,     4] loss: 0.955
[30,     4] loss: 0.895
[31,     4] loss: 0.837
[32,     4] loss: 0.869
[33,     4] loss: 0.895
[34,     4] loss: 0.858
[35,     4] loss: 0.892
[36,     4] loss: 0.878
[37,     4] loss: 0.899
[38,     4] loss: 0.845
[39,     4] loss: 0.793
[40,     4] loss: 0.772
[41,     4] loss: 0.775
[42,     4] loss: 0.791
[43,     4] loss: 0.736
[44,     4] loss: 0.768
[45,     4] loss: 0.762
[46,     4] loss: 0.757
[47,     4] loss: 0.753
[48,     4] loss: 0.755
[49,     4] loss: 0.790
[50,     4] loss: 0.795
[51,     4] loss: 0.789
[52,     4] loss: 0.797
[53,     4] loss: 0.752
[54,     4] loss: 0.771
[55,     4] loss: 0.793
[56,     4] loss: 0.913
[57,     4] loss: 0.945
[58,     4] loss: 0.949
[59,     4] loss: 0.983
[60,     4] loss: 0.863
[61,     4] loss: 0.800
[62,     4] loss: 0.909
[63,     4] loss: 0.880
[64,     4] loss: 0.855
[65,     4] loss: 0.793
[66,     4] loss: 0.795
[67,     4] loss: 0.794
[68,     4] loss: 0.787
Early stopping applied (best metric=0.27486222982406616)
Finished Training
Total time taken: 34.36409139633179
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.381
[3,     4] loss: 1.379
[4,     4] loss: 1.379
[5,     4] loss: 1.359
[6,     4] loss: 1.311
[7,     4] loss: 1.267
[8,     4] loss: 1.197
[9,     4] loss: 1.160
[10,     4] loss: 1.098
[11,     4] loss: 1.050
[12,     4] loss: 1.067
[13,     4] loss: 1.094
[14,     4] loss: 1.097
[15,     4] loss: 1.031
[16,     4] loss: 0.979
[17,     4] loss: 0.951
[18,     4] loss: 0.902
[19,     4] loss: 0.943
[20,     4] loss: 0.949
[21,     4] loss: 0.852
[22,     4] loss: 0.905
[23,     4] loss: 0.831
[24,     4] loss: 0.832
[25,     4] loss: 0.871
[26,     4] loss: 0.981
[27,     4] loss: 0.977
[28,     4] loss: 1.019
[29,     4] loss: 1.017
[30,     4] loss: 0.921
[31,     4] loss: 0.881
[32,     4] loss: 0.839
[33,     4] loss: 0.896
[34,     4] loss: 0.780
[35,     4] loss: 0.775
[36,     4] loss: 0.773
[37,     4] loss: 0.831
[38,     4] loss: 0.761
[39,     4] loss: 0.812
[40,     4] loss: 0.810
[41,     4] loss: 0.785
[42,     4] loss: 0.778
[43,     4] loss: 0.762
[44,     4] loss: 0.828
[45,     4] loss: 0.892
[46,     4] loss: 0.898
[47,     4] loss: 0.868
[48,     4] loss: 0.790
[49,     4] loss: 0.732
[50,     4] loss: 0.744
[51,     4] loss: 0.738
[52,     4] loss: 0.730
[53,     4] loss: 0.741
[54,     4] loss: 0.761
[55,     4] loss: 0.834
[56,     4] loss: 0.833
Early stopping applied (best metric=0.5043380260467529)
Finished Training
Total time taken: 28.263074159622192
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.392
[3,     4] loss: 1.386
[4,     4] loss: 1.387
[5,     4] loss: 1.385
[6,     4] loss: 1.385
[7,     4] loss: 1.379
[8,     4] loss: 1.378
[9,     4] loss: 1.356
[10,     4] loss: 1.317
[11,     4] loss: 1.247
[12,     4] loss: 1.191
[13,     4] loss: 1.146
[14,     4] loss: 1.081
[15,     4] loss: 1.053
[16,     4] loss: 1.113
[17,     4] loss: 0.997
[18,     4] loss: 0.948
[19,     4] loss: 0.946
[20,     4] loss: 0.899
[21,     4] loss: 0.946
[22,     4] loss: 0.847
[23,     4] loss: 0.860
[24,     4] loss: 0.862
[25,     4] loss: 0.839
[26,     4] loss: 0.993
[27,     4] loss: 1.007
[28,     4] loss: 0.919
[29,     4] loss: 0.926
[30,     4] loss: 0.886
[31,     4] loss: 0.792
[32,     4] loss: 0.756
[33,     4] loss: 0.760
[34,     4] loss: 0.748
[35,     4] loss: 0.772
[36,     4] loss: 0.753
[37,     4] loss: 0.773
[38,     4] loss: 0.766
[39,     4] loss: 0.758
[40,     4] loss: 0.749
[41,     4] loss: 0.753
[42,     4] loss: 0.776
[43,     4] loss: 0.775
[44,     4] loss: 0.879
[45,     4] loss: 0.800
[46,     4] loss: 0.792
[47,     4] loss: 0.805
[48,     4] loss: 0.792
[49,     4] loss: 0.838
[50,     4] loss: 0.875
[51,     4] loss: 0.757
[52,     4] loss: 0.775
[53,     4] loss: 0.749
[54,     4] loss: 0.782
[55,     4] loss: 0.773
[56,     4] loss: 0.736
[57,     4] loss: 0.754
[58,     4] loss: 0.739
[59,     4] loss: 0.778
[60,     4] loss: 0.850
[61,     4] loss: 0.857
[62,     4] loss: 0.850
[63,     4] loss: 0.857
Early stopping applied (best metric=0.4285143315792084)
Finished Training
Total time taken: 31.44308567047119
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.397
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.378
[5,     4] loss: 1.389
[6,     4] loss: 1.375
[7,     4] loss: 1.372
[8,     4] loss: 1.358
[9,     4] loss: 1.322
[10,     4] loss: 1.288
[11,     4] loss: 1.254
[12,     4] loss: 1.237
[13,     4] loss: 1.194
[14,     4] loss: 1.244
[15,     4] loss: 1.196
[16,     4] loss: 1.155
[17,     4] loss: 1.175
[18,     4] loss: 1.073
[19,     4] loss: 1.044
[20,     4] loss: 0.983
[21,     4] loss: 0.970
[22,     4] loss: 0.950
[23,     4] loss: 0.977
[24,     4] loss: 0.941
[25,     4] loss: 0.914
[26,     4] loss: 0.910
[27,     4] loss: 0.899
[28,     4] loss: 0.908
[29,     4] loss: 0.891
[30,     4] loss: 0.832
[31,     4] loss: 0.938
[32,     4] loss: 0.901
[33,     4] loss: 0.892
[34,     4] loss: 0.803
[35,     4] loss: 0.851
[36,     4] loss: 0.869
[37,     4] loss: 0.842
[38,     4] loss: 0.813
[39,     4] loss: 0.794
[40,     4] loss: 0.789
[41,     4] loss: 0.839
[42,     4] loss: 0.797
[43,     4] loss: 0.790
[44,     4] loss: 0.771
[45,     4] loss: 0.792
[46,     4] loss: 0.857
[47,     4] loss: 0.834
[48,     4] loss: 0.910
[49,     4] loss: 0.885
[50,     4] loss: 0.826
[51,     4] loss: 0.918
[52,     4] loss: 0.859
[53,     4] loss: 0.854
[54,     4] loss: 0.802
[55,     4] loss: 0.768
[56,     4] loss: 0.750
[57,     4] loss: 0.758
[58,     4] loss: 0.756
[59,     4] loss: 0.784
[60,     4] loss: 0.786
[61,     4] loss: 0.770
[62,     4] loss: 0.752
[63,     4] loss: 0.756
[64,     4] loss: 0.787
[65,     4] loss: 0.795
[66,     4] loss: 0.781
[67,     4] loss: 0.771
[68,     4] loss: 0.812
[69,     4] loss: 0.783
[70,     4] loss: 0.754
[71,     4] loss: 0.839
[72,     4] loss: 0.816
[73,     4] loss: 0.809
[74,     4] loss: 0.780
[75,     4] loss: 0.792
[76,     4] loss: 0.875
[77,     4] loss: 0.864
[78,     4] loss: 0.822
[79,     4] loss: 0.868
[80,     4] loss: 0.778
[81,     4] loss: 0.760
[82,     4] loss: 0.819
[83,     4] loss: 0.788
[84,     4] loss: 0.775
[85,     4] loss: 0.755
[86,     4] loss: 0.731
[87,     4] loss: 0.743
[88,     4] loss: 0.915
[89,     4] loss: 0.882
[90,     4] loss: 0.874
[91,     4] loss: 0.878
[92,     4] loss: 0.808
[93,     4] loss: 0.764
[94,     4] loss: 0.815
[95,     4] loss: 0.784
[96,     4] loss: 0.781
[97,     4] loss: 0.798
[98,     4] loss: 0.773
[99,     4] loss: 0.868
[100,     4] loss: 0.817
[101,     4] loss: 0.790
[102,     4] loss: 0.771
[103,     4] loss: 0.929
[104,     4] loss: 0.928
[105,     4] loss: 0.903
[106,     4] loss: 0.841
[107,     4] loss: 0.787
[108,     4] loss: 0.814
[109,     4] loss: 0.819
[110,     4] loss: 0.761
[111,     4] loss: 0.780
[112,     4] loss: 0.743
[113,     4] loss: 0.769
[114,     4] loss: 0.864
[115,     4] loss: 0.795
[116,     4] loss: 0.806
[117,     4] loss: 0.906
[118,     4] loss: 0.811
[119,     4] loss: 0.817
[120,     4] loss: 0.762
[121,     4] loss: 0.752
[122,     4] loss: 0.743
[123,     4] loss: 0.912
[124,     4] loss: 0.888
Early stopping applied (best metric=0.2860073149204254)
Finished Training
Total time taken: 62.60216665267944
{'Hydroxylation-K Validation Accuracy': 0.7787529550827423, 'Hydroxylation-K Validation Sensitivity': 0.7703703703703704, 'Hydroxylation-K Validation Specificity': 0.7807017543859649, 'Hydroxylation-K Validation Precision': 0.48894675414025257, 'Hydroxylation-K AUC ROC': 0.8491228070175438, 'Hydroxylation-K AUC PR': 0.6306053005562767, 'Hydroxylation-K MCC': 0.4799977593591316, 'Hydroxylation-K F1': 0.5919042462769021, 'Validation Loss (Hydroxylation-K)': 0.3935093402862549, 'Methylation-K Validation Accuracy': 0.7888926603028041, 'Methylation-K Validation Sensitivity': 0.17896836214267908, 'Methylation-K Validation Specificity': 0.8550397529705462, 'Methylation-K Validation Precision': 0.1224654178265402, 'Methylation-K AUC ROC': 0.5411818770995671, 'Methylation-K AUC PR': 0.11299265669232161, 'Methylation-K MCC': 0.02946188521612211, 'Methylation-K F1': 0.13115405827374882, 'Validation Loss (Methylation-K)': 1.0251781225204468, 'Validation Loss (total)': 1.4186874628067017, 'TimeToTrain': 42.7501495997111}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015247268163528734,
 'learning_rate_Hydroxylation-K': 0.0009525085295573527,
 'learning_rate_Methylation-K': 0.004468707383099775,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.08432452787280609,
 'loss_weight_Methylation-K': 0.1422909518992446,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 835293360,
 'sample_weights': [0.5341948880243794, 0.9139063277628072],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.111169591447875,
 'weight_decay_Hydroxylation-K': 6.334494902951656,
 'weight_decay_Methylation-K': 5.760694335002216}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.400
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017590850632246563,
 'learning_rate_Hydroxylation-K': 0.0017468535474977247,
 'learning_rate_Methylation-K': 0.008380778702435768,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6240124707490491,
 'loss_weight_Methylation-K': 0.9634848947918508,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3243469409,
 'sample_weights': [0.08432452787280609, 0.1422909518992446],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.494406086845919,
 'weight_decay_Hydroxylation-K': 3.5125404656259396,
 'weight_decay_Methylation-K': 8.90702771396513}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.386
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028693850386567374,
 'learning_rate_Hydroxylation-K': 0.006180290582471736,
 'learning_rate_Methylation-K': 0.00896416711150627,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6923875541271003,
 'loss_weight_Methylation-K': 0.9471118859173289,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2614797621,
 'sample_weights': [0.6240124707490491, 0.9634848947918508],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.9185497151322695,
 'weight_decay_Hydroxylation-K': 1.4580320312277486,
 'weight_decay_Methylation-K': 9.630985174943472}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.387
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008149953519186032,
 'learning_rate_Hydroxylation-K': 0.005651747111768979,
 'learning_rate_Methylation-K': 0.009805805447299634,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.32150931843676994,
 'loss_weight_Methylation-K': 0.03710484004129322,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1770790077,
 'sample_weights': [0.6923875541271003, 0.9471118859173289],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.29992388381406,
 'weight_decay_Hydroxylation-K': 8.545472267450387,
 'weight_decay_Methylation-K': 4.728890401600803}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.392
[3,     4] loss: 1.388
[4,     4] loss: 1.385
[5,     4] loss: 1.389
[6,     4] loss: 1.386
[7,     4] loss: 1.387
[8,     4] loss: 1.386
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00994005720350704,
 'learning_rate_Hydroxylation-K': 0.0027841402524265324,
 'learning_rate_Methylation-K': 0.006828669192025777,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9438182701747789,
 'loss_weight_Methylation-K': 0.15349601053105472,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2967220228,
 'sample_weights': [0.32150931843676994, 0.03710484004129322],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.903305117995104,
 'weight_decay_Hydroxylation-K': 6.352720923939274,
 'weight_decay_Methylation-K': 0.7589035626251102}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.381
[3,     4] loss: 1.392
[4,     4] loss: 1.388
[5,     4] loss: 1.388
[6,     4] loss: 1.387
[7,     4] loss: 1.388
[8,     4] loss: 1.386
[9,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003212149801440455,
 'learning_rate_Hydroxylation-K': 0.002720389656616893,
 'learning_rate_Methylation-K': 0.005884843914417938,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3972977397638977,
 'loss_weight_Methylation-K': 0.9809846672919983,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1147309220,
 'sample_weights': [0.9438182701747789, 0.15349601053105472],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.961518105296226,
 'weight_decay_Hydroxylation-K': 3.739398358411382,
 'weight_decay_Methylation-K': 5.3883659519242}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.388
[3,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00958705340158564,
 'learning_rate_Hydroxylation-K': 0.004357259423108131,
 'learning_rate_Methylation-K': 0.009790217566710672,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3801920042874709,
 'loss_weight_Methylation-K': 0.0943463898941388,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3301398779,
 'sample_weights': [0.3972977397638977, 0.9809846672919983],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.576480258542787,
 'weight_decay_Hydroxylation-K': 9.137677048118137,
 'weight_decay_Methylation-K': 8.34823165493729}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.389
[3,     4] loss: 1.387
[4,     4] loss: 1.385
[5,     4] loss: 1.384
[6,     4] loss: 1.386
[7,     4] loss: 1.389
[8,     4] loss: 1.387
[9,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0042531727980189395,
 'learning_rate_Hydroxylation-K': 0.008950066947985934,
 'learning_rate_Methylation-K': 0.004108930990031875,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6721445925742836,
 'loss_weight_Methylation-K': 0.897205505342515,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4049378364,
 'sample_weights': [0.3801920042874709, 0.0943463898941388],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.1740980545623194,
 'weight_decay_Hydroxylation-K': 3.77673099844423,
 'weight_decay_Methylation-K': 6.075688993447776}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.388
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00018915408110782182,
 'learning_rate_Hydroxylation-K': 0.002547846021785803,
 'learning_rate_Methylation-K': 0.003402607171223666,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2547414221972839,
 'loss_weight_Methylation-K': 0.4146955957724777,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 940368435,
 'sample_weights': [0.6721445925742836, 0.897205505342515],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8358840377286283,
 'weight_decay_Hydroxylation-K': 6.280349164748276,
 'weight_decay_Methylation-K': 5.064670050348373}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.389
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008748645844986327,
 'learning_rate_Hydroxylation-K': 0.008400168676831037,
 'learning_rate_Methylation-K': 0.0007127404148022888,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.17676440705928148,
 'loss_weight_Methylation-K': 0.5922421419481276,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3528652173,
 'sample_weights': [0.2547414221972839, 0.4146955957724777],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.168413298852051,
 'weight_decay_Hydroxylation-K': 1.734404474430117,
 'weight_decay_Methylation-K': 6.611198506162289}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.396
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012044032188861134,
 'learning_rate_Hydroxylation-K': 0.0004714184045143424,
 'learning_rate_Methylation-K': 0.004116550711153425,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3808723889674768,
 'loss_weight_Methylation-K': 0.7989801861992345,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2910994694,
 'sample_weights': [0.17676440705928148, 0.5922421419481276],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.9681863335067247,
 'weight_decay_Hydroxylation-K': 2.644536260431787,
 'weight_decay_Methylation-K': 0.41979181740102745}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.383
[3,     4] loss: 1.377
[4,     4] loss: 1.378
[5,     4] loss: 1.369
[6,     4] loss: 1.333
[7,     4] loss: 1.304
[8,     4] loss: 1.259
[9,     4] loss: 1.227
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00023550674505789084,
 'learning_rate_Hydroxylation-K': 0.0018835564896651415,
 'learning_rate_Methylation-K': 0.0034025718685554845,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.294800431140285,
 'loss_weight_Methylation-K': 0.6695863161308814,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2696534944,
 'sample_weights': [0.3808723889674768, 0.7989801861992345],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.910108697104631,
 'weight_decay_Hydroxylation-K': 0.8590102156896566,
 'weight_decay_Methylation-K': 7.667613422685905}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.392
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010357062439584046,
 'learning_rate_Hydroxylation-K': 0.0036194625843397788,
 'learning_rate_Methylation-K': 0.0052646034627220105,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8807475316030786,
 'loss_weight_Methylation-K': 0.9827359202953715,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1583843804,
 'sample_weights': [0.294800431140285, 0.6695863161308814],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.376000155584485,
 'weight_decay_Hydroxylation-K': 7.43779334180614,
 'weight_decay_Methylation-K': 0.6986943307708581}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.383
[3,     4] loss: 1.381
[4,     4] loss: 1.377
[5,     4] loss: 1.358
[6,     4] loss: 1.337
[7,     4] loss: 1.328
[8,     4] loss: 1.294
[9,     4] loss: 1.225
[10,     4] loss: 1.230
[11,     4] loss: 1.174
[12,     4] loss: 1.236
[13,     4] loss: 1.162
[14,     4] loss: 1.069
[15,     4] loss: 1.079
[16,     4] loss: 1.070
[17,     4] loss: 1.029
[18,     4] loss: 0.986
[19,     4] loss: 0.984
[20,     4] loss: 0.911
[21,     4] loss: 0.928
[22,     4] loss: 0.895
[23,     4] loss: 0.907
[24,     4] loss: 0.926
[25,     4] loss: 0.905
[26,     4] loss: 0.903
[27,     4] loss: 0.832
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001637064450244163,
 'learning_rate_Hydroxylation-K': 0.00369746733099002,
 'learning_rate_Methylation-K': 0.00863534478513205,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.144294373961434,
 'loss_weight_Methylation-K': 0.9979122561687642,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 101259258,
 'sample_weights': [0.8807475316030786, 0.9827359202953715],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.224335398379704,
 'weight_decay_Hydroxylation-K': 7.587916704627226,
 'weight_decay_Methylation-K': 9.829023539043426}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.385
[3,     4] loss: 1.387
[4,     4] loss: 1.386
[5,     4] loss: 1.380
[6,     4] loss: 1.387
[7,     4] loss: 1.378
[8,     4] loss: 1.367
[9,     4] loss: 1.339
[10,     4] loss: 1.314
[11,     4] loss: 1.225
[12,     4] loss: 1.167
[13,     4] loss: 1.114
[14,     4] loss: 1.045
[15,     4] loss: 1.072
[16,     4] loss: 1.065
[17,     4] loss: 1.012
[18,     4] loss: 0.937
[19,     4] loss: 0.954
[20,     4] loss: 0.961
[21,     4] loss: 0.951
[22,     4] loss: 0.969
[23,     4] loss: 0.949
[24,     4] loss: 0.884
[25,     4] loss: 0.889
[26,     4] loss: 0.902
[27,     4] loss: 0.880
[28,     4] loss: 0.932
[29,     4] loss: 0.946
[30,     4] loss: 0.871
[31,     4] loss: 0.940
[32,     4] loss: 0.883
[33,     4] loss: 0.873
[34,     4] loss: 0.850
[35,     4] loss: 0.838
[36,     4] loss: 0.866
[37,     4] loss: 0.824
[38,     4] loss: 0.856
[39,     4] loss: 0.814
[40,     4] loss: 0.844
[41,     4] loss: 0.783
[42,     4] loss: 0.887
[43,     4] loss: 0.844
[44,     4] loss: 0.816
[45,     4] loss: 0.804
[46,     4] loss: 0.799
[47,     4] loss: 0.820
[48,     4] loss: 0.857
[49,     4] loss: 0.835
[50,     4] loss: 0.873
[51,     4] loss: 0.847
[52,     4] loss: 0.800
[53,     4] loss: 0.797
[54,     4] loss: 0.792
[55,     4] loss: 0.773
[56,     4] loss: 0.782
[57,     4] loss: 0.797
[58,     4] loss: 0.792
[59,     4] loss: 0.816
[60,     4] loss: 0.795
[61,     4] loss: 0.794
[62,     4] loss: 0.778
[63,     4] loss: 0.758
[64,     4] loss: 0.785
[65,     4] loss: 0.772
[66,     4] loss: 0.787
[67,     4] loss: 0.785
[68,     4] loss: 0.794
[69,     4] loss: 0.809
[70,     4] loss: 0.803
[71,     4] loss: 0.884
[72,     4] loss: 0.829
[73,     4] loss: 0.792
[74,     4] loss: 0.792
[75,     4] loss: 0.799
[76,     4] loss: 0.772
[77,     4] loss: 0.776
[78,     4] loss: 0.799
[79,     4] loss: 0.787
[80,     4] loss: 0.764
Early stopping applied (best metric=0.40340229868888855)
Finished Training
Total time taken: 39.970107555389404
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.388
[3,     4] loss: 1.389
[4,     4] loss: 1.382
[5,     4] loss: 1.378
[6,     4] loss: 1.369
[7,     4] loss: 1.356
[8,     4] loss: 1.323
[9,     4] loss: 1.298
[10,     4] loss: 1.190
[11,     4] loss: 1.189
[12,     4] loss: 1.170
[13,     4] loss: 1.052
[14,     4] loss: 1.101
[15,     4] loss: 1.011
[16,     4] loss: 0.965
[17,     4] loss: 0.992
[18,     4] loss: 0.980
[19,     4] loss: 0.970
[20,     4] loss: 0.936
[21,     4] loss: 0.912
[22,     4] loss: 0.888
[23,     4] loss: 0.852
[24,     4] loss: 0.894
[25,     4] loss: 0.844
[26,     4] loss: 0.821
[27,     4] loss: 0.828
[28,     4] loss: 0.837
[29,     4] loss: 0.833
[30,     4] loss: 0.984
[31,     4] loss: 0.807
[32,     4] loss: 0.832
[33,     4] loss: 0.821
[34,     4] loss: 0.806
[35,     4] loss: 0.767
[36,     4] loss: 0.775
[37,     4] loss: 0.768
[38,     4] loss: 0.772
[39,     4] loss: 0.763
[40,     4] loss: 0.758
[41,     4] loss: 0.774
[42,     4] loss: 0.763
[43,     4] loss: 0.782
[44,     4] loss: 0.763
[45,     4] loss: 0.761
[46,     4] loss: 0.780
[47,     4] loss: 0.800
[48,     4] loss: 0.771
[49,     4] loss: 0.796
[50,     4] loss: 0.781
[51,     4] loss: 0.782
[52,     4] loss: 0.821
[53,     4] loss: 0.807
[54,     4] loss: 0.799
[55,     4] loss: 0.805
[56,     4] loss: 0.804
[57,     4] loss: 0.794
[58,     4] loss: 0.797
[59,     4] loss: 0.818
[60,     4] loss: 0.852
[61,     4] loss: 0.748
Early stopping applied (best metric=0.3852810859680176)
Finished Training
Total time taken: 30.70008158683777
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.386
[3,     4] loss: 1.383
[4,     4] loss: 1.377
[5,     4] loss: 1.356
[6,     4] loss: 1.334
[7,     4] loss: 1.287
[8,     4] loss: 1.214
[9,     4] loss: 1.183
[10,     4] loss: 1.152
[11,     4] loss: 1.117
[12,     4] loss: 1.070
[13,     4] loss: 1.093
[14,     4] loss: 1.012
[15,     4] loss: 0.958
[16,     4] loss: 0.981
[17,     4] loss: 0.936
[18,     4] loss: 0.986
[19,     4] loss: 0.931
[20,     4] loss: 0.898
[21,     4] loss: 0.952
[22,     4] loss: 0.897
[23,     4] loss: 0.909
[24,     4] loss: 0.979
[25,     4] loss: 0.884
[26,     4] loss: 0.837
[27,     4] loss: 0.830
[28,     4] loss: 0.808
[29,     4] loss: 0.855
[30,     4] loss: 0.838
[31,     4] loss: 0.889
[32,     4] loss: 0.869
[33,     4] loss: 0.946
[34,     4] loss: 0.844
[35,     4] loss: 0.829
[36,     4] loss: 0.805
[37,     4] loss: 0.939
[38,     4] loss: 0.864
[39,     4] loss: 0.867
[40,     4] loss: 0.875
[41,     4] loss: 0.814
[42,     4] loss: 0.807
[43,     4] loss: 0.817
[44,     4] loss: 0.823
[45,     4] loss: 0.776
[46,     4] loss: 0.769
[47,     4] loss: 0.766
[48,     4] loss: 0.788
[49,     4] loss: 0.766
[50,     4] loss: 0.777
[51,     4] loss: 0.782
[52,     4] loss: 0.830
[53,     4] loss: 0.844
[54,     4] loss: 0.806
[55,     4] loss: 0.811
[56,     4] loss: 0.798
[57,     4] loss: 0.779
[58,     4] loss: 0.779
[59,     4] loss: 0.773
[60,     4] loss: 0.770
Early stopping applied (best metric=0.4418494701385498)
Finished Training
Total time taken: 30.484084606170654
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.402
[2,     4] loss: 1.387
[3,     4] loss: 1.384
[4,     4] loss: 1.383
[5,     4] loss: 1.378
[6,     4] loss: 1.377
[7,     4] loss: 1.363
[8,     4] loss: 1.338
[9,     4] loss: 1.270
[10,     4] loss: 1.212
[11,     4] loss: 1.209
[12,     4] loss: 1.125
[13,     4] loss: 1.087
[14,     4] loss: 1.099
[15,     4] loss: 1.042
[16,     4] loss: 1.002
[17,     4] loss: 1.029
[18,     4] loss: 0.950
[19,     4] loss: 0.985
[20,     4] loss: 0.934
[21,     4] loss: 0.973
[22,     4] loss: 0.930
[23,     4] loss: 0.901
[24,     4] loss: 0.863
[25,     4] loss: 0.900
[26,     4] loss: 0.886
[27,     4] loss: 0.947
[28,     4] loss: 0.836
[29,     4] loss: 0.893
[30,     4] loss: 0.848
[31,     4] loss: 0.811
[32,     4] loss: 0.857
[33,     4] loss: 0.806
[34,     4] loss: 0.891
[35,     4] loss: 0.799
[36,     4] loss: 0.815
[37,     4] loss: 0.830
[38,     4] loss: 0.908
[39,     4] loss: 0.867
[40,     4] loss: 0.863
[41,     4] loss: 0.886
[42,     4] loss: 0.846
[43,     4] loss: 0.837
[44,     4] loss: 0.844
[45,     4] loss: 0.867
[46,     4] loss: 0.861
[47,     4] loss: 0.848
[48,     4] loss: 0.793
[49,     4] loss: 0.794
[50,     4] loss: 0.798
[51,     4] loss: 0.787
Early stopping applied (best metric=0.5455233454704285)
Finished Training
Total time taken: 25.60606861114502
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.384
[2,     4] loss: 1.389
[3,     4] loss: 1.379
[4,     4] loss: 1.384
[5,     4] loss: 1.387
[6,     4] loss: 1.385
[7,     4] loss: 1.385
[8,     4] loss: 1.379
[9,     4] loss: 1.372
[10,     4] loss: 1.363
[11,     4] loss: 1.343
[12,     4] loss: 1.307
[13,     4] loss: 1.286
[14,     4] loss: 1.230
[15,     4] loss: 1.206
[16,     4] loss: 1.232
[17,     4] loss: 1.163
[18,     4] loss: 1.070
[19,     4] loss: 1.073
[20,     4] loss: 0.987
[21,     4] loss: 0.951
[22,     4] loss: 0.932
[23,     4] loss: 1.079
[24,     4] loss: 0.982
[25,     4] loss: 1.010
[26,     4] loss: 0.915
[27,     4] loss: 0.893
[28,     4] loss: 0.845
[29,     4] loss: 0.821
[30,     4] loss: 0.821
[31,     4] loss: 0.842
[32,     4] loss: 0.825
[33,     4] loss: 0.833
[34,     4] loss: 0.788
[35,     4] loss: 0.820
[36,     4] loss: 0.831
[37,     4] loss: 0.803
[38,     4] loss: 0.884
[39,     4] loss: 0.860
[40,     4] loss: 0.811
[41,     4] loss: 0.828
[42,     4] loss: 0.796
[43,     4] loss: 0.780
[44,     4] loss: 0.883
[45,     4] loss: 0.854
[46,     4] loss: 0.823
[47,     4] loss: 0.797
[48,     4] loss: 0.779
[49,     4] loss: 0.770
[50,     4] loss: 0.786
[51,     4] loss: 0.791
[52,     4] loss: 0.755
[53,     4] loss: 0.755
[54,     4] loss: 0.769
[55,     4] loss: 0.789
[56,     4] loss: 0.773
[57,     4] loss: 0.805
[58,     4] loss: 0.845
[59,     4] loss: 0.798
[60,     4] loss: 0.793
[61,     4] loss: 0.770
[62,     4] loss: 0.792
[63,     4] loss: 0.770
[64,     4] loss: 0.744
[65,     4] loss: 0.765
[66,     4] loss: 0.775
Early stopping applied (best metric=0.42995184659957886)
Finished Training
Total time taken: 33.305089712142944
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.385
[3,     4] loss: 1.384
[4,     4] loss: 1.381
[5,     4] loss: 1.377
[6,     4] loss: 1.363
[7,     4] loss: 1.334
[8,     4] loss: 1.283
[9,     4] loss: 1.217
[10,     4] loss: 1.174
[11,     4] loss: 1.164
[12,     4] loss: 1.022
[13,     4] loss: 1.052
[14,     4] loss: 1.035
[15,     4] loss: 0.974
[16,     4] loss: 0.983
[17,     4] loss: 0.969
[18,     4] loss: 0.949
[19,     4] loss: 0.908
[20,     4] loss: 0.885
[21,     4] loss: 0.893
[22,     4] loss: 0.894
[23,     4] loss: 0.899
[24,     4] loss: 0.875
[25,     4] loss: 0.905
[26,     4] loss: 0.863
[27,     4] loss: 0.866
[28,     4] loss: 0.922
[29,     4] loss: 0.942
[30,     4] loss: 0.908
[31,     4] loss: 0.834
[32,     4] loss: 0.860
[33,     4] loss: 0.912
[34,     4] loss: 0.839
[35,     4] loss: 0.810
[36,     4] loss: 0.773
[37,     4] loss: 0.783
[38,     4] loss: 0.807
[39,     4] loss: 0.812
[40,     4] loss: 0.904
[41,     4] loss: 0.839
[42,     4] loss: 0.824
[43,     4] loss: 0.845
[44,     4] loss: 0.855
[45,     4] loss: 0.843
[46,     4] loss: 0.822
[47,     4] loss: 0.845
[48,     4] loss: 0.808
[49,     4] loss: 0.765
[50,     4] loss: 0.751
[51,     4] loss: 0.765
[52,     4] loss: 0.747
[53,     4] loss: 0.775
[54,     4] loss: 0.747
[55,     4] loss: 0.791
[56,     4] loss: 0.776
[57,     4] loss: 0.745
[58,     4] loss: 0.812
[59,     4] loss: 0.832
[60,     4] loss: 0.858
[61,     4] loss: 0.904
[62,     4] loss: 0.856
[63,     4] loss: 0.808
[64,     4] loss: 0.770
[65,     4] loss: 0.756
[66,     4] loss: 0.742
[67,     4] loss: 0.734
[68,     4] loss: 0.747
[69,     4] loss: 0.751
[70,     4] loss: 0.733
[71,     4] loss: 0.748
[72,     4] loss: 0.750
[73,     4] loss: 0.741
[74,     4] loss: 0.742
[75,     4] loss: 0.745
[76,     4] loss: 0.741
[77,     4] loss: 0.738
[78,     4] loss: 0.755
[79,     4] loss: 0.753
[80,     4] loss: 0.740
[81,     4] loss: 0.762
[82,     4] loss: 0.755
[83,     4] loss: 0.796
[84,     4] loss: 0.781
[85,     4] loss: 0.770
[86,     4] loss: 0.749
[87,     4] loss: 0.759
[88,     4] loss: 0.788
[89,     4] loss: 0.869
[90,     4] loss: 0.829
[91,     4] loss: 0.864
[92,     4] loss: 0.762
[93,     4] loss: 0.792
[94,     4] loss: 0.779
[95,     4] loss: 0.760
[96,     4] loss: 0.751
Early stopping applied (best metric=0.3437870442867279)
Finished Training
Total time taken: 48.65113282203674
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.408
[2,     4] loss: 1.384
[3,     4] loss: 1.386
[4,     4] loss: 1.387
[5,     4] loss: 1.383
[6,     4] loss: 1.384
[7,     4] loss: 1.381
[8,     4] loss: 1.375
[9,     4] loss: 1.375
[10,     4] loss: 1.357
[11,     4] loss: 1.324
[12,     4] loss: 1.277
[13,     4] loss: 1.301
[14,     4] loss: 1.193
[15,     4] loss: 1.156
[16,     4] loss: 1.178
[17,     4] loss: 1.124
[18,     4] loss: 1.032
[19,     4] loss: 0.997
[20,     4] loss: 0.960
[21,     4] loss: 0.991
[22,     4] loss: 0.907
[23,     4] loss: 0.984
[24,     4] loss: 0.947
[25,     4] loss: 0.946
[26,     4] loss: 0.928
[27,     4] loss: 0.922
[28,     4] loss: 0.824
[29,     4] loss: 0.825
[30,     4] loss: 0.820
[31,     4] loss: 0.908
[32,     4] loss: 0.816
[33,     4] loss: 0.774
[34,     4] loss: 0.802
[35,     4] loss: 0.803
[36,     4] loss: 0.877
[37,     4] loss: 0.832
[38,     4] loss: 0.879
[39,     4] loss: 0.830
[40,     4] loss: 0.830
[41,     4] loss: 0.812
[42,     4] loss: 0.822
[43,     4] loss: 0.787
[44,     4] loss: 0.789
[45,     4] loss: 0.783
[46,     4] loss: 0.808
[47,     4] loss: 0.854
[48,     4] loss: 0.862
[49,     4] loss: 0.785
[50,     4] loss: 0.781
[51,     4] loss: 0.757
[52,     4] loss: 0.768
[53,     4] loss: 0.762
[54,     4] loss: 0.769
[55,     4] loss: 0.819
[56,     4] loss: 0.826
[57,     4] loss: 0.849
[58,     4] loss: 0.792
[59,     4] loss: 0.807
[60,     4] loss: 0.790
[61,     4] loss: 0.782
[62,     4] loss: 0.785
[63,     4] loss: 0.759
[64,     4] loss: 0.744
[65,     4] loss: 0.745
[66,     4] loss: 0.743
[67,     4] loss: 0.752
[68,     4] loss: 0.743
[69,     4] loss: 0.749
[70,     4] loss: 0.749
[71,     4] loss: 0.739
[72,     4] loss: 0.745
[73,     4] loss: 0.761
[74,     4] loss: 0.745
[75,     4] loss: 0.767
[76,     4] loss: 0.761
[77,     4] loss: 0.767
[78,     4] loss: 0.765
[79,     4] loss: 0.747
[80,     4] loss: 0.772
[81,     4] loss: 0.757
[82,     4] loss: 0.781
[83,     4] loss: 0.770
[84,     4] loss: 0.765
[85,     4] loss: 0.760
[86,     4] loss: 0.793
[87,     4] loss: 0.793
[88,     4] loss: 0.823
[89,     4] loss: 0.809
[90,     4] loss: 0.766
[91,     4] loss: 0.799
[92,     4] loss: 0.849
[93,     4] loss: 0.783
[94,     4] loss: 0.758
[95,     4] loss: 0.784
[96,     4] loss: 0.790
[97,     4] loss: 0.773
[98,     4] loss: 0.759
Early stopping applied (best metric=0.33837687969207764)
Finished Training
Total time taken: 49.54213356971741
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.389
[3,     4] loss: 1.382
[4,     4] loss: 1.385
[5,     4] loss: 1.377
[6,     4] loss: 1.366
[7,     4] loss: 1.353
[8,     4] loss: 1.320
[9,     4] loss: 1.250
[10,     4] loss: 1.234
[11,     4] loss: 1.152
[12,     4] loss: 1.125
[13,     4] loss: 1.051
[14,     4] loss: 1.069
[15,     4] loss: 1.063
[16,     4] loss: 1.073
[17,     4] loss: 1.006
[18,     4] loss: 0.953
[19,     4] loss: 1.035
[20,     4] loss: 1.051
[21,     4] loss: 0.998
[22,     4] loss: 0.943
[23,     4] loss: 0.928
[24,     4] loss: 0.921
[25,     4] loss: 0.914
[26,     4] loss: 0.872
[27,     4] loss: 0.875
[28,     4] loss: 0.892
[29,     4] loss: 0.831
[30,     4] loss: 0.812
[31,     4] loss: 0.847
[32,     4] loss: 0.847
[33,     4] loss: 0.819
[34,     4] loss: 0.879
[35,     4] loss: 0.817
[36,     4] loss: 0.812
[37,     4] loss: 0.800
[38,     4] loss: 0.798
[39,     4] loss: 0.770
[40,     4] loss: 0.851
[41,     4] loss: 0.840
[42,     4] loss: 0.791
[43,     4] loss: 0.811
[44,     4] loss: 0.786
[45,     4] loss: 0.819
[46,     4] loss: 0.840
[47,     4] loss: 0.831
[48,     4] loss: 0.820
[49,     4] loss: 0.766
[50,     4] loss: 0.806
[51,     4] loss: 0.782
[52,     4] loss: 0.771
[53,     4] loss: 0.745
[54,     4] loss: 0.761
[55,     4] loss: 0.753
[56,     4] loss: 0.748
[57,     4] loss: 0.769
[58,     4] loss: 0.764
Early stopping applied (best metric=0.4789623022079468)
Finished Training
Total time taken: 29.941081762313843
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.386
[3,     4] loss: 1.387
[4,     4] loss: 1.385
[5,     4] loss: 1.382
[6,     4] loss: 1.369
[7,     4] loss: 1.369
[8,     4] loss: 1.336
[9,     4] loss: 1.310
[10,     4] loss: 1.277
[11,     4] loss: 1.242
[12,     4] loss: 1.210
[13,     4] loss: 1.175
[14,     4] loss: 1.152
[15,     4] loss: 1.073
[16,     4] loss: 1.147
[17,     4] loss: 1.100
[18,     4] loss: 1.013
[19,     4] loss: 1.013
[20,     4] loss: 0.907
[21,     4] loss: 0.938
[22,     4] loss: 0.878
[23,     4] loss: 0.907
[24,     4] loss: 0.944
[25,     4] loss: 0.933
[26,     4] loss: 0.942
[27,     4] loss: 0.988
[28,     4] loss: 0.915
[29,     4] loss: 0.936
[30,     4] loss: 0.937
[31,     4] loss: 0.921
[32,     4] loss: 0.888
[33,     4] loss: 0.840
[34,     4] loss: 0.858
[35,     4] loss: 0.818
[36,     4] loss: 0.779
[37,     4] loss: 0.781
[38,     4] loss: 0.794
[39,     4] loss: 0.758
[40,     4] loss: 0.794
[41,     4] loss: 0.779
[42,     4] loss: 0.771
[43,     4] loss: 0.782
[44,     4] loss: 0.806
[45,     4] loss: 0.864
[46,     4] loss: 0.849
[47,     4] loss: 0.790
[48,     4] loss: 0.778
[49,     4] loss: 0.783
[50,     4] loss: 0.817
[51,     4] loss: 0.774
[52,     4] loss: 0.747
[53,     4] loss: 0.766
[54,     4] loss: 0.751
[55,     4] loss: 0.780
[56,     4] loss: 0.769
[57,     4] loss: 0.788
[58,     4] loss: 0.764
[59,     4] loss: 0.788
[60,     4] loss: 0.769
[61,     4] loss: 0.849
[62,     4] loss: 0.809
[63,     4] loss: 0.776
[64,     4] loss: 0.792
Early stopping applied (best metric=0.48100489377975464)
Finished Training
Total time taken: 32.218087911605835
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.377
[2,     4] loss: 1.385
[3,     4] loss: 1.386
[4,     4] loss: 1.387
[5,     4] loss: 1.380
[6,     4] loss: 1.362
[7,     4] loss: 1.354
[8,     4] loss: 1.305
[9,     4] loss: 1.272
[10,     4] loss: 1.195
[11,     4] loss: 1.152
[12,     4] loss: 1.133
[13,     4] loss: 1.018
[14,     4] loss: 1.067
[15,     4] loss: 0.965
[16,     4] loss: 0.978
[17,     4] loss: 0.922
[18,     4] loss: 0.890
[19,     4] loss: 0.927
[20,     4] loss: 0.906
[21,     4] loss: 0.854
[22,     4] loss: 0.818
[23,     4] loss: 0.858
[24,     4] loss: 0.882
[25,     4] loss: 0.961
[26,     4] loss: 0.927
[27,     4] loss: 0.889
[28,     4] loss: 0.900
[29,     4] loss: 0.930
[30,     4] loss: 0.841
[31,     4] loss: 0.821
[32,     4] loss: 0.815
[33,     4] loss: 0.814
[34,     4] loss: 0.796
[35,     4] loss: 0.768
[36,     4] loss: 0.776
[37,     4] loss: 0.794
[38,     4] loss: 0.823
[39,     4] loss: 0.814
[40,     4] loss: 0.782
[41,     4] loss: 0.801
[42,     4] loss: 0.790
[43,     4] loss: 0.768
[44,     4] loss: 0.773
[45,     4] loss: 0.773
[46,     4] loss: 0.776
[47,     4] loss: 0.825
[48,     4] loss: 0.864
[49,     4] loss: 0.841
[50,     4] loss: 0.859
[51,     4] loss: 0.805
[52,     4] loss: 0.785
[53,     4] loss: 0.796
[54,     4] loss: 0.777
[55,     4] loss: 0.783
[56,     4] loss: 0.754
[57,     4] loss: 0.753
[58,     4] loss: 0.748
[59,     4] loss: 0.787
Early stopping applied (best metric=0.45152655243873596)
Finished Training
Total time taken: 29.737080574035645
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.398
[3,     4] loss: 1.379
[4,     4] loss: 1.378
[5,     4] loss: 1.371
[6,     4] loss: 1.355
[7,     4] loss: 1.329
[8,     4] loss: 1.297
[9,     4] loss: 1.249
[10,     4] loss: 1.188
[11,     4] loss: 1.158
[12,     4] loss: 1.037
[13,     4] loss: 1.092
[14,     4] loss: 1.142
[15,     4] loss: 1.033
[16,     4] loss: 1.088
[17,     4] loss: 1.051
[18,     4] loss: 1.076
[19,     4] loss: 1.052
[20,     4] loss: 1.051
[21,     4] loss: 1.005
[22,     4] loss: 0.900
[23,     4] loss: 0.899
[24,     4] loss: 0.972
[25,     4] loss: 0.876
[26,     4] loss: 0.881
[27,     4] loss: 0.900
[28,     4] loss: 0.882
[29,     4] loss: 0.882
[30,     4] loss: 0.820
[31,     4] loss: 0.835
[32,     4] loss: 0.936
[33,     4] loss: 0.872
[34,     4] loss: 0.879
[35,     4] loss: 0.852
[36,     4] loss: 0.808
[37,     4] loss: 0.914
[38,     4] loss: 0.856
[39,     4] loss: 0.893
[40,     4] loss: 0.850
[41,     4] loss: 0.866
[42,     4] loss: 0.955
[43,     4] loss: 0.836
[44,     4] loss: 0.854
[45,     4] loss: 0.833
[46,     4] loss: 0.833
[47,     4] loss: 0.774
[48,     4] loss: 0.856
[49,     4] loss: 0.775
[50,     4] loss: 0.801
[51,     4] loss: 0.767
[52,     4] loss: 0.754
[53,     4] loss: 0.749
[54,     4] loss: 0.737
[55,     4] loss: 0.800
[56,     4] loss: 0.749
[57,     4] loss: 0.753
[58,     4] loss: 0.752
[59,     4] loss: 0.754
[60,     4] loss: 0.753
Early stopping applied (best metric=0.42923301458358765)
Finished Training
Total time taken: 30.364083290100098
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.392
[3,     4] loss: 1.387
[4,     4] loss: 1.387
[5,     4] loss: 1.384
[6,     4] loss: 1.383
[7,     4] loss: 1.380
[8,     4] loss: 1.370
[9,     4] loss: 1.359
[10,     4] loss: 1.325
[11,     4] loss: 1.278
[12,     4] loss: 1.216
[13,     4] loss: 1.198
[14,     4] loss: 1.145
[15,     4] loss: 1.176
[16,     4] loss: 1.159
[17,     4] loss: 1.107
[18,     4] loss: 1.116
[19,     4] loss: 1.073
[20,     4] loss: 0.976
[21,     4] loss: 1.016
[22,     4] loss: 0.903
[23,     4] loss: 0.959
[24,     4] loss: 0.902
[25,     4] loss: 0.936
[26,     4] loss: 0.949
[27,     4] loss: 0.936
[28,     4] loss: 0.852
[29,     4] loss: 0.850
[30,     4] loss: 0.856
[31,     4] loss: 0.861
[32,     4] loss: 0.846
[33,     4] loss: 0.807
[34,     4] loss: 0.893
[35,     4] loss: 0.836
[36,     4] loss: 0.843
[37,     4] loss: 0.816
[38,     4] loss: 0.838
[39,     4] loss: 0.784
[40,     4] loss: 0.860
[41,     4] loss: 0.771
[42,     4] loss: 0.818
[43,     4] loss: 0.764
[44,     4] loss: 0.780
[45,     4] loss: 0.857
[46,     4] loss: 0.868
[47,     4] loss: 0.851
[48,     4] loss: 0.918
[49,     4] loss: 0.887
[50,     4] loss: 0.820
[51,     4] loss: 0.821
[52,     4] loss: 0.821
[53,     4] loss: 0.777
[54,     4] loss: 0.769
[55,     4] loss: 0.774
[56,     4] loss: 0.764
[57,     4] loss: 0.766
[58,     4] loss: 0.753
[59,     4] loss: 0.766
[60,     4] loss: 0.766
[61,     4] loss: 0.755
[62,     4] loss: 0.775
[63,     4] loss: 0.779
[64,     4] loss: 0.869
[65,     4] loss: 0.839
[66,     4] loss: 0.871
[67,     4] loss: 0.837
[68,     4] loss: 0.820
[69,     4] loss: 0.826
[70,     4] loss: 0.778
[71,     4] loss: 0.753
[72,     4] loss: 0.765
[73,     4] loss: 0.769
[74,     4] loss: 0.753
[75,     4] loss: 0.752
[76,     4] loss: 0.766
[77,     4] loss: 0.755
[78,     4] loss: 0.752
[79,     4] loss: 0.785
[80,     4] loss: 0.770
[81,     4] loss: 0.763
[82,     4] loss: 0.754
[83,     4] loss: 0.760
[84,     4] loss: 0.754
[85,     4] loss: 0.822
[86,     4] loss: 0.814
[87,     4] loss: 0.789
[88,     4] loss: 0.771
[89,     4] loss: 0.763
[90,     4] loss: 0.743
[91,     4] loss: 0.770
[92,     4] loss: 0.765
[93,     4] loss: 0.791
[94,     4] loss: 0.789
[95,     4] loss: 0.823
[96,     4] loss: 0.800
[97,     4] loss: 0.806
[98,     4] loss: 0.767
[99,     4] loss: 0.796
[100,     4] loss: 0.766
[101,     4] loss: 0.767
[102,     4] loss: 0.813
[103,     4] loss: 0.759
[104,     4] loss: 0.766
[105,     4] loss: 0.786
[106,     4] loss: 0.767
[107,     4] loss: 0.773
[108,     4] loss: 1.000
[109,     4] loss: 0.939
[110,     4] loss: 0.970
[111,     4] loss: 0.937
[112,     4] loss: 0.924
[113,     4] loss: 0.790
[114,     4] loss: 0.874
[115,     4] loss: 0.824
[116,     4] loss: 0.849
[117,     4] loss: 0.814
[118,     4] loss: 0.867
[119,     4] loss: 0.796
[120,     4] loss: 0.784
[121,     4] loss: 0.773
[122,     4] loss: 0.749
[123,     4] loss: 0.762
[124,     4] loss: 0.750
[125,     4] loss: 0.787
[126,     4] loss: 0.744
[127,     4] loss: 0.762
[128,     4] loss: 0.771
[129,     4] loss: 0.784
[130,     4] loss: 0.810
Early stopping applied (best metric=0.3271651268005371)
Finished Training
Total time taken: 65.82495784759521
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.395
[3,     4] loss: 1.376
[4,     4] loss: 1.377
[5,     4] loss: 1.368
[6,     4] loss: 1.330
[7,     4] loss: 1.309
[8,     4] loss: 1.268
[9,     4] loss: 1.189
[10,     4] loss: 1.162
[11,     4] loss: 1.081
[12,     4] loss: 1.049
[13,     4] loss: 1.056
[14,     4] loss: 1.033
[15,     4] loss: 1.045
[16,     4] loss: 1.019
[17,     4] loss: 0.948
[18,     4] loss: 0.982
[19,     4] loss: 0.989
[20,     4] loss: 0.920
[21,     4] loss: 0.882
[22,     4] loss: 0.823
[23,     4] loss: 0.850
[24,     4] loss: 0.815
[25,     4] loss: 0.859
[26,     4] loss: 0.810
[27,     4] loss: 0.911
[28,     4] loss: 0.884
[29,     4] loss: 0.867
[30,     4] loss: 0.860
[31,     4] loss: 0.863
[32,     4] loss: 0.889
[33,     4] loss: 0.806
[34,     4] loss: 0.836
[35,     4] loss: 0.818
[36,     4] loss: 0.855
[37,     4] loss: 0.800
[38,     4] loss: 0.825
[39,     4] loss: 0.821
[40,     4] loss: 0.826
[41,     4] loss: 0.778
[42,     4] loss: 0.776
[43,     4] loss: 0.788
[44,     4] loss: 0.772
[45,     4] loss: 0.816
[46,     4] loss: 0.804
[47,     4] loss: 0.763
[48,     4] loss: 0.795
[49,     4] loss: 0.856
[50,     4] loss: 0.781
[51,     4] loss: 0.772
[52,     4] loss: 0.768
[53,     4] loss: 0.745
[54,     4] loss: 0.793
[55,     4] loss: 0.796
[56,     4] loss: 0.777
[57,     4] loss: 0.791
[58,     4] loss: 0.797
[59,     4] loss: 0.814
[60,     4] loss: 0.822
[61,     4] loss: 0.794
[62,     4] loss: 0.783
[63,     4] loss: 0.771
[64,     4] loss: 0.770
[65,     4] loss: 0.754
[66,     4] loss: 0.739
[67,     4] loss: 0.746
[68,     4] loss: 0.766
[69,     4] loss: 0.761
[70,     4] loss: 0.745
[71,     4] loss: 0.750
[72,     4] loss: 0.772
[73,     4] loss: 0.755
[74,     4] loss: 0.780
[75,     4] loss: 0.859
[76,     4] loss: 0.822
[77,     4] loss: 0.784
[78,     4] loss: 0.797
[79,     4] loss: 0.770
[80,     4] loss: 0.790
[81,     4] loss: 0.766
[82,     4] loss: 0.774
[83,     4] loss: 0.761
[84,     4] loss: 0.747
[85,     4] loss: 0.752
[86,     4] loss: 0.742
[87,     4] loss: 0.765
[88,     4] loss: 0.737
[89,     4] loss: 0.734
[90,     4] loss: 0.742
[91,     4] loss: 0.737
[92,     4] loss: 0.804
[93,     4] loss: 0.850
[94,     4] loss: 0.823
[95,     4] loss: 0.835
[96,     4] loss: 0.769
[97,     4] loss: 0.815
[98,     4] loss: 0.824
[99,     4] loss: 0.790
[100,     4] loss: 0.774
[101,     4] loss: 0.744
[102,     4] loss: 0.766
[103,     4] loss: 0.798
[104,     4] loss: 0.769
[105,     4] loss: 0.800
[106,     4] loss: 0.744
[107,     4] loss: 0.777
[108,     4] loss: 0.749
[109,     4] loss: 0.798
[110,     4] loss: 0.769
[111,     4] loss: 0.790
[112,     4] loss: 0.782
[113,     4] loss: 0.839
[114,     4] loss: 0.825
[115,     4] loss: 0.811
[116,     4] loss: 0.818
[117,     4] loss: 0.840
[118,     4] loss: 0.780
[119,     4] loss: 0.796
[120,     4] loss: 0.799
[121,     4] loss: 0.767
[122,     4] loss: 0.781
[123,     4] loss: 0.743
[124,     4] loss: 0.742
[125,     4] loss: 0.768
[126,     4] loss: 0.779
[127,     4] loss: 0.769
[128,     4] loss: 0.766
[129,     4] loss: 0.828
[130,     4] loss: 0.793
[131,     4] loss: 0.782
[132,     4] loss: 0.755
[133,     4] loss: 0.846
[134,     4] loss: 0.872
[135,     4] loss: 0.944
[136,     4] loss: 0.881
[137,     4] loss: 0.855
[138,     4] loss: 0.822
[139,     4] loss: 0.852
[140,     4] loss: 0.818
[141,     4] loss: 0.779
[142,     4] loss: 0.763
[143,     4] loss: 0.761
[144,     4] loss: 0.765
Early stopping applied (best metric=0.41589075326919556)
Finished Training
Total time taken: 72.98411631584167
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.390
[3,     4] loss: 1.385
[4,     4] loss: 1.384
[5,     4] loss: 1.379
[6,     4] loss: 1.384
[7,     4] loss: 1.363
[8,     4] loss: 1.341
[9,     4] loss: 1.314
[10,     4] loss: 1.307
[11,     4] loss: 1.227
[12,     4] loss: 1.214
[13,     4] loss: 1.147
[14,     4] loss: 1.168
[15,     4] loss: 1.169
[16,     4] loss: 1.142
[17,     4] loss: 1.059
[18,     4] loss: 1.068
[19,     4] loss: 1.031
[20,     4] loss: 1.060
[21,     4] loss: 0.965
[22,     4] loss: 1.037
[23,     4] loss: 0.921
[24,     4] loss: 0.991
[25,     4] loss: 0.940
[26,     4] loss: 0.948
[27,     4] loss: 0.886
[28,     4] loss: 0.901
[29,     4] loss: 0.919
[30,     4] loss: 0.908
[31,     4] loss: 0.919
[32,     4] loss: 0.964
[33,     4] loss: 0.925
[34,     4] loss: 0.990
[35,     4] loss: 0.969
[36,     4] loss: 0.924
[37,     4] loss: 0.863
[38,     4] loss: 0.885
[39,     4] loss: 0.819
[40,     4] loss: 0.812
[41,     4] loss: 0.874
[42,     4] loss: 0.807
[43,     4] loss: 0.843
[44,     4] loss: 0.807
[45,     4] loss: 0.799
[46,     4] loss: 0.809
[47,     4] loss: 0.801
[48,     4] loss: 0.911
[49,     4] loss: 0.860
[50,     4] loss: 0.844
[51,     4] loss: 0.879
[52,     4] loss: 0.832
[53,     4] loss: 0.822
[54,     4] loss: 0.790
[55,     4] loss: 0.782
[56,     4] loss: 0.783
[57,     4] loss: 0.768
[58,     4] loss: 0.748
[59,     4] loss: 0.769
[60,     4] loss: 0.766
[61,     4] loss: 0.758
[62,     4] loss: 0.747
[63,     4] loss: 0.756
[64,     4] loss: 0.755
[65,     4] loss: 0.754
[66,     4] loss: 0.769
[67,     4] loss: 0.762
[68,     4] loss: 0.754
[69,     4] loss: 0.797
[70,     4] loss: 0.780
[71,     4] loss: 0.804
[72,     4] loss: 0.759
[73,     4] loss: 0.795
[74,     4] loss: 0.826
[75,     4] loss: 0.780
[76,     4] loss: 0.808
[77,     4] loss: 0.806
[78,     4] loss: 0.836
[79,     4] loss: 0.795
[80,     4] loss: 0.761
[81,     4] loss: 0.775
[82,     4] loss: 0.774
[83,     4] loss: 0.814
[84,     4] loss: 0.781
[85,     4] loss: 0.782
[86,     4] loss: 0.778
[87,     4] loss: 0.793
[88,     4] loss: 0.768
[89,     4] loss: 0.780
[90,     4] loss: 0.782
[91,     4] loss: 0.773
[92,     4] loss: 0.768
[93,     4] loss: 0.741
[94,     4] loss: 0.785
[95,     4] loss: 0.769
[96,     4] loss: 0.756
[97,     4] loss: 0.756
[98,     4] loss: 0.766
[99,     4] loss: 0.839
[100,     4] loss: 0.777
[101,     4] loss: 0.777
[102,     4] loss: 0.750
[103,     4] loss: 0.776
[104,     4] loss: 0.751
[105,     4] loss: 0.753
[106,     4] loss: 0.748
[107,     4] loss: 0.773
[108,     4] loss: 0.934
[109,     4] loss: 0.839
[110,     4] loss: 0.852
[111,     4] loss: 0.806
[112,     4] loss: 0.769
[113,     4] loss: 0.751
[114,     4] loss: 0.775
[115,     4] loss: 0.805
[116,     4] loss: 0.771
[117,     4] loss: 0.773
[118,     4] loss: 0.818
[119,     4] loss: 0.930
[120,     4] loss: 0.847
[121,     4] loss: 0.822
[122,     4] loss: 0.790
[123,     4] loss: 0.756
[124,     4] loss: 0.750
[125,     4] loss: 0.767
[126,     4] loss: 0.791
[127,     4] loss: 0.752
[128,     4] loss: 0.785
[129,     4] loss: 0.742
[130,     4] loss: 0.741
[131,     4] loss: 0.763
[132,     4] loss: 0.939
[133,     4] loss: 0.886
[134,     4] loss: 0.872
[135,     4] loss: 0.850
[136,     4] loss: 0.854
[137,     4] loss: 0.864
[138,     4] loss: 0.853
[139,     4] loss: 0.789
[140,     4] loss: 0.779
[141,     4] loss: 0.777
[142,     4] loss: 0.749
[143,     4] loss: 0.747
[144,     4] loss: 0.735
[145,     4] loss: 0.740
[146,     4] loss: 0.744
[147,     4] loss: 0.727
[148,     4] loss: 0.729
[149,     4] loss: 0.761
[150,     4] loss: 0.779
[151,     4] loss: 0.784
[152,     4] loss: 0.754
[153,     4] loss: 0.770
[154,     4] loss: 0.778
[155,     4] loss: 0.792
[156,     4] loss: 0.775
[157,     4] loss: 0.762
[158,     4] loss: 0.768
[159,     4] loss: 0.810
[160,     4] loss: 0.806
[161,     4] loss: 0.791
[162,     4] loss: 0.769
[163,     4] loss: 0.785
[164,     4] loss: 0.791
[165,     4] loss: 0.788
[166,     4] loss: 0.819
[167,     4] loss: 0.770
[168,     4] loss: 0.774
[169,     4] loss: 0.777
[170,     4] loss: 0.758
[171,     4] loss: 0.753
[172,     4] loss: 0.739
[173,     4] loss: 0.745
Early stopping applied (best metric=0.12918724119663239)
Finished Training
Total time taken: 87.35623240470886
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.393
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.383
[5,     4] loss: 1.379
[6,     4] loss: 1.379
[7,     4] loss: 1.359
[8,     4] loss: 1.342
[9,     4] loss: 1.304
[10,     4] loss: 1.268
[11,     4] loss: 1.236
[12,     4] loss: 1.131
[13,     4] loss: 1.150
[14,     4] loss: 1.024
[15,     4] loss: 1.084
[16,     4] loss: 1.050
[17,     4] loss: 1.050
[18,     4] loss: 1.031
[19,     4] loss: 0.999
[20,     4] loss: 1.026
[21,     4] loss: 1.037
[22,     4] loss: 1.043
[23,     4] loss: 0.973
[24,     4] loss: 0.995
[25,     4] loss: 0.955
[26,     4] loss: 0.925
[27,     4] loss: 0.941
[28,     4] loss: 0.952
[29,     4] loss: 0.905
[30,     4] loss: 0.899
[31,     4] loss: 0.835
[32,     4] loss: 0.845
[33,     4] loss: 0.857
[34,     4] loss: 0.884
[35,     4] loss: 0.902
[36,     4] loss: 0.815
[37,     4] loss: 0.801
[38,     4] loss: 0.849
[39,     4] loss: 0.781
[40,     4] loss: 0.776
[41,     4] loss: 0.827
[42,     4] loss: 0.927
[43,     4] loss: 0.972
[44,     4] loss: 0.889
[45,     4] loss: 0.956
[46,     4] loss: 0.926
[47,     4] loss: 0.920
[48,     4] loss: 0.860
[49,     4] loss: 0.818
[50,     4] loss: 0.816
[51,     4] loss: 0.820
[52,     4] loss: 0.798
[53,     4] loss: 0.811
[54,     4] loss: 0.762
[55,     4] loss: 0.771
[56,     4] loss: 0.767
[57,     4] loss: 0.773
[58,     4] loss: 0.762
[59,     4] loss: 0.798
[60,     4] loss: 0.761
[61,     4] loss: 0.766
Early stopping applied (best metric=0.3947313129901886)
Finished Training
Total time taken: 31.009084224700928
{'Hydroxylation-K Validation Accuracy': 0.737677304964539, 'Hydroxylation-K Validation Sensitivity': 0.7977777777777778, 'Hydroxylation-K Validation Specificity': 0.7228070175438597, 'Hydroxylation-K Validation Precision': 0.4639766639516327, 'Hydroxylation-K AUC ROC': 0.8237816764132554, 'Hydroxylation-K AUC PR': 0.581747394006974, 'Hydroxylation-K MCC': 0.4497348967148101, 'Hydroxylation-K F1': 0.5754567810248035, 'Validation Loss (Hydroxylation-K)': 0.3997248778740565, 'Methylation-K Validation Accuracy': 0.7506025339940987, 'Methylation-K Validation Sensitivity': 0.21851649926258326, 'Methylation-K Validation Specificity': 0.8083052196648379, 'Methylation-K Validation Precision': 0.1161100274616627, 'Methylation-K AUC ROC': 0.5384156192208778, 'Methylation-K AUC PR': 0.11088204283586095, 'Methylation-K MCC': 0.023143421339218456, 'Methylation-K F1': 0.13189972659831006, 'Validation Loss (Methylation-K)': 0.9192355692386627, 'Validation Loss (total)': 1.318960444132487, 'TimeToTrain': 42.51289485295614}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018211941915657983,
 'learning_rate_Hydroxylation-K': 0.005452539068895463,
 'learning_rate_Methylation-K': 0.004763649343622234,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7389589649956803,
 'loss_weight_Methylation-K': 0.9846265540503608,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1490148482,
 'sample_weights': [0.144294373961434, 0.9979122561687642],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.347071342886666,
 'weight_decay_Hydroxylation-K': 7.572275077236409,
 'weight_decay_Methylation-K': 8.514238045229696}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.385
[3,     4] loss: 1.384
[4,     4] loss: 1.382
[5,     4] loss: 1.374
[6,     4] loss: 1.353
[7,     4] loss: 1.306
[8,     4] loss: 1.240
[9,     4] loss: 1.219
[10,     4] loss: 1.121
[11,     4] loss: 1.164
[12,     4] loss: 1.084
[13,     4] loss: 1.094
[14,     4] loss: 1.114
[15,     4] loss: 1.100
[16,     4] loss: 1.061
[17,     4] loss: 1.000
[18,     4] loss: 0.979
[19,     4] loss: 0.922
[20,     4] loss: 0.937
[21,     4] loss: 0.929
[22,     4] loss: 0.863
[23,     4] loss: 0.919
[24,     4] loss: 0.871
[25,     4] loss: 0.873
[26,     4] loss: 0.865
[27,     4] loss: 0.820
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001177028035188756,
 'learning_rate_Hydroxylation-K': 0.004706987446592611,
 'learning_rate_Methylation-K': 0.006535593894142367,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.23969847565604296,
 'loss_weight_Methylation-K': 0.756443451603775,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3399844561,
 'sample_weights': [0.7389589649956803, 0.9846265540503608],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.606094698092148,
 'weight_decay_Hydroxylation-K': 8.57314735009129,
 'weight_decay_Methylation-K': 8.765339799763355}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.380
[2,     4] loss: 1.402
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015967830214121488,
 'learning_rate_Hydroxylation-K': 0.0008537097504360463,
 'learning_rate_Methylation-K': 0.007875378904579941,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.062390228815510845,
 'loss_weight_Methylation-K': 0.623088012171386,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1885130917,
 'sample_weights': [0.23969847565604296, 0.756443451603775],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.188655451358414,
 'weight_decay_Hydroxylation-K': 4.578466077485514,
 'weight_decay_Methylation-K': 7.690520867226976}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.385
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009174820596784265,
 'learning_rate_Hydroxylation-K': 0.004847578438643499,
 'learning_rate_Methylation-K': 0.0015058477109946146,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9041188314243805,
 'loss_weight_Methylation-K': 0.25268197301691764,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2617763176,
 'sample_weights': [0.062390228815510845, 0.623088012171386],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.883654758843403,
 'weight_decay_Hydroxylation-K': 3.303454730401354,
 'weight_decay_Methylation-K': 4.749518658418548}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.391
[3,     4] loss: 1.385
[4,     4] loss: 1.388
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.387
[9,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013078789025671067,
 'learning_rate_Hydroxylation-K': 0.005103623503407014,
 'learning_rate_Methylation-K': 0.008866718067130753,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.03237331355392123,
 'loss_weight_Methylation-K': 0.9875273814113523,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2340708150,
 'sample_weights': [0.9041188314243805, 0.25268197301691764],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5258869182272539,
 'weight_decay_Hydroxylation-K': 6.213060688707829,
 'weight_decay_Methylation-K': 8.334489787390654}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.380
[5,     4] loss: 1.368
[6,     4] loss: 1.363
[7,     4] loss: 1.356
[8,     4] loss: 1.326
[9,     4] loss: 1.304
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001781522809027521,
 'learning_rate_Hydroxylation-K': 0.0010031836949010555,
 'learning_rate_Methylation-K': 0.005118576006905604,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7845458212431623,
 'loss_weight_Methylation-K': 0.8427628009521939,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1592397010,
 'sample_weights': [0.03237331355392123, 0.9875273814113523],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7652937509290498,
 'weight_decay_Hydroxylation-K': 5.721485047440835,
 'weight_decay_Methylation-K': 0.5085999089532356}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.387
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004223303729957274,
 'learning_rate_Hydroxylation-K': 0.004003034557288577,
 'learning_rate_Methylation-K': 0.009696958014285852,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1063702804585969,
 'loss_weight_Methylation-K': 0.9490507402794996,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1159292497,
 'sample_weights': [0.7845458212431623, 0.8427628009521939],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.656355056492401,
 'weight_decay_Hydroxylation-K': 8.114293252233349,
 'weight_decay_Methylation-K': 9.089490041763659}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.388
[3,     4] loss: 1.382
[4,     4] loss: 1.391
[5,     4] loss: 1.390
[6,     4] loss: 1.387
[7,     4] loss: 1.379
[8,     4] loss: 1.364
[9,     4] loss: 1.330
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004595693862116392,
 'learning_rate_Hydroxylation-K': 0.006449530547541702,
 'learning_rate_Methylation-K': 0.009826919815019224,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6343248353699674,
 'loss_weight_Methylation-K': 0.7795561393891625,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1330713371,
 'sample_weights': [0.1063702804585969, 0.9490507402794996],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.170852801214373,
 'weight_decay_Hydroxylation-K': 3.7027010374606038,
 'weight_decay_Methylation-K': 4.932440832246094}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.385
[3,     4] loss: 1.383
[4,     4] loss: 1.390
[5,     4] loss: 1.388
[6,     4] loss: 1.385
[7,     4] loss: 1.384
[8,     4] loss: 1.384
[9,     4] loss: 1.371
[10,     4] loss: 1.337
[11,     4] loss: 1.249
[12,     4] loss: 1.236
[13,     4] loss: 1.147
[14,     4] loss: 1.095
[15,     4] loss: 1.051
[16,     4] loss: 1.129
[17,     4] loss: 1.053
[18,     4] loss: 0.999
[19,     4] loss: 1.096
[20,     4] loss: 1.038
[21,     4] loss: 1.078
[22,     4] loss: 0.976
[23,     4] loss: 0.871
[24,     4] loss: 0.940
[25,     4] loss: 0.897
[26,     4] loss: 0.943
[27,     4] loss: 1.005
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016995933476810494,
 'learning_rate_Hydroxylation-K': 0.00010487912981933268,
 'learning_rate_Methylation-K': 0.003512565149297618,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3626866029984381,
 'loss_weight_Methylation-K': 0.49308715230559497,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2834067176,
 'sample_weights': [0.6343248353699674, 0.7795561393891625],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.800240328022525,
 'weight_decay_Hydroxylation-K': 2.5497809800755493,
 'weight_decay_Methylation-K': 8.484418349090747}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.385
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00027114759802217693,
 'learning_rate_Hydroxylation-K': 0.006866414175770614,
 'learning_rate_Methylation-K': 0.0035172758855119544,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3939472121486255,
 'loss_weight_Methylation-K': 0.2896382920958911,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 90564563,
 'sample_weights': [0.3626866029984381, 0.49308715230559497],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.06378594519689,
 'weight_decay_Hydroxylation-K': 6.189326576373198,
 'weight_decay_Methylation-K': 6.744583771859382}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.386
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002141445427539449,
 'learning_rate_Hydroxylation-K': 0.0017133118347632224,
 'learning_rate_Methylation-K': 0.004728004413879458,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3661166005008343,
 'loss_weight_Methylation-K': 0.36575384882717143,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1502390519,
 'sample_weights': [0.3939472121486255, 0.2896382920958911],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.207841735900761,
 'weight_decay_Hydroxylation-K': 6.459158213720723,
 'weight_decay_Methylation-K': 8.590811702355564}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.389
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00023237319069120818,
 'learning_rate_Hydroxylation-K': 0.001074027450132993,
 'learning_rate_Methylation-K': 0.009642314311762802,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.15184141063623466,
 'loss_weight_Methylation-K': 0.8504620743112953,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1163352372,
 'sample_weights': [0.3661166005008343, 0.36575384882717143],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.5514130943238658,
 'weight_decay_Hydroxylation-K': 2.7781788615564333,
 'weight_decay_Methylation-K': 8.870958879818215}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.385
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001096141352921532,
 'learning_rate_Hydroxylation-K': 0.0030925172096168377,
 'learning_rate_Methylation-K': 0.009232773954728647,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.19660831378222418,
 'loss_weight_Methylation-K': 0.935390708872109,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2359303506,
 'sample_weights': [0.15184141063623466, 0.8504620743112953],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.557122441542315,
 'weight_decay_Hydroxylation-K': 6.505159194536201,
 'weight_decay_Methylation-K': 8.691546731524594}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.381
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.376
[5,     4] loss: 1.364
[6,     4] loss: 1.337
[7,     4] loss: 1.329
[8,     4] loss: 1.291
[9,     4] loss: 1.251
[10,     4] loss: 1.223
[11,     4] loss: 1.114
[12,     4] loss: 1.079
[13,     4] loss: 0.942
[14,     4] loss: 1.003
[15,     4] loss: 0.905
[16,     4] loss: 1.018
[17,     4] loss: 0.944
[18,     4] loss: 0.906
[19,     4] loss: 0.893
[20,     4] loss: 0.936
[21,     4] loss: 0.904
[22,     4] loss: 0.837
[23,     4] loss: 0.885
[24,     4] loss: 0.857
[25,     4] loss: 0.836
[26,     4] loss: 0.820
[27,     4] loss: 0.810
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003975628553164969,
 'learning_rate_Hydroxylation-K': 0.0010702385334452323,
 'learning_rate_Methylation-K': 0.007221860905756872,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3068160540417702,
 'loss_weight_Methylation-K': 0.08642339043644959,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4291507821,
 'sample_weights': [0.19660831378222418, 0.935390708872109],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.263879924350782,
 'weight_decay_Hydroxylation-K': 1.2615782380810998,
 'weight_decay_Methylation-K': 4.552562350283891}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.393
[3,     4] loss: 1.376
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014817992754716778,
 'learning_rate_Hydroxylation-K': 0.003419551849315399,
 'learning_rate_Methylation-K': 0.007264471206873159,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.08550586366454305,
 'loss_weight_Methylation-K': 0.9036593521466246,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2633316664,
 'sample_weights': [0.3068160540417702, 0.08642339043644959],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.908706979154366,
 'weight_decay_Hydroxylation-K': 6.817118896873509,
 'weight_decay_Methylation-K': 9.35209476580523}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.380
[2,     4] loss: 1.392
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024432559975186728,
 'learning_rate_Hydroxylation-K': 0.0026460631937223877,
 'learning_rate_Methylation-K': 0.009097634386333585,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.10496247888836818,
 'loss_weight_Methylation-K': 0.931705454202082,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 11526911,
 'sample_weights': [0.08550586366454305, 0.9036593521466246],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.0511163205880765,
 'weight_decay_Hydroxylation-K': 5.254852072989496,
 'weight_decay_Methylation-K': 8.556284807065156}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.389
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007113445553323083,
 'learning_rate_Hydroxylation-K': 0.0032263649551895843,
 'learning_rate_Methylation-K': 0.007640604674772583,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22134761502949296,
 'loss_weight_Methylation-K': 0.24000369662423685,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1762627752,
 'sample_weights': [0.10496247888836818, 0.931705454202082],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4222459266156937,
 'weight_decay_Hydroxylation-K': 8.374597846512476,
 'weight_decay_Methylation-K': 0.6572726203695982}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.400
[2,     4] loss: 1.386
[3,     4] loss: 1.387
[4,     4] loss: 1.388
[5,     4] loss: 1.389
[6,     4] loss: 1.386
[7,     4] loss: 1.387
[8,     4] loss: 1.386
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028813827959052185,
 'learning_rate_Hydroxylation-K': 0.0019744967887865,
 'learning_rate_Methylation-K': 0.009902178488848591,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2956165568015301,
 'loss_weight_Methylation-K': 0.19853797467780468,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2268698814,
 'sample_weights': [0.22134761502949296, 0.24000369662423685],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.3720270237732257,
 'weight_decay_Hydroxylation-K': 9.732504190883155,
 'weight_decay_Methylation-K': 1.3752522491045516}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.387
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.391
[6,     4] loss: 1.384
[7,     4] loss: 1.382
[8,     4] loss: 1.383
[9,     4] loss: 1.382
[10,     4] loss: 1.378
[11,     4] loss: 1.371
[12,     4] loss: 1.356
[13,     4] loss: 1.326
[14,     4] loss: 1.249
[15,     4] loss: 1.272
[16,     4] loss: 1.210
[17,     4] loss: 1.149
[18,     4] loss: 1.104
[19,     4] loss: 1.064
[20,     4] loss: 1.008
[21,     4] loss: 1.025
[22,     4] loss: 1.004
[23,     4] loss: 1.035
[24,     4] loss: 1.001
[25,     4] loss: 0.983
[26,     4] loss: 0.988
[27,     4] loss: 0.930
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007379612452894505,
 'learning_rate_Hydroxylation-K': 0.004821475245377374,
 'learning_rate_Methylation-K': 0.00855054322140606,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.36834350879537753,
 'loss_weight_Methylation-K': 0.9467976951597722,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2863730803,
 'sample_weights': [0.2956165568015301, 0.19853797467780468],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.491625584357733,
 'weight_decay_Hydroxylation-K': 2.609233135823408,
 'weight_decay_Methylation-K': 7.589437332836235}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.391
[3,     4] loss: 1.378
[4,     4] loss: 1.382
[5,     4] loss: 1.361
[6,     4] loss: 1.343
[7,     4] loss: 1.316
[8,     4] loss: 1.283
[9,     4] loss: 1.246
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0001668096339457587,
 'learning_rate_Hydroxylation-K': 0.0030058963739608667,
 'learning_rate_Methylation-K': 0.009875816399123107,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2159365894976402,
 'loss_weight_Methylation-K': 0.9721862838864735,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1080905525,
 'sample_weights': [0.36834350879537753, 0.9467976951597722],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.784715935488594,
 'weight_decay_Hydroxylation-K': 8.317913458519023,
 'weight_decay_Methylation-K': 8.59868228067108}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.388
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004250160209278225,
 'learning_rate_Hydroxylation-K': 0.00878513613004491,
 'learning_rate_Methylation-K': 0.0014527761775535832,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8390994480963001,
 'loss_weight_Methylation-K': 0.2997058447933801,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3782295321,
 'sample_weights': [0.2159365894976402, 0.9721862838864735],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.9426985988298355,
 'weight_decay_Hydroxylation-K': 7.245749466228089,
 'weight_decay_Methylation-K': 9.376359112036354}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.384
[3,     4] loss: 1.391
[4,     4] loss: 1.384
[5,     4] loss: 1.384
[6,     4] loss: 1.389
[7,     4] loss: 1.384
[8,     4] loss: 1.386
[9,     4] loss: 1.389
[10,     4] loss: 1.385
[11,     4] loss: 1.386
[12,     4] loss: 1.379
[13,     4] loss: 1.366
[14,     4] loss: 1.283
[15,     4] loss: 1.240
[16,     4] loss: 1.146
[17,     4] loss: 1.128
[18,     4] loss: 1.116
[19,     4] loss: 1.142
[20,     4] loss: 1.080
[21,     4] loss: 1.067
[22,     4] loss: 0.942
[23,     4] loss: 1.045
[24,     4] loss: 1.039
[25,     4] loss: 1.173
[26,     4] loss: 1.085
[27,     4] loss: 1.103
[28,     4] loss: 1.009
[29,     4] loss: 0.952
[30,     4] loss: 0.981
[31,     4] loss: 0.904
[32,     4] loss: 0.913
[33,     4] loss: 0.882
[34,     4] loss: 0.935
[35,     4] loss: 1.041
[36,     4] loss: 0.986
[37,     4] loss: 0.926
[38,     4] loss: 0.893
[39,     4] loss: 0.928
[40,     4] loss: 0.917
[41,     4] loss: 0.896
[42,     4] loss: 0.894
[43,     4] loss: 0.901
[44,     4] loss: 0.813
[45,     4] loss: 0.896
[46,     4] loss: 0.874
[47,     4] loss: 0.906
[48,     4] loss: 1.143
[49,     4] loss: 1.073
[50,     4] loss: 1.004
[51,     4] loss: 1.001
[52,     4] loss: 0.979
[53,     4] loss: 0.990
[54,     4] loss: 0.936
[55,     4] loss: 0.858
[56,     4] loss: 0.963
[57,     4] loss: 1.067
[58,     4] loss: 0.951
[59,     4] loss: 0.931
[60,     4] loss: 0.875
[61,     4] loss: 0.875
[62,     4] loss: 0.878
[63,     4] loss: 0.866
[64,     4] loss: 0.822
[65,     4] loss: 0.795
[66,     4] loss: 1.071
[67,     4] loss: 1.291
[68,     4] loss: 1.268
[69,     4] loss: 1.311
[70,     4] loss: 1.259
[71,     4] loss: 1.217
[72,     4] loss: 1.179
[73,     4] loss: 1.096
[74,     4] loss: 1.006
[75,     4] loss: 1.057
[76,     4] loss: 0.994
[77,     4] loss: 0.974
[78,     4] loss: 0.886
[79,     4] loss: 0.966
[80,     4] loss: 1.122
[81,     4] loss: 1.054
[82,     4] loss: 0.988
[83,     4] loss: 0.953
[84,     4] loss: 0.951
[85,     4] loss: 0.860
[86,     4] loss: 0.891
[87,     4] loss: 0.907
[88,     4] loss: 0.914
[89,     4] loss: 0.846
[90,     4] loss: 0.812
[91,     4] loss: 1.047
[92,     4] loss: 0.872
[93,     4] loss: 0.864
[94,     4] loss: 0.848
[95,     4] loss: 0.847
[96,     4] loss: 0.818
[97,     4] loss: 0.784
[98,     4] loss: 0.845
[99,     4] loss: 0.981
[100,     4] loss: 0.984
[101,     4] loss: 0.975
[102,     4] loss: 0.960
[103,     4] loss: 0.924
[104,     4] loss: 0.938
[105,     4] loss: 0.971
[106,     4] loss: 0.892
[107,     4] loss: 0.810
[108,     4] loss: 0.827
[109,     4] loss: 0.868
[110,     4] loss: 0.857
[111,     4] loss: 0.935
[112,     4] loss: 0.919
[113,     4] loss: 0.998
[114,     4] loss: 0.915
[115,     4] loss: 0.933
[116,     4] loss: 0.849
[117,     4] loss: 0.900
[118,     4] loss: 1.116
[119,     4] loss: 0.930
[120,     4] loss: 0.953
[121,     4] loss: 0.881
[122,     4] loss: 0.849
[123,     4] loss: 0.826
[124,     4] loss: 0.808
[125,     4] loss: 0.909
[126,     4] loss: 0.899
[127,     4] loss: 0.823
[128,     4] loss: 0.843
[129,     4] loss: 0.818
[130,     4] loss: 0.803
[131,     4] loss: 0.855
[132,     4] loss: 0.871
[133,     4] loss: 0.946
[134,     4] loss: 0.929
[135,     4] loss: 0.866
[136,     4] loss: 0.929
[137,     4] loss: 1.037
[138,     4] loss: 0.913
[139,     4] loss: 0.894
[140,     4] loss: 0.856
[141,     4] loss: 0.823
[142,     4] loss: 0.813
[143,     4] loss: 0.787
[144,     4] loss: 0.810
[145,     4] loss: 0.798
[146,     4] loss: 0.891
[147,     4] loss: 0.835
[148,     4] loss: 0.861
[149,     4] loss: 1.202
[150,     4] loss: 1.245
[151,     4] loss: 1.166
[152,     4] loss: 1.128
[153,     4] loss: 1.061
[154,     4] loss: 1.026
[155,     4] loss: 0.924
[156,     4] loss: 0.922
[157,     4] loss: 0.846
[158,     4] loss: 1.009
[159,     4] loss: 1.044
[160,     4] loss: 0.950
[161,     4] loss: 0.913
[162,     4] loss: 0.894
[163,     4] loss: 0.813
[164,     4] loss: 0.877
[165,     4] loss: 0.835
[166,     4] loss: 0.993
[167,     4] loss: 0.960
[168,     4] loss: 0.949
[169,     4] loss: 0.866
[170,     4] loss: 0.871
[171,     4] loss: 0.816
[172,     4] loss: 0.816
[173,     4] loss: 0.858
[174,     4] loss: 0.829
[175,     4] loss: 0.883
[176,     4] loss: 0.889
[177,     4] loss: 0.857
[178,     4] loss: 0.915
[179,     4] loss: 0.912
[180,     4] loss: 0.851
[181,     4] loss: 0.873
[182,     4] loss: 0.874
[183,     4] loss: 0.868
[184,     4] loss: 0.826
[185,     4] loss: 0.939
[186,     4] loss: 0.893
[187,     4] loss: 0.811
[188,     4] loss: 0.779
[189,     4] loss: 0.820
[190,     4] loss: 0.834
[191,     4] loss: 1.235
[192,     4] loss: 1.251
[193,     4] loss: 1.197
[194,     4] loss: 1.101
[195,     4] loss: 1.010
[196,     4] loss: 0.925
[197,     4] loss: 0.931
[198,     4] loss: 1.081
[199,     4] loss: 1.022
[200,     4] loss: 1.045
Finished Training
Total time taken: 100.83578300476074
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.394
[3,     4] loss: 1.390
[4,     4] loss: 1.387
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.385
[8,     4] loss: 1.388
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.387
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.386
[16,     4] loss: 1.386
[17,     4] loss: 1.383
[18,     4] loss: 1.380
[19,     4] loss: 1.368
[20,     4] loss: 1.324
[21,     4] loss: 1.330
[22,     4] loss: 1.294
[23,     4] loss: 1.186
[24,     4] loss: 1.125
[25,     4] loss: 1.170
[26,     4] loss: 1.240
[27,     4] loss: 1.153
[28,     4] loss: 1.133
[29,     4] loss: 1.081
[30,     4] loss: 0.953
[31,     4] loss: 0.900
[32,     4] loss: 1.054
[33,     4] loss: 1.039
[34,     4] loss: 1.066
[35,     4] loss: 1.049
[36,     4] loss: 0.893
[37,     4] loss: 0.871
[38,     4] loss: 1.006
[39,     4] loss: 0.872
[40,     4] loss: 0.924
[41,     4] loss: 0.862
[42,     4] loss: 0.802
[43,     4] loss: 0.789
[44,     4] loss: 0.894
[45,     4] loss: 0.858
[46,     4] loss: 0.816
[47,     4] loss: 0.786
[48,     4] loss: 0.871
[49,     4] loss: 0.813
[50,     4] loss: 0.834
[51,     4] loss: 0.913
[52,     4] loss: 0.809
[53,     4] loss: 0.814
[54,     4] loss: 0.778
[55,     4] loss: 0.756
[56,     4] loss: 0.748
[57,     4] loss: 0.757
[58,     4] loss: 0.769
[59,     4] loss: 0.959
[60,     4] loss: 0.879
[61,     4] loss: 0.847
[62,     4] loss: 0.869
[63,     4] loss: 0.838
[64,     4] loss: 0.851
[65,     4] loss: 0.816
[66,     4] loss: 0.827
[67,     4] loss: 0.828
[68,     4] loss: 0.784
[69,     4] loss: 0.791
[70,     4] loss: 0.750
[71,     4] loss: 0.774
[72,     4] loss: 0.786
[73,     4] loss: 0.852
[74,     4] loss: 0.805
[75,     4] loss: 1.075
[76,     4] loss: 0.990
[77,     4] loss: 1.010
[78,     4] loss: 0.960
[79,     4] loss: 0.884
[80,     4] loss: 0.819
[81,     4] loss: 0.854
[82,     4] loss: 0.835
[83,     4] loss: 0.787
[84,     4] loss: 1.001
[85,     4] loss: 0.990
[86,     4] loss: 0.870
[87,     4] loss: 0.838
[88,     4] loss: 0.803
[89,     4] loss: 0.778
[90,     4] loss: 0.778
[91,     4] loss: 0.791
[92,     4] loss: 0.830
[93,     4] loss: 0.839
[94,     4] loss: 0.812
[95,     4] loss: 0.784
[96,     4] loss: 0.779
[97,     4] loss: 0.791
[98,     4] loss: 0.790
[99,     4] loss: 0.803
[100,     4] loss: 1.108
[101,     4] loss: 1.004
[102,     4] loss: 0.954
[103,     4] loss: 0.922
[104,     4] loss: 0.825
[105,     4] loss: 0.821
[106,     4] loss: 0.790
[107,     4] loss: 0.821
[108,     4] loss: 0.857
[109,     4] loss: 0.833
[110,     4] loss: 0.892
Early stopping applied (best metric=0.4117226302623749)
Finished Training
Total time taken: 55.644150495529175
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.382
[3,     4] loss: 1.395
[4,     4] loss: 1.381
[5,     4] loss: 1.384
[6,     4] loss: 1.380
[7,     4] loss: 1.388
[8,     4] loss: 1.381
[9,     4] loss: 1.377
[10,     4] loss: 1.366
[11,     4] loss: 1.322
[12,     4] loss: 1.231
[13,     4] loss: 1.124
[14,     4] loss: 1.212
[15,     4] loss: 1.099
[16,     4] loss: 1.041
[17,     4] loss: 1.119
[18,     4] loss: 1.067
[19,     4] loss: 1.084
[20,     4] loss: 0.985
[21,     4] loss: 0.960
[22,     4] loss: 0.952
[23,     4] loss: 1.004
[24,     4] loss: 1.125
[25,     4] loss: 1.093
[26,     4] loss: 1.024
[27,     4] loss: 0.956
[28,     4] loss: 0.932
[29,     4] loss: 0.928
[30,     4] loss: 0.901
[31,     4] loss: 0.886
[32,     4] loss: 1.095
[33,     4] loss: 1.151
[34,     4] loss: 1.055
[35,     4] loss: 0.992
[36,     4] loss: 1.087
[37,     4] loss: 0.997
[38,     4] loss: 0.946
[39,     4] loss: 0.945
[40,     4] loss: 0.855
[41,     4] loss: 0.793
[42,     4] loss: 0.912
[43,     4] loss: 0.843
[44,     4] loss: 0.867
[45,     4] loss: 0.898
[46,     4] loss: 0.907
[47,     4] loss: 0.871
[48,     4] loss: 0.869
[49,     4] loss: 0.881
[50,     4] loss: 0.915
[51,     4] loss: 0.902
[52,     4] loss: 1.059
[53,     4] loss: 0.960
[54,     4] loss: 0.916
[55,     4] loss: 0.859
[56,     4] loss: 0.814
[57,     4] loss: 0.835
[58,     4] loss: 0.913
[59,     4] loss: 0.982
[60,     4] loss: 0.937
[61,     4] loss: 0.882
[62,     4] loss: 0.853
[63,     4] loss: 0.839
[64,     4] loss: 0.818
[65,     4] loss: 0.813
[66,     4] loss: 0.826
[67,     4] loss: 0.826
Early stopping applied (best metric=0.4615805745124817)
Finished Training
Total time taken: 33.7120885848999
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.390
[3,     4] loss: 1.385
[4,     4] loss: 1.389
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.387
[8,     4] loss: 1.385
[9,     4] loss: 1.383
[10,     4] loss: 1.386
[11,     4] loss: 1.384
[12,     4] loss: 1.384
[13,     4] loss: 1.373
[14,     4] loss: 1.344
[15,     4] loss: 1.304
[16,     4] loss: 1.207
[17,     4] loss: 1.194
[18,     4] loss: 1.118
[19,     4] loss: 1.176
[20,     4] loss: 1.157
[21,     4] loss: 1.117
[22,     4] loss: 1.161
[23,     4] loss: 1.087
[24,     4] loss: 1.025
[25,     4] loss: 0.993
[26,     4] loss: 0.967
[27,     4] loss: 1.034
[28,     4] loss: 1.091
[29,     4] loss: 1.036
[30,     4] loss: 0.988
[31,     4] loss: 1.094
[32,     4] loss: 0.946
[33,     4] loss: 1.048
[34,     4] loss: 0.881
[35,     4] loss: 0.866
[36,     4] loss: 0.976
[37,     4] loss: 0.972
[38,     4] loss: 0.908
[39,     4] loss: 0.907
[40,     4] loss: 0.836
[41,     4] loss: 0.852
[42,     4] loss: 0.868
[43,     4] loss: 0.863
[44,     4] loss: 0.923
[45,     4] loss: 0.828
[46,     4] loss: 0.898
[47,     4] loss: 0.907
[48,     4] loss: 0.973
[49,     4] loss: 0.871
[50,     4] loss: 0.810
[51,     4] loss: 0.861
[52,     4] loss: 0.868
[53,     4] loss: 0.839
[54,     4] loss: 0.875
[55,     4] loss: 0.887
[56,     4] loss: 0.918
[57,     4] loss: 0.838
[58,     4] loss: 0.828
[59,     4] loss: 0.791
[60,     4] loss: 0.831
[61,     4] loss: 1.063
[62,     4] loss: 1.000
[63,     4] loss: 0.954
[64,     4] loss: 0.922
[65,     4] loss: 0.860
[66,     4] loss: 0.885
[67,     4] loss: 0.844
[68,     4] loss: 0.812
[69,     4] loss: 0.781
[70,     4] loss: 0.931
[71,     4] loss: 0.921
[72,     4] loss: 0.855
[73,     4] loss: 0.835
[74,     4] loss: 0.841
[75,     4] loss: 0.826
[76,     4] loss: 0.821
[77,     4] loss: 0.792
[78,     4] loss: 0.935
[79,     4] loss: 0.988
[80,     4] loss: 0.947
[81,     4] loss: 0.995
[82,     4] loss: 0.903
[83,     4] loss: 0.891
[84,     4] loss: 0.831
[85,     4] loss: 0.878
[86,     4] loss: 0.902
[87,     4] loss: 0.852
[88,     4] loss: 0.877
[89,     4] loss: 0.858
[90,     4] loss: 0.799
[91,     4] loss: 0.809
[92,     4] loss: 0.793
[93,     4] loss: 0.786
[94,     4] loss: 0.791
[95,     4] loss: 1.030
[96,     4] loss: 1.100
[97,     4] loss: 0.969
[98,     4] loss: 0.953
[99,     4] loss: 0.955
[100,     4] loss: 0.965
[101,     4] loss: 0.904
[102,     4] loss: 0.868
[103,     4] loss: 0.845
[104,     4] loss: 0.812
[105,     4] loss: 0.899
[106,     4] loss: 1.006
[107,     4] loss: 1.105
[108,     4] loss: 1.051
[109,     4] loss: 0.911
[110,     4] loss: 0.816
[111,     4] loss: 0.853
[112,     4] loss: 0.837
[113,     4] loss: 0.813
[114,     4] loss: 0.776
[115,     4] loss: 0.797
[116,     4] loss: 0.772
[117,     4] loss: 0.751
[118,     4] loss: 0.979
[119,     4] loss: 1.029
[120,     4] loss: 1.047
[121,     4] loss: 1.010
[122,     4] loss: 0.986
[123,     4] loss: 1.019
[124,     4] loss: 0.915
[125,     4] loss: 0.848
[126,     4] loss: 0.853
[127,     4] loss: 0.771
[128,     4] loss: 0.782
[129,     4] loss: 0.783
[130,     4] loss: 0.867
[131,     4] loss: 0.858
[132,     4] loss: 0.869
[133,     4] loss: 0.845
[134,     4] loss: 0.819
[135,     4] loss: 0.826
[136,     4] loss: 0.846
[137,     4] loss: 0.965
[138,     4] loss: 0.854
[139,     4] loss: 0.839
[140,     4] loss: 0.806
[141,     4] loss: 0.782
[142,     4] loss: 0.783
[143,     4] loss: 0.772
[144,     4] loss: 0.816
[145,     4] loss: 0.841
[146,     4] loss: 0.803
[147,     4] loss: 0.923
[148,     4] loss: 1.049
[149,     4] loss: 1.013
[150,     4] loss: 0.929
[151,     4] loss: 0.845
[152,     4] loss: 0.857
[153,     4] loss: 0.820
[154,     4] loss: 0.851
[155,     4] loss: 0.849
[156,     4] loss: 0.917
[157,     4] loss: 0.836
[158,     4] loss: 0.880
[159,     4] loss: 0.838
[160,     4] loss: 0.876
[161,     4] loss: 0.857
[162,     4] loss: 0.791
[163,     4] loss: 0.786
[164,     4] loss: 0.750
[165,     4] loss: 0.765
[166,     4] loss: 0.852
[167,     4] loss: 0.919
[168,     4] loss: 0.848
[169,     4] loss: 0.882
[170,     4] loss: 0.863
[171,     4] loss: 0.819
[172,     4] loss: 0.799
[173,     4] loss: 0.846
Early stopping applied (best metric=0.3286624252796173)
Finished Training
Total time taken: 87.31223702430725
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.375
[2,     4] loss: 1.391
[3,     4] loss: 1.385
[4,     4] loss: 1.389
[5,     4] loss: 1.385
[6,     4] loss: 1.388
[7,     4] loss: 1.381
[8,     4] loss: 1.385
[9,     4] loss: 1.384
[10,     4] loss: 1.382
[11,     4] loss: 1.369
[12,     4] loss: 1.341
[13,     4] loss: 1.286
[14,     4] loss: 1.228
[15,     4] loss: 1.203
[16,     4] loss: 1.172
[17,     4] loss: 1.124
[18,     4] loss: 1.107
[19,     4] loss: 1.085
[20,     4] loss: 1.091
[21,     4] loss: 1.050
[22,     4] loss: 1.018
[23,     4] loss: 0.994
[24,     4] loss: 1.072
[25,     4] loss: 0.991
[26,     4] loss: 0.955
[27,     4] loss: 0.887
[28,     4] loss: 0.886
[29,     4] loss: 0.939
[30,     4] loss: 0.990
[31,     4] loss: 0.957
[32,     4] loss: 0.949
[33,     4] loss: 0.853
[34,     4] loss: 0.892
[35,     4] loss: 0.839
[36,     4] loss: 0.970
[37,     4] loss: 0.938
[38,     4] loss: 0.886
[39,     4] loss: 0.857
[40,     4] loss: 0.874
[41,     4] loss: 0.859
[42,     4] loss: 0.857
[43,     4] loss: 0.935
[44,     4] loss: 1.008
[45,     4] loss: 0.960
[46,     4] loss: 0.978
[47,     4] loss: 0.900
[48,     4] loss: 0.987
[49,     4] loss: 1.017
[50,     4] loss: 0.960
[51,     4] loss: 0.963
[52,     4] loss: 0.948
[53,     4] loss: 0.895
[54,     4] loss: 0.882
[55,     4] loss: 0.935
[56,     4] loss: 0.909
[57,     4] loss: 0.973
[58,     4] loss: 0.887
[59,     4] loss: 0.919
[60,     4] loss: 0.926
[61,     4] loss: 0.873
[62,     4] loss: 0.856
[63,     4] loss: 0.807
[64,     4] loss: 1.145
[65,     4] loss: 1.238
[66,     4] loss: 1.233
[67,     4] loss: 1.239
[68,     4] loss: 1.201
[69,     4] loss: 1.168
[70,     4] loss: 1.135
[71,     4] loss: 1.101
[72,     4] loss: 1.171
[73,     4] loss: 1.149
[74,     4] loss: 1.059
[75,     4] loss: 1.090
[76,     4] loss: 1.021
[77,     4] loss: 1.023
[78,     4] loss: 0.996
[79,     4] loss: 0.943
[80,     4] loss: 0.943
[81,     4] loss: 1.009
[82,     4] loss: 1.046
[83,     4] loss: 0.992
[84,     4] loss: 0.925
[85,     4] loss: 0.920
[86,     4] loss: 0.861
[87,     4] loss: 0.945
[88,     4] loss: 0.921
[89,     4] loss: 1.002
[90,     4] loss: 0.967
[91,     4] loss: 0.987
[92,     4] loss: 0.952
[93,     4] loss: 0.954
[94,     4] loss: 0.892
[95,     4] loss: 0.854
[96,     4] loss: 0.874
[97,     4] loss: 0.907
[98,     4] loss: 0.953
[99,     4] loss: 0.895
[100,     4] loss: 0.897
[101,     4] loss: 0.883
[102,     4] loss: 0.919
[103,     4] loss: 0.838
[104,     4] loss: 0.808
[105,     4] loss: 0.804
[106,     4] loss: 0.810
[107,     4] loss: 1.058
[108,     4] loss: 0.975
[109,     4] loss: 0.885
[110,     4] loss: 0.808
[111,     4] loss: 0.781
[112,     4] loss: 0.869
[113,     4] loss: 0.927
[114,     4] loss: 0.880
[115,     4] loss: 0.874
[116,     4] loss: 0.845
[117,     4] loss: 0.812
[118,     4] loss: 0.888
[119,     4] loss: 0.835
[120,     4] loss: 0.823
[121,     4] loss: 0.868
[122,     4] loss: 0.942
[123,     4] loss: 0.960
[124,     4] loss: 0.854
[125,     4] loss: 0.853
[126,     4] loss: 0.801
[127,     4] loss: 0.821
[128,     4] loss: 0.892
[129,     4] loss: 0.920
[130,     4] loss: 0.907
[131,     4] loss: 0.908
[132,     4] loss: 0.878
[133,     4] loss: 0.880
[134,     4] loss: 0.881
[135,     4] loss: 0.845
[136,     4] loss: 0.822
[137,     4] loss: 1.280
[138,     4] loss: 1.054
[139,     4] loss: 1.058
[140,     4] loss: 0.992
[141,     4] loss: 0.898
[142,     4] loss: 0.916
[143,     4] loss: 0.852
[144,     4] loss: 0.861
[145,     4] loss: 0.884
[146,     4] loss: 0.912
[147,     4] loss: 0.961
[148,     4] loss: 0.900
[149,     4] loss: 0.857
[150,     4] loss: 0.822
Early stopping applied (best metric=0.39863744378089905)
Finished Training
Total time taken: 75.74020576477051
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.385
[3,     4] loss: 1.387
[4,     4] loss: 1.388
[5,     4] loss: 1.388
[6,     4] loss: 1.386
[7,     4] loss: 1.384
[8,     4] loss: 1.389
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.387
[12,     4] loss: 1.387
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.387
[16,     4] loss: 1.386
[17,     4] loss: 1.386
[18,     4] loss: 1.386
[19,     4] loss: 1.386
[20,     4] loss: 1.386
[21,     4] loss: 1.386
[22,     4] loss: 1.386
[23,     4] loss: 1.386
[24,     4] loss: 1.387
[25,     4] loss: 1.386
[26,     4] loss: 1.386
[27,     4] loss: 1.386
[28,     4] loss: 1.387
[29,     4] loss: 1.386
[30,     4] loss: 1.386
[31,     4] loss: 1.386
[32,     4] loss: 1.386
[33,     4] loss: 1.386
[34,     4] loss: 1.386
[35,     4] loss: 1.386
[36,     4] loss: 1.386
[37,     4] loss: 1.387
[38,     4] loss: 1.387
[39,     4] loss: 1.386
[40,     4] loss: 1.386
[41,     4] loss: 1.386
[42,     4] loss: 1.386
[43,     4] loss: 1.386
[44,     4] loss: 1.386
[45,     4] loss: 1.386
[46,     4] loss: 1.386
[47,     4] loss: 1.386
[48,     4] loss: 1.387
[49,     4] loss: 1.386
[50,     4] loss: 1.386
[51,     4] loss: 1.387
[52,     4] loss: 1.387
Early stopping applied (best metric=0.5622824430465698)
Finished Training
Total time taken: 26.42412829399109
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.391
[3,     4] loss: 1.393
[4,     4] loss: 1.387
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.381
[9,     4] loss: 1.380
[10,     4] loss: 1.390
[11,     4] loss: 1.381
[12,     4] loss: 1.374
[13,     4] loss: 1.350
[14,     4] loss: 1.277
[15,     4] loss: 1.231
[16,     4] loss: 1.202
[17,     4] loss: 1.127
[18,     4] loss: 1.057
[19,     4] loss: 1.145
[20,     4] loss: 1.193
[21,     4] loss: 1.158
[22,     4] loss: 1.046
[23,     4] loss: 1.050
[24,     4] loss: 1.006
[25,     4] loss: 1.024
[26,     4] loss: 1.003
[27,     4] loss: 0.986
[28,     4] loss: 0.940
[29,     4] loss: 0.891
[30,     4] loss: 1.051
[31,     4] loss: 0.908
[32,     4] loss: 0.960
[33,     4] loss: 1.045
[34,     4] loss: 1.144
[35,     4] loss: 1.023
[36,     4] loss: 0.984
[37,     4] loss: 0.917
[38,     4] loss: 0.871
[39,     4] loss: 0.908
[40,     4] loss: 0.853
[41,     4] loss: 0.915
[42,     4] loss: 0.929
[43,     4] loss: 0.990
[44,     4] loss: 0.985
[45,     4] loss: 0.899
[46,     4] loss: 0.865
[47,     4] loss: 0.803
[48,     4] loss: 0.910
[49,     4] loss: 1.081
[50,     4] loss: 1.056
[51,     4] loss: 1.044
[52,     4] loss: 1.041
[53,     4] loss: 0.930
[54,     4] loss: 0.906
[55,     4] loss: 0.848
[56,     4] loss: 0.818
[57,     4] loss: 0.816
[58,     4] loss: 0.805
[59,     4] loss: 0.887
[60,     4] loss: 1.166
[61,     4] loss: 1.111
[62,     4] loss: 1.078
[63,     4] loss: 0.985
[64,     4] loss: 0.948
[65,     4] loss: 0.885
[66,     4] loss: 0.856
[67,     4] loss: 0.928
[68,     4] loss: 0.892
[69,     4] loss: 0.879
[70,     4] loss: 0.903
[71,     4] loss: 1.061
Early stopping applied (best metric=0.40600427985191345)
Finished Training
Total time taken: 36.01009964942932
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.387
[3,     4] loss: 1.384
[4,     4] loss: 1.383
[5,     4] loss: 1.386
[6,     4] loss: 1.386
[7,     4] loss: 1.382
[8,     4] loss: 1.375
[9,     4] loss: 1.347
[10,     4] loss: 1.300
[11,     4] loss: 1.249
[12,     4] loss: 1.225
[13,     4] loss: 1.216
[14,     4] loss: 1.075
[15,     4] loss: 1.063
[16,     4] loss: 1.089
[17,     4] loss: 1.126
[18,     4] loss: 1.070
[19,     4] loss: 1.028
[20,     4] loss: 0.965
[21,     4] loss: 0.978
[22,     4] loss: 0.905
[23,     4] loss: 0.901
[24,     4] loss: 0.859
[25,     4] loss: 0.933
[26,     4] loss: 0.873
[27,     4] loss: 0.867
[28,     4] loss: 0.839
[29,     4] loss: 0.858
[30,     4] loss: 0.797
[31,     4] loss: 0.840
[32,     4] loss: 0.998
[33,     4] loss: 1.027
[34,     4] loss: 0.950
[35,     4] loss: 0.932
[36,     4] loss: 0.860
[37,     4] loss: 0.834
[38,     4] loss: 0.828
[39,     4] loss: 0.794
[40,     4] loss: 0.863
[41,     4] loss: 0.930
[42,     4] loss: 0.945
[43,     4] loss: 0.937
[44,     4] loss: 1.016
[45,     4] loss: 0.933
[46,     4] loss: 1.010
[47,     4] loss: 0.976
[48,     4] loss: 0.873
[49,     4] loss: 0.815
[50,     4] loss: 0.789
[51,     4] loss: 0.776
[52,     4] loss: 0.811
[53,     4] loss: 0.792
[54,     4] loss: 0.803
[55,     4] loss: 0.827
[56,     4] loss: 1.045
[57,     4] loss: 1.020
[58,     4] loss: 0.994
[59,     4] loss: 0.900
[60,     4] loss: 0.851
[61,     4] loss: 0.865
[62,     4] loss: 0.819
[63,     4] loss: 0.813
[64,     4] loss: 0.949
[65,     4] loss: 0.928
[66,     4] loss: 0.902
[67,     4] loss: 0.839
[68,     4] loss: 0.890
Early stopping applied (best metric=0.39655792713165283)
Finished Training
Total time taken: 34.244091510772705
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.381
[3,     4] loss: 1.391
[4,     4] loss: 1.386
[5,     4] loss: 1.382
[6,     4] loss: 1.384
[7,     4] loss: 1.377
[8,     4] loss: 1.374
[9,     4] loss: 1.345
[10,     4] loss: 1.301
[11,     4] loss: 1.213
[12,     4] loss: 1.198
[13,     4] loss: 1.277
[14,     4] loss: 1.217
[15,     4] loss: 1.249
[16,     4] loss: 1.144
[17,     4] loss: 1.197
[18,     4] loss: 1.070
[19,     4] loss: 1.014
[20,     4] loss: 1.075
[21,     4] loss: 1.132
[22,     4] loss: 1.103
[23,     4] loss: 1.010
[24,     4] loss: 1.023
[25,     4] loss: 0.964
[26,     4] loss: 0.953
[27,     4] loss: 0.896
[28,     4] loss: 0.880
[29,     4] loss: 1.075
[30,     4] loss: 1.024
[31,     4] loss: 1.022
[32,     4] loss: 1.032
[33,     4] loss: 0.894
[34,     4] loss: 0.837
[35,     4] loss: 0.843
[36,     4] loss: 0.863
[37,     4] loss: 0.909
[38,     4] loss: 1.025
[39,     4] loss: 1.012
[40,     4] loss: 0.988
[41,     4] loss: 0.923
[42,     4] loss: 0.952
[43,     4] loss: 0.956
[44,     4] loss: 1.043
[45,     4] loss: 0.955
[46,     4] loss: 0.864
[47,     4] loss: 0.876
[48,     4] loss: 0.861
[49,     4] loss: 0.846
[50,     4] loss: 0.832
[51,     4] loss: 0.994
[52,     4] loss: 0.880
[53,     4] loss: 0.871
[54,     4] loss: 0.875
[55,     4] loss: 0.850
[56,     4] loss: 0.904
[57,     4] loss: 1.164
[58,     4] loss: 1.043
[59,     4] loss: 0.954
[60,     4] loss: 0.885
[61,     4] loss: 0.912
[62,     4] loss: 1.010
[63,     4] loss: 0.950
[64,     4] loss: 0.889
[65,     4] loss: 0.861
[66,     4] loss: 0.829
[67,     4] loss: 0.992
[68,     4] loss: 0.923
[69,     4] loss: 0.962
[70,     4] loss: 0.898
[71,     4] loss: 0.885
[72,     4] loss: 0.950
[73,     4] loss: 0.909
[74,     4] loss: 0.856
[75,     4] loss: 0.837
[76,     4] loss: 0.826
[77,     4] loss: 0.902
[78,     4] loss: 0.870
[79,     4] loss: 0.917
[80,     4] loss: 0.860
[81,     4] loss: 0.924
[82,     4] loss: 1.031
[83,     4] loss: 1.033
[84,     4] loss: 0.943
[85,     4] loss: 0.928
[86,     4] loss: 0.870
[87,     4] loss: 0.829
[88,     4] loss: 0.877
[89,     4] loss: 0.833
[90,     4] loss: 0.891
[91,     4] loss: 0.825
[92,     4] loss: 0.810
Early stopping applied (best metric=0.35821017622947693)
Finished Training
Total time taken: 46.98212718963623
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.393
[2,     4] loss: 1.390
[3,     4] loss: 1.386
[4,     4] loss: 1.388
[5,     4] loss: 1.387
[6,     4] loss: 1.387
[7,     4] loss: 1.386
[8,     4] loss: 1.387
[9,     4] loss: 1.386
[10,     4] loss: 1.386
[11,     4] loss: 1.387
[12,     4] loss: 1.386
[13,     4] loss: 1.386
[14,     4] loss: 1.386
[15,     4] loss: 1.384
[16,     4] loss: 1.381
[17,     4] loss: 1.361
[18,     4] loss: 1.301
[19,     4] loss: 1.343
[20,     4] loss: 1.225
[21,     4] loss: 1.231
[22,     4] loss: 1.183
[23,     4] loss: 1.161
[24,     4] loss: 1.156
[25,     4] loss: 1.098
[26,     4] loss: 1.060
[27,     4] loss: 1.048
[28,     4] loss: 1.087
[29,     4] loss: 1.075
[30,     4] loss: 0.963
[31,     4] loss: 0.932
[32,     4] loss: 1.129
[33,     4] loss: 1.053
[34,     4] loss: 1.072
[35,     4] loss: 0.971
[36,     4] loss: 0.945
[37,     4] loss: 0.955
[38,     4] loss: 0.972
[39,     4] loss: 0.881
[40,     4] loss: 0.967
[41,     4] loss: 0.872
[42,     4] loss: 0.951
[43,     4] loss: 0.948
[44,     4] loss: 0.863
[45,     4] loss: 0.871
[46,     4] loss: 0.999
[47,     4] loss: 0.978
[48,     4] loss: 0.953
[49,     4] loss: 0.905
[50,     4] loss: 0.847
[51,     4] loss: 0.931
[52,     4] loss: 0.911
[53,     4] loss: 0.915
[54,     4] loss: 0.859
[55,     4] loss: 0.846
[56,     4] loss: 0.844
[57,     4] loss: 0.816
[58,     4] loss: 0.852
[59,     4] loss: 0.870
[60,     4] loss: 0.810
[61,     4] loss: 0.802
[62,     4] loss: 0.823
[63,     4] loss: 0.896
[64,     4] loss: 0.861
[65,     4] loss: 0.804
[66,     4] loss: 0.976
[67,     4] loss: 1.083
[68,     4] loss: 1.053
[69,     4] loss: 1.061
[70,     4] loss: 0.977
[71,     4] loss: 0.875
[72,     4] loss: 0.864
[73,     4] loss: 0.831
[74,     4] loss: 0.828
[75,     4] loss: 0.783
[76,     4] loss: 0.773
[77,     4] loss: 0.876
[78,     4] loss: 0.846
[79,     4] loss: 0.886
[80,     4] loss: 0.935
[81,     4] loss: 0.839
[82,     4] loss: 0.871
[83,     4] loss: 0.844
[84,     4] loss: 0.813
[85,     4] loss: 0.837
[86,     4] loss: 0.819
[87,     4] loss: 0.833
[88,     4] loss: 0.966
[89,     4] loss: 1.075
[90,     4] loss: 1.051
[91,     4] loss: 0.939
[92,     4] loss: 0.966
[93,     4] loss: 1.020
[94,     4] loss: 1.034
[95,     4] loss: 0.991
[96,     4] loss: 0.972
[97,     4] loss: 0.889
[98,     4] loss: 0.826
[99,     4] loss: 0.780
[100,     4] loss: 0.778
[101,     4] loss: 0.766
[102,     4] loss: 0.838
[103,     4] loss: 0.985
[104,     4] loss: 0.900
[105,     4] loss: 0.904
[106,     4] loss: 0.857
[107,     4] loss: 0.859
[108,     4] loss: 0.893
[109,     4] loss: 0.857
[110,     4] loss: 0.917
[111,     4] loss: 0.909
[112,     4] loss: 0.851
[113,     4] loss: 0.903
[114,     4] loss: 0.842
[115,     4] loss: 0.812
[116,     4] loss: 0.837
[117,     4] loss: 0.798
[118,     4] loss: 0.770
[119,     4] loss: 0.803
Early stopping applied (best metric=0.4034441411495209)
Finished Training
Total time taken: 59.91516065597534
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.385
[3,     4] loss: 1.385
[4,     4] loss: 1.388
[5,     4] loss: 1.388
[6,     4] loss: 1.385
[7,     4] loss: 1.383
[8,     4] loss: 1.385
[9,     4] loss: 1.381
[10,     4] loss: 1.373
[11,     4] loss: 1.339
[12,     4] loss: 1.295
[13,     4] loss: 1.266
[14,     4] loss: 1.195
[15,     4] loss: 1.178
[16,     4] loss: 1.155
[17,     4] loss: 1.218
[18,     4] loss: 1.126
[19,     4] loss: 1.117
[20,     4] loss: 1.070
[21,     4] loss: 0.993
[22,     4] loss: 0.891
[23,     4] loss: 0.955
[24,     4] loss: 1.018
[25,     4] loss: 0.986
[26,     4] loss: 0.983
[27,     4] loss: 1.021
[28,     4] loss: 0.914
[29,     4] loss: 0.875
[30,     4] loss: 0.931
[31,     4] loss: 0.986
[32,     4] loss: 1.060
[33,     4] loss: 1.063
[34,     4] loss: 1.102
[35,     4] loss: 1.009
[36,     4] loss: 0.991
[37,     4] loss: 0.890
[38,     4] loss: 0.880
[39,     4] loss: 0.885
[40,     4] loss: 0.830
[41,     4] loss: 0.922
[42,     4] loss: 0.850
[43,     4] loss: 0.815
[44,     4] loss: 0.798
[45,     4] loss: 1.197
[46,     4] loss: 1.061
[47,     4] loss: 1.043
[48,     4] loss: 0.932
[49,     4] loss: 0.939
[50,     4] loss: 0.878
[51,     4] loss: 0.853
[52,     4] loss: 0.817
[53,     4] loss: 0.858
[54,     4] loss: 0.855
[55,     4] loss: 1.112
[56,     4] loss: 1.210
[57,     4] loss: 1.200
[58,     4] loss: 1.100
[59,     4] loss: 1.018
[60,     4] loss: 0.925
[61,     4] loss: 0.934
[62,     4] loss: 0.837
[63,     4] loss: 0.930
[64,     4] loss: 0.842
[65,     4] loss: 0.799
[66,     4] loss: 0.757
[67,     4] loss: 1.090
[68,     4] loss: 0.962
[69,     4] loss: 0.990
[70,     4] loss: 0.986
[71,     4] loss: 1.008
[72,     4] loss: 0.887
[73,     4] loss: 0.860
[74,     4] loss: 0.905
[75,     4] loss: 0.857
[76,     4] loss: 0.832
[77,     4] loss: 0.883
[78,     4] loss: 0.931
[79,     4] loss: 0.888
[80,     4] loss: 0.865
[81,     4] loss: 0.974
[82,     4] loss: 1.003
[83,     4] loss: 1.030
[84,     4] loss: 0.952
[85,     4] loss: 1.063
[86,     4] loss: 0.915
[87,     4] loss: 0.939
[88,     4] loss: 0.935
[89,     4] loss: 0.854
[90,     4] loss: 0.835
[91,     4] loss: 0.862
[92,     4] loss: 0.893
[93,     4] loss: 0.894
[94,     4] loss: 0.878
[95,     4] loss: 0.850
[96,     4] loss: 0.867
[97,     4] loss: 0.868
[98,     4] loss: 0.872
[99,     4] loss: 0.856
[100,     4] loss: 0.835
[101,     4] loss: 0.786
[102,     4] loss: 1.101
[103,     4] loss: 1.169
[104,     4] loss: 1.126
[105,     4] loss: 1.085
[106,     4] loss: 1.020
[107,     4] loss: 1.027
[108,     4] loss: 1.057
[109,     4] loss: 0.944
[110,     4] loss: 0.863
[111,     4] loss: 0.810
[112,     4] loss: 1.099
[113,     4] loss: 1.176
[114,     4] loss: 1.151
[115,     4] loss: 1.151
[116,     4] loss: 1.047
[117,     4] loss: 1.086
[118,     4] loss: 0.975
Early stopping applied (best metric=0.29666250944137573)
Finished Training
Total time taken: 60.71146559715271
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.387
[3,     4] loss: 1.389
[4,     4] loss: 1.378
[5,     4] loss: 1.363
[6,     4] loss: 1.332
[7,     4] loss: 1.252
[8,     4] loss: 1.157
[9,     4] loss: 1.167
[10,     4] loss: 1.128
[11,     4] loss: 1.110
[12,     4] loss: 1.033
[13,     4] loss: 1.101
[14,     4] loss: 1.039
[15,     4] loss: 0.989
[16,     4] loss: 0.982
[17,     4] loss: 0.988
[18,     4] loss: 0.986
[19,     4] loss: 1.014
[20,     4] loss: 1.026
[21,     4] loss: 1.088
[22,     4] loss: 1.101
[23,     4] loss: 1.113
[24,     4] loss: 1.067
[25,     4] loss: 0.968
[26,     4] loss: 0.930
[27,     4] loss: 0.861
[28,     4] loss: 0.949
[29,     4] loss: 0.889
[30,     4] loss: 0.958
[31,     4] loss: 0.880
[32,     4] loss: 0.859
[33,     4] loss: 0.854
[34,     4] loss: 0.906
[35,     4] loss: 0.819
[36,     4] loss: 0.934
[37,     4] loss: 1.001
[38,     4] loss: 1.020
[39,     4] loss: 0.974
[40,     4] loss: 0.906
[41,     4] loss: 0.938
[42,     4] loss: 0.860
[43,     4] loss: 0.844
[44,     4] loss: 0.866
[45,     4] loss: 0.825
[46,     4] loss: 1.021
[47,     4] loss: 1.070
[48,     4] loss: 1.041
[49,     4] loss: 0.992
[50,     4] loss: 0.911
[51,     4] loss: 0.852
[52,     4] loss: 0.830
[53,     4] loss: 0.855
[54,     4] loss: 0.954
[55,     4] loss: 0.905
[56,     4] loss: 0.882
Early stopping applied (best metric=0.5216241478919983)
Finished Training
Total time taken: 28.461079120635986
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.387
[3,     4] loss: 1.384
[4,     4] loss: 1.382
[5,     4] loss: 1.375
[6,     4] loss: 1.366
[7,     4] loss: 1.331
[8,     4] loss: 1.283
[9,     4] loss: 1.265
[10,     4] loss: 1.196
[11,     4] loss: 1.149
[12,     4] loss: 1.133
[13,     4] loss: 1.038
[14,     4] loss: 1.052
[15,     4] loss: 1.012
[16,     4] loss: 1.009
[17,     4] loss: 0.985
[18,     4] loss: 1.098
[19,     4] loss: 0.999
[20,     4] loss: 1.008
[21,     4] loss: 0.897
[22,     4] loss: 0.862
[23,     4] loss: 0.924
[24,     4] loss: 0.922
[25,     4] loss: 0.866
[26,     4] loss: 0.833
[27,     4] loss: 1.120
[28,     4] loss: 0.909
[29,     4] loss: 1.003
[30,     4] loss: 0.939
[31,     4] loss: 0.931
[32,     4] loss: 0.985
[33,     4] loss: 0.978
[34,     4] loss: 0.956
[35,     4] loss: 0.883
[36,     4] loss: 0.826
[37,     4] loss: 1.224
[38,     4] loss: 1.087
[39,     4] loss: 1.066
[40,     4] loss: 0.995
[41,     4] loss: 1.012
[42,     4] loss: 1.050
[43,     4] loss: 1.007
[44,     4] loss: 0.976
[45,     4] loss: 0.913
[46,     4] loss: 0.912
[47,     4] loss: 1.026
[48,     4] loss: 0.996
[49,     4] loss: 0.944
[50,     4] loss: 0.868
[51,     4] loss: 0.843
[52,     4] loss: 0.894
[53,     4] loss: 0.835
[54,     4] loss: 0.868
[55,     4] loss: 0.886
[56,     4] loss: 0.836
[57,     4] loss: 0.892
[58,     4] loss: 0.892
[59,     4] loss: 0.957
[60,     4] loss: 0.944
[61,     4] loss: 0.890
[62,     4] loss: 0.861
[63,     4] loss: 0.815
[64,     4] loss: 0.849
[65,     4] loss: 0.838
[66,     4] loss: 0.809
[67,     4] loss: 0.826
[68,     4] loss: 0.836
Early stopping applied (best metric=0.401538610458374)
Finished Training
Total time taken: 34.34809398651123
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.390
[3,     4] loss: 1.387
[4,     4] loss: 1.390
[5,     4] loss: 1.387
[6,     4] loss: 1.387
[7,     4] loss: 1.385
[8,     4] loss: 1.384
[9,     4] loss: 1.383
[10,     4] loss: 1.382
[11,     4] loss: 1.366
[12,     4] loss: 1.338
[13,     4] loss: 1.254
[14,     4] loss: 1.190
[15,     4] loss: 1.290
[16,     4] loss: 1.160
[17,     4] loss: 1.160
[18,     4] loss: 1.138
[19,     4] loss: 1.098
[20,     4] loss: 1.058
[21,     4] loss: 1.101
[22,     4] loss: 1.017
[23,     4] loss: 1.068
[24,     4] loss: 0.979
[25,     4] loss: 0.957
[26,     4] loss: 1.118
[27,     4] loss: 1.047
[28,     4] loss: 0.987
[29,     4] loss: 0.929
[30,     4] loss: 1.198
[31,     4] loss: 1.129
[32,     4] loss: 1.080
[33,     4] loss: 1.012
[34,     4] loss: 0.975
[35,     4] loss: 0.934
[36,     4] loss: 0.985
[37,     4] loss: 1.067
[38,     4] loss: 1.028
[39,     4] loss: 1.215
[40,     4] loss: 1.140
[41,     4] loss: 1.046
[42,     4] loss: 0.911
[43,     4] loss: 1.009
[44,     4] loss: 1.077
[45,     4] loss: 1.053
[46,     4] loss: 1.015
[47,     4] loss: 0.988
[48,     4] loss: 0.922
[49,     4] loss: 0.992
[50,     4] loss: 1.080
[51,     4] loss: 1.020
[52,     4] loss: 1.004
[53,     4] loss: 0.886
[54,     4] loss: 0.861
[55,     4] loss: 0.916
[56,     4] loss: 0.992
[57,     4] loss: 0.919
[58,     4] loss: 0.962
[59,     4] loss: 0.996
[60,     4] loss: 0.904
[61,     4] loss: 0.907
[62,     4] loss: 0.956
[63,     4] loss: 0.915
[64,     4] loss: 0.929
[65,     4] loss: 0.833
[66,     4] loss: 1.016
[67,     4] loss: 1.069
[68,     4] loss: 0.966
[69,     4] loss: 0.945
[70,     4] loss: 0.869
[71,     4] loss: 0.809
[72,     4] loss: 0.815
[73,     4] loss: 0.840
[74,     4] loss: 1.474
[75,     4] loss: 1.219
[76,     4] loss: 1.229
[77,     4] loss: 1.196
[78,     4] loss: 1.168
[79,     4] loss: 1.140
[80,     4] loss: 1.115
[81,     4] loss: 1.114
[82,     4] loss: 1.107
[83,     4] loss: 1.088
[84,     4] loss: 1.080
[85,     4] loss: 1.084
[86,     4] loss: 1.085
[87,     4] loss: 1.131
[88,     4] loss: 1.063
[89,     4] loss: 1.095
[90,     4] loss: 1.095
[91,     4] loss: 1.018
[92,     4] loss: 1.018
[93,     4] loss: 0.999
[94,     4] loss: 1.014
[95,     4] loss: 0.941
[96,     4] loss: 0.939
[97,     4] loss: 0.994
[98,     4] loss: 1.027
[99,     4] loss: 1.001
[100,     4] loss: 1.001
[101,     4] loss: 0.932
[102,     4] loss: 0.872
[103,     4] loss: 0.923
[104,     4] loss: 0.998
[105,     4] loss: 1.032
[106,     4] loss: 1.077
[107,     4] loss: 1.024
[108,     4] loss: 0.960
[109,     4] loss: 0.867
[110,     4] loss: 0.846
[111,     4] loss: 0.864
[112,     4] loss: 0.918
[113,     4] loss: 0.929
[114,     4] loss: 0.886
[115,     4] loss: 0.914
[116,     4] loss: 0.906
[117,     4] loss: 0.879
[118,     4] loss: 0.877
[119,     4] loss: 0.838
Early stopping applied (best metric=0.2525468170642853)
Finished Training
Total time taken: 61.35069799423218
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.388
[2,     4] loss: 1.393
[3,     4] loss: 1.382
[4,     4] loss: 1.387
[5,     4] loss: 1.383
[6,     4] loss: 1.387
[7,     4] loss: 1.381
[8,     4] loss: 1.365
[9,     4] loss: 1.349
[10,     4] loss: 1.301
[11,     4] loss: 1.247
[12,     4] loss: 1.173
[13,     4] loss: 1.220
[14,     4] loss: 1.170
[15,     4] loss: 1.143
[16,     4] loss: 1.039
[17,     4] loss: 1.008
[18,     4] loss: 0.975
[19,     4] loss: 0.909
[20,     4] loss: 0.957
[21,     4] loss: 0.908
[22,     4] loss: 0.928
[23,     4] loss: 0.990
[24,     4] loss: 0.926
[25,     4] loss: 0.918
[26,     4] loss: 0.928
[27,     4] loss: 0.928
[28,     4] loss: 0.961
[29,     4] loss: 0.906
[30,     4] loss: 0.928
[31,     4] loss: 0.948
[32,     4] loss: 0.935
[33,     4] loss: 0.842
[34,     4] loss: 0.784
[35,     4] loss: 0.924
[36,     4] loss: 0.863
[37,     4] loss: 0.937
[38,     4] loss: 0.937
[39,     4] loss: 0.894
[40,     4] loss: 0.927
[41,     4] loss: 0.826
[42,     4] loss: 0.933
[43,     4] loss: 0.869
[44,     4] loss: 0.787
[45,     4] loss: 0.835
[46,     4] loss: 0.889
[47,     4] loss: 0.867
[48,     4] loss: 0.852
[49,     4] loss: 0.801
[50,     4] loss: 0.873
[51,     4] loss: 1.076
[52,     4] loss: 0.969
[53,     4] loss: 0.931
[54,     4] loss: 0.842
[55,     4] loss: 0.825
[56,     4] loss: 0.872
[57,     4] loss: 0.843
[58,     4] loss: 0.828
[59,     4] loss: 0.833
[60,     4] loss: 0.910
[61,     4] loss: 0.969
[62,     4] loss: 1.030
[63,     4] loss: 0.958
[64,     4] loss: 0.980
[65,     4] loss: 0.858
[66,     4] loss: 0.851
[67,     4] loss: 0.799
[68,     4] loss: 0.794
Early stopping applied (best metric=0.3548659086227417)
Finished Training
Total time taken: 34.283093214035034
{'Hydroxylation-K Validation Accuracy': 0.7886820330969267, 'Hydroxylation-K Validation Sensitivity': 0.7666666666666666, 'Hydroxylation-K Validation Specificity': 0.7947368421052632, 'Hydroxylation-K Validation Precision': nan, 'Hydroxylation-K AUC ROC': 0.8451851851851852, 'Hydroxylation-K AUC PR': 0.6331452816586229, 'Hydroxylation-K MCC': 0.4902178299787345, 'Hydroxylation-K F1': 0.5815560323367341, 'Validation Loss (Hydroxylation-K)': 0.3922722021738688, 'Methylation-K Validation Accuracy': 0.7817345850533884, 'Methylation-K Validation Sensitivity': 0.18285511916328248, 'Methylation-K Validation Specificity': 0.8466843810097385, 'Methylation-K Validation Precision': nan, 'Methylation-K AUC ROC': 0.535596862441926, 'Methylation-K AUC PR': 0.11080519574739997, 'Methylation-K MCC': 0.024863480832902816, 'Methylation-K F1': 0.1309712063112682, 'Validation Loss (Methylation-K)': 0.8675284266471863, 'Validation Loss (total)': 1.259800632794698, 'TimeToTrain': 51.731633472442624}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003259743458876159,
 'learning_rate_Hydroxylation-K': 0.00781934733371644,
 'learning_rate_Methylation-K': 0.006794291011965888,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2852403802441755,
 'loss_weight_Methylation-K': 0.7090003086983283,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2554954849,
 'sample_weights': [0.8390994480963001, 0.2997058447933801],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.06149564233305,
 'weight_decay_Hydroxylation-K': 2.319081921122981,
 'weight_decay_Methylation-K': 9.900892071040408}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.400
[2,     4] loss: 1.384
[3,     4] loss: 1.383
[4,     4] loss: 1.388
[5,     4] loss: 1.374
[6,     4] loss: 1.366
[7,     4] loss: 1.305
[8,     4] loss: 1.248
[9,     4] loss: 1.224
[10,     4] loss: 1.181
[11,     4] loss: 1.155
[12,     4] loss: 1.093
[13,     4] loss: 1.064
[14,     4] loss: 1.103
[15,     4] loss: 1.110
[16,     4] loss: 1.076
[17,     4] loss: 1.052
[18,     4] loss: 0.998
[19,     4] loss: 0.931
[20,     4] loss: 1.027
[21,     4] loss: 0.955
[22,     4] loss: 0.945
[23,     4] loss: 0.953
[24,     4] loss: 0.879
[25,     4] loss: 0.853
[26,     4] loss: 0.822
[27,     4] loss: 0.894
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012322764721401608,
 'learning_rate_Hydroxylation-K': 0.005135935710209609,
 'learning_rate_Methylation-K': 0.009924141118958965,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.39163859310573657,
 'loss_weight_Methylation-K': 0.9661790068927265,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 536594110,
 'sample_weights': [0.2852403802441755, 0.7090003086983283],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.853490585992132,
 'weight_decay_Hydroxylation-K': 5.4456201034347655,
 'weight_decay_Methylation-K': 7.42682447016019}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.384
[3,     4] loss: 1.391
[4,     4] loss: 1.380
[5,     4] loss: 1.378
[6,     4] loss: 1.365
[7,     4] loss: 1.348
[8,     4] loss: 1.303
[9,     4] loss: 1.269
[10,     4] loss: 1.217
[11,     4] loss: 1.195
[12,     4] loss: 1.159
[13,     4] loss: 1.058
[14,     4] loss: 1.071
[15,     4] loss: 1.034
[16,     4] loss: 0.957
[17,     4] loss: 1.006
[18,     4] loss: 0.974
[19,     4] loss: 0.931
[20,     4] loss: 0.904
[21,     4] loss: 0.892
[22,     4] loss: 0.879
[23,     4] loss: 0.955
[24,     4] loss: 0.857
[25,     4] loss: 0.866
[26,     4] loss: 0.931
[27,     4] loss: 0.827
[28,     4] loss: 0.849
[29,     4] loss: 0.906
[30,     4] loss: 0.845
[31,     4] loss: 0.820
[32,     4] loss: 0.825
[33,     4] loss: 0.796
[34,     4] loss: 0.813
[35,     4] loss: 0.805
[36,     4] loss: 0.785
[37,     4] loss: 0.833
[38,     4] loss: 0.837
[39,     4] loss: 0.782
[40,     4] loss: 0.756
[41,     4] loss: 0.760
[42,     4] loss: 0.755
[43,     4] loss: 0.769
[44,     4] loss: 0.753
[45,     4] loss: 0.815
[46,     4] loss: 0.790
[47,     4] loss: 0.807
[48,     4] loss: 0.741
[49,     4] loss: 0.791
[50,     4] loss: 0.797
[51,     4] loss: 0.798
[52,     4] loss: 0.766
[53,     4] loss: 0.799
[54,     4] loss: 0.809
[55,     4] loss: 0.794
[56,     4] loss: 0.778
[57,     4] loss: 0.775
[58,     4] loss: 0.775
[59,     4] loss: 0.772
[60,     4] loss: 0.780
[61,     4] loss: 0.789
[62,     4] loss: 0.742
[63,     4] loss: 0.747
[64,     4] loss: 0.761
[65,     4] loss: 0.756
[66,     4] loss: 0.754
[67,     4] loss: 0.771
[68,     4] loss: 0.744
[69,     4] loss: 0.743
[70,     4] loss: 0.726
[71,     4] loss: 0.784
[72,     4] loss: 0.764
[73,     4] loss: 0.757
[74,     4] loss: 0.726
[75,     4] loss: 0.791
[76,     4] loss: 0.743
[77,     4] loss: 0.745
[78,     4] loss: 0.737
[79,     4] loss: 0.774
[80,     4] loss: 0.745
[81,     4] loss: 0.735
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002580950092565464,
 'learning_rate_Hydroxylation-K': 0.0005549360205349512,
 'learning_rate_Methylation-K': 0.0006748305267527268,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1887095432082583,
 'loss_weight_Methylation-K': 0.4742492098509715,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2642713087,
 'sample_weights': [0.39163859310573657, 0.9661790068927265],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.930632625967073,
 'weight_decay_Hydroxylation-K': 0.5288207493599637,
 'weight_decay_Methylation-K': 8.951057923927058}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.381
[2,     4] loss: 1.385
[3,     4] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004511685800828169,
 'learning_rate_Hydroxylation-K': 0.008876378858825315,
 'learning_rate_Methylation-K': 0.0030159836546054925,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8976316123892141,
 'loss_weight_Methylation-K': 0.2782117501969638,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2485865941,
 'sample_weights': [0.1887095432082583, 0.4742492098509715],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.126649116942533,
 'weight_decay_Hydroxylation-K': 7.9252271125367795,
 'weight_decay_Methylation-K': 8.844201816300345}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.382
[3,     4] loss: 1.391
[4,     4] loss: 1.386
[5,     4] loss: 1.385
[6,     4] loss: 1.381
[7,     4] loss: 1.374
[8,     4] loss: 1.354
[9,     4] loss: 1.297
[10,     4] loss: 1.263
[11,     4] loss: 1.168
[12,     4] loss: 1.071
[13,     4] loss: 0.997
[14,     4] loss: 1.130
[15,     4] loss: 1.182
[16,     4] loss: 1.070
[17,     4] loss: 1.041
[18,     4] loss: 1.031
[19,     4] loss: 0.999
[20,     4] loss: 0.917
[21,     4] loss: 0.932
[22,     4] loss: 0.977
[23,     4] loss: 0.978
[24,     4] loss: 0.931
[25,     4] loss: 0.946
[26,     4] loss: 0.971
[27,     4] loss: 0.944
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018633612698142658,
 'learning_rate_Hydroxylation-K': 0.0065034315843711145,
 'learning_rate_Methylation-K': 0.00908547656129518,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.46231240558584397,
 'loss_weight_Methylation-K': 0.80986042921607,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 208201466,
 'sample_weights': [0.8976316123892141, 0.2782117501969638],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.952486647665852,
 'weight_decay_Hydroxylation-K': 6.143816649268102,
 'weight_decay_Methylation-K': 7.596365489296437}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.377
[3,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00303125353981217,
 'learning_rate_Hydroxylation-K': 0.006960772881934184,
 'learning_rate_Methylation-K': 0.0009911530343990056,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6090234254170567,
 'loss_weight_Methylation-K': 0.16645558374255084,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2148771698,
 'sample_weights': [0.46231240558584397, 0.80986042921607],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.3799181308741435,
 'weight_decay_Hydroxylation-K': 5.10281775864123,
 'weight_decay_Methylation-K': 9.56791485952919}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.387
[3,     4] loss: 1.389
[4,     4] loss: 1.382
[5,     4] loss: 1.380
[6,     4] loss: 1.369
[7,     4] loss: 1.339
[8,     4] loss: 1.301
[9,     4] loss: 1.263
[10,     4] loss: 1.213
[11,     4] loss: 1.163
[12,     4] loss: 1.095
[13,     4] loss: 1.034
[14,     4] loss: 1.077
[15,     4] loss: 0.991
[16,     4] loss: 0.932
[17,     4] loss: 0.906
[18,     4] loss: 0.906
[19,     4] loss: 0.913
[20,     4] loss: 0.989
[21,     4] loss: 0.987
[22,     4] loss: 0.949
[23,     4] loss: 0.900
[24,     4] loss: 0.863
[25,     4] loss: 0.850
[26,     4] loss: 0.892
[27,     4] loss: 0.825
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020429860859653027,
 'learning_rate_Hydroxylation-K': 0.0044444494695876375,
 'learning_rate_Methylation-K': 0.007569624626539541,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3078237752940801,
 'loss_weight_Methylation-K': 0.8170070562993823,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1479355990,
 'sample_weights': [0.6090234254170567, 0.16645558374255084],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.0329326005979285,
 'weight_decay_Hydroxylation-K': 4.6008632583358935,
 'weight_decay_Methylation-K': 6.692457107958347}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.398
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0004844948891008806,
 'learning_rate_Hydroxylation-K': 0.001699824656612926,
 'learning_rate_Methylation-K': 0.008985685558783126,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.11717121579275057,
 'loss_weight_Methylation-K': 0.964817415749591,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 46865852,
 'sample_weights': [0.3078237752940801, 0.8170070562993823],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.76630692111149,
 'weight_decay_Hydroxylation-K': 6.419838753870708,
 'weight_decay_Methylation-K': 9.960656431658682}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.392
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002408715811865085,
 'learning_rate_Hydroxylation-K': 0.004578449414620837,
 'learning_rate_Methylation-K': 0.009737685757446983,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.37520637092894504,
 'loss_weight_Methylation-K': 0.8029667266786333,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 181889133,
 'sample_weights': [0.11717121579275057, 0.964817415749591],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.822461454312563,
 'weight_decay_Hydroxylation-K': 6.8884767834224325,
 'weight_decay_Methylation-K': 6.2088525014289395}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.382
[3,     4] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014811988817093951,
 'learning_rate_Hydroxylation-K': 0.009056872961014609,
 'learning_rate_Methylation-K': 0.005833848320866716,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.17540027311584389,
 'loss_weight_Methylation-K': 0.8818694280795767,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 84122416,
 'sample_weights': [0.37520637092894504, 0.8029667266786333],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.720753673602902,
 'weight_decay_Hydroxylation-K': 4.053012326225458,
 'weight_decay_Methylation-K': 3.4082728916634735}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.381
[2,     4] loss: 1.381
[3,     4] loss: 1.389
[4,     4] loss: 1.366
[5,     4] loss: 1.367
[6,     4] loss: 1.326
[7,     4] loss: 1.321
[8,     4] loss: 1.296
[9,     4] loss: 1.255
[10,     4] loss: 1.203
[11,     4] loss: 1.144
[12,     4] loss: 1.118
[13,     4] loss: 1.093
[14,     4] loss: 1.066
[15,     4] loss: 1.055
[16,     4] loss: 1.047
[17,     4] loss: 0.962
[18,     4] loss: 0.994
[19,     4] loss: 0.993
[20,     4] loss: 0.915
[21,     4] loss: 0.926
[22,     4] loss: 0.961
[23,     4] loss: 0.892
[24,     4] loss: 0.905
[25,     4] loss: 0.840
[26,     4] loss: 0.827
[27,     4] loss: 0.878
[28,     4] loss: 0.868
[29,     4] loss: 0.902
[30,     4] loss: 0.899
[31,     4] loss: 0.843
[32,     4] loss: 0.816
[33,     4] loss: 0.825
[34,     4] loss: 0.794
[35,     4] loss: 0.860
[36,     4] loss: 0.943
[37,     4] loss: 0.865
[38,     4] loss: 0.896
[39,     4] loss: 0.833
[40,     4] loss: 0.827
[41,     4] loss: 0.795
[42,     4] loss: 0.782
[43,     4] loss: 0.820
[44,     4] loss: 0.893
[45,     4] loss: 0.791
[46,     4] loss: 0.789
[47,     4] loss: 0.803
[48,     4] loss: 0.786
[49,     4] loss: 0.798
[50,     4] loss: 0.772
[51,     4] loss: 0.822
[52,     4] loss: 0.795
[53,     4] loss: 0.821
[54,     4] loss: 0.776
[55,     4] loss: 0.777
[56,     4] loss: 0.752
[57,     4] loss: 0.785
[58,     4] loss: 0.809
[59,     4] loss: 0.771
[60,     4] loss: 0.782
[61,     4] loss: 0.771
[62,     4] loss: 0.784
[63,     4] loss: 0.737
[64,     4] loss: 0.828
[65,     4] loss: 0.772
[66,     4] loss: 0.753
[67,     4] loss: 0.769
[68,     4] loss: 0.785
[69,     4] loss: 0.798
[70,     4] loss: 0.769
[71,     4] loss: 0.767
[72,     4] loss: 0.819
[73,     4] loss: 0.843
[74,     4] loss: 0.815
[75,     4] loss: 0.774
[76,     4] loss: 0.766
[77,     4] loss: 0.743
[78,     4] loss: 0.759
[79,     4] loss: 0.795
[80,     4] loss: 0.773
[81,     4] loss: 0.855
[82,     4] loss: 0.791
[83,     4] loss: 0.806
[84,     4] loss: 0.878
[85,     4] loss: 0.840
[86,     4] loss: 0.809
[87,     4] loss: 0.816
[88,     4] loss: 0.781
[89,     4] loss: 0.816
[90,     4] loss: 0.789
[91,     4] loss: 0.781
[92,     4] loss: 0.760
[93,     4] loss: 0.736
[94,     4] loss: 0.737
[95,     4] loss: 0.759
Early stopping applied (best metric=0.30923736095428467)
Finished Training
Total time taken: 48.13212966918945
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.391
[3,     4] loss: 1.384
[4,     4] loss: 1.370
[5,     4] loss: 1.359
[6,     4] loss: 1.319
[7,     4] loss: 1.248
[8,     4] loss: 1.225
[9,     4] loss: 1.196
[10,     4] loss: 1.133
[11,     4] loss: 1.067
[12,     4] loss: 1.015
[13,     4] loss: 1.026
[14,     4] loss: 1.014
[15,     4] loss: 0.963
[16,     4] loss: 0.942
[17,     4] loss: 0.953
[18,     4] loss: 1.062
[19,     4] loss: 0.985
[20,     4] loss: 0.923
[21,     4] loss: 0.937
[22,     4] loss: 0.903
[23,     4] loss: 0.903
[24,     4] loss: 0.888
[25,     4] loss: 0.936
[26,     4] loss: 0.847
[27,     4] loss: 0.887
[28,     4] loss: 0.836
[29,     4] loss: 0.875
[30,     4] loss: 0.831
[31,     4] loss: 0.808
[32,     4] loss: 0.789
[33,     4] loss: 0.759
[34,     4] loss: 0.783
[35,     4] loss: 0.791
[36,     4] loss: 0.832
[37,     4] loss: 0.889
[38,     4] loss: 0.923
[39,     4] loss: 0.937
[40,     4] loss: 0.990
[41,     4] loss: 0.938
[42,     4] loss: 0.888
[43,     4] loss: 0.826
[44,     4] loss: 0.804
[45,     4] loss: 0.774
[46,     4] loss: 0.781
[47,     4] loss: 0.747
[48,     4] loss: 0.783
[49,     4] loss: 0.793
[50,     4] loss: 0.809
[51,     4] loss: 0.897
[52,     4] loss: 0.846
[53,     4] loss: 0.815
[54,     4] loss: 0.833
[55,     4] loss: 0.836
Early stopping applied (best metric=0.5445348024368286)
Finished Training
Total time taken: 27.804078340530396
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.383
[3,     4] loss: 1.377
[4,     4] loss: 1.369
[5,     4] loss: 1.341
[6,     4] loss: 1.284
[7,     4] loss: 1.284
[8,     4] loss: 1.244
[9,     4] loss: 1.123
[10,     4] loss: 1.112
[11,     4] loss: 1.042
[12,     4] loss: 1.028
[13,     4] loss: 1.003
[14,     4] loss: 0.953
[15,     4] loss: 1.115
[16,     4] loss: 0.983
[17,     4] loss: 0.973
[18,     4] loss: 0.988
[19,     4] loss: 0.860
[20,     4] loss: 0.901
[21,     4] loss: 0.907
[22,     4] loss: 0.892
[23,     4] loss: 0.915
[24,     4] loss: 0.877
[25,     4] loss: 0.861
[26,     4] loss: 0.791
[27,     4] loss: 0.802
[28,     4] loss: 0.801
[29,     4] loss: 0.864
[30,     4] loss: 0.844
[31,     4] loss: 0.915
[32,     4] loss: 0.873
[33,     4] loss: 0.873
[34,     4] loss: 0.795
[35,     4] loss: 0.816
[36,     4] loss: 0.892
[37,     4] loss: 0.874
[38,     4] loss: 0.816
[39,     4] loss: 0.767
[40,     4] loss: 0.769
[41,     4] loss: 0.764
[42,     4] loss: 0.777
[43,     4] loss: 0.798
[44,     4] loss: 0.778
[45,     4] loss: 0.836
[46,     4] loss: 0.801
[47,     4] loss: 0.816
[48,     4] loss: 0.812
[49,     4] loss: 0.772
[50,     4] loss: 0.776
[51,     4] loss: 0.789
[52,     4] loss: 0.756
[53,     4] loss: 0.744
[54,     4] loss: 0.782
[55,     4] loss: 0.783
[56,     4] loss: 0.797
[57,     4] loss: 0.790
[58,     4] loss: 0.747
[59,     4] loss: 0.802
[60,     4] loss: 0.756
Early stopping applied (best metric=0.5064021348953247)
Finished Training
Total time taken: 30.33708119392395
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.383
[3,     4] loss: 1.389
[4,     4] loss: 1.359
[5,     4] loss: 1.353
[6,     4] loss: 1.319
[7,     4] loss: 1.237
[8,     4] loss: 1.181
[9,     4] loss: 1.133
[10,     4] loss: 1.154
[11,     4] loss: 1.091
[12,     4] loss: 1.034
[13,     4] loss: 1.013
[14,     4] loss: 1.019
[15,     4] loss: 0.968
[16,     4] loss: 0.958
[17,     4] loss: 0.860
[18,     4] loss: 0.848
[19,     4] loss: 0.893
[20,     4] loss: 0.856
[21,     4] loss: 0.905
[22,     4] loss: 0.880
[23,     4] loss: 0.843
[24,     4] loss: 0.914
[25,     4] loss: 0.904
[26,     4] loss: 0.855
[27,     4] loss: 0.836
[28,     4] loss: 0.836
[29,     4] loss: 0.859
[30,     4] loss: 0.908
[31,     4] loss: 0.872
[32,     4] loss: 0.845
[33,     4] loss: 0.908
[34,     4] loss: 0.890
[35,     4] loss: 0.814
[36,     4] loss: 0.769
[37,     4] loss: 0.828
[38,     4] loss: 0.744
[39,     4] loss: 0.816
[40,     4] loss: 0.795
[41,     4] loss: 0.831
[42,     4] loss: 0.849
[43,     4] loss: 0.807
[44,     4] loss: 0.814
[45,     4] loss: 0.813
[46,     4] loss: 0.799
[47,     4] loss: 0.817
[48,     4] loss: 0.808
[49,     4] loss: 0.895
[50,     4] loss: 0.901
[51,     4] loss: 0.906
[52,     4] loss: 0.835
[53,     4] loss: 0.781
[54,     4] loss: 0.808
[55,     4] loss: 0.792
[56,     4] loss: 0.783
[57,     4] loss: 0.746
Early stopping applied (best metric=0.46684470772743225)
Finished Training
Total time taken: 28.979077100753784
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.380
[2,     4] loss: 1.391
[3,     4] loss: 1.388
[4,     4] loss: 1.385
[5,     4] loss: 1.378
[6,     4] loss: 1.367
[7,     4] loss: 1.340
[8,     4] loss: 1.303
[9,     4] loss: 1.265
[10,     4] loss: 1.230
[11,     4] loss: 1.179
[12,     4] loss: 1.163
[13,     4] loss: 1.132
[14,     4] loss: 1.061
[15,     4] loss: 1.037
[16,     4] loss: 1.042
[17,     4] loss: 0.992
[18,     4] loss: 0.991
[19,     4] loss: 0.970
[20,     4] loss: 0.969
[21,     4] loss: 0.974
[22,     4] loss: 0.969
[23,     4] loss: 0.927
[24,     4] loss: 0.882
[25,     4] loss: 0.893
[26,     4] loss: 0.817
[27,     4] loss: 0.888
[28,     4] loss: 0.857
[29,     4] loss: 0.823
[30,     4] loss: 0.828
[31,     4] loss: 0.835
[32,     4] loss: 0.803
[33,     4] loss: 0.809
[34,     4] loss: 0.780
[35,     4] loss: 0.795
[36,     4] loss: 0.905
[37,     4] loss: 0.902
[38,     4] loss: 0.853
[39,     4] loss: 0.826
[40,     4] loss: 0.775
[41,     4] loss: 0.757
[42,     4] loss: 0.744
[43,     4] loss: 0.803
[44,     4] loss: 0.797
[45,     4] loss: 0.748
[46,     4] loss: 0.806
[47,     4] loss: 0.775
[48,     4] loss: 0.806
[49,     4] loss: 0.806
[50,     4] loss: 0.785
[51,     4] loss: 0.814
[52,     4] loss: 0.795
[53,     4] loss: 0.832
[54,     4] loss: 0.810
[55,     4] loss: 0.732
[56,     4] loss: 0.797
[57,     4] loss: 0.750
[58,     4] loss: 0.782
[59,     4] loss: 0.743
[60,     4] loss: 0.736
[61,     4] loss: 0.730
[62,     4] loss: 0.729
[63,     4] loss: 0.735
[64,     4] loss: 0.763
[65,     4] loss: 0.761
[66,     4] loss: 0.759
[67,     4] loss: 0.787
[68,     4] loss: 0.754
[69,     4] loss: 0.736
[70,     4] loss: 0.720
Early stopping applied (best metric=0.46113553643226624)
Finished Training
Total time taken: 35.334094762802124
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.389
[3,     4] loss: 1.389
[4,     4] loss: 1.388
[5,     4] loss: 1.385
[6,     4] loss: 1.379
[7,     4] loss: 1.370
[8,     4] loss: 1.354
[9,     4] loss: 1.336
[10,     4] loss: 1.289
[11,     4] loss: 1.251
[12,     4] loss: 1.229
[13,     4] loss: 1.141
[14,     4] loss: 1.090
[15,     4] loss: 1.097
[16,     4] loss: 1.072
[17,     4] loss: 1.008
[18,     4] loss: 1.019
[19,     4] loss: 0.966
[20,     4] loss: 0.899
[21,     4] loss: 0.961
[22,     4] loss: 0.996
[23,     4] loss: 0.977
[24,     4] loss: 0.970
[25,     4] loss: 0.927
[26,     4] loss: 0.895
[27,     4] loss: 0.837
[28,     4] loss: 0.825
[29,     4] loss: 0.837
[30,     4] loss: 0.830
[31,     4] loss: 0.811
[32,     4] loss: 0.864
[33,     4] loss: 0.801
[34,     4] loss: 0.831
[35,     4] loss: 0.818
[36,     4] loss: 0.817
[37,     4] loss: 0.840
[38,     4] loss: 0.794
[39,     4] loss: 0.793
[40,     4] loss: 0.810
[41,     4] loss: 0.845
[42,     4] loss: 0.831
[43,     4] loss: 0.790
[44,     4] loss: 0.760
[45,     4] loss: 0.752
[46,     4] loss: 0.795
[47,     4] loss: 0.782
[48,     4] loss: 0.755
[49,     4] loss: 0.767
[50,     4] loss: 0.801
[51,     4] loss: 0.762
[52,     4] loss: 0.769
[53,     4] loss: 0.790
[54,     4] loss: 0.772
[55,     4] loss: 0.830
[56,     4] loss: 0.778
[57,     4] loss: 0.817
[58,     4] loss: 0.789
[59,     4] loss: 0.784
[60,     4] loss: 0.749
[61,     4] loss: 0.743
Early stopping applied (best metric=0.48165011405944824)
Finished Training
Total time taken: 31.106087684631348
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.388
[3,     4] loss: 1.383
[4,     4] loss: 1.374
[5,     4] loss: 1.352
[6,     4] loss: 1.311
[7,     4] loss: 1.266
[8,     4] loss: 1.217
[9,     4] loss: 1.126
[10,     4] loss: 1.134
[11,     4] loss: 1.049
[12,     4] loss: 0.979
[13,     4] loss: 0.910
[14,     4] loss: 0.956
[15,     4] loss: 0.963
[16,     4] loss: 0.898
[17,     4] loss: 1.008
[18,     4] loss: 0.938
[19,     4] loss: 0.961
[20,     4] loss: 0.919
[21,     4] loss: 0.969
[22,     4] loss: 0.866
[23,     4] loss: 0.951
[24,     4] loss: 0.855
[25,     4] loss: 0.873
[26,     4] loss: 0.895
[27,     4] loss: 0.988
[28,     4] loss: 0.868
[29,     4] loss: 0.864
[30,     4] loss: 0.831
[31,     4] loss: 0.791
[32,     4] loss: 0.780
[33,     4] loss: 0.757
[34,     4] loss: 0.761
[35,     4] loss: 0.745
[36,     4] loss: 0.804
[37,     4] loss: 0.803
[38,     4] loss: 0.822
[39,     4] loss: 0.800
[40,     4] loss: 0.854
[41,     4] loss: 0.801
[42,     4] loss: 0.770
[43,     4] loss: 0.800
[44,     4] loss: 0.802
[45,     4] loss: 0.793
[46,     4] loss: 0.835
[47,     4] loss: 0.820
[48,     4] loss: 0.811
[49,     4] loss: 0.901
[50,     4] loss: 0.855
[51,     4] loss: 0.856
[52,     4] loss: 0.846
[53,     4] loss: 0.802
[54,     4] loss: 0.768
[55,     4] loss: 0.748
[56,     4] loss: 0.752
[57,     4] loss: 0.735
Early stopping applied (best metric=0.41837066411972046)
Finished Training
Total time taken: 28.83407711982727
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.382
[3,     4] loss: 1.382
[4,     4] loss: 1.372
[5,     4] loss: 1.344
[6,     4] loss: 1.313
[7,     4] loss: 1.259
[8,     4] loss: 1.184
[9,     4] loss: 1.147
[10,     4] loss: 1.106
[11,     4] loss: 1.134
[12,     4] loss: 1.013
[13,     4] loss: 1.031
[14,     4] loss: 1.125
[15,     4] loss: 1.015
[16,     4] loss: 0.927
[17,     4] loss: 0.988
[18,     4] loss: 0.920
[19,     4] loss: 0.890
[20,     4] loss: 0.915
[21,     4] loss: 1.005
[22,     4] loss: 0.951
[23,     4] loss: 0.906
[24,     4] loss: 0.957
[25,     4] loss: 0.910
[26,     4] loss: 0.925
[27,     4] loss: 0.855
[28,     4] loss: 0.821
[29,     4] loss: 0.829
[30,     4] loss: 0.791
[31,     4] loss: 0.824
[32,     4] loss: 0.862
[33,     4] loss: 0.864
[34,     4] loss: 0.904
[35,     4] loss: 0.863
[36,     4] loss: 0.836
[37,     4] loss: 0.813
[38,     4] loss: 0.784
[39,     4] loss: 0.793
[40,     4] loss: 0.810
[41,     4] loss: 0.826
[42,     4] loss: 0.824
[43,     4] loss: 0.789
[44,     4] loss: 0.791
[45,     4] loss: 0.811
[46,     4] loss: 0.795
[47,     4] loss: 0.762
[48,     4] loss: 0.775
[49,     4] loss: 0.811
[50,     4] loss: 0.780
[51,     4] loss: 0.815
[52,     4] loss: 0.808
[53,     4] loss: 0.824
[54,     4] loss: 0.758
[55,     4] loss: 0.770
[56,     4] loss: 0.809
[57,     4] loss: 0.743
[58,     4] loss: 0.762
[59,     4] loss: 0.764
[60,     4] loss: 0.773
[61,     4] loss: 0.750
[62,     4] loss: 0.769
[63,     4] loss: 0.763
[64,     4] loss: 0.739
[65,     4] loss: 0.772
[66,     4] loss: 0.773
[67,     4] loss: 0.766
[68,     4] loss: 0.753
[69,     4] loss: 0.747
[70,     4] loss: 0.724
[71,     4] loss: 0.789
[72,     4] loss: 0.734
[73,     4] loss: 0.737
[74,     4] loss: 0.741
[75,     4] loss: 0.743
[76,     4] loss: 0.784
[77,     4] loss: 0.802
[78,     4] loss: 0.800
[79,     4] loss: 0.797
[80,     4] loss: 0.856
[81,     4] loss: 0.828
[82,     4] loss: 0.754
[83,     4] loss: 0.756
[84,     4] loss: 0.768
[85,     4] loss: 0.756
[86,     4] loss: 0.761
[87,     4] loss: 0.766
[88,     4] loss: 0.762
[89,     4] loss: 0.756
[90,     4] loss: 0.741
[91,     4] loss: 0.760
[92,     4] loss: 0.847
[93,     4] loss: 0.984
[94,     4] loss: 0.880
[95,     4] loss: 0.817
[96,     4] loss: 0.789
[97,     4] loss: 0.755
[98,     4] loss: 0.754
[99,     4] loss: 0.753
[100,     4] loss: 0.724
[101,     4] loss: 0.748
[102,     4] loss: 0.716
[103,     4] loss: 0.729
[104,     4] loss: 0.729
[105,     4] loss: 0.732
Early stopping applied (best metric=0.2574988603591919)
Finished Training
Total time taken: 53.314141511917114
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.388
[3,     4] loss: 1.382
[4,     4] loss: 1.381
[5,     4] loss: 1.374
[6,     4] loss: 1.355
[7,     4] loss: 1.334
[8,     4] loss: 1.285
[9,     4] loss: 1.195
[10,     4] loss: 1.155
[11,     4] loss: 1.158
[12,     4] loss: 1.075
[13,     4] loss: 1.157
[14,     4] loss: 1.035
[15,     4] loss: 1.002
[16,     4] loss: 1.019
[17,     4] loss: 0.951
[18,     4] loss: 0.938
[19,     4] loss: 0.921
[20,     4] loss: 0.913
[21,     4] loss: 0.969
[22,     4] loss: 0.951
[23,     4] loss: 0.905
[24,     4] loss: 0.858
[25,     4] loss: 0.813
[26,     4] loss: 0.828
[27,     4] loss: 1.062
[28,     4] loss: 0.845
[29,     4] loss: 0.838
[30,     4] loss: 0.840
[31,     4] loss: 0.816
[32,     4] loss: 0.777
[33,     4] loss: 0.795
[34,     4] loss: 0.790
[35,     4] loss: 0.800
[36,     4] loss: 0.759
[37,     4] loss: 0.812
[38,     4] loss: 0.830
[39,     4] loss: 0.788
[40,     4] loss: 0.787
[41,     4] loss: 0.770
[42,     4] loss: 0.776
[43,     4] loss: 0.751
[44,     4] loss: 0.737
[45,     4] loss: 0.760
[46,     4] loss: 0.774
[47,     4] loss: 0.848
[48,     4] loss: 1.040
[49,     4] loss: 0.863
[50,     4] loss: 0.827
[51,     4] loss: 0.808
[52,     4] loss: 0.801
[53,     4] loss: 0.768
[54,     4] loss: 0.783
[55,     4] loss: 0.820
[56,     4] loss: 0.853
[57,     4] loss: 0.798
[58,     4] loss: 0.792
[59,     4] loss: 0.773
[60,     4] loss: 0.765
[61,     4] loss: 0.738
[62,     4] loss: 0.747
[63,     4] loss: 0.743
[64,     4] loss: 0.750
Early stopping applied (best metric=0.3905886113643646)
Finished Training
Total time taken: 31.767085552215576
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.381
[2,     4] loss: 1.389
[3,     4] loss: 1.384
[4,     4] loss: 1.380
[5,     4] loss: 1.366
[6,     4] loss: 1.348
[7,     4] loss: 1.294
[8,     4] loss: 1.256
[9,     4] loss: 1.186
[10,     4] loss: 1.105
[11,     4] loss: 1.114
[12,     4] loss: 1.134
[13,     4] loss: 1.036
[14,     4] loss: 1.040
[15,     4] loss: 1.033
[16,     4] loss: 0.998
[17,     4] loss: 0.939
[18,     4] loss: 0.949
[19,     4] loss: 0.908
[20,     4] loss: 0.939
[21,     4] loss: 0.999
[22,     4] loss: 0.946
[23,     4] loss: 0.925
[24,     4] loss: 0.892
[25,     4] loss: 0.837
[26,     4] loss: 0.807
[27,     4] loss: 0.831
[28,     4] loss: 0.766
[29,     4] loss: 0.820
[30,     4] loss: 0.875
[31,     4] loss: 0.877
[32,     4] loss: 0.876
[33,     4] loss: 0.905
[34,     4] loss: 0.865
[35,     4] loss: 0.821
[36,     4] loss: 0.771
[37,     4] loss: 0.793
[38,     4] loss: 0.759
[39,     4] loss: 0.743
[40,     4] loss: 0.745
[41,     4] loss: 0.757
[42,     4] loss: 0.800
[43,     4] loss: 0.791
[44,     4] loss: 0.861
[45,     4] loss: 0.838
[46,     4] loss: 0.852
[47,     4] loss: 0.809
[48,     4] loss: 0.756
[49,     4] loss: 0.757
[50,     4] loss: 0.757
[51,     4] loss: 0.760
[52,     4] loss: 0.760
[53,     4] loss: 0.740
[54,     4] loss: 0.757
[55,     4] loss: 0.773
[56,     4] loss: 0.763
[57,     4] loss: 0.761
[58,     4] loss: 0.786
Early stopping applied (best metric=0.40387699007987976)
Finished Training
Total time taken: 29.087079763412476
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.388
[3,     4] loss: 1.389
[4,     4] loss: 1.381
[5,     4] loss: 1.382
[6,     4] loss: 1.379
[7,     4] loss: 1.370
[8,     4] loss: 1.331
[9,     4] loss: 1.295
[10,     4] loss: 1.260
[11,     4] loss: 1.224
[12,     4] loss: 1.123
[13,     4] loss: 1.089
[14,     4] loss: 1.070
[15,     4] loss: 1.253
[16,     4] loss: 1.063
[17,     4] loss: 0.971
[18,     4] loss: 0.949
[19,     4] loss: 1.008
[20,     4] loss: 0.952
[21,     4] loss: 0.899
[22,     4] loss: 0.907
[23,     4] loss: 0.978
[24,     4] loss: 0.936
[25,     4] loss: 0.879
[26,     4] loss: 0.885
[27,     4] loss: 0.896
[28,     4] loss: 0.882
[29,     4] loss: 0.886
[30,     4] loss: 0.867
[31,     4] loss: 0.950
[32,     4] loss: 0.885
[33,     4] loss: 0.864
[34,     4] loss: 0.867
[35,     4] loss: 0.811
[36,     4] loss: 0.820
[37,     4] loss: 0.807
[38,     4] loss: 0.792
[39,     4] loss: 0.772
[40,     4] loss: 0.761
[41,     4] loss: 0.805
[42,     4] loss: 0.831
[43,     4] loss: 0.833
[44,     4] loss: 0.816
[45,     4] loss: 0.774
[46,     4] loss: 0.778
[47,     4] loss: 0.752
[48,     4] loss: 0.807
[49,     4] loss: 0.962
[50,     4] loss: 0.842
[51,     4] loss: 0.896
[52,     4] loss: 0.883
[53,     4] loss: 0.791
[54,     4] loss: 0.743
[55,     4] loss: 0.759
[56,     4] loss: 0.758
[57,     4] loss: 0.782
[58,     4] loss: 0.759
[59,     4] loss: 0.750
[60,     4] loss: 0.779
[61,     4] loss: 0.772
[62,     4] loss: 0.780
[63,     4] loss: 0.768
[64,     4] loss: 0.812
[65,     4] loss: 0.757
[66,     4] loss: 0.762
Early stopping applied (best metric=0.4527512788772583)
Finished Training
Total time taken: 33.290090560913086
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.385
[3,     4] loss: 1.384
[4,     4] loss: 1.382
[5,     4] loss: 1.375
[6,     4] loss: 1.352
[7,     4] loss: 1.319
[8,     4] loss: 1.295
[9,     4] loss: 1.239
[10,     4] loss: 1.181
[11,     4] loss: 1.135
[12,     4] loss: 1.126
[13,     4] loss: 1.129
[14,     4] loss: 1.046
[15,     4] loss: 1.115
[16,     4] loss: 1.030
[17,     4] loss: 1.017
[18,     4] loss: 0.990
[19,     4] loss: 0.926
[20,     4] loss: 0.979
[21,     4] loss: 0.887
[22,     4] loss: 0.895
[23,     4] loss: 0.821
[24,     4] loss: 0.869
[25,     4] loss: 0.881
[26,     4] loss: 0.943
[27,     4] loss: 0.985
[28,     4] loss: 0.894
[29,     4] loss: 0.853
[30,     4] loss: 0.833
[31,     4] loss: 0.871
[32,     4] loss: 0.816
[33,     4] loss: 0.895
[34,     4] loss: 0.833
[35,     4] loss: 0.840
[36,     4] loss: 0.815
[37,     4] loss: 0.819
[38,     4] loss: 0.768
[39,     4] loss: 0.764
[40,     4] loss: 0.776
[41,     4] loss: 0.770
[42,     4] loss: 0.764
[43,     4] loss: 0.777
[44,     4] loss: 0.755
[45,     4] loss: 0.768
[46,     4] loss: 0.766
[47,     4] loss: 0.777
[48,     4] loss: 0.740
[49,     4] loss: 0.786
[50,     4] loss: 0.767
[51,     4] loss: 0.752
[52,     4] loss: 0.751
[53,     4] loss: 0.805
[54,     4] loss: 0.839
[55,     4] loss: 0.811
[56,     4] loss: 0.811
[57,     4] loss: 0.779
[58,     4] loss: 0.752
[59,     4] loss: 0.758
[60,     4] loss: 0.786
[61,     4] loss: 0.890
[62,     4] loss: 0.810
[63,     4] loss: 0.797
[64,     4] loss: 0.821
[65,     4] loss: 0.775
[66,     4] loss: 0.783
[67,     4] loss: 0.752
Early stopping applied (best metric=0.36794716119766235)
Finished Training
Total time taken: 33.98709154129028
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.400
[2,     4] loss: 1.385
[3,     4] loss: 1.387
[4,     4] loss: 1.381
[5,     4] loss: 1.376
[6,     4] loss: 1.350
[7,     4] loss: 1.317
[8,     4] loss: 1.261
[9,     4] loss: 1.186
[10,     4] loss: 1.178
[11,     4] loss: 1.110
[12,     4] loss: 1.035
[13,     4] loss: 1.007
[14,     4] loss: 0.989
[15,     4] loss: 0.996
[16,     4] loss: 0.981
[17,     4] loss: 0.979
[18,     4] loss: 0.950
[19,     4] loss: 0.841
[20,     4] loss: 0.926
[21,     4] loss: 0.857
[22,     4] loss: 0.857
[23,     4] loss: 0.800
[24,     4] loss: 0.892
[25,     4] loss: 0.921
[26,     4] loss: 0.876
[27,     4] loss: 0.853
[28,     4] loss: 0.794
[29,     4] loss: 0.782
[30,     4] loss: 0.806
[31,     4] loss: 0.783
[32,     4] loss: 0.767
[33,     4] loss: 0.804
[34,     4] loss: 0.801
[35,     4] loss: 0.910
[36,     4] loss: 0.872
[37,     4] loss: 0.822
[38,     4] loss: 0.839
[39,     4] loss: 0.805
[40,     4] loss: 0.795
[41,     4] loss: 0.780
[42,     4] loss: 0.768
[43,     4] loss: 0.791
[44,     4] loss: 0.748
[45,     4] loss: 0.810
[46,     4] loss: 0.759
[47,     4] loss: 0.759
[48,     4] loss: 0.742
[49,     4] loss: 0.739
[50,     4] loss: 0.728
[51,     4] loss: 0.744
[52,     4] loss: 0.757
[53,     4] loss: 0.743
[54,     4] loss: 0.768
[55,     4] loss: 0.741
[56,     4] loss: 0.781
[57,     4] loss: 0.769
[58,     4] loss: 0.767
Early stopping applied (best metric=0.4803723692893982)
Finished Training
Total time taken: 29.43808102607727
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.386
[3,     4] loss: 1.386
[4,     4] loss: 1.384
[5,     4] loss: 1.376
[6,     4] loss: 1.381
[7,     4] loss: 1.363
[8,     4] loss: 1.345
[9,     4] loss: 1.301
[10,     4] loss: 1.244
[11,     4] loss: 1.177
[12,     4] loss: 1.110
[13,     4] loss: 1.032
[14,     4] loss: 1.098
[15,     4] loss: 1.101
[16,     4] loss: 1.117
[17,     4] loss: 1.121
[18,     4] loss: 1.027
[19,     4] loss: 1.009
[20,     4] loss: 0.981
[21,     4] loss: 0.929
[22,     4] loss: 0.865
[23,     4] loss: 0.880
[24,     4] loss: 0.916
[25,     4] loss: 1.063
[26,     4] loss: 0.960
[27,     4] loss: 0.948
[28,     4] loss: 0.957
[29,     4] loss: 0.861
[30,     4] loss: 0.846
[31,     4] loss: 0.808
[32,     4] loss: 0.784
[33,     4] loss: 0.795
[34,     4] loss: 0.865
[35,     4] loss: 0.813
[36,     4] loss: 0.810
[37,     4] loss: 0.821
[38,     4] loss: 0.831
[39,     4] loss: 0.821
[40,     4] loss: 0.805
[41,     4] loss: 0.984
[42,     4] loss: 0.967
[43,     4] loss: 1.000
[44,     4] loss: 0.946
[45,     4] loss: 0.894
[46,     4] loss: 0.817
[47,     4] loss: 0.773
[48,     4] loss: 0.777
[49,     4] loss: 0.771
[50,     4] loss: 0.768
[51,     4] loss: 0.796
[52,     4] loss: 0.801
[53,     4] loss: 0.812
[54,     4] loss: 0.780
[55,     4] loss: 0.764
[56,     4] loss: 0.765
[57,     4] loss: 0.749
[58,     4] loss: 0.743
[59,     4] loss: 0.751
[60,     4] loss: 0.741
[61,     4] loss: 0.797
[62,     4] loss: 0.775
[63,     4] loss: 0.784
[64,     4] loss: 0.891
[65,     4] loss: 0.911
[66,     4] loss: 0.967
[67,     4] loss: 0.861
[68,     4] loss: 0.842
[69,     4] loss: 0.777
[70,     4] loss: 0.756
[71,     4] loss: 0.754
[72,     4] loss: 0.744
[73,     4] loss: 0.815
[74,     4] loss: 0.779
[75,     4] loss: 0.800
[76,     4] loss: 0.785
[77,     4] loss: 0.748
[78,     4] loss: 0.762
[79,     4] loss: 0.754
[80,     4] loss: 0.817
[81,     4] loss: 0.779
[82,     4] loss: 0.766
[83,     4] loss: 0.806
[84,     4] loss: 0.757
[85,     4] loss: 0.800
[86,     4] loss: 0.768
[87,     4] loss: 0.762
[88,     4] loss: 0.839
[89,     4] loss: 0.764
[90,     4] loss: 0.757
[91,     4] loss: 0.768
[92,     4] loss: 0.785
[93,     4] loss: 0.774
[94,     4] loss: 0.780
[95,     4] loss: 0.834
[96,     4] loss: 0.782
[97,     4] loss: 0.825
[98,     4] loss: 0.875
[99,     4] loss: 0.799
[100,     4] loss: 0.825
[101,     4] loss: 0.829
[102,     4] loss: 0.819
[103,     4] loss: 0.770
[104,     4] loss: 0.761
[105,     4] loss: 0.766
[106,     4] loss: 0.753
[107,     4] loss: 0.761
[108,     4] loss: 0.823
[109,     4] loss: 0.774
[110,     4] loss: 0.759
[111,     4] loss: 0.735
[112,     4] loss: 0.772
[113,     4] loss: 0.771
[114,     4] loss: 0.825
[115,     4] loss: 0.786
[116,     4] loss: 0.846
[117,     4] loss: 0.864
Early stopping applied (best metric=0.2625488340854645)
Finished Training
Total time taken: 58.78615975379944
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.388
[2,     4] loss: 1.382
[3,     4] loss: 1.393
[4,     4] loss: 1.382
[5,     4] loss: 1.382
[6,     4] loss: 1.370
[7,     4] loss: 1.348
[8,     4] loss: 1.321
[9,     4] loss: 1.278
[10,     4] loss: 1.235
[11,     4] loss: 1.204
[12,     4] loss: 1.146
[13,     4] loss: 1.073
[14,     4] loss: 1.040
[15,     4] loss: 1.042
[16,     4] loss: 1.003
[17,     4] loss: 0.951
[18,     4] loss: 0.916
[19,     4] loss: 0.964
[20,     4] loss: 0.915
[21,     4] loss: 1.151
[22,     4] loss: 1.060
[23,     4] loss: 1.023
[24,     4] loss: 0.947
[25,     4] loss: 0.862
[26,     4] loss: 0.879
[27,     4] loss: 0.853
[28,     4] loss: 0.864
[29,     4] loss: 0.791
[30,     4] loss: 0.795
[31,     4] loss: 0.800
[32,     4] loss: 0.799
[33,     4] loss: 0.798
[34,     4] loss: 0.752
[35,     4] loss: 0.794
[36,     4] loss: 0.791
[37,     4] loss: 0.842
[38,     4] loss: 0.914
[39,     4] loss: 0.946
[40,     4] loss: 0.973
[41,     4] loss: 0.916
[42,     4] loss: 0.845
[43,     4] loss: 0.828
[44,     4] loss: 0.811
[45,     4] loss: 0.755
[46,     4] loss: 0.765
[47,     4] loss: 0.760
[48,     4] loss: 0.784
[49,     4] loss: 0.775
[50,     4] loss: 0.807
[51,     4] loss: 0.738
[52,     4] loss: 0.743
[53,     4] loss: 0.763
[54,     4] loss: 0.743
[55,     4] loss: 0.730
[56,     4] loss: 0.727
[57,     4] loss: 0.729
[58,     4] loss: 0.726
[59,     4] loss: 0.732
[60,     4] loss: 0.759
[61,     4] loss: 0.829
[62,     4] loss: 0.769
[63,     4] loss: 0.750
[64,     4] loss: 0.770
Early stopping applied (best metric=0.3431367576122284)
Finished Training
Total time taken: 31.96908450126648
{'Hydroxylation-K Validation Accuracy': 0.7912825059101655, 'Hydroxylation-K Validation Sensitivity': 0.7385185185185186, 'Hydroxylation-K Validation Specificity': 0.8052631578947368, 'Hydroxylation-K Validation Precision': 0.49015143439292047, 'Hydroxylation-K AUC ROC': 0.827504873294347, 'Hydroxylation-K AUC PR': 0.597638329902181, 'Hydroxylation-K MCC': 0.4747686437441073, 'Hydroxylation-K F1': 0.584914475585719, 'Validation Loss (Hydroxylation-K)': 0.40979307889938354, 'Methylation-K Validation Accuracy': 0.8253763815171976, 'Methylation-K Validation Sensitivity': 0.12977276380996317, 'Methylation-K Validation Specificity': 0.9008162766366173, 'Methylation-K Validation Precision': 0.1248119350160912, 'Methylation-K AUC ROC': 0.5493747929573387, 'Methylation-K AUC PR': 0.11426332536161979, 'Methylation-K MCC': 0.029598531061275274, 'Methylation-K F1': 0.1208305875745193, 'Validation Loss (Methylation-K)': 0.9088274041811625, 'Validation Loss (total)': 1.318620491027832, 'TimeToTrain': 35.47769600550334}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002159458360817857,
 'learning_rate_Hydroxylation-K': 0.0062361150208440404,
 'learning_rate_Methylation-K': 0.003578308747630114,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.47861627705705917,
 'loss_weight_Methylation-K': 0.7268702966962441,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2271414770,
 'sample_weights': [0.17540027311584389, 0.8818694280795767],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.580531869983031,
 'weight_decay_Hydroxylation-K': 4.077688850253224,
 'weight_decay_Methylation-K': 9.601656228924275}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.378
[2,     4] loss: 1.384
[3,     4] loss: 1.383
[4,     4] loss: 1.382
[5,     4] loss: 1.380
[6,     4] loss: 1.376
[7,     4] loss: 1.363
[8,     4] loss: 1.336
[9,     4] loss: 1.306
[10,     4] loss: 1.286
[11,     4] loss: 1.200
[12,     4] loss: 1.210
[13,     4] loss: 1.159
[14,     4] loss: 1.113
[15,     4] loss: 1.176
[16,     4] loss: 1.026
[17,     4] loss: 1.023
[18,     4] loss: 0.996
[19,     4] loss: 1.028
[20,     4] loss: 0.980
[21,     4] loss: 0.914
[22,     4] loss: 0.942
[23,     4] loss: 0.920
[24,     4] loss: 0.906
[25,     4] loss: 0.898
[26,     4] loss: 0.849
[27,     4] loss: 0.926
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008704420877065272,
 'learning_rate_Hydroxylation-K': 0.0018604078998825766,
 'learning_rate_Methylation-K': 0.00826197900611915,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2714585454842321,
 'loss_weight_Methylation-K': 0.3786675833470307,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1845460548,
 'sample_weights': [0.47861627705705917, 0.7268702966962441],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.432465226988425,
 'weight_decay_Hydroxylation-K': 5.537338998190807,
 'weight_decay_Methylation-K': 6.5709930059879404}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.402
[2,     4] loss: 1.387
[3,     4] loss: 1.389
[4,     4] loss: 1.385
[5,     4] loss: 1.381
[6,     4] loss: 1.382
[7,     4] loss: 1.374
[8,     4] loss: 1.368
[9,     4] loss: 1.358
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004570723472047371,
 'learning_rate_Hydroxylation-K': 0.0018721545804450046,
 'learning_rate_Methylation-K': 0.006913735011412882,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7417929336030772,
 'loss_weight_Methylation-K': 0.9025072778546068,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2248568893,
 'sample_weights': [0.2714585454842321, 0.3786675833470307],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.0635965600535355,
 'weight_decay_Hydroxylation-K': 6.943151344888502,
 'weight_decay_Methylation-K': 3.9964978529922752}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.387
[3,     4] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00848208975833269,
 'learning_rate_Hydroxylation-K': 0.009568049748349097,
 'learning_rate_Methylation-K': 0.005773714034940472,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3850091602405534,
 'loss_weight_Methylation-K': 0.29382971372524913,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2999864915,
 'sample_weights': [0.7417929336030772, 0.9025072778546068],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.259374884069125,
 'weight_decay_Hydroxylation-K': 3.199811338850914,
 'weight_decay_Methylation-K': 3.006460034245376}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.379
[3,     4] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0021523854750736056,
 'learning_rate_Hydroxylation-K': 0.00515866261937179,
 'learning_rate_Methylation-K': 0.0035267266919276835,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6480847529774536,
 'loss_weight_Methylation-K': 0.7175764964534258,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1867087893,
 'sample_weights': [0.3850091602405534, 0.29382971372524913],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.190756351705403,
 'weight_decay_Hydroxylation-K': 5.806933707248968,
 'weight_decay_Methylation-K': 7.200532271740103}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.384
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013446801543772265,
 'learning_rate_Hydroxylation-K': 0.0054736149687235145,
 'learning_rate_Methylation-K': 0.005727859899987768,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7437386688332762,
 'loss_weight_Methylation-K': 0.8335858062396797,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1589969303,
 'sample_weights': [0.6480847529774536, 0.7175764964534258],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.575063071163476,
 'weight_decay_Hydroxylation-K': 7.411838973162035,
 'weight_decay_Methylation-K': 0.12762663017838494}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.396
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003815079831938599,
 'learning_rate_Hydroxylation-K': 0.0029851342417747118,
 'learning_rate_Methylation-K': 0.008336499086253259,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9951398691913088,
 'loss_weight_Methylation-K': 0.7209034822229708,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2624713746,
 'sample_weights': [0.7437386688332762, 0.8335858062396797],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.368148851072294,
 'weight_decay_Hydroxylation-K': 4.188671100414394,
 'weight_decay_Methylation-K': 1.6996707529897503}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.402
[2,     4] loss: 1.389
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.380
[6,     4] loss: 1.384
[7,     4] loss: 1.380
[8,     4] loss: 1.375
[9,     4] loss: 1.366
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004354991568959163,
 'learning_rate_Hydroxylation-K': 0.0033982774515504566,
 'learning_rate_Methylation-K': 0.0021940176139031574,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.108022009986452,
 'loss_weight_Methylation-K': 0.6339418530043541,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4004621907,
 'sample_weights': [0.9951398691913088, 0.7209034822229708],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.976377278621067,
 'weight_decay_Hydroxylation-K': 2.498388330829291,
 'weight_decay_Methylation-K': 5.782914506276909}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.390
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005046376684905476,
 'learning_rate_Hydroxylation-K': 0.004278148599149517,
 'learning_rate_Methylation-K': 0.0007316604004789315,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6510844075622646,
 'loss_weight_Methylation-K': 0.8803314307019041,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3674901406,
 'sample_weights': [0.108022009986452, 0.6339418530043541],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.516941941669195,
 'weight_decay_Hydroxylation-K': 5.8960127343939535,
 'weight_decay_Methylation-K': 1.483411153267245}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.380
[3,     4] loss: 1.385
[4,     4] loss: 1.380
[5,     4] loss: 1.369
[6,     4] loss: 1.323
[7,     4] loss: 1.277
[8,     4] loss: 1.196
[9,     4] loss: 1.161
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004198781024220121,
 'learning_rate_Hydroxylation-K': 0.006863085291676556,
 'learning_rate_Methylation-K': 0.0041414659868894465,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.461056983589966,
 'loss_weight_Methylation-K': 0.766692031293779,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1472071544,
 'sample_weights': [0.6510844075622646, 0.8803314307019041],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.700483790237425,
 'weight_decay_Hydroxylation-K': 3.386538614847926,
 'weight_decay_Methylation-K': 2.5057846236381263}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.399
[2,     4] loss: 1.394
[3,     4] loss: 1.383
[4,     4] loss: 1.382
[5,     4] loss: 1.392
[6,     4] loss: 1.383
[7,     4] loss: 1.393
[8,     4] loss: 1.377
[9,     4] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006401146168481416,
 'learning_rate_Hydroxylation-K': 0.004095189605504841,
 'learning_rate_Methylation-K': 0.007741866415241882,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.33132296909860465,
 'loss_weight_Methylation-K': 0.9709438198617335,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1907233475,
 'sample_weights': [0.461056983589966, 0.766692031293779],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.461318114262368,
 'weight_decay_Hydroxylation-K': 7.526109681626121,
 'weight_decay_Methylation-K': 8.269369079983885}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.386
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006951774428854826,
 'learning_rate_Hydroxylation-K': 0.007011944357551233,
 'learning_rate_Methylation-K': 0.009245059867725542,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.293065919777047,
 'loss_weight_Methylation-K': 0.9852809462413096,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3857573573,
 'sample_weights': [0.33132296909860465, 0.9709438198617335],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.170102565780371,
 'weight_decay_Hydroxylation-K': 5.3036492359316405,
 'weight_decay_Methylation-K': 8.121421934471279}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.392
[3,     4] loss: 1.379
[4,     4] loss: 1.385
[5,     4] loss: 1.370
[6,     4] loss: 1.368
[7,     4] loss: 1.360
[8,     4] loss: 1.344
[9,     4] loss: 1.317
[10,     4] loss: 1.279
[11,     4] loss: 1.248
[12,     4] loss: 1.212
[13,     4] loss: 1.135
[14,     4] loss: 1.062
[15,     4] loss: 1.052
[16,     4] loss: 1.022
[17,     4] loss: 0.984
[18,     4] loss: 0.934
[19,     4] loss: 0.888
[20,     4] loss: 0.902
[21,     4] loss: 0.912
[22,     4] loss: 0.866
[23,     4] loss: 0.842
[24,     4] loss: 0.836
[25,     4] loss: 0.810
[26,     4] loss: 0.817
[27,     4] loss: 0.855
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007802240115405399,
 'learning_rate_Hydroxylation-K': 0.002009528721178648,
 'learning_rate_Methylation-K': 0.0066804051226140885,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9830493858243793,
 'loss_weight_Methylation-K': 0.8332594468655707,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1265838754,
 'sample_weights': [0.293065919777047, 0.9852809462413096],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.828197384577814,
 'weight_decay_Hydroxylation-K': 8.767310919485622,
 'weight_decay_Methylation-K': 0.6965976591050794}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.379
[3,     4] loss: 1.375
[4,     4] loss: 1.372
[5,     4] loss: 1.363
[6,     4] loss: 1.333
[7,     4] loss: 1.332
[8,     4] loss: 1.295
[9,     4] loss: 1.240
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030569531510233642,
 'learning_rate_Hydroxylation-K': 0.003960220115815772,
 'learning_rate_Methylation-K': 0.0027744516120566626,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9234178736384206,
 'loss_weight_Methylation-K': 0.9697337846582342,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 116384070,
 'sample_weights': [0.9830493858243793, 0.8332594468655707],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.074823877836086,
 'weight_decay_Hydroxylation-K': 9.5406706318978,
 'weight_decay_Methylation-K': 1.759178776464772}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.390
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003948123913182957,
 'learning_rate_Hydroxylation-K': 0.009401123768862242,
 'learning_rate_Methylation-K': 0.006672408781222243,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5025771894881598,
 'loss_weight_Methylation-K': 0.4146091268423193,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1258207171,
 'sample_weights': [0.9234178736384206, 0.9697337846582342],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.361718231636104,
 'weight_decay_Hydroxylation-K': 7.906408839267348,
 'weight_decay_Methylation-K': 2.1183076705327033}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.392
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002590417176347982,
 'learning_rate_Hydroxylation-K': 0.009231627426095453,
 'learning_rate_Methylation-K': 0.0034052231845658944,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4716495212061604,
 'loss_weight_Methylation-K': 0.5766629404104145,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3090359879,
 'sample_weights': [0.5025771894881598, 0.4146091268423193],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.289234398423848,
 'weight_decay_Hydroxylation-K': 4.276830502836204,
 'weight_decay_Methylation-K': 8.717939713222693}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.387
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016647100795376285,
 'learning_rate_Hydroxylation-K': 0.007935821593343124,
 'learning_rate_Methylation-K': 0.006823885364832408,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3061604861396542,
 'loss_weight_Methylation-K': 0.9276372494850835,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 813946341,
 'sample_weights': [0.4716495212061604, 0.5766629404104145],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.032250406085407,
 'weight_decay_Hydroxylation-K': 4.893509342597826,
 'weight_decay_Methylation-K': 8.834821438090678}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.380
[3,     4] loss: 1.390
[4,     4] loss: 1.388
[5,     4] loss: 1.378
[6,     4] loss: 1.370
[7,     4] loss: 1.348
[8,     4] loss: 1.319
[9,     4] loss: 1.256
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007102360297085158,
 'learning_rate_Hydroxylation-K': 0.0019473464238656572,
 'learning_rate_Methylation-K': 0.005974848022923796,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6921404732019535,
 'loss_weight_Methylation-K': 0.9684195360555625,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3197849890,
 'sample_weights': [0.3061604861396542, 0.9276372494850835],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.841383216710698,
 'weight_decay_Hydroxylation-K': 6.451629644138564,
 'weight_decay_Methylation-K': 1.6428108146512406}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.387
[3,     4] loss: 1.385
[4,     4] loss: 1.386
[5,     4] loss: 1.378
[6,     4] loss: 1.371
[7,     4] loss: 1.362
[8,     4] loss: 1.345
[9,     4] loss: 1.327
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00018141280792002617,
 'learning_rate_Hydroxylation-K': 0.0029738599495836627,
 'learning_rate_Methylation-K': 0.002290030633244001,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.024065698702720226,
 'loss_weight_Methylation-K': 0.5392869665686515,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3106378437,
 'sample_weights': [0.6921404732019535, 0.9684195360555625],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.521686583180224,
 'weight_decay_Hydroxylation-K': 2.021192276886138,
 'weight_decay_Methylation-K': 9.706480876127861}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.377
[2,     4] loss: 1.392
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002789919145597786,
 'learning_rate_Hydroxylation-K': 0.00836007313447572,
 'learning_rate_Methylation-K': 0.004651926397596939,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2615557076145718,
 'loss_weight_Methylation-K': 0.8471596936454752,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3870584420,
 'sample_weights': [0.024065698702720226, 0.5392869665686515],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.6971401682407272,
 'weight_decay_Hydroxylation-K': 2.263277641408088,
 'weight_decay_Methylation-K': 9.865212090654039}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.396
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002012922507299424,
 'learning_rate_Hydroxylation-K': 0.005753111050781904,
 'learning_rate_Methylation-K': 0.009144300245907165,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3311369116661633,
 'loss_weight_Methylation-K': 0.8641362231619789,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4199849730,
 'sample_weights': [0.2615557076145718, 0.8471596936454752],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.035282075900312,
 'weight_decay_Hydroxylation-K': 5.97980178645548,
 'weight_decay_Methylation-K': 8.459312009494232}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.384
[3,     4] loss: 1.385
[4,     4] loss: 1.379
[5,     4] loss: 1.368
[6,     4] loss: 1.343
[7,     4] loss: 1.300
[8,     4] loss: 1.244
[9,     4] loss: 1.197
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015535027012147165,
 'learning_rate_Hydroxylation-K': 0.00815865415825667,
 'learning_rate_Methylation-K': 0.009106386610791457,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.20169987728210365,
 'loss_weight_Methylation-K': 0.8780264929483044,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4151401802,
 'sample_weights': [0.3311369116661633, 0.8641362231619789],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.524802614218648,
 'weight_decay_Hydroxylation-K': 9.297824215592511,
 'weight_decay_Methylation-K': 9.738752725436695}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.372
[3,     4] loss: 1.389
[4,     4] loss: 1.381
[5,     4] loss: 1.344
[6,     4] loss: 1.330
[7,     4] loss: 1.275
[8,     4] loss: 1.229
[9,     4] loss: 1.176
[10,     4] loss: 1.110
[11,     4] loss: 1.119
[12,     4] loss: 1.187
[13,     4] loss: 1.037
[14,     4] loss: 1.089
[15,     4] loss: 1.065
[16,     4] loss: 0.975
[17,     4] loss: 0.967
[18,     4] loss: 0.982
[19,     4] loss: 0.945
[20,     4] loss: 0.991
[21,     4] loss: 0.983
[22,     4] loss: 0.969
[23,     4] loss: 0.916
[24,     4] loss: 0.897
[25,     4] loss: 0.882
[26,     4] loss: 0.895
[27,     4] loss: 0.849
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003991791338497162,
 'learning_rate_Hydroxylation-K': 0.0037533390938060823,
 'learning_rate_Methylation-K': 0.002820748078475161,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.33539140218588137,
 'loss_weight_Methylation-K': 0.7883307962592527,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1303066397,
 'sample_weights': [0.20169987728210365, 0.8780264929483044],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.180748530193533,
 'weight_decay_Hydroxylation-K': 8.896595576568632,
 'weight_decay_Methylation-K': 1.064646238822147}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.389
[3,     4] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005984071749915222,
 'learning_rate_Hydroxylation-K': 0.007578475458252058,
 'learning_rate_Methylation-K': 0.0005306642696498667,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.637392241297217,
 'loss_weight_Methylation-K': 0.4511807362141331,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3935047566,
 'sample_weights': [0.33539140218588137, 0.7883307962592527],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.11892293888972,
 'weight_decay_Hydroxylation-K': 6.762963246880108,
 'weight_decay_Methylation-K': 9.498681341823312}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.381
[2,     4] loss: 1.389
[3,     4] loss: 1.387
[4,     4] loss: 1.388
[5,     4] loss: 1.387
[6,     4] loss: 1.386
[7,     4] loss: 1.387
[8,     4] loss: 1.386
[9,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000916908938843623,
 'learning_rate_Hydroxylation-K': 0.006564117249514961,
 'learning_rate_Methylation-K': 0.007490193272401015,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5334349367757397,
 'loss_weight_Methylation-K': 0.9757054134304849,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1011170184,
 'sample_weights': [0.637392241297217, 0.4511807362141331],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.930640794806938,
 'weight_decay_Hydroxylation-K': 4.973341751159057,
 'weight_decay_Methylation-K': 7.078115285538445}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.396
[3,     4] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00780583211798022,
 'learning_rate_Hydroxylation-K': 0.002197847804811013,
 'learning_rate_Methylation-K': 0.003537329466526076,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9980438330740405,
 'loss_weight_Methylation-K': 0.7074169815936451,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3782063290,
 'sample_weights': [0.5334349367757397, 0.9757054134304849],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.23281313531545,
 'weight_decay_Hydroxylation-K': 3.007821330766824,
 'weight_decay_Methylation-K': 3.6704972190825247}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.394
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004620543736008863,
 'learning_rate_Hydroxylation-K': 0.004357031895386912,
 'learning_rate_Methylation-K': 0.0012529271306683898,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6483930820119619,
 'loss_weight_Methylation-K': 0.5638109984936002,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2524563914,
 'sample_weights': [0.9980438330740405, 0.7074169815936451],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.390548548362401,
 'weight_decay_Hydroxylation-K': 9.924260845189636,
 'weight_decay_Methylation-K': 4.050524226849616}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.403
[2,     4] loss: 1.389
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003482067518652852,
 'learning_rate_Hydroxylation-K': 0.0029673895267053043,
 'learning_rate_Methylation-K': 0.008465485572495707,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.35308633942514,
 'loss_weight_Methylation-K': 0.879771448005005,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3140709465,
 'sample_weights': [0.6483930820119619, 0.5638109984936002],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.4614375131603876,
 'weight_decay_Hydroxylation-K': 7.136079722159521,
 'weight_decay_Methylation-K': 8.89851762465312}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.386
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016737837027436097,
 'learning_rate_Hydroxylation-K': 0.0007923774034500538,
 'learning_rate_Methylation-K': 0.0019440691424455312,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7760899649027774,
 'loss_weight_Methylation-K': 0.13661446753328574,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4005397030,
 'sample_weights': [0.35308633942514, 0.879771448005005],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.678440181851922,
 'weight_decay_Hydroxylation-K': 7.79838480340498,
 'weight_decay_Methylation-K': 4.872642395958381}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.379
[3,     4] loss: 1.370
[4,     4] loss: 1.338
[5,     4] loss: 1.292
[6,     4] loss: 1.275
[7,     4] loss: 1.225
[8,     4] loss: 1.255
[9,     4] loss: 1.141
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012170894212104398,
 'learning_rate_Hydroxylation-K': 0.008581547484468632,
 'learning_rate_Methylation-K': 0.0033453788611086757,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4834075620138164,
 'loss_weight_Methylation-K': 0.6965851830304606,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2121331619,
 'sample_weights': [0.7760899649027774, 0.13661446753328574],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.104050044809394,
 'weight_decay_Hydroxylation-K': 3.912124874207307,
 'weight_decay_Methylation-K': 3.555948960362793}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.387
[3,     4] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016750153297866084,
 'learning_rate_Hydroxylation-K': 0.002084076410717984,
 'learning_rate_Methylation-K': 0.0032800496793904477,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7137137090762673,
 'loss_weight_Methylation-K': 0.46126202045164005,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 880474343,
 'sample_weights': [0.4834075620138164, 0.6965851830304606],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.705747830789134,
 'weight_decay_Hydroxylation-K': 6.917384585857381,
 'weight_decay_Methylation-K': 9.972418817142932}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.381
[2,     4] loss: 1.395
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 8.148149120466332e-05,
 'learning_rate_Hydroxylation-K': 0.0087100716408525,
 'learning_rate_Methylation-K': 0.0023382679073942567,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.750486191692266,
 'loss_weight_Methylation-K': 0.5693976892616908,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3064428388,
 'sample_weights': [0.7137137090762673, 0.46126202045164005],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.293684839233792,
 'weight_decay_Hydroxylation-K': 6.556749999317045,
 'weight_decay_Methylation-K': 8.388378964673391}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.401
[3,     4] loss: 1.390
[4,     4] loss: 1.393
[5,     4] loss: 1.399
[6,     4] loss: 1.388
[7,     4] loss: 1.388
[8,     4] loss: 1.385
[9,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027098721293793266,
 'learning_rate_Hydroxylation-K': 0.0027190904334555635,
 'learning_rate_Methylation-K': 0.00969058792323521,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.12047069777826405,
 'loss_weight_Methylation-K': 0.923152893105822,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1206615821,
 'sample_weights': [0.750486191692266, 0.5693976892616908],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5804640973955983,
 'weight_decay_Hydroxylation-K': 8.396154164102123,
 'weight_decay_Methylation-K': 9.936144378387601}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.390
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001057175857996435,
 'learning_rate_Hydroxylation-K': 0.005720632629242504,
 'learning_rate_Methylation-K': 0.005081462356110358,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3843735212552704,
 'loss_weight_Methylation-K': 0.8113989341695936,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3578966150,
 'sample_weights': [0.12047069777826405, 0.923152893105822],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.37135803478863,
 'weight_decay_Hydroxylation-K': 3.9563530866121064,
 'weight_decay_Methylation-K': 9.163896714367684}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.390
[3,     4] loss: 1.386
[4,     4] loss: 1.378
[5,     4] loss: 1.374
[6,     4] loss: 1.359
[7,     4] loss: 1.339
[8,     4] loss: 1.313
[9,     4] loss: 1.256
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001440742118165571,
 'learning_rate_Hydroxylation-K': 0.0034832411971219613,
 'learning_rate_Methylation-K': 0.006343301658249466,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.05796863655897609,
 'loss_weight_Methylation-K': 0.9733744308476119,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 288384284,
 'sample_weights': [0.3843735212552704, 0.8113989341695936],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.044658487291479,
 'weight_decay_Hydroxylation-K': 8.995550395624333,
 'weight_decay_Methylation-K': 8.842282904299667}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.380
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011278795314349178,
 'learning_rate_Hydroxylation-K': 0.003295533077067406,
 'learning_rate_Methylation-K': 0.005044730894180121,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.873051557126812,
 'loss_weight_Methylation-K': 0.25730192936672813,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3830877372,
 'sample_weights': [0.05796863655897609, 0.9733744308476119],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.4383369689411216,
 'weight_decay_Hydroxylation-K': 3.1154991839490243,
 'weight_decay_Methylation-K': 6.867550204606561}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.383
[3,     4] loss: 1.379
[4,     4] loss: 1.374
[5,     4] loss: 1.353
[6,     4] loss: 1.329
[7,     4] loss: 1.290
[8,     4] loss: 1.285
[9,     4] loss: 1.255
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001712682907590135,
 'learning_rate_Hydroxylation-K': 0.009757028793493093,
 'learning_rate_Methylation-K': 0.006554232357589388,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21519728596556031,
 'loss_weight_Methylation-K': 0.8299440371442907,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2383140601,
 'sample_weights': [0.873051557126812, 0.25730192936672813],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.731347619119893,
 'weight_decay_Hydroxylation-K': 5.547967173860175,
 'weight_decay_Methylation-K': 2.1952750943769876}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.387
[3,     4] loss: 1.387
[4,     4] loss: 1.380
[5,     4] loss: 1.378
[6,     4] loss: 1.369
[7,     4] loss: 1.353
[8,     4] loss: 1.312
[9,     4] loss: 1.256
[10,     4] loss: 1.230
[11,     4] loss: 1.187
[12,     4] loss: 1.160
[13,     4] loss: 1.128
[14,     4] loss: 1.116
[15,     4] loss: 0.997
[16,     4] loss: 0.995
[17,     4] loss: 0.943
[18,     4] loss: 0.932
[19,     4] loss: 0.861
[20,     4] loss: 0.923
[21,     4] loss: 0.888
[22,     4] loss: 0.877
[23,     4] loss: 0.979
[24,     4] loss: 0.866
[25,     4] loss: 0.892
[26,     4] loss: 0.853
[27,     4] loss: 0.821
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008620858472512836,
 'learning_rate_Hydroxylation-K': 0.004550821116258712,
 'learning_rate_Methylation-K': 0.009899696247726566,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.15667373631376444,
 'loss_weight_Methylation-K': 0.9980442052687027,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2562397444,
 'sample_weights': [0.21519728596556031, 0.8299440371442907],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.277310938031358,
 'weight_decay_Hydroxylation-K': 7.810203012252761,
 'weight_decay_Methylation-K': 9.44681606893264}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.385
[3,     4] loss: 1.386
[4,     4] loss: 1.383
[5,     4] loss: 1.383
[6,     4] loss: 1.376
[7,     4] loss: 1.364
[8,     4] loss: 1.358
[9,     4] loss: 1.315
[10,     4] loss: 1.283
[11,     4] loss: 1.255
[12,     4] loss: 1.232
[13,     4] loss: 1.136
[14,     4] loss: 1.071
[15,     4] loss: 1.024
[16,     4] loss: 1.051
[17,     4] loss: 0.977
[18,     4] loss: 1.049
[19,     4] loss: 0.966
[20,     4] loss: 0.961
[21,     4] loss: 0.955
[22,     4] loss: 0.884
[23,     4] loss: 0.856
[24,     4] loss: 0.833
[25,     4] loss: 0.825
[26,     4] loss: 0.848
[27,     4] loss: 0.859
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004743863427809771,
 'learning_rate_Hydroxylation-K': 0.006531996364881219,
 'learning_rate_Methylation-K': 0.003198442891388468,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.45563040932884624,
 'loss_weight_Methylation-K': 0.8732093062136381,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 155315050,
 'sample_weights': [0.15667373631376444, 0.9980442052687027],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.401151062476388,
 'weight_decay_Hydroxylation-K': 3.421910347758107,
 'weight_decay_Methylation-K': 9.58502616317907}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.392
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015563722158620545,
 'learning_rate_Hydroxylation-K': 0.00632120811860672,
 'learning_rate_Methylation-K': 0.0024911543407944332,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5947697365243283,
 'loss_weight_Methylation-K': 0.9426750226616406,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 80603115,
 'sample_weights': [0.45563040932884624, 0.8732093062136381],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.7986698654496824,
 'weight_decay_Hydroxylation-K': 3.6884429379187624,
 'weight_decay_Methylation-K': 3.328052717530217}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.381
[3,     4] loss: 1.381
[4,     4] loss: 1.376
[5,     4] loss: 1.369
[6,     4] loss: 1.341
[7,     4] loss: 1.320
[8,     4] loss: 1.294
[9,     4] loss: 1.296
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010059694833236465,
 'learning_rate_Hydroxylation-K': 0.00773289431230128,
 'learning_rate_Methylation-K': 0.00875255654586663,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.33674525081702034,
 'loss_weight_Methylation-K': 0.9452850593983038,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2199660910,
 'sample_weights': [0.5947697365243283, 0.9426750226616406],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.792627260357224,
 'weight_decay_Hydroxylation-K': 5.414056282726132,
 'weight_decay_Methylation-K': 8.854298210106654}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.384
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001231160617711662,
 'learning_rate_Hydroxylation-K': 0.006899090267541537,
 'learning_rate_Methylation-K': 0.001844912261210114,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.34349974491866386,
 'loss_weight_Methylation-K': 0.7728897514492106,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2889150748,
 'sample_weights': [0.33674525081702034, 0.9452850593983038],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.616409203247947,
 'weight_decay_Hydroxylation-K': 6.902952149051794,
 'weight_decay_Methylation-K': 9.90909577192145}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.406
[2,     4] loss: 1.388
[3,     4] loss: 1.383
[4,     4] loss: 1.379
[5,     4] loss: 1.384
[6,     4] loss: 1.368
[7,     4] loss: 1.353
[8,     4] loss: 1.315
[9,     4] loss: 1.259
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024887225992119956,
 'learning_rate_Hydroxylation-K': 4.432255090711145e-05,
 'learning_rate_Methylation-K': 0.0005800638007703398,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5783899757525952,
 'loss_weight_Methylation-K': 0.19151653227259796,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 116944824,
 'sample_weights': [0.34349974491866386, 0.7728897514492106],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7596904901883523,
 'weight_decay_Hydroxylation-K': 4.949211713292027,
 'weight_decay_Methylation-K': 8.672176013641034}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.381
[3,     4] loss: 1.400
[4,     4] loss: 1.385
[5,     4] loss: 1.386
[6,     4] loss: 1.385
[7,     4] loss: 1.381
[8,     4] loss: 1.377
[9,     4] loss: 1.374
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002929517247481109,
 'learning_rate_Hydroxylation-K': 0.005452948417599042,
 'learning_rate_Methylation-K': 0.009336710930588386,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.06121557904715806,
 'loss_weight_Methylation-K': 0.8710578416613636,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1581893004,
 'sample_weights': [0.5783899757525952, 0.19151653227259796],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.91554444213093,
 'weight_decay_Hydroxylation-K': 8.28107011111015,
 'weight_decay_Methylation-K': 8.86560999501624}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.374
[2,     4] loss: 1.392
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023317368950826903,
 'learning_rate_Hydroxylation-K': 0.0075051758636576005,
 'learning_rate_Methylation-K': 0.0015099034261700137,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7708979990397965,
 'loss_weight_Methylation-K': 0.43099199740644883,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 380139329,
 'sample_weights': [0.06121557904715806, 0.8710578416613636],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.117414395484657,
 'weight_decay_Hydroxylation-K': 5.382735121508352,
 'weight_decay_Methylation-K': 9.599501088267642}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.383
[3,     4] loss: 1.386
[4,     4] loss: 1.385
[5,     4] loss: 1.384
[6,     4] loss: 1.383
[7,     4] loss: 1.375
[8,     4] loss: 1.349
[9,     4] loss: 1.285
[10,     4] loss: 1.205
[11,     4] loss: 1.203
[12,     4] loss: 1.142
[13,     4] loss: 1.182
[14,     4] loss: 1.158
[15,     4] loss: 1.082
[16,     4] loss: 1.116
[17,     4] loss: 1.009
[18,     4] loss: 1.180
[19,     4] loss: 1.063
[20,     4] loss: 1.061
[21,     4] loss: 1.007
[22,     4] loss: 0.972
[23,     4] loss: 0.957
[24,     4] loss: 0.932
[25,     4] loss: 0.931
[26,     4] loss: 0.834
[27,     4] loss: 0.829
[28,     4] loss: 0.893
[29,     4] loss: 0.905
[30,     4] loss: 0.927
[31,     4] loss: 1.059
[32,     4] loss: 1.057
[33,     4] loss: 0.940
[34,     4] loss: 0.881
[35,     4] loss: 0.883
[36,     4] loss: 0.826
[37,     4] loss: 0.885
[38,     4] loss: 0.830
[39,     4] loss: 0.876
[40,     4] loss: 0.867
[41,     4] loss: 0.805
[42,     4] loss: 0.805
[43,     4] loss: 0.779
[44,     4] loss: 0.778
[45,     4] loss: 0.772
[46,     4] loss: 0.763
[47,     4] loss: 0.800
[48,     4] loss: 0.815
[49,     4] loss: 0.804
[50,     4] loss: 0.866
[51,     4] loss: 0.821
[52,     4] loss: 0.836
[53,     4] loss: 0.944
[54,     4] loss: 0.937
[55,     4] loss: 0.931
[56,     4] loss: 0.908
[57,     4] loss: 0.829
[58,     4] loss: 0.817
[59,     4] loss: 0.845
[60,     4] loss: 0.856
[61,     4] loss: 0.797
[62,     4] loss: 0.839
[63,     4] loss: 0.768
[64,     4] loss: 0.857
[65,     4] loss: 0.837
[66,     4] loss: 0.886
[67,     4] loss: 0.876
[68,     4] loss: 1.232
[69,     4] loss: 1.093
[70,     4] loss: 1.096
[71,     4] loss: 1.011
[72,     4] loss: 1.002
[73,     4] loss: 0.878
[74,     4] loss: 0.870
[75,     4] loss: 0.862
[76,     4] loss: 0.795
[77,     4] loss: 0.842
[78,     4] loss: 0.875
Early stopping applied (best metric=0.2559095025062561)
Finished Training
Total time taken: 39.124090909957886
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.385
[3,     4] loss: 1.386
[4,     4] loss: 1.385
[5,     4] loss: 1.373
[6,     4] loss: 1.358
[7,     4] loss: 1.314
[8,     4] loss: 1.266
[9,     4] loss: 1.134
[10,     4] loss: 1.220
[11,     4] loss: 1.159
[12,     4] loss: 1.161
[13,     4] loss: 1.148
[14,     4] loss: 1.094
[15,     4] loss: 1.030
[16,     4] loss: 0.996
[17,     4] loss: 0.953
[18,     4] loss: 0.981
[19,     4] loss: 1.049
[20,     4] loss: 1.000
[21,     4] loss: 1.028
[22,     4] loss: 1.056
[23,     4] loss: 0.984
[24,     4] loss: 0.903
[25,     4] loss: 0.880
[26,     4] loss: 0.895
[27,     4] loss: 0.837
[28,     4] loss: 0.898
[29,     4] loss: 0.863
[30,     4] loss: 0.905
[31,     4] loss: 0.829
[32,     4] loss: 0.835
[33,     4] loss: 0.787
[34,     4] loss: 0.831
[35,     4] loss: 0.819
[36,     4] loss: 0.960
[37,     4] loss: 0.855
[38,     4] loss: 0.944
[39,     4] loss: 0.868
[40,     4] loss: 0.839
[41,     4] loss: 0.798
[42,     4] loss: 0.783
[43,     4] loss: 0.772
[44,     4] loss: 0.756
[45,     4] loss: 0.766
[46,     4] loss: 0.773
[47,     4] loss: 0.771
[48,     4] loss: 0.806
[49,     4] loss: 0.790
[50,     4] loss: 0.829
[51,     4] loss: 0.796
[52,     4] loss: 0.775
[53,     4] loss: 0.822
[54,     4] loss: 0.880
[55,     4] loss: 0.894
[56,     4] loss: 0.826
[57,     4] loss: 0.805
[58,     4] loss: 0.860
[59,     4] loss: 0.851
[60,     4] loss: 0.845
[61,     4] loss: 0.772
[62,     4] loss: 0.770
[63,     4] loss: 0.752
[64,     4] loss: 0.779
[65,     4] loss: 0.856
[66,     4] loss: 0.895
[67,     4] loss: 0.915
[68,     4] loss: 0.905
[69,     4] loss: 0.886
Early stopping applied (best metric=0.431986540555954)
Finished Training
Total time taken: 34.9120831489563
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.376
[3,     4] loss: 1.386
[4,     4] loss: 1.385
[5,     4] loss: 1.380
[6,     4] loss: 1.365
[7,     4] loss: 1.329
[8,     4] loss: 1.307
[9,     4] loss: 1.232
[10,     4] loss: 1.180
[11,     4] loss: 1.173
[12,     4] loss: 1.061
[13,     4] loss: 1.062
[14,     4] loss: 1.055
[15,     4] loss: 0.982
[16,     4] loss: 1.039
[17,     4] loss: 0.986
[18,     4] loss: 0.987
[19,     4] loss: 0.972
[20,     4] loss: 1.001
[21,     4] loss: 1.098
[22,     4] loss: 0.979
[23,     4] loss: 0.972
[24,     4] loss: 0.928
[25,     4] loss: 0.868
[26,     4] loss: 0.859
[27,     4] loss: 0.873
[28,     4] loss: 0.919
[29,     4] loss: 0.899
[30,     4] loss: 0.868
[31,     4] loss: 0.891
[32,     4] loss: 0.877
[33,     4] loss: 0.829
[34,     4] loss: 0.922
[35,     4] loss: 0.837
[36,     4] loss: 1.015
[37,     4] loss: 0.978
[38,     4] loss: 0.924
[39,     4] loss: 0.801
[40,     4] loss: 0.809
[41,     4] loss: 0.794
[42,     4] loss: 0.775
[43,     4] loss: 0.774
[44,     4] loss: 0.773
[45,     4] loss: 0.799
[46,     4] loss: 0.785
[47,     4] loss: 0.811
[48,     4] loss: 0.808
[49,     4] loss: 0.795
[50,     4] loss: 0.802
[51,     4] loss: 0.837
[52,     4] loss: 0.882
[53,     4] loss: 0.930
[54,     4] loss: 0.897
[55,     4] loss: 0.821
[56,     4] loss: 0.818
[57,     4] loss: 0.788
[58,     4] loss: 0.801
[59,     4] loss: 0.799
[60,     4] loss: 0.768
[61,     4] loss: 0.821
[62,     4] loss: 0.979
[63,     4] loss: 0.966
[64,     4] loss: 0.978
[65,     4] loss: 0.907
[66,     4] loss: 0.979
[67,     4] loss: 0.866
[68,     4] loss: 0.818
[69,     4] loss: 0.768
[70,     4] loss: 0.779
[71,     4] loss: 0.742
[72,     4] loss: 0.777
[73,     4] loss: 0.797
[74,     4] loss: 0.858
[75,     4] loss: 0.914
[76,     4] loss: 0.924
[77,     4] loss: 0.856
[78,     4] loss: 0.826
[79,     4] loss: 0.814
[80,     4] loss: 0.781
[81,     4] loss: 0.809
[82,     4] loss: 0.801
[83,     4] loss: 0.816
[84,     4] loss: 0.777
[85,     4] loss: 0.784
[86,     4] loss: 0.785
[87,     4] loss: 0.809
[88,     4] loss: 0.892
Early stopping applied (best metric=0.35672104358673096)
Finished Training
Total time taken: 44.42010498046875
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.381
[3,     4] loss: 1.381
[4,     4] loss: 1.386
[5,     4] loss: 1.389
[6,     4] loss: 1.381
[7,     4] loss: 1.366
[8,     4] loss: 1.344
[9,     4] loss: 1.297
[10,     4] loss: 1.257
[11,     4] loss: 1.172
[12,     4] loss: 1.131
[13,     4] loss: 1.161
[14,     4] loss: 1.160
[15,     4] loss: 1.066
[16,     4] loss: 1.071
[17,     4] loss: 1.059
[18,     4] loss: 0.967
[19,     4] loss: 0.979
[20,     4] loss: 1.042
[21,     4] loss: 0.951
[22,     4] loss: 0.983
[23,     4] loss: 1.021
[24,     4] loss: 0.986
[25,     4] loss: 1.020
[26,     4] loss: 0.994
[27,     4] loss: 0.915
[28,     4] loss: 0.904
[29,     4] loss: 0.882
[30,     4] loss: 0.840
[31,     4] loss: 0.830
[32,     4] loss: 0.950
[33,     4] loss: 0.889
[34,     4] loss: 0.881
[35,     4] loss: 0.848
[36,     4] loss: 0.809
[37,     4] loss: 0.817
[38,     4] loss: 0.840
[39,     4] loss: 0.836
[40,     4] loss: 0.839
[41,     4] loss: 0.833
[42,     4] loss: 0.883
[43,     4] loss: 0.793
[44,     4] loss: 0.858
[45,     4] loss: 0.833
[46,     4] loss: 1.015
[47,     4] loss: 0.915
[48,     4] loss: 0.865
[49,     4] loss: 0.801
[50,     4] loss: 0.803
[51,     4] loss: 0.827
[52,     4] loss: 0.956
[53,     4] loss: 0.876
[54,     4] loss: 0.894
[55,     4] loss: 0.809
[56,     4] loss: 0.835
[57,     4] loss: 0.876
[58,     4] loss: 0.880
[59,     4] loss: 0.850
[60,     4] loss: 0.843
[61,     4] loss: 0.799
[62,     4] loss: 0.844
[63,     4] loss: 0.967
[64,     4] loss: 0.920
Early stopping applied (best metric=0.3922439515590668)
Finished Training
Total time taken: 31.870079278945923
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.392
[2,     4] loss: 1.385
[3,     4] loss: 1.391
[4,     4] loss: 1.382
[5,     4] loss: 1.380
[6,     4] loss: 1.374
[7,     4] loss: 1.348
[8,     4] loss: 1.292
[9,     4] loss: 1.211
[10,     4] loss: 1.163
[11,     4] loss: 1.096
[12,     4] loss: 1.056
[13,     4] loss: 1.043
[14,     4] loss: 1.003
[15,     4] loss: 1.013
[16,     4] loss: 0.929
[17,     4] loss: 0.943
[18,     4] loss: 0.927
[19,     4] loss: 1.002
[20,     4] loss: 0.927
[21,     4] loss: 0.930
[22,     4] loss: 0.920
[23,     4] loss: 0.868
[24,     4] loss: 0.888
[25,     4] loss: 0.804
[26,     4] loss: 0.823
[27,     4] loss: 0.864
[28,     4] loss: 0.937
[29,     4] loss: 0.947
[30,     4] loss: 0.936
[31,     4] loss: 0.905
[32,     4] loss: 0.843
[33,     4] loss: 0.865
[34,     4] loss: 0.813
[35,     4] loss: 0.789
[36,     4] loss: 0.809
[37,     4] loss: 0.791
[38,     4] loss: 0.812
[39,     4] loss: 0.792
[40,     4] loss: 0.802
[41,     4] loss: 0.858
[42,     4] loss: 0.790
[43,     4] loss: 0.770
[44,     4] loss: 0.834
[45,     4] loss: 0.935
[46,     4] loss: 0.952
[47,     4] loss: 0.901
[48,     4] loss: 0.890
[49,     4] loss: 0.850
[50,     4] loss: 0.818
[51,     4] loss: 0.842
[52,     4] loss: 0.795
[53,     4] loss: 0.881
[54,     4] loss: 0.820
[55,     4] loss: 0.823
[56,     4] loss: 0.770
[57,     4] loss: 0.759
[58,     4] loss: 0.740
[59,     4] loss: 0.738
Early stopping applied (best metric=0.4813458025455475)
Finished Training
Total time taken: 29.7820725440979
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.381
[3,     4] loss: 1.383
[4,     4] loss: 1.368
[5,     4] loss: 1.342
[6,     4] loss: 1.306
[7,     4] loss: 1.244
[8,     4] loss: 1.162
[9,     4] loss: 1.069
[10,     4] loss: 1.107
[11,     4] loss: 0.985
[12,     4] loss: 0.997
[13,     4] loss: 1.059
[14,     4] loss: 0.960
[15,     4] loss: 0.952
[16,     4] loss: 0.922
[17,     4] loss: 0.922
[18,     4] loss: 0.876
[19,     4] loss: 0.876
[20,     4] loss: 0.889
[21,     4] loss: 0.839
[22,     4] loss: 0.870
[23,     4] loss: 0.856
[24,     4] loss: 0.864
[25,     4] loss: 0.862
[26,     4] loss: 0.833
[27,     4] loss: 0.859
[28,     4] loss: 0.822
[29,     4] loss: 0.807
[30,     4] loss: 0.837
[31,     4] loss: 0.805
[32,     4] loss: 0.824
[33,     4] loss: 0.790
[34,     4] loss: 0.781
[35,     4] loss: 0.775
[36,     4] loss: 0.801
[37,     4] loss: 0.791
[38,     4] loss: 0.814
[39,     4] loss: 0.856
[40,     4] loss: 0.869
[41,     4] loss: 0.857
[42,     4] loss: 0.809
[43,     4] loss: 0.795
[44,     4] loss: 0.768
[45,     4] loss: 0.739
[46,     4] loss: 0.784
[47,     4] loss: 0.855
[48,     4] loss: 0.808
[49,     4] loss: 0.803
[50,     4] loss: 0.778
[51,     4] loss: 0.765
[52,     4] loss: 0.783
[53,     4] loss: 0.900
[54,     4] loss: 0.945
Early stopping applied (best metric=0.5476723909378052)
Finished Training
Total time taken: 27.07706594467163
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.381
[3,     4] loss: 1.390
[4,     4] loss: 1.387
[5,     4] loss: 1.385
[6,     4] loss: 1.384
[7,     4] loss: 1.377
[8,     4] loss: 1.366
[9,     4] loss: 1.344
[10,     4] loss: 1.322
[11,     4] loss: 1.222
[12,     4] loss: 1.194
[13,     4] loss: 1.071
[14,     4] loss: 1.106
[15,     4] loss: 1.049
[16,     4] loss: 0.997
[17,     4] loss: 1.015
[18,     4] loss: 0.974
[19,     4] loss: 1.030
[20,     4] loss: 1.212
[21,     4] loss: 1.054
[22,     4] loss: 1.091
[23,     4] loss: 1.033
[24,     4] loss: 1.015
[25,     4] loss: 0.948
[26,     4] loss: 0.896
[27,     4] loss: 0.915
[28,     4] loss: 0.859
[29,     4] loss: 0.900
[30,     4] loss: 0.981
[31,     4] loss: 0.900
[32,     4] loss: 0.842
[33,     4] loss: 0.830
[34,     4] loss: 0.944
[35,     4] loss: 0.928
[36,     4] loss: 0.886
[37,     4] loss: 0.834
[38,     4] loss: 0.802
[39,     4] loss: 0.844
[40,     4] loss: 0.846
[41,     4] loss: 0.852
[42,     4] loss: 0.835
[43,     4] loss: 0.800
[44,     4] loss: 0.816
[45,     4] loss: 0.838
[46,     4] loss: 0.814
[47,     4] loss: 0.871
[48,     4] loss: 0.867
[49,     4] loss: 0.843
[50,     4] loss: 0.818
[51,     4] loss: 0.880
[52,     4] loss: 0.995
[53,     4] loss: 0.925
[54,     4] loss: 0.877
[55,     4] loss: 0.836
[56,     4] loss: 0.807
[57,     4] loss: 0.798
[58,     4] loss: 0.808
[59,     4] loss: 0.784
[60,     4] loss: 0.776
[61,     4] loss: 0.769
[62,     4] loss: 0.789
[63,     4] loss: 0.762
[64,     4] loss: 0.771
[65,     4] loss: 0.777
[66,     4] loss: 0.756
[67,     4] loss: 0.797
[68,     4] loss: 0.846
[69,     4] loss: 0.867
[70,     4] loss: 0.848
[71,     4] loss: 0.797
[72,     4] loss: 0.781
[73,     4] loss: 0.783
[74,     4] loss: 0.818
[75,     4] loss: 0.800
[76,     4] loss: 0.819
[77,     4] loss: 0.821
[78,     4] loss: 0.830
[79,     4] loss: 0.818
[80,     4] loss: 0.780
[81,     4] loss: 0.751
[82,     4] loss: 0.767
[83,     4] loss: 1.050
[84,     4] loss: 0.960
[85,     4] loss: 0.949
[86,     4] loss: 0.888
[87,     4] loss: 0.862
[88,     4] loss: 0.783
[89,     4] loss: 0.790
[90,     4] loss: 0.759
[91,     4] loss: 0.789
[92,     4] loss: 0.762
[93,     4] loss: 0.801
[94,     4] loss: 0.830
[95,     4] loss: 0.802
[96,     4] loss: 0.828
[97,     4] loss: 1.005
[98,     4] loss: 0.950
[99,     4] loss: 0.995
[100,     4] loss: 0.910
[101,     4] loss: 0.901
[102,     4] loss: 0.883
[103,     4] loss: 0.799
[104,     4] loss: 0.771
[105,     4] loss: 0.780
[106,     4] loss: 0.773
[107,     4] loss: 0.790
[108,     4] loss: 0.905
Early stopping applied (best metric=0.3739931285381317)
Finished Training
Total time taken: 54.51013207435608
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.388
[3,     4] loss: 1.388
[4,     4] loss: 1.385
[5,     4] loss: 1.382
[6,     4] loss: 1.373
[7,     4] loss: 1.348
[8,     4] loss: 1.286
[9,     4] loss: 1.260
[10,     4] loss: 1.203
[11,     4] loss: 1.164
[12,     4] loss: 1.052
[13,     4] loss: 1.018
[14,     4] loss: 0.989
[15,     4] loss: 1.041
[16,     4] loss: 1.007
[17,     4] loss: 1.020
[18,     4] loss: 1.013
[19,     4] loss: 1.053
[20,     4] loss: 0.968
[21,     4] loss: 0.947
[22,     4] loss: 0.918
[23,     4] loss: 0.900
[24,     4] loss: 0.876
[25,     4] loss: 0.920
[26,     4] loss: 1.112
[27,     4] loss: 0.998
[28,     4] loss: 0.966
[29,     4] loss: 0.906
[30,     4] loss: 0.946
[31,     4] loss: 0.800
[32,     4] loss: 0.862
[33,     4] loss: 0.835
[34,     4] loss: 0.818
[35,     4] loss: 0.856
[36,     4] loss: 0.798
[37,     4] loss: 0.817
[38,     4] loss: 0.815
[39,     4] loss: 0.851
[40,     4] loss: 0.837
[41,     4] loss: 0.837
[42,     4] loss: 0.841
[43,     4] loss: 0.795
[44,     4] loss: 0.833
[45,     4] loss: 0.778
[46,     4] loss: 0.844
[47,     4] loss: 0.868
[48,     4] loss: 0.831
[49,     4] loss: 0.817
[50,     4] loss: 0.765
[51,     4] loss: 0.861
[52,     4] loss: 1.057
[53,     4] loss: 1.042
[54,     4] loss: 1.051
[55,     4] loss: 0.968
[56,     4] loss: 1.039
[57,     4] loss: 0.865
[58,     4] loss: 0.869
[59,     4] loss: 0.803
[60,     4] loss: 0.777
[61,     4] loss: 0.762
[62,     4] loss: 0.790
[63,     4] loss: 0.799
[64,     4] loss: 0.798
[65,     4] loss: 0.920
[66,     4] loss: 0.987
[67,     4] loss: 0.986
[68,     4] loss: 0.935
[69,     4] loss: 0.816
Early stopping applied (best metric=0.4710933566093445)
Finished Training
Total time taken: 34.83608293533325
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.384
[3,     4] loss: 1.385
[4,     4] loss: 1.382
[5,     4] loss: 1.383
[6,     4] loss: 1.379
[7,     4] loss: 1.364
[8,     4] loss: 1.329
[9,     4] loss: 1.295
[10,     4] loss: 1.215
[11,     4] loss: 1.143
[12,     4] loss: 1.241
[13,     4] loss: 1.250
[14,     4] loss: 1.214
[15,     4] loss: 1.167
[16,     4] loss: 1.120
[17,     4] loss: 1.108
[18,     4] loss: 1.070
[19,     4] loss: 1.022
[20,     4] loss: 0.982
[21,     4] loss: 0.990
[22,     4] loss: 0.934
[23,     4] loss: 0.929
[24,     4] loss: 0.927
[25,     4] loss: 0.926
[26,     4] loss: 0.912
[27,     4] loss: 0.923
[28,     4] loss: 0.858
[29,     4] loss: 0.850
[30,     4] loss: 0.847
[31,     4] loss: 0.837
[32,     4] loss: 0.823
[33,     4] loss: 0.889
[34,     4] loss: 0.821
[35,     4] loss: 0.832
[36,     4] loss: 0.806
[37,     4] loss: 0.826
[38,     4] loss: 0.816
[39,     4] loss: 0.829
[40,     4] loss: 0.826
[41,     4] loss: 0.786
[42,     4] loss: 0.818
[43,     4] loss: 0.810
[44,     4] loss: 0.777
[45,     4] loss: 0.778
[46,     4] loss: 0.801
[47,     4] loss: 0.796
[48,     4] loss: 0.807
[49,     4] loss: 0.779
[50,     4] loss: 0.856
[51,     4] loss: 0.822
[52,     4] loss: 0.835
[53,     4] loss: 0.877
[54,     4] loss: 1.002
[55,     4] loss: 0.905
[56,     4] loss: 0.924
[57,     4] loss: 0.873
[58,     4] loss: 0.954
[59,     4] loss: 0.930
[60,     4] loss: 0.909
[61,     4] loss: 0.845
[62,     4] loss: 0.777
[63,     4] loss: 0.815
[64,     4] loss: 0.826
[65,     4] loss: 0.788
Early stopping applied (best metric=0.43465033173561096)
Finished Training
Total time taken: 32.71807789802551
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.393
[2,     4] loss: 1.388
[3,     4] loss: 1.380
[4,     4] loss: 1.387
[5,     4] loss: 1.381
[6,     4] loss: 1.372
[7,     4] loss: 1.359
[8,     4] loss: 1.333
[9,     4] loss: 1.261
[10,     4] loss: 1.242
[11,     4] loss: 1.193
[12,     4] loss: 1.218
[13,     4] loss: 1.085
[14,     4] loss: 1.163
[15,     4] loss: 1.075
[16,     4] loss: 1.038
[17,     4] loss: 1.033
[18,     4] loss: 0.978
[19,     4] loss: 0.931
[20,     4] loss: 1.031
[21,     4] loss: 1.062
[22,     4] loss: 1.020
[23,     4] loss: 1.005
[24,     4] loss: 0.927
[25,     4] loss: 0.922
[26,     4] loss: 0.887
[27,     4] loss: 0.844
[28,     4] loss: 0.910
[29,     4] loss: 0.903
[30,     4] loss: 0.871
[31,     4] loss: 0.892
[32,     4] loss: 0.820
[33,     4] loss: 0.820
[34,     4] loss: 0.773
[35,     4] loss: 0.797
[36,     4] loss: 0.826
[37,     4] loss: 0.927
[38,     4] loss: 0.946
[39,     4] loss: 0.931
[40,     4] loss: 0.876
[41,     4] loss: 0.813
[42,     4] loss: 0.785
[43,     4] loss: 1.003
[44,     4] loss: 0.940
[45,     4] loss: 0.965
[46,     4] loss: 0.884
[47,     4] loss: 0.837
[48,     4] loss: 0.855
[49,     4] loss: 0.818
[50,     4] loss: 0.845
[51,     4] loss: 0.827
[52,     4] loss: 0.847
[53,     4] loss: 0.789
[54,     4] loss: 0.771
[55,     4] loss: 0.781
[56,     4] loss: 0.882
[57,     4] loss: 0.830
[58,     4] loss: 0.836
[59,     4] loss: 0.942
[60,     4] loss: 0.916
[61,     4] loss: 0.829
[62,     4] loss: 0.795
[63,     4] loss: 0.841
[64,     4] loss: 0.823
[65,     4] loss: 0.759
[66,     4] loss: 0.752
[67,     4] loss: 0.787
[68,     4] loss: 0.767
[69,     4] loss: 0.755
[70,     4] loss: 0.787
[71,     4] loss: 0.841
[72,     4] loss: 0.775
[73,     4] loss: 0.792
[74,     4] loss: 0.874
[75,     4] loss: 0.881
[76,     4] loss: 0.851
[77,     4] loss: 0.819
[78,     4] loss: 0.751
[79,     4] loss: 0.935
[80,     4] loss: 0.834
[81,     4] loss: 0.905
[82,     4] loss: 0.838
[83,     4] loss: 0.840
[84,     4] loss: 0.881
[85,     4] loss: 0.788
[86,     4] loss: 0.819
[87,     4] loss: 0.789
[88,     4] loss: 0.747
[89,     4] loss: 0.743
[90,     4] loss: 0.784
[91,     4] loss: 0.811
[92,     4] loss: 0.918
[93,     4] loss: 0.860
[94,     4] loss: 0.812
[95,     4] loss: 0.790
[96,     4] loss: 0.760
[97,     4] loss: 0.774
[98,     4] loss: 0.801
[99,     4] loss: 0.822
[100,     4] loss: 0.853
[101,     4] loss: 0.831
[102,     4] loss: 0.837
[103,     4] loss: 0.862
[104,     4] loss: 0.842
[105,     4] loss: 0.843
[106,     4] loss: 0.882
[107,     4] loss: 0.836
[108,     4] loss: 0.789
[109,     4] loss: 0.850
[110,     4] loss: 0.820
Early stopping applied (best metric=0.3256687521934509)
Finished Training
Total time taken: 55.35313415527344
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.387
[3,     4] loss: 1.388
[4,     4] loss: 1.380
[5,     4] loss: 1.382
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.376
[9,     4] loss: 1.364
[10,     4] loss: 1.324
[11,     4] loss: 1.271
[12,     4] loss: 1.201
[13,     4] loss: 1.111
[14,     4] loss: 1.121
[15,     4] loss: 1.007
[16,     4] loss: 0.994
[17,     4] loss: 0.932
[18,     4] loss: 1.021
[19,     4] loss: 1.085
[20,     4] loss: 0.990
[21,     4] loss: 1.003
[22,     4] loss: 1.019
[23,     4] loss: 0.952
[24,     4] loss: 0.900
[25,     4] loss: 0.925
[26,     4] loss: 0.976
[27,     4] loss: 0.872
[28,     4] loss: 0.933
[29,     4] loss: 0.910
[30,     4] loss: 0.930
[31,     4] loss: 0.935
[32,     4] loss: 0.866
[33,     4] loss: 0.876
[34,     4] loss: 0.835
[35,     4] loss: 0.817
[36,     4] loss: 0.856
[37,     4] loss: 0.903
[38,     4] loss: 0.854
[39,     4] loss: 0.897
[40,     4] loss: 0.871
[41,     4] loss: 0.980
[42,     4] loss: 0.904
[43,     4] loss: 0.913
[44,     4] loss: 0.854
[45,     4] loss: 0.820
[46,     4] loss: 0.810
[47,     4] loss: 0.911
[48,     4] loss: 0.857
[49,     4] loss: 0.864
[50,     4] loss: 0.814
[51,     4] loss: 0.901
[52,     4] loss: 0.830
[53,     4] loss: 0.822
[54,     4] loss: 1.111
[55,     4] loss: 1.069
[56,     4] loss: 1.066
[57,     4] loss: 1.066
[58,     4] loss: 0.962
[59,     4] loss: 0.909
[60,     4] loss: 0.908
[61,     4] loss: 0.890
[62,     4] loss: 0.875
Early stopping applied (best metric=0.44456052780151367)
Finished Training
Total time taken: 31.308075189590454
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.383
[3,     4] loss: 1.386
[4,     4] loss: 1.386
[5,     4] loss: 1.380
[6,     4] loss: 1.371
[7,     4] loss: 1.341
[8,     4] loss: 1.319
[9,     4] loss: 1.244
[10,     4] loss: 1.252
[11,     4] loss: 1.179
[12,     4] loss: 1.202
[13,     4] loss: 1.144
[14,     4] loss: 1.094
[15,     4] loss: 1.105
[16,     4] loss: 1.056
[17,     4] loss: 1.053
[18,     4] loss: 1.030
[19,     4] loss: 1.062
[20,     4] loss: 0.981
[21,     4] loss: 0.906
[22,     4] loss: 0.884
[23,     4] loss: 0.991
[24,     4] loss: 1.155
[25,     4] loss: 1.071
[26,     4] loss: 1.096
[27,     4] loss: 1.037
[28,     4] loss: 1.004
[29,     4] loss: 0.943
[30,     4] loss: 0.878
[31,     4] loss: 0.894
[32,     4] loss: 0.888
[33,     4] loss: 0.826
[34,     4] loss: 0.792
[35,     4] loss: 0.794
[36,     4] loss: 0.796
[37,     4] loss: 0.814
[38,     4] loss: 0.804
[39,     4] loss: 0.811
[40,     4] loss: 0.974
[41,     4] loss: 0.877
[42,     4] loss: 0.906
[43,     4] loss: 0.857
[44,     4] loss: 0.776
[45,     4] loss: 0.828
[46,     4] loss: 0.819
[47,     4] loss: 0.837
[48,     4] loss: 0.827
[49,     4] loss: 0.770
[50,     4] loss: 0.794
[51,     4] loss: 0.906
[52,     4] loss: 0.882
[53,     4] loss: 0.890
[54,     4] loss: 0.880
[55,     4] loss: 0.841
[56,     4] loss: 0.802
[57,     4] loss: 1.031
[58,     4] loss: 0.954
[59,     4] loss: 1.004
[60,     4] loss: 0.921
[61,     4] loss: 0.833
[62,     4] loss: 0.820
[63,     4] loss: 0.904
[64,     4] loss: 0.839
[65,     4] loss: 0.837
[66,     4] loss: 0.901
[67,     4] loss: 0.951
Early stopping applied (best metric=0.29252421855926514)
Finished Training
Total time taken: 33.783079862594604
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.389
[3,     4] loss: 1.387
[4,     4] loss: 1.389
[5,     4] loss: 1.381
[6,     4] loss: 1.378
[7,     4] loss: 1.364
[8,     4] loss: 1.339
[9,     4] loss: 1.289
[10,     4] loss: 1.206
[11,     4] loss: 1.147
[12,     4] loss: 1.115
[13,     4] loss: 0.996
[14,     4] loss: 1.017
[15,     4] loss: 1.016
[16,     4] loss: 0.968
[17,     4] loss: 0.984
[18,     4] loss: 1.018
[19,     4] loss: 0.909
[20,     4] loss: 0.981
[21,     4] loss: 0.904
[22,     4] loss: 0.934
[23,     4] loss: 0.927
[24,     4] loss: 1.042
[25,     4] loss: 0.910
[26,     4] loss: 0.868
[27,     4] loss: 0.835
[28,     4] loss: 0.782
[29,     4] loss: 0.837
[30,     4] loss: 0.795
[31,     4] loss: 0.798
[32,     4] loss: 0.778
[33,     4] loss: 0.793
[34,     4] loss: 0.791
[35,     4] loss: 0.774
[36,     4] loss: 0.785
[37,     4] loss: 0.816
[38,     4] loss: 0.857
[39,     4] loss: 0.925
[40,     4] loss: 0.895
[41,     4] loss: 0.927
[42,     4] loss: 0.835
[43,     4] loss: 0.843
[44,     4] loss: 0.812
[45,     4] loss: 0.780
[46,     4] loss: 0.768
[47,     4] loss: 0.770
[48,     4] loss: 0.764
[49,     4] loss: 0.784
[50,     4] loss: 0.811
[51,     4] loss: 0.957
[52,     4] loss: 1.104
[53,     4] loss: 1.029
[54,     4] loss: 0.906
[55,     4] loss: 0.865
[56,     4] loss: 0.803
[57,     4] loss: 0.776
[58,     4] loss: 0.818
[59,     4] loss: 0.849
[60,     4] loss: 0.817
[61,     4] loss: 0.783
[62,     4] loss: 0.767
[63,     4] loss: 0.756
[64,     4] loss: 0.762
[65,     4] loss: 0.782
[66,     4] loss: 0.784
[67,     4] loss: 0.802
Early stopping applied (best metric=0.4996454119682312)
Finished Training
Total time taken: 34.018081188201904
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.389
[3,     4] loss: 1.384
[4,     4] loss: 1.373
[5,     4] loss: 1.352
[6,     4] loss: 1.294
[7,     4] loss: 1.256
[8,     4] loss: 1.154
[9,     4] loss: 1.097
[10,     4] loss: 1.022
[11,     4] loss: 0.998
[12,     4] loss: 0.999
[13,     4] loss: 0.952
[14,     4] loss: 1.071
[15,     4] loss: 1.033
[16,     4] loss: 1.036
[17,     4] loss: 0.944
[18,     4] loss: 0.928
[19,     4] loss: 0.889
[20,     4] loss: 0.935
[21,     4] loss: 0.915
[22,     4] loss: 0.880
[23,     4] loss: 0.894
[24,     4] loss: 0.864
[25,     4] loss: 0.843
[26,     4] loss: 0.818
[27,     4] loss: 0.820
[28,     4] loss: 0.929
[29,     4] loss: 0.896
[30,     4] loss: 0.858
[31,     4] loss: 0.802
[32,     4] loss: 0.827
[33,     4] loss: 0.828
[34,     4] loss: 0.855
[35,     4] loss: 0.820
[36,     4] loss: 0.834
[37,     4] loss: 0.812
[38,     4] loss: 0.833
[39,     4] loss: 0.844
[40,     4] loss: 0.799
[41,     4] loss: 0.812
[42,     4] loss: 0.807
[43,     4] loss: 0.793
[44,     4] loss: 0.796
[45,     4] loss: 0.814
[46,     4] loss: 0.906
[47,     4] loss: 0.951
[48,     4] loss: 0.900
[49,     4] loss: 0.888
[50,     4] loss: 0.848
[51,     4] loss: 0.852
[52,     4] loss: 0.817
[53,     4] loss: 0.837
[54,     4] loss: 0.802
[55,     4] loss: 0.763
[56,     4] loss: 0.781
[57,     4] loss: 0.799
[58,     4] loss: 0.797
[59,     4] loss: 0.783
[60,     4] loss: 0.775
[61,     4] loss: 0.843
[62,     4] loss: 0.969
[63,     4] loss: 0.935
[64,     4] loss: 0.886
[65,     4] loss: 0.810
Early stopping applied (best metric=0.5093897581100464)
Finished Training
Total time taken: 32.83007884025574
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.387
[2,     4] loss: 1.387
[3,     4] loss: 1.387
[4,     4] loss: 1.385
[5,     4] loss: 1.384
[6,     4] loss: 1.386
[7,     4] loss: 1.384
[8,     4] loss: 1.377
[9,     4] loss: 1.372
[10,     4] loss: 1.365
[11,     4] loss: 1.341
[12,     4] loss: 1.301
[13,     4] loss: 1.273
[14,     4] loss: 1.248
[15,     4] loss: 1.167
[16,     4] loss: 1.215
[17,     4] loss: 1.244
[18,     4] loss: 1.174
[19,     4] loss: 1.153
[20,     4] loss: 1.097
[21,     4] loss: 1.033
[22,     4] loss: 1.088
[23,     4] loss: 1.037
[24,     4] loss: 0.983
[25,     4] loss: 0.977
[26,     4] loss: 0.942
[27,     4] loss: 0.912
[28,     4] loss: 0.876
[29,     4] loss: 0.913
[30,     4] loss: 1.101
[31,     4] loss: 1.000
[32,     4] loss: 1.006
[33,     4] loss: 0.893
[34,     4] loss: 0.882
[35,     4] loss: 0.930
[36,     4] loss: 0.843
[37,     4] loss: 0.823
[38,     4] loss: 0.809
[39,     4] loss: 0.841
[40,     4] loss: 0.808
[41,     4] loss: 0.807
[42,     4] loss: 0.822
[43,     4] loss: 1.029
[44,     4] loss: 1.061
[45,     4] loss: 1.080
[46,     4] loss: 1.025
[47,     4] loss: 0.938
[48,     4] loss: 0.926
[49,     4] loss: 0.911
[50,     4] loss: 0.876
[51,     4] loss: 0.871
[52,     4] loss: 0.834
[53,     4] loss: 0.805
[54,     4] loss: 0.814
[55,     4] loss: 0.814
[56,     4] loss: 0.824
[57,     4] loss: 0.912
[58,     4] loss: 0.964
[59,     4] loss: 0.908
[60,     4] loss: 0.834
[61,     4] loss: 0.964
[62,     4] loss: 0.853
[63,     4] loss: 0.933
[64,     4] loss: 0.864
[65,     4] loss: 0.902
[66,     4] loss: 0.841
[67,     4] loss: 0.879
[68,     4] loss: 1.030
[69,     4] loss: 0.991
[70,     4] loss: 0.941
[71,     4] loss: 0.874
Early stopping applied (best metric=0.28487712144851685)
Finished Training
Total time taken: 35.46308183670044
{'Hydroxylation-K Validation Accuracy': 0.75475768321513, 'Hydroxylation-K Validation Sensitivity': 0.7851851851851852, 'Hydroxylation-K Validation Specificity': 0.7473684210526316, 'Hydroxylation-K Validation Precision': 0.4635350224823909, 'Hydroxylation-K AUC ROC': 0.8293762183235868, 'Hydroxylation-K AUC PR': 0.6186533328744676, 'Hydroxylation-K MCC': 0.45835335628103296, 'Hydroxylation-K F1': 0.5728898134951504, 'Validation Loss (Hydroxylation-K)': 0.40681878924369813, 'Methylation-K Validation Accuracy': 0.7564845472027115, 'Methylation-K Validation Sensitivity': 0.21946104505814293, 'Methylation-K Validation Specificity': 0.8147244195880065, 'Methylation-K Validation Precision': 0.11430438744106887, 'Methylation-K AUC ROC': 0.5409833251333684, 'Methylation-K AUC PR': 0.11053709489391639, 'Methylation-K MCC': 0.026170049791467538, 'Methylation-K F1': 0.14840933390522942, 'Validation Loss (Methylation-K)': 0.8504448413848877, 'Validation Loss (total)': 1.2572636365890504, 'TimeToTrain': 36.80035471916199}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008075429381540265,
 'learning_rate_Hydroxylation-K': 0.00515484657393306,
 'learning_rate_Methylation-K': 0.0033248064491241034,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.80743472141245,
 'loss_weight_Methylation-K': 0.7133765607731855,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3139772008,
 'sample_weights': [0.7708979990397965, 0.43099199740644883],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.019608382126668,
 'weight_decay_Hydroxylation-K': 3.4495539520091296,
 'weight_decay_Methylation-K': 9.778760769722709}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.384
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 1.0480462584636064e-05,
 'learning_rate_Hydroxylation-K': 0.007804085586189882,
 'learning_rate_Methylation-K': 0.0011960630370170468,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.47397873602360535,
 'loss_weight_Methylation-K': 0.8559555415736797,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 484680283,
 'sample_weights': [0.80743472141245, 0.7133765607731855],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8690270336441768,
 'weight_decay_Hydroxylation-K': 3.5576683228299344,
 'weight_decay_Methylation-K': 7.338258284888822}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.401
[2,     4] loss: 1.378
[3,     4] loss: 1.398
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015715323900293583,
 'learning_rate_Hydroxylation-K': 0.001185845778158132,
 'learning_rate_Methylation-K': 0.003830845730155832,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.014291346712095265,
 'loss_weight_Methylation-K': 0.7464430114627776,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2028373321,
 'sample_weights': [0.47397873602360535, 0.8559555415736797],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.169340182853938,
 'weight_decay_Hydroxylation-K': 1.6670434649007637,
 'weight_decay_Methylation-K': 8.048969929146546}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.387
[3,     4] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016184572723930506,
 'learning_rate_Hydroxylation-K': 0.002038206022673189,
 'learning_rate_Methylation-K': 0.009919190920404894,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.47803402155271923,
 'loss_weight_Methylation-K': 0.9778513706455184,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3444620845,
 'sample_weights': [0.014291346712095265, 0.7464430114627776],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.706762666950006,
 'weight_decay_Hydroxylation-K': 4.898884440332758,
 'weight_decay_Methylation-K': 5.990325891699841}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.402
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.376
[5,     4] loss: 1.368
[6,     4] loss: 1.352
[7,     4] loss: 1.325
[8,     4] loss: 1.276
[9,     4] loss: 1.219
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 6.592283438086079e-05,
 'learning_rate_Hydroxylation-K': 0.000575143038561487,
 'learning_rate_Methylation-K': 0.006517580822148775,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3166684564308925,
 'loss_weight_Methylation-K': 0.6299189507552179,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1640091026,
 'sample_weights': [0.47803402155271923, 0.9778513706455184],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.0740468825995655,
 'weight_decay_Hydroxylation-K': 5.256552210236256,
 'weight_decay_Methylation-K': 5.401480791764085}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.387
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006159483770709593,
 'learning_rate_Hydroxylation-K': 0.0003905463841365127,
 'learning_rate_Methylation-K': 0.004520500102741573,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6222177438349858,
 'loss_weight_Methylation-K': 0.12660066446006288,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 387593345,
 'sample_weights': [0.3166684564308925, 0.6299189507552179],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.431280420832561,
 'weight_decay_Hydroxylation-K': 7.187449846589458,
 'weight_decay_Methylation-K': 9.269651940231247}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.384
[3,     4] loss: 1.383
[4,     4] loss: 1.377
[5,     4] loss: 1.375
[6,     4] loss: 1.363
[7,     4] loss: 1.356
[8,     4] loss: 1.328
[9,     4] loss: 1.307
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013222240620169095,
 'learning_rate_Hydroxylation-K': 0.0065258397333316795,
 'learning_rate_Methylation-K': 0.0010292205083542937,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9017618091432484,
 'loss_weight_Methylation-K': 0.551685942654117,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1246358588,
 'sample_weights': [0.6222177438349858, 0.12660066446006288],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.497450547071267,
 'weight_decay_Hydroxylation-K': 6.528752206651265,
 'weight_decay_Methylation-K': 7.916725185003267}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.384
[3,     4] loss: 1.385
[4,     4] loss: 1.383
[5,     4] loss: 1.376
[6,     4] loss: 1.353
[7,     4] loss: 1.326
[8,     4] loss: 1.293
[9,     4] loss: 1.251
[10,     4] loss: 1.212
[11,     4] loss: 1.151
[12,     4] loss: 1.120
[13,     4] loss: 1.084
[14,     4] loss: 1.066
[15,     4] loss: 1.047
[16,     4] loss: 1.001
[17,     4] loss: 0.960
[18,     4] loss: 0.944
[19,     4] loss: 0.914
[20,     4] loss: 0.984
[21,     4] loss: 0.870
[22,     4] loss: 0.914
[23,     4] loss: 0.859
[24,     4] loss: 0.843
[25,     4] loss: 0.851
[26,     4] loss: 0.866
[27,     4] loss: 0.859
[28,     4] loss: 0.829
[29,     4] loss: 0.829
[30,     4] loss: 0.819
[31,     4] loss: 0.829
[32,     4] loss: 0.814
[33,     4] loss: 0.798
[34,     4] loss: 0.823
[35,     4] loss: 0.881
[36,     4] loss: 1.044
[37,     4] loss: 0.979
[38,     4] loss: 0.945
[39,     4] loss: 0.914
[40,     4] loss: 0.865
[41,     4] loss: 0.805
[42,     4] loss: 0.791
[43,     4] loss: 0.761
[44,     4] loss: 0.838
[45,     4] loss: 0.800
[46,     4] loss: 0.789
[47,     4] loss: 0.803
[48,     4] loss: 0.793
[49,     4] loss: 0.777
[50,     4] loss: 0.774
[51,     4] loss: 0.792
[52,     4] loss: 0.801
[53,     4] loss: 0.809
[54,     4] loss: 0.799
[55,     4] loss: 0.803
[56,     4] loss: 0.800
[57,     4] loss: 0.779
[58,     4] loss: 0.745
[59,     4] loss: 0.760
[60,     4] loss: 0.767
[61,     4] loss: 0.746
[62,     4] loss: 0.742
[63,     4] loss: 0.747
[64,     4] loss: 0.761
[65,     4] loss: 0.761
[66,     4] loss: 0.750
[67,     4] loss: 0.771
[68,     4] loss: 0.756
[69,     4] loss: 0.765
[70,     4] loss: 0.754
[71,     4] loss: 0.753
[72,     4] loss: 0.775
[73,     4] loss: 0.798
[74,     4] loss: 0.889
[75,     4] loss: 0.943
[76,     4] loss: 0.853
[77,     4] loss: 0.889
[78,     4] loss: 0.862
[79,     4] loss: 0.792
[80,     4] loss: 0.759
[81,     4] loss: 0.769
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037944815125671317,
 'learning_rate_Hydroxylation-K': 0.005285601041226636,
 'learning_rate_Methylation-K': 0.006641564774618603,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7420854157731787,
 'loss_weight_Methylation-K': 0.947996440111804,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2236639860,
 'sample_weights': [0.9017618091432484, 0.551685942654117],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.767739436830149,
 'weight_decay_Hydroxylation-K': 2.261032986762286,
 'weight_decay_Methylation-K': 6.816027737672029}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.389
[3,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 2.7315735819360932e-05,
 'learning_rate_Hydroxylation-K': 0.007357262550044618,
 'learning_rate_Methylation-K': 0.004103247260607037,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5971203579273165,
 'loss_weight_Methylation-K': 0.6188789012222057,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 977304403,
 'sample_weights': [0.7420854157731787, 0.947996440111804],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.67906429768698,
 'weight_decay_Hydroxylation-K': 6.121669857728228,
 'weight_decay_Methylation-K': 2.8505028109597927}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.394
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002426031477982684,
 'learning_rate_Hydroxylation-K': 0.005745495342046879,
 'learning_rate_Methylation-K': 5.961810592885423e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7944274639513698,
 'loss_weight_Methylation-K': 0.6717250112273508,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2874000169,
 'sample_weights': [0.5971203579273165, 0.6188789012222057],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.165725417840198,
 'weight_decay_Hydroxylation-K': 8.69446325106895,
 'weight_decay_Methylation-K': 5.782430802371858}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.386
[5,     4] loss: 1.382
[6,     4] loss: 1.385
[7,     4] loss: 1.382
[8,     4] loss: 1.368
[9,     4] loss: 1.342
[10,     4] loss: 1.289
[11,     4] loss: 1.217
[12,     4] loss: 1.175
[13,     4] loss: 1.115
[14,     4] loss: 1.067
[15,     4] loss: 1.024
[16,     4] loss: 1.016
[17,     4] loss: 1.003
[18,     4] loss: 0.973
[19,     4] loss: 0.958
[20,     4] loss: 1.103
[21,     4] loss: 1.011
[22,     4] loss: 1.044
[23,     4] loss: 0.982
[24,     4] loss: 0.915
[25,     4] loss: 0.891
[26,     4] loss: 0.843
[27,     4] loss: 0.939
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006470880483945845,
 'learning_rate_Hydroxylation-K': 0.006569622035453033,
 'learning_rate_Methylation-K': 0.00962222606962406,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1849858688516946,
 'loss_weight_Methylation-K': 0.7908690924798273,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1326668644,
 'sample_weights': [0.7944274639513698, 0.6717250112273508],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.780776386124782,
 'weight_decay_Hydroxylation-K': 6.04354998755633,
 'weight_decay_Methylation-K': 9.053552205955162}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.387
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019544390707930625,
 'learning_rate_Hydroxylation-K': 0.001572955170838517,
 'learning_rate_Methylation-K': 0.0053471597649186195,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.40167277832857035,
 'loss_weight_Methylation-K': 0.25370222556940375,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3642167399,
 'sample_weights': [0.1849858688516946, 0.7908690924798273],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.726750288315896,
 'weight_decay_Hydroxylation-K': 6.829287604732296,
 'weight_decay_Methylation-K': 4.15662638143036}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.385
[5,     4] loss: 1.378
[6,     4] loss: 1.382
[7,     4] loss: 1.363
[8,     4] loss: 1.330
[9,     4] loss: 1.305
[10,     4] loss: 1.250
[11,     4] loss: 1.190
[12,     4] loss: 1.131
[13,     4] loss: 1.255
[14,     4] loss: 1.119
[15,     4] loss: 1.113
[16,     4] loss: 1.073
[17,     4] loss: 1.056
[18,     4] loss: 0.991
[19,     4] loss: 0.979
[20,     4] loss: 0.931
[21,     4] loss: 0.884
[22,     4] loss: 0.912
[23,     4] loss: 0.862
[24,     4] loss: 0.880
[25,     4] loss: 0.895
[26,     4] loss: 0.856
[27,     4] loss: 0.850
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00030187368929319655,
 'learning_rate_Hydroxylation-K': 0.007004319167351494,
 'learning_rate_Methylation-K': 0.006526525294829631,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9302548559390986,
 'loss_weight_Methylation-K': 0.7043756279069832,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1920612223,
 'sample_weights': [0.40167277832857035, 0.25370222556940375],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8185614200904374,
 'weight_decay_Hydroxylation-K': 6.295798629084115,
 'weight_decay_Methylation-K': 4.053683843973785}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.384
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008215409719618849,
 'learning_rate_Hydroxylation-K': 0.006798429081068374,
 'learning_rate_Methylation-K': 0.005588999647198631,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1480420162041825,
 'loss_weight_Methylation-K': 0.8946624864131134,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 653928198,
 'sample_weights': [0.9302548559390986, 0.7043756279069832],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.362171218717416,
 'weight_decay_Hydroxylation-K': 0.917610682780472,
 'weight_decay_Methylation-K': 3.029715587585107}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.390
[3,     4] loss: 1.396
[4,     4] loss: 1.388
[5,     4] loss: 1.387
[6,     4] loss: 1.383
[7,     4] loss: 1.382
[8,     4] loss: 1.381
[9,     4] loss: 1.373
[10,     4] loss: 1.354
[11,     4] loss: 1.326
[12,     4] loss: 1.294
[13,     4] loss: 1.275
[14,     4] loss: 1.165
[15,     4] loss: 1.108
[16,     4] loss: 1.186
[17,     4] loss: 1.156
[18,     4] loss: 1.088
[19,     4] loss: 1.053
[20,     4] loss: 1.051
[21,     4] loss: 0.985
[22,     4] loss: 0.952
[23,     4] loss: 0.914
[24,     4] loss: 0.871
[25,     4] loss: 0.895
[26,     4] loss: 0.833
[27,     4] loss: 0.813
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009849661504001213,
 'learning_rate_Hydroxylation-K': 0.00477486683570909,
 'learning_rate_Methylation-K': 0.009637530917619885,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9880040577615505,
 'loss_weight_Methylation-K': 0.19543133900192505,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 392565104,
 'sample_weights': [0.1480420162041825, 0.8946624864131134],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.861751902186398,
 'weight_decay_Hydroxylation-K': 0.15307253928824593,
 'weight_decay_Methylation-K': 0.5779112572602001}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.389
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003391980316918704,
 'learning_rate_Hydroxylation-K': 0.001769047697809571,
 'learning_rate_Methylation-K': 0.002091852072321722,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5360824754821074,
 'loss_weight_Methylation-K': 0.7054483596075732,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2435558537,
 'sample_weights': [0.9880040577615505, 0.19543133900192505],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.823863894572412,
 'weight_decay_Hydroxylation-K': 9.132762517777248,
 'weight_decay_Methylation-K': 2.809887748527632}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.385
[3,     4] loss: 1.384
[4,     4] loss: 1.378
[5,     4] loss: 1.377
[6,     4] loss: 1.370
[7,     4] loss: 1.329
[8,     4] loss: 1.269
[9,     4] loss: 1.260
[10,     4] loss: 1.185
[11,     4] loss: 1.177
[12,     4] loss: 1.121
[13,     4] loss: 1.065
[14,     4] loss: 1.035
[15,     4] loss: 1.031
[16,     4] loss: 1.027
[17,     4] loss: 1.027
[18,     4] loss: 0.940
[19,     4] loss: 0.957
[20,     4] loss: 0.925
[21,     4] loss: 0.928
[22,     4] loss: 0.919
[23,     4] loss: 0.900
[24,     4] loss: 0.897
[25,     4] loss: 0.865
[26,     4] loss: 0.887
[27,     4] loss: 0.886
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003598644244211734,
 'learning_rate_Hydroxylation-K': 0.001557072071892959,
 'learning_rate_Methylation-K': 0.00026721616772360825,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.009239703738426211,
 'loss_weight_Methylation-K': 0.42400260667088097,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 512854765,
 'sample_weights': [0.5360824754821074, 0.7054483596075732],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.85575675531193,
 'weight_decay_Hydroxylation-K': 3.512422569925133,
 'weight_decay_Methylation-K': 6.471100827563092}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.385
[3,     4] loss: 1.383
[4,     4] loss: 1.382
[5,     4] loss: 1.370
[6,     4] loss: 1.347
[7,     4] loss: 1.296
[8,     4] loss: 1.268
[9,     4] loss: 1.225
[10,     4] loss: 1.137
[11,     4] loss: 1.161
[12,     4] loss: 1.052
[13,     4] loss: 1.088
[14,     4] loss: 1.107
[15,     4] loss: 1.012
[16,     4] loss: 0.962
[17,     4] loss: 0.905
[18,     4] loss: 1.017
[19,     4] loss: 1.006
[20,     4] loss: 1.049
[21,     4] loss: 0.984
[22,     4] loss: 0.966
[23,     4] loss: 0.890
[24,     4] loss: 0.867
[25,     4] loss: 0.798
[26,     4] loss: 0.928
[27,     4] loss: 1.188
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035110417869075824,
 'learning_rate_Hydroxylation-K': 0.0016254460698200415,
 'learning_rate_Methylation-K': 0.0027413942878745977,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.0647746997731623,
 'loss_weight_Methylation-K': 0.4630778300897012,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3048687656,
 'sample_weights': [0.009239703738426211, 0.42400260667088097],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.900136688546538,
 'weight_decay_Hydroxylation-K': 2.395878624986602,
 'weight_decay_Methylation-K': 5.33011907517093}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.386
[3,     4] loss: 1.393
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005986767774997402,
 'learning_rate_Hydroxylation-K': 0.00925324347630162,
 'learning_rate_Methylation-K': 0.0042676420651450815,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6467501079466644,
 'loss_weight_Methylation-K': 0.8151410947904618,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3055350129,
 'sample_weights': [0.0647746997731623, 0.4630778300897012],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.059384394677641,
 'weight_decay_Hydroxylation-K': 5.57283638770998,
 'weight_decay_Methylation-K': 4.952850036689201}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.388
[3,     4] loss: 1.388
[4,     4] loss: 1.388
[5,     4] loss: 1.385
[6,     4] loss: 1.382
[7,     4] loss: 1.379
[8,     4] loss: 1.376
[9,     4] loss: 1.368
[10,     4] loss: 1.352
[11,     4] loss: 1.340
[12,     4] loss: 1.300
[13,     4] loss: 1.293
[14,     4] loss: 1.266
[15,     4] loss: 1.214
[16,     4] loss: 1.188
[17,     4] loss: 1.097
[18,     4] loss: 1.091
[19,     4] loss: 1.005
[20,     4] loss: 1.017
[21,     4] loss: 1.002
[22,     4] loss: 0.933
[23,     4] loss: 0.925
[24,     4] loss: 0.928
[25,     4] loss: 0.942
[26,     4] loss: 0.872
[27,     4] loss: 0.880
[28,     4] loss: 0.884
[29,     4] loss: 0.896
[30,     4] loss: 0.904
[31,     4] loss: 0.810
[32,     4] loss: 0.916
[33,     4] loss: 0.809
[34,     4] loss: 0.864
[35,     4] loss: 0.817
[36,     4] loss: 0.835
[37,     4] loss: 0.810
[38,     4] loss: 0.805
[39,     4] loss: 0.839
[40,     4] loss: 0.894
[41,     4] loss: 0.865
[42,     4] loss: 0.828
[43,     4] loss: 0.864
[44,     4] loss: 0.802
[45,     4] loss: 0.775
[46,     4] loss: 0.794
[47,     4] loss: 0.764
[48,     4] loss: 0.743
[49,     4] loss: 0.758
[50,     4] loss: 0.738
[51,     4] loss: 0.743
[52,     4] loss: 0.729
[53,     4] loss: 0.729
[54,     4] loss: 0.729
[55,     4] loss: 0.741
[56,     4] loss: 0.733
[57,     4] loss: 0.737
[58,     4] loss: 0.738
[59,     4] loss: 0.749
[60,     4] loss: 0.747
[61,     4] loss: 0.797
[62,     4] loss: 0.780
[63,     4] loss: 0.800
[64,     4] loss: 0.754
[65,     4] loss: 0.775
[66,     4] loss: 0.785
[67,     4] loss: 0.755
[68,     4] loss: 0.729
[69,     4] loss: 0.733
Early stopping applied (best metric=0.338161438703537)
Finished Training
Total time taken: 34.822083473205566
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.384
[5,     4] loss: 1.383
[6,     4] loss: 1.376
[7,     4] loss: 1.374
[8,     4] loss: 1.360
[9,     4] loss: 1.346
[10,     4] loss: 1.323
[11,     4] loss: 1.303
[12,     4] loss: 1.279
[13,     4] loss: 1.238
[14,     4] loss: 1.229
[15,     4] loss: 1.156
[16,     4] loss: 1.111
[17,     4] loss: 1.059
[18,     4] loss: 0.996
[19,     4] loss: 0.993
[20,     4] loss: 0.960
[21,     4] loss: 0.978
[22,     4] loss: 0.939
[23,     4] loss: 0.910
[24,     4] loss: 0.904
[25,     4] loss: 0.952
[26,     4] loss: 1.083
[27,     4] loss: 1.078
[28,     4] loss: 1.020
[29,     4] loss: 1.006
[30,     4] loss: 0.968
[31,     4] loss: 0.922
[32,     4] loss: 0.906
[33,     4] loss: 0.847
[34,     4] loss: 0.871
[35,     4] loss: 0.790
[36,     4] loss: 0.820
[37,     4] loss: 0.788
[38,     4] loss: 0.780
[39,     4] loss: 0.789
[40,     4] loss: 0.770
[41,     4] loss: 0.791
[42,     4] loss: 0.837
[43,     4] loss: 0.786
[44,     4] loss: 0.782
[45,     4] loss: 0.814
[46,     4] loss: 0.806
[47,     4] loss: 0.775
[48,     4] loss: 0.810
[49,     4] loss: 0.768
[50,     4] loss: 0.765
[51,     4] loss: 0.757
[52,     4] loss: 0.769
[53,     4] loss: 0.766
[54,     4] loss: 0.744
[55,     4] loss: 0.739
[56,     4] loss: 0.766
[57,     4] loss: 0.758
[58,     4] loss: 0.745
[59,     4] loss: 0.773
[60,     4] loss: 0.744
[61,     4] loss: 0.745
[62,     4] loss: 0.789
[63,     4] loss: 0.770
[64,     4] loss: 0.746
[65,     4] loss: 0.781
[66,     4] loss: 0.760
[67,     4] loss: 0.740
[68,     4] loss: 0.738
[69,     4] loss: 0.748
[70,     4] loss: 0.736
[71,     4] loss: 0.724
[72,     4] loss: 0.736
[73,     4] loss: 0.720
[74,     4] loss: 0.731
[75,     4] loss: 0.739
[76,     4] loss: 0.738
[77,     4] loss: 0.760
[78,     4] loss: 0.730
[79,     4] loss: 0.765
[80,     4] loss: 0.752
[81,     4] loss: 0.717
[82,     4] loss: 0.726
[83,     4] loss: 0.725
[84,     4] loss: 0.708
[85,     4] loss: 0.718
[86,     4] loss: 0.708
[87,     4] loss: 0.740
[88,     4] loss: 0.710
[89,     4] loss: 0.713
[90,     4] loss: 0.693
[91,     4] loss: 0.700
[92,     4] loss: 0.710
Early stopping applied (best metric=0.2630985975265503)
Finished Training
Total time taken: 46.57110929489136
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.384
[5,     4] loss: 1.384
[6,     4] loss: 1.380
[7,     4] loss: 1.377
[8,     4] loss: 1.363
[9,     4] loss: 1.356
[10,     4] loss: 1.320
[11,     4] loss: 1.302
[12,     4] loss: 1.272
[13,     4] loss: 1.236
[14,     4] loss: 1.187
[15,     4] loss: 1.102
[16,     4] loss: 1.103
[17,     4] loss: 1.090
[18,     4] loss: 1.086
[19,     4] loss: 1.102
[20,     4] loss: 1.018
[21,     4] loss: 0.980
[22,     4] loss: 0.975
[23,     4] loss: 0.922
[24,     4] loss: 0.958
[25,     4] loss: 0.924
[26,     4] loss: 0.872
[27,     4] loss: 0.888
[28,     4] loss: 0.839
[29,     4] loss: 0.852
[30,     4] loss: 0.839
[31,     4] loss: 0.838
[32,     4] loss: 0.817
[33,     4] loss: 0.784
[34,     4] loss: 0.807
[35,     4] loss: 0.820
[36,     4] loss: 0.817
[37,     4] loss: 0.807
[38,     4] loss: 0.800
[39,     4] loss: 0.766
[40,     4] loss: 0.812
[41,     4] loss: 0.797
[42,     4] loss: 0.793
[43,     4] loss: 0.761
[44,     4] loss: 0.749
[45,     4] loss: 0.750
[46,     4] loss: 0.732
[47,     4] loss: 0.750
[48,     4] loss: 0.746
[49,     4] loss: 0.734
[50,     4] loss: 0.715
[51,     4] loss: 0.713
[52,     4] loss: 0.717
[53,     4] loss: 0.733
[54,     4] loss: 0.784
[55,     4] loss: 0.730
[56,     4] loss: 0.725
[57,     4] loss: 0.728
[58,     4] loss: 0.704
[59,     4] loss: 0.715
[60,     4] loss: 0.741
[61,     4] loss: 0.732
[62,     4] loss: 0.753
[63,     4] loss: 0.806
[64,     4] loss: 0.742
Early stopping applied (best metric=0.47866401076316833)
Finished Training
Total time taken: 32.53207612037659
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.381
[2,     4] loss: 1.386
[3,     4] loss: 1.381
[4,     4] loss: 1.379
[5,     4] loss: 1.369
[6,     4] loss: 1.364
[7,     4] loss: 1.338
[8,     4] loss: 1.329
[9,     4] loss: 1.280
[10,     4] loss: 1.249
[11,     4] loss: 1.220
[12,     4] loss: 1.164
[13,     4] loss: 1.117
[14,     4] loss: 1.124
[15,     4] loss: 1.088
[16,     4] loss: 1.011
[17,     4] loss: 1.068
[18,     4] loss: 1.025
[19,     4] loss: 0.965
[20,     4] loss: 0.975
[21,     4] loss: 0.909
[22,     4] loss: 0.953
[23,     4] loss: 0.916
[24,     4] loss: 0.868
[25,     4] loss: 0.830
[26,     4] loss: 0.862
[27,     4] loss: 0.819
[28,     4] loss: 0.799
[29,     4] loss: 0.822
[30,     4] loss: 0.823
[31,     4] loss: 0.795
[32,     4] loss: 0.782
[33,     4] loss: 0.772
[34,     4] loss: 0.748
[35,     4] loss: 0.766
[36,     4] loss: 0.758
[37,     4] loss: 0.785
[38,     4] loss: 0.881
[39,     4] loss: 0.811
[40,     4] loss: 0.811
[41,     4] loss: 0.853
[42,     4] loss: 0.824
[43,     4] loss: 0.808
[44,     4] loss: 0.770
[45,     4] loss: 0.761
[46,     4] loss: 0.772
[47,     4] loss: 0.770
[48,     4] loss: 0.730
[49,     4] loss: 0.726
[50,     4] loss: 0.717
[51,     4] loss: 0.745
[52,     4] loss: 0.726
[53,     4] loss: 0.754
[54,     4] loss: 0.745
[55,     4] loss: 0.766
[56,     4] loss: 0.791
[57,     4] loss: 0.788
[58,     4] loss: 0.813
[59,     4] loss: 0.777
[60,     4] loss: 0.765
[61,     4] loss: 0.742
[62,     4] loss: 0.729
[63,     4] loss: 0.718
[64,     4] loss: 0.725
Early stopping applied (best metric=0.3116844892501831)
Finished Training
Total time taken: 32.42408061027527
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.378
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.379
[6,     4] loss: 1.370
[7,     4] loss: 1.360
[8,     4] loss: 1.336
[9,     4] loss: 1.314
[10,     4] loss: 1.308
[11,     4] loss: 1.227
[12,     4] loss: 1.224
[13,     4] loss: 1.214
[14,     4] loss: 1.162
[15,     4] loss: 1.090
[16,     4] loss: 1.070
[17,     4] loss: 1.079
[18,     4] loss: 1.021
[19,     4] loss: 1.073
[20,     4] loss: 0.981
[21,     4] loss: 0.973
[22,     4] loss: 0.910
[23,     4] loss: 0.929
[24,     4] loss: 0.856
[25,     4] loss: 0.848
[26,     4] loss: 0.899
[27,     4] loss: 0.885
[28,     4] loss: 0.835
[29,     4] loss: 0.879
[30,     4] loss: 0.872
[31,     4] loss: 0.895
[32,     4] loss: 0.940
[33,     4] loss: 0.859
[34,     4] loss: 0.910
[35,     4] loss: 0.928
[36,     4] loss: 0.876
[37,     4] loss: 0.866
[38,     4] loss: 0.833
[39,     4] loss: 0.853
[40,     4] loss: 0.825
[41,     4] loss: 0.873
[42,     4] loss: 0.819
[43,     4] loss: 0.796
[44,     4] loss: 0.812
[45,     4] loss: 0.809
[46,     4] loss: 0.781
[47,     4] loss: 0.774
[48,     4] loss: 0.776
[49,     4] loss: 0.788
[50,     4] loss: 0.786
[51,     4] loss: 0.787
[52,     4] loss: 0.773
[53,     4] loss: 0.805
[54,     4] loss: 0.791
[55,     4] loss: 0.771
[56,     4] loss: 0.743
[57,     4] loss: 0.748
[58,     4] loss: 0.758
[59,     4] loss: 0.745
[60,     4] loss: 0.749
[61,     4] loss: 0.740
[62,     4] loss: 0.785
[63,     4] loss: 0.769
[64,     4] loss: 0.770
[65,     4] loss: 0.785
Early stopping applied (best metric=0.31107380986213684)
Finished Training
Total time taken: 32.36907649040222
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.387
[3,     4] loss: 1.387
[4,     4] loss: 1.380
[5,     4] loss: 1.380
[6,     4] loss: 1.377
[7,     4] loss: 1.373
[8,     4] loss: 1.364
[9,     4] loss: 1.348
[10,     4] loss: 1.301
[11,     4] loss: 1.295
[12,     4] loss: 1.239
[13,     4] loss: 1.225
[14,     4] loss: 1.129
[15,     4] loss: 1.137
[16,     4] loss: 1.079
[17,     4] loss: 1.025
[18,     4] loss: 1.016
[19,     4] loss: 0.991
[20,     4] loss: 0.949
[21,     4] loss: 0.884
[22,     4] loss: 0.906
[23,     4] loss: 0.926
[24,     4] loss: 0.895
[25,     4] loss: 0.889
[26,     4] loss: 0.852
[27,     4] loss: 0.838
[28,     4] loss: 0.885
[29,     4] loss: 0.884
[30,     4] loss: 0.956
[31,     4] loss: 0.882
[32,     4] loss: 0.824
[33,     4] loss: 0.792
[34,     4] loss: 0.858
[35,     4] loss: 0.817
[36,     4] loss: 0.804
[37,     4] loss: 0.797
[38,     4] loss: 0.776
[39,     4] loss: 0.803
[40,     4] loss: 0.801
[41,     4] loss: 0.799
[42,     4] loss: 0.795
[43,     4] loss: 0.755
[44,     4] loss: 0.835
[45,     4] loss: 0.779
[46,     4] loss: 0.797
[47,     4] loss: 0.784
[48,     4] loss: 0.800
[49,     4] loss: 0.796
[50,     4] loss: 0.773
[51,     4] loss: 0.782
[52,     4] loss: 0.787
[53,     4] loss: 0.811
[54,     4] loss: 0.788
[55,     4] loss: 0.775
[56,     4] loss: 0.787
[57,     4] loss: 0.772
[58,     4] loss: 0.786
[59,     4] loss: 0.785
[60,     4] loss: 0.782
Early stopping applied (best metric=0.5342357158660889)
Finished Training
Total time taken: 30.421071767807007
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.384
[3,     4] loss: 1.387
[4,     4] loss: 1.381
[5,     4] loss: 1.376
[6,     4] loss: 1.367
[7,     4] loss: 1.350
[8,     4] loss: 1.327
[9,     4] loss: 1.299
[10,     4] loss: 1.258
[11,     4] loss: 1.245
[12,     4] loss: 1.149
[13,     4] loss: 1.096
[14,     4] loss: 1.081
[15,     4] loss: 1.063
[16,     4] loss: 1.080
[17,     4] loss: 1.002
[18,     4] loss: 0.999
[19,     4] loss: 0.996
[20,     4] loss: 0.934
[21,     4] loss: 0.930
[22,     4] loss: 0.927
[23,     4] loss: 0.914
[24,     4] loss: 0.916
[25,     4] loss: 0.879
[26,     4] loss: 0.919
[27,     4] loss: 0.949
[28,     4] loss: 0.868
[29,     4] loss: 0.900
[30,     4] loss: 0.892
[31,     4] loss: 0.858
[32,     4] loss: 0.904
[33,     4] loss: 0.797
[34,     4] loss: 0.818
[35,     4] loss: 0.847
[36,     4] loss: 0.873
[37,     4] loss: 0.858
[38,     4] loss: 0.790
[39,     4] loss: 0.783
[40,     4] loss: 0.864
[41,     4] loss: 0.835
[42,     4] loss: 0.820
[43,     4] loss: 0.817
[44,     4] loss: 0.803
[45,     4] loss: 0.761
[46,     4] loss: 0.774
[47,     4] loss: 0.786
[48,     4] loss: 0.756
[49,     4] loss: 0.773
[50,     4] loss: 0.768
[51,     4] loss: 0.818
[52,     4] loss: 0.799
[53,     4] loss: 0.812
[54,     4] loss: 0.777
[55,     4] loss: 0.766
[56,     4] loss: 0.753
[57,     4] loss: 0.791
[58,     4] loss: 0.773
[59,     4] loss: 0.743
[60,     4] loss: 0.749
Early stopping applied (best metric=0.44902175664901733)
Finished Training
Total time taken: 30.359076261520386
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.393
[5,     4] loss: 1.388
[6,     4] loss: 1.381
[7,     4] loss: 1.375
[8,     4] loss: 1.368
[9,     4] loss: 1.350
[10,     4] loss: 1.343
[11,     4] loss: 1.321
[12,     4] loss: 1.272
[13,     4] loss: 1.255
[14,     4] loss: 1.192
[15,     4] loss: 1.160
[16,     4] loss: 1.105
[17,     4] loss: 1.095
[18,     4] loss: 1.055
[19,     4] loss: 0.987
[20,     4] loss: 0.970
[21,     4] loss: 0.953
[22,     4] loss: 0.909
[23,     4] loss: 0.887
[24,     4] loss: 0.944
[25,     4] loss: 0.904
[26,     4] loss: 0.913
[27,     4] loss: 0.914
[28,     4] loss: 0.915
[29,     4] loss: 0.842
[30,     4] loss: 0.879
[31,     4] loss: 0.807
[32,     4] loss: 0.857
[33,     4] loss: 0.850
[34,     4] loss: 0.818
[35,     4] loss: 0.841
[36,     4] loss: 0.828
[37,     4] loss: 0.851
[38,     4] loss: 0.817
[39,     4] loss: 0.836
[40,     4] loss: 0.808
[41,     4] loss: 0.857
[42,     4] loss: 0.872
[43,     4] loss: 0.835
[44,     4] loss: 0.796
[45,     4] loss: 0.814
[46,     4] loss: 0.801
[47,     4] loss: 0.809
[48,     4] loss: 0.780
[49,     4] loss: 0.793
[50,     4] loss: 0.787
[51,     4] loss: 0.796
[52,     4] loss: 0.782
[53,     4] loss: 0.774
[54,     4] loss: 0.770
[55,     4] loss: 0.741
[56,     4] loss: 0.745
[57,     4] loss: 0.768
[58,     4] loss: 0.754
[59,     4] loss: 0.744
[60,     4] loss: 0.745
[61,     4] loss: 0.740
[62,     4] loss: 0.776
[63,     4] loss: 0.751
Early stopping applied (best metric=0.4697604179382324)
Finished Training
Total time taken: 31.990079402923584
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.382
[3,     4] loss: 1.388
[4,     4] loss: 1.384
[5,     4] loss: 1.375
[6,     4] loss: 1.367
[7,     4] loss: 1.347
[8,     4] loss: 1.333
[9,     4] loss: 1.314
[10,     4] loss: 1.277
[11,     4] loss: 1.231
[12,     4] loss: 1.170
[13,     4] loss: 1.137
[14,     4] loss: 1.117
[15,     4] loss: 1.062
[16,     4] loss: 1.008
[17,     4] loss: 0.963
[18,     4] loss: 0.991
[19,     4] loss: 0.958
[20,     4] loss: 1.005
[21,     4] loss: 0.917
[22,     4] loss: 0.960
[23,     4] loss: 0.894
[24,     4] loss: 0.973
[25,     4] loss: 0.916
[26,     4] loss: 0.898
[27,     4] loss: 0.871
[28,     4] loss: 0.828
[29,     4] loss: 0.863
[30,     4] loss: 0.803
[31,     4] loss: 0.826
[32,     4] loss: 0.757
[33,     4] loss: 0.855
[34,     4] loss: 0.819
[35,     4] loss: 0.818
[36,     4] loss: 0.844
[37,     4] loss: 0.836
[38,     4] loss: 0.790
[39,     4] loss: 0.799
[40,     4] loss: 0.801
[41,     4] loss: 0.762
[42,     4] loss: 0.793
[43,     4] loss: 0.755
[44,     4] loss: 0.766
[45,     4] loss: 0.755
[46,     4] loss: 0.757
[47,     4] loss: 0.765
[48,     4] loss: 0.802
[49,     4] loss: 0.786
[50,     4] loss: 0.768
[51,     4] loss: 0.745
[52,     4] loss: 0.746
[53,     4] loss: 0.740
[54,     4] loss: 0.745
[55,     4] loss: 0.749
[56,     4] loss: 0.740
[57,     4] loss: 0.745
[58,     4] loss: 0.806
[59,     4] loss: 0.777
[60,     4] loss: 0.778
[61,     4] loss: 0.800
[62,     4] loss: 0.768
Early stopping applied (best metric=0.4349091947078705)
Finished Training
Total time taken: 31.167075872421265
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.396
[2,     4] loss: 1.379
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.377
[6,     4] loss: 1.371
[7,     4] loss: 1.357
[8,     4] loss: 1.340
[9,     4] loss: 1.319
[10,     4] loss: 1.266
[11,     4] loss: 1.243
[12,     4] loss: 1.210
[13,     4] loss: 1.140
[14,     4] loss: 1.124
[15,     4] loss: 1.118
[16,     4] loss: 1.104
[17,     4] loss: 1.092
[18,     4] loss: 1.038
[19,     4] loss: 0.996
[20,     4] loss: 0.989
[21,     4] loss: 1.031
[22,     4] loss: 0.994
[23,     4] loss: 1.018
[24,     4] loss: 0.900
[25,     4] loss: 0.932
[26,     4] loss: 0.955
[27,     4] loss: 0.939
[28,     4] loss: 0.923
[29,     4] loss: 0.854
[30,     4] loss: 0.850
[31,     4] loss: 0.813
[32,     4] loss: 0.862
[33,     4] loss: 0.811
[34,     4] loss: 0.786
[35,     4] loss: 0.815
[36,     4] loss: 0.811
[37,     4] loss: 0.834
[38,     4] loss: 0.783
[39,     4] loss: 0.824
[40,     4] loss: 0.774
[41,     4] loss: 0.781
[42,     4] loss: 0.772
[43,     4] loss: 0.763
[44,     4] loss: 0.793
[45,     4] loss: 0.757
[46,     4] loss: 0.798
[47,     4] loss: 0.798
[48,     4] loss: 0.777
[49,     4] loss: 0.797
[50,     4] loss: 0.788
[51,     4] loss: 0.782
[52,     4] loss: 0.788
[53,     4] loss: 0.788
[54,     4] loss: 0.769
[55,     4] loss: 0.803
[56,     4] loss: 0.786
[57,     4] loss: 0.770
[58,     4] loss: 0.769
[59,     4] loss: 0.760
[60,     4] loss: 0.747
[61,     4] loss: 0.749
Early stopping applied (best metric=0.430744469165802)
Finished Training
Total time taken: 30.8600754737854
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.386
[3,     4] loss: 1.382
[4,     4] loss: 1.382
[5,     4] loss: 1.378
[6,     4] loss: 1.367
[7,     4] loss: 1.361
[8,     4] loss: 1.334
[9,     4] loss: 1.309
[10,     4] loss: 1.290
[11,     4] loss: 1.269
[12,     4] loss: 1.211
[13,     4] loss: 1.163
[14,     4] loss: 1.152
[15,     4] loss: 1.172
[16,     4] loss: 1.066
[17,     4] loss: 1.037
[18,     4] loss: 1.007
[19,     4] loss: 0.934
[20,     4] loss: 0.895
[21,     4] loss: 0.886
[22,     4] loss: 0.862
[23,     4] loss: 0.860
[24,     4] loss: 0.877
[25,     4] loss: 0.901
[26,     4] loss: 0.867
[27,     4] loss: 0.833
[28,     4] loss: 0.822
[29,     4] loss: 0.796
[30,     4] loss: 0.843
[31,     4] loss: 0.819
[32,     4] loss: 0.789
[33,     4] loss: 0.784
[34,     4] loss: 0.774
[35,     4] loss: 0.769
[36,     4] loss: 0.817
[37,     4] loss: 0.822
[38,     4] loss: 0.831
[39,     4] loss: 0.824
[40,     4] loss: 0.860
[41,     4] loss: 0.796
[42,     4] loss: 0.775
[43,     4] loss: 0.775
[44,     4] loss: 0.761
[45,     4] loss: 0.771
[46,     4] loss: 0.753
[47,     4] loss: 0.799
[48,     4] loss: 0.796
[49,     4] loss: 0.793
[50,     4] loss: 0.791
[51,     4] loss: 0.775
[52,     4] loss: 0.754
[53,     4] loss: 0.745
[54,     4] loss: 0.753
[55,     4] loss: 0.737
[56,     4] loss: 0.734
[57,     4] loss: 0.740
[58,     4] loss: 0.751
[59,     4] loss: 0.749
[60,     4] loss: 0.748
[61,     4] loss: 0.755
[62,     4] loss: 0.740
[63,     4] loss: 0.730
Early stopping applied (best metric=0.429673969745636)
Finished Training
Total time taken: 31.693077564239502
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.380
[3,     4] loss: 1.385
[4,     4] loss: 1.381
[5,     4] loss: 1.369
[6,     4] loss: 1.355
[7,     4] loss: 1.325
[8,     4] loss: 1.302
[9,     4] loss: 1.279
[10,     4] loss: 1.274
[11,     4] loss: 1.220
[12,     4] loss: 1.153
[13,     4] loss: 1.171
[14,     4] loss: 1.036
[15,     4] loss: 1.058
[16,     4] loss: 0.995
[17,     4] loss: 1.017
[18,     4] loss: 0.945
[19,     4] loss: 0.961
[20,     4] loss: 0.935
[21,     4] loss: 0.907
[22,     4] loss: 0.884
[23,     4] loss: 0.877
[24,     4] loss: 0.852
[25,     4] loss: 0.930
[26,     4] loss: 0.916
[27,     4] loss: 0.881
[28,     4] loss: 0.822
[29,     4] loss: 0.808
[30,     4] loss: 0.811
[31,     4] loss: 0.790
[32,     4] loss: 0.806
[33,     4] loss: 0.791
[34,     4] loss: 0.854
[35,     4] loss: 0.825
[36,     4] loss: 0.812
[37,     4] loss: 0.776
[38,     4] loss: 0.829
[39,     4] loss: 0.795
[40,     4] loss: 0.746
[41,     4] loss: 0.788
[42,     4] loss: 0.774
[43,     4] loss: 0.764
[44,     4] loss: 0.748
[45,     4] loss: 0.743
[46,     4] loss: 0.755
[47,     4] loss: 0.743
[48,     4] loss: 0.755
[49,     4] loss: 0.788
[50,     4] loss: 0.790
[51,     4] loss: 0.754
[52,     4] loss: 0.734
[53,     4] loss: 0.726
[54,     4] loss: 0.733
[55,     4] loss: 0.738
[56,     4] loss: 0.731
[57,     4] loss: 0.727
[58,     4] loss: 0.758
[59,     4] loss: 0.722
[60,     4] loss: 0.777
[61,     4] loss: 0.783
Early stopping applied (best metric=0.47516417503356934)
Finished Training
Total time taken: 30.56407141685486
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.384
[5,     4] loss: 1.382
[6,     4] loss: 1.380
[7,     4] loss: 1.369
[8,     4] loss: 1.357
[9,     4] loss: 1.344
[10,     4] loss: 1.312
[11,     4] loss: 1.300
[12,     4] loss: 1.279
[13,     4] loss: 1.203
[14,     4] loss: 1.196
[15,     4] loss: 1.156
[16,     4] loss: 1.119
[17,     4] loss: 1.058
[18,     4] loss: 1.014
[19,     4] loss: 1.030
[20,     4] loss: 0.991
[21,     4] loss: 0.976
[22,     4] loss: 0.916
[23,     4] loss: 0.931
[24,     4] loss: 0.870
[25,     4] loss: 0.868
[26,     4] loss: 0.929
[27,     4] loss: 0.908
[28,     4] loss: 0.859
[29,     4] loss: 0.845
[30,     4] loss: 0.916
[31,     4] loss: 0.880
[32,     4] loss: 0.828
[33,     4] loss: 0.829
[34,     4] loss: 0.818
[35,     4] loss: 0.841
[36,     4] loss: 0.805
[37,     4] loss: 0.797
[38,     4] loss: 0.784
[39,     4] loss: 0.771
[40,     4] loss: 0.788
[41,     4] loss: 0.791
[42,     4] loss: 0.796
[43,     4] loss: 0.773
[44,     4] loss: 0.780
[45,     4] loss: 0.773
[46,     4] loss: 0.781
[47,     4] loss: 0.765
[48,     4] loss: 0.769
[49,     4] loss: 0.753
[50,     4] loss: 0.748
[51,     4] loss: 0.770
[52,     4] loss: 0.769
[53,     4] loss: 0.772
[54,     4] loss: 0.744
[55,     4] loss: 0.758
[56,     4] loss: 0.760
[57,     4] loss: 0.753
[58,     4] loss: 0.739
[59,     4] loss: 0.751
[60,     4] loss: 0.766
[61,     4] loss: 0.765
[62,     4] loss: 0.762
[63,     4] loss: 0.739
[64,     4] loss: 0.733
[65,     4] loss: 0.735
[66,     4] loss: 0.732
[67,     4] loss: 0.740
[68,     4] loss: 0.728
Early stopping applied (best metric=0.36843550205230713)
Finished Training
Total time taken: 34.19608449935913
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.390
[3,     4] loss: 1.379
[4,     4] loss: 1.380
[5,     4] loss: 1.380
[6,     4] loss: 1.376
[7,     4] loss: 1.383
[8,     4] loss: 1.347
[9,     4] loss: 1.344
[10,     4] loss: 1.334
[11,     4] loss: 1.297
[12,     4] loss: 1.264
[13,     4] loss: 1.234
[14,     4] loss: 1.199
[15,     4] loss: 1.158
[16,     4] loss: 1.125
[17,     4] loss: 1.066
[18,     4] loss: 0.973
[19,     4] loss: 0.980
[20,     4] loss: 0.999
[21,     4] loss: 0.895
[22,     4] loss: 1.011
[23,     4] loss: 0.913
[24,     4] loss: 0.880
[25,     4] loss: 0.892
[26,     4] loss: 0.835
[27,     4] loss: 0.864
[28,     4] loss: 0.835
[29,     4] loss: 0.843
[30,     4] loss: 0.806
[31,     4] loss: 0.837
[32,     4] loss: 0.827
[33,     4] loss: 0.826
[34,     4] loss: 0.798
[35,     4] loss: 0.778
[36,     4] loss: 0.775
[37,     4] loss: 0.799
[38,     4] loss: 0.800
[39,     4] loss: 0.785
[40,     4] loss: 0.814
[41,     4] loss: 0.757
[42,     4] loss: 0.746
[43,     4] loss: 0.769
[44,     4] loss: 0.764
[45,     4] loss: 0.724
[46,     4] loss: 0.754
[47,     4] loss: 0.760
[48,     4] loss: 0.736
[49,     4] loss: 0.745
[50,     4] loss: 0.737
[51,     4] loss: 0.823
[52,     4] loss: 0.805
[53,     4] loss: 0.773
[54,     4] loss: 0.784
[55,     4] loss: 0.772
[56,     4] loss: 0.752
[57,     4] loss: 0.753
[58,     4] loss: 0.758
[59,     4] loss: 0.815
[60,     4] loss: 0.788
[61,     4] loss: 0.736
[62,     4] loss: 0.752
[63,     4] loss: 0.771
[64,     4] loss: 0.756
[65,     4] loss: 0.730
Early stopping applied (best metric=0.39031997323036194)
Finished Training
Total time taken: 32.99107885360718
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.380
[2,     4] loss: 1.382
[3,     4] loss: 1.382
[4,     4] loss: 1.386
[5,     4] loss: 1.368
[6,     4] loss: 1.378
[7,     4] loss: 1.361
[8,     4] loss: 1.344
[9,     4] loss: 1.308
[10,     4] loss: 1.268
[11,     4] loss: 1.274
[12,     4] loss: 1.186
[13,     4] loss: 1.184
[14,     4] loss: 1.151
[15,     4] loss: 1.105
[16,     4] loss: 1.051
[17,     4] loss: 1.055
[18,     4] loss: 1.025
[19,     4] loss: 0.973
[20,     4] loss: 0.924
[21,     4] loss: 0.946
[22,     4] loss: 0.931
[23,     4] loss: 0.910
[24,     4] loss: 0.889
[25,     4] loss: 0.831
[26,     4] loss: 0.867
[27,     4] loss: 0.864
[28,     4] loss: 0.878
[29,     4] loss: 0.836
[30,     4] loss: 0.880
[31,     4] loss: 0.875
[32,     4] loss: 0.833
[33,     4] loss: 0.921
[34,     4] loss: 0.852
[35,     4] loss: 0.857
[36,     4] loss: 0.829
[37,     4] loss: 0.792
[38,     4] loss: 0.797
[39,     4] loss: 0.783
[40,     4] loss: 0.835
[41,     4] loss: 0.783
[42,     4] loss: 0.804
[43,     4] loss: 0.790
[44,     4] loss: 0.800
[45,     4] loss: 0.787
[46,     4] loss: 0.845
[47,     4] loss: 0.849
[48,     4] loss: 0.781
[49,     4] loss: 0.786
[50,     4] loss: 0.775
[51,     4] loss: 0.755
[52,     4] loss: 0.728
[53,     4] loss: 0.746
[54,     4] loss: 0.774
[55,     4] loss: 0.770
[56,     4] loss: 0.767
[57,     4] loss: 0.769
[58,     4] loss: 0.744
[59,     4] loss: 0.764
[60,     4] loss: 0.756
[61,     4] loss: 0.745
[62,     4] loss: 0.731
[63,     4] loss: 0.723
[64,     4] loss: 0.730
[65,     4] loss: 0.710
[66,     4] loss: 0.724
[67,     4] loss: 0.716
[68,     4] loss: 0.710
[69,     4] loss: 0.716
[70,     4] loss: 0.724
Early stopping applied (best metric=0.3925401270389557)
Finished Training
Total time taken: 35.012084007263184
{'Hydroxylation-K Validation Accuracy': 0.7870567375886525, 'Hydroxylation-K Validation Sensitivity': 0.7511111111111111, 'Hydroxylation-K Validation Specificity': 0.7964912280701755, 'Hydroxylation-K Validation Precision': 0.5001870406282171, 'Hydroxylation-K AUC ROC': 0.8355165692007798, 'Hydroxylation-K AUC PR': 0.6189380301406863, 'Hydroxylation-K MCC': 0.4825605191746501, 'Hydroxylation-K F1': 0.5940140685937788, 'Validation Loss (Hydroxylation-K)': 0.4051658431688944, 'Methylation-K Validation Accuracy': 0.8108006829889047, 'Methylation-K Validation Sensitivity': 0.14530783168414488, 'Methylation-K Validation Specificity': 0.8829749798597943, 'Methylation-K Validation Precision': 0.12091935333609878, 'Methylation-K AUC ROC': 0.5466136291565136, 'Methylation-K AUC PR': 0.1145527355165867, 'Methylation-K MCC': 0.026720739764469727, 'Methylation-K F1': 0.12731758937882579, 'Validation Loss (Methylation-K)': 0.7862192312876384, 'Validation Loss (total)': 1.1913850704828899, 'TimeToTrain': 33.1981467405955}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0038963113111739655,
 'learning_rate_Hydroxylation-K': 0.0018117064377969738,
 'learning_rate_Methylation-K': 0.004646305426347439,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6172926423660816,
 'loss_weight_Methylation-K': 0.2730673900691401,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2565220668,
 'sample_weights': [0.6467501079466644, 0.8151410947904618],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.14036066993832064,
 'weight_decay_Hydroxylation-K': 8.880950988572968,
 'weight_decay_Methylation-K': 3.4813897508894076}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.376
[2,     4] loss: 1.384
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005739935750096074,
 'learning_rate_Hydroxylation-K': 0.0010681054061641632,
 'learning_rate_Methylation-K': 8.540157445305861e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24009951563583887,
 'loss_weight_Methylation-K': 0.45048215875069425,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3503383222,
 'sample_weights': [0.6172926423660816, 0.2730673900691401],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.199703005068891,
 'weight_decay_Hydroxylation-K': 3.0399122332334816,
 'weight_decay_Methylation-K': 7.340680087997833}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.390
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0040451449785514106,
 'learning_rate_Hydroxylation-K': 0.0030276161923644693,
 'learning_rate_Methylation-K': 0.0007256160274646854,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.03798344201261897,
 'loss_weight_Methylation-K': 0.2548126562048635,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3738055365,
 'sample_weights': [0.24009951563583887, 0.45048215875069425],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.3003736428886965,
 'weight_decay_Hydroxylation-K': 5.515529561792871,
 'weight_decay_Methylation-K': 9.772080744091308}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.386
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002207586525047121,
 'learning_rate_Hydroxylation-K': 0.003708329248946086,
 'learning_rate_Methylation-K': 0.000749338543703019,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.15168924721893423,
 'loss_weight_Methylation-K': 0.3248532008338616,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 903956772,
 'sample_weights': [0.03798344201261897, 0.2548126562048635],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.252274482749393,
 'weight_decay_Hydroxylation-K': 4.361581360530271,
 'weight_decay_Methylation-K': 5.893964061262097}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.385
[3,     4] loss: 1.380
[4,     4] loss: 1.384
[5,     4] loss: 1.378
[6,     4] loss: 1.367
[7,     4] loss: 1.342
[8,     4] loss: 1.311
[9,     4] loss: 1.228
[10,     4] loss: 1.215
[11,     4] loss: 1.212
[12,     4] loss: 1.096
[13,     4] loss: 1.106
[14,     4] loss: 1.072
[15,     4] loss: 1.156
[16,     4] loss: 1.040
[17,     4] loss: 1.019
[18,     4] loss: 1.016
[19,     4] loss: 1.047
[20,     4] loss: 0.897
[21,     4] loss: 0.938
[22,     4] loss: 0.865
[23,     4] loss: 0.944
[24,     4] loss: 1.001
[25,     4] loss: 0.973
[26,     4] loss: 0.919
[27,     4] loss: 0.863
[28,     4] loss: 0.842
[29,     4] loss: 0.800
[30,     4] loss: 0.811
[31,     4] loss: 0.854
[32,     4] loss: 0.897
[33,     4] loss: 0.822
[34,     4] loss: 0.837
[35,     4] loss: 0.886
[36,     4] loss: 0.863
[37,     4] loss: 0.813
[38,     4] loss: 0.783
[39,     4] loss: 0.805
[40,     4] loss: 0.794
[41,     4] loss: 0.761
[42,     4] loss: 0.758
[43,     4] loss: 0.738
[44,     4] loss: 0.763
[45,     4] loss: 0.760
[46,     4] loss: 0.756
[47,     4] loss: 0.737
[48,     4] loss: 0.845
[49,     4] loss: 0.839
[50,     4] loss: 0.807
[51,     4] loss: 0.831
[52,     4] loss: 0.822
[53,     4] loss: 0.884
[54,     4] loss: 0.768
[55,     4] loss: 0.750
[56,     4] loss: 0.740
[57,     4] loss: 0.746
[58,     4] loss: 0.744
[59,     4] loss: 0.739
[60,     4] loss: 0.743
[61,     4] loss: 0.751
[62,     4] loss: 0.758
[63,     4] loss: 0.749
Early stopping applied (best metric=0.3612707853317261)
Finished Training
Total time taken: 31.68807578086853
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.400
[2,     4] loss: 1.390
[3,     4] loss: 1.387
[4,     4] loss: 1.386
[5,     4] loss: 1.384
[6,     4] loss: 1.383
[7,     4] loss: 1.371
[8,     4] loss: 1.345
[9,     4] loss: 1.311
[10,     4] loss: 1.260
[11,     4] loss: 1.173
[12,     4] loss: 1.258
[13,     4] loss: 1.155
[14,     4] loss: 1.079
[15,     4] loss: 1.087
[16,     4] loss: 1.019
[17,     4] loss: 0.977
[18,     4] loss: 0.978
[19,     4] loss: 1.032
[20,     4] loss: 0.926
[21,     4] loss: 0.973
[22,     4] loss: 0.894
[23,     4] loss: 0.842
[24,     4] loss: 0.968
[25,     4] loss: 1.056
[26,     4] loss: 1.042
[27,     4] loss: 0.971
[28,     4] loss: 0.989
[29,     4] loss: 0.889
[30,     4] loss: 0.881
[31,     4] loss: 0.880
[32,     4] loss: 0.860
[33,     4] loss: 0.851
[34,     4] loss: 0.861
[35,     4] loss: 0.857
[36,     4] loss: 0.866
[37,     4] loss: 0.816
[38,     4] loss: 0.794
[39,     4] loss: 0.811
[40,     4] loss: 0.790
[41,     4] loss: 0.779
[42,     4] loss: 0.827
[43,     4] loss: 0.859
[44,     4] loss: 0.805
[45,     4] loss: 0.789
[46,     4] loss: 0.830
[47,     4] loss: 0.838
[48,     4] loss: 0.818
[49,     4] loss: 0.818
[50,     4] loss: 0.758
[51,     4] loss: 0.788
[52,     4] loss: 0.764
[53,     4] loss: 0.749
[54,     4] loss: 0.764
[55,     4] loss: 0.791
[56,     4] loss: 0.779
[57,     4] loss: 0.791
[58,     4] loss: 0.763
[59,     4] loss: 0.788
[60,     4] loss: 0.754
[61,     4] loss: 0.796
[62,     4] loss: 0.810
[63,     4] loss: 0.796
[64,     4] loss: 0.876
[65,     4] loss: 0.822
[66,     4] loss: 0.827
[67,     4] loss: 0.833
[68,     4] loss: 0.788
[69,     4] loss: 0.806
[70,     4] loss: 0.786
[71,     4] loss: 0.867
[72,     4] loss: 0.881
[73,     4] loss: 0.805
[74,     4] loss: 0.767
[75,     4] loss: 0.801
[76,     4] loss: 0.765
[77,     4] loss: 0.842
[78,     4] loss: 0.805
[79,     4] loss: 0.841
[80,     4] loss: 0.885
[81,     4] loss: 0.838
[82,     4] loss: 0.782
[83,     4] loss: 0.791
[84,     4] loss: 0.810
[85,     4] loss: 0.765
[86,     4] loss: 0.750
[87,     4] loss: 0.816
[88,     4] loss: 0.785
[89,     4] loss: 0.792
[90,     4] loss: 0.789
[91,     4] loss: 0.826
[92,     4] loss: 0.796
[93,     4] loss: 0.816
[94,     4] loss: 0.758
[95,     4] loss: 0.770
[96,     4] loss: 0.808
[97,     4] loss: 0.778
[98,     4] loss: 0.757
[99,     4] loss: 0.748
[100,     4] loss: 0.765
[101,     4] loss: 0.791
[102,     4] loss: 0.831
[103,     4] loss: 0.767
[104,     4] loss: 0.802
[105,     4] loss: 0.874
[106,     4] loss: 0.912
[107,     4] loss: 0.871
[108,     4] loss: 0.872
[109,     4] loss: 0.903
[110,     4] loss: 0.840
[111,     4] loss: 0.820
[112,     4] loss: 0.809
[113,     4] loss: 0.763
[114,     4] loss: 0.755
[115,     4] loss: 0.762
[116,     4] loss: 0.780
[117,     4] loss: 0.776
[118,     4] loss: 0.767
[119,     4] loss: 0.765
[120,     4] loss: 0.742
[121,     4] loss: 0.732
[122,     4] loss: 0.747
[123,     4] loss: 0.753
[124,     4] loss: 0.790
[125,     4] loss: 0.790
[126,     4] loss: 0.819
[127,     4] loss: 0.775
[128,     4] loss: 0.794
[129,     4] loss: 0.837
[130,     4] loss: 0.881
[131,     4] loss: 0.900
[132,     4] loss: 0.790
[133,     4] loss: 0.763
[134,     4] loss: 0.830
[135,     4] loss: 0.760
[136,     4] loss: 0.755
[137,     4] loss: 0.799
[138,     4] loss: 0.747
[139,     4] loss: 0.755
[140,     4] loss: 0.739
[141,     4] loss: 0.734
[142,     4] loss: 0.740
[143,     4] loss: 0.780
[144,     4] loss: 0.771
[145,     4] loss: 0.760
[146,     4] loss: 0.790
[147,     4] loss: 0.816
[148,     4] loss: 0.931
[149,     4] loss: 0.867
[150,     4] loss: 0.860
[151,     4] loss: 0.786
[152,     4] loss: 0.760
[153,     4] loss: 0.735
[154,     4] loss: 0.744
[155,     4] loss: 0.740
[156,     4] loss: 0.742
[157,     4] loss: 0.744
[158,     4] loss: 0.754
[159,     4] loss: 0.739
[160,     4] loss: 0.747
[161,     4] loss: 0.749
[162,     4] loss: 0.976
[163,     4] loss: 0.905
[164,     4] loss: 0.897
[165,     4] loss: 0.894
[166,     4] loss: 0.848
[167,     4] loss: 0.826
[168,     4] loss: 0.752
[169,     4] loss: 0.756
[170,     4] loss: 0.742
[171,     4] loss: 0.743
[172,     4] loss: 0.754
[173,     4] loss: 0.744
[174,     4] loss: 0.774
[175,     4] loss: 0.779
[176,     4] loss: 0.768
[177,     4] loss: 0.844
[178,     4] loss: 0.827
[179,     4] loss: 0.896
[180,     4] loss: 0.804
[181,     4] loss: 0.769
[182,     4] loss: 0.755
[183,     4] loss: 0.741
Early stopping applied (best metric=0.4122614562511444)
Finished Training
Total time taken: 92.10322093963623
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.380
[3,     4] loss: 1.384
[4,     4] loss: 1.386
[5,     4] loss: 1.381
[6,     4] loss: 1.362
[7,     4] loss: 1.331
[8,     4] loss: 1.299
[9,     4] loss: 1.258
[10,     4] loss: 1.235
[11,     4] loss: 1.194
[12,     4] loss: 1.126
[13,     4] loss: 1.066
[14,     4] loss: 1.036
[15,     4] loss: 1.108
[16,     4] loss: 1.069
[17,     4] loss: 1.048
[18,     4] loss: 1.030
[19,     4] loss: 1.011
[20,     4] loss: 0.950
[21,     4] loss: 0.923
[22,     4] loss: 0.992
[23,     4] loss: 0.924
[24,     4] loss: 0.917
[25,     4] loss: 0.884
[26,     4] loss: 0.910
[27,     4] loss: 0.881
[28,     4] loss: 0.886
[29,     4] loss: 0.814
[30,     4] loss: 0.905
[31,     4] loss: 0.804
[32,     4] loss: 0.846
[33,     4] loss: 0.811
[34,     4] loss: 0.849
[35,     4] loss: 0.868
[36,     4] loss: 0.857
[37,     4] loss: 0.867
[38,     4] loss: 0.814
[39,     4] loss: 0.895
[40,     4] loss: 0.857
[41,     4] loss: 0.811
[42,     4] loss: 0.786
[43,     4] loss: 0.802
[44,     4] loss: 0.838
[45,     4] loss: 0.828
[46,     4] loss: 0.791
[47,     4] loss: 0.797
[48,     4] loss: 0.747
[49,     4] loss: 0.775
[50,     4] loss: 0.761
[51,     4] loss: 0.788
[52,     4] loss: 0.783
[53,     4] loss: 0.906
[54,     4] loss: 0.811
[55,     4] loss: 0.778
[56,     4] loss: 0.867
[57,     4] loss: 0.854
[58,     4] loss: 0.888
[59,     4] loss: 0.865
[60,     4] loss: 0.766
[61,     4] loss: 0.772
[62,     4] loss: 0.778
[63,     4] loss: 0.759
[64,     4] loss: 0.773
[65,     4] loss: 0.782
[66,     4] loss: 0.786
[67,     4] loss: 0.774
[68,     4] loss: 0.755
[69,     4] loss: 0.775
[70,     4] loss: 0.734
[71,     4] loss: 0.737
[72,     4] loss: 0.751
[73,     4] loss: 0.747
[74,     4] loss: 0.822
Early stopping applied (best metric=0.39677172899246216)
Finished Training
Total time taken: 37.59009051322937
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.387
[3,     4] loss: 1.374
[4,     4] loss: 1.383
[5,     4] loss: 1.370
[6,     4] loss: 1.349
[7,     4] loss: 1.327
[8,     4] loss: 1.242
[9,     4] loss: 1.234
[10,     4] loss: 1.154
[11,     4] loss: 1.120
[12,     4] loss: 1.146
[13,     4] loss: 1.056
[14,     4] loss: 1.027
[15,     4] loss: 1.008
[16,     4] loss: 0.984
[17,     4] loss: 1.017
[18,     4] loss: 0.976
[19,     4] loss: 0.989
[20,     4] loss: 1.016
[21,     4] loss: 0.953
[22,     4] loss: 0.881
[23,     4] loss: 0.868
[24,     4] loss: 0.872
[25,     4] loss: 0.947
[26,     4] loss: 1.004
[27,     4] loss: 0.903
[28,     4] loss: 0.876
[29,     4] loss: 0.849
[30,     4] loss: 0.858
[31,     4] loss: 0.791
[32,     4] loss: 0.784
[33,     4] loss: 0.775
[34,     4] loss: 0.774
[35,     4] loss: 0.741
[36,     4] loss: 0.778
[37,     4] loss: 0.771
[38,     4] loss: 0.805
[39,     4] loss: 0.789
[40,     4] loss: 0.790
[41,     4] loss: 0.824
[42,     4] loss: 0.812
[43,     4] loss: 0.993
[44,     4] loss: 0.932
[45,     4] loss: 0.896
[46,     4] loss: 0.853
[47,     4] loss: 0.936
[48,     4] loss: 0.868
[49,     4] loss: 0.839
[50,     4] loss: 0.822
[51,     4] loss: 0.793
[52,     4] loss: 0.801
[53,     4] loss: 0.800
[54,     4] loss: 0.789
[55,     4] loss: 0.767
[56,     4] loss: 0.786
[57,     4] loss: 0.777
[58,     4] loss: 0.746
[59,     4] loss: 0.779
[60,     4] loss: 0.821
[61,     4] loss: 0.791
[62,     4] loss: 0.781
Early stopping applied (best metric=0.45280683040618896)
Finished Training
Total time taken: 31.49189043045044
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.380
[2,     4] loss: 1.398
[3,     4] loss: 1.382
[4,     4] loss: 1.387
[5,     4] loss: 1.379
[6,     4] loss: 1.378
[7,     4] loss: 1.373
[8,     4] loss: 1.349
[9,     4] loss: 1.315
[10,     4] loss: 1.269
[11,     4] loss: 1.220
[12,     4] loss: 1.134
[13,     4] loss: 1.084
[14,     4] loss: 1.049
[15,     4] loss: 1.016
[16,     4] loss: 0.953
[17,     4] loss: 0.976
[18,     4] loss: 1.021
[19,     4] loss: 1.021
[20,     4] loss: 1.008
[21,     4] loss: 0.935
[22,     4] loss: 0.863
[23,     4] loss: 0.834
[24,     4] loss: 0.868
[25,     4] loss: 0.868
[26,     4] loss: 0.883
[27,     4] loss: 0.927
[28,     4] loss: 0.842
[29,     4] loss: 0.880
[30,     4] loss: 0.796
[31,     4] loss: 0.835
[32,     4] loss: 0.815
[33,     4] loss: 0.799
[34,     4] loss: 0.778
[35,     4] loss: 0.765
[36,     4] loss: 0.790
[37,     4] loss: 0.788
[38,     4] loss: 0.790
[39,     4] loss: 0.826
[40,     4] loss: 0.775
[41,     4] loss: 0.775
[42,     4] loss: 0.774
[43,     4] loss: 0.855
[44,     4] loss: 0.813
[45,     4] loss: 0.790
[46,     4] loss: 0.749
[47,     4] loss: 0.781
[48,     4] loss: 0.810
[49,     4] loss: 0.808
[50,     4] loss: 0.817
[51,     4] loss: 0.801
[52,     4] loss: 0.795
[53,     4] loss: 0.746
[54,     4] loss: 0.843
[55,     4] loss: 0.779
[56,     4] loss: 0.824
[57,     4] loss: 0.796
[58,     4] loss: 0.783
[59,     4] loss: 0.845
[60,     4] loss: 0.872
[61,     4] loss: 0.809
[62,     4] loss: 0.784
Early stopping applied (best metric=0.47579458355903625)
Finished Training
Total time taken: 31.465540647506714
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.386
[3,     4] loss: 1.386
[4,     4] loss: 1.380
[5,     4] loss: 1.370
[6,     4] loss: 1.363
[7,     4] loss: 1.331
[8,     4] loss: 1.295
[9,     4] loss: 1.306
[10,     4] loss: 1.238
[11,     4] loss: 1.214
[12,     4] loss: 1.175
[13,     4] loss: 1.141
[14,     4] loss: 1.124
[15,     4] loss: 1.142
[16,     4] loss: 1.115
[17,     4] loss: 1.058
[18,     4] loss: 1.012
[19,     4] loss: 1.074
[20,     4] loss: 1.062
[21,     4] loss: 1.051
[22,     4] loss: 0.935
[23,     4] loss: 1.002
[24,     4] loss: 0.979
[25,     4] loss: 0.891
[26,     4] loss: 0.860
[27,     4] loss: 0.911
[28,     4] loss: 0.849
[29,     4] loss: 0.846
[30,     4] loss: 0.883
[31,     4] loss: 0.981
[32,     4] loss: 0.979
[33,     4] loss: 0.954
[34,     4] loss: 0.941
[35,     4] loss: 0.889
[36,     4] loss: 0.850
[37,     4] loss: 0.849
[38,     4] loss: 0.842
[39,     4] loss: 0.856
[40,     4] loss: 0.814
[41,     4] loss: 0.794
[42,     4] loss: 0.810
[43,     4] loss: 0.887
[44,     4] loss: 0.801
[45,     4] loss: 0.804
[46,     4] loss: 0.821
[47,     4] loss: 0.813
[48,     4] loss: 0.775
[49,     4] loss: 0.796
[50,     4] loss: 0.846
[51,     4] loss: 0.818
[52,     4] loss: 0.837
[53,     4] loss: 0.833
[54,     4] loss: 0.837
[55,     4] loss: 0.822
[56,     4] loss: 0.801
[57,     4] loss: 0.830
[58,     4] loss: 0.785
[59,     4] loss: 0.794
[60,     4] loss: 0.788
[61,     4] loss: 0.756
[62,     4] loss: 0.752
[63,     4] loss: 0.744
[64,     4] loss: 0.855
[65,     4] loss: 0.809
[66,     4] loss: 0.824
[67,     4] loss: 0.773
[68,     4] loss: 0.937
[69,     4] loss: 1.038
[70,     4] loss: 1.166
[71,     4] loss: 1.120
[72,     4] loss: 1.093
[73,     4] loss: 1.024
[74,     4] loss: 0.899
[75,     4] loss: 0.893
[76,     4] loss: 0.847
[77,     4] loss: 0.809
[78,     4] loss: 0.858
[79,     4] loss: 0.863
[80,     4] loss: 0.810
[81,     4] loss: 0.796
[82,     4] loss: 0.775
[83,     4] loss: 0.776
[84,     4] loss: 0.841
[85,     4] loss: 0.790
[86,     4] loss: 0.858
[87,     4] loss: 0.856
[88,     4] loss: 0.867
[89,     4] loss: 0.811
[90,     4] loss: 0.834
[91,     4] loss: 0.892
[92,     4] loss: 0.901
[93,     4] loss: 0.851
[94,     4] loss: 0.805
[95,     4] loss: 0.794
[96,     4] loss: 0.755
[97,     4] loss: 0.763
[98,     4] loss: 0.760
[99,     4] loss: 0.755
[100,     4] loss: 0.758
[101,     4] loss: 0.930
[102,     4] loss: 0.914
[103,     4] loss: 0.881
[104,     4] loss: 0.864
[105,     4] loss: 0.772
[106,     4] loss: 0.790
[107,     4] loss: 0.787
[108,     4] loss: 0.804
[109,     4] loss: 0.750
[110,     4] loss: 0.790
[111,     4] loss: 0.781
[112,     4] loss: 0.855
[113,     4] loss: 0.787
[114,     4] loss: 0.773
[115,     4] loss: 0.755
[116,     4] loss: 0.757
Early stopping applied (best metric=0.38936930894851685)
Finished Training
Total time taken: 58.306848764419556
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.386
[3,     4] loss: 1.381
[4,     4] loss: 1.372
[5,     4] loss: 1.375
[6,     4] loss: 1.344
[7,     4] loss: 1.294
[8,     4] loss: 1.253
[9,     4] loss: 1.164
[10,     4] loss: 1.169
[11,     4] loss: 1.207
[12,     4] loss: 1.137
[13,     4] loss: 1.077
[14,     4] loss: 1.056
[15,     4] loss: 1.014
[16,     4] loss: 0.957
[17,     4] loss: 0.914
[18,     4] loss: 0.867
[19,     4] loss: 0.874
[20,     4] loss: 0.876
[21,     4] loss: 0.887
[22,     4] loss: 0.924
[23,     4] loss: 0.874
[24,     4] loss: 0.906
[25,     4] loss: 0.853
[26,     4] loss: 0.846
[27,     4] loss: 0.842
[28,     4] loss: 0.821
[29,     4] loss: 0.809
[30,     4] loss: 0.946
[31,     4] loss: 0.812
[32,     4] loss: 0.804
[33,     4] loss: 0.826
[34,     4] loss: 0.787
[35,     4] loss: 0.775
[36,     4] loss: 0.825
[37,     4] loss: 0.791
[38,     4] loss: 0.777
[39,     4] loss: 0.752
[40,     4] loss: 0.806
[41,     4] loss: 0.759
[42,     4] loss: 0.784
[43,     4] loss: 0.771
[44,     4] loss: 0.753
[45,     4] loss: 0.745
[46,     4] loss: 0.792
[47,     4] loss: 0.771
[48,     4] loss: 0.770
[49,     4] loss: 0.751
[50,     4] loss: 0.776
[51,     4] loss: 0.775
[52,     4] loss: 0.765
[53,     4] loss: 0.824
[54,     4] loss: 0.796
[55,     4] loss: 0.771
[56,     4] loss: 0.840
[57,     4] loss: 0.791
Early stopping applied (best metric=0.539128839969635)
Finished Training
Total time taken: 28.87541127204895
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.384
[3,     4] loss: 1.370
[4,     4] loss: 1.351
[5,     4] loss: 1.299
[6,     4] loss: 1.261
[7,     4] loss: 1.263
[8,     4] loss: 1.176
[9,     4] loss: 1.118
[10,     4] loss: 1.112
[11,     4] loss: 0.975
[12,     4] loss: 0.964
[13,     4] loss: 0.898
[14,     4] loss: 1.048
[15,     4] loss: 0.902
[16,     4] loss: 0.985
[17,     4] loss: 0.948
[18,     4] loss: 0.966
[19,     4] loss: 0.953
[20,     4] loss: 0.918
[21,     4] loss: 0.988
[22,     4] loss: 0.936
[23,     4] loss: 0.895
[24,     4] loss: 0.833
[25,     4] loss: 0.820
[26,     4] loss: 0.803
[27,     4] loss: 1.029
[28,     4] loss: 0.865
[29,     4] loss: 0.850
[30,     4] loss: 0.819
[31,     4] loss: 0.846
[32,     4] loss: 0.800
[33,     4] loss: 0.807
[34,     4] loss: 0.761
[35,     4] loss: 0.760
[36,     4] loss: 0.747
[37,     4] loss: 0.797
[38,     4] loss: 0.800
[39,     4] loss: 0.834
[40,     4] loss: 0.811
[41,     4] loss: 0.885
[42,     4] loss: 0.936
[43,     4] loss: 0.896
[44,     4] loss: 0.868
[45,     4] loss: 0.835
[46,     4] loss: 0.816
[47,     4] loss: 0.806
[48,     4] loss: 0.793
[49,     4] loss: 0.826
[50,     4] loss: 0.823
[51,     4] loss: 0.794
[52,     4] loss: 0.795
[53,     4] loss: 0.757
[54,     4] loss: 0.776
[55,     4] loss: 0.777
[56,     4] loss: 0.754
[57,     4] loss: 0.736
[58,     4] loss: 0.739
Early stopping applied (best metric=0.4864749312400818)
Finished Training
Total time taken: 29.479441165924072
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.385
[3,     4] loss: 1.374
[4,     4] loss: 1.347
[5,     4] loss: 1.296
[6,     4] loss: 1.251
[7,     4] loss: 1.257
[8,     4] loss: 1.176
[9,     4] loss: 1.180
[10,     4] loss: 1.160
[11,     4] loss: 1.105
[12,     4] loss: 1.099
[13,     4] loss: 0.971
[14,     4] loss: 0.970
[15,     4] loss: 0.953
[16,     4] loss: 0.927
[17,     4] loss: 0.914
[18,     4] loss: 0.901
[19,     4] loss: 0.968
[20,     4] loss: 0.937
[21,     4] loss: 0.897
[22,     4] loss: 0.985
[23,     4] loss: 0.959
[24,     4] loss: 0.961
[25,     4] loss: 0.934
[26,     4] loss: 0.865
[27,     4] loss: 0.828
[28,     4] loss: 0.806
[29,     4] loss: 0.833
[30,     4] loss: 0.753
[31,     4] loss: 0.827
[32,     4] loss: 0.820
[33,     4] loss: 0.822
[34,     4] loss: 0.796
[35,     4] loss: 0.777
[36,     4] loss: 0.780
[37,     4] loss: 0.792
[38,     4] loss: 0.797
[39,     4] loss: 0.750
[40,     4] loss: 0.767
[41,     4] loss: 0.778
[42,     4] loss: 0.835
[43,     4] loss: 0.786
[44,     4] loss: 0.848
[45,     4] loss: 0.819
[46,     4] loss: 0.836
[47,     4] loss: 0.833
[48,     4] loss: 0.805
[49,     4] loss: 0.786
[50,     4] loss: 0.803
[51,     4] loss: 0.784
[52,     4] loss: 0.765
[53,     4] loss: 0.788
[54,     4] loss: 0.763
[55,     4] loss: 0.762
[56,     4] loss: 0.758
[57,     4] loss: 0.769
[58,     4] loss: 0.744
[59,     4] loss: 0.737
[60,     4] loss: 0.780
Early stopping applied (best metric=0.44891080260276794)
Finished Training
Total time taken: 30.088470697402954
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.396
[2,     4] loss: 1.389
[3,     4] loss: 1.384
[4,     4] loss: 1.382
[5,     4] loss: 1.378
[6,     4] loss: 1.370
[7,     4] loss: 1.346
[8,     4] loss: 1.289
[9,     4] loss: 1.262
[10,     4] loss: 1.182
[11,     4] loss: 1.106
[12,     4] loss: 1.034
[13,     4] loss: 1.018
[14,     4] loss: 1.040
[15,     4] loss: 1.026
[16,     4] loss: 0.995
[17,     4] loss: 0.983
[18,     4] loss: 0.975
[19,     4] loss: 0.895
[20,     4] loss: 0.939
[21,     4] loss: 0.917
[22,     4] loss: 0.847
[23,     4] loss: 0.986
[24,     4] loss: 0.942
[25,     4] loss: 0.937
[26,     4] loss: 0.875
[27,     4] loss: 0.842
[28,     4] loss: 0.871
[29,     4] loss: 0.889
[30,     4] loss: 0.929
[31,     4] loss: 0.879
[32,     4] loss: 0.856
[33,     4] loss: 0.819
[34,     4] loss: 0.788
[35,     4] loss: 0.860
[36,     4] loss: 0.835
[37,     4] loss: 0.871
[38,     4] loss: 0.804
[39,     4] loss: 0.797
[40,     4] loss: 0.842
[41,     4] loss: 0.805
[42,     4] loss: 0.785
[43,     4] loss: 0.772
[44,     4] loss: 0.779
[45,     4] loss: 0.763
[46,     4] loss: 0.752
[47,     4] loss: 0.847
[48,     4] loss: 0.805
[49,     4] loss: 0.759
[50,     4] loss: 0.770
[51,     4] loss: 0.799
[52,     4] loss: 0.812
[53,     4] loss: 0.784
[54,     4] loss: 0.738
[55,     4] loss: 0.743
[56,     4] loss: 0.778
[57,     4] loss: 0.745
[58,     4] loss: 0.732
Early stopping applied (best metric=0.5174168944358826)
Finished Training
Total time taken: 29.238430738449097
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.392
[3,     4] loss: 1.388
[4,     4] loss: 1.391
[5,     4] loss: 1.388
[6,     4] loss: 1.385
[7,     4] loss: 1.385
[8,     4] loss: 1.384
[9,     4] loss: 1.381
[10,     4] loss: 1.367
[11,     4] loss: 1.348
[12,     4] loss: 1.314
[13,     4] loss: 1.240
[14,     4] loss: 1.173
[15,     4] loss: 1.101
[16,     4] loss: 1.078
[17,     4] loss: 1.301
[18,     4] loss: 1.138
[19,     4] loss: 1.107
[20,     4] loss: 1.098
[21,     4] loss: 1.035
[22,     4] loss: 0.968
[23,     4] loss: 0.990
[24,     4] loss: 0.938
[25,     4] loss: 0.877
[26,     4] loss: 0.936
[27,     4] loss: 1.020
[28,     4] loss: 0.975
[29,     4] loss: 0.966
[30,     4] loss: 0.912
[31,     4] loss: 0.922
[32,     4] loss: 0.842
[33,     4] loss: 0.799
[34,     4] loss: 0.784
[35,     4] loss: 0.800
[36,     4] loss: 0.767
[37,     4] loss: 0.765
[38,     4] loss: 0.889
[39,     4] loss: 0.951
[40,     4] loss: 1.075
[41,     4] loss: 0.972
[42,     4] loss: 0.910
[43,     4] loss: 0.841
[44,     4] loss: 0.812
[45,     4] loss: 0.783
[46,     4] loss: 0.755
[47,     4] loss: 0.749
[48,     4] loss: 0.752
[49,     4] loss: 0.756
[50,     4] loss: 0.803
[51,     4] loss: 0.773
[52,     4] loss: 0.787
[53,     4] loss: 0.779
[54,     4] loss: 0.880
[55,     4] loss: 0.833
[56,     4] loss: 0.803
[57,     4] loss: 0.777
[58,     4] loss: 0.764
[59,     4] loss: 0.796
[60,     4] loss: 0.817
[61,     4] loss: 0.869
[62,     4] loss: 0.868
[63,     4] loss: 0.814
[64,     4] loss: 0.778
[65,     4] loss: 0.765
[66,     4] loss: 0.764
[67,     4] loss: 0.815
[68,     4] loss: 0.800
[69,     4] loss: 0.739
[70,     4] loss: 0.798
[71,     4] loss: 0.823
[72,     4] loss: 0.783
[73,     4] loss: 0.760
[74,     4] loss: 0.756
[75,     4] loss: 0.743
[76,     4] loss: 0.752
[77,     4] loss: 0.863
[78,     4] loss: 0.923
[79,     4] loss: 0.898
[80,     4] loss: 0.868
[81,     4] loss: 0.895
[82,     4] loss: 0.827
[83,     4] loss: 0.829
[84,     4] loss: 0.778
[85,     4] loss: 0.744
[86,     4] loss: 0.779
[87,     4] loss: 0.771
[88,     4] loss: 0.748
[89,     4] loss: 0.767
[90,     4] loss: 0.739
[91,     4] loss: 0.732
[92,     4] loss: 0.742
Early stopping applied (best metric=0.31028950214385986)
Finished Training
Total time taken: 46.202258825302124
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.386
[3,     4] loss: 1.389
[4,     4] loss: 1.394
[5,     4] loss: 1.380
[6,     4] loss: 1.367
[7,     4] loss: 1.324
[8,     4] loss: 1.261
[9,     4] loss: 1.257
[10,     4] loss: 1.183
[11,     4] loss: 1.112
[12,     4] loss: 1.095
[13,     4] loss: 1.069
[14,     4] loss: 1.003
[15,     4] loss: 1.035
[16,     4] loss: 1.112
[17,     4] loss: 1.110
[18,     4] loss: 1.003
[19,     4] loss: 1.004
[20,     4] loss: 0.902
[21,     4] loss: 0.829
[22,     4] loss: 0.897
[23,     4] loss: 0.819
[24,     4] loss: 0.886
[25,     4] loss: 0.877
[26,     4] loss: 0.881
[27,     4] loss: 0.874
[28,     4] loss: 0.824
[29,     4] loss: 0.795
[30,     4] loss: 0.776
[31,     4] loss: 0.784
[32,     4] loss: 0.811
[33,     4] loss: 0.831
[34,     4] loss: 0.779
[35,     4] loss: 0.844
[36,     4] loss: 0.858
[37,     4] loss: 0.840
[38,     4] loss: 0.819
[39,     4] loss: 0.777
[40,     4] loss: 0.760
[41,     4] loss: 0.784
[42,     4] loss: 0.797
[43,     4] loss: 0.737
[44,     4] loss: 0.759
[45,     4] loss: 0.768
[46,     4] loss: 0.757
[47,     4] loss: 0.837
[48,     4] loss: 0.819
[49,     4] loss: 0.793
[50,     4] loss: 0.764
[51,     4] loss: 0.731
[52,     4] loss: 0.715
[53,     4] loss: 0.720
[54,     4] loss: 0.746
[55,     4] loss: 0.744
[56,     4] loss: 0.780
[57,     4] loss: 0.797
[58,     4] loss: 0.818
[59,     4] loss: 0.757
[60,     4] loss: 0.751
Early stopping applied (best metric=0.3790348470211029)
Finished Training
Total time taken: 30.219475030899048
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.401
[2,     4] loss: 1.389
[3,     4] loss: 1.393
[4,     4] loss: 1.385
[5,     4] loss: 1.381
[6,     4] loss: 1.380
[7,     4] loss: 1.375
[8,     4] loss: 1.353
[9,     4] loss: 1.318
[10,     4] loss: 1.258
[11,     4] loss: 1.169
[12,     4] loss: 1.129
[13,     4] loss: 1.110
[14,     4] loss: 1.083
[15,     4] loss: 0.979
[16,     4] loss: 0.988
[17,     4] loss: 0.977
[18,     4] loss: 1.047
[19,     4] loss: 0.996
[20,     4] loss: 0.983
[21,     4] loss: 0.951
[22,     4] loss: 0.980
[23,     4] loss: 0.883
[24,     4] loss: 0.945
[25,     4] loss: 0.941
[26,     4] loss: 0.880
[27,     4] loss: 0.858
[28,     4] loss: 0.852
[29,     4] loss: 0.790
[30,     4] loss: 0.846
[31,     4] loss: 0.790
[32,     4] loss: 0.794
[33,     4] loss: 0.804
[34,     4] loss: 0.884
[35,     4] loss: 0.799
[36,     4] loss: 0.797
[37,     4] loss: 0.859
[38,     4] loss: 0.823
[39,     4] loss: 0.835
[40,     4] loss: 0.783
[41,     4] loss: 0.856
[42,     4] loss: 0.796
[43,     4] loss: 0.778
[44,     4] loss: 0.782
[45,     4] loss: 0.774
[46,     4] loss: 0.818
[47,     4] loss: 0.814
[48,     4] loss: 0.847
[49,     4] loss: 0.812
[50,     4] loss: 0.778
[51,     4] loss: 0.746
[52,     4] loss: 0.740
[53,     4] loss: 0.748
[54,     4] loss: 0.745
[55,     4] loss: 0.737
[56,     4] loss: 0.746
[57,     4] loss: 0.738
[58,     4] loss: 0.779
[59,     4] loss: 0.816
[60,     4] loss: 0.900
[61,     4] loss: 0.807
[62,     4] loss: 0.794
[63,     4] loss: 0.743
[64,     4] loss: 0.746
[65,     4] loss: 0.769
[66,     4] loss: 0.772
[67,     4] loss: 0.795
[68,     4] loss: 0.873
[69,     4] loss: 0.841
[70,     4] loss: 0.826
[71,     4] loss: 0.749
[72,     4] loss: 0.766
[73,     4] loss: 0.847
[74,     4] loss: 0.841
[75,     4] loss: 0.819
[76,     4] loss: 0.805
Early stopping applied (best metric=0.2865086793899536)
Finished Training
Total time taken: 38.05486059188843
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.385
[5,     4] loss: 1.383
[6,     4] loss: 1.388
[7,     4] loss: 1.386
[8,     4] loss: 1.377
[9,     4] loss: 1.367
[10,     4] loss: 1.329
[11,     4] loss: 1.291
[12,     4] loss: 1.200
[13,     4] loss: 1.139
[14,     4] loss: 1.313
[15,     4] loss: 1.153
[16,     4] loss: 1.152
[17,     4] loss: 1.066
[18,     4] loss: 1.043
[19,     4] loss: 1.029
[20,     4] loss: 0.982
[21,     4] loss: 0.947
[22,     4] loss: 1.031
[23,     4] loss: 1.004
[24,     4] loss: 0.979
[25,     4] loss: 0.889
[26,     4] loss: 0.897
[27,     4] loss: 0.883
[28,     4] loss: 0.872
[29,     4] loss: 0.940
[30,     4] loss: 0.936
[31,     4] loss: 0.896
[32,     4] loss: 0.927
[33,     4] loss: 0.960
[34,     4] loss: 0.985
[35,     4] loss: 0.881
[36,     4] loss: 0.947
[37,     4] loss: 0.854
[38,     4] loss: 0.867
[39,     4] loss: 0.901
[40,     4] loss: 0.886
[41,     4] loss: 0.804
[42,     4] loss: 0.934
[43,     4] loss: 0.932
[44,     4] loss: 0.836
[45,     4] loss: 0.827
[46,     4] loss: 0.818
[47,     4] loss: 0.838
[48,     4] loss: 0.792
[49,     4] loss: 0.803
[50,     4] loss: 0.808
[51,     4] loss: 0.802
[52,     4] loss: 0.774
[53,     4] loss: 0.792
[54,     4] loss: 0.861
[55,     4] loss: 0.803
[56,     4] loss: 0.807
[57,     4] loss: 0.791
[58,     4] loss: 0.794
[59,     4] loss: 0.750
[60,     4] loss: 0.771
[61,     4] loss: 0.753
[62,     4] loss: 0.934
[63,     4] loss: 1.222
[64,     4] loss: 1.168
[65,     4] loss: 1.184
[66,     4] loss: 1.137
[67,     4] loss: 0.978
[68,     4] loss: 0.956
[69,     4] loss: 0.903
[70,     4] loss: 0.910
[71,     4] loss: 0.868
[72,     4] loss: 0.818
[73,     4] loss: 0.791
[74,     4] loss: 0.766
[75,     4] loss: 0.735
[76,     4] loss: 0.782
[77,     4] loss: 0.779
[78,     4] loss: 0.800
[79,     4] loss: 0.899
[80,     4] loss: 0.899
[81,     4] loss: 0.836
[82,     4] loss: 0.831
[83,     4] loss: 0.807
[84,     4] loss: 0.822
[85,     4] loss: 0.911
[86,     4] loss: 0.885
[87,     4] loss: 0.827
[88,     4] loss: 0.806
[89,     4] loss: 0.768
[90,     4] loss: 0.746
[91,     4] loss: 0.749
[92,     4] loss: 0.734
[93,     4] loss: 0.748
[94,     4] loss: 0.773
[95,     4] loss: 0.792
[96,     4] loss: 0.791
[97,     4] loss: 0.768
[98,     4] loss: 0.816
[99,     4] loss: 0.768
[100,     4] loss: 0.787
[101,     4] loss: 0.767
[102,     4] loss: 0.747
[103,     4] loss: 0.815
[104,     4] loss: 0.753
[105,     4] loss: 0.770
[106,     4] loss: 0.755
[107,     4] loss: 0.752
[108,     4] loss: 0.757
[109,     4] loss: 0.760
[110,     4] loss: 0.759
[111,     4] loss: 0.754
[112,     4] loss: 0.745
[113,     4] loss: 0.740
[114,     4] loss: 0.745
[115,     4] loss: 0.759
[116,     4] loss: 0.812
[117,     4] loss: 0.785
[118,     4] loss: 0.798
[119,     4] loss: 0.818
[120,     4] loss: 0.833
[121,     4] loss: 0.835
Early stopping applied (best metric=0.2870081067085266)
Finished Training
Total time taken: 61.365002155303955
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.381
[2,     4] loss: 1.388
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.380
[6,     4] loss: 1.376
[7,     4] loss: 1.369
[8,     4] loss: 1.331
[9,     4] loss: 1.299
[10,     4] loss: 1.230
[11,     4] loss: 1.167
[12,     4] loss: 1.118
[13,     4] loss: 1.101
[14,     4] loss: 1.093
[15,     4] loss: 1.115
[16,     4] loss: 1.084
[17,     4] loss: 0.988
[18,     4] loss: 1.014
[19,     4] loss: 0.988
[20,     4] loss: 0.928
[21,     4] loss: 0.967
[22,     4] loss: 0.920
[23,     4] loss: 0.958
[24,     4] loss: 0.928
[25,     4] loss: 1.038
[26,     4] loss: 1.001
[27,     4] loss: 0.946
[28,     4] loss: 0.972
[29,     4] loss: 0.865
[30,     4] loss: 0.852
[31,     4] loss: 0.794
[32,     4] loss: 0.845
[33,     4] loss: 0.874
[34,     4] loss: 0.825
[35,     4] loss: 0.794
[36,     4] loss: 0.832
[37,     4] loss: 0.831
[38,     4] loss: 0.810
[39,     4] loss: 0.754
[40,     4] loss: 0.787
[41,     4] loss: 0.817
[42,     4] loss: 0.783
[43,     4] loss: 0.758
[44,     4] loss: 0.823
[45,     4] loss: 0.746
[46,     4] loss: 0.806
[47,     4] loss: 0.773
[48,     4] loss: 0.812
[49,     4] loss: 0.832
[50,     4] loss: 0.791
[51,     4] loss: 0.815
[52,     4] loss: 0.791
[53,     4] loss: 0.757
[54,     4] loss: 0.756
[55,     4] loss: 0.764
[56,     4] loss: 0.795
[57,     4] loss: 0.873
[58,     4] loss: 0.803
[59,     4] loss: 0.777
[60,     4] loss: 0.742
Early stopping applied (best metric=0.40160810947418213)
Finished Training
Total time taken: 30.298479318618774
{'Hydroxylation-K Validation Accuracy': 0.7712765957446809, 'Hydroxylation-K Validation Sensitivity': 0.7837037037037037, 'Hydroxylation-K Validation Specificity': 0.7684210526315789, 'Hydroxylation-K Validation Precision': 0.4811623682475076, 'Hydroxylation-K AUC ROC': 0.8273294346978557, 'Hydroxylation-K AUC PR': 0.5765294325901765, 'Hydroxylation-K MCC': 0.47785638780746154, 'Hydroxylation-K F1': 0.5895397392155337, 'Validation Loss (Hydroxylation-K)': 0.4096436937650045, 'Methylation-K Validation Accuracy': 0.7816872051567322, 'Methylation-K Validation Sensitivity': 0.18773612674092868, 'Methylation-K Validation Specificity': 0.8461005781947337, 'Methylation-K Validation Precision': 0.12057876877586575, 'Methylation-K AUC ROC': 0.5492284907890788, 'Methylation-K AUC PR': 0.1135322456397041, 'Methylation-K MCC': 0.028960986995240977, 'Methylation-K F1': 0.13886914819480795, 'Validation Loss (Methylation-K)': 0.905224601427714, 'Validation Loss (total)': 1.3148682912190754, 'TimeToTrain': 40.43116645812988}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008961661164599864,
 'learning_rate_Hydroxylation-K': 0.003439243789675355,
 'learning_rate_Methylation-K': 0.00968766632678087,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.0820239749020794,
 'loss_weight_Methylation-K': 0.950167930342441,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2272617043,
 'sample_weights': [0.15168924721893423, 0.3248532008338616],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.49257515636172,
 'weight_decay_Hydroxylation-K': 7.731712255634221,
 'weight_decay_Methylation-K': 8.02898066464152}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.382
[3,     4] loss: 1.382
[4,     4] loss: 1.373
[5,     4] loss: 1.371
[6,     4] loss: 1.349
[7,     4] loss: 1.335
[8,     4] loss: 1.295
[9,     4] loss: 1.289
[10,     4] loss: 1.206
[11,     4] loss: 1.155
[12,     4] loss: 1.127
[13,     4] loss: 1.082
[14,     4] loss: 1.037
[15,     4] loss: 1.041
[16,     4] loss: 0.991
[17,     4] loss: 0.966
[18,     4] loss: 0.906
[19,     4] loss: 0.953
[20,     4] loss: 0.868
[21,     4] loss: 0.822
[22,     4] loss: 0.817
[23,     4] loss: 0.873
[24,     4] loss: 0.789
[25,     4] loss: 0.833
[26,     4] loss: 0.815
[27,     4] loss: 0.809
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022208866279226826,
 'learning_rate_Hydroxylation-K': 0.006976180576953487,
 'learning_rate_Methylation-K': 0.002023552273108177,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9044008932662225,
 'loss_weight_Methylation-K': 0.5044755373350459,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2074778134,
 'sample_weights': [0.0820239749020794, 0.950167930342441],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.631017088991786,
 'weight_decay_Hydroxylation-K': 4.37421047943759,
 'weight_decay_Methylation-K': 8.833407605266228}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.387
[3,     4] loss: 1.389
[4,     4] loss: 1.384
[5,     4] loss: 1.384
[6,     4] loss: 1.379
[7,     4] loss: 1.366
[8,     4] loss: 1.324
[9,     4] loss: 1.260
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002868774089543304,
 'learning_rate_Hydroxylation-K': 0.000981130616687907,
 'learning_rate_Methylation-K': 0.00019346025034777095,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.019238101251090167,
 'loss_weight_Methylation-K': 0.3093883702711815,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 205775795,
 'sample_weights': [0.9044008932662225, 0.5044755373350459],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.136728965625336,
 'weight_decay_Hydroxylation-K': 3.000825711099363,
 'weight_decay_Methylation-K': 6.5581339324499615}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.393
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023084418344017713,
 'learning_rate_Hydroxylation-K': 0.0019645070338075005,
 'learning_rate_Methylation-K': 0.0008969359432301751,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.06901621749925561,
 'loss_weight_Methylation-K': 0.5619068444927768,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2141423637,
 'sample_weights': [0.019238101251090167, 0.3093883702711815],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.330664387600073,
 'weight_decay_Hydroxylation-K': 4.47652940552461,
 'weight_decay_Methylation-K': 7.813206859983172}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.388
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0004161130814610424,
 'learning_rate_Hydroxylation-K': 0.004282206835094804,
 'learning_rate_Methylation-K': 0.000504097574936411,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.059484355023160185,
 'loss_weight_Methylation-K': 0.4403619233420541,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1903674050,
 'sample_weights': [0.06901621749925561, 0.5619068444927768],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.8118523034959395,
 'weight_decay_Hydroxylation-K': 2.7939964784638667,
 'weight_decay_Methylation-K': 5.170931818730484}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.388
[3,     4] loss: 1.385
[4,     4] loss: 1.382
[5,     4] loss: 1.384
[6,     4] loss: 1.385
[7,     4] loss: 1.370
[8,     4] loss: 1.370
[9,     4] loss: 1.362
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011020066343902161,
 'learning_rate_Hydroxylation-K': 0.0022722386187795443,
 'learning_rate_Methylation-K': 0.004949208188738177,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.41893074661674484,
 'loss_weight_Methylation-K': 0.25080515327929603,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3721572855,
 'sample_weights': [0.059484355023160185, 0.4403619233420541],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5295219877880821,
 'weight_decay_Hydroxylation-K': 7.225677914709479,
 'weight_decay_Methylation-K': 0.6839054925034964}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.381
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0021782717614979713,
 'learning_rate_Hydroxylation-K': 0.0005331683686341619,
 'learning_rate_Methylation-K': 0.0022873235925250424,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7779257216209752,
 'loss_weight_Methylation-K': 0.7951116366631795,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1876634266,
 'sample_weights': [0.41893074661674484, 0.25080515327929603],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.977818993271457,
 'weight_decay_Hydroxylation-K': 8.337912094243126,
 'weight_decay_Methylation-K': 1.6595187392522146}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.392
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012744675418822598,
 'learning_rate_Hydroxylation-K': 0.005984128169249342,
 'learning_rate_Methylation-K': 0.009263466305532058,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.46655861148062905,
 'loss_weight_Methylation-K': 0.9813491094813224,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 960021533,
 'sample_weights': [0.7779257216209752, 0.7951116366631795],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.414795793665844,
 'weight_decay_Hydroxylation-K': 5.72569012076766,
 'weight_decay_Methylation-K': 3.5253169734226906}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.390
[3,     4] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018915424072875127,
 'learning_rate_Hydroxylation-K': 0.00523618454220366,
 'learning_rate_Methylation-K': 0.0016245684528459808,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3375122258329426,
 'loss_weight_Methylation-K': 0.1182257608378926,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2208032239,
 'sample_weights': [0.46655861148062905, 0.9813491094813224],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.226114342688934,
 'weight_decay_Hydroxylation-K': 2.6627114513684855,
 'weight_decay_Methylation-K': 5.504842104211832}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.389
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031839687051243874,
 'learning_rate_Hydroxylation-K': 0.009268062594764228,
 'learning_rate_Methylation-K': 0.0004584811107199839,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9099640401019128,
 'loss_weight_Methylation-K': 0.5047134254902013,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1511181427,
 'sample_weights': [0.3375122258329426, 0.1182257608378926],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.725860870958887,
 'weight_decay_Hydroxylation-K': 9.143015509355388,
 'weight_decay_Methylation-K': 8.232151449773804}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.388
[3,     4] loss: 1.380
[4,     4] loss: 1.390
[5,     4] loss: 1.390
[6,     4] loss: 1.383
[7,     4] loss: 1.376
[8,     4] loss: 1.366
[9,     4] loss: 1.337
[10,     4] loss: 1.298
[11,     4] loss: 1.213
[12,     4] loss: 1.122
[13,     4] loss: 1.046
[14,     4] loss: 1.001
[15,     4] loss: 0.960
[16,     4] loss: 1.012
[17,     4] loss: 0.907
[18,     4] loss: 0.983
[19,     4] loss: 0.950
[20,     4] loss: 0.935
[21,     4] loss: 0.881
[22,     4] loss: 0.892
[23,     4] loss: 0.841
[24,     4] loss: 0.872
[25,     4] loss: 0.851
[26,     4] loss: 0.827
[27,     4] loss: 0.888
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004089792326198258,
 'learning_rate_Hydroxylation-K': 0.002107457387812439,
 'learning_rate_Methylation-K': 0.0015967426863886876,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.36210785721219085,
 'loss_weight_Methylation-K': 0.6341047692806785,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2610349401,
 'sample_weights': [0.9099640401019128, 0.5047134254902013],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.756163049773637,
 'weight_decay_Hydroxylation-K': 9.63950030335389,
 'weight_decay_Methylation-K': 4.547488778336987}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.386
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025474403326465733,
 'learning_rate_Hydroxylation-K': 0.008430827208525503,
 'learning_rate_Methylation-K': 0.00430769540708907,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6818272273552826,
 'loss_weight_Methylation-K': 0.7783007950838039,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 971315890,
 'sample_weights': [0.36210785721219085, 0.6341047692806785],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.768791235356945,
 'weight_decay_Hydroxylation-K': 4.9634098936404785,
 'weight_decay_Methylation-K': 4.998535412591711}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.382
[3,     4] loss: 1.399
[4,     4] loss: 1.385
[5,     4] loss: 1.379
[6,     4] loss: 1.385
[7,     4] loss: 1.379
[8,     4] loss: 1.351
[9,     4] loss: 1.310
[10,     4] loss: 1.266
[11,     4] loss: 1.257
[12,     4] loss: 1.165
[13,     4] loss: 1.129
[14,     4] loss: 1.152
[15,     4] loss: 1.023
[16,     4] loss: 1.026
[17,     4] loss: 1.100
[18,     4] loss: 1.058
[19,     4] loss: 0.980
[20,     4] loss: 0.945
[21,     4] loss: 0.891
[22,     4] loss: 1.142
[23,     4] loss: 1.086
[24,     4] loss: 1.073
[25,     4] loss: 0.979
[26,     4] loss: 0.993
[27,     4] loss: 0.958
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007903295062644846,
 'learning_rate_Hydroxylation-K': 0.009547600657298956,
 'learning_rate_Methylation-K': 0.0017213053877681646,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6022833022964346,
 'loss_weight_Methylation-K': 0.8150882115642452,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 770688893,
 'sample_weights': [0.6818272273552826, 0.7783007950838039],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.985240300737816,
 'weight_decay_Hydroxylation-K': 3.1659969550368765,
 'weight_decay_Methylation-K': 6.473924022109028}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.383
[3,     4] loss: 1.385
[4,     4] loss: 1.373
[5,     4] loss: 1.377
[6,     4] loss: 1.352
[7,     4] loss: 1.345
[8,     4] loss: 1.318
[9,     4] loss: 1.254
[10,     4] loss: 1.217
[11,     4] loss: 1.192
[12,     4] loss: 1.093
[13,     4] loss: 1.076
[14,     4] loss: 1.060
[15,     4] loss: 1.018
[16,     4] loss: 1.002
[17,     4] loss: 0.980
[18,     4] loss: 0.917
[19,     4] loss: 0.888
[20,     4] loss: 0.921
[21,     4] loss: 1.006
[22,     4] loss: 0.897
[23,     4] loss: 0.972
[24,     4] loss: 0.923
[25,     4] loss: 0.891
[26,     4] loss: 0.937
[27,     4] loss: 0.961
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0055200211603986474,
 'learning_rate_Hydroxylation-K': 0.004088291456013064,
 'learning_rate_Methylation-K': 0.0022218146263399676,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2980685194759032,
 'loss_weight_Methylation-K': 0.22539237302944964,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 323694251,
 'sample_weights': [0.6022833022964346, 0.8150882115642452],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.798643945918364,
 'weight_decay_Hydroxylation-K': 8.011787753169521,
 'weight_decay_Methylation-K': 6.337267404534407}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.390
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003609332155279271,
 'learning_rate_Hydroxylation-K': 0.005030077291446147,
 'learning_rate_Methylation-K': 0.005031064215578103,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5933917542758799,
 'loss_weight_Methylation-K': 0.6705402849659072,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 970814584,
 'sample_weights': [0.2980685194759032, 0.22539237302944964],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.88759990168125,
 'weight_decay_Hydroxylation-K': 1.4225191349819117,
 'weight_decay_Methylation-K': 5.825122689612808}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.389
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005829479929547705,
 'learning_rate_Hydroxylation-K': 0.004464857606076932,
 'learning_rate_Methylation-K': 0.0008336315798035904,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.330732331507905,
 'loss_weight_Methylation-K': 0.5273611575198331,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3604984752,
 'sample_weights': [0.5933917542758799, 0.6705402849659072],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.135491456459952,
 'weight_decay_Hydroxylation-K': 4.490940999924113,
 'weight_decay_Methylation-K': 4.524887669139137}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.389
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033397063510263707,
 'learning_rate_Hydroxylation-K': 0.0027485478090251625,
 'learning_rate_Methylation-K': 0.0003142629417974012,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1688830612847133,
 'loss_weight_Methylation-K': 0.366608412277346,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1889888089,
 'sample_weights': [0.330732331507905, 0.5273611575198331],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.861360681469797,
 'weight_decay_Hydroxylation-K': 4.545729469179256,
 'weight_decay_Methylation-K': 6.463616461876786}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.378
[2,     4] loss: 1.397
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002185988694461133,
 'learning_rate_Hydroxylation-K': 0.002555620690816572,
 'learning_rate_Methylation-K': 0.002091462326610718,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3933726025953408,
 'loss_weight_Methylation-K': 0.06851170584105487,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 954784243,
 'sample_weights': [0.1688830612847133, 0.366608412277346],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.317176535572293,
 'weight_decay_Hydroxylation-K': 6.144633541828902,
 'weight_decay_Methylation-K': 4.647474865884629}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.388
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010317535198561783,
 'learning_rate_Hydroxylation-K': 0.006873270175771996,
 'learning_rate_Methylation-K': 0.009025850204089112,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24811408064659346,
 'loss_weight_Methylation-K': 0.9264194838946933,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1058804426,
 'sample_weights': [0.3933726025953408, 0.06851170584105487],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.4549050143090545,
 'weight_decay_Hydroxylation-K': 4.24055234885512,
 'weight_decay_Methylation-K': 7.323209962859993}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.380
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012979735790956868,
 'learning_rate_Hydroxylation-K': 0.0055609211681636765,
 'learning_rate_Methylation-K': 0.0020181333004384767,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.40919919607107286,
 'loss_weight_Methylation-K': 0.7589102688067527,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3917045791,
 'sample_weights': [0.24811408064659346, 0.9264194838946933],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.88483290661102,
 'weight_decay_Hydroxylation-K': 5.736394540668141,
 'weight_decay_Methylation-K': 8.007040308032634}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.385
[3,     4] loss: 1.366
[4,     4] loss: 1.351
[5,     4] loss: 1.314
[6,     4] loss: 1.264
[7,     4] loss: 1.253
[8,     4] loss: 1.200
[9,     4] loss: 1.091
[10,     4] loss: 1.138
[11,     4] loss: 1.015
[12,     4] loss: 1.084
[13,     4] loss: 1.045
[14,     4] loss: 0.990
[15,     4] loss: 0.995
[16,     4] loss: 0.942
[17,     4] loss: 0.992
[18,     4] loss: 0.946
[19,     4] loss: 0.949
[20,     4] loss: 0.850
[21,     4] loss: 0.900
[22,     4] loss: 0.838
[23,     4] loss: 0.893
[24,     4] loss: 0.903
[25,     4] loss: 0.845
[26,     4] loss: 0.810
[27,     4] loss: 0.834
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011909533325536877,
 'learning_rate_Hydroxylation-K': 0.0016056901004523976,
 'learning_rate_Methylation-K': 0.008999109538092095,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.34112588358033835,
 'loss_weight_Methylation-K': 0.755504076008883,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1484580489,
 'sample_weights': [0.40919919607107286, 0.7589102688067527],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.203807762732779,
 'weight_decay_Hydroxylation-K': 9.552846370680053,
 'weight_decay_Methylation-K': 9.224009103345804}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.380
[3,     4] loss: 1.386
[4,     4] loss: 1.381
[5,     4] loss: 1.377
[6,     4] loss: 1.372
[7,     4] loss: 1.357
[8,     4] loss: 1.337
[9,     4] loss: 1.315
[10,     4] loss: 1.270
[11,     4] loss: 1.221
[12,     4] loss: 1.179
[13,     4] loss: 1.142
[14,     4] loss: 1.047
[15,     4] loss: 1.044
[16,     4] loss: 1.039
[17,     4] loss: 1.065
[18,     4] loss: 0.953
[19,     4] loss: 0.946
[20,     4] loss: 0.946
[21,     4] loss: 0.891
[22,     4] loss: 0.909
[23,     4] loss: 0.868
[24,     4] loss: 0.902
[25,     4] loss: 0.907
[26,     4] loss: 0.836
[27,     4] loss: 0.930
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000584887320845462,
 'learning_rate_Hydroxylation-K': 0.0016878556907917132,
 'learning_rate_Methylation-K': 0.0091294559012494,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3598676914991421,
 'loss_weight_Methylation-K': 0.7782006315450265,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 531758641,
 'sample_weights': [0.34112588358033835, 0.755504076008883],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.661632886843282,
 'weight_decay_Hydroxylation-K': 9.826861678876574,
 'weight_decay_Methylation-K': 8.34782026931191}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.390
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010450078000936965,
 'learning_rate_Hydroxylation-K': 0.008171412772216436,
 'learning_rate_Methylation-K': 0.007207505042548975,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6161109250400963,
 'loss_weight_Methylation-K': 0.688395311457081,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1174123422,
 'sample_weights': [0.3598676914991421, 0.7782006315450265],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.354149323955603,
 'weight_decay_Hydroxylation-K': 0.07063980432127215,
 'weight_decay_Methylation-K': 7.097715985752767}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.378
[2,     4] loss: 1.387
[3,     4] loss: 1.383
[4,     4] loss: 1.374
[5,     4] loss: 1.355
[6,     4] loss: 1.325
[7,     4] loss: 1.278
[8,     4] loss: 1.192
[9,     4] loss: 1.175
[10,     4] loss: 1.125
[11,     4] loss: 1.178
[12,     4] loss: 1.091
[13,     4] loss: 1.105
[14,     4] loss: 1.013
[15,     4] loss: 0.971
[16,     4] loss: 0.963
[17,     4] loss: 0.913
[18,     4] loss: 0.881
[19,     4] loss: 0.860
[20,     4] loss: 0.922
[21,     4] loss: 0.858
[22,     4] loss: 0.851
[23,     4] loss: 0.828
[24,     4] loss: 0.818
[25,     4] loss: 0.825
[26,     4] loss: 0.795
[27,     4] loss: 0.852
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015168780883614687,
 'learning_rate_Hydroxylation-K': 0.0018069149152017182,
 'learning_rate_Methylation-K': 0.00811193452692415,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.39773688262748846,
 'loss_weight_Methylation-K': 0.08972956673514718,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 212160626,
 'sample_weights': [0.6161109250400963, 0.688395311457081],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.9755718526750203,
 'weight_decay_Hydroxylation-K': 5.807552510356315,
 'weight_decay_Methylation-K': 3.1246744777199886}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.390
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004254296637130588,
 'learning_rate_Hydroxylation-K': 0.004894620466926068,
 'learning_rate_Methylation-K': 0.006443490511824981,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5787445008177066,
 'loss_weight_Methylation-K': 0.7279947798903333,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2789573355,
 'sample_weights': [0.39773688262748846, 0.08972956673514718],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.082262371843263,
 'weight_decay_Hydroxylation-K': 4.033163804348348,
 'weight_decay_Methylation-K': 8.894635022630363}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.390
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014861107269060023,
 'learning_rate_Hydroxylation-K': 0.004881048737033418,
 'learning_rate_Methylation-K': 0.00011388067644125426,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8399759104762052,
 'loss_weight_Methylation-K': 0.4736014404085321,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 132059821,
 'sample_weights': [0.5787445008177066, 0.7279947798903333],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.541279497453,
 'weight_decay_Hydroxylation-K': 5.0265879268493805,
 'weight_decay_Methylation-K': 6.013664599641337}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.403
[2,     4] loss: 1.385
[3,     4] loss: 1.383
[4,     4] loss: 1.376
[5,     4] loss: 1.365
[6,     4] loss: 1.329
[7,     4] loss: 1.290
[8,     4] loss: 1.239
[9,     4] loss: 1.131
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022944049605815933,
 'learning_rate_Hydroxylation-K': 0.002853654681380451,
 'learning_rate_Methylation-K': 0.00627000360117313,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8749864675027544,
 'loss_weight_Methylation-K': 0.9199647274246008,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2977205266,
 'sample_weights': [0.8399759104762052, 0.4736014404085321],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.126776853909314,
 'weight_decay_Hydroxylation-K': 8.850115463165722,
 'weight_decay_Methylation-K': 0.5239755127172276}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.406
[2,     4] loss: 1.389
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0040155496507523975,
 'learning_rate_Hydroxylation-K': 0.0016645119500712268,
 'learning_rate_Methylation-K': 0.0019764734195689432,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.570561493692693,
 'loss_weight_Methylation-K': 0.6588624736943448,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1043419555,
 'sample_weights': [0.8749864675027544, 0.9199647274246008],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.4415485254902265,
 'weight_decay_Hydroxylation-K': 8.372413294720431,
 'weight_decay_Methylation-K': 1.533585048312442}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.387
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0039906756268689916,
 'learning_rate_Hydroxylation-K': 0.0002426596766506262,
 'learning_rate_Methylation-K': 0.0029480948555247635,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4060055878617389,
 'loss_weight_Methylation-K': 0.3147795178680961,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4176820789,
 'sample_weights': [0.570561493692693, 0.6588624736943448],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.167515670877189,
 'weight_decay_Hydroxylation-K': 6.603658648193137,
 'weight_decay_Methylation-K': 5.8138577961312095}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.378
[2,     4] loss: 1.385
[3,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008869028078028945,
 'learning_rate_Hydroxylation-K': 0.0029097465536732895,
 'learning_rate_Methylation-K': 0.009276959413694205,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.33148266249991654,
 'loss_weight_Methylation-K': 0.6614849863125921,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4004841634,
 'sample_weights': [0.4060055878617389, 0.3147795178680961],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.4075258040115335,
 'weight_decay_Hydroxylation-K': 1.3574197362569023,
 'weight_decay_Methylation-K': 6.21102718618954}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.387
[3,     4] loss: 1.393
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006095292920121629,
 'learning_rate_Hydroxylation-K': 0.006362863406053848,
 'learning_rate_Methylation-K': 0.0024090990875649076,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7437224592211155,
 'loss_weight_Methylation-K': 0.5187106039587609,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3801304018,
 'sample_weights': [0.33148266249991654, 0.6614849863125921],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.4152427043923,
 'weight_decay_Hydroxylation-K': 4.746774703751622,
 'weight_decay_Methylation-K': 7.085443551604733}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.388
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008482389581801477,
 'learning_rate_Hydroxylation-K': 0.0036768021817342135,
 'learning_rate_Methylation-K': 0.004452441196558568,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5637447054915439,
 'loss_weight_Methylation-K': 0.2945776246287155,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2565989394,
 'sample_weights': [0.7437224592211155, 0.5187106039587609],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.223465802880746,
 'weight_decay_Hydroxylation-K': 4.9003502168362925,
 'weight_decay_Methylation-K': 3.292538620908773}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.397
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005026342214602437,
 'learning_rate_Hydroxylation-K': 0.002813958966264966,
 'learning_rate_Methylation-K': 0.0007559640296215499,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22730017357661714,
 'loss_weight_Methylation-K': 0.2536990301929609,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3123983008,
 'sample_weights': [0.5637447054915439, 0.2945776246287155],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.220659998633276,
 'weight_decay_Hydroxylation-K': 5.650081260163388,
 'weight_decay_Methylation-K': 6.402606546685021}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.386
[3,     4] loss: 1.381
[4,     4] loss: 1.379
[5,     4] loss: 1.366
[6,     4] loss: 1.356
[7,     4] loss: 1.344
[8,     4] loss: 1.308
[9,     4] loss: 1.318
[10,     4] loss: 1.279
[11,     4] loss: 1.239
[12,     4] loss: 1.200
[13,     4] loss: 1.174
[14,     4] loss: 1.141
[15,     4] loss: 1.088
[16,     4] loss: 1.083
[17,     4] loss: 1.055
[18,     4] loss: 1.038
[19,     4] loss: 0.961
[20,     4] loss: 1.037
[21,     4] loss: 0.954
[22,     4] loss: 0.960
[23,     4] loss: 0.960
[24,     4] loss: 1.007
[25,     4] loss: 0.932
[26,     4] loss: 0.956
[27,     4] loss: 0.942
[28,     4] loss: 0.881
[29,     4] loss: 0.927
[30,     4] loss: 0.911
[31,     4] loss: 0.918
[32,     4] loss: 0.850
[33,     4] loss: 0.831
[34,     4] loss: 0.856
[35,     4] loss: 0.846
[36,     4] loss: 0.819
[37,     4] loss: 0.812
[38,     4] loss: 0.784
[39,     4] loss: 0.776
[40,     4] loss: 0.770
[41,     4] loss: 0.749
[42,     4] loss: 0.760
[43,     4] loss: 0.757
[44,     4] loss: 0.743
[45,     4] loss: 0.743
[46,     4] loss: 0.777
[47,     4] loss: 0.759
[48,     4] loss: 0.772
[49,     4] loss: 0.787
[50,     4] loss: 0.759
[51,     4] loss: 0.752
[52,     4] loss: 0.807
[53,     4] loss: 0.782
[54,     4] loss: 0.765
[55,     4] loss: 0.766
[56,     4] loss: 0.771
[57,     4] loss: 0.777
[58,     4] loss: 0.748
[59,     4] loss: 0.737
[60,     4] loss: 0.772
[61,     4] loss: 0.755
[62,     4] loss: 0.753
[63,     4] loss: 0.745
[64,     4] loss: 0.729
Early stopping applied (best metric=0.43477460741996765)
Finished Training
Total time taken: 32.24657917022705
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.385
[3,     4] loss: 1.387
[4,     4] loss: 1.383
[5,     4] loss: 1.381
[6,     4] loss: 1.382
[7,     4] loss: 1.372
[8,     4] loss: 1.362
[9,     4] loss: 1.342
[10,     4] loss: 1.343
[11,     4] loss: 1.299
[12,     4] loss: 1.266
[13,     4] loss: 1.241
[14,     4] loss: 1.229
[15,     4] loss: 1.168
[16,     4] loss: 1.134
[17,     4] loss: 1.083
[18,     4] loss: 1.062
[19,     4] loss: 1.078
[20,     4] loss: 1.005
[21,     4] loss: 1.004
[22,     4] loss: 0.951
[23,     4] loss: 0.947
[24,     4] loss: 0.926
[25,     4] loss: 0.921
[26,     4] loss: 0.879
[27,     4] loss: 0.848
[28,     4] loss: 0.865
[29,     4] loss: 0.850
[30,     4] loss: 0.853
[31,     4] loss: 0.928
[32,     4] loss: 0.833
[33,     4] loss: 0.879
[34,     4] loss: 0.833
[35,     4] loss: 0.816
[36,     4] loss: 0.854
[37,     4] loss: 0.778
[38,     4] loss: 0.816
[39,     4] loss: 0.798
[40,     4] loss: 0.829
[41,     4] loss: 0.798
[42,     4] loss: 0.786
[43,     4] loss: 0.808
[44,     4] loss: 0.778
[45,     4] loss: 0.778
[46,     4] loss: 0.750
[47,     4] loss: 0.775
[48,     4] loss: 0.759
[49,     4] loss: 0.764
[50,     4] loss: 0.749
[51,     4] loss: 0.773
[52,     4] loss: 0.768
[53,     4] loss: 0.744
[54,     4] loss: 0.734
[55,     4] loss: 0.761
[56,     4] loss: 0.765
[57,     4] loss: 0.719
[58,     4] loss: 0.760
[59,     4] loss: 0.722
[60,     4] loss: 0.739
[61,     4] loss: 0.754
Early stopping applied (best metric=0.5229904055595398)
Finished Training
Total time taken: 30.50149130821228
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.380
[2,     4] loss: 1.387
[3,     4] loss: 1.387
[4,     4] loss: 1.383
[5,     4] loss: 1.379
[6,     4] loss: 1.378
[7,     4] loss: 1.376
[8,     4] loss: 1.369
[9,     4] loss: 1.356
[10,     4] loss: 1.335
[11,     4] loss: 1.321
[12,     4] loss: 1.286
[13,     4] loss: 1.252
[14,     4] loss: 1.240
[15,     4] loss: 1.195
[16,     4] loss: 1.119
[17,     4] loss: 1.112
[18,     4] loss: 1.079
[19,     4] loss: 1.057
[20,     4] loss: 1.028
[21,     4] loss: 0.962
[22,     4] loss: 0.903
[23,     4] loss: 1.032
[24,     4] loss: 0.933
[25,     4] loss: 0.868
[26,     4] loss: 0.925
[27,     4] loss: 0.901
[28,     4] loss: 0.946
[29,     4] loss: 0.960
[30,     4] loss: 0.831
[31,     4] loss: 0.831
[32,     4] loss: 0.863
[33,     4] loss: 0.834
[34,     4] loss: 0.804
[35,     4] loss: 0.835
[36,     4] loss: 0.791
[37,     4] loss: 0.778
[38,     4] loss: 0.789
[39,     4] loss: 0.849
[40,     4] loss: 0.825
[41,     4] loss: 0.810
[42,     4] loss: 0.842
[43,     4] loss: 0.847
[44,     4] loss: 0.806
[45,     4] loss: 0.797
[46,     4] loss: 0.778
[47,     4] loss: 0.754
[48,     4] loss: 0.756
[49,     4] loss: 0.749
[50,     4] loss: 0.745
[51,     4] loss: 0.735
[52,     4] loss: 0.740
[53,     4] loss: 0.732
[54,     4] loss: 0.728
[55,     4] loss: 0.733
[56,     4] loss: 0.742
[57,     4] loss: 0.744
[58,     4] loss: 0.729
[59,     4] loss: 0.738
[60,     4] loss: 0.739
[61,     4] loss: 0.780
[62,     4] loss: 0.737
[63,     4] loss: 0.739
[64,     4] loss: 0.739
[65,     4] loss: 0.735
[66,     4] loss: 0.740
[67,     4] loss: 0.742
[68,     4] loss: 0.737
[69,     4] loss: 0.731
[70,     4] loss: 0.728
[71,     4] loss: 0.752
Early stopping applied (best metric=0.38154715299606323)
Finished Training
Total time taken: 35.61874175071716
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.384
[3,     4] loss: 1.385
[4,     4] loss: 1.379
[5,     4] loss: 1.378
[6,     4] loss: 1.369
[7,     4] loss: 1.361
[8,     4] loss: 1.341
[9,     4] loss: 1.315
[10,     4] loss: 1.300
[11,     4] loss: 1.267
[12,     4] loss: 1.265
[13,     4] loss: 1.222
[14,     4] loss: 1.135
[15,     4] loss: 1.108
[16,     4] loss: 1.074
[17,     4] loss: 1.015
[18,     4] loss: 1.002
[19,     4] loss: 1.001
[20,     4] loss: 0.967
[21,     4] loss: 0.937
[22,     4] loss: 0.897
[23,     4] loss: 0.909
[24,     4] loss: 0.874
[25,     4] loss: 0.866
[26,     4] loss: 0.868
[27,     4] loss: 0.856
[28,     4] loss: 0.888
[29,     4] loss: 0.889
[30,     4] loss: 0.843
[31,     4] loss: 0.883
[32,     4] loss: 0.837
[33,     4] loss: 0.788
[34,     4] loss: 0.812
[35,     4] loss: 0.773
[36,     4] loss: 0.768
[37,     4] loss: 0.823
[38,     4] loss: 0.821
[39,     4] loss: 0.826
[40,     4] loss: 0.856
[41,     4] loss: 0.824
[42,     4] loss: 0.827
[43,     4] loss: 0.808
[44,     4] loss: 0.787
[45,     4] loss: 0.789
[46,     4] loss: 0.796
[47,     4] loss: 0.798
[48,     4] loss: 0.758
[49,     4] loss: 0.763
[50,     4] loss: 0.786
[51,     4] loss: 0.803
[52,     4] loss: 0.800
[53,     4] loss: 0.790
[54,     4] loss: 0.808
[55,     4] loss: 0.834
[56,     4] loss: 0.817
[57,     4] loss: 0.793
[58,     4] loss: 0.771
[59,     4] loss: 0.784
[60,     4] loss: 0.776
[61,     4] loss: 0.746
[62,     4] loss: 0.753
[63,     4] loss: 0.728
[64,     4] loss: 0.729
Early stopping applied (best metric=0.49635377526283264)
Finished Training
Total time taken: 32.47659254074097
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.387
[2,     4] loss: 1.384
[3,     4] loss: 1.384
[4,     4] loss: 1.379
[5,     4] loss: 1.389
[6,     4] loss: 1.371
[7,     4] loss: 1.374
[8,     4] loss: 1.372
[9,     4] loss: 1.364
[10,     4] loss: 1.342
[11,     4] loss: 1.317
[12,     4] loss: 1.286
[13,     4] loss: 1.280
[14,     4] loss: 1.204
[15,     4] loss: 1.181
[16,     4] loss: 1.112
[17,     4] loss: 1.062
[18,     4] loss: 1.047
[19,     4] loss: 1.010
[20,     4] loss: 1.003
[21,     4] loss: 0.925
[22,     4] loss: 0.897
[23,     4] loss: 0.951
[24,     4] loss: 0.866
[25,     4] loss: 0.869
[26,     4] loss: 0.843
[27,     4] loss: 0.922
[28,     4] loss: 0.924
[29,     4] loss: 0.856
[30,     4] loss: 0.833
[31,     4] loss: 0.851
[32,     4] loss: 0.822
[33,     4] loss: 0.793
[34,     4] loss: 0.770
[35,     4] loss: 0.788
[36,     4] loss: 0.759
[37,     4] loss: 0.792
[38,     4] loss: 0.772
[39,     4] loss: 0.755
[40,     4] loss: 0.777
[41,     4] loss: 0.762
[42,     4] loss: 0.774
[43,     4] loss: 0.770
[44,     4] loss: 0.779
[45,     4] loss: 0.824
[46,     4] loss: 0.741
[47,     4] loss: 0.785
[48,     4] loss: 0.768
[49,     4] loss: 0.773
[50,     4] loss: 0.748
[51,     4] loss: 0.736
[52,     4] loss: 0.753
[53,     4] loss: 0.790
[54,     4] loss: 0.758
[55,     4] loss: 0.784
[56,     4] loss: 0.751
[57,     4] loss: 0.740
[58,     4] loss: 0.769
[59,     4] loss: 0.754
[60,     4] loss: 0.755
[61,     4] loss: 0.741
[62,     4] loss: 0.728
[63,     4] loss: 0.733
[64,     4] loss: 0.726
[65,     4] loss: 0.752
[66,     4] loss: 0.736
[67,     4] loss: 0.732
[68,     4] loss: 0.738
[69,     4] loss: 0.727
[70,     4] loss: 0.743
[71,     4] loss: 0.753
[72,     4] loss: 0.731
[73,     4] loss: 0.742
Early stopping applied (best metric=0.2734023332595825)
Finished Training
Total time taken: 37.19881749153137
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.386
[4,     4] loss: 1.380
[5,     4] loss: 1.382
[6,     4] loss: 1.375
[7,     4] loss: 1.367
[8,     4] loss: 1.355
[9,     4] loss: 1.336
[10,     4] loss: 1.303
[11,     4] loss: 1.289
[12,     4] loss: 1.256
[13,     4] loss: 1.201
[14,     4] loss: 1.155
[15,     4] loss: 1.120
[16,     4] loss: 1.050
[17,     4] loss: 1.040
[18,     4] loss: 0.998
[19,     4] loss: 1.004
[20,     4] loss: 0.957
[21,     4] loss: 0.902
[22,     4] loss: 0.850
[23,     4] loss: 0.860
[24,     4] loss: 0.846
[25,     4] loss: 0.857
[26,     4] loss: 0.899
[27,     4] loss: 0.863
[28,     4] loss: 0.829
[29,     4] loss: 0.783
[30,     4] loss: 0.849
[31,     4] loss: 0.856
[32,     4] loss: 0.857
[33,     4] loss: 0.841
[34,     4] loss: 0.807
[35,     4] loss: 0.797
[36,     4] loss: 0.786
[37,     4] loss: 0.765
[38,     4] loss: 0.769
[39,     4] loss: 0.774
[40,     4] loss: 0.738
[41,     4] loss: 0.765
[42,     4] loss: 0.779
[43,     4] loss: 0.735
[44,     4] loss: 0.729
[45,     4] loss: 0.746
[46,     4] loss: 0.742
[47,     4] loss: 0.738
[48,     4] loss: 0.765
[49,     4] loss: 0.727
[50,     4] loss: 0.728
[51,     4] loss: 0.717
[52,     4] loss: 0.733
[53,     4] loss: 0.729
[54,     4] loss: 0.722
[55,     4] loss: 0.716
[56,     4] loss: 0.731
[57,     4] loss: 0.727
[58,     4] loss: 0.728
[59,     4] loss: 0.766
[60,     4] loss: 0.734
[61,     4] loss: 0.784
[62,     4] loss: 0.718
Early stopping applied (best metric=0.5039220452308655)
Finished Training
Total time taken: 31.45953631401062
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.384
[5,     4] loss: 1.384
[6,     4] loss: 1.379
[7,     4] loss: 1.380
[8,     4] loss: 1.370
[9,     4] loss: 1.363
[10,     4] loss: 1.338
[11,     4] loss: 1.315
[12,     4] loss: 1.294
[13,     4] loss: 1.248
[14,     4] loss: 1.196
[15,     4] loss: 1.198
[16,     4] loss: 1.101
[17,     4] loss: 1.141
[18,     4] loss: 1.105
[19,     4] loss: 1.047
[20,     4] loss: 1.007
[21,     4] loss: 0.952
[22,     4] loss: 0.970
[23,     4] loss: 0.966
[24,     4] loss: 0.968
[25,     4] loss: 0.897
[26,     4] loss: 0.858
[27,     4] loss: 0.853
[28,     4] loss: 0.869
[29,     4] loss: 0.798
[30,     4] loss: 0.824
[31,     4] loss: 0.786
[32,     4] loss: 0.755
[33,     4] loss: 0.774
[34,     4] loss: 0.762
[35,     4] loss: 0.749
[36,     4] loss: 0.714
[37,     4] loss: 0.714
[38,     4] loss: 0.746
[39,     4] loss: 0.831
[40,     4] loss: 0.746
[41,     4] loss: 0.767
[42,     4] loss: 0.731
[43,     4] loss: 0.787
[44,     4] loss: 0.760
[45,     4] loss: 0.719
[46,     4] loss: 0.766
[47,     4] loss: 0.709
[48,     4] loss: 0.710
[49,     4] loss: 0.702
[50,     4] loss: 0.692
[51,     4] loss: 0.687
[52,     4] loss: 0.683
[53,     4] loss: 0.684
[54,     4] loss: 0.700
[55,     4] loss: 0.672
[56,     4] loss: 0.675
[57,     4] loss: 0.666
[58,     4] loss: 0.687
[59,     4] loss: 0.675
[60,     4] loss: 0.664
[61,     4] loss: 0.678
[62,     4] loss: 0.690
[63,     4] loss: 0.694
[64,     4] loss: 0.670
[65,     4] loss: 0.695
[66,     4] loss: 0.673
[67,     4] loss: 0.663
[68,     4] loss: 0.665
[69,     4] loss: 0.671
[70,     4] loss: 0.671
[71,     4] loss: 0.677
[72,     4] loss: 0.656
Early stopping applied (best metric=0.4284268319606781)
Finished Training
Total time taken: 36.46078443527222
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.405
[2,     4] loss: 1.382
[3,     4] loss: 1.387
[4,     4] loss: 1.382
[5,     4] loss: 1.376
[6,     4] loss: 1.373
[7,     4] loss: 1.360
[8,     4] loss: 1.350
[9,     4] loss: 1.319
[10,     4] loss: 1.295
[11,     4] loss: 1.287
[12,     4] loss: 1.261
[13,     4] loss: 1.209
[14,     4] loss: 1.220
[15,     4] loss: 1.155
[16,     4] loss: 1.129
[17,     4] loss: 1.092
[18,     4] loss: 1.092
[19,     4] loss: 1.027
[20,     4] loss: 0.986
[21,     4] loss: 1.003
[22,     4] loss: 0.926
[23,     4] loss: 0.937
[24,     4] loss: 0.936
[25,     4] loss: 0.928
[26,     4] loss: 0.870
[27,     4] loss: 0.894
[28,     4] loss: 0.808
[29,     4] loss: 0.854
[30,     4] loss: 0.815
[31,     4] loss: 0.822
[32,     4] loss: 0.821
[33,     4] loss: 0.794
[34,     4] loss: 0.830
[35,     4] loss: 0.802
[36,     4] loss: 0.808
[37,     4] loss: 0.793
[38,     4] loss: 0.812
[39,     4] loss: 0.864
[40,     4] loss: 0.893
[41,     4] loss: 0.763
[42,     4] loss: 0.782
[43,     4] loss: 0.784
[44,     4] loss: 0.782
[45,     4] loss: 0.775
[46,     4] loss: 0.752
[47,     4] loss: 0.755
[48,     4] loss: 0.757
[49,     4] loss: 0.751
[50,     4] loss: 0.820
[51,     4] loss: 0.751
[52,     4] loss: 0.772
[53,     4] loss: 0.765
[54,     4] loss: 0.745
[55,     4] loss: 0.748
[56,     4] loss: 0.749
[57,     4] loss: 0.768
[58,     4] loss: 0.737
[59,     4] loss: 0.745
[60,     4] loss: 0.764
[61,     4] loss: 0.740
[62,     4] loss: 0.766
Early stopping applied (best metric=0.5195279121398926)
Finished Training
Total time taken: 31.683549642562866
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.383
[5,     4] loss: 1.381
[6,     4] loss: 1.383
[7,     4] loss: 1.371
[8,     4] loss: 1.361
[9,     4] loss: 1.345
[10,     4] loss: 1.320
[11,     4] loss: 1.307
[12,     4] loss: 1.277
[13,     4] loss: 1.227
[14,     4] loss: 1.156
[15,     4] loss: 1.145
[16,     4] loss: 1.131
[17,     4] loss: 1.079
[18,     4] loss: 1.030
[19,     4] loss: 1.097
[20,     4] loss: 1.005
[21,     4] loss: 1.034
[22,     4] loss: 0.989
[23,     4] loss: 1.013
[24,     4] loss: 1.007
[25,     4] loss: 0.941
[26,     4] loss: 0.931
[27,     4] loss: 0.895
[28,     4] loss: 0.914
[29,     4] loss: 0.879
[30,     4] loss: 0.884
[31,     4] loss: 0.899
[32,     4] loss: 0.818
[33,     4] loss: 0.841
[34,     4] loss: 0.813
[35,     4] loss: 0.812
[36,     4] loss: 0.808
[37,     4] loss: 0.796
[38,     4] loss: 0.806
[39,     4] loss: 0.796
[40,     4] loss: 0.787
[41,     4] loss: 0.777
[42,     4] loss: 0.781
[43,     4] loss: 0.751
[44,     4] loss: 0.767
[45,     4] loss: 0.773
[46,     4] loss: 0.786
[47,     4] loss: 0.820
[48,     4] loss: 0.822
[49,     4] loss: 0.791
[50,     4] loss: 0.770
[51,     4] loss: 0.766
[52,     4] loss: 0.757
[53,     4] loss: 0.743
[54,     4] loss: 0.750
[55,     4] loss: 0.751
[56,     4] loss: 0.738
[57,     4] loss: 0.745
[58,     4] loss: 0.739
[59,     4] loss: 0.742
[60,     4] loss: 0.722
[61,     4] loss: 0.757
[62,     4] loss: 0.727
Early stopping applied (best metric=0.507696807384491)
Finished Training
Total time taken: 31.45553946495056
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.389
[2,     4] loss: 1.386
[3,     4] loss: 1.387
[4,     4] loss: 1.382
[5,     4] loss: 1.381
[6,     4] loss: 1.381
[7,     4] loss: 1.371
[8,     4] loss: 1.354
[9,     4] loss: 1.349
[10,     4] loss: 1.329
[11,     4] loss: 1.299
[12,     4] loss: 1.287
[13,     4] loss: 1.264
[14,     4] loss: 1.252
[15,     4] loss: 1.250
[16,     4] loss: 1.155
[17,     4] loss: 1.154
[18,     4] loss: 1.123
[19,     4] loss: 1.082
[20,     4] loss: 1.080
[21,     4] loss: 1.085
[22,     4] loss: 1.009
[23,     4] loss: 0.945
[24,     4] loss: 0.952
[25,     4] loss: 0.909
[26,     4] loss: 0.938
[27,     4] loss: 0.926
[28,     4] loss: 0.901
[29,     4] loss: 0.901
[30,     4] loss: 0.880
[31,     4] loss: 0.855
[32,     4] loss: 0.835
[33,     4] loss: 0.816
[34,     4] loss: 0.797
[35,     4] loss: 0.786
[36,     4] loss: 0.796
[37,     4] loss: 0.840
[38,     4] loss: 0.823
[39,     4] loss: 0.764
[40,     4] loss: 0.786
[41,     4] loss: 0.827
[42,     4] loss: 0.781
[43,     4] loss: 0.806
[44,     4] loss: 0.788
[45,     4] loss: 0.830
[46,     4] loss: 0.791
[47,     4] loss: 0.789
[48,     4] loss: 0.757
[49,     4] loss: 0.771
[50,     4] loss: 0.766
[51,     4] loss: 0.776
[52,     4] loss: 0.767
[53,     4] loss: 0.755
[54,     4] loss: 0.737
[55,     4] loss: 0.759
[56,     4] loss: 0.761
[57,     4] loss: 0.746
[58,     4] loss: 0.734
[59,     4] loss: 0.759
[60,     4] loss: 0.745
[61,     4] loss: 0.738
[62,     4] loss: 0.751
[63,     4] loss: 0.731
[64,     4] loss: 0.745
[65,     4] loss: 0.729
[66,     4] loss: 0.739
[67,     4] loss: 0.734
[68,     4] loss: 0.729
[69,     4] loss: 0.717
[70,     4] loss: 0.728
[71,     4] loss: 0.735
[72,     4] loss: 0.752
Early stopping applied (best metric=0.37043875455856323)
Finished Training
Total time taken: 36.20176911354065
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.384
[3,     4] loss: 1.388
[4,     4] loss: 1.384
[5,     4] loss: 1.381
[6,     4] loss: 1.373
[7,     4] loss: 1.369
[8,     4] loss: 1.354
[9,     4] loss: 1.343
[10,     4] loss: 1.315
[11,     4] loss: 1.312
[12,     4] loss: 1.264
[13,     4] loss: 1.229
[14,     4] loss: 1.218
[15,     4] loss: 1.155
[16,     4] loss: 1.132
[17,     4] loss: 1.113
[18,     4] loss: 1.066
[19,     4] loss: 1.075
[20,     4] loss: 1.035
[21,     4] loss: 1.001
[22,     4] loss: 0.978
[23,     4] loss: 0.924
[24,     4] loss: 0.927
[25,     4] loss: 0.898
[26,     4] loss: 0.859
[27,     4] loss: 0.881
[28,     4] loss: 0.884
[29,     4] loss: 0.817
[30,     4] loss: 0.838
[31,     4] loss: 0.865
[32,     4] loss: 0.885
[33,     4] loss: 0.844
[34,     4] loss: 0.777
[35,     4] loss: 0.834
[36,     4] loss: 0.867
[37,     4] loss: 0.799
[38,     4] loss: 0.763
[39,     4] loss: 0.771
[40,     4] loss: 0.751
[41,     4] loss: 0.783
[42,     4] loss: 0.796
[43,     4] loss: 0.765
[44,     4] loss: 0.774
[45,     4] loss: 0.788
[46,     4] loss: 0.803
[47,     4] loss: 0.782
[48,     4] loss: 0.801
[49,     4] loss: 0.783
[50,     4] loss: 0.754
[51,     4] loss: 0.735
[52,     4] loss: 0.733
[53,     4] loss: 0.726
[54,     4] loss: 0.724
[55,     4] loss: 0.718
[56,     4] loss: 0.732
[57,     4] loss: 0.723
[58,     4] loss: 0.718
[59,     4] loss: 0.725
[60,     4] loss: 0.725
[61,     4] loss: 0.703
[62,     4] loss: 0.713
[63,     4] loss: 0.713
[64,     4] loss: 0.734
[65,     4] loss: 0.718
[66,     4] loss: 0.715
[67,     4] loss: 0.741
[68,     4] loss: 0.763
Early stopping applied (best metric=0.40754181146621704)
Finished Training
Total time taken: 34.20967245101929
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.390
[3,     4] loss: 1.380
[4,     4] loss: 1.387
[5,     4] loss: 1.381
[6,     4] loss: 1.378
[7,     4] loss: 1.372
[8,     4] loss: 1.366
[9,     4] loss: 1.356
[10,     4] loss: 1.343
[11,     4] loss: 1.306
[12,     4] loss: 1.291
[13,     4] loss: 1.257
[14,     4] loss: 1.260
[15,     4] loss: 1.182
[16,     4] loss: 1.150
[17,     4] loss: 1.116
[18,     4] loss: 1.095
[19,     4] loss: 1.093
[20,     4] loss: 0.969
[21,     4] loss: 0.952
[22,     4] loss: 0.963
[23,     4] loss: 0.924
[24,     4] loss: 0.952
[25,     4] loss: 0.897
[26,     4] loss: 0.874
[27,     4] loss: 0.902
[28,     4] loss: 0.892
[29,     4] loss: 0.842
[30,     4] loss: 0.871
[31,     4] loss: 0.884
[32,     4] loss: 0.819
[33,     4] loss: 0.780
[34,     4] loss: 0.804
[35,     4] loss: 0.808
[36,     4] loss: 0.825
[37,     4] loss: 0.819
[38,     4] loss: 0.808
[39,     4] loss: 0.779
[40,     4] loss: 0.813
[41,     4] loss: 0.792
[42,     4] loss: 0.770
[43,     4] loss: 0.784
[44,     4] loss: 0.745
[45,     4] loss: 0.735
[46,     4] loss: 0.744
[47,     4] loss: 0.731
[48,     4] loss: 0.722
[49,     4] loss: 0.717
[50,     4] loss: 0.713
[51,     4] loss: 0.748
[52,     4] loss: 0.712
[53,     4] loss: 0.734
[54,     4] loss: 0.728
[55,     4] loss: 0.720
[56,     4] loss: 0.700
[57,     4] loss: 0.695
[58,     4] loss: 0.694
[59,     4] loss: 0.714
[60,     4] loss: 0.688
[61,     4] loss: 0.700
[62,     4] loss: 0.687
[63,     4] loss: 0.686
[64,     4] loss: 0.737
[65,     4] loss: 0.734
[66,     4] loss: 0.735
[67,     4] loss: 0.721
Early stopping applied (best metric=0.3906182646751404)
Finished Training
Total time taken: 34.023664712905884
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.383
[3,     4] loss: 1.382
[4,     4] loss: 1.380
[5,     4] loss: 1.370
[6,     4] loss: 1.367
[7,     4] loss: 1.350
[8,     4] loss: 1.337
[9,     4] loss: 1.293
[10,     4] loss: 1.297
[11,     4] loss: 1.271
[12,     4] loss: 1.247
[13,     4] loss: 1.195
[14,     4] loss: 1.190
[15,     4] loss: 1.186
[16,     4] loss: 1.087
[17,     4] loss: 1.101
[18,     4] loss: 1.073
[19,     4] loss: 1.072
[20,     4] loss: 0.991
[21,     4] loss: 1.071
[22,     4] loss: 0.981
[23,     4] loss: 0.973
[24,     4] loss: 0.905
[25,     4] loss: 0.925
[26,     4] loss: 0.887
[27,     4] loss: 0.917
[28,     4] loss: 0.863
[29,     4] loss: 0.861
[30,     4] loss: 0.836
[31,     4] loss: 0.856
[32,     4] loss: 0.841
[33,     4] loss: 0.828
[34,     4] loss: 0.855
[35,     4] loss: 0.790
[36,     4] loss: 0.799
[37,     4] loss: 0.798
[38,     4] loss: 0.774
[39,     4] loss: 0.797
[40,     4] loss: 0.774
[41,     4] loss: 0.772
[42,     4] loss: 0.759
[43,     4] loss: 0.795
[44,     4] loss: 0.759
[45,     4] loss: 0.793
[46,     4] loss: 0.836
[47,     4] loss: 0.794
[48,     4] loss: 0.746
[49,     4] loss: 0.754
[50,     4] loss: 0.784
[51,     4] loss: 0.792
[52,     4] loss: 0.826
[53,     4] loss: 0.778
[54,     4] loss: 0.750
[55,     4] loss: 0.781
[56,     4] loss: 0.752
[57,     4] loss: 0.748
[58,     4] loss: 0.758
[59,     4] loss: 0.767
[60,     4] loss: 0.742
[61,     4] loss: 0.776
[62,     4] loss: 0.734
[63,     4] loss: 0.739
[64,     4] loss: 0.738
[65,     4] loss: 0.734
[66,     4] loss: 0.764
[67,     4] loss: 0.752
[68,     4] loss: 0.747
[69,     4] loss: 0.739
[70,     4] loss: 0.726
[71,     4] loss: 0.750
[72,     4] loss: 0.762
[73,     4] loss: 0.779
[74,     4] loss: 0.810
[75,     4] loss: 0.753
[76,     4] loss: 0.775
[77,     4] loss: 0.778
[78,     4] loss: 0.747
[79,     4] loss: 0.726
[80,     4] loss: 0.738
[81,     4] loss: 0.729
[82,     4] loss: 0.718
[83,     4] loss: 0.731
Early stopping applied (best metric=0.2638810873031616)
Finished Training
Total time taken: 41.82504749298096
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.390
[3,     4] loss: 1.386
[4,     4] loss: 1.380
[5,     4] loss: 1.381
[6,     4] loss: 1.378
[7,     4] loss: 1.367
[8,     4] loss: 1.354
[9,     4] loss: 1.341
[10,     4] loss: 1.300
[11,     4] loss: 1.252
[12,     4] loss: 1.256
[13,     4] loss: 1.146
[14,     4] loss: 1.148
[15,     4] loss: 1.116
[16,     4] loss: 1.073
[17,     4] loss: 1.020
[18,     4] loss: 0.959
[19,     4] loss: 0.954
[20,     4] loss: 0.989
[21,     4] loss: 0.919
[22,     4] loss: 0.888
[23,     4] loss: 0.844
[24,     4] loss: 0.842
[25,     4] loss: 0.816
[26,     4] loss: 0.826
[27,     4] loss: 0.791
[28,     4] loss: 0.842
[29,     4] loss: 0.842
[30,     4] loss: 0.781
[31,     4] loss: 0.811
[32,     4] loss: 0.784
[33,     4] loss: 0.786
[34,     4] loss: 0.769
[35,     4] loss: 0.776
[36,     4] loss: 0.764
[37,     4] loss: 0.740
[38,     4] loss: 0.733
[39,     4] loss: 0.731
[40,     4] loss: 0.759
[41,     4] loss: 0.732
[42,     4] loss: 0.724
[43,     4] loss: 0.725
[44,     4] loss: 0.740
[45,     4] loss: 0.735
[46,     4] loss: 0.752
[47,     4] loss: 0.739
[48,     4] loss: 0.725
[49,     4] loss: 0.790
[50,     4] loss: 0.758
[51,     4] loss: 0.802
[52,     4] loss: 0.749
[53,     4] loss: 0.736
[54,     4] loss: 0.737
[55,     4] loss: 0.733
[56,     4] loss: 0.739
[57,     4] loss: 0.729
[58,     4] loss: 0.726
[59,     4] loss: 0.726
[60,     4] loss: 0.726
[61,     4] loss: 0.738
[62,     4] loss: 0.738
Early stopping applied (best metric=0.42747369408607483)
Finished Training
Total time taken: 31.38553285598755
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.393
[2,     4] loss: 1.384
[3,     4] loss: 1.384
[4,     4] loss: 1.381
[5,     4] loss: 1.376
[6,     4] loss: 1.374
[7,     4] loss: 1.364
[8,     4] loss: 1.358
[9,     4] loss: 1.347
[10,     4] loss: 1.326
[11,     4] loss: 1.288
[12,     4] loss: 1.273
[13,     4] loss: 1.236
[14,     4] loss: 1.209
[15,     4] loss: 1.187
[16,     4] loss: 1.130
[17,     4] loss: 1.085
[18,     4] loss: 1.132
[19,     4] loss: 1.071
[20,     4] loss: 1.012
[21,     4] loss: 0.996
[22,     4] loss: 0.947
[23,     4] loss: 0.971
[24,     4] loss: 0.938
[25,     4] loss: 0.942
[26,     4] loss: 0.917
[27,     4] loss: 0.896
[28,     4] loss: 0.875
[29,     4] loss: 0.869
[30,     4] loss: 0.877
[31,     4] loss: 0.908
[32,     4] loss: 0.901
[33,     4] loss: 0.830
[34,     4] loss: 0.807
[35,     4] loss: 0.796
[36,     4] loss: 0.804
[37,     4] loss: 0.777
[38,     4] loss: 0.801
[39,     4] loss: 0.788
[40,     4] loss: 0.788
[41,     4] loss: 0.796
[42,     4] loss: 0.777
[43,     4] loss: 0.846
[44,     4] loss: 0.780
[45,     4] loss: 0.743
[46,     4] loss: 0.775
[47,     4] loss: 0.803
[48,     4] loss: 0.791
[49,     4] loss: 0.806
[50,     4] loss: 0.816
[51,     4] loss: 0.762
[52,     4] loss: 0.757
[53,     4] loss: 0.741
[54,     4] loss: 0.745
[55,     4] loss: 0.736
[56,     4] loss: 0.729
[57,     4] loss: 0.742
[58,     4] loss: 0.739
[59,     4] loss: 0.732
[60,     4] loss: 0.725
[61,     4] loss: 0.748
[62,     4] loss: 0.763
[63,     4] loss: 0.741
[64,     4] loss: 0.755
[65,     4] loss: 0.739
[66,     4] loss: 0.749
[67,     4] loss: 0.760
[68,     4] loss: 0.746
[69,     4] loss: 0.746
[70,     4] loss: 0.751
[71,     4] loss: 0.742
[72,     4] loss: 0.738
[73,     4] loss: 0.755
[74,     4] loss: 0.763
[75,     4] loss: 0.728
[76,     4] loss: 0.744
[77,     4] loss: 0.750
[78,     4] loss: 0.733
[79,     4] loss: 0.729
[80,     4] loss: 0.737
[81,     4] loss: 0.745
[82,     4] loss: 0.758
[83,     4] loss: 0.820
[84,     4] loss: 0.783
[85,     4] loss: 0.759
[86,     4] loss: 0.734
[87,     4] loss: 0.733
[88,     4] loss: 0.746
[89,     4] loss: 0.739
[90,     4] loss: 0.733
[91,     4] loss: 0.735
[92,     4] loss: 0.734
[93,     4] loss: 0.720
[94,     4] loss: 0.727
[95,     4] loss: 0.721
[96,     4] loss: 0.721
[97,     4] loss: 0.728
[98,     4] loss: 0.726
[99,     4] loss: 0.742
[100,     4] loss: 0.731
[101,     4] loss: 0.723
[102,     4] loss: 0.727
[103,     4] loss: 0.734
[104,     4] loss: 0.732
[105,     4] loss: 0.719
[106,     4] loss: 0.741
[107,     4] loss: 0.742
[108,     4] loss: 0.740
[109,     4] loss: 0.720
[110,     4] loss: 0.735
[111,     4] loss: 0.732
[112,     4] loss: 0.719
[113,     4] loss: 0.741
[114,     4] loss: 0.736
[115,     4] loss: 0.721
[116,     4] loss: 0.719
Early stopping applied (best metric=0.40514838695526123)
Finished Training
Total time taken: 58.481857776641846
{'Hydroxylation-K Validation Accuracy': 0.8066193853427895, 'Hydroxylation-K Validation Sensitivity': 0.717037037037037, 'Hydroxylation-K Validation Specificity': 0.8298245614035088, 'Hydroxylation-K Validation Precision': 0.5467401051160642, 'Hydroxylation-K AUC ROC': 0.8200779727095516, 'Hydroxylation-K AUC PR': 0.6197347217374889, 'Hydroxylation-K MCC': 0.5040568404698627, 'Hydroxylation-K F1': 0.6084902306637623, 'Validation Loss (Hydroxylation-K)': 0.4222495913505554, 'Methylation-K Validation Accuracy': 0.827522486567835, 'Methylation-K Validation Sensitivity': 0.12351229377377965, 'Methylation-K Validation Specificity': 0.9038740685853827, 'Methylation-K Validation Precision': 0.12588858771948422, 'Methylation-K AUC ROC': 0.5483180718504791, 'Methylation-K AUC PR': 0.11376076407733277, 'Methylation-K MCC': 0.02835167092181897, 'Methylation-K F1': 0.11784903896549044, 'Validation Loss (Methylation-K)': 0.9236086388429006, 'Validation Loss (total)': 1.3458582401275634, 'TimeToTrain': 35.681945101420084}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035404647496063086,
 'learning_rate_Hydroxylation-K': 0.0002754189592445433,
 'learning_rate_Methylation-K': 0.00492033427638021,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.27768821093565954,
 'loss_weight_Methylation-K': 0.37751031154982706,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 202622594,
 'sample_weights': [0.22730017357661714, 0.2536990301929609],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.5232323975602071,
 'weight_decay_Hydroxylation-K': 7.576664628436278,
 'weight_decay_Methylation-K': 6.389118288583087}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.388
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004229130569158684,
 'learning_rate_Hydroxylation-K': 0.005538528479157628,
 'learning_rate_Methylation-K': 0.005391106734527544,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2752128069822796,
 'loss_weight_Methylation-K': 0.4627339296810531,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2536651500,
 'sample_weights': [0.27768821093565954, 0.37751031154982706],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.43990633872041585,
 'weight_decay_Hydroxylation-K': 2.769670146531675,
 'weight_decay_Methylation-K': 6.220501488052991}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.403
[2,     4] loss: 1.388
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005611161403208189,
 'learning_rate_Hydroxylation-K': 0.00095587125616403,
 'learning_rate_Methylation-K': 0.004814776925919506,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7344704324769525,
 'loss_weight_Methylation-K': 0.6688942750844272,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2666524551,
 'sample_weights': [0.2752128069822796, 0.4627339296810531],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.711627267094007,
 'weight_decay_Hydroxylation-K': 8.206378853610165,
 'weight_decay_Methylation-K': 4.475611522316917}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.388
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0035514779057823262,
 'learning_rate_Hydroxylation-K': 0.008068114597394347,
 'learning_rate_Methylation-K': 0.009595243249383465,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7025308231672298,
 'loss_weight_Methylation-K': 0.4409222556531388,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1318730715,
 'sample_weights': [0.7344704324769525, 0.6688942750844272],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.534200575621613,
 'weight_decay_Hydroxylation-K': 3.2611708559764363,
 'weight_decay_Methylation-K': 9.836527151840002}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.399
[3,     4] loss: 1.385
[4,     4] loss: 1.382
[5,     4] loss: 1.384
[6,     4] loss: 1.382
[7,     4] loss: 1.356
[8,     4] loss: 1.290
[9,     4] loss: 1.195
[10,     4] loss: 1.173
[11,     4] loss: 1.226
[12,     4] loss: 1.227
[13,     4] loss: 1.217
[14,     4] loss: 1.207
[15,     4] loss: 1.156
[16,     4] loss: 1.110
[17,     4] loss: 1.019
[18,     4] loss: 1.076
[19,     4] loss: 1.010
[20,     4] loss: 1.013
[21,     4] loss: 0.945
[22,     4] loss: 0.896
[23,     4] loss: 0.922
[24,     4] loss: 0.966
[25,     4] loss: 1.034
[26,     4] loss: 1.054
[27,     4] loss: 0.983
[28,     4] loss: 0.973
[29,     4] loss: 0.945
[30,     4] loss: 0.857
[31,     4] loss: 0.833
[32,     4] loss: 0.912
[33,     4] loss: 1.083
[34,     4] loss: 1.058
[35,     4] loss: 1.016
[36,     4] loss: 1.061
[37,     4] loss: 0.966
[38,     4] loss: 0.962
[39,     4] loss: 0.923
[40,     4] loss: 0.858
[41,     4] loss: 0.828
[42,     4] loss: 0.823
[43,     4] loss: 0.878
[44,     4] loss: 1.163
[45,     4] loss: 1.194
[46,     4] loss: 1.232
[47,     4] loss: 1.194
[48,     4] loss: 1.086
[49,     4] loss: 1.041
[50,     4] loss: 0.997
[51,     4] loss: 0.912
[52,     4] loss: 0.879
[53,     4] loss: 0.864
[54,     4] loss: 1.017
[55,     4] loss: 1.042
[56,     4] loss: 0.992
[57,     4] loss: 0.975
[58,     4] loss: 0.902
[59,     4] loss: 0.840
[60,     4] loss: 0.804
[61,     4] loss: 0.879
[62,     4] loss: 0.968
[63,     4] loss: 0.916
[64,     4] loss: 0.864
[65,     4] loss: 0.804
[66,     4] loss: 0.838
[67,     4] loss: 0.848
[68,     4] loss: 0.883
[69,     4] loss: 0.857
[70,     4] loss: 0.884
[71,     4] loss: 0.910
[72,     4] loss: 0.935
[73,     4] loss: 0.947
[74,     4] loss: 0.866
[75,     4] loss: 0.792
[76,     4] loss: 0.843
[77,     4] loss: 0.865
[78,     4] loss: 0.850
[79,     4] loss: 0.840
[80,     4] loss: 1.082
[81,     4] loss: 1.099
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015550623001639547,
 'learning_rate_Hydroxylation-K': 0.006974830207272025,
 'learning_rate_Methylation-K': 0.00834691730606129,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4364028900803643,
 'loss_weight_Methylation-K': 0.802393834649062,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1960021094,
 'sample_weights': [0.7025308231672298, 0.4409222556531388],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.884303771472519,
 'weight_decay_Hydroxylation-K': 5.8150464305382785,
 'weight_decay_Methylation-K': 6.979384857480233}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.379
[3,     4] loss: 1.378
[4,     4] loss: 1.351
[5,     4] loss: 1.320
[6,     4] loss: 1.264
[7,     4] loss: 1.187
[8,     4] loss: 1.187
[9,     4] loss: 1.148
[10,     4] loss: 1.081
[11,     4] loss: 1.060
[12,     4] loss: 1.049
[13,     4] loss: 0.966
[14,     4] loss: 0.955
[15,     4] loss: 0.936
[16,     4] loss: 0.981
[17,     4] loss: 0.894
[18,     4] loss: 0.938
[19,     4] loss: 0.905
[20,     4] loss: 0.904
[21,     4] loss: 0.853
[22,     4] loss: 0.943
[23,     4] loss: 0.960
[24,     4] loss: 0.896
[25,     4] loss: 0.869
[26,     4] loss: 0.840
[27,     4] loss: 0.845
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0003469555493522551,
 'learning_rate_Hydroxylation-K': 0.002624323240518794,
 'learning_rate_Methylation-K': 0.0006705212663973695,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1881774128446641,
 'loss_weight_Methylation-K': 0.3532997925581707,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4148023062,
 'sample_weights': [0.4364028900803643, 0.802393834649062],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.2691935461209205,
 'weight_decay_Hydroxylation-K': 8.919493309962418,
 'weight_decay_Methylation-K': 5.193100809021162}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.385
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.008764709539982983,
 'learning_rate_Hydroxylation-K': 0.008007797877065268,
 'learning_rate_Methylation-K': 0.006501785055339154,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.06343016762834419,
 'loss_weight_Methylation-K': 0.06570241496379392,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 826209133,
 'sample_weights': [0.1881774128446641, 0.3532997925581707],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.498297754822516,
 'weight_decay_Hydroxylation-K': 5.760731549886356,
 'weight_decay_Methylation-K': 8.582085829095458}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.376
[2,     4] loss: 1.385
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006242076010727939,
 'learning_rate_Hydroxylation-K': 0.004092250655999767,
 'learning_rate_Methylation-K': 0.00428404039770655,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2181201162542452,
 'loss_weight_Methylation-K': 0.3295530412641867,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4266195003,
 'sample_weights': [0.06343016762834419, 0.06570241496379392],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.311946252092662,
 'weight_decay_Hydroxylation-K': 6.5581042030582894,
 'weight_decay_Methylation-K': 4.794338505427437}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.401
[2,     4] loss: 1.388
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010752785968183099,
 'learning_rate_Hydroxylation-K': 0.00046277825888720254,
 'learning_rate_Methylation-K': 0.0013292847687242967,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.28566828993526877,
 'loss_weight_Methylation-K': 0.15292538654705692,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 77949613,
 'sample_weights': [0.2181201162542452, 0.3295530412641867],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.868504107543198,
 'weight_decay_Hydroxylation-K': 7.37112672683609,
 'weight_decay_Methylation-K': 8.878653740148208}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.383
[3,     4] loss: 1.384
[4,     4] loss: 1.381
[5,     4] loss: 1.372
[6,     4] loss: 1.361
[7,     4] loss: 1.352
[8,     4] loss: 1.333
[9,     4] loss: 1.288
[10,     4] loss: 1.275
[11,     4] loss: 1.183
[12,     4] loss: 1.181
[13,     4] loss: 1.134
[14,     4] loss: 1.193
[15,     4] loss: 1.072
[16,     4] loss: 1.030
[17,     4] loss: 0.987
[18,     4] loss: 0.938
[19,     4] loss: 0.937
[20,     4] loss: 0.930
[21,     4] loss: 0.911
[22,     4] loss: 1.001
[23,     4] loss: 1.008
[24,     4] loss: 0.926
[25,     4] loss: 0.923
[26,     4] loss: 0.902
[27,     4] loss: 0.919
[28,     4] loss: 0.945
[29,     4] loss: 0.834
[30,     4] loss: 0.858
[31,     4] loss: 0.833
[32,     4] loss: 0.877
[33,     4] loss: 0.860
[34,     4] loss: 0.885
[35,     4] loss: 0.952
[36,     4] loss: 0.914
[37,     4] loss: 0.887
[38,     4] loss: 0.845
[39,     4] loss: 0.842
[40,     4] loss: 0.822
[41,     4] loss: 0.812
[42,     4] loss: 0.825
[43,     4] loss: 0.777
[44,     4] loss: 0.761
[45,     4] loss: 0.755
[46,     4] loss: 0.762
[47,     4] loss: 0.769
[48,     4] loss: 0.771
[49,     4] loss: 0.775
[50,     4] loss: 0.801
[51,     4] loss: 0.756
[52,     4] loss: 0.756
[53,     4] loss: 0.766
[54,     4] loss: 0.767
[55,     4] loss: 0.757
[56,     4] loss: 0.751
[57,     4] loss: 0.767
[58,     4] loss: 0.751
[59,     4] loss: 0.769
[60,     4] loss: 0.767
[61,     4] loss: 0.772
[62,     4] loss: 0.770
[63,     4] loss: 0.749
[64,     4] loss: 0.937
[65,     4] loss: 0.848
[66,     4] loss: 0.818
[67,     4] loss: 0.792
[68,     4] loss: 0.761
[69,     4] loss: 0.764
[70,     4] loss: 0.784
[71,     4] loss: 0.747
[72,     4] loss: 0.756
[73,     4] loss: 0.752
[74,     4] loss: 0.758
[75,     4] loss: 0.768
[76,     4] loss: 0.794
[77,     4] loss: 0.777
[78,     4] loss: 0.760
[79,     4] loss: 0.749
[80,     4] loss: 0.754
[81,     4] loss: 0.763
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006868700202038806,
 'learning_rate_Hydroxylation-K': 0.009069458075054777,
 'learning_rate_Methylation-K': 0.0024095789675717964,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.19950816096616097,
 'loss_weight_Methylation-K': 0.5777365550522368,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 197457304,
 'sample_weights': [0.28566828993526877, 0.15292538654705692],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.690707997925543,
 'weight_decay_Hydroxylation-K': 9.005527475429592,
 'weight_decay_Methylation-K': 3.2308353051831356}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.384
[3,     4] loss: 1.384
[4,     4] loss: 1.391
[5,     4] loss: 1.384
[6,     4] loss: 1.379
[7,     4] loss: 1.380
[8,     4] loss: 1.360
[9,     4] loss: 1.343
[10,     4] loss: 1.326
[11,     4] loss: 1.306
[12,     4] loss: 1.278
[13,     4] loss: 1.214
[14,     4] loss: 1.205
[15,     4] loss: 1.136
[16,     4] loss: 1.042
[17,     4] loss: 1.058
[18,     4] loss: 1.051
[19,     4] loss: 1.021
[20,     4] loss: 1.034
[21,     4] loss: 0.989
[22,     4] loss: 0.972
[23,     4] loss: 0.915
[24,     4] loss: 0.887
[25,     4] loss: 0.913
[26,     4] loss: 0.899
[27,     4] loss: 0.870
[28,     4] loss: 0.870
[29,     4] loss: 0.831
[30,     4] loss: 0.861
[31,     4] loss: 0.844
[32,     4] loss: 0.867
[33,     4] loss: 0.850
[34,     4] loss: 0.844
[35,     4] loss: 0.840
[36,     4] loss: 0.797
[37,     4] loss: 0.807
[38,     4] loss: 0.828
[39,     4] loss: 0.832
[40,     4] loss: 0.799
[41,     4] loss: 0.762
[42,     4] loss: 0.777
[43,     4] loss: 0.770
[44,     4] loss: 0.785
[45,     4] loss: 0.763
[46,     4] loss: 0.761
[47,     4] loss: 0.789
[48,     4] loss: 0.827
[49,     4] loss: 0.795
[50,     4] loss: 0.798
[51,     4] loss: 0.771
[52,     4] loss: 0.764
[53,     4] loss: 0.775
[54,     4] loss: 0.771
[55,     4] loss: 0.785
[56,     4] loss: 0.810
[57,     4] loss: 0.780
[58,     4] loss: 0.800
[59,     4] loss: 0.758
[60,     4] loss: 0.749
[61,     4] loss: 0.756
[62,     4] loss: 0.750
[63,     4] loss: 0.742
[64,     4] loss: 0.762
[65,     4] loss: 0.745
Early stopping applied (best metric=0.31501299142837524)
Finished Training
Total time taken: 32.69460105895996
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.391
[3,     4] loss: 1.386
[4,     4] loss: 1.385
[5,     4] loss: 1.385
[6,     4] loss: 1.386
[7,     4] loss: 1.383
[8,     4] loss: 1.382
[9,     4] loss: 1.381
[10,     4] loss: 1.373
[11,     4] loss: 1.359
[12,     4] loss: 1.347
[13,     4] loss: 1.306
[14,     4] loss: 1.279
[15,     4] loss: 1.213
[16,     4] loss: 1.187
[17,     4] loss: 1.103
[18,     4] loss: 1.106
[19,     4] loss: 1.005
[20,     4] loss: 0.963
[21,     4] loss: 0.983
[22,     4] loss: 0.886
[23,     4] loss: 0.990
[24,     4] loss: 1.083
[25,     4] loss: 0.922
[26,     4] loss: 0.939
[27,     4] loss: 0.956
[28,     4] loss: 0.925
[29,     4] loss: 0.888
[30,     4] loss: 0.911
[31,     4] loss: 0.883
[32,     4] loss: 0.853
[33,     4] loss: 0.829
[34,     4] loss: 0.832
[35,     4] loss: 0.833
[36,     4] loss: 0.816
[37,     4] loss: 0.793
[38,     4] loss: 0.841
[39,     4] loss: 0.820
[40,     4] loss: 0.856
[41,     4] loss: 0.858
[42,     4] loss: 0.815
[43,     4] loss: 0.821
[44,     4] loss: 0.782
[45,     4] loss: 0.800
[46,     4] loss: 0.788
[47,     4] loss: 0.772
[48,     4] loss: 0.762
[49,     4] loss: 0.778
[50,     4] loss: 0.779
[51,     4] loss: 0.788
[52,     4] loss: 0.779
[53,     4] loss: 0.767
[54,     4] loss: 0.790
[55,     4] loss: 0.768
[56,     4] loss: 0.807
[57,     4] loss: 0.789
[58,     4] loss: 0.790
[59,     4] loss: 0.799
[60,     4] loss: 0.774
[61,     4] loss: 0.763
[62,     4] loss: 0.776
[63,     4] loss: 0.803
[64,     4] loss: 0.752
Early stopping applied (best metric=0.5131637454032898)
Finished Training
Total time taken: 32.60359239578247
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.385
[3,     4] loss: 1.382
[4,     4] loss: 1.375
[5,     4] loss: 1.365
[6,     4] loss: 1.348
[7,     4] loss: 1.321
[8,     4] loss: 1.301
[9,     4] loss: 1.273
[10,     4] loss: 1.198
[11,     4] loss: 1.230
[12,     4] loss: 1.148
[13,     4] loss: 1.111
[14,     4] loss: 1.048
[15,     4] loss: 1.041
[16,     4] loss: 1.042
[17,     4] loss: 0.992
[18,     4] loss: 0.999
[19,     4] loss: 0.944
[20,     4] loss: 0.945
[21,     4] loss: 0.840
[22,     4] loss: 0.931
[23,     4] loss: 0.879
[24,     4] loss: 0.899
[25,     4] loss: 0.860
[26,     4] loss: 0.884
[27,     4] loss: 0.841
[28,     4] loss: 0.820
[29,     4] loss: 0.797
[30,     4] loss: 0.768
[31,     4] loss: 0.792
[32,     4] loss: 0.760
[33,     4] loss: 0.756
[34,     4] loss: 0.768
[35,     4] loss: 0.758
[36,     4] loss: 0.779
[37,     4] loss: 0.802
[38,     4] loss: 0.780
[39,     4] loss: 0.776
[40,     4] loss: 0.774
[41,     4] loss: 0.791
[42,     4] loss: 0.812
[43,     4] loss: 0.751
[44,     4] loss: 0.766
[45,     4] loss: 0.801
[46,     4] loss: 0.809
[47,     4] loss: 0.821
[48,     4] loss: 0.773
[49,     4] loss: 0.790
[50,     4] loss: 0.756
[51,     4] loss: 0.770
[52,     4] loss: 0.775
[53,     4] loss: 0.769
[54,     4] loss: 0.760
[55,     4] loss: 0.760
[56,     4] loss: 0.750
[57,     4] loss: 0.743
[58,     4] loss: 0.752
[59,     4] loss: 0.750
[60,     4] loss: 0.780
Early stopping applied (best metric=0.5099450945854187)
Finished Training
Total time taken: 30.123472213745117
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.389
[3,     4] loss: 1.384
[4,     4] loss: 1.377
[5,     4] loss: 1.374
[6,     4] loss: 1.363
[7,     4] loss: 1.349
[8,     4] loss: 1.322
[9,     4] loss: 1.289
[10,     4] loss: 1.263
[11,     4] loss: 1.250
[12,     4] loss: 1.180
[13,     4] loss: 1.173
[14,     4] loss: 1.108
[15,     4] loss: 1.051
[16,     4] loss: 0.997
[17,     4] loss: 0.972
[18,     4] loss: 0.996
[19,     4] loss: 0.896
[20,     4] loss: 0.976
[21,     4] loss: 1.003
[22,     4] loss: 0.890
[23,     4] loss: 0.871
[24,     4] loss: 0.868
[25,     4] loss: 0.942
[26,     4] loss: 0.974
[27,     4] loss: 0.939
[28,     4] loss: 0.960
[29,     4] loss: 0.889
[30,     4] loss: 0.884
[31,     4] loss: 0.863
[32,     4] loss: 0.868
[33,     4] loss: 0.872
[34,     4] loss: 0.821
[35,     4] loss: 0.808
[36,     4] loss: 0.785
[37,     4] loss: 0.800
[38,     4] loss: 0.793
[39,     4] loss: 0.798
[40,     4] loss: 0.811
[41,     4] loss: 0.778
[42,     4] loss: 0.774
[43,     4] loss: 0.773
[44,     4] loss: 0.793
[45,     4] loss: 0.771
[46,     4] loss: 0.779
[47,     4] loss: 0.799
[48,     4] loss: 0.809
[49,     4] loss: 0.822
[50,     4] loss: 0.818
[51,     4] loss: 0.823
[52,     4] loss: 0.765
[53,     4] loss: 0.783
[54,     4] loss: 0.782
[55,     4] loss: 0.778
[56,     4] loss: 0.775
[57,     4] loss: 0.779
[58,     4] loss: 0.756
[59,     4] loss: 0.765
[60,     4] loss: 0.768
Early stopping applied (best metric=0.38318875432014465)
Finished Training
Total time taken: 30.34248375892639
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.380
[2,     4] loss: 1.397
[3,     4] loss: 1.397
[4,     4] loss: 1.392
[5,     4] loss: 1.388
[6,     4] loss: 1.387
[7,     4] loss: 1.383
[8,     4] loss: 1.382
[9,     4] loss: 1.382
[10,     4] loss: 1.377
[11,     4] loss: 1.368
[12,     4] loss: 1.360
[13,     4] loss: 1.337
[14,     4] loss: 1.320
[15,     4] loss: 1.271
[16,     4] loss: 1.256
[17,     4] loss: 1.180
[18,     4] loss: 1.096
[19,     4] loss: 1.047
[20,     4] loss: 1.040
[21,     4] loss: 0.997
[22,     4] loss: 0.995
[23,     4] loss: 0.939
[24,     4] loss: 0.972
[25,     4] loss: 0.946
[26,     4] loss: 0.907
[27,     4] loss: 0.854
[28,     4] loss: 0.897
[29,     4] loss: 0.883
[30,     4] loss: 0.821
[31,     4] loss: 0.839
[32,     4] loss: 0.800
[33,     4] loss: 0.900
[34,     4] loss: 0.831
[35,     4] loss: 0.810
[36,     4] loss: 0.801
[37,     4] loss: 0.827
[38,     4] loss: 0.830
[39,     4] loss: 0.807
[40,     4] loss: 0.810
[41,     4] loss: 0.793
[42,     4] loss: 0.790
[43,     4] loss: 0.793
[44,     4] loss: 0.835
[45,     4] loss: 0.795
[46,     4] loss: 0.764
[47,     4] loss: 0.753
[48,     4] loss: 0.810
[49,     4] loss: 0.756
[50,     4] loss: 0.763
[51,     4] loss: 0.796
[52,     4] loss: 0.757
[53,     4] loss: 0.767
[54,     4] loss: 0.748
[55,     4] loss: 0.763
[56,     4] loss: 0.765
[57,     4] loss: 0.744
[58,     4] loss: 0.769
[59,     4] loss: 0.753
[60,     4] loss: 0.769
[61,     4] loss: 0.745
[62,     4] loss: 0.750
[63,     4] loss: 0.747
[64,     4] loss: 0.742
[65,     4] loss: 0.743
[66,     4] loss: 0.756
[67,     4] loss: 0.746
Early stopping applied (best metric=0.41273099184036255)
Finished Training
Total time taken: 34.13667011260986
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.382
[3,     4] loss: 1.378
[4,     4] loss: 1.374
[5,     4] loss: 1.356
[6,     4] loss: 1.337
[7,     4] loss: 1.315
[8,     4] loss: 1.280
[9,     4] loss: 1.241
[10,     4] loss: 1.199
[11,     4] loss: 1.165
[12,     4] loss: 1.142
[13,     4] loss: 1.046
[14,     4] loss: 1.013
[15,     4] loss: 0.979
[16,     4] loss: 0.980
[17,     4] loss: 0.982
[18,     4] loss: 1.030
[19,     4] loss: 0.906
[20,     4] loss: 0.959
[21,     4] loss: 0.945
[22,     4] loss: 0.911
[23,     4] loss: 0.933
[24,     4] loss: 0.911
[25,     4] loss: 0.973
[26,     4] loss: 0.883
[27,     4] loss: 0.885
[28,     4] loss: 0.856
[29,     4] loss: 0.842
[30,     4] loss: 0.869
[31,     4] loss: 0.839
[32,     4] loss: 0.821
[33,     4] loss: 0.843
[34,     4] loss: 0.806
[35,     4] loss: 0.843
[36,     4] loss: 0.844
[37,     4] loss: 0.827
[38,     4] loss: 0.802
[39,     4] loss: 0.831
[40,     4] loss: 0.844
[41,     4] loss: 0.836
[42,     4] loss: 0.863
[43,     4] loss: 0.841
[44,     4] loss: 0.799
[45,     4] loss: 0.826
[46,     4] loss: 0.823
[47,     4] loss: 0.764
[48,     4] loss: 0.789
[49,     4] loss: 0.789
[50,     4] loss: 0.805
[51,     4] loss: 0.777
[52,     4] loss: 0.767
[53,     4] loss: 0.796
[54,     4] loss: 0.793
[55,     4] loss: 0.769
[56,     4] loss: 0.798
[57,     4] loss: 0.766
[58,     4] loss: 0.761
[59,     4] loss: 0.764
[60,     4] loss: 0.785
[61,     4] loss: 0.749
[62,     4] loss: 0.763
[63,     4] loss: 0.783
[64,     4] loss: 0.776
[65,     4] loss: 0.804
[66,     4] loss: 0.776
[67,     4] loss: 0.770
[68,     4] loss: 0.762
[69,     4] loss: 0.764
[70,     4] loss: 0.747
[71,     4] loss: 0.732
[72,     4] loss: 0.749
[73,     4] loss: 0.750
[74,     4] loss: 0.822
[75,     4] loss: 0.853
[76,     4] loss: 0.851
[77,     4] loss: 0.801
[78,     4] loss: 0.819
[79,     4] loss: 0.798
[80,     4] loss: 0.805
[81,     4] loss: 0.814
[82,     4] loss: 0.834
[83,     4] loss: 0.824
[84,     4] loss: 0.803
[85,     4] loss: 0.779
[86,     4] loss: 0.793
[87,     4] loss: 0.772
[88,     4] loss: 0.766
[89,     4] loss: 0.776
[90,     4] loss: 0.795
[91,     4] loss: 0.774
[92,     4] loss: 0.761
[93,     4] loss: 0.744
[94,     4] loss: 0.751
[95,     4] loss: 0.758
[96,     4] loss: 0.738
[97,     4] loss: 0.753
[98,     4] loss: 0.751
[99,     4] loss: 0.742
[100,     4] loss: 0.783
[101,     4] loss: 0.768
[102,     4] loss: 0.753
[103,     4] loss: 0.791
[104,     4] loss: 0.748
[105,     4] loss: 0.756
[106,     4] loss: 0.763
[107,     4] loss: 0.772
[108,     4] loss: 0.751
[109,     4] loss: 0.755
[110,     4] loss: 0.765
[111,     4] loss: 0.767
[112,     4] loss: 0.753
[113,     4] loss: 0.738
[114,     4] loss: 0.756
[115,     4] loss: 0.778
[116,     4] loss: 0.737
[117,     4] loss: 0.743
[118,     4] loss: 0.728
[119,     4] loss: 0.752
[120,     4] loss: 0.732
[121,     4] loss: 0.732
[122,     4] loss: 0.746
[123,     4] loss: 0.731
[124,     4] loss: 0.742
[125,     4] loss: 0.734
[126,     4] loss: 0.770
[127,     4] loss: 0.756
[128,     4] loss: 0.746
[129,     4] loss: 0.770
[130,     4] loss: 0.731
[131,     4] loss: 0.740
[132,     4] loss: 0.725
[133,     4] loss: 0.728
[134,     4] loss: 0.754
[135,     4] loss: 0.743
[136,     4] loss: 0.751
[137,     4] loss: 0.748
[138,     4] loss: 0.763
[139,     4] loss: 0.815
[140,     4] loss: 0.802
[141,     4] loss: 0.765
[142,     4] loss: 0.767
[143,     4] loss: 0.775
[144,     4] loss: 0.752
[145,     4] loss: 0.772
[146,     4] loss: 0.769
[147,     4] loss: 0.774
[148,     4] loss: 0.759
[149,     4] loss: 0.762
[150,     4] loss: 0.743
[151,     4] loss: 0.754
[152,     4] loss: 0.752
[153,     4] loss: 0.740
[154,     4] loss: 0.746
[155,     4] loss: 0.735
[156,     4] loss: 0.768
[157,     4] loss: 0.767
[158,     4] loss: 0.746
[159,     4] loss: 0.742
[160,     4] loss: 0.759
[161,     4] loss: 0.859
Early stopping applied (best metric=0.3292946219444275)
Finished Training
Total time taken: 81.03696322441101
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.387
[3,     4] loss: 1.383
[4,     4] loss: 1.377
[5,     4] loss: 1.386
[6,     4] loss: 1.371
[7,     4] loss: 1.360
[8,     4] loss: 1.336
[9,     4] loss: 1.332
[10,     4] loss: 1.283
[11,     4] loss: 1.237
[12,     4] loss: 1.218
[13,     4] loss: 1.143
[14,     4] loss: 1.109
[15,     4] loss: 1.130
[16,     4] loss: 1.045
[17,     4] loss: 0.972
[18,     4] loss: 1.010
[19,     4] loss: 0.918
[20,     4] loss: 0.985
[21,     4] loss: 0.961
[22,     4] loss: 1.000
[23,     4] loss: 0.939
[24,     4] loss: 0.865
[25,     4] loss: 0.855
[26,     4] loss: 0.840
[27,     4] loss: 0.847
[28,     4] loss: 0.829
[29,     4] loss: 0.860
[30,     4] loss: 0.802
[31,     4] loss: 0.828
[32,     4] loss: 0.807
[33,     4] loss: 0.773
[34,     4] loss: 0.774
[35,     4] loss: 0.786
[36,     4] loss: 0.775
[37,     4] loss: 0.796
[38,     4] loss: 0.767
[39,     4] loss: 0.753
[40,     4] loss: 0.777
[41,     4] loss: 0.781
[42,     4] loss: 0.744
[43,     4] loss: 0.752
[44,     4] loss: 0.768
[45,     4] loss: 0.766
[46,     4] loss: 0.773
[47,     4] loss: 0.853
[48,     4] loss: 0.782
[49,     4] loss: 0.786
[50,     4] loss: 0.781
[51,     4] loss: 0.766
[52,     4] loss: 0.762
[53,     4] loss: 0.756
[54,     4] loss: 0.753
[55,     4] loss: 0.736
[56,     4] loss: 0.741
[57,     4] loss: 0.731
[58,     4] loss: 0.719
[59,     4] loss: 0.718
Early stopping applied (best metric=0.5120859146118164)
Finished Training
Total time taken: 29.502445220947266
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.386
[3,     4] loss: 1.382
[4,     4] loss: 1.380
[5,     4] loss: 1.385
[6,     4] loss: 1.373
[7,     4] loss: 1.371
[8,     4] loss: 1.350
[9,     4] loss: 1.346
[10,     4] loss: 1.306
[11,     4] loss: 1.277
[12,     4] loss: 1.245
[13,     4] loss: 1.174
[14,     4] loss: 1.189
[15,     4] loss: 1.097
[16,     4] loss: 1.070
[17,     4] loss: 1.104
[18,     4] loss: 1.026
[19,     4] loss: 0.996
[20,     4] loss: 1.033
[21,     4] loss: 1.000
[22,     4] loss: 0.982
[23,     4] loss: 0.927
[24,     4] loss: 0.943
[25,     4] loss: 0.966
[26,     4] loss: 0.882
[27,     4] loss: 0.940
[28,     4] loss: 0.859
[29,     4] loss: 0.847
[30,     4] loss: 0.854
[31,     4] loss: 0.881
[32,     4] loss: 0.836
[33,     4] loss: 0.847
[34,     4] loss: 0.841
[35,     4] loss: 0.844
[36,     4] loss: 0.835
[37,     4] loss: 0.817
[38,     4] loss: 0.773
[39,     4] loss: 0.813
[40,     4] loss: 0.799
[41,     4] loss: 0.857
[42,     4] loss: 0.859
[43,     4] loss: 0.782
[44,     4] loss: 0.778
[45,     4] loss: 0.777
[46,     4] loss: 0.780
[47,     4] loss: 0.814
[48,     4] loss: 0.756
[49,     4] loss: 0.792
[50,     4] loss: 0.785
[51,     4] loss: 0.861
[52,     4] loss: 0.857
[53,     4] loss: 0.814
[54,     4] loss: 0.810
[55,     4] loss: 0.776
[56,     4] loss: 0.761
[57,     4] loss: 0.762
[58,     4] loss: 0.766
[59,     4] loss: 0.774
[60,     4] loss: 0.774
[61,     4] loss: 0.789
[62,     4] loss: 0.791
[63,     4] loss: 0.773
[64,     4] loss: 0.795
[65,     4] loss: 0.775
[66,     4] loss: 0.780
[67,     4] loss: 0.779
[68,     4] loss: 0.750
[69,     4] loss: 0.750
[70,     4] loss: 0.753
[71,     4] loss: 0.758
[72,     4] loss: 0.738
[73,     4] loss: 0.766
[74,     4] loss: 0.763
[75,     4] loss: 0.772
[76,     4] loss: 0.758
[77,     4] loss: 0.758
[78,     4] loss: 0.758
[79,     4] loss: 0.748
[80,     4] loss: 0.770
[81,     4] loss: 0.756
[82,     4] loss: 0.782
[83,     4] loss: 0.777
[84,     4] loss: 0.806
[85,     4] loss: 0.857
[86,     4] loss: 0.824
[87,     4] loss: 0.783
[88,     4] loss: 0.785
[89,     4] loss: 0.761
[90,     4] loss: 0.784
[91,     4] loss: 0.788
[92,     4] loss: 0.773
Early stopping applied (best metric=0.2342301607131958)
Finished Training
Total time taken: 46.34726572036743
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.390
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.382
[6,     4] loss: 1.375
[7,     4] loss: 1.368
[8,     4] loss: 1.349
[9,     4] loss: 1.323
[10,     4] loss: 1.317
[11,     4] loss: 1.282
[12,     4] loss: 1.240
[13,     4] loss: 1.152
[14,     4] loss: 1.159
[15,     4] loss: 1.147
[16,     4] loss: 1.070
[17,     4] loss: 1.071
[18,     4] loss: 1.056
[19,     4] loss: 1.051
[20,     4] loss: 0.957
[21,     4] loss: 0.955
[22,     4] loss: 0.990
[23,     4] loss: 0.990
[24,     4] loss: 1.000
[25,     4] loss: 0.956
[26,     4] loss: 0.935
[27,     4] loss: 0.878
[28,     4] loss: 0.898
[29,     4] loss: 0.907
[30,     4] loss: 0.856
[31,     4] loss: 0.843
[32,     4] loss: 0.882
[33,     4] loss: 0.909
[34,     4] loss: 0.866
[35,     4] loss: 0.827
[36,     4] loss: 0.856
[37,     4] loss: 0.800
[38,     4] loss: 0.801
[39,     4] loss: 0.767
[40,     4] loss: 0.800
[41,     4] loss: 0.803
[42,     4] loss: 0.815
[43,     4] loss: 0.809
[44,     4] loss: 0.803
[45,     4] loss: 0.839
[46,     4] loss: 0.816
[47,     4] loss: 0.798
[48,     4] loss: 0.800
[49,     4] loss: 0.824
[50,     4] loss: 0.792
[51,     4] loss: 0.774
[52,     4] loss: 0.762
[53,     4] loss: 0.768
[54,     4] loss: 0.741
[55,     4] loss: 0.776
[56,     4] loss: 0.757
[57,     4] loss: 0.763
[58,     4] loss: 0.755
[59,     4] loss: 0.740
[60,     4] loss: 0.747
[61,     4] loss: 0.760
[62,     4] loss: 0.755
[63,     4] loss: 0.771
[64,     4] loss: 0.786
[65,     4] loss: 0.791
[66,     4] loss: 0.786
[67,     4] loss: 0.766
[68,     4] loss: 0.768
[69,     4] loss: 0.757
[70,     4] loss: 0.793
[71,     4] loss: 0.788
[72,     4] loss: 0.779
[73,     4] loss: 0.787
[74,     4] loss: 0.804
[75,     4] loss: 0.775
[76,     4] loss: 0.771
[77,     4] loss: 0.766
[78,     4] loss: 0.758
[79,     4] loss: 0.762
[80,     4] loss: 0.747
[81,     4] loss: 0.754
[82,     4] loss: 0.742
[83,     4] loss: 0.737
[84,     4] loss: 0.750
[85,     4] loss: 0.744
[86,     4] loss: 0.761
Early stopping applied (best metric=0.290526807308197)
Finished Training
Total time taken: 43.65913510322571
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.392
[2,     4] loss: 1.386
[3,     4] loss: 1.382
[4,     4] loss: 1.384
[5,     4] loss: 1.377
[6,     4] loss: 1.375
[7,     4] loss: 1.365
[8,     4] loss: 1.344
[9,     4] loss: 1.320
[10,     4] loss: 1.293
[11,     4] loss: 1.251
[12,     4] loss: 1.216
[13,     4] loss: 1.166
[14,     4] loss: 1.099
[15,     4] loss: 1.033
[16,     4] loss: 1.035
[17,     4] loss: 1.056
[18,     4] loss: 0.950
[19,     4] loss: 0.950
[20,     4] loss: 1.102
[21,     4] loss: 0.963
[22,     4] loss: 0.925
[23,     4] loss: 0.890
[24,     4] loss: 0.899
[25,     4] loss: 0.879
[26,     4] loss: 0.823
[27,     4] loss: 0.822
[28,     4] loss: 0.861
[29,     4] loss: 0.902
[30,     4] loss: 0.871
[31,     4] loss: 0.805
[32,     4] loss: 0.857
[33,     4] loss: 0.818
[34,     4] loss: 0.845
[35,     4] loss: 0.867
[36,     4] loss: 0.810
[37,     4] loss: 0.896
[38,     4] loss: 0.821
[39,     4] loss: 0.817
[40,     4] loss: 0.833
[41,     4] loss: 0.812
[42,     4] loss: 0.804
[43,     4] loss: 0.809
[44,     4] loss: 0.811
[45,     4] loss: 0.776
[46,     4] loss: 0.773
[47,     4] loss: 0.811
[48,     4] loss: 0.846
[49,     4] loss: 0.777
[50,     4] loss: 0.760
[51,     4] loss: 0.797
[52,     4] loss: 0.792
[53,     4] loss: 0.757
[54,     4] loss: 0.734
[55,     4] loss: 0.746
[56,     4] loss: 0.769
[57,     4] loss: 0.759
[58,     4] loss: 0.753
[59,     4] loss: 0.760
[60,     4] loss: 0.759
[61,     4] loss: 0.737
[62,     4] loss: 0.768
[63,     4] loss: 0.779
[64,     4] loss: 0.808
[65,     4] loss: 0.811
[66,     4] loss: 0.785
[67,     4] loss: 0.787
[68,     4] loss: 0.748
[69,     4] loss: 0.758
[70,     4] loss: 0.761
[71,     4] loss: 0.719
[72,     4] loss: 0.783
[73,     4] loss: 0.790
[74,     4] loss: 0.769
[75,     4] loss: 0.767
[76,     4] loss: 0.791
[77,     4] loss: 0.776
[78,     4] loss: 0.747
[79,     4] loss: 0.757
[80,     4] loss: 0.731
[81,     4] loss: 0.787
[82,     4] loss: 0.752
[83,     4] loss: 0.730
[84,     4] loss: 0.703
[85,     4] loss: 0.720
Early stopping applied (best metric=0.45287078619003296)
Finished Training
Total time taken: 42.962098121643066
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.391
[3,     4] loss: 1.384
[4,     4] loss: 1.379
[5,     4] loss: 1.375
[6,     4] loss: 1.361
[7,     4] loss: 1.350
[8,     4] loss: 1.315
[9,     4] loss: 1.316
[10,     4] loss: 1.252
[11,     4] loss: 1.187
[12,     4] loss: 1.149
[13,     4] loss: 1.110
[14,     4] loss: 1.009
[15,     4] loss: 0.989
[16,     4] loss: 0.962
[17,     4] loss: 0.947
[18,     4] loss: 0.962
[19,     4] loss: 0.928
[20,     4] loss: 0.906
[21,     4] loss: 0.890
[22,     4] loss: 0.875
[23,     4] loss: 0.894
[24,     4] loss: 0.846
[25,     4] loss: 0.892
[26,     4] loss: 0.914
[27,     4] loss: 1.002
[28,     4] loss: 0.881
[29,     4] loss: 0.858
[30,     4] loss: 0.835
[31,     4] loss: 0.840
[32,     4] loss: 0.846
[33,     4] loss: 0.842
[34,     4] loss: 0.840
[35,     4] loss: 0.853
[36,     4] loss: 0.827
[37,     4] loss: 0.848
[38,     4] loss: 0.795
[39,     4] loss: 0.826
[40,     4] loss: 0.809
[41,     4] loss: 0.779
[42,     4] loss: 0.809
[43,     4] loss: 0.870
[44,     4] loss: 0.790
[45,     4] loss: 0.873
[46,     4] loss: 0.849
[47,     4] loss: 0.811
[48,     4] loss: 0.853
[49,     4] loss: 0.797
[50,     4] loss: 0.768
[51,     4] loss: 0.784
[52,     4] loss: 0.791
[53,     4] loss: 0.783
[54,     4] loss: 0.838
[55,     4] loss: 0.775
[56,     4] loss: 0.777
[57,     4] loss: 0.759
[58,     4] loss: 0.761
[59,     4] loss: 0.751
Early stopping applied (best metric=0.495132178068161)
Finished Training
Total time taken: 29.884459972381592
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.388
[3,     4] loss: 1.388
[4,     4] loss: 1.383
[5,     4] loss: 1.384
[6,     4] loss: 1.380
[7,     4] loss: 1.371
[8,     4] loss: 1.362
[9,     4] loss: 1.337
[10,     4] loss: 1.310
[11,     4] loss: 1.298
[12,     4] loss: 1.254
[13,     4] loss: 1.217
[14,     4] loss: 1.171
[15,     4] loss: 1.114
[16,     4] loss: 1.096
[17,     4] loss: 1.093
[18,     4] loss: 1.027
[19,     4] loss: 0.974
[20,     4] loss: 1.023
[21,     4] loss: 1.037
[22,     4] loss: 1.000
[23,     4] loss: 0.949
[24,     4] loss: 1.015
[25,     4] loss: 0.972
[26,     4] loss: 1.020
[27,     4] loss: 0.901
[28,     4] loss: 0.904
[29,     4] loss: 0.890
[30,     4] loss: 0.896
[31,     4] loss: 0.881
[32,     4] loss: 0.818
[33,     4] loss: 0.796
[34,     4] loss: 0.896
[35,     4] loss: 0.804
[36,     4] loss: 0.798
[37,     4] loss: 0.783
[38,     4] loss: 0.773
[39,     4] loss: 0.787
[40,     4] loss: 0.779
[41,     4] loss: 0.778
[42,     4] loss: 0.752
[43,     4] loss: 0.752
[44,     4] loss: 0.745
[45,     4] loss: 0.752
[46,     4] loss: 0.717
[47,     4] loss: 0.760
[48,     4] loss: 0.787
[49,     4] loss: 0.755
[50,     4] loss: 0.828
[51,     4] loss: 0.827
[52,     4] loss: 0.769
[53,     4] loss: 0.783
[54,     4] loss: 0.754
[55,     4] loss: 0.751
[56,     4] loss: 0.759
[57,     4] loss: 0.783
[58,     4] loss: 0.767
[59,     4] loss: 0.757
[60,     4] loss: 0.768
[61,     4] loss: 0.799
[62,     4] loss: 0.743
[63,     4] loss: 0.731
[64,     4] loss: 0.737
[65,     4] loss: 0.737
[66,     4] loss: 0.718
[67,     4] loss: 0.720
[68,     4] loss: 0.704
[69,     4] loss: 0.712
[70,     4] loss: 0.715
[71,     4] loss: 0.692
[72,     4] loss: 0.716
Early stopping applied (best metric=0.3067029118537903)
Finished Training
Total time taken: 36.922805309295654
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.391
[3,     4] loss: 1.394
[4,     4] loss: 1.383
[5,     4] loss: 1.377
[6,     4] loss: 1.376
[7,     4] loss: 1.357
[8,     4] loss: 1.342
[9,     4] loss: 1.312
[10,     4] loss: 1.295
[11,     4] loss: 1.251
[12,     4] loss: 1.238
[13,     4] loss: 1.171
[14,     4] loss: 1.177
[15,     4] loss: 1.156
[16,     4] loss: 1.135
[17,     4] loss: 1.032
[18,     4] loss: 1.025
[19,     4] loss: 0.988
[20,     4] loss: 0.982
[21,     4] loss: 0.961
[22,     4] loss: 0.967
[23,     4] loss: 0.937
[24,     4] loss: 0.896
[25,     4] loss: 0.913
[26,     4] loss: 0.857
[27,     4] loss: 0.852
[28,     4] loss: 0.873
[29,     4] loss: 0.902
[30,     4] loss: 0.864
[31,     4] loss: 0.848
[32,     4] loss: 0.809
[33,     4] loss: 0.819
[34,     4] loss: 0.768
[35,     4] loss: 0.776
[36,     4] loss: 0.804
[37,     4] loss: 0.773
[38,     4] loss: 0.777
[39,     4] loss: 0.857
[40,     4] loss: 0.779
[41,     4] loss: 0.788
[42,     4] loss: 0.821
[43,     4] loss: 0.773
[44,     4] loss: 0.749
[45,     4] loss: 0.759
[46,     4] loss: 0.743
[47,     4] loss: 0.765
[48,     4] loss: 0.747
[49,     4] loss: 0.740
[50,     4] loss: 0.761
[51,     4] loss: 0.738
[52,     4] loss: 0.730
[53,     4] loss: 0.800
[54,     4] loss: 0.732
[55,     4] loss: 0.748
[56,     4] loss: 0.781
[57,     4] loss: 0.778
[58,     4] loss: 0.800
[59,     4] loss: 0.757
[60,     4] loss: 0.748
[61,     4] loss: 0.744
[62,     4] loss: 0.732
[63,     4] loss: 0.747
[64,     4] loss: 0.715
[65,     4] loss: 0.712
[66,     4] loss: 0.731
[67,     4] loss: 0.746
[68,     4] loss: 0.714
[69,     4] loss: 0.710
Early stopping applied (best metric=0.42761796712875366)
Finished Training
Total time taken: 34.91570687294006
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.398
[3,     4] loss: 1.384
[4,     4] loss: 1.383
[5,     4] loss: 1.378
[6,     4] loss: 1.370
[7,     4] loss: 1.359
[8,     4] loss: 1.334
[9,     4] loss: 1.309
[10,     4] loss: 1.274
[11,     4] loss: 1.248
[12,     4] loss: 1.211
[13,     4] loss: 1.171
[14,     4] loss: 1.122
[15,     4] loss: 1.087
[16,     4] loss: 1.000
[17,     4] loss: 1.054
[18,     4] loss: 0.998
[19,     4] loss: 0.963
[20,     4] loss: 0.975
[21,     4] loss: 0.967
[22,     4] loss: 0.924
[23,     4] loss: 0.945
[24,     4] loss: 0.888
[25,     4] loss: 0.848
[26,     4] loss: 0.875
[27,     4] loss: 0.886
[28,     4] loss: 0.882
[29,     4] loss: 0.846
[30,     4] loss: 0.867
[31,     4] loss: 0.809
[32,     4] loss: 0.827
[33,     4] loss: 0.807
[34,     4] loss: 0.801
[35,     4] loss: 0.789
[36,     4] loss: 0.804
[37,     4] loss: 0.791
[38,     4] loss: 0.806
[39,     4] loss: 0.794
[40,     4] loss: 0.827
[41,     4] loss: 0.804
[42,     4] loss: 0.801
[43,     4] loss: 0.832
[44,     4] loss: 0.777
[45,     4] loss: 0.797
[46,     4] loss: 0.804
[47,     4] loss: 0.773
[48,     4] loss: 0.811
[49,     4] loss: 0.768
[50,     4] loss: 0.783
[51,     4] loss: 0.778
[52,     4] loss: 0.765
[53,     4] loss: 0.782
[54,     4] loss: 0.747
[55,     4] loss: 0.777
[56,     4] loss: 0.789
[57,     4] loss: 0.775
[58,     4] loss: 0.761
[59,     4] loss: 0.742
[60,     4] loss: 0.757
Early stopping applied (best metric=0.4988408088684082)
Finished Training
Total time taken: 30.54249382019043
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.388
[2,     4] loss: 1.386
[3,     4] loss: 1.388
[4,     4] loss: 1.381
[5,     4] loss: 1.388
[6,     4] loss: 1.380
[7,     4] loss: 1.377
[8,     4] loss: 1.377
[9,     4] loss: 1.368
[10,     4] loss: 1.344
[11,     4] loss: 1.314
[12,     4] loss: 1.270
[13,     4] loss: 1.251
[14,     4] loss: 1.155
[15,     4] loss: 1.122
[16,     4] loss: 1.110
[17,     4] loss: 1.070
[18,     4] loss: 1.054
[19,     4] loss: 1.058
[20,     4] loss: 0.964
[21,     4] loss: 0.998
[22,     4] loss: 0.959
[23,     4] loss: 0.898
[24,     4] loss: 0.883
[25,     4] loss: 0.856
[26,     4] loss: 0.854
[27,     4] loss: 0.913
[28,     4] loss: 0.829
[29,     4] loss: 0.819
[30,     4] loss: 0.813
[31,     4] loss: 0.881
[32,     4] loss: 0.811
[33,     4] loss: 0.790
[34,     4] loss: 0.786
[35,     4] loss: 0.817
[36,     4] loss: 0.795
[37,     4] loss: 0.849
[38,     4] loss: 0.797
[39,     4] loss: 0.775
[40,     4] loss: 0.774
[41,     4] loss: 0.799
[42,     4] loss: 0.805
[43,     4] loss: 0.773
[44,     4] loss: 0.786
[45,     4] loss: 0.786
[46,     4] loss: 0.797
[47,     4] loss: 0.784
[48,     4] loss: 0.765
[49,     4] loss: 0.786
[50,     4] loss: 0.766
[51,     4] loss: 0.770
[52,     4] loss: 0.778
[53,     4] loss: 0.773
[54,     4] loss: 0.768
[55,     4] loss: 0.777
[56,     4] loss: 0.787
[57,     4] loss: 0.753
[58,     4] loss: 0.763
[59,     4] loss: 0.768
Early stopping applied (best metric=0.5348645448684692)
Finished Training
Total time taken: 29.62445092201233
{'Hydroxylation-K Validation Accuracy': 0.7745862884160757, 'Hydroxylation-K Validation Sensitivity': 0.7548148148148148, 'Hydroxylation-K Validation Specificity': 0.7789473684210526, 'Hydroxylation-K Validation Precision': 0.47129280140149704, 'Hydroxylation-K AUC ROC': 0.8173489278752436, 'Hydroxylation-K AUC PR': 0.576801214698297, 'Hydroxylation-K MCC': 0.4612704163201949, 'Hydroxylation-K F1': 0.5751501958504247, 'Validation Loss (Hydroxylation-K)': 0.41441388527552286, 'Methylation-K Validation Accuracy': 0.8056088381552537, 'Methylation-K Validation Sensitivity': 0.14982700413093167, 'Methylation-K Validation Specificity': 0.8767277233622871, 'Methylation-K Validation Precision': 0.11747916446508809, 'Methylation-K AUC ROC': 0.5441879692691067, 'Methylation-K AUC PR': 0.11267458969696616, 'Methylation-K MCC': 0.024021710109182616, 'Methylation-K F1': 0.12707718765571888, 'Validation Loss (Methylation-K)': 0.8067121605078379, 'Validation Loss (total)': 1.2211260318756103, 'TimeToTrain': 37.68657625516256}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005227591406197729,
 'learning_rate_Hydroxylation-K': 0.0061364198853116,
 'learning_rate_Methylation-K': 0.008664169569894796,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.34693423088851205,
 'loss_weight_Methylation-K': 0.11035918795266159,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3660167576,
 'sample_weights': [0.19950816096616097, 0.5777365550522368],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.990470512135703,
 'weight_decay_Hydroxylation-K': 2.6321793847111494,
 'weight_decay_Methylation-K': 0.7643279637309064}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.385
[3,     4] loss: 1.382
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013234035269634112,
 'learning_rate_Hydroxylation-K': 0.002030649781793659,
 'learning_rate_Methylation-K': 0.0026770333980298943,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4069312355402705,
 'loss_weight_Methylation-K': 0.03209619862361751,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 439950360,
 'sample_weights': [0.34693423088851205, 0.11035918795266159],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.573850558551339,
 'weight_decay_Hydroxylation-K': 8.295309793534335,
 'weight_decay_Methylation-K': 6.355748425532082}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.387
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00263132578081411,
 'learning_rate_Hydroxylation-K': 0.0008943523065259027,
 'learning_rate_Methylation-K': 0.0014356192194767319,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3090005378591684,
 'loss_weight_Methylation-K': 0.015249293879864623,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1399303185,
 'sample_weights': [0.4069312355402705, 0.03209619862361751],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.1325505967716305,
 'weight_decay_Hydroxylation-K': 5.288142643193357,
 'weight_decay_Methylation-K': 7.892298588303315}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.387
[3,     4] loss: 1.374
[4,     4] loss: 1.382
[5,     4] loss: 1.373
[6,     4] loss: 1.342
[7,     4] loss: 1.295
[8,     4] loss: 1.210
[9,     4] loss: 1.150
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012790783167844011,
 'learning_rate_Hydroxylation-K': 0.0024289656766467247,
 'learning_rate_Methylation-K': 0.0018708470977021724,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3490070637774794,
 'loss_weight_Methylation-K': 0.24149426485162892,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1682254606,
 'sample_weights': [0.3090005378591684, 0.015249293879864623],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.199610308090671,
 'weight_decay_Hydroxylation-K': 7.006013889738555,
 'weight_decay_Methylation-K': 7.396987521234483}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.391
[3,     4] loss: 1.384
[4,     4] loss: 1.382
[5,     4] loss: 1.385
[6,     4] loss: 1.379
[7,     4] loss: 1.373
[8,     4] loss: 1.363
[9,     4] loss: 1.350
[10,     4] loss: 1.299
[11,     4] loss: 1.270
[12,     4] loss: 1.182
[13,     4] loss: 1.198
[14,     4] loss: 1.158
[15,     4] loss: 1.085
[16,     4] loss: 1.059
[17,     4] loss: 0.962
[18,     4] loss: 0.998
[19,     4] loss: 0.975
[20,     4] loss: 0.943
[21,     4] loss: 0.969
[22,     4] loss: 0.954
[23,     4] loss: 0.979
[24,     4] loss: 0.858
[25,     4] loss: 0.914
[26,     4] loss: 0.900
[27,     4] loss: 0.933
[28,     4] loss: 0.944
[29,     4] loss: 0.913
[30,     4] loss: 0.964
[31,     4] loss: 0.909
[32,     4] loss: 0.925
[33,     4] loss: 0.862
[34,     4] loss: 0.813
[35,     4] loss: 0.829
[36,     4] loss: 0.857
[37,     4] loss: 0.860
[38,     4] loss: 0.831
[39,     4] loss: 0.791
[40,     4] loss: 0.775
[41,     4] loss: 0.809
[42,     4] loss: 0.816
[43,     4] loss: 0.761
[44,     4] loss: 0.782
[45,     4] loss: 0.775
[46,     4] loss: 0.741
[47,     4] loss: 0.764
[48,     4] loss: 0.757
[49,     4] loss: 0.831
[50,     4] loss: 0.907
[51,     4] loss: 0.923
[52,     4] loss: 0.833
[53,     4] loss: 0.831
[54,     4] loss: 0.850
[55,     4] loss: 0.882
[56,     4] loss: 0.843
[57,     4] loss: 0.817
[58,     4] loss: 0.772
[59,     4] loss: 0.778
[60,     4] loss: 0.796
[61,     4] loss: 0.765
[62,     4] loss: 0.744
[63,     4] loss: 0.771
[64,     4] loss: 0.748
[65,     4] loss: 0.750
[66,     4] loss: 0.763
[67,     4] loss: 0.752
[68,     4] loss: 0.771
Early stopping applied (best metric=0.2601436674594879)
Finished Training
Total time taken: 34.43168497085571
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.389
[3,     4] loss: 1.387
[4,     4] loss: 1.385
[5,     4] loss: 1.390
[6,     4] loss: 1.381
[7,     4] loss: 1.378
[8,     4] loss: 1.370
[9,     4] loss: 1.365
[10,     4] loss: 1.344
[11,     4] loss: 1.320
[12,     4] loss: 1.280
[13,     4] loss: 1.241
[14,     4] loss: 1.182
[15,     4] loss: 1.133
[16,     4] loss: 1.103
[17,     4] loss: 1.043
[18,     4] loss: 0.983
[19,     4] loss: 1.001
[20,     4] loss: 0.937
[21,     4] loss: 0.918
[22,     4] loss: 0.886
[23,     4] loss: 0.960
[24,     4] loss: 0.918
[25,     4] loss: 0.872
[26,     4] loss: 0.899
[27,     4] loss: 0.884
[28,     4] loss: 0.955
[29,     4] loss: 0.911
[30,     4] loss: 0.897
[31,     4] loss: 0.981
[32,     4] loss: 0.878
[33,     4] loss: 0.859
[34,     4] loss: 0.801
[35,     4] loss: 0.814
[36,     4] loss: 0.787
[37,     4] loss: 0.809
[38,     4] loss: 0.916
[39,     4] loss: 0.822
[40,     4] loss: 0.844
[41,     4] loss: 0.769
[42,     4] loss: 0.810
[43,     4] loss: 0.822
[44,     4] loss: 0.793
[45,     4] loss: 0.799
[46,     4] loss: 0.784
[47,     4] loss: 0.799
[48,     4] loss: 0.813
[49,     4] loss: 0.785
[50,     4] loss: 0.757
[51,     4] loss: 0.774
[52,     4] loss: 0.752
[53,     4] loss: 0.782
[54,     4] loss: 0.843
[55,     4] loss: 0.795
[56,     4] loss: 0.780
[57,     4] loss: 0.754
[58,     4] loss: 0.739
[59,     4] loss: 0.761
[60,     4] loss: 0.759
[61,     4] loss: 0.777
[62,     4] loss: 0.729
[63,     4] loss: 0.746
[64,     4] loss: 0.797
[65,     4] loss: 0.752
[66,     4] loss: 0.751
[67,     4] loss: 0.765
[68,     4] loss: 0.743
[69,     4] loss: 0.775
[70,     4] loss: 0.760
[71,     4] loss: 0.757
[72,     4] loss: 0.757
[73,     4] loss: 0.763
[74,     4] loss: 0.772
[75,     4] loss: 0.801
Early stopping applied (best metric=0.36759281158447266)
Finished Training
Total time taken: 37.83484745025635
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.387
[5,     4] loss: 1.384
[6,     4] loss: 1.382
[7,     4] loss: 1.375
[8,     4] loss: 1.374
[9,     4] loss: 1.359
[10,     4] loss: 1.328
[11,     4] loss: 1.304
[12,     4] loss: 1.213
[13,     4] loss: 1.143
[14,     4] loss: 1.120
[15,     4] loss: 1.028
[16,     4] loss: 1.022
[17,     4] loss: 0.939
[18,     4] loss: 0.980
[19,     4] loss: 0.948
[20,     4] loss: 0.922
[21,     4] loss: 1.005
[22,     4] loss: 0.908
[23,     4] loss: 0.880
[24,     4] loss: 0.915
[25,     4] loss: 0.872
[26,     4] loss: 0.900
[27,     4] loss: 0.881
[28,     4] loss: 0.890
[29,     4] loss: 0.923
[30,     4] loss: 0.844
[31,     4] loss: 0.806
[32,     4] loss: 0.824
[33,     4] loss: 0.826
[34,     4] loss: 0.798
[35,     4] loss: 0.803
[36,     4] loss: 0.787
[37,     4] loss: 0.802
[38,     4] loss: 0.802
[39,     4] loss: 0.783
[40,     4] loss: 0.864
[41,     4] loss: 0.769
[42,     4] loss: 0.762
[43,     4] loss: 0.825
[44,     4] loss: 0.793
[45,     4] loss: 0.748
[46,     4] loss: 0.736
[47,     4] loss: 0.766
[48,     4] loss: 0.768
[49,     4] loss: 0.756
[50,     4] loss: 0.729
[51,     4] loss: 0.765
[52,     4] loss: 0.739
[53,     4] loss: 0.734
[54,     4] loss: 0.743
[55,     4] loss: 0.758
[56,     4] loss: 0.756
[57,     4] loss: 0.772
[58,     4] loss: 0.769
[59,     4] loss: 0.777
[60,     4] loss: 0.775
[61,     4] loss: 0.811
[62,     4] loss: 0.769
Early stopping applied (best metric=0.44374212622642517)
Finished Training
Total time taken: 31.16852641105652
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.385
[5,     4] loss: 1.377
[6,     4] loss: 1.367
[7,     4] loss: 1.352
[8,     4] loss: 1.328
[9,     4] loss: 1.279
[10,     4] loss: 1.230
[11,     4] loss: 1.175
[12,     4] loss: 1.142
[13,     4] loss: 1.037
[14,     4] loss: 1.088
[15,     4] loss: 0.977
[16,     4] loss: 1.031
[17,     4] loss: 1.034
[18,     4] loss: 0.967
[19,     4] loss: 0.980
[20,     4] loss: 0.916
[21,     4] loss: 0.889
[22,     4] loss: 0.872
[23,     4] loss: 0.837
[24,     4] loss: 0.844
[25,     4] loss: 0.843
[26,     4] loss: 0.903
[27,     4] loss: 0.856
[28,     4] loss: 0.876
[29,     4] loss: 0.834
[30,     4] loss: 0.820
[31,     4] loss: 0.786
[32,     4] loss: 0.862
[33,     4] loss: 0.791
[34,     4] loss: 0.797
[35,     4] loss: 0.796
[36,     4] loss: 0.795
[37,     4] loss: 0.793
[38,     4] loss: 0.766
[39,     4] loss: 0.812
[40,     4] loss: 0.770
[41,     4] loss: 0.767
[42,     4] loss: 0.791
[43,     4] loss: 0.786
[44,     4] loss: 0.870
[45,     4] loss: 0.820
[46,     4] loss: 0.765
[47,     4] loss: 0.775
[48,     4] loss: 0.758
[49,     4] loss: 0.767
[50,     4] loss: 0.758
[51,     4] loss: 0.783
[52,     4] loss: 0.783
[53,     4] loss: 0.745
[54,     4] loss: 0.755
[55,     4] loss: 0.748
[56,     4] loss: 0.751
[57,     4] loss: 0.843
[58,     4] loss: 0.932
[59,     4] loss: 0.849
[60,     4] loss: 0.826
Early stopping applied (best metric=0.43456465005874634)
Finished Training
Total time taken: 30.44048833847046
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.382
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.384
[5,     4] loss: 1.385
[6,     4] loss: 1.380
[7,     4] loss: 1.374
[8,     4] loss: 1.360
[9,     4] loss: 1.351
[10,     4] loss: 1.330
[11,     4] loss: 1.283
[12,     4] loss: 1.266
[13,     4] loss: 1.190
[14,     4] loss: 1.136
[15,     4] loss: 1.103
[16,     4] loss: 1.065
[17,     4] loss: 1.101
[18,     4] loss: 1.134
[19,     4] loss: 1.034
[20,     4] loss: 1.017
[21,     4] loss: 0.949
[22,     4] loss: 0.910
[23,     4] loss: 0.919
[24,     4] loss: 0.940
[25,     4] loss: 0.916
[26,     4] loss: 0.886
[27,     4] loss: 0.929
[28,     4] loss: 0.941
[29,     4] loss: 0.890
[30,     4] loss: 0.896
[31,     4] loss: 0.842
[32,     4] loss: 0.855
[33,     4] loss: 0.833
[34,     4] loss: 0.829
[35,     4] loss: 0.839
[36,     4] loss: 0.795
[37,     4] loss: 0.854
[38,     4] loss: 0.854
[39,     4] loss: 0.844
[40,     4] loss: 0.887
[41,     4] loss: 0.837
[42,     4] loss: 0.801
[43,     4] loss: 0.848
[44,     4] loss: 0.789
[45,     4] loss: 0.850
[46,     4] loss: 0.821
[47,     4] loss: 0.799
[48,     4] loss: 0.816
[49,     4] loss: 0.768
[50,     4] loss: 0.778
[51,     4] loss: 0.796
[52,     4] loss: 0.792
[53,     4] loss: 0.750
[54,     4] loss: 0.768
[55,     4] loss: 0.771
[56,     4] loss: 0.814
[57,     4] loss: 0.770
[58,     4] loss: 0.770
[59,     4] loss: 0.801
[60,     4] loss: 0.763
[61,     4] loss: 0.757
[62,     4] loss: 0.812
[63,     4] loss: 0.758
[64,     4] loss: 0.766
Early stopping applied (best metric=0.3972266912460327)
Finished Training
Total time taken: 32.004568576812744
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.382
[3,     4] loss: 1.384
[4,     4] loss: 1.375
[5,     4] loss: 1.380
[6,     4] loss: 1.360
[7,     4] loss: 1.318
[8,     4] loss: 1.297
[9,     4] loss: 1.249
[10,     4] loss: 1.198
[11,     4] loss: 1.136
[12,     4] loss: 1.056
[13,     4] loss: 1.049
[14,     4] loss: 1.021
[15,     4] loss: 1.118
[16,     4] loss: 1.087
[17,     4] loss: 1.008
[18,     4] loss: 0.960
[19,     4] loss: 0.967
[20,     4] loss: 0.984
[21,     4] loss: 0.897
[22,     4] loss: 0.875
[23,     4] loss: 0.924
[24,     4] loss: 1.013
[25,     4] loss: 0.939
[26,     4] loss: 0.929
[27,     4] loss: 1.003
[28,     4] loss: 0.968
[29,     4] loss: 0.910
[30,     4] loss: 0.918
[31,     4] loss: 0.886
[32,     4] loss: 0.901
[33,     4] loss: 0.908
[34,     4] loss: 0.924
[35,     4] loss: 0.875
[36,     4] loss: 0.854
[37,     4] loss: 0.853
[38,     4] loss: 0.892
[39,     4] loss: 0.875
[40,     4] loss: 0.802
[41,     4] loss: 0.790
[42,     4] loss: 0.833
[43,     4] loss: 0.823
[44,     4] loss: 0.766
[45,     4] loss: 0.777
[46,     4] loss: 0.760
[47,     4] loss: 0.765
[48,     4] loss: 0.760
[49,     4] loss: 0.765
[50,     4] loss: 0.818
[51,     4] loss: 0.878
[52,     4] loss: 0.903
[53,     4] loss: 0.864
[54,     4] loss: 0.940
[55,     4] loss: 0.924
[56,     4] loss: 0.829
[57,     4] loss: 0.801
[58,     4] loss: 0.795
[59,     4] loss: 0.772
[60,     4] loss: 0.751
[61,     4] loss: 0.753
[62,     4] loss: 0.754
[63,     4] loss: 0.742
[64,     4] loss: 0.742
[65,     4] loss: 0.747
[66,     4] loss: 0.753
[67,     4] loss: 0.756
[68,     4] loss: 0.778
[69,     4] loss: 0.797
[70,     4] loss: 0.792
[71,     4] loss: 0.790
[72,     4] loss: 0.776
[73,     4] loss: 0.777
[74,     4] loss: 0.743
[75,     4] loss: 0.749
[76,     4] loss: 0.767
[77,     4] loss: 0.759
[78,     4] loss: 0.766
[79,     4] loss: 0.746
[80,     4] loss: 0.763
[81,     4] loss: 0.748
[82,     4] loss: 0.748
[83,     4] loss: 0.736
[84,     4] loss: 0.735
[85,     4] loss: 0.735
[86,     4] loss: 0.732
[87,     4] loss: 0.744
[88,     4] loss: 0.742
[89,     4] loss: 0.756
[90,     4] loss: 0.751
[91,     4] loss: 0.764
[92,     4] loss: 0.760
[93,     4] loss: 0.745
[94,     4] loss: 0.747
[95,     4] loss: 0.746
[96,     4] loss: 0.740
[97,     4] loss: 0.776
[98,     4] loss: 0.769
[99,     4] loss: 0.743
[100,     4] loss: 0.766
[101,     4] loss: 0.788
[102,     4] loss: 0.799
[103,     4] loss: 0.795
[104,     4] loss: 0.792
[105,     4] loss: 0.784
[106,     4] loss: 0.748
Early stopping applied (best metric=0.3361806869506836)
Finished Training
Total time taken: 53.10859704017639
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.382
[5,     4] loss: 1.379
[6,     4] loss: 1.370
[7,     4] loss: 1.358
[8,     4] loss: 1.323
[9,     4] loss: 1.304
[10,     4] loss: 1.247
[11,     4] loss: 1.198
[12,     4] loss: 1.153
[13,     4] loss: 1.076
[14,     4] loss: 1.085
[15,     4] loss: 1.077
[16,     4] loss: 1.050
[17,     4] loss: 1.032
[18,     4] loss: 0.987
[19,     4] loss: 0.920
[20,     4] loss: 0.884
[21,     4] loss: 0.905
[22,     4] loss: 0.876
[23,     4] loss: 0.956
[24,     4] loss: 0.835
[25,     4] loss: 0.898
[26,     4] loss: 0.844
[27,     4] loss: 0.837
[28,     4] loss: 0.843
[29,     4] loss: 0.826
[30,     4] loss: 0.815
[31,     4] loss: 0.789
[32,     4] loss: 0.789
[33,     4] loss: 0.854
[34,     4] loss: 0.794
[35,     4] loss: 0.828
[36,     4] loss: 0.785
[37,     4] loss: 0.804
[38,     4] loss: 0.795
[39,     4] loss: 0.797
[40,     4] loss: 0.807
[41,     4] loss: 0.775
[42,     4] loss: 0.755
[43,     4] loss: 0.754
[44,     4] loss: 0.811
[45,     4] loss: 0.812
[46,     4] loss: 0.793
[47,     4] loss: 0.758
[48,     4] loss: 0.799
[49,     4] loss: 0.760
[50,     4] loss: 0.754
[51,     4] loss: 0.782
[52,     4] loss: 0.754
[53,     4] loss: 0.809
[54,     4] loss: 0.784
[55,     4] loss: 0.839
[56,     4] loss: 0.849
[57,     4] loss: 0.780
[58,     4] loss: 0.788
[59,     4] loss: 0.777
[60,     4] loss: 0.785
[61,     4] loss: 0.750
[62,     4] loss: 0.751
[63,     4] loss: 0.747
Early stopping applied (best metric=0.40796348452568054)
Finished Training
Total time taken: 31.685547351837158
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.387
[5,     4] loss: 1.377
[6,     4] loss: 1.374
[7,     4] loss: 1.345
[8,     4] loss: 1.310
[9,     4] loss: 1.273
[10,     4] loss: 1.201
[11,     4] loss: 1.182
[12,     4] loss: 1.211
[13,     4] loss: 1.111
[14,     4] loss: 1.131
[15,     4] loss: 1.131
[16,     4] loss: 1.022
[17,     4] loss: 0.987
[18,     4] loss: 0.946
[19,     4] loss: 1.039
[20,     4] loss: 0.971
[21,     4] loss: 0.931
[22,     4] loss: 0.949
[23,     4] loss: 0.926
[24,     4] loss: 0.860
[25,     4] loss: 0.827
[26,     4] loss: 0.804
[27,     4] loss: 0.811
[28,     4] loss: 0.764
[29,     4] loss: 0.777
[30,     4] loss: 0.971
[31,     4] loss: 0.843
[32,     4] loss: 0.810
[33,     4] loss: 0.851
[34,     4] loss: 0.843
[35,     4] loss: 0.813
[36,     4] loss: 0.831
[37,     4] loss: 0.829
[38,     4] loss: 0.797
[39,     4] loss: 0.798
[40,     4] loss: 0.777
[41,     4] loss: 0.772
[42,     4] loss: 0.751
[43,     4] loss: 0.756
[44,     4] loss: 0.754
[45,     4] loss: 0.750
[46,     4] loss: 0.758
[47,     4] loss: 0.763
[48,     4] loss: 0.760
[49,     4] loss: 0.764
[50,     4] loss: 0.784
[51,     4] loss: 0.789
[52,     4] loss: 0.789
[53,     4] loss: 0.770
[54,     4] loss: 0.764
[55,     4] loss: 0.866
[56,     4] loss: 0.850
[57,     4] loss: 0.826
[58,     4] loss: 0.793
[59,     4] loss: 0.772
[60,     4] loss: 0.773
[61,     4] loss: 0.773
[62,     4] loss: 0.763
[63,     4] loss: 0.780
[64,     4] loss: 0.800
[65,     4] loss: 0.778
[66,     4] loss: 0.840
[67,     4] loss: 0.820
[68,     4] loss: 0.792
Early stopping applied (best metric=0.5396450757980347)
Finished Training
Total time taken: 33.944659948349
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.399
[2,     4] loss: 1.384
[3,     4] loss: 1.388
[4,     4] loss: 1.385
[5,     4] loss: 1.380
[6,     4] loss: 1.369
[7,     4] loss: 1.362
[8,     4] loss: 1.343
[9,     4] loss: 1.319
[10,     4] loss: 1.281
[11,     4] loss: 1.231
[12,     4] loss: 1.183
[13,     4] loss: 1.122
[14,     4] loss: 1.173
[15,     4] loss: 1.208
[16,     4] loss: 1.078
[17,     4] loss: 1.035
[18,     4] loss: 1.048
[19,     4] loss: 0.995
[20,     4] loss: 0.937
[21,     4] loss: 0.956
[22,     4] loss: 0.956
[23,     4] loss: 0.944
[24,     4] loss: 0.892
[25,     4] loss: 0.983
[26,     4] loss: 0.939
[27,     4] loss: 0.886
[28,     4] loss: 0.880
[29,     4] loss: 0.994
[30,     4] loss: 0.866
[31,     4] loss: 0.846
[32,     4] loss: 0.835
[33,     4] loss: 0.799
[34,     4] loss: 0.822
[35,     4] loss: 0.808
[36,     4] loss: 0.809
[37,     4] loss: 0.807
[38,     4] loss: 0.780
[39,     4] loss: 0.788
[40,     4] loss: 0.770
[41,     4] loss: 0.765
[42,     4] loss: 0.773
[43,     4] loss: 0.800
[44,     4] loss: 0.821
[45,     4] loss: 0.800
[46,     4] loss: 0.771
[47,     4] loss: 0.808
[48,     4] loss: 0.826
[49,     4] loss: 0.814
[50,     4] loss: 0.858
[51,     4] loss: 0.883
[52,     4] loss: 0.851
[53,     4] loss: 0.829
[54,     4] loss: 0.809
[55,     4] loss: 0.786
[56,     4] loss: 0.787
[57,     4] loss: 0.762
[58,     4] loss: 0.753
[59,     4] loss: 0.748
[60,     4] loss: 0.743
[61,     4] loss: 0.746
Early stopping applied (best metric=0.39192819595336914)
Finished Training
Total time taken: 30.497493505477905
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.383
[2,     4] loss: 1.392
[3,     4] loss: 1.385
[4,     4] loss: 1.382
[5,     4] loss: 1.375
[6,     4] loss: 1.374
[7,     4] loss: 1.354
[8,     4] loss: 1.310
[9,     4] loss: 1.283
[10,     4] loss: 1.226
[11,     4] loss: 1.190
[12,     4] loss: 1.168
[13,     4] loss: 1.132
[14,     4] loss: 1.103
[15,     4] loss: 1.031
[16,     4] loss: 1.011
[17,     4] loss: 1.038
[18,     4] loss: 0.956
[19,     4] loss: 0.959
[20,     4] loss: 0.916
[21,     4] loss: 0.897
[22,     4] loss: 0.912
[23,     4] loss: 0.891
[24,     4] loss: 0.849
[25,     4] loss: 0.919
[26,     4] loss: 0.832
[27,     4] loss: 0.851
[28,     4] loss: 0.886
[29,     4] loss: 0.919
[30,     4] loss: 0.896
[31,     4] loss: 0.895
[32,     4] loss: 0.872
[33,     4] loss: 0.838
[34,     4] loss: 0.828
[35,     4] loss: 0.851
[36,     4] loss: 0.831
[37,     4] loss: 0.829
[38,     4] loss: 0.823
[39,     4] loss: 0.807
[40,     4] loss: 0.815
[41,     4] loss: 0.805
[42,     4] loss: 0.847
[43,     4] loss: 0.890
[44,     4] loss: 0.879
[45,     4] loss: 0.880
[46,     4] loss: 0.863
[47,     4] loss: 0.835
[48,     4] loss: 0.787
[49,     4] loss: 0.776
[50,     4] loss: 0.783
[51,     4] loss: 0.804
[52,     4] loss: 0.756
[53,     4] loss: 0.754
[54,     4] loss: 0.755
[55,     4] loss: 0.744
[56,     4] loss: 0.745
[57,     4] loss: 0.752
[58,     4] loss: 0.790
[59,     4] loss: 0.777
[60,     4] loss: 0.787
[61,     4] loss: 0.781
[62,     4] loss: 0.741
[63,     4] loss: 0.758
[64,     4] loss: 0.769
Early stopping applied (best metric=0.39320501685142517)
Finished Training
Total time taken: 32.4615843296051
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.381
[3,     4] loss: 1.386
[4,     4] loss: 1.387
[5,     4] loss: 1.382
[6,     4] loss: 1.377
[7,     4] loss: 1.374
[8,     4] loss: 1.349
[9,     4] loss: 1.317
[10,     4] loss: 1.302
[11,     4] loss: 1.205
[12,     4] loss: 1.168
[13,     4] loss: 1.105
[14,     4] loss: 1.148
[15,     4] loss: 1.094
[16,     4] loss: 1.038
[17,     4] loss: 0.993
[18,     4] loss: 0.939
[19,     4] loss: 0.927
[20,     4] loss: 0.908
[21,     4] loss: 0.868
[22,     4] loss: 0.931
[23,     4] loss: 0.856
[24,     4] loss: 0.844
[25,     4] loss: 0.851
[26,     4] loss: 0.846
[27,     4] loss: 0.853
[28,     4] loss: 0.853
[29,     4] loss: 0.812
[30,     4] loss: 0.865
[31,     4] loss: 0.855
[32,     4] loss: 0.814
[33,     4] loss: 0.912
[34,     4] loss: 0.795
[35,     4] loss: 0.786
[36,     4] loss: 0.805
[37,     4] loss: 0.766
[38,     4] loss: 0.787
[39,     4] loss: 0.828
[40,     4] loss: 0.779
[41,     4] loss: 0.804
[42,     4] loss: 0.827
[43,     4] loss: 0.818
[44,     4] loss: 0.809
[45,     4] loss: 0.763
[46,     4] loss: 0.794
[47,     4] loss: 0.769
[48,     4] loss: 0.770
[49,     4] loss: 0.749
[50,     4] loss: 0.774
[51,     4] loss: 0.777
[52,     4] loss: 0.757
[53,     4] loss: 0.782
[54,     4] loss: 0.765
[55,     4] loss: 0.757
[56,     4] loss: 0.776
[57,     4] loss: 0.749
[58,     4] loss: 0.767
[59,     4] loss: 0.784
[60,     4] loss: 0.770
[61,     4] loss: 0.793
[62,     4] loss: 0.804
[63,     4] loss: 0.779
Early stopping applied (best metric=0.3864213824272156)
Finished Training
Total time taken: 31.796552658081055
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.389
[3,     4] loss: 1.383
[4,     4] loss: 1.389
[5,     4] loss: 1.382
[6,     4] loss: 1.383
[7,     4] loss: 1.374
[8,     4] loss: 1.357
[9,     4] loss: 1.336
[10,     4] loss: 1.299
[11,     4] loss: 1.251
[12,     4] loss: 1.141
[13,     4] loss: 1.107
[14,     4] loss: 1.075
[15,     4] loss: 0.993
[16,     4] loss: 0.957
[17,     4] loss: 0.997
[18,     4] loss: 0.902
[19,     4] loss: 0.918
[20,     4] loss: 0.868
[21,     4] loss: 0.808
[22,     4] loss: 0.809
[23,     4] loss: 0.826
[24,     4] loss: 0.773
[25,     4] loss: 0.789
[26,     4] loss: 0.797
[27,     4] loss: 0.800
[28,     4] loss: 0.799
[29,     4] loss: 0.804
[30,     4] loss: 0.775
[31,     4] loss: 0.848
[32,     4] loss: 0.833
[33,     4] loss: 0.988
[34,     4] loss: 0.966
[35,     4] loss: 0.909
[36,     4] loss: 0.874
[37,     4] loss: 0.846
[38,     4] loss: 0.795
[39,     4] loss: 0.789
[40,     4] loss: 0.766
[41,     4] loss: 0.760
[42,     4] loss: 0.744
[43,     4] loss: 0.749
[44,     4] loss: 0.760
[45,     4] loss: 0.756
[46,     4] loss: 0.754
[47,     4] loss: 0.768
[48,     4] loss: 0.755
[49,     4] loss: 0.790
[50,     4] loss: 0.736
[51,     4] loss: 0.735
[52,     4] loss: 0.756
[53,     4] loss: 0.738
[54,     4] loss: 0.742
[55,     4] loss: 0.756
[56,     4] loss: 0.768
[57,     4] loss: 0.762
[58,     4] loss: 0.765
[59,     4] loss: 0.771
[60,     4] loss: 0.767
[61,     4] loss: 0.764
Early stopping applied (best metric=0.4726564884185791)
Finished Training
Total time taken: 30.704503059387207
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.382
[4,     4] loss: 1.384
[5,     4] loss: 1.379
[6,     4] loss: 1.370
[7,     4] loss: 1.346
[8,     4] loss: 1.317
[9,     4] loss: 1.288
[10,     4] loss: 1.195
[11,     4] loss: 1.159
[12,     4] loss: 1.101
[13,     4] loss: 1.049
[14,     4] loss: 0.992
[15,     4] loss: 0.947
[16,     4] loss: 0.929
[17,     4] loss: 0.919
[18,     4] loss: 0.996
[19,     4] loss: 0.908
[20,     4] loss: 0.918
[21,     4] loss: 0.972
[22,     4] loss: 0.885
[23,     4] loss: 0.887
[24,     4] loss: 0.938
[25,     4] loss: 0.865
[26,     4] loss: 0.826
[27,     4] loss: 0.805
[28,     4] loss: 0.817
[29,     4] loss: 0.825
[30,     4] loss: 0.852
[31,     4] loss: 0.999
[32,     4] loss: 0.968
[33,     4] loss: 0.899
[34,     4] loss: 0.850
[35,     4] loss: 0.834
[36,     4] loss: 0.847
[37,     4] loss: 0.784
[38,     4] loss: 0.761
[39,     4] loss: 0.759
[40,     4] loss: 0.744
[41,     4] loss: 0.752
[42,     4] loss: 0.761
[43,     4] loss: 0.740
[44,     4] loss: 0.741
[45,     4] loss: 0.780
[46,     4] loss: 0.759
[47,     4] loss: 0.750
[48,     4] loss: 0.766
[49,     4] loss: 0.796
[50,     4] loss: 0.777
[51,     4] loss: 0.769
[52,     4] loss: 0.775
[53,     4] loss: 0.753
[54,     4] loss: 0.771
[55,     4] loss: 0.758
[56,     4] loss: 0.741
[57,     4] loss: 0.742
Early stopping applied (best metric=0.5271161794662476)
Finished Training
Total time taken: 28.89241313934326
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.390
[3,     4] loss: 1.385
[4,     4] loss: 1.390
[5,     4] loss: 1.384
[6,     4] loss: 1.379
[7,     4] loss: 1.373
[8,     4] loss: 1.362
[9,     4] loss: 1.341
[10,     4] loss: 1.325
[11,     4] loss: 1.276
[12,     4] loss: 1.220
[13,     4] loss: 1.131
[14,     4] loss: 1.074
[15,     4] loss: 1.018
[16,     4] loss: 0.964
[17,     4] loss: 1.067
[18,     4] loss: 1.027
[19,     4] loss: 0.979
[20,     4] loss: 0.947
[21,     4] loss: 1.003
[22,     4] loss: 1.041
[23,     4] loss: 0.989
[24,     4] loss: 0.963
[25,     4] loss: 0.956
[26,     4] loss: 0.921
[27,     4] loss: 0.917
[28,     4] loss: 0.880
[29,     4] loss: 0.916
[30,     4] loss: 0.845
[31,     4] loss: 0.807
[32,     4] loss: 0.808
[33,     4] loss: 0.830
[34,     4] loss: 0.828
[35,     4] loss: 0.819
[36,     4] loss: 0.829
[37,     4] loss: 0.833
[38,     4] loss: 0.852
[39,     4] loss: 0.864
[40,     4] loss: 0.815
[41,     4] loss: 0.815
[42,     4] loss: 0.784
[43,     4] loss: 0.781
[44,     4] loss: 0.826
[45,     4] loss: 0.834
[46,     4] loss: 0.855
[47,     4] loss: 0.823
[48,     4] loss: 0.826
[49,     4] loss: 0.859
[50,     4] loss: 0.811
[51,     4] loss: 0.778
[52,     4] loss: 0.762
[53,     4] loss: 0.744
[54,     4] loss: 0.733
[55,     4] loss: 0.750
[56,     4] loss: 0.744
[57,     4] loss: 0.776
[58,     4] loss: 0.822
[59,     4] loss: 0.797
[60,     4] loss: 0.797
[61,     4] loss: 0.817
[62,     4] loss: 0.772
[63,     4] loss: 0.778
[64,     4] loss: 0.757
Early stopping applied (best metric=0.41372784972190857)
Finished Training
Total time taken: 32.34657859802246
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.389
[2,     4] loss: 1.388
[3,     4] loss: 1.383
[4,     4] loss: 1.389
[5,     4] loss: 1.382
[6,     4] loss: 1.384
[7,     4] loss: 1.379
[8,     4] loss: 1.379
[9,     4] loss: 1.366
[10,     4] loss: 1.354
[11,     4] loss: 1.345
[12,     4] loss: 1.301
[13,     4] loss: 1.242
[14,     4] loss: 1.142
[15,     4] loss: 1.151
[16,     4] loss: 1.145
[17,     4] loss: 1.149
[18,     4] loss: 1.077
[19,     4] loss: 1.056
[20,     4] loss: 1.003
[21,     4] loss: 0.971
[22,     4] loss: 1.016
[23,     4] loss: 1.055
[24,     4] loss: 0.909
[25,     4] loss: 0.915
[26,     4] loss: 0.912
[27,     4] loss: 0.955
[28,     4] loss: 0.945
[29,     4] loss: 0.949
[30,     4] loss: 0.849
[31,     4] loss: 0.851
[32,     4] loss: 0.867
[33,     4] loss: 0.850
[34,     4] loss: 0.858
[35,     4] loss: 0.872
[36,     4] loss: 0.787
[37,     4] loss: 0.786
[38,     4] loss: 0.854
[39,     4] loss: 0.795
[40,     4] loss: 0.797
[41,     4] loss: 0.813
[42,     4] loss: 0.780
[43,     4] loss: 0.790
[44,     4] loss: 0.809
[45,     4] loss: 0.781
[46,     4] loss: 0.778
[47,     4] loss: 0.817
[48,     4] loss: 0.767
[49,     4] loss: 0.778
[50,     4] loss: 0.777
[51,     4] loss: 0.762
[52,     4] loss: 0.777
[53,     4] loss: 0.803
[54,     4] loss: 0.773
[55,     4] loss: 0.781
[56,     4] loss: 0.808
[57,     4] loss: 0.767
[58,     4] loss: 0.788
[59,     4] loss: 0.741
[60,     4] loss: 0.841
[61,     4] loss: 0.791
[62,     4] loss: 0.808
[63,     4] loss: 0.766
[64,     4] loss: 0.774
[65,     4] loss: 0.816
[66,     4] loss: 0.806
[67,     4] loss: 0.763
[68,     4] loss: 0.771
[69,     4] loss: 0.757
[70,     4] loss: 0.758
[71,     4] loss: 0.747
[72,     4] loss: 0.763
[73,     4] loss: 0.760
Early stopping applied (best metric=0.21536339819431305)
Finished Training
Total time taken: 36.60878920555115
{'Hydroxylation-K Validation Accuracy': 0.7868794326241135, 'Hydroxylation-K Validation Sensitivity': 0.7874074074074074, 'Hydroxylation-K Validation Specificity': 0.787719298245614, 'Hydroxylation-K Validation Precision': 0.514050061050061, 'Hydroxylation-K AUC ROC': 0.844541910331384, 'Hydroxylation-K AUC PR': 0.6199305357513193, 'Hydroxylation-K MCC': 0.5072774541104945, 'Hydroxylation-K F1': 0.6064928739407488, 'Validation Loss (Hydroxylation-K)': 0.39916518032550813, 'Methylation-K Validation Accuracy': 0.8139349304370301, 'Methylation-K Validation Sensitivity': 0.1434202157031321, 'Methylation-K Validation Specificity': 0.8866509826626482, 'Methylation-K Validation Precision': 0.12577380981203024, 'Methylation-K AUC ROC': 0.5395631134090161, 'Methylation-K AUC PR': 0.1135062972258713, 'Methylation-K MCC': 0.029344456032309417, 'Methylation-K F1': 0.1199657427139829, 'Validation Loss (Methylation-K)': 0.8641301830609639, 'Validation Loss (total)': 1.2632953723271687, 'TimeToTrain': 33.86178897221883}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006148798753575243,
 'learning_rate_Hydroxylation-K': 0.0048558258261454275,
 'learning_rate_Methylation-K': 1.0815227639761598e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5441369136981111,
 'loss_weight_Methylation-K': 0.1948700362760951,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2368807162,
 'sample_weights': [0.3490070637774794, 0.24149426485162892],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.303434045215097,
 'weight_decay_Hydroxylation-K': 5.500369065411512,
 'weight_decay_Methylation-K': 9.887547756763531}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.386
[5,     4] loss: 1.380
[6,     4] loss: 1.374
[7,     4] loss: 1.358
[8,     4] loss: 1.354
[9,     4] loss: 1.333
[10,     4] loss: 1.314
[11,     4] loss: 1.281
[12,     4] loss: 1.276
[13,     4] loss: 1.228
[14,     4] loss: 1.200
[15,     4] loss: 1.142
[16,     4] loss: 1.094
[17,     4] loss: 1.052
[18,     4] loss: 1.045
[19,     4] loss: 1.031
[20,     4] loss: 0.955
[21,     4] loss: 0.987
[22,     4] loss: 0.967
[23,     4] loss: 0.926
[24,     4] loss: 0.929
[25,     4] loss: 0.968
[26,     4] loss: 0.886
[27,     4] loss: 0.831
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008320145681209828,
 'learning_rate_Hydroxylation-K': 0.0077376392249701685,
 'learning_rate_Methylation-K': 0.004863129628701668,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6476910992146659,
 'loss_weight_Methylation-K': 0.5289169125652977,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1880987747,
 'sample_weights': [0.5441369136981111, 0.1948700362760951],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.307429171286555,
 'weight_decay_Hydroxylation-K': 6.796572418036213,
 'weight_decay_Methylation-K': 5.136795615575566}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.386
[3,     4] loss: 1.386
[4,     4] loss: 1.380
[5,     4] loss: 1.376
[6,     4] loss: 1.363
[7,     4] loss: 1.349
[8,     4] loss: 1.331
[9,     4] loss: 1.308
[10,     4] loss: 1.257
[11,     4] loss: 1.239
[12,     4] loss: 1.139
[13,     4] loss: 1.079
[14,     4] loss: 1.053
[15,     4] loss: 1.049
[16,     4] loss: 0.985
[17,     4] loss: 0.975
[18,     4] loss: 0.995
[19,     4] loss: 0.944
[20,     4] loss: 0.954
[21,     4] loss: 0.869
[22,     4] loss: 0.915
[23,     4] loss: 0.916
[24,     4] loss: 0.881
[25,     4] loss: 0.901
[26,     4] loss: 0.857
[27,     4] loss: 0.896
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 6.047233315932185e-05,
 'learning_rate_Hydroxylation-K': 0.0006049705186194305,
 'learning_rate_Methylation-K': 0.0031424181317322828,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8612659332681636,
 'loss_weight_Methylation-K': 0.3445251729903005,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 381260463,
 'sample_weights': [0.6476910992146659, 0.5289169125652977],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.260715046634413,
 'weight_decay_Hydroxylation-K': 5.884762259807813,
 'weight_decay_Methylation-K': 7.881148561074613}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.400
[2,     4] loss: 1.389
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0020077259803717405,
 'learning_rate_Hydroxylation-K': 0.0003615042257913292,
 'learning_rate_Methylation-K': 0.0015851998751903395,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.30795803807972727,
 'loss_weight_Methylation-K': 0.27738491428340317,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3717787717,
 'sample_weights': [0.8612659332681636, 0.3445251729903005],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.574089638115925,
 'weight_decay_Hydroxylation-K': 6.663574028971548,
 'weight_decay_Methylation-K': 8.736939181488694}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.386
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005577634751841849,
 'learning_rate_Hydroxylation-K': 0.005526716048106138,
 'learning_rate_Methylation-K': 0.0014739374176583216,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.11165866844613861,
 'loss_weight_Methylation-K': 0.3851711354805371,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 339738186,
 'sample_weights': [0.30795803807972727, 0.27738491428340317],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.8868282079692005,
 'weight_decay_Hydroxylation-K': 4.632814317136521,
 'weight_decay_Methylation-K': 6.055330061095345}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.378
[2,     4] loss: 1.386
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011211603940961552,
 'learning_rate_Hydroxylation-K': 0.0013608341212631302,
 'learning_rate_Methylation-K': 0.002030887934303797,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.23048077397885477,
 'loss_weight_Methylation-K': 0.2557557211175706,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2485323485,
 'sample_weights': [0.11165866844613861, 0.3851711354805371],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.524121944202644,
 'weight_decay_Hydroxylation-K': 9.799046740238937,
 'weight_decay_Methylation-K': 9.524818224583251}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.387
[3,     4] loss: 1.385
[4,     4] loss: 1.383
[5,     4] loss: 1.380
[6,     4] loss: 1.379
[7,     4] loss: 1.369
[8,     4] loss: 1.349
[9,     4] loss: 1.318
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006301638062517768,
 'learning_rate_Hydroxylation-K': 0.0005152636139215776,
 'learning_rate_Methylation-K': 0.003794576258421275,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7087707591213087,
 'loss_weight_Methylation-K': 0.11631922222783114,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3079395205,
 'sample_weights': [0.23048077397885477, 0.2557557211175706],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8933303423775427,
 'weight_decay_Hydroxylation-K': 6.997918447724288,
 'weight_decay_Methylation-K': 5.318545897976909}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.383
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013222120004476525,
 'learning_rate_Hydroxylation-K': 0.003775569077830061,
 'learning_rate_Methylation-K': 0.0006106650090810547,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22914346484165682,
 'loss_weight_Methylation-K': 0.08647870558183812,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1645196472,
 'sample_weights': [0.7087707591213087, 0.11631922222783114],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.026914046629795,
 'weight_decay_Hydroxylation-K': 5.630981079886572,
 'weight_decay_Methylation-K': 8.00923377243584}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.389
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010065967526350348,
 'learning_rate_Hydroxylation-K': 0.008669799130994993,
 'learning_rate_Methylation-K': 0.004713387376136354,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.622547165270489,
 'loss_weight_Methylation-K': 0.9376923596311463,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1379106007,
 'sample_weights': [0.22914346484165682, 0.08647870558183812],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.993775444926101,
 'weight_decay_Hydroxylation-K': 6.78978433414343,
 'weight_decay_Methylation-K': 5.036616498855886}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.384
[3,     4] loss: 1.382
[4,     4] loss: 1.373
[5,     4] loss: 1.376
[6,     4] loss: 1.345
[7,     4] loss: 1.319
[8,     4] loss: 1.274
[9,     4] loss: 1.258
[10,     4] loss: 1.187
[11,     4] loss: 1.106
[12,     4] loss: 1.068
[13,     4] loss: 1.028
[14,     4] loss: 1.035
[15,     4] loss: 0.960
[16,     4] loss: 0.931
[17,     4] loss: 0.923
[18,     4] loss: 0.908
[19,     4] loss: 0.895
[20,     4] loss: 0.873
[21,     4] loss: 0.846
[22,     4] loss: 0.840
[23,     4] loss: 0.853
[24,     4] loss: 0.848
[25,     4] loss: 0.806
[26,     4] loss: 0.883
[27,     4] loss: 0.851
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0022574162543680418,
 'learning_rate_Hydroxylation-K': 0.00795431489504287,
 'learning_rate_Methylation-K': 0.001068107408148572,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6180147022852207,
 'loss_weight_Methylation-K': 0.974860557981163,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1402984848,
 'sample_weights': [0.622547165270489, 0.9376923596311463],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.179873647478113,
 'weight_decay_Hydroxylation-K': 5.182493440802574,
 'weight_decay_Methylation-K': 1.173749877080704}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.385
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003918164588922513,
 'learning_rate_Hydroxylation-K': 0.00443648480843778,
 'learning_rate_Methylation-K': 0.004202023121739682,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.27943720867112015,
 'loss_weight_Methylation-K': 0.6793476054450709,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1479630954,
 'sample_weights': [0.6180147022852207, 0.974860557981163],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.991828737052498,
 'weight_decay_Hydroxylation-K': 5.608170236724941,
 'weight_decay_Methylation-K': 7.442562543232222}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.392
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00024581680450868265,
 'learning_rate_Hydroxylation-K': 0.0010111284939004826,
 'learning_rate_Methylation-K': 0.0004221337712280511,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22894530877753952,
 'loss_weight_Methylation-K': 0.2989614661314327,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 895486914,
 'sample_weights': [0.27943720867112015, 0.6793476054450709],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.480987650817891,
 'weight_decay_Hydroxylation-K': 7.230440593700254,
 'weight_decay_Methylation-K': 7.324820666873564}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.388
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025961913401594335,
 'learning_rate_Hydroxylation-K': 0.004563723362218504,
 'learning_rate_Methylation-K': 0.006267232386601417,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5959556170412804,
 'loss_weight_Methylation-K': 0.023990550887784817,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 444313165,
 'sample_weights': [0.22894530877753952, 0.2989614661314327],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.422487788330843,
 'weight_decay_Hydroxylation-K': 8.44731819756323,
 'weight_decay_Methylation-K': 4.920881297150808}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.387
[3,     4] loss: 1.383
[4,     4] loss: 1.375
[5,     4] loss: 1.357
[6,     4] loss: 1.343
[7,     4] loss: 1.281
[8,     4] loss: 1.231
[9,     4] loss: 1.215
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002100412829210812,
 'learning_rate_Hydroxylation-K': 0.003076891850731074,
 'learning_rate_Methylation-K': 0.0006365909499891618,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4683236497531038,
 'loss_weight_Methylation-K': 0.750266985057009,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1237141879,
 'sample_weights': [0.5959556170412804, 0.023990550887784817],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.62176185950786,
 'weight_decay_Hydroxylation-K': 9.888281386175642,
 'weight_decay_Methylation-K': 1.9964171668106223}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.388
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0018738591776784642,
 'learning_rate_Hydroxylation-K': 0.00532154800786815,
 'learning_rate_Methylation-K': 0.0021377932601131305,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9482713064970736,
 'loss_weight_Methylation-K': 0.6114784014516068,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 183814600,
 'sample_weights': [0.4683236497531038, 0.750266985057009],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.969235707067092,
 'weight_decay_Hydroxylation-K': 7.697459357523756,
 'weight_decay_Methylation-K': 9.369331522631985}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.384
[3,     4] loss: 1.385
[4,     4] loss: 1.387
[5,     4] loss: 1.385
[6,     4] loss: 1.385
[7,     4] loss: 1.376
[8,     4] loss: 1.360
[9,     4] loss: 1.344
[10,     4] loss: 1.306
[11,     4] loss: 1.260
[12,     4] loss: 1.217
[13,     4] loss: 1.144
[14,     4] loss: 1.185
[15,     4] loss: 1.090
[16,     4] loss: 1.092
[17,     4] loss: 1.152
[18,     4] loss: 1.200
[19,     4] loss: 1.137
[20,     4] loss: 1.118
[21,     4] loss: 1.043
[22,     4] loss: 0.980
[23,     4] loss: 0.953
[24,     4] loss: 0.915
[25,     4] loss: 1.008
[26,     4] loss: 0.996
[27,     4] loss: 0.929
[28,     4] loss: 0.959
[29,     4] loss: 0.935
[30,     4] loss: 0.922
[31,     4] loss: 0.899
[32,     4] loss: 0.867
[33,     4] loss: 0.893
[34,     4] loss: 0.909
[35,     4] loss: 0.895
[36,     4] loss: 0.887
[37,     4] loss: 0.855
[38,     4] loss: 0.875
[39,     4] loss: 0.880
[40,     4] loss: 0.842
[41,     4] loss: 0.851
[42,     4] loss: 0.823
[43,     4] loss: 0.882
[44,     4] loss: 0.941
[45,     4] loss: 0.805
[46,     4] loss: 0.828
[47,     4] loss: 0.803
[48,     4] loss: 0.795
[49,     4] loss: 0.792
[50,     4] loss: 0.790
[51,     4] loss: 0.804
[52,     4] loss: 0.818
[53,     4] loss: 0.782
[54,     4] loss: 0.783
[55,     4] loss: 0.913
[56,     4] loss: 0.914
[57,     4] loss: 0.977
[58,     4] loss: 0.945
[59,     4] loss: 0.877
[60,     4] loss: 0.934
[61,     4] loss: 0.837
[62,     4] loss: 0.838
[63,     4] loss: 0.816
[64,     4] loss: 0.814
[65,     4] loss: 0.793
[66,     4] loss: 0.837
[67,     4] loss: 0.839
[68,     4] loss: 0.825
[69,     4] loss: 0.853
[70,     4] loss: 0.821
[71,     4] loss: 0.807
[72,     4] loss: 0.824
[73,     4] loss: 0.984
[74,     4] loss: 0.984
[75,     4] loss: 0.935
[76,     4] loss: 0.904
[77,     4] loss: 0.840
[78,     4] loss: 0.883
[79,     4] loss: 0.828
[80,     4] loss: 0.884
[81,     4] loss: 0.910
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002267184983204591,
 'learning_rate_Hydroxylation-K': 0.0052740663810269565,
 'learning_rate_Methylation-K': 0.0015239941058003857,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7970644841968618,
 'loss_weight_Methylation-K': 0.5018413680153452,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 161621502,
 'sample_weights': [0.9482713064970736, 0.6114784014516068],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.922827564892561,
 'weight_decay_Hydroxylation-K': 9.189530036767035,
 'weight_decay_Methylation-K': 9.642405184176683}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.391
[3,     4] loss: 1.385
[4,     4] loss: 1.381
[5,     4] loss: 1.377
[6,     4] loss: 1.364
[7,     4] loss: 1.345
[8,     4] loss: 1.293
[9,     4] loss: 1.257
[10,     4] loss: 1.181
[11,     4] loss: 1.165
[12,     4] loss: 1.077
[13,     4] loss: 1.057
[14,     4] loss: 1.072
[15,     4] loss: 1.018
[16,     4] loss: 0.997
[17,     4] loss: 0.959
[18,     4] loss: 1.079
[19,     4] loss: 1.017
[20,     4] loss: 0.942
[21,     4] loss: 0.910
[22,     4] loss: 0.893
[23,     4] loss: 0.872
[24,     4] loss: 0.916
[25,     4] loss: 1.009
[26,     4] loss: 0.975
[27,     4] loss: 1.013
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002798433356606768,
 'learning_rate_Hydroxylation-K': 0.007286341758500754,
 'learning_rate_Methylation-K': 0.005360257588350094,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6458735912198279,
 'loss_weight_Methylation-K': 0.5382368041086915,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1589568075,
 'sample_weights': [0.7970644841968618, 0.5018413680153452],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.599687862315491,
 'weight_decay_Hydroxylation-K': 5.3880880017016795,
 'weight_decay_Methylation-K': 3.78095206647153}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.384
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002415893456210586,
 'learning_rate_Hydroxylation-K': 0.001142314010894496,
 'learning_rate_Methylation-K': 0.008684664952873905,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4769323160732204,
 'loss_weight_Methylation-K': 0.7552981450202779,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1563077973,
 'sample_weights': [0.6458735912198279, 0.5382368041086915],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.343480240158968,
 'weight_decay_Hydroxylation-K': 9.892850482233742,
 'weight_decay_Methylation-K': 9.494566816816528}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.383
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00026478297673265583,
 'learning_rate_Hydroxylation-K': 0.00859405030057167,
 'learning_rate_Methylation-K': 0.003291902476455718,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6696375238273947,
 'loss_weight_Methylation-K': 0.5862875852880762,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3807871113,
 'sample_weights': [0.4769323160732204, 0.7552981450202779],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.83437896284019,
 'weight_decay_Hydroxylation-K': 3.414595904821573,
 'weight_decay_Methylation-K': 2.222964603966731}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.384
[5,     4] loss: 1.380
[6,     4] loss: 1.376
[7,     4] loss: 1.382
[8,     4] loss: 1.371
[9,     4] loss: 1.364
[10,     4] loss: 1.358
[11,     4] loss: 1.341
[12,     4] loss: 1.322
[13,     4] loss: 1.327
[14,     4] loss: 1.305
[15,     4] loss: 1.267
[16,     4] loss: 1.246
[17,     4] loss: 1.221
[18,     4] loss: 1.205
[19,     4] loss: 1.188
[20,     4] loss: 1.131
[21,     4] loss: 1.147
[22,     4] loss: 1.103
[23,     4] loss: 1.048
[24,     4] loss: 1.036
[25,     4] loss: 1.063
[26,     4] loss: 1.002
[27,     4] loss: 0.955
[28,     4] loss: 0.970
[29,     4] loss: 0.942
[30,     4] loss: 0.958
[31,     4] loss: 0.950
[32,     4] loss: 0.951
[33,     4] loss: 0.900
[34,     4] loss: 0.850
[35,     4] loss: 0.876
[36,     4] loss: 0.842
[37,     4] loss: 0.866
[38,     4] loss: 0.826
[39,     4] loss: 0.810
[40,     4] loss: 0.831
[41,     4] loss: 0.842
[42,     4] loss: 0.831
[43,     4] loss: 0.799
[44,     4] loss: 0.824
[45,     4] loss: 0.823
[46,     4] loss: 0.761
[47,     4] loss: 0.773
[48,     4] loss: 0.810
[49,     4] loss: 0.761
[50,     4] loss: 0.767
[51,     4] loss: 0.756
[52,     4] loss: 0.766
[53,     4] loss: 0.767
[54,     4] loss: 0.747
[55,     4] loss: 0.742
[56,     4] loss: 0.747
[57,     4] loss: 0.741
[58,     4] loss: 0.752
[59,     4] loss: 0.723
[60,     4] loss: 0.724
[61,     4] loss: 0.744
[62,     4] loss: 0.761
[63,     4] loss: 0.740
[64,     4] loss: 0.752
[65,     4] loss: 0.751
[66,     4] loss: 0.751
[67,     4] loss: 0.734
[68,     4] loss: 0.737
[69,     4] loss: 0.720
[70,     4] loss: 0.723
[71,     4] loss: 0.716
[72,     4] loss: 0.728
[73,     4] loss: 0.717
[74,     4] loss: 0.757
[75,     4] loss: 0.742
[76,     4] loss: 0.723
[77,     4] loss: 0.736
[78,     4] loss: 0.727
[79,     4] loss: 0.729
[80,     4] loss: 0.749
[81,     4] loss: 0.737
[82,     4] loss: 0.744
[83,     4] loss: 0.725
[84,     4] loss: 0.723
[85,     4] loss: 0.728
[86,     4] loss: 0.722
[87,     4] loss: 0.723
[88,     4] loss: 0.706
[89,     4] loss: 0.698
[90,     4] loss: 0.712
[91,     4] loss: 0.705
[92,     4] loss: 0.696
[93,     4] loss: 0.710
[94,     4] loss: 0.697
[95,     4] loss: 0.709
[96,     4] loss: 0.709
[97,     4] loss: 0.706
[98,     4] loss: 0.700
[99,     4] loss: 0.689
[100,     4] loss: 0.728
[101,     4] loss: 0.723
[102,     4] loss: 0.707
[103,     4] loss: 0.698
[104,     4] loss: 0.681
[105,     4] loss: 0.692
[106,     4] loss: 0.676
[107,     4] loss: 0.681
[108,     4] loss: 0.683
[109,     4] loss: 0.672
[110,     4] loss: 0.681
[111,     4] loss: 0.681
[112,     4] loss: 0.669
[113,     4] loss: 0.672
[114,     4] loss: 0.669
[115,     4] loss: 0.671
[116,     4] loss: 0.675
[117,     4] loss: 0.666
[118,     4] loss: 0.667
[119,     4] loss: 0.666
[120,     4] loss: 0.673
Early stopping applied (best metric=0.32715344429016113)
Finished Training
Total time taken: 60.2789466381073
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.384
[5,     4] loss: 1.384
[6,     4] loss: 1.383
[7,     4] loss: 1.380
[8,     4] loss: 1.378
[9,     4] loss: 1.369
[10,     4] loss: 1.363
[11,     4] loss: 1.353
[12,     4] loss: 1.345
[13,     4] loss: 1.322
[14,     4] loss: 1.306
[15,     4] loss: 1.285
[16,     4] loss: 1.263
[17,     4] loss: 1.197
[18,     4] loss: 1.187
[19,     4] loss: 1.174
[20,     4] loss: 1.134
[21,     4] loss: 1.124
[22,     4] loss: 1.092
[23,     4] loss: 1.062
[24,     4] loss: 1.011
[25,     4] loss: 1.028
[26,     4] loss: 0.952
[27,     4] loss: 0.986
[28,     4] loss: 0.900
[29,     4] loss: 0.919
[30,     4] loss: 0.876
[31,     4] loss: 0.884
[32,     4] loss: 0.829
[33,     4] loss: 0.828
[34,     4] loss: 0.819
[35,     4] loss: 0.790
[36,     4] loss: 0.788
[37,     4] loss: 0.781
[38,     4] loss: 0.792
[39,     4] loss: 0.756
[40,     4] loss: 0.778
[41,     4] loss: 0.751
[42,     4] loss: 0.764
[43,     4] loss: 0.755
[44,     4] loss: 0.747
[45,     4] loss: 0.747
[46,     4] loss: 0.766
[47,     4] loss: 0.754
[48,     4] loss: 0.752
[49,     4] loss: 0.776
[50,     4] loss: 0.734
[51,     4] loss: 0.738
[52,     4] loss: 0.737
[53,     4] loss: 0.719
[54,     4] loss: 0.756
[55,     4] loss: 0.738
[56,     4] loss: 0.745
[57,     4] loss: 0.725
[58,     4] loss: 0.738
[59,     4] loss: 0.726
[60,     4] loss: 0.748
[61,     4] loss: 0.722
[62,     4] loss: 0.737
[63,     4] loss: 0.736
[64,     4] loss: 0.734
[65,     4] loss: 0.755
[66,     4] loss: 0.728
Early stopping applied (best metric=0.47804689407348633)
Finished Training
Total time taken: 33.314631938934326
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.384
[3,     4] loss: 1.383
[4,     4] loss: 1.382
[5,     4] loss: 1.383
[6,     4] loss: 1.377
[7,     4] loss: 1.374
[8,     4] loss: 1.364
[9,     4] loss: 1.354
[10,     4] loss: 1.347
[11,     4] loss: 1.314
[12,     4] loss: 1.308
[13,     4] loss: 1.298
[14,     4] loss: 1.263
[15,     4] loss: 1.245
[16,     4] loss: 1.212
[17,     4] loss: 1.132
[18,     4] loss: 1.130
[19,     4] loss: 1.147
[20,     4] loss: 1.058
[21,     4] loss: 1.053
[22,     4] loss: 1.027
[23,     4] loss: 1.051
[24,     4] loss: 0.978
[25,     4] loss: 0.924
[26,     4] loss: 0.950
[27,     4] loss: 0.916
[28,     4] loss: 0.916
[29,     4] loss: 0.859
[30,     4] loss: 0.894
[31,     4] loss: 0.870
[32,     4] loss: 0.852
[33,     4] loss: 0.836
[34,     4] loss: 0.819
[35,     4] loss: 0.829
[36,     4] loss: 0.833
[37,     4] loss: 0.787
[38,     4] loss: 0.776
[39,     4] loss: 0.814
[40,     4] loss: 0.764
[41,     4] loss: 0.752
[42,     4] loss: 0.763
[43,     4] loss: 0.758
[44,     4] loss: 0.775
[45,     4] loss: 0.755
[46,     4] loss: 0.754
[47,     4] loss: 0.739
[48,     4] loss: 0.750
[49,     4] loss: 0.742
[50,     4] loss: 0.743
[51,     4] loss: 0.747
[52,     4] loss: 0.759
[53,     4] loss: 0.763
[54,     4] loss: 0.727
[55,     4] loss: 0.744
[56,     4] loss: 0.749
[57,     4] loss: 0.743
[58,     4] loss: 0.771
[59,     4] loss: 0.758
[60,     4] loss: 0.730
[61,     4] loss: 0.726
[62,     4] loss: 0.752
[63,     4] loss: 0.759
[64,     4] loss: 0.734
[65,     4] loss: 0.746
[66,     4] loss: 0.758
[67,     4] loss: 0.728
[68,     4] loss: 0.745
[69,     4] loss: 0.718
Early stopping applied (best metric=0.41200217604637146)
Finished Training
Total time taken: 35.01471209526062
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.388
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.386
[6,     4] loss: 1.382
[7,     4] loss: 1.375
[8,     4] loss: 1.375
[9,     4] loss: 1.369
[10,     4] loss: 1.363
[11,     4] loss: 1.338
[12,     4] loss: 1.321
[13,     4] loss: 1.304
[14,     4] loss: 1.290
[15,     4] loss: 1.246
[16,     4] loss: 1.221
[17,     4] loss: 1.227
[18,     4] loss: 1.157
[19,     4] loss: 1.132
[20,     4] loss: 1.108
[21,     4] loss: 1.077
[22,     4] loss: 1.025
[23,     4] loss: 1.009
[24,     4] loss: 0.998
[25,     4] loss: 1.046
[26,     4] loss: 0.962
[27,     4] loss: 1.010
[28,     4] loss: 0.964
[29,     4] loss: 0.959
[30,     4] loss: 0.939
[31,     4] loss: 0.929
[32,     4] loss: 0.937
[33,     4] loss: 0.925
[34,     4] loss: 0.834
[35,     4] loss: 0.890
[36,     4] loss: 0.845
[37,     4] loss: 0.827
[38,     4] loss: 0.841
[39,     4] loss: 0.872
[40,     4] loss: 0.876
[41,     4] loss: 0.905
[42,     4] loss: 0.850
[43,     4] loss: 0.845
[44,     4] loss: 0.877
[45,     4] loss: 0.935
[46,     4] loss: 0.864
[47,     4] loss: 0.869
[48,     4] loss: 0.881
[49,     4] loss: 0.856
[50,     4] loss: 0.809
[51,     4] loss: 0.840
[52,     4] loss: 0.804
[53,     4] loss: 0.782
[54,     4] loss: 0.769
[55,     4] loss: 0.831
[56,     4] loss: 0.766
[57,     4] loss: 0.832
[58,     4] loss: 0.798
[59,     4] loss: 0.774
[60,     4] loss: 0.756
[61,     4] loss: 0.781
Early stopping applied (best metric=0.5313952565193176)
Finished Training
Total time taken: 30.672500133514404
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.389
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.385
[5,     4] loss: 1.381
[6,     4] loss: 1.380
[7,     4] loss: 1.376
[8,     4] loss: 1.376
[9,     4] loss: 1.373
[10,     4] loss: 1.351
[11,     4] loss: 1.349
[12,     4] loss: 1.326
[13,     4] loss: 1.321
[14,     4] loss: 1.311
[15,     4] loss: 1.300
[16,     4] loss: 1.263
[17,     4] loss: 1.222
[18,     4] loss: 1.193
[19,     4] loss: 1.206
[20,     4] loss: 1.139
[21,     4] loss: 1.126
[22,     4] loss: 1.119
[23,     4] loss: 1.080
[24,     4] loss: 1.061
[25,     4] loss: 1.009
[26,     4] loss: 0.994
[27,     4] loss: 0.913
[28,     4] loss: 0.939
[29,     4] loss: 0.897
[30,     4] loss: 0.923
[31,     4] loss: 0.857
[32,     4] loss: 0.866
[33,     4] loss: 0.867
[34,     4] loss: 0.839
[35,     4] loss: 0.851
[36,     4] loss: 0.800
[37,     4] loss: 0.804
[38,     4] loss: 0.783
[39,     4] loss: 0.791
[40,     4] loss: 0.806
[41,     4] loss: 0.800
[42,     4] loss: 0.786
[43,     4] loss: 0.776
[44,     4] loss: 0.768
[45,     4] loss: 0.757
[46,     4] loss: 0.792
[47,     4] loss: 0.765
[48,     4] loss: 0.789
[49,     4] loss: 0.768
[50,     4] loss: 0.738
[51,     4] loss: 0.745
[52,     4] loss: 0.777
[53,     4] loss: 0.738
[54,     4] loss: 0.760
[55,     4] loss: 0.759
[56,     4] loss: 0.733
[57,     4] loss: 0.751
[58,     4] loss: 0.743
[59,     4] loss: 0.741
[60,     4] loss: 0.737
[61,     4] loss: 0.742
[62,     4] loss: 0.735
[63,     4] loss: 0.713
[64,     4] loss: 0.714
[65,     4] loss: 0.721
[66,     4] loss: 0.724
[67,     4] loss: 0.731
[68,     4] loss: 0.711
[69,     4] loss: 0.716
[70,     4] loss: 0.708
Early stopping applied (best metric=0.4826493561267853)
Finished Training
Total time taken: 35.17171859741211
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.388
[3,     4] loss: 1.389
[4,     4] loss: 1.386
[5,     4] loss: 1.382
[6,     4] loss: 1.384
[7,     4] loss: 1.377
[8,     4] loss: 1.383
[9,     4] loss: 1.370
[10,     4] loss: 1.370
[11,     4] loss: 1.364
[12,     4] loss: 1.350
[13,     4] loss: 1.342
[14,     4] loss: 1.321
[15,     4] loss: 1.325
[16,     4] loss: 1.290
[17,     4] loss: 1.258
[18,     4] loss: 1.229
[19,     4] loss: 1.204
[20,     4] loss: 1.198
[21,     4] loss: 1.161
[22,     4] loss: 1.120
[23,     4] loss: 1.074
[24,     4] loss: 1.068
[25,     4] loss: 1.022
[26,     4] loss: 1.029
[27,     4] loss: 0.987
[28,     4] loss: 0.992
[29,     4] loss: 0.986
[30,     4] loss: 0.922
[31,     4] loss: 0.892
[32,     4] loss: 0.865
[33,     4] loss: 0.879
[34,     4] loss: 0.973
[35,     4] loss: 0.887
[36,     4] loss: 0.903
[37,     4] loss: 0.821
[38,     4] loss: 0.862
[39,     4] loss: 0.843
[40,     4] loss: 0.833
[41,     4] loss: 0.804
[42,     4] loss: 0.853
[43,     4] loss: 0.809
[44,     4] loss: 0.779
[45,     4] loss: 0.765
[46,     4] loss: 0.754
[47,     4] loss: 0.746
[48,     4] loss: 0.769
[49,     4] loss: 0.777
[50,     4] loss: 0.746
[51,     4] loss: 0.744
[52,     4] loss: 0.770
[53,     4] loss: 0.754
[54,     4] loss: 0.757
[55,     4] loss: 0.723
[56,     4] loss: 0.723
[57,     4] loss: 0.724
[58,     4] loss: 0.701
[59,     4] loss: 0.708
[60,     4] loss: 0.701
[61,     4] loss: 0.713
[62,     4] loss: 0.722
[63,     4] loss: 0.728
[64,     4] loss: 0.698
[65,     4] loss: 0.729
[66,     4] loss: 0.696
[67,     4] loss: 0.730
[68,     4] loss: 0.707
[69,     4] loss: 0.690
[70,     4] loss: 0.692
[71,     4] loss: 0.684
[72,     4] loss: 0.680
[73,     4] loss: 0.701
[74,     4] loss: 0.670
Early stopping applied (best metric=0.33561038970947266)
Finished Training
Total time taken: 37.54784679412842
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.405
[2,     4] loss: 1.385
[3,     4] loss: 1.386
[4,     4] loss: 1.389
[5,     4] loss: 1.384
[6,     4] loss: 1.387
[7,     4] loss: 1.382
[8,     4] loss: 1.381
[9,     4] loss: 1.379
[10,     4] loss: 1.374
[11,     4] loss: 1.375
[12,     4] loss: 1.369
[13,     4] loss: 1.368
[14,     4] loss: 1.352
[15,     4] loss: 1.345
[16,     4] loss: 1.319
[17,     4] loss: 1.307
[18,     4] loss: 1.266
[19,     4] loss: 1.245
[20,     4] loss: 1.213
[21,     4] loss: 1.210
[22,     4] loss: 1.125
[23,     4] loss: 1.128
[24,     4] loss: 1.095
[25,     4] loss: 1.017
[26,     4] loss: 1.007
[27,     4] loss: 0.952
[28,     4] loss: 0.963
[29,     4] loss: 0.931
[30,     4] loss: 0.976
[31,     4] loss: 0.904
[32,     4] loss: 0.937
[33,     4] loss: 0.916
[34,     4] loss: 0.912
[35,     4] loss: 0.889
[36,     4] loss: 0.857
[37,     4] loss: 0.906
[38,     4] loss: 0.904
[39,     4] loss: 0.882
[40,     4] loss: 0.834
[41,     4] loss: 0.839
[42,     4] loss: 0.811
[43,     4] loss: 0.805
[44,     4] loss: 0.889
[45,     4] loss: 0.821
[46,     4] loss: 0.855
[47,     4] loss: 0.811
[48,     4] loss: 0.787
[49,     4] loss: 0.803
[50,     4] loss: 0.845
[51,     4] loss: 0.764
[52,     4] loss: 0.795
[53,     4] loss: 0.765
[54,     4] loss: 0.744
[55,     4] loss: 0.770
[56,     4] loss: 0.747
[57,     4] loss: 0.748
[58,     4] loss: 0.763
[59,     4] loss: 0.746
[60,     4] loss: 0.801
[61,     4] loss: 0.733
[62,     4] loss: 0.772
[63,     4] loss: 0.766
[64,     4] loss: 0.734
[65,     4] loss: 0.726
[66,     4] loss: 0.722
[67,     4] loss: 0.724
[68,     4] loss: 0.729
[69,     4] loss: 0.727
[70,     4] loss: 0.712
[71,     4] loss: 0.745
[72,     4] loss: 0.724
[73,     4] loss: 0.757
Early stopping applied (best metric=0.38763412833213806)
Finished Training
Total time taken: 36.72879481315613
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.385
[3,     4] loss: 1.380
[4,     4] loss: 1.389
[5,     4] loss: 1.383
[6,     4] loss: 1.378
[7,     4] loss: 1.375
[8,     4] loss: 1.377
[9,     4] loss: 1.360
[10,     4] loss: 1.351
[11,     4] loss: 1.344
[12,     4] loss: 1.318
[13,     4] loss: 1.285
[14,     4] loss: 1.276
[15,     4] loss: 1.252
[16,     4] loss: 1.235
[17,     4] loss: 1.200
[18,     4] loss: 1.216
[19,     4] loss: 1.150
[20,     4] loss: 1.134
[21,     4] loss: 1.105
[22,     4] loss: 1.049
[23,     4] loss: 1.023
[24,     4] loss: 1.020
[25,     4] loss: 1.000
[26,     4] loss: 0.989
[27,     4] loss: 0.955
[28,     4] loss: 0.964
[29,     4] loss: 0.935
[30,     4] loss: 0.858
[31,     4] loss: 0.947
[32,     4] loss: 0.887
[33,     4] loss: 0.851
[34,     4] loss: 0.946
[35,     4] loss: 0.839
[36,     4] loss: 0.851
[37,     4] loss: 0.837
[38,     4] loss: 0.869
[39,     4] loss: 0.793
[40,     4] loss: 0.894
[41,     4] loss: 0.820
[42,     4] loss: 0.830
[43,     4] loss: 0.821
[44,     4] loss: 0.832
[45,     4] loss: 0.788
[46,     4] loss: 0.762
[47,     4] loss: 0.759
[48,     4] loss: 0.767
[49,     4] loss: 0.758
[50,     4] loss: 0.741
[51,     4] loss: 0.776
[52,     4] loss: 0.739
[53,     4] loss: 0.736
[54,     4] loss: 0.729
[55,     4] loss: 0.734
[56,     4] loss: 0.748
[57,     4] loss: 0.752
[58,     4] loss: 0.737
[59,     4] loss: 0.733
[60,     4] loss: 0.726
[61,     4] loss: 0.725
[62,     4] loss: 0.711
[63,     4] loss: 0.708
[64,     4] loss: 0.729
[65,     4] loss: 0.712
[66,     4] loss: 0.734
[67,     4] loss: 0.711
Early stopping applied (best metric=0.4880617558956146)
Finished Training
Total time taken: 33.86165761947632
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.407
[2,     4] loss: 1.390
[3,     4] loss: 1.383
[4,     4] loss: 1.383
[5,     4] loss: 1.378
[6,     4] loss: 1.375
[7,     4] loss: 1.373
[8,     4] loss: 1.371
[9,     4] loss: 1.363
[10,     4] loss: 1.351
[11,     4] loss: 1.344
[12,     4] loss: 1.317
[13,     4] loss: 1.308
[14,     4] loss: 1.297
[15,     4] loss: 1.250
[16,     4] loss: 1.230
[17,     4] loss: 1.218
[18,     4] loss: 1.168
[19,     4] loss: 1.213
[20,     4] loss: 1.116
[21,     4] loss: 1.094
[22,     4] loss: 1.056
[23,     4] loss: 0.997
[24,     4] loss: 1.010
[25,     4] loss: 1.033
[26,     4] loss: 1.030
[27,     4] loss: 0.916
[28,     4] loss: 0.898
[29,     4] loss: 0.927
[30,     4] loss: 0.915
[31,     4] loss: 0.943
[32,     4] loss: 0.893
[33,     4] loss: 0.886
[34,     4] loss: 0.888
[35,     4] loss: 0.861
[36,     4] loss: 0.852
[37,     4] loss: 0.859
[38,     4] loss: 0.818
[39,     4] loss: 0.813
[40,     4] loss: 0.819
[41,     4] loss: 0.820
[42,     4] loss: 0.868
[43,     4] loss: 0.805
[44,     4] loss: 0.775
[45,     4] loss: 0.811
[46,     4] loss: 0.792
[47,     4] loss: 0.787
[48,     4] loss: 0.761
[49,     4] loss: 0.775
[50,     4] loss: 0.759
[51,     4] loss: 0.752
[52,     4] loss: 0.729
[53,     4] loss: 0.743
[54,     4] loss: 0.718
[55,     4] loss: 0.717
[56,     4] loss: 0.745
[57,     4] loss: 0.741
[58,     4] loss: 0.745
[59,     4] loss: 0.718
[60,     4] loss: 0.714
[61,     4] loss: 0.705
[62,     4] loss: 0.712
[63,     4] loss: 0.701
[64,     4] loss: 0.707
[65,     4] loss: 0.698
Early stopping applied (best metric=0.49492383003234863)
Finished Training
Total time taken: 33.11061763763428
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.381
[2,     4] loss: 1.387
[3,     4] loss: 1.390
[4,     4] loss: 1.390
[5,     4] loss: 1.385
[6,     4] loss: 1.381
[7,     4] loss: 1.380
[8,     4] loss: 1.376
[9,     4] loss: 1.372
[10,     4] loss: 1.362
[11,     4] loss: 1.355
[12,     4] loss: 1.342
[13,     4] loss: 1.325
[14,     4] loss: 1.308
[15,     4] loss: 1.309
[16,     4] loss: 1.265
[17,     4] loss: 1.237
[18,     4] loss: 1.250
[19,     4] loss: 1.191
[20,     4] loss: 1.173
[21,     4] loss: 1.117
[22,     4] loss: 1.118
[23,     4] loss: 1.179
[24,     4] loss: 1.045
[25,     4] loss: 1.096
[26,     4] loss: 1.015
[27,     4] loss: 1.012
[28,     4] loss: 1.018
[29,     4] loss: 0.960
[30,     4] loss: 0.918
[31,     4] loss: 0.958
[32,     4] loss: 0.938
[33,     4] loss: 0.895
[34,     4] loss: 0.903
[35,     4] loss: 0.862
[36,     4] loss: 0.890
[37,     4] loss: 0.883
[38,     4] loss: 0.835
[39,     4] loss: 0.824
[40,     4] loss: 0.817
[41,     4] loss: 0.813
[42,     4] loss: 0.806
[43,     4] loss: 0.794
[44,     4] loss: 0.773
[45,     4] loss: 0.782
[46,     4] loss: 0.758
[47,     4] loss: 0.772
[48,     4] loss: 0.746
[49,     4] loss: 0.767
[50,     4] loss: 0.728
[51,     4] loss: 0.758
[52,     4] loss: 0.739
[53,     4] loss: 0.739
[54,     4] loss: 0.734
[55,     4] loss: 0.749
[56,     4] loss: 0.751
[57,     4] loss: 0.732
[58,     4] loss: 0.720
[59,     4] loss: 0.730
[60,     4] loss: 0.733
[61,     4] loss: 0.736
[62,     4] loss: 0.734
[63,     4] loss: 0.730
[64,     4] loss: 0.742
[65,     4] loss: 0.734
[66,     4] loss: 0.742
[67,     4] loss: 0.726
[68,     4] loss: 0.787
[69,     4] loss: 0.755
[70,     4] loss: 0.759
[71,     4] loss: 0.769
[72,     4] loss: 0.757
Early stopping applied (best metric=0.3930242657661438)
Finished Training
Total time taken: 36.27177381515503
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.389
[3,     4] loss: 1.384
[4,     4] loss: 1.381
[5,     4] loss: 1.374
[6,     4] loss: 1.377
[7,     4] loss: 1.365
[8,     4] loss: 1.364
[9,     4] loss: 1.357
[10,     4] loss: 1.338
[11,     4] loss: 1.311
[12,     4] loss: 1.272
[13,     4] loss: 1.295
[14,     4] loss: 1.254
[15,     4] loss: 1.241
[16,     4] loss: 1.185
[17,     4] loss: 1.195
[18,     4] loss: 1.160
[19,     4] loss: 1.140
[20,     4] loss: 1.120
[21,     4] loss: 1.104
[22,     4] loss: 1.096
[23,     4] loss: 1.071
[24,     4] loss: 1.053
[25,     4] loss: 1.083
[26,     4] loss: 0.969
[27,     4] loss: 0.927
[28,     4] loss: 0.919
[29,     4] loss: 0.938
[30,     4] loss: 0.904
[31,     4] loss: 0.868
[32,     4] loss: 0.914
[33,     4] loss: 0.931
[34,     4] loss: 0.910
[35,     4] loss: 0.856
[36,     4] loss: 0.860
[37,     4] loss: 0.837
[38,     4] loss: 0.857
[39,     4] loss: 0.855
[40,     4] loss: 0.818
[41,     4] loss: 0.789
[42,     4] loss: 0.813
[43,     4] loss: 0.798
[44,     4] loss: 0.819
[45,     4] loss: 0.850
[46,     4] loss: 0.834
[47,     4] loss: 0.810
[48,     4] loss: 0.781
[49,     4] loss: 0.795
[50,     4] loss: 0.800
[51,     4] loss: 0.754
[52,     4] loss: 0.790
[53,     4] loss: 0.783
[54,     4] loss: 0.779
[55,     4] loss: 0.805
[56,     4] loss: 0.838
[57,     4] loss: 0.805
[58,     4] loss: 0.792
[59,     4] loss: 0.776
[60,     4] loss: 0.773
[61,     4] loss: 0.810
[62,     4] loss: 0.823
[63,     4] loss: 0.756
Early stopping applied (best metric=0.5159083604812622)
Finished Training
Total time taken: 32.009565114974976
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.388
[3,     4] loss: 1.387
[4,     4] loss: 1.383
[5,     4] loss: 1.385
[6,     4] loss: 1.383
[7,     4] loss: 1.385
[8,     4] loss: 1.381
[9,     4] loss: 1.380
[10,     4] loss: 1.378
[11,     4] loss: 1.371
[12,     4] loss: 1.362
[13,     4] loss: 1.351
[14,     4] loss: 1.342
[15,     4] loss: 1.317
[16,     4] loss: 1.299
[17,     4] loss: 1.311
[18,     4] loss: 1.283
[19,     4] loss: 1.262
[20,     4] loss: 1.245
[21,     4] loss: 1.186
[22,     4] loss: 1.144
[23,     4] loss: 1.087
[24,     4] loss: 1.091
[25,     4] loss: 1.042
[26,     4] loss: 1.020
[27,     4] loss: 0.984
[28,     4] loss: 0.942
[29,     4] loss: 0.938
[30,     4] loss: 0.929
[31,     4] loss: 0.887
[32,     4] loss: 0.898
[33,     4] loss: 0.869
[34,     4] loss: 0.876
[35,     4] loss: 0.820
[36,     4] loss: 0.823
[37,     4] loss: 0.796
[38,     4] loss: 0.820
[39,     4] loss: 0.807
[40,     4] loss: 0.791
[41,     4] loss: 0.783
[42,     4] loss: 0.785
[43,     4] loss: 0.743
[44,     4] loss: 0.766
[45,     4] loss: 0.773
[46,     4] loss: 0.757
[47,     4] loss: 0.792
[48,     4] loss: 0.733
[49,     4] loss: 0.737
[50,     4] loss: 0.735
[51,     4] loss: 0.704
[52,     4] loss: 0.717
[53,     4] loss: 0.708
[54,     4] loss: 0.700
[55,     4] loss: 0.700
[56,     4] loss: 0.687
[57,     4] loss: 0.692
[58,     4] loss: 0.686
[59,     4] loss: 0.717
[60,     4] loss: 0.710
[61,     4] loss: 0.693
[62,     4] loss: 0.684
[63,     4] loss: 0.697
[64,     4] loss: 0.689
[65,     4] loss: 0.675
[66,     4] loss: 0.668
[67,     4] loss: 0.663
[68,     4] loss: 0.669
[69,     4] loss: 0.676
[70,     4] loss: 0.667
[71,     4] loss: 0.676
[72,     4] loss: 0.676
[73,     4] loss: 0.664
Early stopping applied (best metric=0.4368281960487366)
Finished Training
Total time taken: 36.810802936553955
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.370
[2,     4] loss: 1.388
[3,     4] loss: 1.390
[4,     4] loss: 1.384
[5,     4] loss: 1.387
[6,     4] loss: 1.383
[7,     4] loss: 1.372
[8,     4] loss: 1.368
[9,     4] loss: 1.360
[10,     4] loss: 1.354
[11,     4] loss: 1.340
[12,     4] loss: 1.312
[13,     4] loss: 1.297
[14,     4] loss: 1.267
[15,     4] loss: 1.246
[16,     4] loss: 1.258
[17,     4] loss: 1.191
[18,     4] loss: 1.193
[19,     4] loss: 1.162
[20,     4] loss: 1.119
[21,     4] loss: 1.120
[22,     4] loss: 1.076
[23,     4] loss: 1.039
[24,     4] loss: 1.032
[25,     4] loss: 0.938
[26,     4] loss: 0.948
[27,     4] loss: 0.904
[28,     4] loss: 0.915
[29,     4] loss: 0.863
[30,     4] loss: 0.866
[31,     4] loss: 0.809
[32,     4] loss: 0.810
[33,     4] loss: 0.818
[34,     4] loss: 0.785
[35,     4] loss: 0.786
[36,     4] loss: 0.839
[37,     4] loss: 0.809
[38,     4] loss: 0.771
[39,     4] loss: 0.774
[40,     4] loss: 0.739
[41,     4] loss: 0.772
[42,     4] loss: 0.798
[43,     4] loss: 0.786
[44,     4] loss: 0.789
[45,     4] loss: 0.764
[46,     4] loss: 0.761
[47,     4] loss: 0.798
[48,     4] loss: 0.797
[49,     4] loss: 0.807
[50,     4] loss: 0.770
[51,     4] loss: 0.763
[52,     4] loss: 0.734
[53,     4] loss: 0.760
[54,     4] loss: 0.739
[55,     4] loss: 0.742
[56,     4] loss: 0.719
[57,     4] loss: 0.735
[58,     4] loss: 0.720
[59,     4] loss: 0.717
[60,     4] loss: 0.731
[61,     4] loss: 0.732
[62,     4] loss: 0.737
[63,     4] loss: 0.737
[64,     4] loss: 0.730
Early stopping applied (best metric=0.5181354284286499)
Finished Training
Total time taken: 32.32458233833313
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.387
[3,     4] loss: 1.387
[4,     4] loss: 1.386
[5,     4] loss: 1.384
[6,     4] loss: 1.382
[7,     4] loss: 1.380
[8,     4] loss: 1.379
[9,     4] loss: 1.374
[10,     4] loss: 1.367
[11,     4] loss: 1.356
[12,     4] loss: 1.338
[13,     4] loss: 1.337
[14,     4] loss: 1.330
[15,     4] loss: 1.308
[16,     4] loss: 1.295
[17,     4] loss: 1.286
[18,     4] loss: 1.271
[19,     4] loss: 1.227
[20,     4] loss: 1.217
[21,     4] loss: 1.174
[22,     4] loss: 1.173
[23,     4] loss: 1.195
[24,     4] loss: 1.140
[25,     4] loss: 1.109
[26,     4] loss: 1.104
[27,     4] loss: 1.103
[28,     4] loss: 1.076
[29,     4] loss: 1.043
[30,     4] loss: 1.000
[31,     4] loss: 0.958
[32,     4] loss: 0.933
[33,     4] loss: 0.970
[34,     4] loss: 0.960
[35,     4] loss: 0.918
[36,     4] loss: 0.902
[37,     4] loss: 0.856
[38,     4] loss: 0.847
[39,     4] loss: 0.898
[40,     4] loss: 0.843
[41,     4] loss: 0.891
[42,     4] loss: 0.817
[43,     4] loss: 0.817
[44,     4] loss: 0.814
[45,     4] loss: 0.834
[46,     4] loss: 0.808
[47,     4] loss: 0.803
[48,     4] loss: 0.828
[49,     4] loss: 0.830
[50,     4] loss: 0.775
[51,     4] loss: 0.786
[52,     4] loss: 0.776
[53,     4] loss: 0.768
[54,     4] loss: 0.788
[55,     4] loss: 0.767
[56,     4] loss: 0.774
[57,     4] loss: 0.765
[58,     4] loss: 0.783
[59,     4] loss: 0.779
[60,     4] loss: 0.761
[61,     4] loss: 0.752
[62,     4] loss: 0.746
[63,     4] loss: 0.759
[64,     4] loss: 0.741
[65,     4] loss: 0.729
[66,     4] loss: 0.777
[67,     4] loss: 0.738
[68,     4] loss: 0.725
[69,     4] loss: 0.769
[70,     4] loss: 0.768
[71,     4] loss: 0.733
[72,     4] loss: 0.788
[73,     4] loss: 0.780
[74,     4] loss: 0.712
Early stopping applied (best metric=0.44901421666145325)
Finished Training
Total time taken: 37.11681890487671
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.384
[2,     4] loss: 1.385
[3,     4] loss: 1.384
[4,     4] loss: 1.382
[5,     4] loss: 1.383
[6,     4] loss: 1.379
[7,     4] loss: 1.379
[8,     4] loss: 1.367
[9,     4] loss: 1.366
[10,     4] loss: 1.354
[11,     4] loss: 1.347
[12,     4] loss: 1.330
[13,     4] loss: 1.332
[14,     4] loss: 1.295
[15,     4] loss: 1.267
[16,     4] loss: 1.271
[17,     4] loss: 1.243
[18,     4] loss: 1.215
[19,     4] loss: 1.173
[20,     4] loss: 1.173
[21,     4] loss: 1.107
[22,     4] loss: 1.107
[23,     4] loss: 1.166
[24,     4] loss: 1.046
[25,     4] loss: 1.094
[26,     4] loss: 1.013
[27,     4] loss: 0.988
[28,     4] loss: 0.931
[29,     4] loss: 0.947
[30,     4] loss: 0.917
[31,     4] loss: 0.918
[32,     4] loss: 0.917
[33,     4] loss: 0.903
[34,     4] loss: 0.882
[35,     4] loss: 0.867
[36,     4] loss: 0.830
[37,     4] loss: 0.796
[38,     4] loss: 0.791
[39,     4] loss: 0.819
[40,     4] loss: 0.831
[41,     4] loss: 0.815
[42,     4] loss: 0.823
[43,     4] loss: 0.810
[44,     4] loss: 0.775
[45,     4] loss: 0.759
[46,     4] loss: 0.798
[47,     4] loss: 0.788
[48,     4] loss: 0.855
[49,     4] loss: 0.802
[50,     4] loss: 0.774
[51,     4] loss: 0.772
[52,     4] loss: 0.780
[53,     4] loss: 0.739
[54,     4] loss: 0.771
[55,     4] loss: 0.731
[56,     4] loss: 0.729
[57,     4] loss: 0.732
[58,     4] loss: 0.739
[59,     4] loss: 0.727
[60,     4] loss: 0.707
[61,     4] loss: 0.709
[62,     4] loss: 0.746
[63,     4] loss: 0.740
[64,     4] loss: 0.719
[65,     4] loss: 0.709
[66,     4] loss: 0.703
[67,     4] loss: 0.709
[68,     4] loss: 0.701
Early stopping applied (best metric=0.4951342046260834)
Finished Training
Total time taken: 34.22567558288574
{'Hydroxylation-K Validation Accuracy': 0.7575945626477542, 'Hydroxylation-K Validation Sensitivity': 0.6577777777777778, 'Hydroxylation-K Validation Specificity': 0.7824561403508772, 'Hydroxylation-K Validation Precision': 0.4391522366522366, 'Hydroxylation-K AUC ROC': 0.7726900584795322, 'Hydroxylation-K AUC PR': 0.5036577051606252, 'Hydroxylation-K MCC': 0.387048512073266, 'Hydroxylation-K F1': 0.5223317848605205, 'Validation Loss (Hydroxylation-K)': 0.449701460202535, 'Methylation-K Validation Accuracy': 0.842703357519536, 'Methylation-K Validation Sensitivity': 0.09761758865116034, 'Methylation-K Validation Specificity': 0.9235095852954885, 'Methylation-K Validation Precision': 0.1236210744143891, 'Methylation-K AUC ROC': 0.5409551468544098, 'Methylation-K AUC PR': 0.1121347601215208, 'Methylation-K MCC': 0.023664190793138924, 'Methylation-K F1': 0.10314953609602738, 'Validation Loss (Methylation-K)': 0.7413063724835713, 'Validation Loss (total)': 1.1910078128178914, 'TimeToTrain': 36.29737633069356}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012798615090228943,
 'learning_rate_Hydroxylation-K': 0.00366919413916098,
 'learning_rate_Methylation-K': 0.009537033940084778,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21546455240804055,
 'loss_weight_Methylation-K': 0.4692628054828139,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 940187746,
 'sample_weights': [0.6696375238273947, 0.5862875852880762],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.327345540635465,
 'weight_decay_Hydroxylation-K': 8.499921798253562,
 'weight_decay_Methylation-K': 9.234376732564073}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.390
[3,     4] loss: 1.383
[4,     4] loss: 1.379
[5,     4] loss: 1.368
[6,     4] loss: 1.341
[7,     4] loss: 1.319
[8,     4] loss: 1.279
[9,     4] loss: 1.268
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.007233675941830433,
 'learning_rate_Hydroxylation-K': 0.007674257547211785,
 'learning_rate_Methylation-K': 0.0023637963786651926,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7906270773473387,
 'loss_weight_Methylation-K': 0.09017963793852096,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2206296583,
 'sample_weights': [0.21546455240804055, 0.4692628054828139],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.7561086921935285,
 'weight_decay_Hydroxylation-K': 1.1848135655710896,
 'weight_decay_Methylation-K': 0.7624889575843321}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.383
[3,     4] loss: 1.399
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008280005685253363,
 'learning_rate_Hydroxylation-K': 0.008690198288848481,
 'learning_rate_Methylation-K': 0.002135789019830659,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.40587791355200786,
 'loss_weight_Methylation-K': 0.925045553082045,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 73719947,
 'sample_weights': [0.7906270773473387, 0.09017963793852096],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.876428761248319,
 'weight_decay_Hydroxylation-K': 2.6620837821027914,
 'weight_decay_Methylation-K': 4.450520958562723}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.386
[3,     4] loss: 1.382
[4,     4] loss: 1.382
[5,     4] loss: 1.379
[6,     4] loss: 1.372
[7,     4] loss: 1.361
[8,     4] loss: 1.333
[9,     4] loss: 1.320
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00047854797287159357,
 'learning_rate_Hydroxylation-K': 0.0020978618914292016,
 'learning_rate_Methylation-K': 5.380823482666031e-05,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6200865003211906,
 'loss_weight_Methylation-K': 0.07712822348893976,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 599814554,
 'sample_weights': [0.40587791355200786, 0.925045553082045],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.8222842407048345,
 'weight_decay_Hydroxylation-K': 9.955190971114513,
 'weight_decay_Methylation-K': 9.565172348446135}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.382
[3,     4] loss: 1.396
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023308767727066282,
 'learning_rate_Hydroxylation-K': 0.001410936506075034,
 'learning_rate_Methylation-K': 0.00497612229503232,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.29271537220736604,
 'loss_weight_Methylation-K': 0.23253823166565057,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1006871097,
 'sample_weights': [0.6200865003211906, 0.07712822348893976],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.963500502625341,
 'weight_decay_Hydroxylation-K': 5.384170683018288,
 'weight_decay_Methylation-K': 5.880373277617084}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.388
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023230211199868835,
 'learning_rate_Hydroxylation-K': 0.008734090061400586,
 'learning_rate_Methylation-K': 0.004414801421796391,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.11348029382506261,
 'loss_weight_Methylation-K': 0.76719732391758,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1991796731,
 'sample_weights': [0.29271537220736604, 0.23253823166565057],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.897929857974884,
 'weight_decay_Hydroxylation-K': 5.23073175400488,
 'weight_decay_Methylation-K': 4.691789779113596}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.381
[5,     4] loss: 1.374
[6,     4] loss: 1.345
[7,     4] loss: 1.292
[8,     4] loss: 1.258
[9,     4] loss: 1.186
[10,     4] loss: 1.115
[11,     4] loss: 1.155
[12,     4] loss: 1.113
[13,     4] loss: 1.071
[14,     4] loss: 1.073
[15,     4] loss: 1.067
[16,     4] loss: 1.042
[17,     4] loss: 0.997
[18,     4] loss: 0.941
[19,     4] loss: 0.881
[20,     4] loss: 0.839
[21,     4] loss: 0.958
[22,     4] loss: 1.030
[23,     4] loss: 0.985
[24,     4] loss: 0.888
[25,     4] loss: 0.914
[26,     4] loss: 0.867
[27,     4] loss: 0.857
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004762811586475691,
 'learning_rate_Hydroxylation-K': 0.009644439219798918,
 'learning_rate_Methylation-K': 0.0007489571389758886,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8518417821398832,
 'loss_weight_Methylation-K': 0.007188099621063537,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2492202071,
 'sample_weights': [0.11348029382506261, 0.76719732391758],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.97861874027532,
 'weight_decay_Hydroxylation-K': 6.892306534396262,
 'weight_decay_Methylation-K': 9.607894293207128}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.388
[5,     4] loss: 1.390
[6,     4] loss: 1.386
[7,     4] loss: 1.386
[8,     4] loss: 1.385
[9,     4] loss: 1.382
[10,     4] loss: 1.374
[11,     4] loss: 1.353
[12,     4] loss: 1.298
[13,     4] loss: 1.285
[14,     4] loss: 1.212
[15,     4] loss: 1.182
[16,     4] loss: 1.165
[17,     4] loss: 1.147
[18,     4] loss: 1.044
[19,     4] loss: 1.056
[20,     4] loss: 1.085
[21,     4] loss: 1.168
[22,     4] loss: 1.155
[23,     4] loss: 0.993
[24,     4] loss: 1.137
[25,     4] loss: 1.391
[26,     4] loss: 1.300
[27,     4] loss: 1.321
[28,     4] loss: 1.317
[29,     4] loss: 1.289
[30,     4] loss: 1.216
[31,     4] loss: 1.133
[32,     4] loss: 1.085
[33,     4] loss: 1.154
[34,     4] loss: 1.096
[35,     4] loss: 1.050
[36,     4] loss: 1.060
[37,     4] loss: 1.128
[38,     4] loss: 1.093
[39,     4] loss: 1.012
[40,     4] loss: 1.108
[41,     4] loss: 1.131
[42,     4] loss: 1.058
[43,     4] loss: 1.021
[44,     4] loss: 1.008
[45,     4] loss: 1.029
[46,     4] loss: 0.999
[47,     4] loss: 0.968
[48,     4] loss: 0.928
[49,     4] loss: 1.015
[50,     4] loss: 1.145
[51,     4] loss: 1.141
[52,     4] loss: 1.014
[53,     4] loss: 1.001
[54,     4] loss: 1.003
[55,     4] loss: 0.951
[56,     4] loss: 0.935
[57,     4] loss: 1.397
[58,     4] loss: 1.413
[59,     4] loss: 1.350
[60,     4] loss: 1.375
[61,     4] loss: 1.373
[62,     4] loss: 1.367
[63,     4] loss: 1.358
[64,     4] loss: 1.346
[65,     4] loss: 1.302
[66,     4] loss: 1.293
[67,     4] loss: 1.220
[68,     4] loss: 1.253
[69,     4] loss: 1.229
[70,     4] loss: 1.193
[71,     4] loss: 1.203
[72,     4] loss: 1.193
[73,     4] loss: 1.189
[74,     4] loss: 1.270
[75,     4] loss: 1.360
[76,     4] loss: 1.380
[77,     4] loss: 1.384
[78,     4] loss: 1.385
[79,     4] loss: 1.392
[80,     4] loss: 1.387
[81,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004277909389326909,
 'learning_rate_Hydroxylation-K': 0.005449496764645452,
 'learning_rate_Methylation-K': 0.004544758075373402,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4122102581689632,
 'loss_weight_Methylation-K': 0.49568057857281334,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2609296111,
 'sample_weights': [0.8518417821398832, 0.007188099621063537],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9548348885210389,
 'weight_decay_Hydroxylation-K': 2.9077652461241588,
 'weight_decay_Methylation-K': 9.75444537633069}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.392
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003865077050919157,
 'learning_rate_Hydroxylation-K': 0.00280989513038229,
 'learning_rate_Methylation-K': 0.006075342042554074,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.903079187354279,
 'loss_weight_Methylation-K': 0.9560417025914267,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3024001244,
 'sample_weights': [0.4122102581689632, 0.49568057857281334],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.73218012235537,
 'weight_decay_Hydroxylation-K': 5.196078011967372,
 'weight_decay_Methylation-K': 0.9465859236943801}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.424
[2,     4] loss: 1.392
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0033439926832475493,
 'learning_rate_Hydroxylation-K': 0.005218738106615323,
 'learning_rate_Methylation-K': 0.0058108281093946995,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.41344549019831855,
 'loss_weight_Methylation-K': 0.8093113673217118,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3363391774,
 'sample_weights': [0.903079187354279, 0.9560417025914267],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.648098184499872,
 'weight_decay_Hydroxylation-K': 5.094812954609835,
 'weight_decay_Methylation-K': 3.8289415102810396}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.387
[3,     4] loss: 1.380
[4,     4] loss: 1.368
[5,     4] loss: 1.351
[6,     4] loss: 1.276
[7,     4] loss: 1.232
[8,     4] loss: 1.203
[9,     4] loss: 1.175
[10,     4] loss: 1.200
[11,     4] loss: 1.161
[12,     4] loss: 1.083
[13,     4] loss: 1.066
[14,     4] loss: 1.020
[15,     4] loss: 1.019
[16,     4] loss: 1.068
[17,     4] loss: 1.082
[18,     4] loss: 1.033
[19,     4] loss: 1.041
[20,     4] loss: 0.942
[21,     4] loss: 0.946
[22,     4] loss: 0.983
[23,     4] loss: 0.953
[24,     4] loss: 0.973
[25,     4] loss: 0.912
[26,     4] loss: 0.848
[27,     4] loss: 1.020
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009330815478634413,
 'learning_rate_Hydroxylation-K': 0.0036204005386301823,
 'learning_rate_Methylation-K': 0.005474411334559323,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.39285424786228995,
 'loss_weight_Methylation-K': 0.8992331357038517,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2680241560,
 'sample_weights': [0.41344549019831855, 0.8093113673217118],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.858650271325853,
 'weight_decay_Hydroxylation-K': 2.855699238264252,
 'weight_decay_Methylation-K': 9.154542890143123}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.402
[2,     4] loss: 1.388
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0028863914912459366,
 'learning_rate_Hydroxylation-K': 0.0014494378716085226,
 'learning_rate_Methylation-K': 0.004267645850941701,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24210085613560967,
 'loss_weight_Methylation-K': 0.2717292682732695,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 454574396,
 'sample_weights': [0.39285424786228995, 0.8992331357038517],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.4806241264014406,
 'weight_decay_Hydroxylation-K': 5.4952358824155,
 'weight_decay_Methylation-K': 7.691489082366257}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.383
[3,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006035401132982967,
 'learning_rate_Hydroxylation-K': 0.0063531796260794075,
 'learning_rate_Methylation-K': 0.005298517946611056,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.26813121223139463,
 'loss_weight_Methylation-K': 0.4251701091031702,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 88574206,
 'sample_weights': [0.24210085613560967, 0.2717292682732695],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.82633922819647,
 'weight_decay_Hydroxylation-K': 9.657417410500845,
 'weight_decay_Methylation-K': 2.3810989792037445}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.384
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.004534936536704732,
 'learning_rate_Hydroxylation-K': 0.007424922352617316,
 'learning_rate_Methylation-K': 0.005299557688024129,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4209540448097263,
 'loss_weight_Methylation-K': 0.43421824846104895,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2686707255,
 'sample_weights': [0.26813121223139463, 0.4251701091031702],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.91244485418489,
 'weight_decay_Hydroxylation-K': 5.853718026631132,
 'weight_decay_Methylation-K': 2.6459790809642776}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.385
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002933715040238872,
 'learning_rate_Hydroxylation-K': 0.009769291497394056,
 'learning_rate_Methylation-K': 0.0008391495139274506,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9317516520287425,
 'loss_weight_Methylation-K': 0.0654940311328856,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3249596003,
 'sample_weights': [0.4209540448097263, 0.43421824846104895],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.366431341066313,
 'weight_decay_Hydroxylation-K': 4.045899468090099,
 'weight_decay_Methylation-K': 9.998253006931014}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.383
[3,     4] loss: 1.390
[4,     4] loss: 1.384
[5,     4] loss: 1.384
[6,     4] loss: 1.380
[7,     4] loss: 1.355
[8,     4] loss: 1.321
[9,     4] loss: 1.273
[10,     4] loss: 1.243
[11,     4] loss: 1.315
[12,     4] loss: 1.209
[13,     4] loss: 1.162
[14,     4] loss: 1.053
[15,     4] loss: 0.985
[16,     4] loss: 1.494
[17,     4] loss: 1.267
[18,     4] loss: 1.294
[19,     4] loss: 1.245
[20,     4] loss: 1.261
[21,     4] loss: 1.250
[22,     4] loss: 1.164
[23,     4] loss: 1.102
[24,     4] loss: 1.054
[25,     4] loss: 1.008
[26,     4] loss: 1.026
[27,     4] loss: 0.971
[28,     4] loss: 0.981
[29,     4] loss: 0.922
[30,     4] loss: 0.893
[31,     4] loss: 0.878
[32,     4] loss: 0.949
[33,     4] loss: 0.911
[34,     4] loss: 0.954
[35,     4] loss: 0.888
[36,     4] loss: 0.830
[37,     4] loss: 1.009
[38,     4] loss: 0.927
[39,     4] loss: 0.878
[40,     4] loss: 0.837
[41,     4] loss: 0.804
[42,     4] loss: 0.756
[43,     4] loss: 0.821
[44,     4] loss: 0.799
[45,     4] loss: 0.922
[46,     4] loss: 0.811
[47,     4] loss: 0.876
[48,     4] loss: 0.839
[49,     4] loss: 0.838
[50,     4] loss: 0.880
[51,     4] loss: 0.922
[52,     4] loss: 0.851
[53,     4] loss: 0.808
[54,     4] loss: 0.927
[55,     4] loss: 0.804
[56,     4] loss: 0.840
[57,     4] loss: 0.863
[58,     4] loss: 0.850
[59,     4] loss: 0.942
[60,     4] loss: 0.920
[61,     4] loss: 0.843
[62,     4] loss: 0.914
[63,     4] loss: 0.913
[64,     4] loss: 0.931
[65,     4] loss: 0.974
[66,     4] loss: 0.963
[67,     4] loss: 0.972
[68,     4] loss: 0.927
[69,     4] loss: 0.825
[70,     4] loss: 0.808
[71,     4] loss: 0.848
[72,     4] loss: 0.880
[73,     4] loss: 0.819
[74,     4] loss: 0.788
[75,     4] loss: 0.783
[76,     4] loss: 0.775
[77,     4] loss: 0.793
[78,     4] loss: 0.798
[79,     4] loss: 0.858
[80,     4] loss: 0.801
[81,     4] loss: 0.848
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0038999783340617237,
 'learning_rate_Hydroxylation-K': 0.0001279806690943576,
 'learning_rate_Methylation-K': 0.0006298163905139728,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.03427552577510307,
 'loss_weight_Methylation-K': 0.6171634791075545,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 247952282,
 'sample_weights': [0.9317516520287425, 0.0654940311328856],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.564403528465905,
 'weight_decay_Hydroxylation-K': 3.1509295638872006,
 'weight_decay_Methylation-K': 4.478863483140092}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.393
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0001604922034809204,
 'learning_rate_Hydroxylation-K': 0.0009692988387890403,
 'learning_rate_Methylation-K': 0.00949675317933708,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2190549407157838,
 'loss_weight_Methylation-K': 0.38479997760097817,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1709296360,
 'sample_weights': [0.03427552577510307, 0.6171634791075545],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.042751071561696,
 'weight_decay_Hydroxylation-K': 8.087541881129948,
 'weight_decay_Methylation-K': 6.7946332537862935}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.387
[3,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00011641755327651917,
 'learning_rate_Hydroxylation-K': 0.00441943909406072,
 'learning_rate_Methylation-K': 0.0012787520701374325,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.13221739290381526,
 'loss_weight_Methylation-K': 0.2560744239159807,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 739004920,
 'sample_weights': [0.2190549407157838, 0.38479997760097817],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.257148709862794,
 'weight_decay_Hydroxylation-K': 6.666524987062672,
 'weight_decay_Methylation-K': 7.047767561810811}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.383
[3,     4] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006403198482495762,
 'learning_rate_Hydroxylation-K': 0.00428965483062713,
 'learning_rate_Methylation-K': 0.004536769988834427,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9478279505949111,
 'loss_weight_Methylation-K': 0.9698646673673327,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1567298640,
 'sample_weights': [0.13221739290381526, 0.2560744239159807],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.8335638640521905,
 'weight_decay_Hydroxylation-K': 5.354095711865443,
 'weight_decay_Methylation-K': 0.5265477275066628}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.377
[2,     4] loss: 1.385
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0016483008285098765,
 'learning_rate_Hydroxylation-K': 0.004216939522328119,
 'learning_rate_Methylation-K': 0.00273495618991747,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4258202924818282,
 'loss_weight_Methylation-K': 0.28657340251461494,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2865049321,
 'sample_weights': [0.9478279505949111, 0.9698646673673327],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.671668871352106,
 'weight_decay_Hydroxylation-K': 6.334924619215748,
 'weight_decay_Methylation-K': 6.276460636427247}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.387
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003056159674716807,
 'learning_rate_Hydroxylation-K': 0.009067777092888994,
 'learning_rate_Methylation-K': 0.006918460854137581,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.23284592872883925,
 'loss_weight_Methylation-K': 0.996373101091671,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2212290320,
 'sample_weights': [0.4258202924818282, 0.28657340251461494],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.435005268948576,
 'weight_decay_Hydroxylation-K': 3.4618486874618624,
 'weight_decay_Methylation-K': 2.06861398335894}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.385
[3,     4] loss: 1.387
[4,     4] loss: 1.383
[5,     4] loss: 1.388
[6,     4] loss: 1.378
[7,     4] loss: 1.369
[8,     4] loss: 1.325
[9,     4] loss: 1.283
[10,     4] loss: 1.255
[11,     4] loss: 1.219
[12,     4] loss: 1.206
[13,     4] loss: 1.171
[14,     4] loss: 1.140
[15,     4] loss: 1.062
[16,     4] loss: 1.186
[17,     4] loss: 1.156
[18,     4] loss: 1.172
[19,     4] loss: 1.188
[20,     4] loss: 1.146
[21,     4] loss: 1.083
[22,     4] loss: 1.027
[23,     4] loss: 0.963
[24,     4] loss: 0.912
[25,     4] loss: 0.948
[26,     4] loss: 0.985
[27,     4] loss: 1.027
[28,     4] loss: 0.975
[29,     4] loss: 0.880
[30,     4] loss: 0.898
[31,     4] loss: 0.890
[32,     4] loss: 0.912
[33,     4] loss: 0.927
[34,     4] loss: 0.871
[35,     4] loss: 0.812
[36,     4] loss: 0.991
[37,     4] loss: 0.967
[38,     4] loss: 1.067
[39,     4] loss: 0.976
[40,     4] loss: 0.949
[41,     4] loss: 0.923
[42,     4] loss: 0.840
[43,     4] loss: 0.826
[44,     4] loss: 0.868
[45,     4] loss: 1.101
[46,     4] loss: 0.947
[47,     4] loss: 0.986
[48,     4] loss: 0.856
[49,     4] loss: 0.840
[50,     4] loss: 0.808
[51,     4] loss: 0.856
[52,     4] loss: 0.903
[53,     4] loss: 0.865
[54,     4] loss: 0.835
[55,     4] loss: 0.818
[56,     4] loss: 0.817
[57,     4] loss: 0.810
[58,     4] loss: 0.861
[59,     4] loss: 0.800
[60,     4] loss: 0.782
[61,     4] loss: 0.833
[62,     4] loss: 0.872
[63,     4] loss: 0.807
[64,     4] loss: 0.833
[65,     4] loss: 0.811
[66,     4] loss: 0.827
[67,     4] loss: 1.080
[68,     4] loss: 1.052
[69,     4] loss: 0.911
[70,     4] loss: 0.835
[71,     4] loss: 0.891
[72,     4] loss: 0.869
[73,     4] loss: 0.861
[74,     4] loss: 0.871
[75,     4] loss: 0.797
[76,     4] loss: 0.794
[77,     4] loss: 0.810
[78,     4] loss: 0.850
[79,     4] loss: 0.803
[80,     4] loss: 0.902
[81,     4] loss: 1.005
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027766317525890734,
 'learning_rate_Hydroxylation-K': 0.008454127706522468,
 'learning_rate_Methylation-K': 0.0027240320737156056,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9767130446034195,
 'loss_weight_Methylation-K': 0.04388931731355632,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1216026835,
 'sample_weights': [0.23284592872883925, 0.996373101091671],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.070552806891692,
 'weight_decay_Hydroxylation-K': 7.7952760743605065,
 'weight_decay_Methylation-K': 6.776037588260754}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.383
[3,     4] loss: 1.379
[4,     4] loss: 1.360
[5,     4] loss: 1.328
[6,     4] loss: 1.267
[7,     4] loss: 1.230
[8,     4] loss: 1.118
[9,     4] loss: 1.140
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025004189097347536,
 'learning_rate_Hydroxylation-K': 0.002816723924378199,
 'learning_rate_Methylation-K': 0.0004717545763635886,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24819536121086466,
 'loss_weight_Methylation-K': 0.4158294616103146,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3042175444,
 'sample_weights': [0.9767130446034195, 0.04388931731355632],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.238905568993319,
 'weight_decay_Hydroxylation-K': 4.209981971919742,
 'weight_decay_Methylation-K': 3.934376559309868}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.390
[3,     4] loss: 1.394
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0037838924360574615,
 'learning_rate_Hydroxylation-K': 0.005757913540594318,
 'learning_rate_Methylation-K': 0.006088036022804589,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7069722021302518,
 'loss_weight_Methylation-K': 0.4472690986883215,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3701439669,
 'sample_weights': [0.24819536121086466, 0.4158294616103146],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.1244722695602234,
 'weight_decay_Hydroxylation-K': 9.795885041058925,
 'weight_decay_Methylation-K': 3.9212419884434437}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.388
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.006931053976852699,
 'learning_rate_Hydroxylation-K': 0.009094002336594338,
 'learning_rate_Methylation-K': 0.0007195287350623418,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9681589517142499,
 'loss_weight_Methylation-K': 0.08177235752811766,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1119188372,
 'sample_weights': [0.7069722021302518, 0.4472690986883215],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.109444036550007,
 'weight_decay_Hydroxylation-K': 8.075491580736557,
 'weight_decay_Methylation-K': 6.818525318048158}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.383
[3,     4] loss: 1.388
[4,     4] loss: 1.385
[5,     4] loss: 1.383
[6,     4] loss: 1.386
[7,     4] loss: 1.382
[8,     4] loss: 1.376
[9,     4] loss: 1.333
[10,     4] loss: 1.227
[11,     4] loss: 1.242
[12,     4] loss: 1.232
[13,     4] loss: 1.227
[14,     4] loss: 1.138
[15,     4] loss: 1.071
[16,     4] loss: 1.102
[17,     4] loss: 1.027
[18,     4] loss: 1.098
[19,     4] loss: 1.061
[20,     4] loss: 1.045
[21,     4] loss: 1.045
[22,     4] loss: 1.204
[23,     4] loss: 1.136
[24,     4] loss: 1.074
[25,     4] loss: 1.074
[26,     4] loss: 1.083
[27,     4] loss: 0.957
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009599538936648992,
 'learning_rate_Hydroxylation-K': 0.0009057275839991138,
 'learning_rate_Methylation-K': 0.0017795942295207653,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.20997164502796,
 'loss_weight_Methylation-K': 0.10891817749660823,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1741836769,
 'sample_weights': [0.9681589517142499, 0.08177235752811766],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.865444090461912,
 'weight_decay_Hydroxylation-K': 6.421536064958781,
 'weight_decay_Methylation-K': 9.667982347232057}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.399
[2,     4] loss: 1.387
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019944545417871257,
 'learning_rate_Hydroxylation-K': 0.008252923819726025,
 'learning_rate_Methylation-K': 0.0047108968426967995,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8220359399995258,
 'loss_weight_Methylation-K': 0.7304354521076101,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3376045042,
 'sample_weights': [0.20997164502796, 0.10891817749660823],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.990790033339876,
 'weight_decay_Hydroxylation-K': 3.222170664908762,
 'weight_decay_Methylation-K': 1.9768832483045542}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.391
[3,     4] loss: 1.380
[4,     4] loss: 1.377
[5,     4] loss: 1.368
[6,     4] loss: 1.333
[7,     4] loss: 1.264
[8,     4] loss: 1.225
[9,     4] loss: 1.126
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00426892260734811,
 'learning_rate_Hydroxylation-K': 0.005258556498802475,
 'learning_rate_Methylation-K': 0.004614924647825749,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.32642686762131506,
 'loss_weight_Methylation-K': 0.5944672554081474,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1635838021,
 'sample_weights': [0.8220359399995258, 0.7304354521076101],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9367927719770057,
 'weight_decay_Hydroxylation-K': 7.300126445067966,
 'weight_decay_Methylation-K': 1.1271937930056528}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.383
[3,     4] loss: 1.395
[4,     4] loss: 1.384
[5,     4] loss: 1.384
[6,     4] loss: 1.384
[7,     4] loss: 1.385
[8,     4] loss: 1.386
[9,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001720192790190717,
 'learning_rate_Hydroxylation-K': 0.0044206756799374395,
 'learning_rate_Methylation-K': 0.005388074528710044,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3511999120423352,
 'loss_weight_Methylation-K': 0.4467730125984218,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1209117503,
 'sample_weights': [0.32642686762131506, 0.5944672554081474],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.768334836356828,
 'weight_decay_Hydroxylation-K': 8.480183595828638,
 'weight_decay_Methylation-K': 1.7466250289125822}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.389
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0021397656435080134,
 'learning_rate_Hydroxylation-K': 0.007100282828822866,
 'learning_rate_Methylation-K': 0.003903928247724527,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5655004652147149,
 'loss_weight_Methylation-K': 0.8291100051465843,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 444227944,
 'sample_weights': [0.3511999120423352, 0.4467730125984218],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.077368433944759,
 'weight_decay_Hydroxylation-K': 5.523177679901257,
 'weight_decay_Methylation-K': 9.462492164862047}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.380
[2,     4] loss: 1.384
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003832383185978314,
 'learning_rate_Hydroxylation-K': 0.008595459409169262,
 'learning_rate_Methylation-K': 0.0073153692636423445,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8755567858546998,
 'loss_weight_Methylation-K': 0.09404456097143032,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 627727336,
 'sample_weights': [0.5655004652147149, 0.8291100051465843],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.484998190673683,
 'weight_decay_Hydroxylation-K': 9.859623429490991,
 'weight_decay_Methylation-K': 5.242012220550816}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.384
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009268922164184482,
 'learning_rate_Hydroxylation-K': 0.005056665142650156,
 'learning_rate_Methylation-K': 0.009999027063485244,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3289354892077272,
 'loss_weight_Methylation-K': 0.9815074554097564,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4058150189,
 'sample_weights': [0.8755567858546998, 0.09404456097143032],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.8836050077429634,
 'weight_decay_Hydroxylation-K': 7.238607790285091,
 'weight_decay_Methylation-K': 8.50989399924409}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.408
[2,     4] loss: 1.395
[3,     4] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00042842041986311367,
 'learning_rate_Hydroxylation-K': 0.003842609877094377,
 'learning_rate_Methylation-K': 0.00392779143937204,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8156590208409906,
 'loss_weight_Methylation-K': 0.973717485376432,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1142331582,
 'sample_weights': [0.3289354892077272, 0.9815074554097564],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.6258607219290395,
 'weight_decay_Hydroxylation-K': 6.75920905989687,
 'weight_decay_Methylation-K': 0.7726064843239464}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031173570144456004,
 'learning_rate_Hydroxylation-K': 0.0037704421815636896,
 'learning_rate_Methylation-K': 0.002041201775142344,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4487524514205857,
 'loss_weight_Methylation-K': 0.9326642823264546,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1423806558,
 'sample_weights': [0.8156590208409906, 0.973717485376432],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.741462669384564,
 'weight_decay_Hydroxylation-K': 8.248096137947014,
 'weight_decay_Methylation-K': 3.9344831244084277}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.389
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017831959818637405,
 'learning_rate_Hydroxylation-K': 0.0007224999319175823,
 'learning_rate_Methylation-K': 0.0057277803638236275,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6089508935441987,
 'loss_weight_Methylation-K': 0.34624964335993524,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4009712762,
 'sample_weights': [0.4487524514205857, 0.9326642823264546],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.436081111592211,
 'weight_decay_Hydroxylation-K': 4.262373955364496,
 'weight_decay_Methylation-K': 6.539024605760231}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.391
[3,     4] loss: 1.386
[4,     4] loss: 1.384
[5,     4] loss: 1.385
[6,     4] loss: 1.381
[7,     4] loss: 1.377
[8,     4] loss: 1.363
[9,     4] loss: 1.342
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0038409971550548505,
 'learning_rate_Hydroxylation-K': 0.0030018886264210694,
 'learning_rate_Methylation-K': 0.009095701860567178,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.36784749514002824,
 'loss_weight_Methylation-K': 0.8432672943323679,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 371367627,
 'sample_weights': [0.6089508935441987, 0.34624964335993524],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.084714863674554,
 'weight_decay_Hydroxylation-K': 8.809341060618538,
 'weight_decay_Methylation-K': 9.657341834289928}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.385
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024490908066852795,
 'learning_rate_Hydroxylation-K': 0.006131546889243311,
 'learning_rate_Methylation-K': 0.006599391827367476,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9819498995380526,
 'loss_weight_Methylation-K': 0.5110581633123635,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1292228510,
 'sample_weights': [0.36784749514002824, 0.8432672943323679],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.31554330514453,
 'weight_decay_Hydroxylation-K': 8.024673356357406,
 'weight_decay_Methylation-K': 9.450891690884214}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.383
[4,     4] loss: 1.376
[5,     4] loss: 1.360
[6,     4] loss: 1.323
[7,     4] loss: 1.272
[8,     4] loss: 1.222
[9,     4] loss: 1.125
[10,     4] loss: 1.090
[11,     4] loss: 1.127
[12,     4] loss: 1.063
[13,     4] loss: 1.147
[14,     4] loss: 0.996
[15,     4] loss: 1.051
[16,     4] loss: 1.036
[17,     4] loss: 1.024
[18,     4] loss: 1.010
[19,     4] loss: 0.966
[20,     4] loss: 0.929
[21,     4] loss: 0.867
[22,     4] loss: 0.926
[23,     4] loss: 0.926
[24,     4] loss: 1.019
[25,     4] loss: 0.926
[26,     4] loss: 0.947
[27,     4] loss: 1.025
[28,     4] loss: 0.938
[29,     4] loss: 0.974
[30,     4] loss: 0.910
[31,     4] loss: 0.900
[32,     4] loss: 0.914
[33,     4] loss: 0.934
[34,     4] loss: 0.890
[35,     4] loss: 0.974
[36,     4] loss: 0.989
[37,     4] loss: 0.973
[38,     4] loss: 0.962
[39,     4] loss: 0.933
[40,     4] loss: 0.866
[41,     4] loss: 0.972
[42,     4] loss: 0.880
[43,     4] loss: 0.869
[44,     4] loss: 0.835
[45,     4] loss: 0.853
[46,     4] loss: 0.796
[47,     4] loss: 0.803
[48,     4] loss: 0.797
[49,     4] loss: 0.898
[50,     4] loss: 0.932
[51,     4] loss: 0.885
[52,     4] loss: 0.884
[53,     4] loss: 0.821
[54,     4] loss: 0.801
[55,     4] loss: 0.797
[56,     4] loss: 1.068
[57,     4] loss: 0.950
[58,     4] loss: 0.930
[59,     4] loss: 0.915
[60,     4] loss: 0.907
[61,     4] loss: 0.907
[62,     4] loss: 0.845
[63,     4] loss: 0.865
[64,     4] loss: 0.813
[65,     4] loss: 0.797
[66,     4] loss: 0.780
[67,     4] loss: 0.787
[68,     4] loss: 0.783
[69,     4] loss: 0.776
[70,     4] loss: 0.808
[71,     4] loss: 0.773
[72,     4] loss: 0.776
[73,     4] loss: 0.839
[74,     4] loss: 0.809
[75,     4] loss: 0.841
[76,     4] loss: 0.992
[77,     4] loss: 0.985
[78,     4] loss: 1.025
[79,     4] loss: 0.953
[80,     4] loss: 0.884
[81,     4] loss: 0.814
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024209137915131972,
 'learning_rate_Hydroxylation-K': 0.00010011092153219207,
 'learning_rate_Methylation-K': 0.00023757698342198922,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.16985178264019776,
 'loss_weight_Methylation-K': 0.07082683412328837,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1754656412,
 'sample_weights': [0.9819498995380526, 0.5110581633123635],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.918858990947767,
 'weight_decay_Hydroxylation-K': 8.136792740310248,
 'weight_decay_Methylation-K': 9.575583542149689}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.381
[3,     4] loss: 1.390
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000187363130782004,
 'learning_rate_Hydroxylation-K': 0.006221918955250146,
 'learning_rate_Methylation-K': 0.008342321026645528,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5478391000150723,
 'loss_weight_Methylation-K': 0.667383148593463,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3935850687,
 'sample_weights': [0.16985178264019776, 0.07082683412328837],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.2283507672436915,
 'weight_decay_Hydroxylation-K': 7.535753394324665,
 'weight_decay_Methylation-K': 2.633051091374419}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.390
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001289644144546786,
 'learning_rate_Hydroxylation-K': 0.003906253580719512,
 'learning_rate_Methylation-K': 0.00780333394404963,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.13003191468366665,
 'loss_weight_Methylation-K': 0.8191352460842535,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4030466988,
 'sample_weights': [0.5478391000150723, 0.667383148593463],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.347413569897426,
 'weight_decay_Hydroxylation-K': 6.61171524168587,
 'weight_decay_Methylation-K': 7.1272551218210705}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.382
[3,     4] loss: 1.382
[4,     4] loss: 1.372
[5,     4] loss: 1.361
[6,     4] loss: 1.357
[7,     4] loss: 1.280
[8,     4] loss: 1.240
[9,     4] loss: 1.219
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00015425277747419647,
 'learning_rate_Hydroxylation-K': 0.00581884163367582,
 'learning_rate_Methylation-K': 0.0053675542518933535,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4959996518969295,
 'loss_weight_Methylation-K': 0.6185190994134165,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1455431492,
 'sample_weights': [0.13003191468366665, 0.8191352460842535],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.2997224709021702,
 'weight_decay_Hydroxylation-K': 9.973907215054055,
 'weight_decay_Methylation-K': 1.9021624141045694}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.392
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002389478226902347,
 'learning_rate_Hydroxylation-K': 0.002938851846471547,
 'learning_rate_Methylation-K': 0.00736322352845275,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3273909993205836,
 'loss_weight_Methylation-K': 0.395141347370622,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 483471086,
 'sample_weights': [0.4959996518969295, 0.6185190994134165],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.1695147878106535,
 'weight_decay_Hydroxylation-K': 6.21650805623706,
 'weight_decay_Methylation-K': 6.611766930195021}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.385
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014157210068200987,
 'learning_rate_Hydroxylation-K': 6.194228407987957e-05,
 'learning_rate_Methylation-K': 0.0014570276791422312,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.030921994321231487,
 'loss_weight_Methylation-K': 0.3793445630354615,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2617006913,
 'sample_weights': [0.3273909993205836, 0.395141347370622],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.872705582011613,
 'weight_decay_Hydroxylation-K': 1.0684291800130237,
 'weight_decay_Methylation-K': 9.042103164190298}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.384
[3,     4] loss: 1.384
[4,     4] loss: 1.368
[5,     4] loss: 1.359
[6,     4] loss: 1.321
[7,     4] loss: 1.272
[8,     4] loss: 1.245
[9,     4] loss: 1.223
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001389887062626109,
 'learning_rate_Hydroxylation-K': 0.0058249013231000644,
 'learning_rate_Methylation-K': 0.009098995852841763,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.11723351688551503,
 'loss_weight_Methylation-K': 0.9915007134412932,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1338198260,
 'sample_weights': [0.030921994321231487, 0.3793445630354615],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.921594026769807,
 'weight_decay_Hydroxylation-K': 7.051602911012884,
 'weight_decay_Methylation-K': 7.972832428979123}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.383
[3,     4] loss: 1.393
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001156040253105311,
 'learning_rate_Hydroxylation-K': 0.003874541854614859,
 'learning_rate_Methylation-K': 0.009240000818583154,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1022094816973394,
 'loss_weight_Methylation-K': 0.8236443659614304,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1167938498,
 'sample_weights': [0.11723351688551503, 0.9915007134412932],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.816477083835417,
 'weight_decay_Hydroxylation-K': 5.659675021897414,
 'weight_decay_Methylation-K': 9.094853689759137}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.388
[3,     4] loss: 1.384
[4,     4] loss: 1.382
[5,     4] loss: 1.382
[6,     4] loss: 1.381
[7,     4] loss: 1.381
[8,     4] loss: 1.356
[9,     4] loss: 1.333
[10,     4] loss: 1.309
[11,     4] loss: 1.285
[12,     4] loss: 1.249
[13,     4] loss: 1.164
[14,     4] loss: 1.143
[15,     4] loss: 1.174
[16,     4] loss: 1.060
[17,     4] loss: 1.025
[18,     4] loss: 1.019
[19,     4] loss: 0.941
[20,     4] loss: 1.017
[21,     4] loss: 0.947
[22,     4] loss: 0.905
[23,     4] loss: 0.904
[24,     4] loss: 0.987
[25,     4] loss: 0.897
[26,     4] loss: 0.987
[27,     4] loss: 0.865
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0015631175972476937,
 'learning_rate_Hydroxylation-K': 0.0021858174279764907,
 'learning_rate_Methylation-K': 0.005155037442314453,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.05546003489953813,
 'loss_weight_Methylation-K': 0.46049371780870646,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 609990370,
 'sample_weights': [0.1022094816973394, 0.8236443659614304],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.575379077842149,
 'weight_decay_Hydroxylation-K': 4.218845443984996,
 'weight_decay_Methylation-K': 7.36480094999348}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.402
[2,     4] loss: 1.386
[3,     4] loss: 1.386
[4,     4] loss: 1.378
[5,     4] loss: 1.373
[6,     4] loss: 1.357
[7,     4] loss: 1.340
[8,     4] loss: 1.289
[9,     4] loss: 1.246
[10,     4] loss: 1.167
[11,     4] loss: 1.110
[12,     4] loss: 1.135
[13,     4] loss: 1.077
[14,     4] loss: 1.056
[15,     4] loss: 1.035
[16,     4] loss: 1.027
[17,     4] loss: 0.985
[18,     4] loss: 0.953
[19,     4] loss: 0.967
[20,     4] loss: 0.917
[21,     4] loss: 1.003
[22,     4] loss: 0.961
[23,     4] loss: 0.994
[24,     4] loss: 0.954
[25,     4] loss: 0.881
[26,     4] loss: 0.960
[27,     4] loss: 1.002
[28,     4] loss: 0.930
[29,     4] loss: 0.879
[30,     4] loss: 0.828
[31,     4] loss: 0.803
[32,     4] loss: 0.812
[33,     4] loss: 0.777
[34,     4] loss: 0.761
[35,     4] loss: 0.752
[36,     4] loss: 0.755
[37,     4] loss: 0.757
[38,     4] loss: 0.771
[39,     4] loss: 0.788
[40,     4] loss: 0.838
[41,     4] loss: 0.826
[42,     4] loss: 0.832
[43,     4] loss: 0.778
[44,     4] loss: 0.782
[45,     4] loss: 0.840
[46,     4] loss: 0.798
[47,     4] loss: 0.793
[48,     4] loss: 0.792
[49,     4] loss: 0.785
[50,     4] loss: 0.759
[51,     4] loss: 0.765
[52,     4] loss: 0.756
[53,     4] loss: 0.766
[54,     4] loss: 0.763
[55,     4] loss: 0.765
[56,     4] loss: 0.789
[57,     4] loss: 0.764
[58,     4] loss: 0.786
[59,     4] loss: 0.836
[60,     4] loss: 0.775
[61,     4] loss: 0.764
[62,     4] loss: 0.776
[63,     4] loss: 0.786
[64,     4] loss: 0.789
[65,     4] loss: 0.806
[66,     4] loss: 0.762
[67,     4] loss: 0.733
[68,     4] loss: 0.752
[69,     4] loss: 0.764
[70,     4] loss: 0.736
[71,     4] loss: 0.733
[72,     4] loss: 0.760
[73,     4] loss: 0.745
[74,     4] loss: 0.752
[75,     4] loss: 0.771
[76,     4] loss: 0.749
[77,     4] loss: 0.745
Early stopping applied (best metric=0.2565712630748749)
Finished Training
Total time taken: 39.101911306381226
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.381
[3,     4] loss: 1.368
[4,     4] loss: 1.352
[5,     4] loss: 1.307
[6,     4] loss: 1.258
[7,     4] loss: 1.199
[8,     4] loss: 1.128
[9,     4] loss: 1.076
[10,     4] loss: 1.003
[11,     4] loss: 0.967
[12,     4] loss: 0.908
[13,     4] loss: 0.900
[14,     4] loss: 0.936
[15,     4] loss: 0.924
[16,     4] loss: 0.862
[17,     4] loss: 0.848
[18,     4] loss: 0.843
[19,     4] loss: 0.807
[20,     4] loss: 0.918
[21,     4] loss: 0.871
[22,     4] loss: 0.887
[23,     4] loss: 0.814
[24,     4] loss: 0.817
[25,     4] loss: 0.822
[26,     4] loss: 0.794
[27,     4] loss: 0.856
[28,     4] loss: 0.864
[29,     4] loss: 0.829
[30,     4] loss: 0.854
[31,     4] loss: 0.912
[32,     4] loss: 0.833
[33,     4] loss: 0.914
[34,     4] loss: 0.817
[35,     4] loss: 0.804
[36,     4] loss: 0.823
[37,     4] loss: 0.809
[38,     4] loss: 0.787
[39,     4] loss: 0.762
[40,     4] loss: 0.761
[41,     4] loss: 0.741
[42,     4] loss: 0.735
[43,     4] loss: 0.748
[44,     4] loss: 0.743
[45,     4] loss: 0.740
[46,     4] loss: 0.738
[47,     4] loss: 0.763
[48,     4] loss: 0.747
[49,     4] loss: 0.796
[50,     4] loss: 0.823
[51,     4] loss: 0.773
[52,     4] loss: 0.739
[53,     4] loss: 0.736
[54,     4] loss: 0.736
Early stopping applied (best metric=0.5406134128570557)
Finished Training
Total time taken: 27.30033540725708
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.385
[4,     4] loss: 1.386
[5,     4] loss: 1.385
[6,     4] loss: 1.381
[7,     4] loss: 1.370
[8,     4] loss: 1.359
[9,     4] loss: 1.337
[10,     4] loss: 1.298
[11,     4] loss: 1.265
[12,     4] loss: 1.176
[13,     4] loss: 1.118
[14,     4] loss: 1.046
[15,     4] loss: 1.036
[16,     4] loss: 0.988
[17,     4] loss: 1.097
[18,     4] loss: 0.969
[19,     4] loss: 1.039
[20,     4] loss: 0.995
[21,     4] loss: 0.906
[22,     4] loss: 0.933
[23,     4] loss: 0.925
[24,     4] loss: 0.852
[25,     4] loss: 0.855
[26,     4] loss: 0.806
[27,     4] loss: 0.830
[28,     4] loss: 0.865
[29,     4] loss: 0.779
[30,     4] loss: 0.824
[31,     4] loss: 0.859
[32,     4] loss: 0.864
[33,     4] loss: 0.788
[34,     4] loss: 0.805
[35,     4] loss: 0.801
[36,     4] loss: 0.802
[37,     4] loss: 0.875
[38,     4] loss: 0.783
[39,     4] loss: 0.765
[40,     4] loss: 0.847
[41,     4] loss: 0.802
[42,     4] loss: 0.791
[43,     4] loss: 0.766
[44,     4] loss: 0.809
[45,     4] loss: 0.901
[46,     4] loss: 0.895
[47,     4] loss: 0.808
[48,     4] loss: 0.838
[49,     4] loss: 0.796
[50,     4] loss: 0.775
[51,     4] loss: 0.741
[52,     4] loss: 0.747
[53,     4] loss: 0.771
[54,     4] loss: 0.739
[55,     4] loss: 0.756
[56,     4] loss: 0.766
[57,     4] loss: 0.783
[58,     4] loss: 0.778
[59,     4] loss: 0.764
[60,     4] loss: 0.756
[61,     4] loss: 0.749
[62,     4] loss: 0.733
[63,     4] loss: 0.744
[64,     4] loss: 0.751
[65,     4] loss: 0.732
[66,     4] loss: 0.746
[67,     4] loss: 0.767
[68,     4] loss: 0.742
[69,     4] loss: 0.741
Early stopping applied (best metric=0.29596877098083496)
Finished Training
Total time taken: 34.90471076965332
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.386
[3,     4] loss: 1.382
[4,     4] loss: 1.374
[5,     4] loss: 1.368
[6,     4] loss: 1.334
[7,     4] loss: 1.314
[8,     4] loss: 1.296
[9,     4] loss: 1.252
[10,     4] loss: 1.222
[11,     4] loss: 1.181
[12,     4] loss: 1.147
[13,     4] loss: 1.098
[14,     4] loss: 1.098
[15,     4] loss: 1.014
[16,     4] loss: 0.993
[17,     4] loss: 1.076
[18,     4] loss: 1.007
[19,     4] loss: 0.967
[20,     4] loss: 0.939
[21,     4] loss: 0.913
[22,     4] loss: 0.935
[23,     4] loss: 0.833
[24,     4] loss: 0.858
[25,     4] loss: 0.867
[26,     4] loss: 0.832
[27,     4] loss: 0.779
[28,     4] loss: 0.827
[29,     4] loss: 0.781
[30,     4] loss: 0.785
[31,     4] loss: 0.810
[32,     4] loss: 0.817
[33,     4] loss: 0.863
[34,     4] loss: 0.831
[35,     4] loss: 0.842
[36,     4] loss: 0.813
[37,     4] loss: 0.774
[38,     4] loss: 0.759
[39,     4] loss: 0.781
[40,     4] loss: 0.767
[41,     4] loss: 0.760
[42,     4] loss: 0.772
[43,     4] loss: 0.773
[44,     4] loss: 0.736
[45,     4] loss: 0.818
[46,     4] loss: 0.809
[47,     4] loss: 0.814
[48,     4] loss: 0.794
[49,     4] loss: 0.832
[50,     4] loss: 0.768
[51,     4] loss: 0.755
[52,     4] loss: 0.809
[53,     4] loss: 0.748
[54,     4] loss: 0.782
[55,     4] loss: 0.840
[56,     4] loss: 0.847
[57,     4] loss: 0.796
[58,     4] loss: 0.777
[59,     4] loss: 0.750
[60,     4] loss: 0.744
[61,     4] loss: 0.787
[62,     4] loss: 0.807
[63,     4] loss: 0.741
[64,     4] loss: 0.787
[65,     4] loss: 0.735
[66,     4] loss: 0.751
[67,     4] loss: 0.766
[68,     4] loss: 0.794
[69,     4] loss: 0.813
[70,     4] loss: 0.799
[71,     4] loss: 0.781
[72,     4] loss: 0.785
[73,     4] loss: 0.765
Early stopping applied (best metric=0.21602967381477356)
Finished Training
Total time taken: 36.85879945755005
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.400
[2,     4] loss: 1.385
[3,     4] loss: 1.393
[4,     4] loss: 1.386
[5,     4] loss: 1.384
[6,     4] loss: 1.376
[7,     4] loss: 1.384
[8,     4] loss: 1.369
[9,     4] loss: 1.350
[10,     4] loss: 1.324
[11,     4] loss: 1.272
[12,     4] loss: 1.228
[13,     4] loss: 1.181
[14,     4] loss: 1.204
[15,     4] loss: 1.060
[16,     4] loss: 1.073
[17,     4] loss: 1.009
[18,     4] loss: 1.003
[19,     4] loss: 0.961
[20,     4] loss: 0.901
[21,     4] loss: 0.990
[22,     4] loss: 0.962
[23,     4] loss: 0.972
[24,     4] loss: 0.922
[25,     4] loss: 0.946
[26,     4] loss: 0.931
[27,     4] loss: 0.882
[28,     4] loss: 0.851
[29,     4] loss: 0.856
[30,     4] loss: 0.836
[31,     4] loss: 0.873
[32,     4] loss: 0.860
[33,     4] loss: 0.830
[34,     4] loss: 0.839
[35,     4] loss: 0.813
[36,     4] loss: 0.823
[37,     4] loss: 0.831
[38,     4] loss: 0.804
[39,     4] loss: 0.801
[40,     4] loss: 0.766
[41,     4] loss: 0.764
[42,     4] loss: 0.812
[43,     4] loss: 0.832
[44,     4] loss: 0.841
[45,     4] loss: 0.789
[46,     4] loss: 0.799
[47,     4] loss: 0.803
[48,     4] loss: 0.767
[49,     4] loss: 0.764
[50,     4] loss: 0.792
[51,     4] loss: 0.768
[52,     4] loss: 0.733
[53,     4] loss: 0.756
[54,     4] loss: 0.867
[55,     4] loss: 0.796
[56,     4] loss: 0.744
[57,     4] loss: 0.774
[58,     4] loss: 0.770
[59,     4] loss: 0.748
[60,     4] loss: 0.736
[61,     4] loss: 0.767
Early stopping applied (best metric=0.41860395669937134)
Finished Training
Total time taken: 30.383485078811646
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.405
[2,     4] loss: 1.390
[3,     4] loss: 1.385
[4,     4] loss: 1.385
[5,     4] loss: 1.380
[6,     4] loss: 1.379
[7,     4] loss: 1.365
[8,     4] loss: 1.347
[9,     4] loss: 1.297
[10,     4] loss: 1.257
[11,     4] loss: 1.153
[12,     4] loss: 1.124
[13,     4] loss: 1.017
[14,     4] loss: 1.066
[15,     4] loss: 1.006
[16,     4] loss: 1.028
[17,     4] loss: 1.011
[18,     4] loss: 0.986
[19,     4] loss: 0.993
[20,     4] loss: 0.995
[21,     4] loss: 0.898
[22,     4] loss: 0.917
[23,     4] loss: 0.843
[24,     4] loss: 0.901
[25,     4] loss: 0.830
[26,     4] loss: 0.860
[27,     4] loss: 0.849
[28,     4] loss: 0.797
[29,     4] loss: 0.854
[30,     4] loss: 0.859
[31,     4] loss: 0.806
[32,     4] loss: 0.853
[33,     4] loss: 0.786
[34,     4] loss: 0.787
[35,     4] loss: 0.788
[36,     4] loss: 0.824
[37,     4] loss: 0.817
[38,     4] loss: 0.867
[39,     4] loss: 0.799
[40,     4] loss: 0.794
[41,     4] loss: 0.786
[42,     4] loss: 0.799
[43,     4] loss: 0.791
[44,     4] loss: 0.796
[45,     4] loss: 0.824
[46,     4] loss: 0.798
[47,     4] loss: 0.770
[48,     4] loss: 0.772
[49,     4] loss: 0.807
[50,     4] loss: 0.835
[51,     4] loss: 0.757
[52,     4] loss: 0.764
[53,     4] loss: 0.765
[54,     4] loss: 0.764
[55,     4] loss: 0.748
[56,     4] loss: 0.764
[57,     4] loss: 0.742
[58,     4] loss: 0.761
[59,     4] loss: 0.801
[60,     4] loss: 0.744
Early stopping applied (best metric=0.4761306941509247)
Finished Training
Total time taken: 30.07647132873535
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.379
[5,     4] loss: 1.382
[6,     4] loss: 1.371
[7,     4] loss: 1.352
[8,     4] loss: 1.308
[9,     4] loss: 1.320
[10,     4] loss: 1.261
[11,     4] loss: 1.232
[12,     4] loss: 1.192
[13,     4] loss: 1.179
[14,     4] loss: 1.155
[15,     4] loss: 1.157
[16,     4] loss: 1.091
[17,     4] loss: 1.078
[18,     4] loss: 1.011
[19,     4] loss: 1.024
[20,     4] loss: 0.995
[21,     4] loss: 1.042
[22,     4] loss: 0.949
[23,     4] loss: 0.974
[24,     4] loss: 0.933
[25,     4] loss: 0.870
[26,     4] loss: 0.861
[27,     4] loss: 0.841
[28,     4] loss: 0.822
[29,     4] loss: 0.786
[30,     4] loss: 0.830
[31,     4] loss: 0.795
[32,     4] loss: 0.816
[33,     4] loss: 0.859
[34,     4] loss: 0.936
[35,     4] loss: 0.894
[36,     4] loss: 0.825
[37,     4] loss: 0.831
[38,     4] loss: 0.840
[39,     4] loss: 0.815
[40,     4] loss: 0.846
[41,     4] loss: 0.842
[42,     4] loss: 0.817
[43,     4] loss: 0.800
[44,     4] loss: 0.771
[45,     4] loss: 0.786
[46,     4] loss: 0.767
[47,     4] loss: 0.747
[48,     4] loss: 0.819
[49,     4] loss: 0.955
[50,     4] loss: 0.875
[51,     4] loss: 0.858
[52,     4] loss: 0.849
[53,     4] loss: 0.797
[54,     4] loss: 0.820
[55,     4] loss: 0.794
[56,     4] loss: 0.782
[57,     4] loss: 0.814
[58,     4] loss: 0.760
[59,     4] loss: 0.779
[60,     4] loss: 0.753
[61,     4] loss: 0.737
[62,     4] loss: 0.764
[63,     4] loss: 0.740
[64,     4] loss: 0.753
[65,     4] loss: 0.785
[66,     4] loss: 0.772
[67,     4] loss: 0.777
[68,     4] loss: 0.798
[69,     4] loss: 0.810
[70,     4] loss: 0.848
[71,     4] loss: 0.797
[72,     4] loss: 0.780
[73,     4] loss: 0.907
[74,     4] loss: 0.796
[75,     4] loss: 0.791
[76,     4] loss: 0.755
[77,     4] loss: 0.746
[78,     4] loss: 0.732
[79,     4] loss: 0.753
[80,     4] loss: 0.730
[81,     4] loss: 0.739
[82,     4] loss: 0.737
[83,     4] loss: 0.730
[84,     4] loss: 0.769
[85,     4] loss: 0.738
[86,     4] loss: 0.732
[87,     4] loss: 0.745
[88,     4] loss: 0.717
[89,     4] loss: 0.731
[90,     4] loss: 0.734
[91,     4] loss: 0.733
[92,     4] loss: 0.731
[93,     4] loss: 0.720
[94,     4] loss: 0.727
[95,     4] loss: 0.729
[96,     4] loss: 0.746
[97,     4] loss: 0.758
[98,     4] loss: 0.736
[99,     4] loss: 0.749
[100,     4] loss: 0.807
[101,     4] loss: 0.753
[102,     4] loss: 0.773
[103,     4] loss: 0.755
[104,     4] loss: 0.732
[105,     4] loss: 0.786
[106,     4] loss: 0.749
[107,     4] loss: 0.773
[108,     4] loss: 0.739
[109,     4] loss: 0.788
[110,     4] loss: 0.765
[111,     4] loss: 0.790
[112,     4] loss: 0.746
[113,     4] loss: 0.978
[114,     4] loss: 0.929
[115,     4] loss: 0.841
[116,     4] loss: 0.846
[117,     4] loss: 0.865
[118,     4] loss: 0.946
[119,     4] loss: 0.844
[120,     4] loss: 0.776
[121,     4] loss: 0.749
[122,     4] loss: 0.779
[123,     4] loss: 0.733
[124,     4] loss: 0.770
[125,     4] loss: 0.730
[126,     4] loss: 0.738
[127,     4] loss: 0.752
[128,     4] loss: 0.788
[129,     4] loss: 0.763
[130,     4] loss: 0.910
[131,     4] loss: 0.803
[132,     4] loss: 0.800
[133,     4] loss: 0.765
[134,     4] loss: 0.742
[135,     4] loss: 0.748
[136,     4] loss: 0.761
[137,     4] loss: 0.781
[138,     4] loss: 0.784
[139,     4] loss: 0.765
[140,     4] loss: 0.786
[141,     4] loss: 0.800
[142,     4] loss: 0.745
[143,     4] loss: 0.766
[144,     4] loss: 0.771
[145,     4] loss: 0.765
[146,     4] loss: 0.807
[147,     4] loss: 0.771
[148,     4] loss: 0.799
[149,     4] loss: 0.793
[150,     4] loss: 0.774
[151,     4] loss: 0.757
Early stopping applied (best metric=0.2732413113117218)
Finished Training
Total time taken: 76.17572474479675
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.400
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.383
[5,     4] loss: 1.389
[6,     4] loss: 1.380
[7,     4] loss: 1.380
[8,     4] loss: 1.369
[9,     4] loss: 1.358
[10,     4] loss: 1.313
[11,     4] loss: 1.253
[12,     4] loss: 1.222
[13,     4] loss: 1.134
[14,     4] loss: 1.124
[15,     4] loss: 1.121
[16,     4] loss: 1.074
[17,     4] loss: 1.085
[18,     4] loss: 1.043
[19,     4] loss: 1.085
[20,     4] loss: 1.004
[21,     4] loss: 1.055
[22,     4] loss: 0.963
[23,     4] loss: 1.006
[24,     4] loss: 1.003
[25,     4] loss: 0.887
[26,     4] loss: 0.910
[27,     4] loss: 0.915
[28,     4] loss: 0.944
[29,     4] loss: 0.948
[30,     4] loss: 0.891
[31,     4] loss: 0.955
[32,     4] loss: 0.999
[33,     4] loss: 0.901
[34,     4] loss: 0.942
[35,     4] loss: 0.905
[36,     4] loss: 0.846
[37,     4] loss: 0.822
[38,     4] loss: 0.811
[39,     4] loss: 0.794
[40,     4] loss: 0.839
[41,     4] loss: 0.805
[42,     4] loss: 0.788
[43,     4] loss: 0.843
[44,     4] loss: 0.817
[45,     4] loss: 0.792
[46,     4] loss: 0.767
[47,     4] loss: 0.776
[48,     4] loss: 0.739
[49,     4] loss: 0.768
[50,     4] loss: 0.770
[51,     4] loss: 0.753
[52,     4] loss: 0.810
[53,     4] loss: 0.812
[54,     4] loss: 0.769
[55,     4] loss: 0.803
[56,     4] loss: 0.812
[57,     4] loss: 0.895
[58,     4] loss: 0.768
[59,     4] loss: 0.766
[60,     4] loss: 0.784
Early stopping applied (best metric=0.46535080671310425)
Finished Training
Total time taken: 30.104471683502197
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.384
[5,     4] loss: 1.375
[6,     4] loss: 1.366
[7,     4] loss: 1.344
[8,     4] loss: 1.308
[9,     4] loss: 1.254
[10,     4] loss: 1.252
[11,     4] loss: 1.139
[12,     4] loss: 1.213
[13,     4] loss: 1.130
[14,     4] loss: 1.072
[15,     4] loss: 1.031
[16,     4] loss: 1.024
[17,     4] loss: 0.995
[18,     4] loss: 0.916
[19,     4] loss: 0.953
[20,     4] loss: 0.904
[21,     4] loss: 0.930
[22,     4] loss: 0.936
[23,     4] loss: 0.928
[24,     4] loss: 0.933
[25,     4] loss: 1.004
[26,     4] loss: 0.943
[27,     4] loss: 0.856
[28,     4] loss: 0.907
[29,     4] loss: 0.881
[30,     4] loss: 0.848
[31,     4] loss: 0.799
[32,     4] loss: 0.771
[33,     4] loss: 0.771
[34,     4] loss: 0.803
[35,     4] loss: 0.760
[36,     4] loss: 0.836
[37,     4] loss: 0.855
[38,     4] loss: 0.910
[39,     4] loss: 0.854
[40,     4] loss: 0.832
[41,     4] loss: 0.823
[42,     4] loss: 0.794
[43,     4] loss: 0.782
[44,     4] loss: 0.825
[45,     4] loss: 0.774
[46,     4] loss: 0.767
[47,     4] loss: 0.728
[48,     4] loss: 0.739
[49,     4] loss: 0.788
[50,     4] loss: 0.795
[51,     4] loss: 0.760
[52,     4] loss: 0.766
[53,     4] loss: 0.733
[54,     4] loss: 0.742
[55,     4] loss: 0.759
[56,     4] loss: 0.749
[57,     4] loss: 0.737
[58,     4] loss: 0.779
[59,     4] loss: 0.739
[60,     4] loss: 0.750
[61,     4] loss: 0.798
[62,     4] loss: 0.763
[63,     4] loss: 0.809
Early stopping applied (best metric=0.4127610921859741)
Finished Training
Total time taken: 31.705204010009766
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.410
[2,     4] loss: 1.385
[3,     4] loss: 1.388
[4,     4] loss: 1.381
[5,     4] loss: 1.387
[6,     4] loss: 1.380
[7,     4] loss: 1.385
[8,     4] loss: 1.375
[9,     4] loss: 1.373
[10,     4] loss: 1.356
[11,     4] loss: 1.339
[12,     4] loss: 1.291
[13,     4] loss: 1.208
[14,     4] loss: 1.171
[15,     4] loss: 1.142
[16,     4] loss: 1.079
[17,     4] loss: 1.013
[18,     4] loss: 1.050
[19,     4] loss: 1.022
[20,     4] loss: 1.048
[21,     4] loss: 1.014
[22,     4] loss: 0.975
[23,     4] loss: 0.992
[24,     4] loss: 0.945
[25,     4] loss: 0.943
[26,     4] loss: 0.880
[27,     4] loss: 0.941
[28,     4] loss: 0.902
[29,     4] loss: 0.884
[30,     4] loss: 0.862
[31,     4] loss: 0.828
[32,     4] loss: 0.781
[33,     4] loss: 0.826
[34,     4] loss: 0.818
[35,     4] loss: 0.821
[36,     4] loss: 0.800
[37,     4] loss: 0.824
[38,     4] loss: 0.828
[39,     4] loss: 0.798
[40,     4] loss: 0.797
[41,     4] loss: 0.764
[42,     4] loss: 0.798
[43,     4] loss: 0.787
[44,     4] loss: 0.755
[45,     4] loss: 0.769
[46,     4] loss: 0.797
[47,     4] loss: 0.753
[48,     4] loss: 0.804
[49,     4] loss: 0.826
[50,     4] loss: 0.771
[51,     4] loss: 0.749
[52,     4] loss: 0.773
[53,     4] loss: 0.754
[54,     4] loss: 0.767
[55,     4] loss: 0.721
[56,     4] loss: 0.760
[57,     4] loss: 0.756
[58,     4] loss: 0.756
[59,     4] loss: 0.763
[60,     4] loss: 0.759
[61,     4] loss: 0.814
[62,     4] loss: 0.759
[63,     4] loss: 0.777
[64,     4] loss: 0.839
Early stopping applied (best metric=0.3698618412017822)
Finished Training
Total time taken: 32.268913984298706
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.386
[3,     4] loss: 1.389
[4,     4] loss: 1.385
[5,     4] loss: 1.385
[6,     4] loss: 1.374
[7,     4] loss: 1.370
[8,     4] loss: 1.348
[9,     4] loss: 1.310
[10,     4] loss: 1.257
[11,     4] loss: 1.273
[12,     4] loss: 1.195
[13,     4] loss: 1.164
[14,     4] loss: 1.078
[15,     4] loss: 1.089
[16,     4] loss: 1.031
[17,     4] loss: 1.009
[18,     4] loss: 1.068
[19,     4] loss: 1.052
[20,     4] loss: 1.030
[21,     4] loss: 0.977
[22,     4] loss: 0.975
[23,     4] loss: 0.939
[24,     4] loss: 0.912
[25,     4] loss: 0.869
[26,     4] loss: 0.881
[27,     4] loss: 0.833
[28,     4] loss: 0.826
[29,     4] loss: 0.851
[30,     4] loss: 0.789
[31,     4] loss: 0.829
[32,     4] loss: 0.813
[33,     4] loss: 0.831
[34,     4] loss: 0.840
[35,     4] loss: 0.914
[36,     4] loss: 0.822
[37,     4] loss: 0.816
[38,     4] loss: 0.815
[39,     4] loss: 0.791
[40,     4] loss: 0.796
[41,     4] loss: 0.763
[42,     4] loss: 0.791
[43,     4] loss: 0.766
[44,     4] loss: 0.777
[45,     4] loss: 0.797
[46,     4] loss: 0.773
[47,     4] loss: 0.785
[48,     4] loss: 0.769
[49,     4] loss: 0.798
[50,     4] loss: 0.786
[51,     4] loss: 0.792
[52,     4] loss: 0.753
[53,     4] loss: 0.750
[54,     4] loss: 0.747
[55,     4] loss: 0.742
[56,     4] loss: 0.739
[57,     4] loss: 0.785
[58,     4] loss: 0.743
Early stopping applied (best metric=0.536102294921875)
Finished Training
Total time taken: 29.446836948394775
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.381
[3,     4] loss: 1.386
[4,     4] loss: 1.363
[5,     4] loss: 1.357
[6,     4] loss: 1.313
[7,     4] loss: 1.239
[8,     4] loss: 1.207
[9,     4] loss: 1.200
[10,     4] loss: 1.092
[11,     4] loss: 1.034
[12,     4] loss: 1.054
[13,     4] loss: 0.952
[14,     4] loss: 0.951
[15,     4] loss: 1.117
[16,     4] loss: 0.940
[17,     4] loss: 0.980
[18,     4] loss: 0.949
[19,     4] loss: 0.905
[20,     4] loss: 0.848
[21,     4] loss: 0.869
[22,     4] loss: 0.883
[23,     4] loss: 0.903
[24,     4] loss: 0.915
[25,     4] loss: 0.894
[26,     4] loss: 0.866
[27,     4] loss: 0.923
[28,     4] loss: 0.913
[29,     4] loss: 0.877
[30,     4] loss: 0.833
[31,     4] loss: 0.797
[32,     4] loss: 0.785
[33,     4] loss: 0.768
[34,     4] loss: 0.812
[35,     4] loss: 0.793
[36,     4] loss: 0.754
[37,     4] loss: 0.744
[38,     4] loss: 0.746
[39,     4] loss: 0.755
[40,     4] loss: 0.770
[41,     4] loss: 0.772
[42,     4] loss: 0.778
[43,     4] loss: 0.744
[44,     4] loss: 0.792
[45,     4] loss: 0.792
[46,     4] loss: 0.805
[47,     4] loss: 0.813
[48,     4] loss: 0.788
[49,     4] loss: 0.781
[50,     4] loss: 0.760
[51,     4] loss: 0.762
[52,     4] loss: 0.746
[53,     4] loss: 0.733
[54,     4] loss: 0.740
[55,     4] loss: 0.745
[56,     4] loss: 0.724
Early stopping applied (best metric=0.47374576330184937)
Finished Training
Total time taken: 28.298800230026245
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.383
[3,     4] loss: 1.380
[4,     4] loss: 1.366
[5,     4] loss: 1.360
[6,     4] loss: 1.338
[7,     4] loss: 1.279
[8,     4] loss: 1.232
[9,     4] loss: 1.158
[10,     4] loss: 1.112
[11,     4] loss: 1.058
[12,     4] loss: 0.944
[13,     4] loss: 0.977
[14,     4] loss: 1.004
[15,     4] loss: 0.971
[16,     4] loss: 0.965
[17,     4] loss: 0.989
[18,     4] loss: 0.930
[19,     4] loss: 0.914
[20,     4] loss: 0.877
[21,     4] loss: 0.895
[22,     4] loss: 0.877
[23,     4] loss: 0.855
[24,     4] loss: 0.808
[25,     4] loss: 0.851
[26,     4] loss: 0.902
[27,     4] loss: 0.871
[28,     4] loss: 0.877
[29,     4] loss: 0.817
[30,     4] loss: 0.809
[31,     4] loss: 0.812
[32,     4] loss: 0.834
[33,     4] loss: 0.838
[34,     4] loss: 0.784
[35,     4] loss: 0.796
[36,     4] loss: 0.789
[37,     4] loss: 0.784
[38,     4] loss: 0.811
[39,     4] loss: 0.804
[40,     4] loss: 0.798
[41,     4] loss: 0.812
[42,     4] loss: 0.813
[43,     4] loss: 0.811
[44,     4] loss: 0.768
[45,     4] loss: 0.775
[46,     4] loss: 0.746
[47,     4] loss: 0.735
[48,     4] loss: 0.767
[49,     4] loss: 0.807
[50,     4] loss: 0.789
[51,     4] loss: 0.746
[52,     4] loss: 0.737
[53,     4] loss: 0.761
[54,     4] loss: 0.763
[55,     4] loss: 0.780
[56,     4] loss: 0.786
[57,     4] loss: 0.773
Early stopping applied (best metric=0.5116497874259949)
Finished Training
Total time taken: 28.704814672470093
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.389
[3,     4] loss: 1.386
[4,     4] loss: 1.385
[5,     4] loss: 1.386
[6,     4] loss: 1.381
[7,     4] loss: 1.386
[8,     4] loss: 1.381
[9,     4] loss: 1.375
[10,     4] loss: 1.351
[11,     4] loss: 1.322
[12,     4] loss: 1.256
[13,     4] loss: 1.226
[14,     4] loss: 1.147
[15,     4] loss: 1.151
[16,     4] loss: 1.130
[17,     4] loss: 1.010
[18,     4] loss: 1.058
[19,     4] loss: 1.048
[20,     4] loss: 1.044
[21,     4] loss: 0.981
[22,     4] loss: 0.999
[23,     4] loss: 0.969
[24,     4] loss: 0.897
[25,     4] loss: 0.932
[26,     4] loss: 0.911
[27,     4] loss: 0.844
[28,     4] loss: 0.879
[29,     4] loss: 0.886
[30,     4] loss: 0.864
[31,     4] loss: 0.883
[32,     4] loss: 0.943
[33,     4] loss: 0.899
[34,     4] loss: 0.877
[35,     4] loss: 0.836
[36,     4] loss: 0.837
[37,     4] loss: 0.831
[38,     4] loss: 0.806
[39,     4] loss: 0.782
[40,     4] loss: 0.782
[41,     4] loss: 0.774
[42,     4] loss: 0.745
[43,     4] loss: 0.763
[44,     4] loss: 0.750
[45,     4] loss: 0.728
[46,     4] loss: 0.763
[47,     4] loss: 0.757
[48,     4] loss: 0.769
[49,     4] loss: 0.790
[50,     4] loss: 0.769
[51,     4] loss: 0.789
[52,     4] loss: 0.764
[53,     4] loss: 0.749
[54,     4] loss: 0.743
[55,     4] loss: 0.751
[56,     4] loss: 0.792
[57,     4] loss: 0.731
[58,     4] loss: 0.767
[59,     4] loss: 0.743
[60,     4] loss: 0.782
[61,     4] loss: 0.747
[62,     4] loss: 0.755
[63,     4] loss: 0.783
[64,     4] loss: 0.764
[65,     4] loss: 0.797
[66,     4] loss: 0.779
[67,     4] loss: 0.753
[68,     4] loss: 0.769
[69,     4] loss: 0.884
[70,     4] loss: 0.879
[71,     4] loss: 0.859
[72,     4] loss: 0.792
[73,     4] loss: 0.754
[74,     4] loss: 0.741
[75,     4] loss: 0.787
[76,     4] loss: 0.782
[77,     4] loss: 0.748
[78,     4] loss: 0.743
[79,     4] loss: 0.740
[80,     4] loss: 0.733
[81,     4] loss: 0.721
[82,     4] loss: 0.734
[83,     4] loss: 0.753
[84,     4] loss: 0.797
[85,     4] loss: 0.749
[86,     4] loss: 0.750
[87,     4] loss: 0.743
[88,     4] loss: 0.731
[89,     4] loss: 0.740
[90,     4] loss: 0.741
[91,     4] loss: 0.838
[92,     4] loss: 0.808
[93,     4] loss: 0.786
[94,     4] loss: 0.745
[95,     4] loss: 0.761
[96,     4] loss: 0.737
[97,     4] loss: 0.735
[98,     4] loss: 0.768
[99,     4] loss: 0.750
[100,     4] loss: 0.779
[101,     4] loss: 0.772
[102,     4] loss: 0.743
[103,     4] loss: 0.738
[104,     4] loss: 0.756
[105,     4] loss: 0.754
[106,     4] loss: 0.736
[107,     4] loss: 0.736
[108,     4] loss: 0.734
[109,     4] loss: 0.727
[110,     4] loss: 0.731
[111,     4] loss: 0.721
[112,     4] loss: 0.745
[113,     4] loss: 0.739
[114,     4] loss: 0.749
[115,     4] loss: 0.767
[116,     4] loss: 0.732
[117,     4] loss: 0.722
[118,     4] loss: 0.758
[119,     4] loss: 0.793
[120,     4] loss: 0.755
[121,     4] loss: 0.757
[122,     4] loss: 0.787
[123,     4] loss: 0.733
[124,     4] loss: 0.730
[125,     4] loss: 0.740
[126,     4] loss: 0.738
[127,     4] loss: 0.786
[128,     4] loss: 0.795
[129,     4] loss: 0.790
[130,     4] loss: 0.953
[131,     4] loss: 0.818
[132,     4] loss: 0.796
Early stopping applied (best metric=0.19992488622665405)
Finished Training
Total time taken: 66.73440504074097
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.391
[2,     4] loss: 1.387
[3,     4] loss: 1.389
[4,     4] loss: 1.389
[5,     4] loss: 1.381
[6,     4] loss: 1.378
[7,     4] loss: 1.352
[8,     4] loss: 1.328
[9,     4] loss: 1.279
[10,     4] loss: 1.214
[11,     4] loss: 1.164
[12,     4] loss: 1.079
[13,     4] loss: 1.046
[14,     4] loss: 1.009
[15,     4] loss: 1.044
[16,     4] loss: 0.951
[17,     4] loss: 0.994
[18,     4] loss: 0.883
[19,     4] loss: 0.990
[20,     4] loss: 0.911
[21,     4] loss: 0.967
[22,     4] loss: 0.990
[23,     4] loss: 0.940
[24,     4] loss: 0.902
[25,     4] loss: 0.878
[26,     4] loss: 0.878
[27,     4] loss: 0.871
[28,     4] loss: 0.878
[29,     4] loss: 0.886
[30,     4] loss: 0.905
[31,     4] loss: 0.845
[32,     4] loss: 0.924
[33,     4] loss: 0.874
[34,     4] loss: 0.812
[35,     4] loss: 0.819
[36,     4] loss: 0.787
[37,     4] loss: 0.784
[38,     4] loss: 0.773
[39,     4] loss: 0.741
[40,     4] loss: 0.737
[41,     4] loss: 0.766
[42,     4] loss: 0.791
[43,     4] loss: 0.760
[44,     4] loss: 0.762
[45,     4] loss: 0.788
[46,     4] loss: 0.843
[47,     4] loss: 0.893
[48,     4] loss: 0.861
[49,     4] loss: 0.833
[50,     4] loss: 0.805
[51,     4] loss: 0.820
[52,     4] loss: 0.840
[53,     4] loss: 0.763
[54,     4] loss: 0.776
[55,     4] loss: 0.749
[56,     4] loss: 0.762
[57,     4] loss: 0.774
[58,     4] loss: 0.783
Early stopping applied (best metric=0.5308208465576172)
Finished Training
Total time taken: 29.09082579612732
{'Hydroxylation-K Validation Accuracy': 0.7941489361702128, 'Hydroxylation-K Validation Sensitivity': 0.717037037037037, 'Hydroxylation-K Validation Specificity': 0.8140350877192982, 'Hydroxylation-K Validation Precision': 0.5067371190900603, 'Hydroxylation-K AUC ROC': 0.819103313840156, 'Hydroxylation-K AUC PR': 0.6215604488384379, 'Hydroxylation-K MCC': 0.4748824488486062, 'Hydroxylation-K F1': 0.5888226777124433, 'Validation Loss (Hydroxylation-K)': 0.3984917600949605, 'Methylation-K Validation Accuracy': 0.841099835991608, 'Methylation-K Validation Sensitivity': 0.10192621483485205, 'Methylation-K Validation Specificity': 0.9212636331812725, 'Methylation-K Validation Precision': 0.12416416699353042, 'Methylation-K AUC ROC': 0.5408503152671892, 'Methylation-K AUC PR': 0.11280665982832254, 'Methylation-K MCC': 0.0249330832342981, 'Methylation-K F1': 0.1025639630911154, 'Validation Loss (Methylation-K)': 0.8993960241476695, 'Validation Loss (total)': 1.2978877703348795, 'TimeToTrain': 36.743714030583696}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009237718107660336,
 'learning_rate_Hydroxylation-K': 0.009000388264632595,
 'learning_rate_Methylation-K': 0.0020816192491582798,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5635545689270983,
 'loss_weight_Methylation-K': 0.462322404371241,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4035930378,
 'sample_weights': [0.05546003489953813, 0.46049371780870646],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.844141604088042,
 'weight_decay_Hydroxylation-K': 6.199537698774633,
 'weight_decay_Methylation-K': 4.833717251074925}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.389
[3,     4] loss: 1.374
[4,     4] loss: 1.375
[5,     4] loss: 1.372
[6,     4] loss: 1.336
[7,     4] loss: 1.338
[8,     4] loss: 1.280
[9,     4] loss: 1.280
[10,     4] loss: 1.198
[11,     4] loss: 1.202
[12,     4] loss: 1.172
[13,     4] loss: 1.127
[14,     4] loss: 1.150
[15,     4] loss: 1.039
[16,     4] loss: 1.071
[17,     4] loss: 1.030
[18,     4] loss: 0.976
[19,     4] loss: 0.922
[20,     4] loss: 0.949
[21,     4] loss: 0.930
[22,     4] loss: 0.871
[23,     4] loss: 0.865
[24,     4] loss: 0.838
[25,     4] loss: 0.876
[26,     4] loss: 0.891
[27,     4] loss: 0.937
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012778708462787502,
 'learning_rate_Hydroxylation-K': 0.009734211603894177,
 'learning_rate_Methylation-K': 0.0012464475281412277,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5683182312515541,
 'loss_weight_Methylation-K': 0.538529324690928,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2775478433,
 'sample_weights': [0.5635545689270983, 0.462322404371241],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.075263709444577,
 'weight_decay_Hydroxylation-K': 6.730772998686895,
 'weight_decay_Methylation-K': 6.601599401617043}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.385
[3,     4] loss: 1.387
[4,     4] loss: 1.382
[5,     4] loss: 1.378
[6,     4] loss: 1.373
[7,     4] loss: 1.355
[8,     4] loss: 1.328
[9,     4] loss: 1.287
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019409012716002294,
 'learning_rate_Hydroxylation-K': 0.005564252873339669,
 'learning_rate_Methylation-K': 0.0076762351315607675,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8463679711275396,
 'loss_weight_Methylation-K': 0.47195220353828066,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 88149066,
 'sample_weights': [0.5683182312515541, 0.538529324690928],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.678179388774739,
 'weight_decay_Hydroxylation-K': 7.324445116127112,
 'weight_decay_Methylation-K': 9.461165924013105}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.387
[3,     4] loss: 1.390
[4,     4] loss: 1.389
[5,     4] loss: 1.387
[6,     4] loss: 1.383
[7,     4] loss: 1.377
[8,     4] loss: 1.365
[9,     4] loss: 1.338
[10,     4] loss: 1.288
[11,     4] loss: 1.218
[12,     4] loss: 1.187
[13,     4] loss: 1.158
[14,     4] loss: 1.143
[15,     4] loss: 1.114
[16,     4] loss: 1.034
[17,     4] loss: 1.007
[18,     4] loss: 0.972
[19,     4] loss: 1.070
[20,     4] loss: 0.946
[21,     4] loss: 0.896
[22,     4] loss: 0.924
[23,     4] loss: 0.990
[24,     4] loss: 0.886
[25,     4] loss: 0.882
[26,     4] loss: 0.954
[27,     4] loss: 0.958
[28,     4] loss: 0.906
[29,     4] loss: 0.854
[30,     4] loss: 0.866
[31,     4] loss: 0.882
[32,     4] loss: 0.873
[33,     4] loss: 0.830
[34,     4] loss: 0.830
[35,     4] loss: 0.885
[36,     4] loss: 0.922
[37,     4] loss: 0.928
[38,     4] loss: 0.907
[39,     4] loss: 0.884
[40,     4] loss: 0.844
[41,     4] loss: 0.847
[42,     4] loss: 0.814
[43,     4] loss: 0.775
[44,     4] loss: 0.775
[45,     4] loss: 0.768
[46,     4] loss: 0.764
[47,     4] loss: 0.788
[48,     4] loss: 0.770
[49,     4] loss: 0.791
[50,     4] loss: 0.770
[51,     4] loss: 0.768
[52,     4] loss: 0.808
[53,     4] loss: 0.765
[54,     4] loss: 0.834
[55,     4] loss: 0.824
[56,     4] loss: 0.890
[57,     4] loss: 0.833
[58,     4] loss: 0.790
[59,     4] loss: 0.811
[60,     4] loss: 0.809
[61,     4] loss: 0.836
[62,     4] loss: 0.876
[63,     4] loss: 0.833
[64,     4] loss: 0.812
[65,     4] loss: 0.794
[66,     4] loss: 0.829
[67,     4] loss: 0.839
[68,     4] loss: 0.955
[69,     4] loss: 0.903
Early stopping applied (best metric=0.2946320176124573)
Finished Training
Total time taken: 34.50398015975952
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.383
[3,     4] loss: 1.387
[4,     4] loss: 1.384
[5,     4] loss: 1.381
[6,     4] loss: 1.377
[7,     4] loss: 1.369
[8,     4] loss: 1.341
[9,     4] loss: 1.288
[10,     4] loss: 1.288
[11,     4] loss: 1.252
[12,     4] loss: 1.222
[13,     4] loss: 1.155
[14,     4] loss: 1.092
[15,     4] loss: 0.995
[16,     4] loss: 1.089
[17,     4] loss: 1.060
[18,     4] loss: 1.006
[19,     4] loss: 1.006
[20,     4] loss: 1.015
[21,     4] loss: 0.932
[22,     4] loss: 1.060
[23,     4] loss: 0.926
[24,     4] loss: 0.913
[25,     4] loss: 0.908
[26,     4] loss: 0.851
[27,     4] loss: 0.872
[28,     4] loss: 0.964
[29,     4] loss: 0.878
[30,     4] loss: 0.955
[31,     4] loss: 0.876
[32,     4] loss: 0.892
[33,     4] loss: 0.909
[34,     4] loss: 0.853
[35,     4] loss: 0.849
[36,     4] loss: 0.816
[37,     4] loss: 0.847
[38,     4] loss: 0.796
[39,     4] loss: 0.896
[40,     4] loss: 0.858
[41,     4] loss: 0.810
[42,     4] loss: 0.806
[43,     4] loss: 0.775
[44,     4] loss: 0.826
[45,     4] loss: 0.800
[46,     4] loss: 0.840
[47,     4] loss: 0.903
[48,     4] loss: 0.891
[49,     4] loss: 0.843
[50,     4] loss: 0.849
[51,     4] loss: 0.834
[52,     4] loss: 0.812
[53,     4] loss: 0.789
[54,     4] loss: 0.787
[55,     4] loss: 0.782
[56,     4] loss: 0.757
[57,     4] loss: 0.770
[58,     4] loss: 0.779
[59,     4] loss: 0.748
[60,     4] loss: 0.759
[61,     4] loss: 0.756
[62,     4] loss: 0.752
[63,     4] loss: 0.823
[64,     4] loss: 0.896
[65,     4] loss: 0.884
[66,     4] loss: 0.840
[67,     4] loss: 0.868
[68,     4] loss: 0.834
[69,     4] loss: 0.808
[70,     4] loss: 0.759
[71,     4] loss: 0.770
[72,     4] loss: 0.787
[73,     4] loss: 0.783
[74,     4] loss: 0.779
[75,     4] loss: 0.757
[76,     4] loss: 0.755
[77,     4] loss: 0.775
[78,     4] loss: 0.784
[79,     4] loss: 0.929
[80,     4] loss: 0.919
[81,     4] loss: 0.875
[82,     4] loss: 0.819
[83,     4] loss: 0.778
[84,     4] loss: 0.775
[85,     4] loss: 0.792
[86,     4] loss: 0.777
[87,     4] loss: 0.788
[88,     4] loss: 0.809
[89,     4] loss: 0.776
[90,     4] loss: 0.843
[91,     4] loss: 0.834
[92,     4] loss: 0.798
[93,     4] loss: 0.784
[94,     4] loss: 0.777
[95,     4] loss: 0.766
[96,     4] loss: 0.790
[97,     4] loss: 0.818
[98,     4] loss: 0.773
[99,     4] loss: 0.788
[100,     4] loss: 0.791
[101,     4] loss: 0.966
[102,     4] loss: 0.942
[103,     4] loss: 0.992
[104,     4] loss: 0.935
[105,     4] loss: 0.891
[106,     4] loss: 0.875
[107,     4] loss: 0.813
[108,     4] loss: 0.811
[109,     4] loss: 0.780
[110,     4] loss: 0.765
[111,     4] loss: 0.817
[112,     4] loss: 0.851
[113,     4] loss: 0.817
[114,     4] loss: 0.824
[115,     4] loss: 0.800
[116,     4] loss: 0.758
[117,     4] loss: 0.795
[118,     4] loss: 0.775
[119,     4] loss: 0.771
[120,     4] loss: 0.766
[121,     4] loss: 0.782
[122,     4] loss: 0.794
[123,     4] loss: 0.831
[124,     4] loss: 0.815
[125,     4] loss: 0.781
[126,     4] loss: 0.774
[127,     4] loss: 0.857
[128,     4] loss: 0.800
[129,     4] loss: 0.933
[130,     4] loss: 0.833
[131,     4] loss: 0.843
[132,     4] loss: 0.787
[133,     4] loss: 0.791
[134,     4] loss: 0.788
[135,     4] loss: 0.794
[136,     4] loss: 0.780
[137,     4] loss: 0.764
[138,     4] loss: 0.747
[139,     4] loss: 0.740
[140,     4] loss: 0.791
Early stopping applied (best metric=0.2771056294441223)
Finished Training
Total time taken: 70.60900473594666
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.405
[2,     4] loss: 1.390
[3,     4] loss: 1.385
[4,     4] loss: 1.382
[5,     4] loss: 1.388
[6,     4] loss: 1.385
[7,     4] loss: 1.384
[8,     4] loss: 1.381
[9,     4] loss: 1.377
[10,     4] loss: 1.364
[11,     4] loss: 1.338
[12,     4] loss: 1.294
[13,     4] loss: 1.276
[14,     4] loss: 1.230
[15,     4] loss: 1.230
[16,     4] loss: 1.151
[17,     4] loss: 1.078
[18,     4] loss: 1.074
[19,     4] loss: 1.087
[20,     4] loss: 1.020
[21,     4] loss: 0.980
[22,     4] loss: 0.990
[23,     4] loss: 0.935
[24,     4] loss: 0.971
[25,     4] loss: 0.986
[26,     4] loss: 0.913
[27,     4] loss: 0.974
[28,     4] loss: 0.922
[29,     4] loss: 0.956
[30,     4] loss: 0.893
[31,     4] loss: 0.862
[32,     4] loss: 0.909
[33,     4] loss: 0.894
[34,     4] loss: 0.873
[35,     4] loss: 0.906
[36,     4] loss: 0.849
[37,     4] loss: 0.812
[38,     4] loss: 0.854
[39,     4] loss: 0.826
[40,     4] loss: 0.814
[41,     4] loss: 0.795
[42,     4] loss: 0.798
[43,     4] loss: 0.759
[44,     4] loss: 0.782
[45,     4] loss: 0.796
[46,     4] loss: 0.845
[47,     4] loss: 0.851
[48,     4] loss: 0.821
[49,     4] loss: 0.831
[50,     4] loss: 0.797
[51,     4] loss: 0.764
[52,     4] loss: 0.753
[53,     4] loss: 0.765
[54,     4] loss: 0.769
[55,     4] loss: 0.769
[56,     4] loss: 0.826
[57,     4] loss: 0.814
[58,     4] loss: 0.850
[59,     4] loss: 0.880
[60,     4] loss: 0.794
[61,     4] loss: 0.860
[62,     4] loss: 0.884
[63,     4] loss: 0.796
[64,     4] loss: 0.795
[65,     4] loss: 0.833
[66,     4] loss: 0.785
[67,     4] loss: 0.790
Early stopping applied (best metric=0.35464948415756226)
Finished Training
Total time taken: 34.168970346450806
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.396
[3,     4] loss: 1.385
[4,     4] loss: 1.389
[5,     4] loss: 1.384
[6,     4] loss: 1.388
[7,     4] loss: 1.383
[8,     4] loss: 1.383
[9,     4] loss: 1.377
[10,     4] loss: 1.359
[11,     4] loss: 1.330
[12,     4] loss: 1.260
[13,     4] loss: 1.206
[14,     4] loss: 1.115
[15,     4] loss: 1.166
[16,     4] loss: 1.084
[17,     4] loss: 1.036
[18,     4] loss: 1.034
[19,     4] loss: 1.014
[20,     4] loss: 1.017
[21,     4] loss: 0.944
[22,     4] loss: 0.908
[23,     4] loss: 0.858
[24,     4] loss: 0.988
[25,     4] loss: 0.911
[26,     4] loss: 0.920
[27,     4] loss: 0.897
[28,     4] loss: 0.843
[29,     4] loss: 0.870
[30,     4] loss: 0.855
[31,     4] loss: 0.868
[32,     4] loss: 1.040
[33,     4] loss: 0.898
[34,     4] loss: 0.886
[35,     4] loss: 0.824
[36,     4] loss: 0.805
[37,     4] loss: 0.784
[38,     4] loss: 0.800
[39,     4] loss: 0.793
[40,     4] loss: 0.788
[41,     4] loss: 0.794
[42,     4] loss: 0.817
[43,     4] loss: 0.772
[44,     4] loss: 0.815
[45,     4] loss: 0.783
[46,     4] loss: 0.835
[47,     4] loss: 0.806
[48,     4] loss: 0.787
[49,     4] loss: 0.780
[50,     4] loss: 0.909
[51,     4] loss: 0.970
[52,     4] loss: 0.878
[53,     4] loss: 0.879
[54,     4] loss: 0.842
[55,     4] loss: 0.968
[56,     4] loss: 0.832
[57,     4] loss: 0.828
[58,     4] loss: 0.801
[59,     4] loss: 0.778
[60,     4] loss: 0.790
[61,     4] loss: 0.796
Early stopping applied (best metric=0.487496554851532)
Finished Training
Total time taken: 30.469866037368774
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.392
[2,     4] loss: 1.389
[3,     4] loss: 1.389
[4,     4] loss: 1.385
[5,     4] loss: 1.385
[6,     4] loss: 1.381
[7,     4] loss: 1.372
[8,     4] loss: 1.352
[9,     4] loss: 1.315
[10,     4] loss: 1.288
[11,     4] loss: 1.181
[12,     4] loss: 1.167
[13,     4] loss: 1.084
[14,     4] loss: 1.096
[15,     4] loss: 1.065
[16,     4] loss: 1.158
[17,     4] loss: 1.095
[18,     4] loss: 1.117
[19,     4] loss: 1.004
[20,     4] loss: 0.975
[21,     4] loss: 0.938
[22,     4] loss: 0.903
[23,     4] loss: 0.907
[24,     4] loss: 0.907
[25,     4] loss: 0.979
[26,     4] loss: 0.938
[27,     4] loss: 0.893
[28,     4] loss: 0.864
[29,     4] loss: 0.925
[30,     4] loss: 0.896
[31,     4] loss: 0.874
[32,     4] loss: 0.834
[33,     4] loss: 0.887
[34,     4] loss: 0.889
[35,     4] loss: 0.898
[36,     4] loss: 0.873
[37,     4] loss: 0.828
[38,     4] loss: 0.811
[39,     4] loss: 0.829
[40,     4] loss: 0.826
[41,     4] loss: 0.809
[42,     4] loss: 0.814
[43,     4] loss: 0.781
[44,     4] loss: 0.829
[45,     4] loss: 0.784
[46,     4] loss: 0.854
[47,     4] loss: 0.784
[48,     4] loss: 0.783
[49,     4] loss: 0.798
[50,     4] loss: 0.824
[51,     4] loss: 0.851
[52,     4] loss: 0.832
[53,     4] loss: 0.860
[54,     4] loss: 0.830
[55,     4] loss: 0.848
[56,     4] loss: 0.868
[57,     4] loss: 0.856
[58,     4] loss: 0.825
[59,     4] loss: 0.879
[60,     4] loss: 0.790
[61,     4] loss: 0.778
[62,     4] loss: 0.775
[63,     4] loss: 0.802
[64,     4] loss: 0.823
[65,     4] loss: 0.810
[66,     4] loss: 0.802
[67,     4] loss: 0.818
[68,     4] loss: 0.873
Early stopping applied (best metric=0.422139972448349)
Finished Training
Total time taken: 34.55297875404358
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.386
[3,     4] loss: 1.379
[4,     4] loss: 1.376
[5,     4] loss: 1.365
[6,     4] loss: 1.345
[7,     4] loss: 1.287
[8,     4] loss: 1.260
[9,     4] loss: 1.204
[10,     4] loss: 1.169
[11,     4] loss: 1.171
[12,     4] loss: 1.190
[13,     4] loss: 1.088
[14,     4] loss: 1.085
[15,     4] loss: 1.127
[16,     4] loss: 1.056
[17,     4] loss: 1.021
[18,     4] loss: 0.958
[19,     4] loss: 0.935
[20,     4] loss: 0.933
[21,     4] loss: 0.958
[22,     4] loss: 0.934
[23,     4] loss: 0.942
[24,     4] loss: 0.907
[25,     4] loss: 0.845
[26,     4] loss: 0.873
[27,     4] loss: 0.843
[28,     4] loss: 0.827
[29,     4] loss: 0.819
[30,     4] loss: 0.877
[31,     4] loss: 0.909
[32,     4] loss: 0.823
[33,     4] loss: 0.797
[34,     4] loss: 0.805
[35,     4] loss: 0.801
[36,     4] loss: 0.770
[37,     4] loss: 0.780
[38,     4] loss: 0.761
[39,     4] loss: 0.764
[40,     4] loss: 0.793
[41,     4] loss: 0.765
[42,     4] loss: 0.748
[43,     4] loss: 0.757
[44,     4] loss: 0.782
[45,     4] loss: 0.837
[46,     4] loss: 0.775
[47,     4] loss: 0.846
[48,     4] loss: 0.903
[49,     4] loss: 0.825
[50,     4] loss: 0.857
[51,     4] loss: 0.791
[52,     4] loss: 0.778
[53,     4] loss: 0.790
[54,     4] loss: 0.795
[55,     4] loss: 0.804
[56,     4] loss: 0.801
[57,     4] loss: 0.935
[58,     4] loss: 0.832
[59,     4] loss: 0.793
Early stopping applied (best metric=0.48153793811798096)
Finished Training
Total time taken: 29.800844430923462
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.390
[3,     4] loss: 1.382
[4,     4] loss: 1.387
[5,     4] loss: 1.385
[6,     4] loss: 1.383
[7,     4] loss: 1.378
[8,     4] loss: 1.362
[9,     4] loss: 1.321
[10,     4] loss: 1.281
[11,     4] loss: 1.250
[12,     4] loss: 1.192
[13,     4] loss: 1.126
[14,     4] loss: 1.063
[15,     4] loss: 1.075
[16,     4] loss: 1.031
[17,     4] loss: 1.067
[18,     4] loss: 1.038
[19,     4] loss: 0.948
[20,     4] loss: 0.959
[21,     4] loss: 0.964
[22,     4] loss: 0.954
[23,     4] loss: 0.954
[24,     4] loss: 0.908
[25,     4] loss: 0.865
[26,     4] loss: 0.853
[27,     4] loss: 0.825
[28,     4] loss: 0.814
[29,     4] loss: 0.828
[30,     4] loss: 0.805
[31,     4] loss: 0.869
[32,     4] loss: 0.858
[33,     4] loss: 0.829
[34,     4] loss: 0.844
[35,     4] loss: 0.801
[36,     4] loss: 0.838
[37,     4] loss: 0.826
[38,     4] loss: 0.801
[39,     4] loss: 0.870
[40,     4] loss: 0.788
[41,     4] loss: 0.850
[42,     4] loss: 0.869
[43,     4] loss: 0.818
[44,     4] loss: 0.812
[45,     4] loss: 0.785
[46,     4] loss: 0.770
[47,     4] loss: 0.757
[48,     4] loss: 0.758
[49,     4] loss: 0.760
[50,     4] loss: 0.783
[51,     4] loss: 0.971
[52,     4] loss: 0.867
[53,     4] loss: 0.821
[54,     4] loss: 0.839
[55,     4] loss: 0.798
[56,     4] loss: 0.831
[57,     4] loss: 0.812
[58,     4] loss: 0.866
[59,     4] loss: 0.781
[60,     4] loss: 0.840
Early stopping applied (best metric=0.45984721183776855)
Finished Training
Total time taken: 30.185861110687256
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.388
[3,     4] loss: 1.383
[4,     4] loss: 1.385
[5,     4] loss: 1.385
[6,     4] loss: 1.376
[7,     4] loss: 1.361
[8,     4] loss: 1.328
[9,     4] loss: 1.282
[10,     4] loss: 1.219
[11,     4] loss: 1.180
[12,     4] loss: 1.091
[13,     4] loss: 1.083
[14,     4] loss: 1.073
[15,     4] loss: 1.021
[16,     4] loss: 1.052
[17,     4] loss: 1.075
[18,     4] loss: 1.014
[19,     4] loss: 1.005
[20,     4] loss: 0.966
[21,     4] loss: 0.892
[22,     4] loss: 0.882
[23,     4] loss: 0.848
[24,     4] loss: 0.815
[25,     4] loss: 0.866
[26,     4] loss: 0.839
[27,     4] loss: 0.853
[28,     4] loss: 0.823
[29,     4] loss: 0.825
[30,     4] loss: 0.806
[31,     4] loss: 0.838
[32,     4] loss: 0.941
[33,     4] loss: 1.061
[34,     4] loss: 1.019
[35,     4] loss: 0.936
[36,     4] loss: 0.923
[37,     4] loss: 0.879
[38,     4] loss: 0.917
[39,     4] loss: 0.820
[40,     4] loss: 0.829
[41,     4] loss: 0.816
[42,     4] loss: 0.809
[43,     4] loss: 0.837
[44,     4] loss: 0.799
[45,     4] loss: 0.784
[46,     4] loss: 0.767
[47,     4] loss: 0.782
[48,     4] loss: 0.766
[49,     4] loss: 0.846
[50,     4] loss: 0.807
[51,     4] loss: 0.820
[52,     4] loss: 0.834
[53,     4] loss: 0.773
[54,     4] loss: 0.757
[55,     4] loss: 0.798
[56,     4] loss: 0.797
[57,     4] loss: 0.834
[58,     4] loss: 0.827
[59,     4] loss: 0.803
[60,     4] loss: 0.793
[61,     4] loss: 0.806
[62,     4] loss: 0.793
[63,     4] loss: 0.846
[64,     4] loss: 1.196
[65,     4] loss: 0.994
[66,     4] loss: 0.976
[67,     4] loss: 0.929
[68,     4] loss: 0.877
[69,     4] loss: 0.857
[70,     4] loss: 0.859
Early stopping applied (best metric=0.38613027334213257)
Finished Training
Total time taken: 35.39300513267517
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.386
[3,     4] loss: 1.391
[4,     4] loss: 1.381
[5,     4] loss: 1.380
[6,     4] loss: 1.368
[7,     4] loss: 1.343
[8,     4] loss: 1.278
[9,     4] loss: 1.242
[10,     4] loss: 1.170
[11,     4] loss: 1.181
[12,     4] loss: 1.134
[13,     4] loss: 1.159
[14,     4] loss: 1.083
[15,     4] loss: 0.992
[16,     4] loss: 1.034
[17,     4] loss: 1.052
[18,     4] loss: 1.081
[19,     4] loss: 0.974
[20,     4] loss: 1.062
[21,     4] loss: 0.962
[22,     4] loss: 0.953
[23,     4] loss: 0.975
[24,     4] loss: 0.966
[25,     4] loss: 0.898
[26,     4] loss: 0.893
[27,     4] loss: 0.874
[28,     4] loss: 0.942
[29,     4] loss: 0.937
[30,     4] loss: 0.856
[31,     4] loss: 0.847
[32,     4] loss: 0.855
[33,     4] loss: 0.858
[34,     4] loss: 0.823
[35,     4] loss: 0.796
[36,     4] loss: 0.808
[37,     4] loss: 0.840
[38,     4] loss: 0.856
[39,     4] loss: 0.791
[40,     4] loss: 0.813
[41,     4] loss: 0.785
[42,     4] loss: 0.774
[43,     4] loss: 0.759
[44,     4] loss: 0.819
[45,     4] loss: 0.820
[46,     4] loss: 0.794
[47,     4] loss: 0.818
[48,     4] loss: 0.836
[49,     4] loss: 0.859
[50,     4] loss: 0.831
[51,     4] loss: 0.848
[52,     4] loss: 0.968
[53,     4] loss: 0.879
[54,     4] loss: 0.866
[55,     4] loss: 0.857
[56,     4] loss: 0.817
[57,     4] loss: 0.779
[58,     4] loss: 0.794
[59,     4] loss: 0.795
[60,     4] loss: 0.794
[61,     4] loss: 0.800
[62,     4] loss: 0.780
[63,     4] loss: 0.800
[64,     4] loss: 0.865
[65,     4] loss: 0.830
[66,     4] loss: 0.847
[67,     4] loss: 0.918
[68,     4] loss: 1.033
[69,     4] loss: 0.892
[70,     4] loss: 0.828
[71,     4] loss: 0.815
[72,     4] loss: 0.823
[73,     4] loss: 0.842
[74,     4] loss: 0.782
[75,     4] loss: 0.777
[76,     4] loss: 0.777
[77,     4] loss: 0.799
[78,     4] loss: 0.799
[79,     4] loss: 0.840
[80,     4] loss: 0.860
[81,     4] loss: 0.917
[82,     4] loss: 0.859
[83,     4] loss: 0.916
[84,     4] loss: 0.830
[85,     4] loss: 0.789
[86,     4] loss: 0.792
[87,     4] loss: 0.831
[88,     4] loss: 0.814
[89,     4] loss: 0.782
[90,     4] loss: 0.796
[91,     4] loss: 0.805
[92,     4] loss: 0.834
[93,     4] loss: 0.802
[94,     4] loss: 0.780
[95,     4] loss: 0.788
[96,     4] loss: 0.955
[97,     4] loss: 0.885
[98,     4] loss: 0.832
[99,     4] loss: 0.911
[100,     4] loss: 0.956
[101,     4] loss: 0.868
[102,     4] loss: 0.836
[103,     4] loss: 0.854
[104,     4] loss: 0.824
Early stopping applied (best metric=0.2607932984828949)
Finished Training
Total time taken: 53.73952555656433
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.384
[2,     4] loss: 1.382
[3,     4] loss: 1.389
[4,     4] loss: 1.384
[5,     4] loss: 1.384
[6,     4] loss: 1.376
[7,     4] loss: 1.363
[8,     4] loss: 1.338
[9,     4] loss: 1.275
[10,     4] loss: 1.176
[11,     4] loss: 1.114
[12,     4] loss: 1.140
[13,     4] loss: 1.122
[14,     4] loss: 1.104
[15,     4] loss: 1.115
[16,     4] loss: 1.106
[17,     4] loss: 1.072
[18,     4] loss: 1.043
[19,     4] loss: 0.984
[20,     4] loss: 0.968
[21,     4] loss: 0.921
[22,     4] loss: 1.000
[23,     4] loss: 0.912
[24,     4] loss: 0.972
[25,     4] loss: 0.945
[26,     4] loss: 0.938
[27,     4] loss: 0.988
[28,     4] loss: 1.065
[29,     4] loss: 0.960
[30,     4] loss: 0.925
[31,     4] loss: 0.917
[32,     4] loss: 0.880
[33,     4] loss: 0.846
[34,     4] loss: 0.904
[35,     4] loss: 0.900
[36,     4] loss: 0.873
[37,     4] loss: 0.851
[38,     4] loss: 0.847
[39,     4] loss: 0.788
[40,     4] loss: 0.808
[41,     4] loss: 0.800
[42,     4] loss: 0.821
[43,     4] loss: 0.801
[44,     4] loss: 0.811
[45,     4] loss: 0.805
[46,     4] loss: 0.798
[47,     4] loss: 0.788
[48,     4] loss: 0.800
[49,     4] loss: 0.813
[50,     4] loss: 0.808
[51,     4] loss: 0.820
[52,     4] loss: 0.786
[53,     4] loss: 0.794
[54,     4] loss: 0.849
[55,     4] loss: 0.831
[56,     4] loss: 0.800
[57,     4] loss: 0.786
[58,     4] loss: 0.815
[59,     4] loss: 0.786
[60,     4] loss: 0.827
[61,     4] loss: 0.801
[62,     4] loss: 0.785
[63,     4] loss: 0.813
[64,     4] loss: 0.916
[65,     4] loss: 0.836
[66,     4] loss: 0.841
[67,     4] loss: 0.786
[68,     4] loss: 0.799
[69,     4] loss: 0.850
[70,     4] loss: 0.811
[71,     4] loss: 0.932
[72,     4] loss: 0.858
[73,     4] loss: 0.829
[74,     4] loss: 0.812
[75,     4] loss: 0.834
[76,     4] loss: 0.868
[77,     4] loss: 0.859
[78,     4] loss: 0.825
Early stopping applied (best metric=0.4245980978012085)
Finished Training
Total time taken: 39.2821159362793
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.383
[3,     4] loss: 1.387
[4,     4] loss: 1.386
[5,     4] loss: 1.382
[6,     4] loss: 1.364
[7,     4] loss: 1.361
[8,     4] loss: 1.333
[9,     4] loss: 1.284
[10,     4] loss: 1.207
[11,     4] loss: 1.213
[12,     4] loss: 1.115
[13,     4] loss: 1.094
[14,     4] loss: 1.100
[15,     4] loss: 1.040
[16,     4] loss: 1.009
[17,     4] loss: 1.018
[18,     4] loss: 1.002
[19,     4] loss: 1.021
[20,     4] loss: 0.951
[21,     4] loss: 0.958
[22,     4] loss: 0.914
[23,     4] loss: 0.880
[24,     4] loss: 0.939
[25,     4] loss: 0.955
[26,     4] loss: 0.968
[27,     4] loss: 0.962
[28,     4] loss: 0.913
[29,     4] loss: 0.897
[30,     4] loss: 0.829
[31,     4] loss: 0.794
[32,     4] loss: 0.808
[33,     4] loss: 0.829
[34,     4] loss: 0.789
[35,     4] loss: 0.808
[36,     4] loss: 0.780
[37,     4] loss: 0.812
[38,     4] loss: 0.799
[39,     4] loss: 0.801
[40,     4] loss: 0.786
[41,     4] loss: 0.783
[42,     4] loss: 0.786
[43,     4] loss: 0.773
[44,     4] loss: 0.806
[45,     4] loss: 0.804
[46,     4] loss: 0.786
[47,     4] loss: 0.760
[48,     4] loss: 0.905
[49,     4] loss: 0.941
[50,     4] loss: 0.946
[51,     4] loss: 0.923
[52,     4] loss: 0.843
[53,     4] loss: 0.816
[54,     4] loss: 0.776
[55,     4] loss: 0.766
[56,     4] loss: 0.783
[57,     4] loss: 0.776
[58,     4] loss: 0.793
[59,     4] loss: 0.783
[60,     4] loss: 0.792
[61,     4] loss: 0.795
[62,     4] loss: 0.859
[63,     4] loss: 0.825
[64,     4] loss: 0.809
[65,     4] loss: 0.802
[66,     4] loss: 0.808
[67,     4] loss: 0.899
[68,     4] loss: 0.880
[69,     4] loss: 0.820
[70,     4] loss: 0.800
[71,     4] loss: 0.930
[72,     4] loss: 0.880
[73,     4] loss: 0.850
[74,     4] loss: 0.864
[75,     4] loss: 0.786
[76,     4] loss: 0.770
[77,     4] loss: 0.868
[78,     4] loss: 0.879
[79,     4] loss: 0.868
[80,     4] loss: 0.858
[81,     4] loss: 0.851
[82,     4] loss: 0.817
[83,     4] loss: 0.810
[84,     4] loss: 0.806
[85,     4] loss: 0.821
[86,     4] loss: 0.851
[87,     4] loss: 0.810
[88,     4] loss: 0.822
[89,     4] loss: 0.827
[90,     4] loss: 0.789
[91,     4] loss: 0.777
[92,     4] loss: 0.770
[93,     4] loss: 0.802
[94,     4] loss: 0.816
[95,     4] loss: 0.811
[96,     4] loss: 0.824
[97,     4] loss: 0.832
[98,     4] loss: 0.778
[99,     4] loss: 0.871
[100,     4] loss: 0.856
[101,     4] loss: 0.805
[102,     4] loss: 0.792
[103,     4] loss: 0.788
[104,     4] loss: 0.837
[105,     4] loss: 0.789
[106,     4] loss: 0.789
[107,     4] loss: 0.764
[108,     4] loss: 0.790
[109,     4] loss: 0.944
[110,     4] loss: 0.969
[111,     4] loss: 0.903
[112,     4] loss: 0.847
[113,     4] loss: 0.805
[114,     4] loss: 0.813
[115,     4] loss: 0.838
[116,     4] loss: 0.809
[117,     4] loss: 0.800
[118,     4] loss: 0.838
[119,     4] loss: 0.888
[120,     4] loss: 0.819
[121,     4] loss: 0.819
[122,     4] loss: 0.816
Early stopping applied (best metric=0.2306734323501587)
Finished Training
Total time taken: 64.24782824516296
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.387
[3,     4] loss: 1.377
[4,     4] loss: 1.379
[5,     4] loss: 1.368
[6,     4] loss: 1.360
[7,     4] loss: 1.310
[8,     4] loss: 1.279
[9,     4] loss: 1.216
[10,     4] loss: 1.193
[11,     4] loss: 1.110
[12,     4] loss: 1.123
[13,     4] loss: 1.109
[14,     4] loss: 1.050
[15,     4] loss: 1.046
[16,     4] loss: 1.024
[17,     4] loss: 1.042
[18,     4] loss: 1.055
[19,     4] loss: 1.084
[20,     4] loss: 1.034
[21,     4] loss: 0.966
[22,     4] loss: 0.996
[23,     4] loss: 1.017
[24,     4] loss: 0.954
[25,     4] loss: 0.951
[26,     4] loss: 0.919
[27,     4] loss: 0.882
[28,     4] loss: 0.838
[29,     4] loss: 0.818
[30,     4] loss: 0.839
[31,     4] loss: 0.802
[32,     4] loss: 0.816
[33,     4] loss: 0.835
[34,     4] loss: 0.833
[35,     4] loss: 0.839
[36,     4] loss: 0.952
[37,     4] loss: 0.895
[38,     4] loss: 0.927
[39,     4] loss: 0.849
[40,     4] loss: 0.900
[41,     4] loss: 0.920
[42,     4] loss: 0.849
[43,     4] loss: 0.823
[44,     4] loss: 0.811
[45,     4] loss: 0.783
[46,     4] loss: 0.791
[47,     4] loss: 0.800
[48,     4] loss: 0.875
[49,     4] loss: 0.842
[50,     4] loss: 0.799
[51,     4] loss: 0.780
[52,     4] loss: 0.758
[53,     4] loss: 0.750
[54,     4] loss: 0.777
[55,     4] loss: 0.893
[56,     4] loss: 0.922
[57,     4] loss: 0.886
[58,     4] loss: 0.877
[59,     4] loss: 0.859
[60,     4] loss: 0.816
[61,     4] loss: 0.822
[62,     4] loss: 0.799
[63,     4] loss: 0.773
[64,     4] loss: 0.777
[65,     4] loss: 0.774
[66,     4] loss: 0.801
[67,     4] loss: 0.807
[68,     4] loss: 0.787
[69,     4] loss: 0.820
[70,     4] loss: 0.863
[71,     4] loss: 0.805
[72,     4] loss: 0.791
[73,     4] loss: 0.770
[74,     4] loss: 0.800
[75,     4] loss: 0.821
[76,     4] loss: 0.869
[77,     4] loss: 0.911
[78,     4] loss: 0.836
[79,     4] loss: 0.806
Early stopping applied (best metric=0.1256178319454193)
Finished Training
Total time taken: 42.48720407485962
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.384
[3,     4] loss: 1.388
[4,     4] loss: 1.387
[5,     4] loss: 1.382
[6,     4] loss: 1.370
[7,     4] loss: 1.353
[8,     4] loss: 1.330
[9,     4] loss: 1.328
[10,     4] loss: 1.230
[11,     4] loss: 1.175
[12,     4] loss: 1.128
[13,     4] loss: 1.136
[14,     4] loss: 1.080
[15,     4] loss: 1.019
[16,     4] loss: 1.040
[17,     4] loss: 0.994
[18,     4] loss: 0.994
[19,     4] loss: 0.923
[20,     4] loss: 0.897
[21,     4] loss: 0.905
[22,     4] loss: 0.873
[23,     4] loss: 0.938
[24,     4] loss: 0.972
[25,     4] loss: 0.924
[26,     4] loss: 0.886
[27,     4] loss: 0.903
[28,     4] loss: 0.844
[29,     4] loss: 0.828
[30,     4] loss: 0.826
[31,     4] loss: 0.812
[32,     4] loss: 0.789
[33,     4] loss: 0.804
[34,     4] loss: 0.787
[35,     4] loss: 0.765
[36,     4] loss: 0.817
[37,     4] loss: 0.843
[38,     4] loss: 0.779
[39,     4] loss: 0.789
[40,     4] loss: 0.794
[41,     4] loss: 0.914
[42,     4] loss: 0.840
[43,     4] loss: 0.817
[44,     4] loss: 0.805
[45,     4] loss: 0.760
[46,     4] loss: 0.802
[47,     4] loss: 0.788
[48,     4] loss: 0.873
[49,     4] loss: 0.888
[50,     4] loss: 0.833
[51,     4] loss: 0.812
[52,     4] loss: 0.803
[53,     4] loss: 0.811
[54,     4] loss: 0.795
[55,     4] loss: 0.790
[56,     4] loss: 0.754
[57,     4] loss: 0.773
[58,     4] loss: 0.809
[59,     4] loss: 0.977
[60,     4] loss: 0.863
[61,     4] loss: 0.844
Early stopping applied (best metric=0.3923019766807556)
Finished Training
Total time taken: 31.750941276550293
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.380
[3,     4] loss: 1.385
[4,     4] loss: 1.370
[5,     4] loss: 1.341
[6,     4] loss: 1.296
[7,     4] loss: 1.224
[8,     4] loss: 1.166
[9,     4] loss: 1.216
[10,     4] loss: 1.133
[11,     4] loss: 1.009
[12,     4] loss: 0.988
[13,     4] loss: 0.943
[14,     4] loss: 0.966
[15,     4] loss: 0.894
[16,     4] loss: 0.924
[17,     4] loss: 0.982
[18,     4] loss: 0.926
[19,     4] loss: 0.874
[20,     4] loss: 0.865
[21,     4] loss: 0.929
[22,     4] loss: 0.897
[23,     4] loss: 0.932
[24,     4] loss: 0.883
[25,     4] loss: 1.027
[26,     4] loss: 0.946
[27,     4] loss: 0.979
[28,     4] loss: 0.904
[29,     4] loss: 0.892
[30,     4] loss: 0.832
[31,     4] loss: 0.830
[32,     4] loss: 0.813
[33,     4] loss: 0.821
[34,     4] loss: 0.787
[35,     4] loss: 0.821
[36,     4] loss: 0.812
[37,     4] loss: 0.834
[38,     4] loss: 0.811
[39,     4] loss: 0.819
[40,     4] loss: 0.785
[41,     4] loss: 0.827
[42,     4] loss: 0.861
[43,     4] loss: 0.818
[44,     4] loss: 0.813
[45,     4] loss: 0.781
[46,     4] loss: 0.777
[47,     4] loss: 0.780
[48,     4] loss: 0.806
[49,     4] loss: 0.770
[50,     4] loss: 0.845
[51,     4] loss: 0.779
[52,     4] loss: 0.780
[53,     4] loss: 0.780
[54,     4] loss: 0.757
[55,     4] loss: 0.769
[56,     4] loss: 0.819
Early stopping applied (best metric=0.5111295580863953)
Finished Training
Total time taken: 29.710845470428467
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.395
[2,     4] loss: 1.383
[3,     4] loss: 1.390
[4,     4] loss: 1.384
[5,     4] loss: 1.378
[6,     4] loss: 1.373
[7,     4] loss: 1.369
[8,     4] loss: 1.350
[9,     4] loss: 1.321
[10,     4] loss: 1.287
[11,     4] loss: 1.252
[12,     4] loss: 1.153
[13,     4] loss: 1.125
[14,     4] loss: 1.175
[15,     4] loss: 1.059
[16,     4] loss: 1.077
[17,     4] loss: 1.078
[18,     4] loss: 1.003
[19,     4] loss: 0.974
[20,     4] loss: 0.921
[21,     4] loss: 0.972
[22,     4] loss: 0.973
[23,     4] loss: 0.974
[24,     4] loss: 0.946
[25,     4] loss: 0.933
[26,     4] loss: 0.952
[27,     4] loss: 0.870
[28,     4] loss: 0.865
[29,     4] loss: 0.856
[30,     4] loss: 0.836
[31,     4] loss: 0.924
[32,     4] loss: 0.875
[33,     4] loss: 0.832
[34,     4] loss: 0.830
[35,     4] loss: 0.811
[36,     4] loss: 0.864
[37,     4] loss: 0.818
[38,     4] loss: 0.820
[39,     4] loss: 0.826
[40,     4] loss: 0.869
[41,     4] loss: 0.882
[42,     4] loss: 0.878
[43,     4] loss: 0.852
[44,     4] loss: 0.856
[45,     4] loss: 0.825
[46,     4] loss: 0.850
[47,     4] loss: 0.811
[48,     4] loss: 0.778
[49,     4] loss: 0.788
[50,     4] loss: 0.786
[51,     4] loss: 0.765
[52,     4] loss: 0.763
[53,     4] loss: 0.793
[54,     4] loss: 0.782
[55,     4] loss: 0.801
[56,     4] loss: 0.827
[57,     4] loss: 0.840
[58,     4] loss: 0.794
[59,     4] loss: 0.788
[60,     4] loss: 0.809
[61,     4] loss: 0.877
[62,     4] loss: 0.913
[63,     4] loss: 0.887
[64,     4] loss: 0.851
Early stopping applied (best metric=0.34535354375839233)
Finished Training
Total time taken: 33.3229455947876
{'Hydroxylation-K Validation Accuracy': 0.7893617021276595, 'Hydroxylation-K Validation Sensitivity': 0.7837037037037037, 'Hydroxylation-K Validation Specificity': 0.7912280701754386, 'Hydroxylation-K Validation Precision': 0.5072732169790993, 'Hydroxylation-K AUC ROC': 0.8550487329434697, 'Hydroxylation-K AUC PR': 0.6441085532449058, 'Hydroxylation-K MCC': 0.5036114204626874, 'Hydroxylation-K F1': 0.6083879387127763, 'Validation Loss (Hydroxylation-K)': 0.3636004547278086, 'Methylation-K Validation Accuracy': 0.8026657636079021, 'Methylation-K Validation Sensitivity': 0.15350632143603268, 'Methylation-K Validation Specificity': 0.8730681075135737, 'Methylation-K Validation Precision': 0.11774530263805072, 'Methylation-K AUC ROC': 0.5394075417149172, 'Methylation-K AUC PR': 0.11090029742259105, 'Methylation-K MCC': 0.023441645096245016, 'Methylation-K F1': 0.12120159776888893, 'Validation Loss (Methylation-K)': 0.8407166242599488, 'Validation Loss (total)': 1.2043170849482219, 'TimeToTrain': 39.615061124165855}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005004771217187802,
 'learning_rate_Hydroxylation-K': 0.0008410743617568634,
 'learning_rate_Methylation-K': 0.0003709649353685968,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5832679779504331,
 'loss_weight_Methylation-K': 0.23482452609442261,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2547409423,
 'sample_weights': [0.8463679711275396, 0.47195220353828066],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.050693964998602,
 'weight_decay_Hydroxylation-K': 4.8551819745730045,
 'weight_decay_Methylation-K': 7.205640080473825}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.385
[3,     4] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0004661258834052307,
 'learning_rate_Hydroxylation-K': 0.006586555732500526,
 'learning_rate_Methylation-K': 0.004087025698545831,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.40815678733151195,
 'loss_weight_Methylation-K': 0.6439447923326775,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 768344554,
 'sample_weights': [0.5832679779504331, 0.23482452609442261],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.9116540189560265,
 'weight_decay_Hydroxylation-K': 3.3289046116139107,
 'weight_decay_Methylation-K': 7.98483430080466}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.387
[3,     4] loss: 1.384
[4,     4] loss: 1.380
[5,     4] loss: 1.377
[6,     4] loss: 1.369
[7,     4] loss: 1.362
[8,     4] loss: 1.339
[9,     4] loss: 1.325
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0044053475437449115,
 'learning_rate_Hydroxylation-K': 0.0034398649417191935,
 'learning_rate_Methylation-K': 0.0015336851931763444,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.44741810306226615,
 'loss_weight_Methylation-K': 0.9540970708210552,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1846237923,
 'sample_weights': [0.40815678733151195, 0.6439447923326775],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.020945816134025,
 'weight_decay_Hydroxylation-K': 7.236411685200329,
 'weight_decay_Methylation-K': 4.273050516815266}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.390
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.000622667806089202,
 'learning_rate_Hydroxylation-K': 0.004764588848484361,
 'learning_rate_Methylation-K': 0.00930565123648363,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1603640157370664,
 'loss_weight_Methylation-K': 0.6587233988769294,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3707041874,
 'sample_weights': [0.44741810306226615, 0.9540970708210552],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.1621471332035895,
 'weight_decay_Hydroxylation-K': 3.328631291229015,
 'weight_decay_Methylation-K': 7.740695885785826}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.400
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.383
[5,     4] loss: 1.383
[6,     4] loss: 1.379
[7,     4] loss: 1.363
[8,     4] loss: 1.347
[9,     4] loss: 1.333
[10,     4] loss: 1.321
[11,     4] loss: 1.286
[12,     4] loss: 1.282
[13,     4] loss: 1.258
[14,     4] loss: 1.224
[15,     4] loss: 1.182
[16,     4] loss: 1.055
[17,     4] loss: 1.055
[18,     4] loss: 1.090
[19,     4] loss: 1.076
[20,     4] loss: 1.025
[21,     4] loss: 0.989
[22,     4] loss: 0.962
[23,     4] loss: 0.967
[24,     4] loss: 0.943
[25,     4] loss: 0.906
[26,     4] loss: 1.002
[27,     4] loss: 0.893
[28,     4] loss: 0.895
[29,     4] loss: 0.905
[30,     4] loss: 0.894
[31,     4] loss: 0.882
[32,     4] loss: 0.814
[33,     4] loss: 0.806
[34,     4] loss: 0.796
[35,     4] loss: 0.801
[36,     4] loss: 0.792
[37,     4] loss: 0.766
[38,     4] loss: 0.771
[39,     4] loss: 0.765
[40,     4] loss: 0.753
[41,     4] loss: 0.780
[42,     4] loss: 0.756
[43,     4] loss: 0.742
[44,     4] loss: 0.767
[45,     4] loss: 0.789
[46,     4] loss: 0.750
[47,     4] loss: 0.746
[48,     4] loss: 0.762
[49,     4] loss: 0.822
[50,     4] loss: 0.768
[51,     4] loss: 0.748
[52,     4] loss: 0.750
[53,     4] loss: 0.783
[54,     4] loss: 0.766
[55,     4] loss: 0.731
[56,     4] loss: 0.741
[57,     4] loss: 0.722
[58,     4] loss: 0.744
[59,     4] loss: 0.772
[60,     4] loss: 0.732
[61,     4] loss: 0.726
[62,     4] loss: 0.742
[63,     4] loss: 0.726
[64,     4] loss: 0.746
[65,     4] loss: 0.738
[66,     4] loss: 0.760
[67,     4] loss: 0.756
[68,     4] loss: 0.784
[69,     4] loss: 0.759
[70,     4] loss: 0.737
[71,     4] loss: 0.723
[72,     4] loss: 0.723
[73,     4] loss: 0.725
[74,     4] loss: 0.706
[75,     4] loss: 0.721
[76,     4] loss: 0.719
[77,     4] loss: 0.710
[78,     4] loss: 0.712
[79,     4] loss: 0.709
[80,     4] loss: 0.715
[81,     4] loss: 0.721
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009313947103645442,
 'learning_rate_Hydroxylation-K': 0.006135490196863403,
 'learning_rate_Methylation-K': 0.009792003630255857,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.047311970917984975,
 'loss_weight_Methylation-K': 0.6806366455059263,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3899812106,
 'sample_weights': [0.1603640157370664, 0.6587233988769294],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.224154302094293,
 'weight_decay_Hydroxylation-K': 3.5368454778218434,
 'weight_decay_Methylation-K': 5.572824345720379}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.390
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012363584576588022,
 'learning_rate_Hydroxylation-K': 0.007075075236944829,
 'learning_rate_Methylation-K': 0.007900300706921078,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6969325950424633,
 'loss_weight_Methylation-K': 0.8489242854389732,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2397604364,
 'sample_weights': [0.047311970917984975, 0.6806366455059263],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.23496630155402,
 'weight_decay_Hydroxylation-K': 6.007861501929475,
 'weight_decay_Methylation-K': 0.489878171059563}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.384
[5,     4] loss: 1.377
[6,     4] loss: 1.361
[7,     4] loss: 1.361
[8,     4] loss: 1.327
[9,     4] loss: 1.296
[10,     4] loss: 1.255
[11,     4] loss: 1.212
[12,     4] loss: 1.125
[13,     4] loss: 1.156
[14,     4] loss: 1.097
[15,     4] loss: 1.098
[16,     4] loss: 1.009
[17,     4] loss: 0.938
[18,     4] loss: 0.952
[19,     4] loss: 0.925
[20,     4] loss: 0.957
[21,     4] loss: 0.951
[22,     4] loss: 0.855
[23,     4] loss: 0.851
[24,     4] loss: 0.932
[25,     4] loss: 0.858
[26,     4] loss: 0.890
[27,     4] loss: 0.817
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003850063660289123,
 'learning_rate_Hydroxylation-K': 0.002940559886949477,
 'learning_rate_Methylation-K': 0.004895117289123889,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7851473509950817,
 'loss_weight_Methylation-K': 0.9706110011359318,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 473304476,
 'sample_weights': [0.6969325950424633, 0.8489242854389732],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.7175514356853157,
 'weight_decay_Hydroxylation-K': 5.117342760621102,
 'weight_decay_Methylation-K': 0.9543220657214444}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.395
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0025655989238582153,
 'learning_rate_Hydroxylation-K': 0.00045772623731660787,
 'learning_rate_Methylation-K': 0.00550630819610478,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.048813985219112864,
 'loss_weight_Methylation-K': 0.5948053634641047,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 101331876,
 'sample_weights': [0.7851473509950817, 0.9706110011359318],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.561412427521672,
 'weight_decay_Hydroxylation-K': 2.554858938880514,
 'weight_decay_Methylation-K': 6.999944046928505}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.390
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00354287986779899,
 'learning_rate_Hydroxylation-K': 0.0007755294005938928,
 'learning_rate_Methylation-K': 0.0017600127234124602,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9514682547257055,
 'loss_weight_Methylation-K': 0.8871445700563291,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 831047112,
 'sample_weights': [0.048813985219112864, 0.5948053634641047],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.621254660881217,
 'weight_decay_Hydroxylation-K': 7.3177059790364485,
 'weight_decay_Methylation-K': 8.536463087691581}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.385
[3,     4] loss: 1.385
[4,     4] loss: 1.382
[5,     4] loss: 1.386
[6,     4] loss: 1.377
[7,     4] loss: 1.361
[8,     4] loss: 1.304
[9,     4] loss: 1.250
[10,     4] loss: 1.142
[11,     4] loss: 1.159
[12,     4] loss: 1.154
[13,     4] loss: 1.118
[14,     4] loss: 1.092
[15,     4] loss: 1.013
[16,     4] loss: 0.979
[17,     4] loss: 1.317
[18,     4] loss: 1.182
[19,     4] loss: 1.164
[20,     4] loss: 1.151
[21,     4] loss: 1.088
[22,     4] loss: 0.989
[23,     4] loss: 0.942
[24,     4] loss: 0.882
[25,     4] loss: 0.913
[26,     4] loss: 0.873
[27,     4] loss: 0.893
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008785384691191917,
 'learning_rate_Hydroxylation-K': 0.0032077859645626297,
 'learning_rate_Methylation-K': 0.00871537312315191,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21059561305520685,
 'loss_weight_Methylation-K': 0.5543502765539512,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2715413314,
 'sample_weights': [0.9514682547257055, 0.8871445700563291],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.570464617748993,
 'weight_decay_Hydroxylation-K': 3.8836166323595798,
 'weight_decay_Methylation-K': 7.005569892167948}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.387
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017769539987832566,
 'learning_rate_Hydroxylation-K': 0.008372360044398166,
 'learning_rate_Methylation-K': 0.0037457362818498338,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4607019817082345,
 'loss_weight_Methylation-K': 0.5602580356653367,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 217881538,
 'sample_weights': [0.21059561305520685, 0.5543502765539512],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.924775392906071,
 'weight_decay_Hydroxylation-K': 8.574948227209562,
 'weight_decay_Methylation-K': 3.7199426714292545}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.387
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00021216352565723846,
 'learning_rate_Hydroxylation-K': 0.001114834013073944,
 'learning_rate_Methylation-K': 0.005374092331880777,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4234297099207463,
 'loss_weight_Methylation-K': 0.31866390365011965,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1535103135,
 'sample_weights': [0.4607019817082345, 0.5602580356653367],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.7691853451796455,
 'weight_decay_Hydroxylation-K': 8.456799690963622,
 'weight_decay_Methylation-K': 8.001804953164529}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.389
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0004960296949067073,
 'learning_rate_Hydroxylation-K': 0.0029280230141322,
 'learning_rate_Methylation-K': 0.008436559936057051,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.10949106414628254,
 'loss_weight_Methylation-K': 0.5951075317660924,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 670134426,
 'sample_weights': [0.4234297099207463, 0.31866390365011965],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.93225819781506,
 'weight_decay_Hydroxylation-K': 0.19770011027335732,
 'weight_decay_Methylation-K': 8.53076318039454}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.389
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0030890635086651477,
 'learning_rate_Hydroxylation-K': 0.008963334221568427,
 'learning_rate_Methylation-K': 0.00149781980860405,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.30363514366537586,
 'loss_weight_Methylation-K': 0.13021615763924593,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1312989040,
 'sample_weights': [0.10949106414628254, 0.5951075317660924],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.476361437926281,
 'weight_decay_Hydroxylation-K': 7.309570397930721,
 'weight_decay_Methylation-K': 6.099232382140069}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.387
[3,     4] loss: 1.392
[4,     4] loss: 1.387
[5,     4] loss: 1.388
[6,     4] loss: 1.384
[7,     4] loss: 1.383
[8,     4] loss: 1.381
[9,     4] loss: 1.374
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00046557600497750657,
 'learning_rate_Hydroxylation-K': 0.007139576795162077,
 'learning_rate_Methylation-K': 0.009498705842117245,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6010774442057053,
 'loss_weight_Methylation-K': 0.9676913242299795,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1786503092,
 'sample_weights': [0.30363514366537586, 0.13021615763924593],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.668982919942025,
 'weight_decay_Hydroxylation-K': 6.994276210493101,
 'weight_decay_Methylation-K': 6.445180071917901}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.387
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002241689678999603,
 'learning_rate_Hydroxylation-K': 0.0019429540708551056,
 'learning_rate_Methylation-K': 0.0065670884344202615,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24718211745703977,
 'loss_weight_Methylation-K': 0.6354814447481824,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3528556734,
 'sample_weights': [0.6010774442057053, 0.9676913242299795],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.312032527401095,
 'weight_decay_Hydroxylation-K': 8.27099588289527,
 'weight_decay_Methylation-K': 8.559435162590752}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.385
[3,     4] loss: 1.376
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00477522750581345,
 'learning_rate_Hydroxylation-K': 0.006379987643688998,
 'learning_rate_Methylation-K': 0.003959397277516843,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.44299324959855824,
 'loss_weight_Methylation-K': 0.9318209811799838,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 467830156,
 'sample_weights': [0.24718211745703977, 0.6354814447481824],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.643156546400029,
 'weight_decay_Hydroxylation-K': 5.133573899903405,
 'weight_decay_Methylation-K': 8.62315465255888}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.378
[2,     4] loss: 1.391
[3,     4] loss: 1.383
[4,     4] loss: 1.383
[5,     4] loss: 1.383
[6,     4] loss: 1.379
[7,     4] loss: 1.366
[8,     4] loss: 1.312
[9,     4] loss: 1.223
[10,     4] loss: 1.143
[11,     4] loss: 1.142
[12,     4] loss: 1.044
[13,     4] loss: 1.076
[14,     4] loss: 1.118
[15,     4] loss: 1.088
[16,     4] loss: 1.102
[17,     4] loss: 1.059
[18,     4] loss: 1.017
[19,     4] loss: 1.059
[20,     4] loss: 1.029
[21,     4] loss: 1.026
[22,     4] loss: 0.976
[23,     4] loss: 1.064
[24,     4] loss: 0.980
[25,     4] loss: 0.985
[26,     4] loss: 0.934
[27,     4] loss: 0.934
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002529002475445034,
 'learning_rate_Hydroxylation-K': 0.0021878372836055568,
 'learning_rate_Methylation-K': 0.002239928268996878,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.08294772974159029,
 'loss_weight_Methylation-K': 0.6225619418522333,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 260229117,
 'sample_weights': [0.44299324959855824, 0.9318209811799838],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.0238102802880364,
 'weight_decay_Hydroxylation-K': 7.862837822027319,
 'weight_decay_Methylation-K': 5.730333100009626}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.385
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00119027997005865,
 'learning_rate_Hydroxylation-K': 0.009666280883683688,
 'learning_rate_Methylation-K': 0.0009227186580822823,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5114653694302258,
 'loss_weight_Methylation-K': 0.37496018769796946,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2730730372,
 'sample_weights': [0.08294772974159029, 0.6225619418522333],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.636414830520547,
 'weight_decay_Hydroxylation-K': 4.187612278478225,
 'weight_decay_Methylation-K': 4.713173586709378}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.400
[3,     4] loss: 1.381
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012076599237263023,
 'learning_rate_Hydroxylation-K': 0.0006901480658343191,
 'learning_rate_Methylation-K': 0.004876143533775273,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.02475099204737674,
 'loss_weight_Methylation-K': 0.5812398940096742,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 242895871,
 'sample_weights': [0.5114653694302258, 0.37496018769796946],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.522997660633525,
 'weight_decay_Hydroxylation-K': 6.248358839853784,
 'weight_decay_Methylation-K': 6.541131583984506}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.386
[3,     4] loss: 1.380
[4,     4] loss: 1.379
[5,     4] loss: 1.369
[6,     4] loss: 1.347
[7,     4] loss: 1.329
[8,     4] loss: 1.277
[9,     4] loss: 1.241
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011268122491005042,
 'learning_rate_Hydroxylation-K': 0.0002554685568869912,
 'learning_rate_Methylation-K': 0.005510900543862648,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.31725619592908416,
 'loss_weight_Methylation-K': 0.23620424581635807,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1090345003,
 'sample_weights': [0.02475099204737674, 0.5812398940096742],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.3879436041190383,
 'weight_decay_Hydroxylation-K': 6.824677240708275,
 'weight_decay_Methylation-K': 3.608492057297913}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.383
[3,     4] loss: 1.382
[4,     4] loss: 1.379
[5,     4] loss: 1.378
[6,     4] loss: 1.355
[7,     4] loss: 1.332
[8,     4] loss: 1.306
[9,     4] loss: 1.251
[10,     4] loss: 1.234
[11,     4] loss: 1.187
[12,     4] loss: 1.122
[13,     4] loss: 1.159
[14,     4] loss: 1.085
[15,     4] loss: 1.099
[16,     4] loss: 1.048
[17,     4] loss: 0.964
[18,     4] loss: 0.920
[19,     4] loss: 0.975
[20,     4] loss: 0.887
[21,     4] loss: 0.889
[22,     4] loss: 0.981
[23,     4] loss: 0.955
[24,     4] loss: 0.991
[25,     4] loss: 0.922
[26,     4] loss: 0.873
[27,     4] loss: 0.858
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002106761667432823,
 'learning_rate_Hydroxylation-K': 0.004898045144463587,
 'learning_rate_Methylation-K': 0.00017017200749224186,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22915882334371349,
 'loss_weight_Methylation-K': 0.28390682462893313,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4226660403,
 'sample_weights': [0.31725619592908416, 0.23620424581635807],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.974141462953704,
 'weight_decay_Hydroxylation-K': 5.443812669256224,
 'weight_decay_Methylation-K': 4.841024344701855}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.388
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00019607154982091961,
 'learning_rate_Hydroxylation-K': 0.005520978248687748,
 'learning_rate_Methylation-K': 0.0009633926129659113,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6044615367794658,
 'loss_weight_Methylation-K': 0.4282549281779111,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2167153979,
 'sample_weights': [0.22915882334371349, 0.28390682462893313],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.6012478088130715,
 'weight_decay_Hydroxylation-K': 7.760458723848384,
 'weight_decay_Methylation-K': 3.7186006443862643}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.390
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003219300602261159,
 'learning_rate_Hydroxylation-K': 0.0008004789966237118,
 'learning_rate_Methylation-K': 0.00446812405179167,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3089845346008485,
 'loss_weight_Methylation-K': 0.5406642442305541,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 151039340,
 'sample_weights': [0.6044615367794658, 0.4282549281779111],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.81429023522312,
 'weight_decay_Hydroxylation-K': 9.691087017407815,
 'weight_decay_Methylation-K': 2.277816911528998}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.388
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002602902845459964,
 'learning_rate_Hydroxylation-K': 0.007910595053839873,
 'learning_rate_Methylation-K': 0.006850112261051084,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6368095362216398,
 'loss_weight_Methylation-K': 0.6902194347483532,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4131982485,
 'sample_weights': [0.3089845346008485, 0.5406642442305541],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.88914143517677,
 'weight_decay_Hydroxylation-K': 3.689931970416124,
 'weight_decay_Methylation-K': 6.649309241571725}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.386
[3,     4] loss: 1.386
[4,     4] loss: 1.382
[5,     4] loss: 1.376
[6,     4] loss: 1.356
[7,     4] loss: 1.310
[8,     4] loss: 1.261
[9,     4] loss: 1.185
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002089338755487286,
 'learning_rate_Hydroxylation-K': 0.005394639148544693,
 'learning_rate_Methylation-K': 0.009728103521793187,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2585559263430281,
 'loss_weight_Methylation-K': 0.9590449510333303,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3805084477,
 'sample_weights': [0.6368095362216398, 0.6902194347483532],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.080949658369266,
 'weight_decay_Hydroxylation-K': 8.968434510627592,
 'weight_decay_Methylation-K': 9.709360378362318}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.384
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010466855614194406,
 'learning_rate_Hydroxylation-K': 0.005568068955448752,
 'learning_rate_Methylation-K': 0.007060433886075278,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9005653879128908,
 'loss_weight_Methylation-K': 0.8890298314646999,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1531028557,
 'sample_weights': [0.2585559263430281, 0.9590449510333303],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.440361534511378,
 'weight_decay_Hydroxylation-K': 2.577391690298552,
 'weight_decay_Methylation-K': 4.832220374701396}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.389
[3,     4] loss: 1.385
[4,     4] loss: 1.386
[5,     4] loss: 1.382
[6,     4] loss: 1.375
[7,     4] loss: 1.369
[8,     4] loss: 1.342
[9,     4] loss: 1.321
[10,     4] loss: 1.283
[11,     4] loss: 1.228
[12,     4] loss: 1.180
[13,     4] loss: 1.095
[14,     4] loss: 1.079
[15,     4] loss: 1.071
[16,     4] loss: 0.975
[17,     4] loss: 0.949
[18,     4] loss: 0.992
[19,     4] loss: 0.912
[20,     4] loss: 0.873
[21,     4] loss: 0.860
[22,     4] loss: 0.918
[23,     4] loss: 0.869
[24,     4] loss: 0.850
[25,     4] loss: 0.845
[26,     4] loss: 0.891
[27,     4] loss: 0.864
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001062080168304273,
 'learning_rate_Hydroxylation-K': 0.00477532677799774,
 'learning_rate_Methylation-K': 0.008665333735314034,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1176517229527356,
 'loss_weight_Methylation-K': 0.8744349379053713,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 8634611,
 'sample_weights': [0.9005653879128908, 0.8890298314646999],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.753966970841978,
 'weight_decay_Hydroxylation-K': 6.9691983112302145,
 'weight_decay_Methylation-K': 9.62980653166521}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.387
[3,     4] loss: 1.383
[4,     4] loss: 1.385
[5,     4] loss: 1.378
[6,     4] loss: 1.369
[7,     4] loss: 1.355
[8,     4] loss: 1.339
[9,     4] loss: 1.270
[10,     4] loss: 1.268
[11,     4] loss: 1.204
[12,     4] loss: 1.154
[13,     4] loss: 1.137
[14,     4] loss: 1.066
[15,     4] loss: 1.018
[16,     4] loss: 0.979
[17,     4] loss: 0.937
[18,     4] loss: 0.966
[19,     4] loss: 0.955
[20,     4] loss: 0.896
[21,     4] loss: 0.966
[22,     4] loss: 1.081
[23,     4] loss: 1.004
[24,     4] loss: 1.030
[25,     4] loss: 0.925
[26,     4] loss: 0.948
[27,     4] loss: 0.954
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009514178238028599,
 'learning_rate_Hydroxylation-K': 0.006151486150319075,
 'learning_rate_Methylation-K': 0.008901958357077595,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8174412512772007,
 'loss_weight_Methylation-K': 0.7781996346018751,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 683610149,
 'sample_weights': [0.1176517229527356, 0.8744349379053713],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.501829288404853,
 'weight_decay_Hydroxylation-K': 5.193938592137122,
 'weight_decay_Methylation-K': 8.031294386603005}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.389
[3,     4] loss: 1.386
[4,     4] loss: 1.386
[5,     4] loss: 1.388
[6,     4] loss: 1.385
[7,     4] loss: 1.381
[8,     4] loss: 1.378
[9,     4] loss: 1.372
[10,     4] loss: 1.361
[11,     4] loss: 1.337
[12,     4] loss: 1.311
[13,     4] loss: 1.285
[14,     4] loss: 1.275
[15,     4] loss: 1.141
[16,     4] loss: 1.124
[17,     4] loss: 1.088
[18,     4] loss: 1.035
[19,     4] loss: 1.047
[20,     4] loss: 1.020
[21,     4] loss: 0.955
[22,     4] loss: 1.036
[23,     4] loss: 0.974
[24,     4] loss: 1.053
[25,     4] loss: 0.964
[26,     4] loss: 0.941
[27,     4] loss: 0.926
[28,     4] loss: 0.866
[29,     4] loss: 0.859
[30,     4] loss: 0.871
[31,     4] loss: 0.867
[32,     4] loss: 0.845
[33,     4] loss: 0.841
[34,     4] loss: 0.811
[35,     4] loss: 0.834
[36,     4] loss: 0.858
[37,     4] loss: 0.786
[38,     4] loss: 0.838
[39,     4] loss: 0.858
[40,     4] loss: 0.862
[41,     4] loss: 0.847
[42,     4] loss: 0.808
[43,     4] loss: 0.811
[44,     4] loss: 0.780
[45,     4] loss: 0.833
[46,     4] loss: 0.824
[47,     4] loss: 0.824
[48,     4] loss: 0.844
[49,     4] loss: 0.818
[50,     4] loss: 0.826
[51,     4] loss: 0.846
[52,     4] loss: 0.832
[53,     4] loss: 0.812
[54,     4] loss: 0.784
[55,     4] loss: 0.773
[56,     4] loss: 0.750
[57,     4] loss: 0.769
[58,     4] loss: 0.759
[59,     4] loss: 0.788
[60,     4] loss: 0.789
[61,     4] loss: 0.760
[62,     4] loss: 0.758
[63,     4] loss: 0.761
[64,     4] loss: 0.759
Early stopping applied (best metric=0.4226362407207489)
Finished Training
Total time taken: 41.84387683868408
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.375
[5,     4] loss: 1.384
[6,     4] loss: 1.376
[7,     4] loss: 1.354
[8,     4] loss: 1.325
[9,     4] loss: 1.291
[10,     4] loss: 1.225
[11,     4] loss: 1.223
[12,     4] loss: 1.175
[13,     4] loss: 1.117
[14,     4] loss: 1.109
[15,     4] loss: 1.058
[16,     4] loss: 1.054
[17,     4] loss: 0.971
[18,     4] loss: 0.964
[19,     4] loss: 0.986
[20,     4] loss: 1.035
[21,     4] loss: 0.952
[22,     4] loss: 0.945
[23,     4] loss: 0.915
[24,     4] loss: 0.916
[25,     4] loss: 0.966
[26,     4] loss: 0.873
[27,     4] loss: 0.818
[28,     4] loss: 0.927
[29,     4] loss: 0.879
[30,     4] loss: 0.911
[31,     4] loss: 0.906
[32,     4] loss: 0.924
[33,     4] loss: 0.904
[34,     4] loss: 0.956
[35,     4] loss: 0.927
[36,     4] loss: 0.817
[37,     4] loss: 0.849
[38,     4] loss: 0.836
[39,     4] loss: 0.795
[40,     4] loss: 0.795
[41,     4] loss: 0.795
[42,     4] loss: 0.765
[43,     4] loss: 0.828
[44,     4] loss: 0.877
[45,     4] loss: 0.839
[46,     4] loss: 0.767
[47,     4] loss: 0.778
[48,     4] loss: 0.774
[49,     4] loss: 0.753
[50,     4] loss: 0.749
[51,     4] loss: 0.753
[52,     4] loss: 0.766
[53,     4] loss: 0.802
[54,     4] loss: 0.784
[55,     4] loss: 0.836
[56,     4] loss: 0.809
[57,     4] loss: 0.814
[58,     4] loss: 0.788
[59,     4] loss: 0.874
Early stopping applied (best metric=0.5226027369499207)
Finished Training
Total time taken: 35.84787917137146
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.399
[2,     4] loss: 1.386
[3,     4] loss: 1.387
[4,     4] loss: 1.388
[5,     4] loss: 1.385
[6,     4] loss: 1.379
[7,     4] loss: 1.378
[8,     4] loss: 1.369
[9,     4] loss: 1.349
[10,     4] loss: 1.325
[11,     4] loss: 1.285
[12,     4] loss: 1.221
[13,     4] loss: 1.236
[14,     4] loss: 1.162
[15,     4] loss: 1.157
[16,     4] loss: 1.136
[17,     4] loss: 1.062
[18,     4] loss: 1.038
[19,     4] loss: 1.053
[20,     4] loss: 1.067
[21,     4] loss: 0.939
[22,     4] loss: 0.911
[23,     4] loss: 0.937
[24,     4] loss: 0.916
[25,     4] loss: 0.913
[26,     4] loss: 0.864
[27,     4] loss: 0.939
[28,     4] loss: 0.938
[29,     4] loss: 0.902
[30,     4] loss: 0.868
[31,     4] loss: 0.922
[32,     4] loss: 0.887
[33,     4] loss: 0.873
[34,     4] loss: 0.883
[35,     4] loss: 0.855
[36,     4] loss: 0.825
[37,     4] loss: 0.799
[38,     4] loss: 0.794
[39,     4] loss: 0.789
[40,     4] loss: 0.768
[41,     4] loss: 0.778
[42,     4] loss: 0.788
[43,     4] loss: 0.772
[44,     4] loss: 0.791
[45,     4] loss: 0.761
[46,     4] loss: 0.862
[47,     4] loss: 0.777
[48,     4] loss: 0.854
[49,     4] loss: 0.819
[50,     4] loss: 0.770
[51,     4] loss: 0.777
[52,     4] loss: 0.787
[53,     4] loss: 0.765
[54,     4] loss: 0.751
[55,     4] loss: 0.763
[56,     4] loss: 0.756
[57,     4] loss: 0.786
[58,     4] loss: 0.753
[59,     4] loss: 0.773
[60,     4] loss: 0.753
[61,     4] loss: 0.766
[62,     4] loss: 0.752
[63,     4] loss: 0.748
[64,     4] loss: 0.753
[65,     4] loss: 0.750
[66,     4] loss: 0.793
Early stopping applied (best metric=0.33920687437057495)
Finished Training
Total time taken: 39.8103187084198
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.384
[4,     4] loss: 1.380
[5,     4] loss: 1.380
[6,     4] loss: 1.358
[7,     4] loss: 1.340
[8,     4] loss: 1.287
[9,     4] loss: 1.256
[10,     4] loss: 1.234
[11,     4] loss: 1.197
[12,     4] loss: 1.151
[13,     4] loss: 1.137
[14,     4] loss: 1.054
[15,     4] loss: 1.064
[16,     4] loss: 1.049
[17,     4] loss: 0.946
[18,     4] loss: 0.918
[19,     4] loss: 0.879
[20,     4] loss: 0.867
[21,     4] loss: 0.849
[22,     4] loss: 0.940
[23,     4] loss: 0.875
[24,     4] loss: 0.856
[25,     4] loss: 0.870
[26,     4] loss: 0.816
[27,     4] loss: 0.826
[28,     4] loss: 0.832
[29,     4] loss: 0.821
[30,     4] loss: 0.852
[31,     4] loss: 1.013
[32,     4] loss: 0.810
[33,     4] loss: 0.836
[34,     4] loss: 0.829
[35,     4] loss: 0.786
[36,     4] loss: 0.773
[37,     4] loss: 0.758
[38,     4] loss: 0.752
[39,     4] loss: 0.853
[40,     4] loss: 0.797
[41,     4] loss: 0.799
[42,     4] loss: 0.790
[43,     4] loss: 0.791
[44,     4] loss: 0.780
[45,     4] loss: 0.773
[46,     4] loss: 0.770
[47,     4] loss: 0.775
[48,     4] loss: 0.751
[49,     4] loss: 0.775
[50,     4] loss: 0.759
[51,     4] loss: 0.746
[52,     4] loss: 0.748
[53,     4] loss: 0.733
[54,     4] loss: 0.745
[55,     4] loss: 0.753
[56,     4] loss: 0.753
[57,     4] loss: 0.747
[58,     4] loss: 0.785
Early stopping applied (best metric=0.4937379062175751)
Finished Training
Total time taken: 34.779592752456665
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.393
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.383
[5,     4] loss: 1.379
[6,     4] loss: 1.375
[7,     4] loss: 1.367
[8,     4] loss: 1.340
[9,     4] loss: 1.313
[10,     4] loss: 1.304
[11,     4] loss: 1.223
[12,     4] loss: 1.232
[13,     4] loss: 1.136
[14,     4] loss: 1.107
[15,     4] loss: 1.131
[16,     4] loss: 1.035
[17,     4] loss: 1.036
[18,     4] loss: 0.996
[19,     4] loss: 1.007
[20,     4] loss: 1.002
[21,     4] loss: 0.920
[22,     4] loss: 0.958
[23,     4] loss: 0.978
[24,     4] loss: 0.908
[25,     4] loss: 0.869
[26,     4] loss: 0.906
[27,     4] loss: 0.966
[28,     4] loss: 0.851
[29,     4] loss: 0.848
[30,     4] loss: 0.804
[31,     4] loss: 0.873
[32,     4] loss: 0.840
[33,     4] loss: 0.851
[34,     4] loss: 0.837
[35,     4] loss: 0.794
[36,     4] loss: 0.803
[37,     4] loss: 0.767
[38,     4] loss: 0.810
[39,     4] loss: 0.781
[40,     4] loss: 0.779
[41,     4] loss: 0.781
[42,     4] loss: 0.794
[43,     4] loss: 0.809
[44,     4] loss: 0.785
[45,     4] loss: 0.777
[46,     4] loss: 0.757
[47,     4] loss: 0.806
[48,     4] loss: 0.962
[49,     4] loss: 0.819
[50,     4] loss: 0.830
[51,     4] loss: 0.802
[52,     4] loss: 0.873
[53,     4] loss: 0.848
[54,     4] loss: 0.796
[55,     4] loss: 0.786
[56,     4] loss: 0.776
[57,     4] loss: 0.797
[58,     4] loss: 0.786
[59,     4] loss: 0.766
[60,     4] loss: 0.764
[61,     4] loss: 0.765
[62,     4] loss: 0.767
[63,     4] loss: 0.744
Early stopping applied (best metric=0.3783864676952362)
Finished Training
Total time taken: 33.32160472869873
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.388
[3,     4] loss: 1.384
[4,     4] loss: 1.383
[5,     4] loss: 1.377
[6,     4] loss: 1.366
[7,     4] loss: 1.337
[8,     4] loss: 1.293
[9,     4] loss: 1.288
[10,     4] loss: 1.243
[11,     4] loss: 1.169
[12,     4] loss: 1.174
[13,     4] loss: 1.137
[14,     4] loss: 1.115
[15,     4] loss: 1.109
[16,     4] loss: 1.039
[17,     4] loss: 1.071
[18,     4] loss: 0.987
[19,     4] loss: 1.071
[20,     4] loss: 0.958
[21,     4] loss: 1.032
[22,     4] loss: 1.042
[23,     4] loss: 0.917
[24,     4] loss: 0.953
[25,     4] loss: 0.906
[26,     4] loss: 0.846
[27,     4] loss: 0.849
[28,     4] loss: 0.836
[29,     4] loss: 0.880
[30,     4] loss: 0.913
[31,     4] loss: 0.847
[32,     4] loss: 0.882
[33,     4] loss: 0.802
[34,     4] loss: 0.864
[35,     4] loss: 0.836
[36,     4] loss: 0.840
[37,     4] loss: 0.795
[38,     4] loss: 0.761
[39,     4] loss: 0.781
[40,     4] loss: 0.789
[41,     4] loss: 0.773
[42,     4] loss: 0.759
[43,     4] loss: 0.783
[44,     4] loss: 0.781
[45,     4] loss: 0.785
[46,     4] loss: 0.818
[47,     4] loss: 0.789
[48,     4] loss: 0.766
[49,     4] loss: 0.744
[50,     4] loss: 0.766
[51,     4] loss: 0.766
[52,     4] loss: 0.811
[53,     4] loss: 0.817
[54,     4] loss: 0.798
[55,     4] loss: 0.787
[56,     4] loss: 0.821
[57,     4] loss: 0.845
[58,     4] loss: 0.828
[59,     4] loss: 0.828
[60,     4] loss: 0.796
[61,     4] loss: 0.756
[62,     4] loss: 0.786
[63,     4] loss: 0.763
[64,     4] loss: 0.765
[65,     4] loss: 0.772
[66,     4] loss: 0.777
Early stopping applied (best metric=0.49420270323753357)
Finished Training
Total time taken: 36.50244116783142
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.391
[3,     4] loss: 1.385
[4,     4] loss: 1.387
[5,     4] loss: 1.379
[6,     4] loss: 1.369
[7,     4] loss: 1.361
[8,     4] loss: 1.341
[9,     4] loss: 1.327
[10,     4] loss: 1.280
[11,     4] loss: 1.218
[12,     4] loss: 1.205
[13,     4] loss: 1.137
[14,     4] loss: 1.112
[15,     4] loss: 1.115
[16,     4] loss: 0.983
[17,     4] loss: 1.019
[18,     4] loss: 0.940
[19,     4] loss: 0.955
[20,     4] loss: 0.975
[21,     4] loss: 0.927
[22,     4] loss: 0.922
[23,     4] loss: 0.850
[24,     4] loss: 0.928
[25,     4] loss: 0.912
[26,     4] loss: 0.879
[27,     4] loss: 0.900
[28,     4] loss: 0.930
[29,     4] loss: 0.858
[30,     4] loss: 0.853
[31,     4] loss: 0.829
[32,     4] loss: 0.826
[33,     4] loss: 0.837
[34,     4] loss: 0.866
[35,     4] loss: 0.824
[36,     4] loss: 0.793
[37,     4] loss: 0.785
[38,     4] loss: 0.768
[39,     4] loss: 0.773
[40,     4] loss: 0.782
[41,     4] loss: 0.789
[42,     4] loss: 0.764
[43,     4] loss: 0.771
[44,     4] loss: 0.757
[45,     4] loss: 0.754
[46,     4] loss: 0.777
[47,     4] loss: 0.793
[48,     4] loss: 0.800
[49,     4] loss: 0.844
[50,     4] loss: 0.829
[51,     4] loss: 0.809
[52,     4] loss: 0.788
[53,     4] loss: 0.739
[54,     4] loss: 0.740
[55,     4] loss: 0.724
[56,     4] loss: 0.723
[57,     4] loss: 0.728
[58,     4] loss: 0.716
[59,     4] loss: 0.726
[60,     4] loss: 0.730
[61,     4] loss: 0.720
[62,     4] loss: 0.727
[63,     4] loss: 0.770
[64,     4] loss: 0.723
Early stopping applied (best metric=0.4307544231414795)
Finished Training
Total time taken: 35.01943802833557
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.403
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.380
[5,     4] loss: 1.380
[6,     4] loss: 1.379
[7,     4] loss: 1.352
[8,     4] loss: 1.325
[9,     4] loss: 1.297
[10,     4] loss: 1.287
[11,     4] loss: 1.229
[12,     4] loss: 1.261
[13,     4] loss: 1.159
[14,     4] loss: 1.149
[15,     4] loss: 1.082
[16,     4] loss: 1.113
[17,     4] loss: 1.060
[18,     4] loss: 1.033
[19,     4] loss: 1.050
[20,     4] loss: 0.990
[21,     4] loss: 0.937
[22,     4] loss: 0.925
[23,     4] loss: 0.936
[24,     4] loss: 0.917
[25,     4] loss: 0.896
[26,     4] loss: 0.915
[27,     4] loss: 0.851
[28,     4] loss: 0.883
[29,     4] loss: 0.921
[30,     4] loss: 0.890
[31,     4] loss: 0.880
[32,     4] loss: 0.847
[33,     4] loss: 0.853
[34,     4] loss: 0.799
[35,     4] loss: 0.843
[36,     4] loss: 0.796
[37,     4] loss: 0.789
[38,     4] loss: 0.788
[39,     4] loss: 0.786
[40,     4] loss: 0.779
[41,     4] loss: 0.783
[42,     4] loss: 0.778
[43,     4] loss: 0.783
[44,     4] loss: 0.776
[45,     4] loss: 0.764
[46,     4] loss: 0.774
[47,     4] loss: 0.768
[48,     4] loss: 0.767
[49,     4] loss: 0.763
[50,     4] loss: 0.790
[51,     4] loss: 0.788
[52,     4] loss: 0.762
[53,     4] loss: 0.794
[54,     4] loss: 0.788
[55,     4] loss: 0.837
[56,     4] loss: 0.814
[57,     4] loss: 0.756
[58,     4] loss: 0.754
[59,     4] loss: 0.800
[60,     4] loss: 0.795
[61,     4] loss: 0.741
[62,     4] loss: 0.781
[63,     4] loss: 0.754
[64,     4] loss: 0.737
[65,     4] loss: 0.745
[66,     4] loss: 0.745
[67,     4] loss: 0.763
[68,     4] loss: 0.759
[69,     4] loss: 0.765
[70,     4] loss: 0.801
[71,     4] loss: 0.768
[72,     4] loss: 0.769
[73,     4] loss: 0.752
[74,     4] loss: 0.761
[75,     4] loss: 0.740
[76,     4] loss: 0.749
[77,     4] loss: 0.760
[78,     4] loss: 0.747
[79,     4] loss: 0.734
[80,     4] loss: 0.736
[81,     4] loss: 0.812
Early stopping applied (best metric=0.353792279958725)
Finished Training
Total time taken: 42.77626848220825
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.389
[3,     4] loss: 1.376
[4,     4] loss: 1.388
[5,     4] loss: 1.375
[6,     4] loss: 1.361
[7,     4] loss: 1.341
[8,     4] loss: 1.298
[9,     4] loss: 1.257
[10,     4] loss: 1.230
[11,     4] loss: 1.198
[12,     4] loss: 1.133
[13,     4] loss: 1.155
[14,     4] loss: 1.063
[15,     4] loss: 1.025
[16,     4] loss: 0.962
[17,     4] loss: 0.947
[18,     4] loss: 0.876
[19,     4] loss: 0.923
[20,     4] loss: 0.883
[21,     4] loss: 0.874
[22,     4] loss: 0.873
[23,     4] loss: 0.841
[24,     4] loss: 0.841
[25,     4] loss: 0.832
[26,     4] loss: 0.905
[27,     4] loss: 0.890
[28,     4] loss: 0.861
[29,     4] loss: 0.848
[30,     4] loss: 0.820
[31,     4] loss: 0.838
[32,     4] loss: 0.811
[33,     4] loss: 0.836
[34,     4] loss: 0.795
[35,     4] loss: 0.817
[36,     4] loss: 0.846
[37,     4] loss: 0.840
[38,     4] loss: 0.847
[39,     4] loss: 0.801
[40,     4] loss: 0.796
[41,     4] loss: 0.821
[42,     4] loss: 0.755
[43,     4] loss: 0.762
[44,     4] loss: 0.762
[45,     4] loss: 0.770
[46,     4] loss: 0.742
[47,     4] loss: 0.749
[48,     4] loss: 0.758
[49,     4] loss: 0.744
[50,     4] loss: 0.769
[51,     4] loss: 0.788
[52,     4] loss: 0.775
[53,     4] loss: 0.752
[54,     4] loss: 0.773
[55,     4] loss: 0.743
[56,     4] loss: 0.783
[57,     4] loss: 0.766
[58,     4] loss: 0.754
Early stopping applied (best metric=0.4954071342945099)
Finished Training
Total time taken: 32.265018701553345
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.396
[2,     4] loss: 1.382
[3,     4] loss: 1.382
[4,     4] loss: 1.377
[5,     4] loss: 1.368
[6,     4] loss: 1.346
[7,     4] loss: 1.323
[8,     4] loss: 1.286
[9,     4] loss: 1.267
[10,     4] loss: 1.202
[11,     4] loss: 1.152
[12,     4] loss: 1.059
[13,     4] loss: 1.026
[14,     4] loss: 1.107
[15,     4] loss: 1.037
[16,     4] loss: 0.998
[17,     4] loss: 0.977
[18,     4] loss: 0.919
[19,     4] loss: 0.948
[20,     4] loss: 0.940
[21,     4] loss: 0.917
[22,     4] loss: 0.966
[23,     4] loss: 0.956
[24,     4] loss: 0.912
[25,     4] loss: 0.943
[26,     4] loss: 0.873
[27,     4] loss: 0.854
[28,     4] loss: 0.817
[29,     4] loss: 0.813
[30,     4] loss: 0.893
[31,     4] loss: 0.885
[32,     4] loss: 0.819
[33,     4] loss: 0.874
[34,     4] loss: 0.820
[35,     4] loss: 0.809
[36,     4] loss: 0.794
[37,     4] loss: 0.776
[38,     4] loss: 0.780
[39,     4] loss: 0.809
[40,     4] loss: 0.777
[41,     4] loss: 0.756
[42,     4] loss: 0.792
[43,     4] loss: 0.803
[44,     4] loss: 0.779
[45,     4] loss: 0.823
[46,     4] loss: 0.753
[47,     4] loss: 0.753
[48,     4] loss: 0.777
[49,     4] loss: 0.774
[50,     4] loss: 0.794
[51,     4] loss: 0.778
[52,     4] loss: 0.840
[53,     4] loss: 0.792
[54,     4] loss: 0.761
[55,     4] loss: 0.765
[56,     4] loss: 0.780
[57,     4] loss: 0.754
[58,     4] loss: 0.741
[59,     4] loss: 0.739
[60,     4] loss: 0.759
[61,     4] loss: 0.755
[62,     4] loss: 0.745
[63,     4] loss: 0.745
[64,     4] loss: 0.738
[65,     4] loss: 0.751
Early stopping applied (best metric=0.399824321269989)
Finished Training
Total time taken: 35.731274366378784
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.395
[3,     4] loss: 1.390
[4,     4] loss: 1.382
[5,     4] loss: 1.376
[6,     4] loss: 1.366
[7,     4] loss: 1.353
[8,     4] loss: 1.343
[9,     4] loss: 1.297
[10,     4] loss: 1.300
[11,     4] loss: 1.272
[12,     4] loss: 1.196
[13,     4] loss: 1.174
[14,     4] loss: 1.120
[15,     4] loss: 1.098
[16,     4] loss: 1.152
[17,     4] loss: 1.029
[18,     4] loss: 0.967
[19,     4] loss: 0.968
[20,     4] loss: 0.955
[21,     4] loss: 0.919
[22,     4] loss: 0.906
[23,     4] loss: 0.964
[24,     4] loss: 0.844
[25,     4] loss: 0.918
[26,     4] loss: 0.955
[27,     4] loss: 0.962
[28,     4] loss: 0.849
[29,     4] loss: 0.886
[30,     4] loss: 0.860
[31,     4] loss: 0.836
[32,     4] loss: 0.856
[33,     4] loss: 0.890
[34,     4] loss: 0.819
[35,     4] loss: 0.839
[36,     4] loss: 0.860
[37,     4] loss: 0.815
[38,     4] loss: 0.866
[39,     4] loss: 0.837
[40,     4] loss: 0.798
[41,     4] loss: 0.807
[42,     4] loss: 0.795
[43,     4] loss: 0.766
[44,     4] loss: 0.760
[45,     4] loss: 0.793
[46,     4] loss: 0.777
[47,     4] loss: 0.762
[48,     4] loss: 0.756
[49,     4] loss: 0.842
[50,     4] loss: 0.801
[51,     4] loss: 0.823
[52,     4] loss: 0.771
[53,     4] loss: 0.761
[54,     4] loss: 0.749
[55,     4] loss: 0.762
[56,     4] loss: 0.805
[57,     4] loss: 0.866
[58,     4] loss: 0.769
[59,     4] loss: 0.746
[60,     4] loss: 0.760
Early stopping applied (best metric=0.46878260374069214)
Finished Training
Total time taken: 30.676860809326172
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.389
[3,     4] loss: 1.388
[4,     4] loss: 1.381
[5,     4] loss: 1.380
[6,     4] loss: 1.375
[7,     4] loss: 1.370
[8,     4] loss: 1.340
[9,     4] loss: 1.320
[10,     4] loss: 1.263
[11,     4] loss: 1.224
[12,     4] loss: 1.175
[13,     4] loss: 1.164
[14,     4] loss: 1.091
[15,     4] loss: 1.104
[16,     4] loss: 1.033
[17,     4] loss: 1.029
[18,     4] loss: 1.033
[19,     4] loss: 0.979
[20,     4] loss: 0.990
[21,     4] loss: 0.909
[22,     4] loss: 0.875
[23,     4] loss: 0.863
[24,     4] loss: 0.883
[25,     4] loss: 0.829
[26,     4] loss: 0.783
[27,     4] loss: 0.778
[28,     4] loss: 0.826
[29,     4] loss: 0.917
[30,     4] loss: 0.838
[31,     4] loss: 0.877
[32,     4] loss: 0.821
[33,     4] loss: 0.800
[34,     4] loss: 0.783
[35,     4] loss: 0.796
[36,     4] loss: 0.905
[37,     4] loss: 0.899
[38,     4] loss: 0.884
[39,     4] loss: 0.877
[40,     4] loss: 0.886
[41,     4] loss: 0.839
[42,     4] loss: 0.792
[43,     4] loss: 0.788
[44,     4] loss: 0.760
[45,     4] loss: 0.751
[46,     4] loss: 0.737
[47,     4] loss: 0.759
[48,     4] loss: 0.777
[49,     4] loss: 0.757
[50,     4] loss: 0.770
[51,     4] loss: 0.766
[52,     4] loss: 0.761
[53,     4] loss: 0.757
[54,     4] loss: 0.750
[55,     4] loss: 0.757
[56,     4] loss: 0.755
[57,     4] loss: 0.770
[58,     4] loss: 0.747
[59,     4] loss: 0.757
[60,     4] loss: 0.773
[61,     4] loss: 0.776
[62,     4] loss: 0.768
[63,     4] loss: 0.769
[64,     4] loss: 0.763
[65,     4] loss: 0.767
[66,     4] loss: 0.764
[67,     4] loss: 0.781
[68,     4] loss: 0.800
[69,     4] loss: 0.796
[70,     4] loss: 0.776
[71,     4] loss: 0.758
[72,     4] loss: 0.773
[73,     4] loss: 0.756
[74,     4] loss: 0.738
[75,     4] loss: 0.745
[76,     4] loss: 0.746
[77,     4] loss: 0.745
[78,     4] loss: 0.736
[79,     4] loss: 0.729
[80,     4] loss: 0.739
[81,     4] loss: 0.726
[82,     4] loss: 0.746
[83,     4] loss: 0.746
[84,     4] loss: 0.775
[85,     4] loss: 0.768
[86,     4] loss: 0.735
[87,     4] loss: 0.750
[88,     4] loss: 0.742
[89,     4] loss: 0.740
[90,     4] loss: 0.731
[91,     4] loss: 0.731
[92,     4] loss: 0.746
Early stopping applied (best metric=0.2852654755115509)
Finished Training
Total time taken: 49.68405246734619
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.409
[2,     4] loss: 1.382
[3,     4] loss: 1.380
[4,     4] loss: 1.378
[5,     4] loss: 1.371
[6,     4] loss: 1.347
[7,     4] loss: 1.319
[8,     4] loss: 1.269
[9,     4] loss: 1.221
[10,     4] loss: 1.266
[11,     4] loss: 1.198
[12,     4] loss: 1.181
[13,     4] loss: 1.122
[14,     4] loss: 1.075
[15,     4] loss: 1.020
[16,     4] loss: 1.026
[17,     4] loss: 1.017
[18,     4] loss: 0.919
[19,     4] loss: 0.978
[20,     4] loss: 0.970
[21,     4] loss: 0.952
[22,     4] loss: 1.019
[23,     4] loss: 0.907
[24,     4] loss: 0.903
[25,     4] loss: 0.897
[26,     4] loss: 0.914
[27,     4] loss: 0.882
[28,     4] loss: 0.850
[29,     4] loss: 0.860
[30,     4] loss: 0.865
[31,     4] loss: 0.845
[32,     4] loss: 0.863
[33,     4] loss: 0.832
[34,     4] loss: 0.863
[35,     4] loss: 0.845
[36,     4] loss: 0.823
[37,     4] loss: 0.790
[38,     4] loss: 0.804
[39,     4] loss: 0.774
[40,     4] loss: 0.802
[41,     4] loss: 0.781
[42,     4] loss: 0.800
[43,     4] loss: 0.777
[44,     4] loss: 0.777
[45,     4] loss: 0.762
[46,     4] loss: 0.814
[47,     4] loss: 0.802
[48,     4] loss: 0.809
[49,     4] loss: 0.797
[50,     4] loss: 0.788
[51,     4] loss: 0.784
[52,     4] loss: 0.800
[53,     4] loss: 0.761
[54,     4] loss: 0.774
[55,     4] loss: 0.765
[56,     4] loss: 0.769
[57,     4] loss: 0.811
[58,     4] loss: 0.784
[59,     4] loss: 0.746
[60,     4] loss: 0.766
[61,     4] loss: 0.754
[62,     4] loss: 0.759
[63,     4] loss: 0.854
[64,     4] loss: 0.775
[65,     4] loss: 0.759
[66,     4] loss: 0.759
[67,     4] loss: 0.755
[68,     4] loss: 0.747
[69,     4] loss: 0.743
[70,     4] loss: 0.748
[71,     4] loss: 0.744
[72,     4] loss: 0.762
[73,     4] loss: 0.834
[74,     4] loss: 0.782
[75,     4] loss: 0.791
[76,     4] loss: 0.773
[77,     4] loss: 0.748
[78,     4] loss: 0.737
[79,     4] loss: 0.732
[80,     4] loss: 0.725
[81,     4] loss: 0.731
[82,     4] loss: 0.735
[83,     4] loss: 0.740
[84,     4] loss: 0.749
[85,     4] loss: 0.796
[86,     4] loss: 0.777
[87,     4] loss: 0.767
[88,     4] loss: 0.765
[89,     4] loss: 0.774
[90,     4] loss: 0.754
[91,     4] loss: 0.764
[92,     4] loss: 0.740
[93,     4] loss: 0.730
[94,     4] loss: 0.735
[95,     4] loss: 0.729
[96,     4] loss: 0.746
[97,     4] loss: 0.750
[98,     4] loss: 0.808
Early stopping applied (best metric=0.31122836470603943)
Finished Training
Total time taken: 51.066412925720215
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.383
[3,     4] loss: 1.386
[4,     4] loss: 1.378
[5,     4] loss: 1.368
[6,     4] loss: 1.350
[7,     4] loss: 1.322
[8,     4] loss: 1.290
[9,     4] loss: 1.257
[10,     4] loss: 1.174
[11,     4] loss: 1.126
[12,     4] loss: 1.101
[13,     4] loss: 1.129
[14,     4] loss: 1.044
[15,     4] loss: 1.089
[16,     4] loss: 0.974
[17,     4] loss: 0.993
[18,     4] loss: 1.014
[19,     4] loss: 0.937
[20,     4] loss: 0.903
[21,     4] loss: 0.935
[22,     4] loss: 0.886
[23,     4] loss: 0.856
[24,     4] loss: 0.863
[25,     4] loss: 0.848
[26,     4] loss: 0.830
[27,     4] loss: 0.863
[28,     4] loss: 0.819
[29,     4] loss: 0.850
[30,     4] loss: 0.798
[31,     4] loss: 0.809
[32,     4] loss: 0.811
[33,     4] loss: 0.792
[34,     4] loss: 0.833
[35,     4] loss: 0.818
[36,     4] loss: 0.842
[37,     4] loss: 0.846
[38,     4] loss: 0.827
[39,     4] loss: 0.804
[40,     4] loss: 0.785
[41,     4] loss: 0.753
[42,     4] loss: 0.778
[43,     4] loss: 0.804
[44,     4] loss: 0.804
[45,     4] loss: 0.813
[46,     4] loss: 0.871
[47,     4] loss: 0.844
[48,     4] loss: 0.802
[49,     4] loss: 0.812
[50,     4] loss: 0.778
[51,     4] loss: 0.753
[52,     4] loss: 0.738
[53,     4] loss: 0.754
[54,     4] loss: 0.741
[55,     4] loss: 0.734
[56,     4] loss: 0.784
[57,     4] loss: 0.809
[58,     4] loss: 0.773
[59,     4] loss: 0.768
[60,     4] loss: 0.760
[61,     4] loss: 0.758
Early stopping applied (best metric=0.4992080628871918)
Finished Training
Total time taken: 32.3378643989563
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.388
[2,     4] loss: 1.390
[3,     4] loss: 1.389
[4,     4] loss: 1.386
[5,     4] loss: 1.385
[6,     4] loss: 1.382
[7,     4] loss: 1.379
[8,     4] loss: 1.374
[9,     4] loss: 1.354
[10,     4] loss: 1.349
[11,     4] loss: 1.319
[12,     4] loss: 1.247
[13,     4] loss: 1.223
[14,     4] loss: 1.261
[15,     4] loss: 1.181
[16,     4] loss: 1.207
[17,     4] loss: 1.095
[18,     4] loss: 1.092
[19,     4] loss: 1.051
[20,     4] loss: 1.010
[21,     4] loss: 0.948
[22,     4] loss: 1.048
[23,     4] loss: 1.022
[24,     4] loss: 1.008
[25,     4] loss: 1.035
[26,     4] loss: 0.933
[27,     4] loss: 0.931
[28,     4] loss: 0.924
[29,     4] loss: 0.887
[30,     4] loss: 0.905
[31,     4] loss: 0.879
[32,     4] loss: 0.816
[33,     4] loss: 0.816
[34,     4] loss: 0.818
[35,     4] loss: 0.804
[36,     4] loss: 0.833
[37,     4] loss: 0.850
[38,     4] loss: 0.853
[39,     4] loss: 0.866
[40,     4] loss: 0.798
[41,     4] loss: 0.800
[42,     4] loss: 0.820
[43,     4] loss: 0.794
[44,     4] loss: 0.765
[45,     4] loss: 0.747
[46,     4] loss: 0.766
[47,     4] loss: 0.780
[48,     4] loss: 0.764
[49,     4] loss: 0.782
[50,     4] loss: 0.781
[51,     4] loss: 0.827
[52,     4] loss: 0.861
[53,     4] loss: 0.790
[54,     4] loss: 0.835
[55,     4] loss: 0.817
[56,     4] loss: 0.801
[57,     4] loss: 0.791
[58,     4] loss: 0.755
[59,     4] loss: 0.743
[60,     4] loss: 0.733
[61,     4] loss: 0.759
[62,     4] loss: 0.740
[63,     4] loss: 0.773
[64,     4] loss: 0.752
[65,     4] loss: 0.757
[66,     4] loss: 0.769
[67,     4] loss: 0.771
[68,     4] loss: 0.764
[69,     4] loss: 0.773
[70,     4] loss: 0.796
Early stopping applied (best metric=0.41312548518180847)
Finished Training
Total time taken: 37.68453359603882
{'Hydroxylation-K Validation Accuracy': 0.7867612293144208, 'Hydroxylation-K Validation Sensitivity': 0.7281481481481481, 'Hydroxylation-K Validation Specificity': 0.8017543859649122, 'Hydroxylation-K Validation Precision': 0.5049728874496676, 'Hydroxylation-K AUC ROC': 0.8168615984405458, 'Hydroxylation-K AUC PR': 0.6134924070978235, 'Hydroxylation-K MCC': 0.4744996545457152, 'Hydroxylation-K F1': 0.5851868223892535, 'Validation Loss (Hydroxylation-K)': 0.42054407199223837, 'Methylation-K Validation Accuracy': 0.8237442862624058, 'Methylation-K Validation Sensitivity': 0.12638437468691824, 'Methylation-K Validation Specificity': 0.8993735819750077, 'Methylation-K Validation Precision': 0.12324399357075444, 'Methylation-K AUC ROC': 0.5389375119887857, 'Methylation-K AUC PR': 0.11112263419366007, 'Methylation-K MCC': 0.025939924536421827, 'Methylation-K F1': 0.11511826893903113, 'Validation Loss (Methylation-K)': 0.866417404015859, 'Validation Loss (total)': 1.2869614680608115, 'TimeToTrain': 37.95649580955505}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0006371853119552419,
 'learning_rate_Hydroxylation-K': 5.2308351601785435e-05,
 'learning_rate_Methylation-K': 0.00585164317638158,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.1014526148544877,
 'loss_weight_Methylation-K': 0.11495818567936536,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3938643811,
 'sample_weights': [0.8174412512772007, 0.7781996346018751],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.2044446430472224,
 'weight_decay_Hydroxylation-K': 7.327359766504902,
 'weight_decay_Methylation-K': 2.979656621983923}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.381
[5,     4] loss: 1.374
[6,     4] loss: 1.362
[7,     4] loss: 1.352
[8,     4] loss: 1.316
[9,     4] loss: 1.288
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0002444588860926807,
 'learning_rate_Hydroxylation-K': 0.0026910481667693584,
 'learning_rate_Methylation-K': 0.002145967419403938,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.13334960877169819,
 'loss_weight_Methylation-K': 0.1717436053671152,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 631789937,
 'sample_weights': [0.1014526148544877, 0.11495818567936536],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.108228906859525,
 'weight_decay_Hydroxylation-K': 3.1646655049292582,
 'weight_decay_Methylation-K': 4.757597877568585}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.387
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0031263878343660853,
 'learning_rate_Hydroxylation-K': 0.006642799002223887,
 'learning_rate_Methylation-K': 0.008073138587764681,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7179501398466953,
 'loss_weight_Methylation-K': 0.6589798178799375,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3582997546,
 'sample_weights': [0.13334960877169819, 0.1717436053671152],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.022730686810796,
 'weight_decay_Hydroxylation-K': 2.6695468523365573,
 'weight_decay_Methylation-K': 8.834433922990716}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.393
[3,     4] loss: 1.378
[4,     4] loss: 1.392
[5,     4] loss: 1.390
[6,     4] loss: 1.382
[7,     4] loss: 1.380
[8,     4] loss: 1.369
[9,     4] loss: 1.346
[10,     4] loss: 1.294
[11,     4] loss: 1.216
[12,     4] loss: 1.198
[13,     4] loss: 1.254
[14,     4] loss: 1.153
[15,     4] loss: 1.156
[16,     4] loss: 1.098
[17,     4] loss: 1.121
[18,     4] loss: 1.060
[19,     4] loss: 0.990
[20,     4] loss: 0.974
[21,     4] loss: 0.885
[22,     4] loss: 1.032
[23,     4] loss: 0.918
[24,     4] loss: 0.913
[25,     4] loss: 0.915
[26,     4] loss: 0.863
[27,     4] loss: 0.834
[28,     4] loss: 0.932
[29,     4] loss: 0.898
[30,     4] loss: 0.829
[31,     4] loss: 0.774
[32,     4] loss: 0.765
[33,     4] loss: 0.831
[34,     4] loss: 0.831
[35,     4] loss: 0.875
[36,     4] loss: 0.859
[37,     4] loss: 0.830
[38,     4] loss: 1.025
[39,     4] loss: 0.994
[40,     4] loss: 0.928
[41,     4] loss: 0.914
[42,     4] loss: 0.879
[43,     4] loss: 0.843
[44,     4] loss: 0.813
[45,     4] loss: 0.878
[46,     4] loss: 0.794
[47,     4] loss: 0.794
[48,     4] loss: 0.797
[49,     4] loss: 0.749
[50,     4] loss: 0.775
[51,     4] loss: 0.776
[52,     4] loss: 0.929
[53,     4] loss: 0.856
[54,     4] loss: 0.873
[55,     4] loss: 0.824
[56,     4] loss: 0.935
[57,     4] loss: 0.907
[58,     4] loss: 0.910
[59,     4] loss: 0.817
[60,     4] loss: 0.841
[61,     4] loss: 1.108
[62,     4] loss: 1.025
[63,     4] loss: 1.032
[64,     4] loss: 0.978
[65,     4] loss: 0.850
[66,     4] loss: 0.831
[67,     4] loss: 0.756
[68,     4] loss: 0.746
[69,     4] loss: 0.749
[70,     4] loss: 0.761
[71,     4] loss: 0.807
[72,     4] loss: 0.787
[73,     4] loss: 0.773
[74,     4] loss: 0.787
[75,     4] loss: 0.800
[76,     4] loss: 0.817
[77,     4] loss: 0.843
[78,     4] loss: 0.808
[79,     4] loss: 0.957
[80,     4] loss: 0.892
[81,     4] loss: 0.849
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002459980222192697,
 'learning_rate_Hydroxylation-K': 0.005133967031544893,
 'learning_rate_Methylation-K': 0.009501261472979044,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.12636418617408685,
 'loss_weight_Methylation-K': 0.7045382147827279,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 91396643,
 'sample_weights': [0.7179501398466953, 0.6589798178799375],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.6445252629842195,
 'weight_decay_Hydroxylation-K': 4.506111214233653,
 'weight_decay_Methylation-K': 9.24994331458854}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.387
[3,     4] loss: 1.385
[4,     4] loss: 1.384
[5,     4] loss: 1.383
[6,     4] loss: 1.381
[7,     4] loss: 1.371
[8,     4] loss: 1.359
[9,     4] loss: 1.327
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002238847317358746,
 'learning_rate_Hydroxylation-K': 0.0024635200044602753,
 'learning_rate_Methylation-K': 0.003946791304003264,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.6230269362784938,
 'loss_weight_Methylation-K': 0.30488726034941976,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2202442069,
 'sample_weights': [0.12636418617408685, 0.7045382147827279],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.227459608501027,
 'weight_decay_Hydroxylation-K': 6.879601757105545,
 'weight_decay_Methylation-K': 4.131356646369304}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.376
[2,     4] loss: 1.384
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.003759322878161199,
 'learning_rate_Hydroxylation-K': 0.009504715184438175,
 'learning_rate_Methylation-K': 0.005539507308964802,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.05673912678723464,
 'loss_weight_Methylation-K': 0.651732945458647,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3067557917,
 'sample_weights': [0.6230269362784938, 0.30488726034941976],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.596601967578773,
 'weight_decay_Hydroxylation-K': 5.359659868302163,
 'weight_decay_Methylation-K': 4.989046564220734}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.385
[3,     4] loss: 1.379
[4,     4] loss: 1.383
[5,     4] loss: 1.365
[6,     4] loss: 1.340
[7,     4] loss: 1.289
[8,     4] loss: 1.302
[9,     4] loss: 1.185
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005182079893060248,
 'learning_rate_Hydroxylation-K': 0.004509779305588913,
 'learning_rate_Methylation-K': 0.007096496356444248,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.08122937703646013,
 'loss_weight_Methylation-K': 0.6882108435581985,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3516687514,
 'sample_weights': [0.05673912678723464, 0.651732945458647],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.852324106855139,
 'weight_decay_Hydroxylation-K': 4.961664985195575,
 'weight_decay_Methylation-K': 9.743164023825987}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.386
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023280521712024356,
 'learning_rate_Hydroxylation-K': 0.00798191338815651,
 'learning_rate_Methylation-K': 0.008010361751208497,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7950326880924425,
 'loss_weight_Methylation-K': 0.9185780557888348,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3490690810,
 'sample_weights': [0.08122937703646013, 0.6882108435581985],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 9.383760703477595,
 'weight_decay_Hydroxylation-K': 5.215325709929104,
 'weight_decay_Methylation-K': 7.60275720687825}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.383
[5,     4] loss: 1.378
[6,     4] loss: 1.378
[7,     4] loss: 1.346
[8,     4] loss: 1.318
[9,     4] loss: 1.254
[10,     4] loss: 1.161
[11,     4] loss: 1.105
[12,     4] loss: 1.117
[13,     4] loss: 1.147
[14,     4] loss: 1.071
[15,     4] loss: 1.010
[16,     4] loss: 0.995
[17,     4] loss: 0.940
[18,     4] loss: 0.894
[19,     4] loss: 0.863
[20,     4] loss: 0.862
[21,     4] loss: 0.932
[22,     4] loss: 0.986
[23,     4] loss: 1.054
[24,     4] loss: 0.966
[25,     4] loss: 0.936
[26,     4] loss: 0.882
[27,     4] loss: 0.885
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0010796831804111432,
 'learning_rate_Hydroxylation-K': 0.0031196116124226317,
 'learning_rate_Methylation-K': 0.0018790779991393364,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5563161662899448,
 'loss_weight_Methylation-K': 0.005257289053479719,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 72773434,
 'sample_weights': [0.7950326880924425, 0.9185780557888348],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.098270775011746,
 'weight_decay_Hydroxylation-K': 5.74117170467002,
 'weight_decay_Methylation-K': 6.959464326800748}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.383
[3,     4] loss: 1.380
[4,     4] loss: 1.383
[5,     4] loss: 1.368
[6,     4] loss: 1.347
[7,     4] loss: 1.302
[8,     4] loss: 1.266
[9,     4] loss: 1.190
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008117092297973288,
 'learning_rate_Hydroxylation-K': 0.009599994222837468,
 'learning_rate_Methylation-K': 0.0016793662575532104,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.7355252860503535,
 'loss_weight_Methylation-K': 0.4226775791912074,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 866783136,
 'sample_weights': [0.5563161662899448, 0.005257289053479719],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.471996480078852,
 'weight_decay_Hydroxylation-K': 5.5788356458332835,
 'weight_decay_Methylation-K': 2.2729699554057765}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.383
[3,     4] loss: 1.380
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019267600829677434,
 'learning_rate_Hydroxylation-K': 0.005669669722903057,
 'learning_rate_Methylation-K': 0.0059596207796525965,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24117633870175514,
 'loss_weight_Methylation-K': 0.7928474043639459,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 220557592,
 'sample_weights': [0.7355252860503535, 0.4226775791912074],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.10147665199328,
 'weight_decay_Hydroxylation-K': 9.471323578680964,
 'weight_decay_Methylation-K': 1.5269030026515094}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.391
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00020574113724626525,
 'learning_rate_Hydroxylation-K': 0.003976337923603723,
 'learning_rate_Methylation-K': 0.005837925076106075,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.19793370597974058,
 'loss_weight_Methylation-K': 0.8283739181550769,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4282210202,
 'sample_weights': [0.24117633870175514, 0.7928474043639459],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.43168719969722424,
 'weight_decay_Hydroxylation-K': 2.31679615854034,
 'weight_decay_Methylation-K': 7.361523605446333}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.382
[5,     4] loss: 1.385
[6,     4] loss: 1.380
[7,     4] loss: 1.378
[8,     4] loss: 1.376
[9,     4] loss: 1.369
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007923391873499066,
 'learning_rate_Hydroxylation-K': 0.008604450016850746,
 'learning_rate_Methylation-K': 0.0011751022065548925,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8653696598062368,
 'loss_weight_Methylation-K': 0.4230372221444074,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1642771120,
 'sample_weights': [0.19793370597974058, 0.8283739181550769],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.2151763425618016,
 'weight_decay_Hydroxylation-K': 7.4742451622057535,
 'weight_decay_Methylation-K': 4.673452550876752}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.387
[3,     4] loss: 1.385
[4,     4] loss: 1.381
[5,     4] loss: 1.381
[6,     4] loss: 1.373
[7,     4] loss: 1.365
[8,     4] loss: 1.348
[9,     4] loss: 1.317
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0027630424035118895,
 'learning_rate_Hydroxylation-K': 0.005031927767814564,
 'learning_rate_Methylation-K': 0.00661369343753356,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2698601557870547,
 'loss_weight_Methylation-K': 0.9820119460967706,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2989301148,
 'sample_weights': [0.8653696598062368, 0.4230372221444074],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.395039787714431,
 'weight_decay_Hydroxylation-K': 6.949743887146387,
 'weight_decay_Methylation-K': 9.520508566698831}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.386
[3,     4] loss: 1.380
[4,     4] loss: 1.385
[5,     4] loss: 1.377
[6,     4] loss: 1.369
[7,     4] loss: 1.358
[8,     4] loss: 1.340
[9,     4] loss: 1.303
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014510877195542209,
 'learning_rate_Hydroxylation-K': 0.008991309656734888,
 'learning_rate_Methylation-K': 0.0040870222707448875,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5901683106588784,
 'loss_weight_Methylation-K': 0.8736674016022752,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 220536316,
 'sample_weights': [0.2698601557870547, 0.9820119460967706],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.962083622231355,
 'weight_decay_Hydroxylation-K': 6.514473830450804,
 'weight_decay_Methylation-K': 3.5389275370803452}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.388
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00364053859304589,
 'learning_rate_Hydroxylation-K': 0.002956380813604445,
 'learning_rate_Methylation-K': 0.00010389685939828433,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.601129083696697,
 'loss_weight_Methylation-K': 0.5153789069329304,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1646076707,
 'sample_weights': [0.5901683106588784, 0.8736674016022752],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.42522745377012,
 'weight_decay_Hydroxylation-K': 7.211176493818404,
 'weight_decay_Methylation-K': 8.406654877360845}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.387
[3,     4] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0013811414478131152,
 'learning_rate_Hydroxylation-K': 0.005635043276509524,
 'learning_rate_Methylation-K': 0.00692297348186191,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5573305171411389,
 'loss_weight_Methylation-K': 0.3576230470567988,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1719955952,
 'sample_weights': [0.601129083696697, 0.5153789069329304],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.069511903782756,
 'weight_decay_Hydroxylation-K': 9.605993587980617,
 'weight_decay_Methylation-K': 6.596570800441333}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.372
[4,     4] loss: 1.363
[5,     4] loss: 1.334
[6,     4] loss: 1.279
[7,     4] loss: 1.229
[8,     4] loss: 1.200
[9,     4] loss: 1.187
[10,     4] loss: 1.105
[11,     4] loss: 1.065
[12,     4] loss: 1.044
[13,     4] loss: 0.974
[14,     4] loss: 0.996
[15,     4] loss: 1.044
[16,     4] loss: 1.004
[17,     4] loss: 1.036
[18,     4] loss: 0.928
[19,     4] loss: 0.943
[20,     4] loss: 0.953
[21,     4] loss: 0.891
[22,     4] loss: 0.999
[23,     4] loss: 0.906
[24,     4] loss: 0.884
[25,     4] loss: 0.923
[26,     4] loss: 0.858
[27,     4] loss: 0.801
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005537485536993659,
 'learning_rate_Hydroxylation-K': 0.00028326494118987856,
 'learning_rate_Methylation-K': 0.008983472210216413,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2544483767620333,
 'loss_weight_Methylation-K': 0.45043104150292435,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 128431635,
 'sample_weights': [0.5573305171411389, 0.3576230470567988],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.162129011491598,
 'weight_decay_Hydroxylation-K': 5.131508888587808,
 'weight_decay_Methylation-K': 1.9549233338378853}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.387
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009209087308076173,
 'learning_rate_Hydroxylation-K': 0.00510244378323066,
 'learning_rate_Methylation-K': 0.009212603276835466,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8100376093731405,
 'loss_weight_Methylation-K': 0.6732015519536787,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 600590666,
 'sample_weights': [0.2544483767620333, 0.45043104150292435],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.450997361249893,
 'weight_decay_Hydroxylation-K': 7.164451330879992,
 'weight_decay_Methylation-K': 8.478229304318253}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.384
[3,     4] loss: 1.381
[4,     4] loss: 1.384
[5,     4] loss: 1.380
[6,     4] loss: 1.381
[7,     4] loss: 1.380
[8,     4] loss: 1.371
[9,     4] loss: 1.354
[10,     4] loss: 1.332
[11,     4] loss: 1.315
[12,     4] loss: 1.280
[13,     4] loss: 1.234
[14,     4] loss: 1.205
[15,     4] loss: 1.137
[16,     4] loss: 1.041
[17,     4] loss: 1.014
[18,     4] loss: 0.942
[19,     4] loss: 0.963
[20,     4] loss: 0.898
[21,     4] loss: 0.848
[22,     4] loss: 0.908
[23,     4] loss: 0.853
[24,     4] loss: 0.814
[25,     4] loss: 0.916
[26,     4] loss: 0.859
[27,     4] loss: 0.886
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008920139793507367,
 'learning_rate_Hydroxylation-K': 0.0045493168865783536,
 'learning_rate_Methylation-K': 0.008998672054776558,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.12182788857788766,
 'loss_weight_Methylation-K': 0.8426806263579278,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3769896322,
 'sample_weights': [0.8100376093731405, 0.6732015519536787],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.46851071412679,
 'weight_decay_Hydroxylation-K': 5.963369988912766,
 'weight_decay_Methylation-K': 9.843254789817358}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.390
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002998368864751557,
 'learning_rate_Hydroxylation-K': 0.007338067237260393,
 'learning_rate_Methylation-K': 0.0031217218511970708,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4277528446697958,
 'loss_weight_Methylation-K': 0.7972601327918734,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1512746284,
 'sample_weights': [0.12182788857788766, 0.8426806263579278],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.7329317023880915,
 'weight_decay_Hydroxylation-K': 4.04372849702602,
 'weight_decay_Methylation-K': 4.871586987960332}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.386
[3,     4] loss: 1.382
[4,     4] loss: 1.375
[5,     4] loss: 1.373
[6,     4] loss: 1.354
[7,     4] loss: 1.318
[8,     4] loss: 1.275
[9,     4] loss: 1.176
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00277919770130997,
 'learning_rate_Hydroxylation-K': 0.002449263735525735,
 'learning_rate_Methylation-K': 0.009620236843257383,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.25679112961125994,
 'loss_weight_Methylation-K': 0.9875833823373099,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1209083422,
 'sample_weights': [0.4277528446697958, 0.7972601327918734],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.60140843319714,
 'weight_decay_Hydroxylation-K': 6.96895101575507,
 'weight_decay_Methylation-K': 9.388227725860613}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.396
[3,     4] loss: 1.389
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0014463641986417097,
 'learning_rate_Hydroxylation-K': 0.003909325097040945,
 'learning_rate_Methylation-K': 0.0028626651832073724,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.38126033400830067,
 'loss_weight_Methylation-K': 0.33103505842727665,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 897673002,
 'sample_weights': [0.25679112961125994, 0.9875833823373099],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.437704123000197,
 'weight_decay_Hydroxylation-K': 4.017208875363712,
 'weight_decay_Methylation-K': 9.746631773769929}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.384
[3,     4] loss: 1.387
[4,     4] loss: 1.373
[5,     4] loss: 1.356
[6,     4] loss: 1.349
[7,     4] loss: 1.282
[8,     4] loss: 1.249
[9,     4] loss: 1.224
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008045779738131904,
 'learning_rate_Hydroxylation-K': 0.004589590534154114,
 'learning_rate_Methylation-K': 0.008883175971289984,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3055773620574327,
 'loss_weight_Methylation-K': 0.9365063552678018,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4241204212,
 'sample_weights': [0.38126033400830067, 0.33103505842727665],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.8339893539800824,
 'weight_decay_Hydroxylation-K': 3.049804512176774,
 'weight_decay_Methylation-K': 8.984193799918048}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.385
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0008901248374796372,
 'learning_rate_Hydroxylation-K': 0.004767195154945341,
 'learning_rate_Methylation-K': 0.0021839077147840706,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.21964742966013528,
 'loss_weight_Methylation-K': 0.6113109477271768,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1843784435,
 'sample_weights': [0.3055773620574327, 0.9365063552678018],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.903688344995364,
 'weight_decay_Hydroxylation-K': 2.928781571329079,
 'weight_decay_Methylation-K': 7.422058867915125}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.386
[3,     4] loss: 1.386
[4,     4] loss: 1.377
[5,     4] loss: 1.384
[6,     4] loss: 1.372
[7,     4] loss: 1.371
[8,     4] loss: 1.342
[9,     4] loss: 1.309
[10,     4] loss: 1.263
[11,     4] loss: 1.216
[12,     4] loss: 1.207
[13,     4] loss: 1.121
[14,     4] loss: 1.148
[15,     4] loss: 1.105
[16,     4] loss: 1.028
[17,     4] loss: 1.037
[18,     4] loss: 1.011
[19,     4] loss: 0.938
[20,     4] loss: 0.912
[21,     4] loss: 0.885
[22,     4] loss: 0.884
[23,     4] loss: 0.804
[24,     4] loss: 0.818
[25,     4] loss: 0.800
[26,     4] loss: 0.803
[27,     4] loss: 0.837
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019158246217427016,
 'learning_rate_Hydroxylation-K': 0.00011124618677499647,
 'learning_rate_Methylation-K': 0.006477536087557683,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.348034705356417,
 'loss_weight_Methylation-K': 0.1763374779293263,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 131553922,
 'sample_weights': [0.21964742966013528, 0.6113109477271768],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.295123907743162,
 'weight_decay_Hydroxylation-K': 8.54427011140588,
 'weight_decay_Methylation-K': 5.393313210477492}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.402
[2,     4] loss: 1.386
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017085436481230217,
 'learning_rate_Hydroxylation-K': 0.005619383398752911,
 'learning_rate_Methylation-K': 0.00819195847983345,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.528208288867282,
 'loss_weight_Methylation-K': 0.7630423279927236,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2324654377,
 'sample_weights': [0.348034705356417, 0.1763374779293263],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.620140000766575,
 'weight_decay_Hydroxylation-K': 6.470397922827207,
 'weight_decay_Methylation-K': 6.795180535838964}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.388
[3,     4] loss: 1.389
[4,     4] loss: 1.387
[5,     4] loss: 1.383
[6,     4] loss: 1.383
[7,     4] loss: 1.383
[8,     4] loss: 1.380
[9,     4] loss: 1.375
[10,     4] loss: 1.361
[11,     4] loss: 1.331
[12,     4] loss: 1.304
[13,     4] loss: 1.215
[14,     4] loss: 1.193
[15,     4] loss: 1.160
[16,     4] loss: 1.097
[17,     4] loss: 1.084
[18,     4] loss: 0.968
[19,     4] loss: 1.001
[20,     4] loss: 0.971
[21,     4] loss: 0.949
[22,     4] loss: 0.973
[23,     4] loss: 0.968
[24,     4] loss: 0.981
[25,     4] loss: 0.997
[26,     4] loss: 1.064
[27,     4] loss: 1.008
[28,     4] loss: 0.966
[29,     4] loss: 0.960
[30,     4] loss: 0.899
[31,     4] loss: 0.883
[32,     4] loss: 0.879
[33,     4] loss: 0.821
[34,     4] loss: 0.856
[35,     4] loss: 0.829
[36,     4] loss: 0.799
[37,     4] loss: 0.809
[38,     4] loss: 0.798
[39,     4] loss: 0.795
[40,     4] loss: 0.793
[41,     4] loss: 0.800
[42,     4] loss: 0.790
[43,     4] loss: 0.772
[44,     4] loss: 0.824
[45,     4] loss: 0.830
[46,     4] loss: 0.881
[47,     4] loss: 0.835
[48,     4] loss: 0.867
[49,     4] loss: 0.833
[50,     4] loss: 0.791
[51,     4] loss: 0.776
[52,     4] loss: 0.783
[53,     4] loss: 0.759
[54,     4] loss: 0.892
[55,     4] loss: 0.844
[56,     4] loss: 0.812
[57,     4] loss: 0.783
[58,     4] loss: 0.760
[59,     4] loss: 0.777
[60,     4] loss: 0.759
[61,     4] loss: 0.801
[62,     4] loss: 0.786
[63,     4] loss: 0.773
[64,     4] loss: 0.782
[65,     4] loss: 0.787
[66,     4] loss: 0.755
[67,     4] loss: 0.742
[68,     4] loss: 0.755
[69,     4] loss: 0.763
Early stopping applied (best metric=0.393957257270813)
Finished Training
Total time taken: 37.19272255897522
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.387
[3,     4] loss: 1.384
[4,     4] loss: 1.388
[5,     4] loss: 1.383
[6,     4] loss: 1.380
[7,     4] loss: 1.369
[8,     4] loss: 1.335
[9,     4] loss: 1.298
[10,     4] loss: 1.274
[11,     4] loss: 1.243
[12,     4] loss: 1.200
[13,     4] loss: 1.121
[14,     4] loss: 1.151
[15,     4] loss: 1.074
[16,     4] loss: 1.047
[17,     4] loss: 0.978
[18,     4] loss: 0.924
[19,     4] loss: 0.921
[20,     4] loss: 0.923
[21,     4] loss: 0.921
[22,     4] loss: 0.975
[23,     4] loss: 0.966
[24,     4] loss: 0.926
[25,     4] loss: 0.912
[26,     4] loss: 0.839
[27,     4] loss: 0.849
[28,     4] loss: 0.810
[29,     4] loss: 0.834
[30,     4] loss: 0.774
[31,     4] loss: 0.814
[32,     4] loss: 0.800
[33,     4] loss: 0.814
[34,     4] loss: 0.857
[35,     4] loss: 0.830
[36,     4] loss: 0.837
[37,     4] loss: 0.791
[38,     4] loss: 0.789
[39,     4] loss: 0.797
[40,     4] loss: 0.804
[41,     4] loss: 0.801
[42,     4] loss: 0.824
[43,     4] loss: 0.820
[44,     4] loss: 0.801
[45,     4] loss: 0.834
[46,     4] loss: 0.839
[47,     4] loss: 0.826
[48,     4] loss: 0.801
[49,     4] loss: 0.866
[50,     4] loss: 0.808
[51,     4] loss: 0.870
[52,     4] loss: 0.837
[53,     4] loss: 0.805
[54,     4] loss: 0.777
[55,     4] loss: 0.773
[56,     4] loss: 0.764
[57,     4] loss: 0.762
[58,     4] loss: 0.774
[59,     4] loss: 0.759
[60,     4] loss: 0.755
[61,     4] loss: 0.772
Early stopping applied (best metric=0.45389604568481445)
Finished Training
Total time taken: 33.82503366470337
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.390
[5,     4] loss: 1.380
[6,     4] loss: 1.375
[7,     4] loss: 1.364
[8,     4] loss: 1.338
[9,     4] loss: 1.295
[10,     4] loss: 1.256
[11,     4] loss: 1.181
[12,     4] loss: 1.160
[13,     4] loss: 1.119
[14,     4] loss: 1.128
[15,     4] loss: 1.036
[16,     4] loss: 0.972
[17,     4] loss: 1.007
[18,     4] loss: 0.910
[19,     4] loss: 0.924
[20,     4] loss: 0.973
[21,     4] loss: 0.990
[22,     4] loss: 0.986
[23,     4] loss: 1.003
[24,     4] loss: 0.936
[25,     4] loss: 0.876
[26,     4] loss: 0.930
[27,     4] loss: 0.826
[28,     4] loss: 0.860
[29,     4] loss: 0.877
[30,     4] loss: 0.811
[31,     4] loss: 0.803
[32,     4] loss: 0.799
[33,     4] loss: 0.775
[34,     4] loss: 0.845
[35,     4] loss: 0.850
[36,     4] loss: 0.837
[37,     4] loss: 0.812
[38,     4] loss: 0.890
[39,     4] loss: 0.834
[40,     4] loss: 0.814
[41,     4] loss: 0.826
[42,     4] loss: 0.953
[43,     4] loss: 0.869
[44,     4] loss: 1.001
[45,     4] loss: 0.901
[46,     4] loss: 0.922
[47,     4] loss: 0.879
[48,     4] loss: 0.816
[49,     4] loss: 0.803
[50,     4] loss: 0.771
[51,     4] loss: 0.764
[52,     4] loss: 0.790
[53,     4] loss: 0.821
[54,     4] loss: 0.796
[55,     4] loss: 0.807
[56,     4] loss: 0.804
[57,     4] loss: 0.783
[58,     4] loss: 0.801
[59,     4] loss: 0.787
[60,     4] loss: 0.798
[61,     4] loss: 0.803
Early stopping applied (best metric=0.4879152178764343)
Finished Training
Total time taken: 31.204240798950195
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.385
[3,     4] loss: 1.380
[4,     4] loss: 1.371
[5,     4] loss: 1.351
[6,     4] loss: 1.307
[7,     4] loss: 1.245
[8,     4] loss: 1.163
[9,     4] loss: 1.167
[10,     4] loss: 1.131
[11,     4] loss: 1.136
[12,     4] loss: 1.063
[13,     4] loss: 1.010
[14,     4] loss: 0.978
[15,     4] loss: 0.981
[16,     4] loss: 1.014
[17,     4] loss: 1.012
[18,     4] loss: 1.016
[19,     4] loss: 1.030
[20,     4] loss: 0.963
[21,     4] loss: 1.028
[22,     4] loss: 0.949
[23,     4] loss: 0.940
[24,     4] loss: 0.914
[25,     4] loss: 0.977
[26,     4] loss: 0.888
[27,     4] loss: 0.875
[28,     4] loss: 0.917
[29,     4] loss: 0.848
[30,     4] loss: 0.883
[31,     4] loss: 0.978
[32,     4] loss: 0.926
[33,     4] loss: 0.896
[34,     4] loss: 0.820
[35,     4] loss: 0.809
[36,     4] loss: 0.818
[37,     4] loss: 0.850
[38,     4] loss: 0.804
[39,     4] loss: 0.804
[40,     4] loss: 0.856
[41,     4] loss: 0.801
[42,     4] loss: 0.793
[43,     4] loss: 0.757
[44,     4] loss: 0.887
[45,     4] loss: 0.865
[46,     4] loss: 0.831
[47,     4] loss: 0.790
[48,     4] loss: 0.781
[49,     4] loss: 0.755
[50,     4] loss: 0.746
[51,     4] loss: 0.755
[52,     4] loss: 0.752
[53,     4] loss: 0.751
[54,     4] loss: 0.748
[55,     4] loss: 0.767
[56,     4] loss: 0.765
Early stopping applied (best metric=0.4745975434780121)
Finished Training
Total time taken: 29.14615488052368
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.396
[2,     4] loss: 1.383
[3,     4] loss: 1.377
[4,     4] loss: 1.371
[5,     4] loss: 1.345
[6,     4] loss: 1.276
[7,     4] loss: 1.221
[8,     4] loss: 1.174
[9,     4] loss: 1.130
[10,     4] loss: 1.162
[11,     4] loss: 1.038
[12,     4] loss: 1.031
[13,     4] loss: 0.938
[14,     4] loss: 1.003
[15,     4] loss: 0.917
[16,     4] loss: 0.973
[17,     4] loss: 1.036
[18,     4] loss: 1.033
[19,     4] loss: 1.038
[20,     4] loss: 1.020
[21,     4] loss: 0.973
[22,     4] loss: 0.932
[23,     4] loss: 0.995
[24,     4] loss: 0.860
[25,     4] loss: 0.903
[26,     4] loss: 0.832
[27,     4] loss: 0.882
[28,     4] loss: 0.838
[29,     4] loss: 0.816
[30,     4] loss: 0.806
[31,     4] loss: 0.781
[32,     4] loss: 0.765
[33,     4] loss: 0.754
[34,     4] loss: 0.874
[35,     4] loss: 0.853
[36,     4] loss: 0.818
[37,     4] loss: 0.908
[38,     4] loss: 0.835
[39,     4] loss: 0.848
[40,     4] loss: 0.807
[41,     4] loss: 0.905
[42,     4] loss: 0.831
[43,     4] loss: 0.786
[44,     4] loss: 0.798
[45,     4] loss: 0.780
[46,     4] loss: 0.754
[47,     4] loss: 0.738
[48,     4] loss: 0.749
[49,     4] loss: 0.749
[50,     4] loss: 0.759
[51,     4] loss: 0.779
[52,     4] loss: 0.830
[53,     4] loss: 0.774
[54,     4] loss: 0.772
[55,     4] loss: 0.745
Early stopping applied (best metric=0.5064511895179749)
Finished Training
Total time taken: 30.280515670776367
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.384
[2,     4] loss: 1.384
[3,     4] loss: 1.385
[4,     4] loss: 1.388
[5,     4] loss: 1.378
[6,     4] loss: 1.380
[7,     4] loss: 1.368
[8,     4] loss: 1.329
[9,     4] loss: 1.303
[10,     4] loss: 1.265
[11,     4] loss: 1.269
[12,     4] loss: 1.235
[13,     4] loss: 1.190
[14,     4] loss: 1.180
[15,     4] loss: 1.106
[16,     4] loss: 1.061
[17,     4] loss: 1.013
[18,     4] loss: 0.947
[19,     4] loss: 1.001
[20,     4] loss: 1.044
[21,     4] loss: 1.005
[22,     4] loss: 1.003
[23,     4] loss: 0.926
[24,     4] loss: 0.906
[25,     4] loss: 0.895
[26,     4] loss: 0.885
[27,     4] loss: 0.833
[28,     4] loss: 0.877
[29,     4] loss: 0.846
[30,     4] loss: 0.830
[31,     4] loss: 0.844
[32,     4] loss: 0.825
[33,     4] loss: 0.860
[34,     4] loss: 0.881
[35,     4] loss: 0.837
[36,     4] loss: 0.843
[37,     4] loss: 0.843
[38,     4] loss: 0.829
[39,     4] loss: 0.807
[40,     4] loss: 0.781
[41,     4] loss: 0.792
[42,     4] loss: 0.861
[43,     4] loss: 0.828
[44,     4] loss: 0.767
[45,     4] loss: 0.796
[46,     4] loss: 0.768
[47,     4] loss: 0.772
[48,     4] loss: 0.769
[49,     4] loss: 0.778
[50,     4] loss: 0.825
[51,     4] loss: 0.826
[52,     4] loss: 0.777
[53,     4] loss: 0.766
[54,     4] loss: 0.781
[55,     4] loss: 0.764
[56,     4] loss: 0.763
[57,     4] loss: 0.780
[58,     4] loss: 0.797
[59,     4] loss: 0.802
[60,     4] loss: 0.902
[61,     4] loss: 0.867
[62,     4] loss: 0.810
[63,     4] loss: 0.830
[64,     4] loss: 0.804
[65,     4] loss: 0.787
[66,     4] loss: 0.779
[67,     4] loss: 0.827
[68,     4] loss: 0.817
[69,     4] loss: 0.844
[70,     4] loss: 0.812
[71,     4] loss: 0.793
Early stopping applied (best metric=0.40584421157836914)
Finished Training
Total time taken: 37.77593493461609
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.388
[3,     4] loss: 1.386
[4,     4] loss: 1.380
[5,     4] loss: 1.374
[6,     4] loss: 1.351
[7,     4] loss: 1.332
[8,     4] loss: 1.288
[9,     4] loss: 1.242
[10,     4] loss: 1.158
[11,     4] loss: 1.144
[12,     4] loss: 1.220
[13,     4] loss: 1.208
[14,     4] loss: 1.098
[15,     4] loss: 1.068
[16,     4] loss: 1.021
[17,     4] loss: 1.061
[18,     4] loss: 1.000
[19,     4] loss: 0.985
[20,     4] loss: 0.943
[21,     4] loss: 0.937
[22,     4] loss: 0.908
[23,     4] loss: 0.851
[24,     4] loss: 0.816
[25,     4] loss: 0.923
[26,     4] loss: 0.858
[27,     4] loss: 0.831
[28,     4] loss: 0.848
[29,     4] loss: 0.878
[30,     4] loss: 0.853
[31,     4] loss: 0.846
[32,     4] loss: 0.834
[33,     4] loss: 0.826
[34,     4] loss: 0.840
[35,     4] loss: 0.845
[36,     4] loss: 0.811
[37,     4] loss: 0.787
[38,     4] loss: 0.787
[39,     4] loss: 0.801
[40,     4] loss: 0.805
[41,     4] loss: 0.788
[42,     4] loss: 0.797
[43,     4] loss: 0.781
[44,     4] loss: 0.748
[45,     4] loss: 0.748
[46,     4] loss: 0.749
[47,     4] loss: 0.824
[48,     4] loss: 0.841
[49,     4] loss: 0.871
[50,     4] loss: 0.885
[51,     4] loss: 0.811
[52,     4] loss: 0.793
[53,     4] loss: 0.774
[54,     4] loss: 0.742
[55,     4] loss: 0.749
[56,     4] loss: 0.754
[57,     4] loss: 0.775
[58,     4] loss: 0.793
[59,     4] loss: 0.755
Early stopping applied (best metric=0.39992833137512207)
Finished Training
Total time taken: 37.72248291969299
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.382
[3,     4] loss: 1.383
[4,     4] loss: 1.368
[5,     4] loss: 1.354
[6,     4] loss: 1.314
[7,     4] loss: 1.294
[8,     4] loss: 1.214
[9,     4] loss: 1.131
[10,     4] loss: 1.084
[11,     4] loss: 1.088
[12,     4] loss: 1.012
[13,     4] loss: 1.002
[14,     4] loss: 0.982
[15,     4] loss: 1.040
[16,     4] loss: 0.991
[17,     4] loss: 0.941
[18,     4] loss: 0.841
[19,     4] loss: 0.947
[20,     4] loss: 0.919
[21,     4] loss: 0.905
[22,     4] loss: 0.921
[23,     4] loss: 0.934
[24,     4] loss: 0.931
[25,     4] loss: 0.893
[26,     4] loss: 0.876
[27,     4] loss: 0.905
[28,     4] loss: 0.831
[29,     4] loss: 0.873
[30,     4] loss: 0.946
[31,     4] loss: 0.864
[32,     4] loss: 0.837
[33,     4] loss: 0.832
[34,     4] loss: 0.840
[35,     4] loss: 0.827
[36,     4] loss: 0.788
[37,     4] loss: 0.774
[38,     4] loss: 0.800
[39,     4] loss: 0.769
[40,     4] loss: 0.800
[41,     4] loss: 0.784
[42,     4] loss: 0.776
[43,     4] loss: 0.815
[44,     4] loss: 0.846
[45,     4] loss: 0.830
[46,     4] loss: 0.916
[47,     4] loss: 0.816
[48,     4] loss: 0.769
[49,     4] loss: 0.776
[50,     4] loss: 0.791
[51,     4] loss: 0.755
[52,     4] loss: 0.774
[53,     4] loss: 0.766
[54,     4] loss: 0.756
[55,     4] loss: 0.749
[56,     4] loss: 0.769
[57,     4] loss: 0.752
[58,     4] loss: 0.855
Early stopping applied (best metric=0.4574766159057617)
Finished Training
Total time taken: 32.36764073371887
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.386
[3,     4] loss: 1.383
[4,     4] loss: 1.378
[5,     4] loss: 1.361
[6,     4] loss: 1.337
[7,     4] loss: 1.293
[8,     4] loss: 1.235
[9,     4] loss: 1.140
[10,     4] loss: 1.147
[11,     4] loss: 1.045
[12,     4] loss: 1.150
[13,     4] loss: 1.209
[14,     4] loss: 1.110
[15,     4] loss: 1.031
[16,     4] loss: 1.048
[17,     4] loss: 0.949
[18,     4] loss: 1.029
[19,     4] loss: 0.947
[20,     4] loss: 0.997
[21,     4] loss: 1.015
[22,     4] loss: 1.029
[23,     4] loss: 0.925
[24,     4] loss: 0.932
[25,     4] loss: 0.900
[26,     4] loss: 0.848
[27,     4] loss: 0.828
[28,     4] loss: 0.811
[29,     4] loss: 0.809
[30,     4] loss: 0.813
[31,     4] loss: 0.832
[32,     4] loss: 0.907
[33,     4] loss: 0.910
[34,     4] loss: 0.821
[35,     4] loss: 0.836
[36,     4] loss: 0.789
[37,     4] loss: 0.852
[38,     4] loss: 0.773
[39,     4] loss: 0.801
[40,     4] loss: 0.782
[41,     4] loss: 0.827
[42,     4] loss: 0.848
[43,     4] loss: 0.810
[44,     4] loss: 0.822
[45,     4] loss: 0.838
[46,     4] loss: 0.831
[47,     4] loss: 0.868
[48,     4] loss: 0.864
[49,     4] loss: 0.858
[50,     4] loss: 0.842
[51,     4] loss: 0.783
[52,     4] loss: 0.791
[53,     4] loss: 0.759
[54,     4] loss: 0.770
[55,     4] loss: 0.763
[56,     4] loss: 0.757
[57,     4] loss: 0.796
[58,     4] loss: 0.781
[59,     4] loss: 0.783
[60,     4] loss: 0.763
[61,     4] loss: 0.783
[62,     4] loss: 0.760
[63,     4] loss: 0.757
Early stopping applied (best metric=0.44737404584884644)
Finished Training
Total time taken: 35.11522841453552
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.388
[2,     4] loss: 1.390
[3,     4] loss: 1.388
[4,     4] loss: 1.381
[5,     4] loss: 1.381
[6,     4] loss: 1.373
[7,     4] loss: 1.353
[8,     4] loss: 1.323
[9,     4] loss: 1.282
[10,     4] loss: 1.235
[11,     4] loss: 1.206
[12,     4] loss: 1.149
[13,     4] loss: 1.059
[14,     4] loss: 1.049
[15,     4] loss: 1.007
[16,     4] loss: 1.002
[17,     4] loss: 1.095
[18,     4] loss: 1.056
[19,     4] loss: 0.987
[20,     4] loss: 1.038
[21,     4] loss: 0.994
[22,     4] loss: 0.955
[23,     4] loss: 0.875
[24,     4] loss: 0.905
[25,     4] loss: 1.044
[26,     4] loss: 0.957
[27,     4] loss: 0.901
[28,     4] loss: 0.916
[29,     4] loss: 0.896
[30,     4] loss: 0.862
[31,     4] loss: 0.860
[32,     4] loss: 0.869
[33,     4] loss: 0.852
[34,     4] loss: 0.828
[35,     4] loss: 0.797
[36,     4] loss: 0.831
[37,     4] loss: 0.824
[38,     4] loss: 0.841
[39,     4] loss: 0.807
[40,     4] loss: 0.893
[41,     4] loss: 0.858
[42,     4] loss: 0.863
[43,     4] loss: 0.824
[44,     4] loss: 0.820
[45,     4] loss: 0.815
[46,     4] loss: 0.825
[47,     4] loss: 0.785
[48,     4] loss: 0.791
[49,     4] loss: 0.858
[50,     4] loss: 0.796
[51,     4] loss: 0.802
[52,     4] loss: 0.844
[53,     4] loss: 0.871
[54,     4] loss: 0.874
[55,     4] loss: 0.925
[56,     4] loss: 0.913
[57,     4] loss: 0.923
[58,     4] loss: 0.909
[59,     4] loss: 0.936
[60,     4] loss: 0.879
[61,     4] loss: 0.855
[62,     4] loss: 0.831
[63,     4] loss: 0.783
[64,     4] loss: 0.786
[65,     4] loss: 0.784
[66,     4] loss: 0.754
[67,     4] loss: 0.775
[68,     4] loss: 0.770
[69,     4] loss: 0.787
[70,     4] loss: 0.769
[71,     4] loss: 0.758
Early stopping applied (best metric=0.48310887813568115)
Finished Training
Total time taken: 41.27982759475708
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.390
[3,     4] loss: 1.387
[4,     4] loss: 1.381
[5,     4] loss: 1.388
[6,     4] loss: 1.379
[7,     4] loss: 1.359
[8,     4] loss: 1.339
[9,     4] loss: 1.302
[10,     4] loss: 1.240
[11,     4] loss: 1.200
[12,     4] loss: 1.135
[13,     4] loss: 1.096
[14,     4] loss: 1.104
[15,     4] loss: 1.091
[16,     4] loss: 1.049
[17,     4] loss: 1.054
[18,     4] loss: 1.070
[19,     4] loss: 0.983
[20,     4] loss: 0.950
[21,     4] loss: 0.965
[22,     4] loss: 0.924
[23,     4] loss: 0.924
[24,     4] loss: 0.985
[25,     4] loss: 0.944
[26,     4] loss: 0.929
[27,     4] loss: 1.005
[28,     4] loss: 1.025
[29,     4] loss: 0.917
[30,     4] loss: 0.924
[31,     4] loss: 0.897
[32,     4] loss: 0.877
[33,     4] loss: 0.963
[34,     4] loss: 0.874
[35,     4] loss: 0.881
[36,     4] loss: 0.859
[37,     4] loss: 0.824
[38,     4] loss: 0.815
[39,     4] loss: 0.809
[40,     4] loss: 0.780
[41,     4] loss: 0.801
[42,     4] loss: 0.813
[43,     4] loss: 0.841
[44,     4] loss: 0.808
[45,     4] loss: 0.790
[46,     4] loss: 0.770
[47,     4] loss: 0.745
[48,     4] loss: 0.754
[49,     4] loss: 0.780
[50,     4] loss: 0.843
[51,     4] loss: 0.826
[52,     4] loss: 0.823
[53,     4] loss: 0.801
[54,     4] loss: 0.772
[55,     4] loss: 0.741
[56,     4] loss: 0.775
[57,     4] loss: 0.752
[58,     4] loss: 0.774
[59,     4] loss: 0.790
[60,     4] loss: 0.770
[61,     4] loss: 0.752
[62,     4] loss: 0.760
[63,     4] loss: 0.735
[64,     4] loss: 0.809
[65,     4] loss: 0.885
[66,     4] loss: 0.804
[67,     4] loss: 0.814
[68,     4] loss: 0.763
[69,     4] loss: 0.763
[70,     4] loss: 0.754
[71,     4] loss: 0.760
[72,     4] loss: 0.745
[73,     4] loss: 0.750
[74,     4] loss: 0.773
[75,     4] loss: 0.894
[76,     4] loss: 0.817
[77,     4] loss: 0.807
[78,     4] loss: 0.823
[79,     4] loss: 0.818
[80,     4] loss: 0.760
[81,     4] loss: 0.779
[82,     4] loss: 0.794
[83,     4] loss: 0.794
[84,     4] loss: 0.845
[85,     4] loss: 0.855
[86,     4] loss: 0.851
[87,     4] loss: 0.899
[88,     4] loss: 0.954
[89,     4] loss: 0.879
[90,     4] loss: 0.782
[91,     4] loss: 0.780
[92,     4] loss: 0.753
[93,     4] loss: 0.767
[94,     4] loss: 0.747
[95,     4] loss: 0.759
[96,     4] loss: 0.762
[97,     4] loss: 0.752
[98,     4] loss: 0.753
[99,     4] loss: 0.736
[100,     4] loss: 0.750
[101,     4] loss: 0.762
[102,     4] loss: 0.762
[103,     4] loss: 0.835
[104,     4] loss: 0.986
[105,     4] loss: 0.909
[106,     4] loss: 0.913
[107,     4] loss: 0.827
[108,     4] loss: 0.831
[109,     4] loss: 0.780
[110,     4] loss: 0.752
[111,     4] loss: 0.766
[112,     4] loss: 0.755
[113,     4] loss: 0.747
Early stopping applied (best metric=0.29626578092575073)
Finished Training
Total time taken: 65.55605506896973
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.380
[3,     4] loss: 1.373
[4,     4] loss: 1.347
[5,     4] loss: 1.327
[6,     4] loss: 1.279
[7,     4] loss: 1.262
[8,     4] loss: 1.205
[9,     4] loss: 1.132
[10,     4] loss: 1.091
[11,     4] loss: 1.097
[12,     4] loss: 1.064
[13,     4] loss: 1.040
[14,     4] loss: 1.075
[15,     4] loss: 0.993
[16,     4] loss: 0.934
[17,     4] loss: 0.900
[18,     4] loss: 0.846
[19,     4] loss: 0.947
[20,     4] loss: 0.902
[21,     4] loss: 0.887
[22,     4] loss: 0.846
[23,     4] loss: 0.890
[24,     4] loss: 0.835
[25,     4] loss: 0.850
[26,     4] loss: 0.815
[27,     4] loss: 0.894
[28,     4] loss: 0.812
[29,     4] loss: 0.796
[30,     4] loss: 0.800
[31,     4] loss: 0.850
[32,     4] loss: 0.848
[33,     4] loss: 0.857
[34,     4] loss: 0.867
[35,     4] loss: 0.831
[36,     4] loss: 0.815
[37,     4] loss: 0.784
[38,     4] loss: 0.892
[39,     4] loss: 0.817
[40,     4] loss: 0.794
[41,     4] loss: 0.882
[42,     4] loss: 0.894
[43,     4] loss: 0.806
[44,     4] loss: 0.834
[45,     4] loss: 0.783
[46,     4] loss: 0.773
[47,     4] loss: 0.842
[48,     4] loss: 0.757
[49,     4] loss: 0.786
[50,     4] loss: 0.769
[51,     4] loss: 0.775
[52,     4] loss: 0.744
[53,     4] loss: 0.736
[54,     4] loss: 0.755
Early stopping applied (best metric=0.5435734987258911)
Finished Training
Total time taken: 28.3339421749115
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.379
[2,     4] loss: 1.387
[3,     4] loss: 1.378
[4,     4] loss: 1.364
[5,     4] loss: 1.325
[6,     4] loss: 1.293
[7,     4] loss: 1.235
[8,     4] loss: 1.252
[9,     4] loss: 1.136
[10,     4] loss: 1.140
[11,     4] loss: 1.120
[12,     4] loss: 1.047
[13,     4] loss: 1.014
[14,     4] loss: 1.019
[15,     4] loss: 1.046
[16,     4] loss: 0.973
[17,     4] loss: 0.991
[18,     4] loss: 0.947
[19,     4] loss: 0.964
[20,     4] loss: 0.944
[21,     4] loss: 0.898
[22,     4] loss: 0.912
[23,     4] loss: 0.957
[24,     4] loss: 0.914
[25,     4] loss: 0.836
[26,     4] loss: 0.849
[27,     4] loss: 0.907
[28,     4] loss: 0.867
[29,     4] loss: 0.940
[30,     4] loss: 0.852
[31,     4] loss: 0.836
[32,     4] loss: 0.832
[33,     4] loss: 0.824
[34,     4] loss: 0.788
[35,     4] loss: 0.820
[36,     4] loss: 0.802
[37,     4] loss: 0.804
[38,     4] loss: 0.833
[39,     4] loss: 0.837
[40,     4] loss: 0.825
[41,     4] loss: 0.778
[42,     4] loss: 0.790
[43,     4] loss: 0.802
[44,     4] loss: 0.951
[45,     4] loss: 1.083
[46,     4] loss: 1.080
[47,     4] loss: 1.007
[48,     4] loss: 0.971
[49,     4] loss: 0.867
[50,     4] loss: 0.804
[51,     4] loss: 0.831
[52,     4] loss: 0.822
[53,     4] loss: 0.829
[54,     4] loss: 0.869
[55,     4] loss: 0.796
[56,     4] loss: 0.801
[57,     4] loss: 0.794
[58,     4] loss: 0.862
Early stopping applied (best metric=0.3826372027397156)
Finished Training
Total time taken: 30.583114624023438
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.383
[3,     4] loss: 1.387
[4,     4] loss: 1.385
[5,     4] loss: 1.375
[6,     4] loss: 1.383
[7,     4] loss: 1.355
[8,     4] loss: 1.332
[9,     4] loss: 1.285
[10,     4] loss: 1.187
[11,     4] loss: 1.146
[12,     4] loss: 1.101
[13,     4] loss: 1.103
[14,     4] loss: 1.027
[15,     4] loss: 1.108
[16,     4] loss: 1.202
[17,     4] loss: 1.135
[18,     4] loss: 1.140
[19,     4] loss: 1.074
[20,     4] loss: 1.012
[21,     4] loss: 0.933
[22,     4] loss: 0.932
[23,     4] loss: 0.880
[24,     4] loss: 0.988
[25,     4] loss: 0.966
[26,     4] loss: 0.930
[27,     4] loss: 0.905
[28,     4] loss: 0.913
[29,     4] loss: 0.874
[30,     4] loss: 0.876
[31,     4] loss: 0.926
[32,     4] loss: 0.879
[33,     4] loss: 0.907
[34,     4] loss: 0.916
[35,     4] loss: 0.903
[36,     4] loss: 0.888
[37,     4] loss: 0.870
[38,     4] loss: 0.825
[39,     4] loss: 0.818
[40,     4] loss: 0.809
[41,     4] loss: 0.776
[42,     4] loss: 0.787
[43,     4] loss: 0.782
[44,     4] loss: 0.920
[45,     4] loss: 0.877
[46,     4] loss: 0.891
[47,     4] loss: 0.869
[48,     4] loss: 0.909
[49,     4] loss: 0.931
[50,     4] loss: 0.869
[51,     4] loss: 0.814
[52,     4] loss: 0.790
[53,     4] loss: 0.778
[54,     4] loss: 0.760
[55,     4] loss: 0.792
[56,     4] loss: 0.780
[57,     4] loss: 0.785
[58,     4] loss: 0.761
[59,     4] loss: 0.783
[60,     4] loss: 0.747
[61,     4] loss: 0.769
[62,     4] loss: 0.753
[63,     4] loss: 0.760
[64,     4] loss: 0.761
[65,     4] loss: 0.805
[66,     4] loss: 0.925
[67,     4] loss: 0.999
[68,     4] loss: 0.922
[69,     4] loss: 0.894
[70,     4] loss: 0.831
[71,     4] loss: 0.795
[72,     4] loss: 0.784
[73,     4] loss: 0.822
[74,     4] loss: 0.793
[75,     4] loss: 0.795
[76,     4] loss: 0.788
[77,     4] loss: 0.787
[78,     4] loss: 0.784
[79,     4] loss: 0.923
Early stopping applied (best metric=0.2481244057416916)
Finished Training
Total time taken: 40.044270277023315
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.391
[2,     4] loss: 1.394
[3,     4] loss: 1.383
[4,     4] loss: 1.382
[5,     4] loss: 1.383
[6,     4] loss: 1.388
[7,     4] loss: 1.379
[8,     4] loss: 1.371
[9,     4] loss: 1.360
[10,     4] loss: 1.332
[11,     4] loss: 1.248
[12,     4] loss: 1.259
[13,     4] loss: 1.186
[14,     4] loss: 1.138
[15,     4] loss: 1.065
[16,     4] loss: 1.054
[17,     4] loss: 0.986
[18,     4] loss: 1.038
[19,     4] loss: 0.928
[20,     4] loss: 0.954
[21,     4] loss: 1.069
[22,     4] loss: 0.941
[23,     4] loss: 0.893
[24,     4] loss: 1.016
[25,     4] loss: 0.898
[26,     4] loss: 0.891
[27,     4] loss: 0.836
[28,     4] loss: 0.825
[29,     4] loss: 0.787
[30,     4] loss: 0.850
[31,     4] loss: 0.921
[32,     4] loss: 0.840
[33,     4] loss: 0.856
[34,     4] loss: 0.786
[35,     4] loss: 0.773
[36,     4] loss: 0.788
[37,     4] loss: 0.773
[38,     4] loss: 0.798
[39,     4] loss: 0.767
[40,     4] loss: 0.784
[41,     4] loss: 0.762
[42,     4] loss: 0.751
[43,     4] loss: 0.862
[44,     4] loss: 0.982
[45,     4] loss: 0.846
[46,     4] loss: 0.892
[47,     4] loss: 0.843
[48,     4] loss: 0.818
[49,     4] loss: 0.790
[50,     4] loss: 0.791
[51,     4] loss: 0.785
[52,     4] loss: 0.756
[53,     4] loss: 0.764
[54,     4] loss: 0.751
[55,     4] loss: 0.743
[56,     4] loss: 0.729
[57,     4] loss: 0.729
[58,     4] loss: 0.742
[59,     4] loss: 0.747
[60,     4] loss: 0.744
[61,     4] loss: 0.723
[62,     4] loss: 0.730
Early stopping applied (best metric=0.3823202848434448)
Finished Training
Total time taken: 33.74508762359619
{'Hydroxylation-K Validation Accuracy': 0.7577718676122931, 'Hydroxylation-K Validation Sensitivity': 0.7437037037037036, 'Hydroxylation-K Validation Specificity': 0.7614035087719299, 'Hydroxylation-K Validation Precision': 0.47136393190572756, 'Hydroxylation-K AUC ROC': 0.8223196881091618, 'Hydroxylation-K AUC PR': 0.5825412240112832, 'Hydroxylation-K MCC': 0.4448057283228596, 'Hydroxylation-K F1': 0.5627489341098171, 'Validation Loss (Hydroxylation-K)': 0.4242313673098882, 'Methylation-K Validation Accuracy': 0.801413620007158, 'Methylation-K Validation Sensitivity': 0.1688907994156584, 'Methylation-K Validation Specificity': 0.8700105447082896, 'Methylation-K Validation Precision': 0.12314354359586664, 'Methylation-K AUC ROC': 0.55028489655383, 'Methylation-K AUC PR': 0.11525623627758903, 'Methylation-K MCC': 0.03268472572257832, 'Methylation-K F1': 0.12945287822133786, 'Validation Loss (Methylation-K)': 0.7684448719024658, 'Validation Loss (total)': 1.1926762223243714, 'TimeToTrain': 36.278150129318234}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00010907571518090813,
 'learning_rate_Hydroxylation-K': 0.00010988373125783214,
 'learning_rate_Methylation-K': 0.00021032044790964422,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.12498165126707009,
 'loss_weight_Methylation-K': 0.6307721136312264,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2905688673,
 'sample_weights': [0.528208288867282, 0.7630423279927236],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.7262686047322156,
 'weight_decay_Hydroxylation-K': 0.8337117421432474,
 'weight_decay_Methylation-K': 9.416698775781832}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.388
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002114541788544498,
 'learning_rate_Hydroxylation-K': 0.0013452887586592895,
 'learning_rate_Methylation-K': 0.008356836606687772,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.0810305991912576,
 'loss_weight_Methylation-K': 0.5673331394254075,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1301670706,
 'sample_weights': [0.12498165126707009, 0.6307721136312264],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.438936667369857,
 'weight_decay_Hydroxylation-K': 9.194562271655533,
 'weight_decay_Methylation-K': 9.886257736086684}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.388
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0011442994215420284,
 'learning_rate_Hydroxylation-K': 0.0024316089923945385,
 'learning_rate_Methylation-K': 0.003437954268834997,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.44813255748284275,
 'loss_weight_Methylation-K': 0.24303600171217243,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2159023284,
 'sample_weights': [0.0810305991912576, 0.5673331394254075],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.273646003441947,
 'weight_decay_Hydroxylation-K': 6.884959324068183,
 'weight_decay_Methylation-K': 8.932872393797107}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.382
[3,     4] loss: 1.388
[4,     4] loss: 1.384
[5,     4] loss: 1.372
[6,     4] loss: 1.355
[7,     4] loss: 1.325
[8,     4] loss: 1.293
[9,     4] loss: 1.244
[10,     4] loss: 1.209
[11,     4] loss: 1.130
[12,     4] loss: 1.116
[13,     4] loss: 1.072
[14,     4] loss: 1.115
[15,     4] loss: 1.068
[16,     4] loss: 1.069
[17,     4] loss: 1.076
[18,     4] loss: 0.996
[19,     4] loss: 0.999
[20,     4] loss: 1.020
[21,     4] loss: 0.982
[22,     4] loss: 0.968
[23,     4] loss: 0.930
[24,     4] loss: 0.999
[25,     4] loss: 0.965
[26,     4] loss: 0.910
[27,     4] loss: 0.972
[28,     4] loss: 0.897
[29,     4] loss: 0.874
[30,     4] loss: 0.883
[31,     4] loss: 0.872
[32,     4] loss: 0.892
[33,     4] loss: 0.859
[34,     4] loss: 0.856
[35,     4] loss: 0.850
[36,     4] loss: 0.821
[37,     4] loss: 0.837
[38,     4] loss: 0.814
[39,     4] loss: 0.799
[40,     4] loss: 0.796
[41,     4] loss: 0.811
[42,     4] loss: 0.783
[43,     4] loss: 0.787
[44,     4] loss: 0.771
[45,     4] loss: 0.800
[46,     4] loss: 0.760
[47,     4] loss: 0.793
[48,     4] loss: 0.746
[49,     4] loss: 0.759
[50,     4] loss: 0.783
[51,     4] loss: 0.780
[52,     4] loss: 0.758
[53,     4] loss: 0.794
[54,     4] loss: 0.772
[55,     4] loss: 0.769
[56,     4] loss: 0.770
[57,     4] loss: 0.774
[58,     4] loss: 0.741
[59,     4] loss: 0.765
[60,     4] loss: 0.783
[61,     4] loss: 0.754
[62,     4] loss: 0.752
[63,     4] loss: 0.735
[64,     4] loss: 0.719
[65,     4] loss: 0.708
[66,     4] loss: 0.702
[67,     4] loss: 0.717
[68,     4] loss: 0.706
[69,     4] loss: 0.718
[70,     4] loss: 0.714
[71,     4] loss: 0.705
[72,     4] loss: 0.739
[73,     4] loss: 0.708
[74,     4] loss: 0.701
[75,     4] loss: 0.702
[76,     4] loss: 0.719
[77,     4] loss: 0.715
[78,     4] loss: 0.698
[79,     4] loss: 0.697
[80,     4] loss: 0.706
[81,     4] loss: 0.704
[82,     4] loss: 0.707
[83,     4] loss: 0.697
[84,     4] loss: 0.696
[85,     4] loss: 0.756
[86,     4] loss: 0.734
[87,     4] loss: 0.730
[88,     4] loss: 0.739
[89,     4] loss: 0.725
[90,     4] loss: 0.719
[91,     4] loss: 0.697
[92,     4] loss: 0.749
[93,     4] loss: 0.710
[94,     4] loss: 0.695
[95,     4] loss: 0.703
[96,     4] loss: 0.709
[97,     4] loss: 0.716
[98,     4] loss: 0.690
[99,     4] loss: 0.690
[100,     4] loss: 0.682
[101,     4] loss: 0.675
[102,     4] loss: 0.706
[103,     4] loss: 0.686
[104,     4] loss: 0.683
[105,     4] loss: 0.683
[106,     4] loss: 0.687
[107,     4] loss: 0.699
[108,     4] loss: 0.705
[109,     4] loss: 0.702
[110,     4] loss: 0.678
[111,     4] loss: 0.689
[112,     4] loss: 0.678
[113,     4] loss: 0.669
[114,     4] loss: 0.672
[115,     4] loss: 0.674
[116,     4] loss: 0.679
[117,     4] loss: 0.712
Early stopping applied (best metric=0.2824258506298065)
Finished Training
Total time taken: 64.02045512199402
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.382
[3,     4] loss: 1.378
[4,     4] loss: 1.371
[5,     4] loss: 1.350
[6,     4] loss: 1.331
[7,     4] loss: 1.300
[8,     4] loss: 1.234
[9,     4] loss: 1.191
[10,     4] loss: 1.174
[11,     4] loss: 1.115
[12,     4] loss: 1.129
[13,     4] loss: 1.136
[14,     4] loss: 1.105
[15,     4] loss: 1.060
[16,     4] loss: 1.023
[17,     4] loss: 1.037
[18,     4] loss: 0.972
[19,     4] loss: 0.966
[20,     4] loss: 0.947
[21,     4] loss: 0.880
[22,     4] loss: 0.867
[23,     4] loss: 0.990
[24,     4] loss: 0.864
[25,     4] loss: 0.924
[26,     4] loss: 0.895
[27,     4] loss: 0.870
[28,     4] loss: 0.846
[29,     4] loss: 0.867
[30,     4] loss: 0.869
[31,     4] loss: 0.861
[32,     4] loss: 0.823
[33,     4] loss: 0.823
[34,     4] loss: 0.832
[35,     4] loss: 0.768
[36,     4] loss: 0.781
[37,     4] loss: 0.768
[38,     4] loss: 0.786
[39,     4] loss: 0.815
[40,     4] loss: 0.789
[41,     4] loss: 0.793
[42,     4] loss: 0.857
[43,     4] loss: 0.772
[44,     4] loss: 0.776
[45,     4] loss: 0.776
[46,     4] loss: 0.773
[47,     4] loss: 0.793
[48,     4] loss: 0.767
[49,     4] loss: 0.766
[50,     4] loss: 0.768
[51,     4] loss: 0.787
[52,     4] loss: 0.784
[53,     4] loss: 0.848
[54,     4] loss: 0.836
[55,     4] loss: 0.801
[56,     4] loss: 0.761
[57,     4] loss: 0.757
[58,     4] loss: 0.750
[59,     4] loss: 0.749
[60,     4] loss: 0.778
[61,     4] loss: 0.767
[62,     4] loss: 0.741
[63,     4] loss: 0.740
[64,     4] loss: 0.745
[65,     4] loss: 0.750
[66,     4] loss: 0.737
[67,     4] loss: 0.782
[68,     4] loss: 0.766
[69,     4] loss: 0.774
[70,     4] loss: 0.787
[71,     4] loss: 0.753
[72,     4] loss: 0.738
[73,     4] loss: 0.763
[74,     4] loss: 0.775
[75,     4] loss: 0.731
[76,     4] loss: 0.748
[77,     4] loss: 0.732
[78,     4] loss: 0.763
[79,     4] loss: 0.749
[80,     4] loss: 0.732
[81,     4] loss: 0.728
[82,     4] loss: 0.720
[83,     4] loss: 0.718
[84,     4] loss: 0.716
[85,     4] loss: 0.720
[86,     4] loss: 0.707
[87,     4] loss: 0.727
[88,     4] loss: 0.720
[89,     4] loss: 0.707
[90,     4] loss: 0.720
[91,     4] loss: 0.716
[92,     4] loss: 0.711
[93,     4] loss: 0.728
[94,     4] loss: 0.725
[95,     4] loss: 0.725
[96,     4] loss: 0.712
[97,     4] loss: 0.724
[98,     4] loss: 0.791
[99,     4] loss: 0.767
[100,     4] loss: 0.740
[101,     4] loss: 0.750
[102,     4] loss: 0.744
[103,     4] loss: 0.732
[104,     4] loss: 0.744
[105,     4] loss: 0.723
[106,     4] loss: 0.706
[107,     4] loss: 0.707
[108,     4] loss: 0.701
[109,     4] loss: 0.694
[110,     4] loss: 0.705
[111,     4] loss: 0.693
[112,     4] loss: 0.692
[113,     4] loss: 0.697
[114,     4] loss: 0.693
[115,     4] loss: 0.696
[116,     4] loss: 0.687
[117,     4] loss: 0.691
[118,     4] loss: 0.688
[119,     4] loss: 0.686
[120,     4] loss: 0.692
[121,     4] loss: 0.713
[122,     4] loss: 0.699
[123,     4] loss: 0.706
[124,     4] loss: 0.695
[125,     4] loss: 0.695
[126,     4] loss: 0.696
[127,     4] loss: 0.754
[128,     4] loss: 0.764
[129,     4] loss: 0.776
[130,     4] loss: 0.733
[131,     4] loss: 0.741
[132,     4] loss: 0.745
[133,     4] loss: 0.742
[134,     4] loss: 0.748
[135,     4] loss: 0.736
[136,     4] loss: 0.705
[137,     4] loss: 0.732
[138,     4] loss: 0.718
[139,     4] loss: 0.696
[140,     4] loss: 0.733
[141,     4] loss: 0.715
[142,     4] loss: 0.696
[143,     4] loss: 0.692
[144,     4] loss: 0.694
[145,     4] loss: 0.714
[146,     4] loss: 0.720
[147,     4] loss: 0.737
[148,     4] loss: 0.728
[149,     4] loss: 0.713
[150,     4] loss: 0.718
[151,     4] loss: 0.698
[152,     4] loss: 0.683
[153,     4] loss: 0.685
Early stopping applied (best metric=0.289745032787323)
Finished Training
Total time taken: 84.68773460388184
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.383
[3,     4] loss: 1.388
[4,     4] loss: 1.383
[5,     4] loss: 1.377
[6,     4] loss: 1.368
[7,     4] loss: 1.351
[8,     4] loss: 1.326
[9,     4] loss: 1.298
[10,     4] loss: 1.264
[11,     4] loss: 1.247
[12,     4] loss: 1.235
[13,     4] loss: 1.178
[14,     4] loss: 1.105
[15,     4] loss: 1.063
[16,     4] loss: 1.041
[17,     4] loss: 0.995
[18,     4] loss: 1.036
[19,     4] loss: 0.925
[20,     4] loss: 0.984
[21,     4] loss: 0.875
[22,     4] loss: 0.889
[23,     4] loss: 0.888
[24,     4] loss: 0.942
[25,     4] loss: 0.899
[26,     4] loss: 0.944
[27,     4] loss: 0.917
[28,     4] loss: 0.916
[29,     4] loss: 0.860
[30,     4] loss: 0.880
[31,     4] loss: 0.834
[32,     4] loss: 0.825
[33,     4] loss: 0.869
[34,     4] loss: 0.841
[35,     4] loss: 0.836
[36,     4] loss: 0.798
[37,     4] loss: 0.847
[38,     4] loss: 0.800
[39,     4] loss: 0.826
[40,     4] loss: 0.794
[41,     4] loss: 0.797
[42,     4] loss: 0.815
[43,     4] loss: 0.782
[44,     4] loss: 0.778
[45,     4] loss: 0.798
[46,     4] loss: 0.821
[47,     4] loss: 0.805
[48,     4] loss: 0.800
[49,     4] loss: 0.962
[50,     4] loss: 0.803
[51,     4] loss: 0.883
[52,     4] loss: 0.866
[53,     4] loss: 0.835
[54,     4] loss: 0.822
[55,     4] loss: 0.754
[56,     4] loss: 0.762
[57,     4] loss: 0.770
[58,     4] loss: 0.737
[59,     4] loss: 0.755
[60,     4] loss: 0.738
[61,     4] loss: 0.755
[62,     4] loss: 0.738
[63,     4] loss: 0.745
[64,     4] loss: 0.738
[65,     4] loss: 0.744
[66,     4] loss: 0.740
[67,     4] loss: 0.738
[68,     4] loss: 0.762
[69,     4] loss: 0.764
[70,     4] loss: 0.762
Early stopping applied (best metric=0.2887662947177887)
Finished Training
Total time taken: 35.01415252685547
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.385
[3,     4] loss: 1.378
[4,     4] loss: 1.376
[5,     4] loss: 1.366
[6,     4] loss: 1.342
[7,     4] loss: 1.318
[8,     4] loss: 1.272
[9,     4] loss: 1.239
[10,     4] loss: 1.179
[11,     4] loss: 1.137
[12,     4] loss: 1.119
[13,     4] loss: 1.087
[14,     4] loss: 1.084
[15,     4] loss: 1.006
[16,     4] loss: 1.037
[17,     4] loss: 1.019
[18,     4] loss: 0.932
[19,     4] loss: 0.953
[20,     4] loss: 0.955
[21,     4] loss: 0.925
[22,     4] loss: 0.870
[23,     4] loss: 0.889
[24,     4] loss: 0.907
[25,     4] loss: 0.840
[26,     4] loss: 0.867
[27,     4] loss: 0.906
[28,     4] loss: 0.840
[29,     4] loss: 0.836
[30,     4] loss: 0.833
[31,     4] loss: 0.810
[32,     4] loss: 0.802
[33,     4] loss: 0.860
[34,     4] loss: 0.924
[35,     4] loss: 0.842
[36,     4] loss: 0.797
[37,     4] loss: 0.826
[38,     4] loss: 0.791
[39,     4] loss: 0.791
[40,     4] loss: 0.844
[41,     4] loss: 0.804
[42,     4] loss: 0.841
[43,     4] loss: 0.817
[44,     4] loss: 0.793
[45,     4] loss: 0.769
[46,     4] loss: 0.766
[47,     4] loss: 0.763
[48,     4] loss: 0.767
[49,     4] loss: 0.787
[50,     4] loss: 0.767
[51,     4] loss: 0.748
[52,     4] loss: 0.791
[53,     4] loss: 0.782
[54,     4] loss: 0.812
[55,     4] loss: 0.791
[56,     4] loss: 0.754
[57,     4] loss: 0.750
Early stopping applied (best metric=0.5047953128814697)
Finished Training
Total time taken: 29.84098196029663
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.391
[2,     4] loss: 1.383
[3,     4] loss: 1.386
[4,     4] loss: 1.384
[5,     4] loss: 1.377
[6,     4] loss: 1.373
[7,     4] loss: 1.362
[8,     4] loss: 1.337
[9,     4] loss: 1.319
[10,     4] loss: 1.298
[11,     4] loss: 1.250
[12,     4] loss: 1.227
[13,     4] loss: 1.116
[14,     4] loss: 1.073
[15,     4] loss: 1.055
[16,     4] loss: 1.057
[17,     4] loss: 0.984
[18,     4] loss: 0.985
[19,     4] loss: 0.994
[20,     4] loss: 0.906
[21,     4] loss: 1.005
[22,     4] loss: 0.925
[23,     4] loss: 0.958
[24,     4] loss: 1.002
[25,     4] loss: 0.930
[26,     4] loss: 0.919
[27,     4] loss: 0.852
[28,     4] loss: 0.867
[29,     4] loss: 0.876
[30,     4] loss: 0.853
[31,     4] loss: 0.795
[32,     4] loss: 0.816
[33,     4] loss: 0.823
[34,     4] loss: 0.813
[35,     4] loss: 0.766
[36,     4] loss: 0.799
[37,     4] loss: 0.797
[38,     4] loss: 0.785
[39,     4] loss: 0.828
[40,     4] loss: 0.849
[41,     4] loss: 0.780
[42,     4] loss: 0.793
[43,     4] loss: 0.808
[44,     4] loss: 0.813
[45,     4] loss: 0.773
[46,     4] loss: 0.772
[47,     4] loss: 0.800
[48,     4] loss: 0.793
[49,     4] loss: 0.758
[50,     4] loss: 0.759
[51,     4] loss: 0.761
[52,     4] loss: 0.738
[53,     4] loss: 0.745
[54,     4] loss: 0.741
[55,     4] loss: 0.778
[56,     4] loss: 0.741
[57,     4] loss: 0.785
[58,     4] loss: 0.745
[59,     4] loss: 0.745
[60,     4] loss: 0.760
[61,     4] loss: 0.795
[62,     4] loss: 0.779
Early stopping applied (best metric=0.35537439584732056)
Finished Training
Total time taken: 34.44872999191284
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.387
[3,     4] loss: 1.385
[4,     4] loss: 1.382
[5,     4] loss: 1.370
[6,     4] loss: 1.361
[7,     4] loss: 1.336
[8,     4] loss: 1.308
[9,     4] loss: 1.245
[10,     4] loss: 1.190
[11,     4] loss: 1.136
[12,     4] loss: 1.093
[13,     4] loss: 1.044
[14,     4] loss: 0.978
[15,     4] loss: 1.001
[16,     4] loss: 0.962
[17,     4] loss: 0.955
[18,     4] loss: 0.880
[19,     4] loss: 0.881
[20,     4] loss: 0.886
[21,     4] loss: 0.919
[22,     4] loss: 0.913
[23,     4] loss: 0.928
[24,     4] loss: 0.914
[25,     4] loss: 0.905
[26,     4] loss: 0.882
[27,     4] loss: 0.846
[28,     4] loss: 0.870
[29,     4] loss: 0.848
[30,     4] loss: 0.813
[31,     4] loss: 0.810
[32,     4] loss: 0.805
[33,     4] loss: 0.801
[34,     4] loss: 0.782
[35,     4] loss: 0.773
[36,     4] loss: 0.780
[37,     4] loss: 0.769
[38,     4] loss: 0.748
[39,     4] loss: 0.758
[40,     4] loss: 0.796
[41,     4] loss: 0.858
[42,     4] loss: 0.866
[43,     4] loss: 0.818
[44,     4] loss: 0.827
[45,     4] loss: 0.853
[46,     4] loss: 0.789
[47,     4] loss: 0.766
[48,     4] loss: 0.767
[49,     4] loss: 0.751
[50,     4] loss: 0.759
[51,     4] loss: 0.752
[52,     4] loss: 0.734
[53,     4] loss: 0.746
[54,     4] loss: 0.759
[55,     4] loss: 0.731
[56,     4] loss: 0.773
[57,     4] loss: 0.761
[58,     4] loss: 0.746
Early stopping applied (best metric=0.45576366782188416)
Finished Training
Total time taken: 33.17346453666687
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.380
[3,     4] loss: 1.378
[4,     4] loss: 1.381
[5,     4] loss: 1.388
[6,     4] loss: 1.377
[7,     4] loss: 1.380
[8,     4] loss: 1.356
[9,     4] loss: 1.339
[10,     4] loss: 1.306
[11,     4] loss: 1.247
[12,     4] loss: 1.198
[13,     4] loss: 1.159
[14,     4] loss: 1.114
[15,     4] loss: 1.097
[16,     4] loss: 1.045
[17,     4] loss: 0.984
[18,     4] loss: 0.997
[19,     4] loss: 0.929
[20,     4] loss: 0.895
[21,     4] loss: 0.855
[22,     4] loss: 0.892
[23,     4] loss: 0.861
[24,     4] loss: 0.957
[25,     4] loss: 0.946
[26,     4] loss: 0.863
[27,     4] loss: 0.824
[28,     4] loss: 0.868
[29,     4] loss: 0.832
[30,     4] loss: 0.791
[31,     4] loss: 0.791
[32,     4] loss: 0.798
[33,     4] loss: 0.781
[34,     4] loss: 0.796
[35,     4] loss: 0.777
[36,     4] loss: 0.752
[37,     4] loss: 0.773
[38,     4] loss: 0.798
[39,     4] loss: 0.842
[40,     4] loss: 0.848
[41,     4] loss: 0.809
[42,     4] loss: 0.823
[43,     4] loss: 0.803
[44,     4] loss: 0.826
[45,     4] loss: 0.785
[46,     4] loss: 0.754
[47,     4] loss: 0.748
[48,     4] loss: 0.764
[49,     4] loss: 0.742
[50,     4] loss: 0.732
[51,     4] loss: 0.736
[52,     4] loss: 0.748
[53,     4] loss: 0.737
[54,     4] loss: 0.753
[55,     4] loss: 0.756
[56,     4] loss: 0.745
[57,     4] loss: 0.740
[58,     4] loss: 0.775
[59,     4] loss: 0.770
[60,     4] loss: 0.777
[61,     4] loss: 0.794
[62,     4] loss: 0.828
[63,     4] loss: 0.807
Early stopping applied (best metric=0.43265825510025024)
Finished Training
Total time taken: 34.36208891868591
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.378
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.374
[5,     4] loss: 1.377
[6,     4] loss: 1.365
[7,     4] loss: 1.348
[8,     4] loss: 1.323
[9,     4] loss: 1.317
[10,     4] loss: 1.237
[11,     4] loss: 1.218
[12,     4] loss: 1.189
[13,     4] loss: 1.159
[14,     4] loss: 1.114
[15,     4] loss: 1.098
[16,     4] loss: 1.045
[17,     4] loss: 1.002
[18,     4] loss: 0.982
[19,     4] loss: 1.027
[20,     4] loss: 1.137
[21,     4] loss: 1.001
[22,     4] loss: 1.039
[23,     4] loss: 0.997
[24,     4] loss: 0.968
[25,     4] loss: 0.996
[26,     4] loss: 0.929
[27,     4] loss: 0.955
[28,     4] loss: 0.888
[29,     4] loss: 0.841
[30,     4] loss: 0.835
[31,     4] loss: 0.813
[32,     4] loss: 0.812
[33,     4] loss: 0.865
[34,     4] loss: 0.818
[35,     4] loss: 0.884
[36,     4] loss: 0.882
[37,     4] loss: 0.832
[38,     4] loss: 0.835
[39,     4] loss: 0.817
[40,     4] loss: 0.775
[41,     4] loss: 0.796
[42,     4] loss: 0.803
[43,     4] loss: 0.823
[44,     4] loss: 0.774
[45,     4] loss: 0.819
[46,     4] loss: 0.784
[47,     4] loss: 0.739
[48,     4] loss: 0.742
[49,     4] loss: 0.748
[50,     4] loss: 0.732
[51,     4] loss: 0.757
[52,     4] loss: 0.753
[53,     4] loss: 0.764
[54,     4] loss: 0.789
[55,     4] loss: 0.767
[56,     4] loss: 0.743
[57,     4] loss: 0.765
[58,     4] loss: 0.779
[59,     4] loss: 0.761
[60,     4] loss: 0.766
[61,     4] loss: 0.733
[62,     4] loss: 0.753
[63,     4] loss: 0.737
[64,     4] loss: 0.729
[65,     4] loss: 0.725
[66,     4] loss: 0.725
[67,     4] loss: 0.750
[68,     4] loss: 0.778
[69,     4] loss: 0.766
[70,     4] loss: 0.763
[71,     4] loss: 0.771
[72,     4] loss: 0.768
[73,     4] loss: 0.747
[74,     4] loss: 0.800
[75,     4] loss: 0.779
[76,     4] loss: 0.754
[77,     4] loss: 0.747
[78,     4] loss: 0.760
[79,     4] loss: 0.766
[80,     4] loss: 0.773
[81,     4] loss: 0.771
[82,     4] loss: 0.733
[83,     4] loss: 0.743
[84,     4] loss: 0.749
[85,     4] loss: 0.746
[86,     4] loss: 0.743
[87,     4] loss: 0.752
[88,     4] loss: 0.751
[89,     4] loss: 0.742
[90,     4] loss: 0.759
[91,     4] loss: 0.752
[92,     4] loss: 0.738
[93,     4] loss: 0.719
[94,     4] loss: 0.737
[95,     4] loss: 0.737
[96,     4] loss: 0.771
[97,     4] loss: 0.739
[98,     4] loss: 0.761
[99,     4] loss: 0.761
[100,     4] loss: 0.769
[101,     4] loss: 0.801
[102,     4] loss: 0.779
[103,     4] loss: 0.760
[104,     4] loss: 0.738
[105,     4] loss: 0.757
[106,     4] loss: 0.765
Early stopping applied (best metric=0.24840979278087616)
Finished Training
Total time taken: 58.524378061294556
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.384
[3,     4] loss: 1.382
[4,     4] loss: 1.382
[5,     4] loss: 1.373
[6,     4] loss: 1.355
[7,     4] loss: 1.342
[8,     4] loss: 1.293
[9,     4] loss: 1.263
[10,     4] loss: 1.201
[11,     4] loss: 1.154
[12,     4] loss: 1.137
[13,     4] loss: 1.059
[14,     4] loss: 0.987
[15,     4] loss: 1.076
[16,     4] loss: 1.001
[17,     4] loss: 1.036
[18,     4] loss: 0.985
[19,     4] loss: 0.940
[20,     4] loss: 0.946
[21,     4] loss: 0.925
[22,     4] loss: 0.907
[23,     4] loss: 0.903
[24,     4] loss: 0.923
[25,     4] loss: 0.932
[26,     4] loss: 0.849
[27,     4] loss: 0.834
[28,     4] loss: 0.798
[29,     4] loss: 0.942
[30,     4] loss: 0.856
[31,     4] loss: 0.934
[32,     4] loss: 0.841
[33,     4] loss: 0.875
[34,     4] loss: 0.907
[35,     4] loss: 0.870
[36,     4] loss: 0.895
[37,     4] loss: 0.839
[38,     4] loss: 0.810
[39,     4] loss: 0.792
[40,     4] loss: 0.818
[41,     4] loss: 0.765
[42,     4] loss: 0.794
[43,     4] loss: 0.774
[44,     4] loss: 0.779
[45,     4] loss: 0.810
[46,     4] loss: 0.781
[47,     4] loss: 0.881
[48,     4] loss: 0.905
[49,     4] loss: 0.844
[50,     4] loss: 0.813
[51,     4] loss: 0.811
[52,     4] loss: 0.765
[53,     4] loss: 0.775
[54,     4] loss: 0.748
[55,     4] loss: 0.798
[56,     4] loss: 0.753
[57,     4] loss: 0.771
[58,     4] loss: 0.739
[59,     4] loss: 0.757
[60,     4] loss: 0.785
Early stopping applied (best metric=0.43954506516456604)
Finished Training
Total time taken: 33.855100870132446
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.397
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.375
[5,     4] loss: 1.358
[6,     4] loss: 1.325
[7,     4] loss: 1.293
[8,     4] loss: 1.237
[9,     4] loss: 1.221
[10,     4] loss: 1.136
[11,     4] loss: 1.103
[12,     4] loss: 1.004
[13,     4] loss: 0.994
[14,     4] loss: 1.056
[15,     4] loss: 0.981
[16,     4] loss: 0.913
[17,     4] loss: 0.950
[18,     4] loss: 0.861
[19,     4] loss: 0.913
[20,     4] loss: 0.920
[21,     4] loss: 0.921
[22,     4] loss: 0.876
[23,     4] loss: 0.837
[24,     4] loss: 0.861
[25,     4] loss: 0.816
[26,     4] loss: 0.822
[27,     4] loss: 0.812
[28,     4] loss: 0.843
[29,     4] loss: 0.845
[30,     4] loss: 0.794
[31,     4] loss: 0.875
[32,     4] loss: 0.899
[33,     4] loss: 0.840
[34,     4] loss: 0.861
[35,     4] loss: 0.856
[36,     4] loss: 0.811
[37,     4] loss: 0.776
[38,     4] loss: 0.779
[39,     4] loss: 0.769
[40,     4] loss: 0.778
[41,     4] loss: 0.854
[42,     4] loss: 0.759
[43,     4] loss: 0.814
[44,     4] loss: 0.763
[45,     4] loss: 0.787
[46,     4] loss: 0.761
[47,     4] loss: 0.786
[48,     4] loss: 0.758
[49,     4] loss: 0.731
[50,     4] loss: 0.765
[51,     4] loss: 0.748
[52,     4] loss: 0.748
[53,     4] loss: 0.784
[54,     4] loss: 0.742
[55,     4] loss: 0.746
Early stopping applied (best metric=0.5420199036598206)
Finished Training
Total time taken: 31.127467155456543
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.385
[3,     4] loss: 1.383
[4,     4] loss: 1.375
[5,     4] loss: 1.366
[6,     4] loss: 1.345
[7,     4] loss: 1.327
[8,     4] loss: 1.274
[9,     4] loss: 1.233
[10,     4] loss: 1.179
[11,     4] loss: 1.115
[12,     4] loss: 1.098
[13,     4] loss: 1.015
[14,     4] loss: 0.956
[15,     4] loss: 0.942
[16,     4] loss: 0.912
[17,     4] loss: 0.915
[18,     4] loss: 0.953
[19,     4] loss: 0.911
[20,     4] loss: 0.872
[21,     4] loss: 0.950
[22,     4] loss: 0.882
[23,     4] loss: 0.882
[24,     4] loss: 0.877
[25,     4] loss: 0.876
[26,     4] loss: 0.881
[27,     4] loss: 0.850
[28,     4] loss: 0.833
[29,     4] loss: 0.854
[30,     4] loss: 0.847
[31,     4] loss: 0.779
[32,     4] loss: 0.785
[33,     4] loss: 0.825
[34,     4] loss: 0.827
[35,     4] loss: 0.808
[36,     4] loss: 0.773
[37,     4] loss: 0.781
[38,     4] loss: 0.774
[39,     4] loss: 0.748
[40,     4] loss: 0.773
[41,     4] loss: 0.744
[42,     4] loss: 0.779
[43,     4] loss: 0.768
[44,     4] loss: 0.797
[45,     4] loss: 0.765
[46,     4] loss: 0.799
[47,     4] loss: 0.783
[48,     4] loss: 0.823
[49,     4] loss: 0.795
[50,     4] loss: 0.773
[51,     4] loss: 0.832
[52,     4] loss: 0.770
[53,     4] loss: 0.752
[54,     4] loss: 0.785
[55,     4] loss: 0.769
[56,     4] loss: 0.723
Early stopping applied (best metric=0.534968376159668)
Finished Training
Total time taken: 29.062944412231445
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.389
[3,     4] loss: 1.384
[4,     4] loss: 1.385
[5,     4] loss: 1.380
[6,     4] loss: 1.370
[7,     4] loss: 1.360
[8,     4] loss: 1.352
[9,     4] loss: 1.316
[10,     4] loss: 1.268
[11,     4] loss: 1.211
[12,     4] loss: 1.129
[13,     4] loss: 1.093
[14,     4] loss: 1.094
[15,     4] loss: 0.992
[16,     4] loss: 0.920
[17,     4] loss: 0.960
[18,     4] loss: 0.954
[19,     4] loss: 1.133
[20,     4] loss: 0.907
[21,     4] loss: 0.931
[22,     4] loss: 0.896
[23,     4] loss: 0.930
[24,     4] loss: 0.879
[25,     4] loss: 0.883
[26,     4] loss: 0.874
[27,     4] loss: 0.855
[28,     4] loss: 0.851
[29,     4] loss: 0.832
[30,     4] loss: 0.830
[31,     4] loss: 0.835
[32,     4] loss: 0.798
[33,     4] loss: 0.780
[34,     4] loss: 0.820
[35,     4] loss: 0.816
[36,     4] loss: 0.804
[37,     4] loss: 0.789
[38,     4] loss: 0.922
[39,     4] loss: 0.904
[40,     4] loss: 0.855
[41,     4] loss: 0.850
[42,     4] loss: 0.812
[43,     4] loss: 0.802
[44,     4] loss: 0.785
[45,     4] loss: 0.803
[46,     4] loss: 0.774
[47,     4] loss: 0.769
[48,     4] loss: 0.767
[49,     4] loss: 0.745
[50,     4] loss: 0.783
[51,     4] loss: 0.767
[52,     4] loss: 0.760
[53,     4] loss: 0.765
[54,     4] loss: 0.738
[55,     4] loss: 0.738
[56,     4] loss: 0.742
[57,     4] loss: 0.733
[58,     4] loss: 0.733
[59,     4] loss: 0.740
[60,     4] loss: 0.730
Early stopping applied (best metric=0.4872184693813324)
Finished Training
Total time taken: 32.305530309677124
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.384
[3,     4] loss: 1.390
[4,     4] loss: 1.386
[5,     4] loss: 1.386
[6,     4] loss: 1.382
[7,     4] loss: 1.382
[8,     4] loss: 1.375
[9,     4] loss: 1.370
[10,     4] loss: 1.343
[11,     4] loss: 1.310
[12,     4] loss: 1.266
[13,     4] loss: 1.244
[14,     4] loss: 1.120
[15,     4] loss: 1.105
[16,     4] loss: 0.993
[17,     4] loss: 1.022
[18,     4] loss: 1.022
[19,     4] loss: 0.927
[20,     4] loss: 0.938
[21,     4] loss: 0.893
[22,     4] loss: 0.881
[23,     4] loss: 0.907
[24,     4] loss: 0.874
[25,     4] loss: 0.869
[26,     4] loss: 0.802
[27,     4] loss: 0.820
[28,     4] loss: 0.801
[29,     4] loss: 0.805
[30,     4] loss: 0.792
[31,     4] loss: 0.787
[32,     4] loss: 0.839
[33,     4] loss: 0.786
[34,     4] loss: 0.822
[35,     4] loss: 0.797
[36,     4] loss: 0.794
[37,     4] loss: 0.818
[38,     4] loss: 0.809
[39,     4] loss: 0.788
[40,     4] loss: 0.789
[41,     4] loss: 0.769
[42,     4] loss: 0.754
[43,     4] loss: 0.769
[44,     4] loss: 0.817
[45,     4] loss: 0.782
[46,     4] loss: 0.761
[47,     4] loss: 0.811
[48,     4] loss: 0.827
[49,     4] loss: 0.831
[50,     4] loss: 0.874
[51,     4] loss: 0.797
[52,     4] loss: 0.769
[53,     4] loss: 0.788
[54,     4] loss: 0.807
[55,     4] loss: 0.790
[56,     4] loss: 0.762
[57,     4] loss: 0.782
[58,     4] loss: 0.728
[59,     4] loss: 0.753
[60,     4] loss: 0.748
[61,     4] loss: 0.740
[62,     4] loss: 0.763
Early stopping applied (best metric=0.46579647064208984)
Finished Training
Total time taken: 34.947086334228516
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.384
[3,     4] loss: 1.384
[4,     4] loss: 1.381
[5,     4] loss: 1.372
[6,     4] loss: 1.370
[7,     4] loss: 1.351
[8,     4] loss: 1.307
[9,     4] loss: 1.264
[10,     4] loss: 1.224
[11,     4] loss: 1.211
[12,     4] loss: 1.175
[13,     4] loss: 1.093
[14,     4] loss: 1.013
[15,     4] loss: 1.123
[16,     4] loss: 0.988
[17,     4] loss: 0.957
[18,     4] loss: 0.992
[19,     4] loss: 1.001
[20,     4] loss: 0.972
[21,     4] loss: 0.997
[22,     4] loss: 1.064
[23,     4] loss: 0.968
[24,     4] loss: 0.987
[25,     4] loss: 0.877
[26,     4] loss: 0.889
[27,     4] loss: 0.877
[28,     4] loss: 0.843
[29,     4] loss: 0.872
[30,     4] loss: 0.838
[31,     4] loss: 0.835
[32,     4] loss: 0.843
[33,     4] loss: 0.882
[34,     4] loss: 0.835
[35,     4] loss: 0.872
[36,     4] loss: 0.851
[37,     4] loss: 0.845
[38,     4] loss: 0.794
[39,     4] loss: 0.869
[40,     4] loss: 0.824
[41,     4] loss: 0.832
[42,     4] loss: 0.819
[43,     4] loss: 0.845
[44,     4] loss: 0.843
[45,     4] loss: 0.814
[46,     4] loss: 0.856
[47,     4] loss: 0.833
[48,     4] loss: 0.781
[49,     4] loss: 0.763
[50,     4] loss: 0.772
[51,     4] loss: 0.769
[52,     4] loss: 0.780
[53,     4] loss: 0.772
[54,     4] loss: 0.795
[55,     4] loss: 0.801
[56,     4] loss: 0.784
[57,     4] loss: 0.795
[58,     4] loss: 0.867
[59,     4] loss: 0.867
[60,     4] loss: 0.875
Early stopping applied (best metric=0.47305113077163696)
Finished Training
Total time taken: 33.544597864151
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.396
[2,     4] loss: 1.388
[3,     4] loss: 1.383
[4,     4] loss: 1.375
[5,     4] loss: 1.361
[6,     4] loss: 1.334
[7,     4] loss: 1.291
[8,     4] loss: 1.271
[9,     4] loss: 1.224
[10,     4] loss: 1.172
[11,     4] loss: 1.115
[12,     4] loss: 1.082
[13,     4] loss: 1.052
[14,     4] loss: 0.958
[15,     4] loss: 1.006
[16,     4] loss: 0.974
[17,     4] loss: 0.990
[18,     4] loss: 1.005
[19,     4] loss: 0.936
[20,     4] loss: 0.935
[21,     4] loss: 0.899
[22,     4] loss: 0.903
[23,     4] loss: 0.890
[24,     4] loss: 0.900
[25,     4] loss: 0.881
[26,     4] loss: 0.862
[27,     4] loss: 0.847
[28,     4] loss: 0.832
[29,     4] loss: 0.845
[30,     4] loss: 0.862
[31,     4] loss: 0.812
[32,     4] loss: 0.807
[33,     4] loss: 0.837
[34,     4] loss: 0.828
[35,     4] loss: 0.830
[36,     4] loss: 0.820
[37,     4] loss: 0.820
[38,     4] loss: 0.773
[39,     4] loss: 0.766
[40,     4] loss: 0.758
[41,     4] loss: 0.780
[42,     4] loss: 0.790
[43,     4] loss: 0.752
[44,     4] loss: 0.735
[45,     4] loss: 0.764
[46,     4] loss: 0.785
[47,     4] loss: 0.795
[48,     4] loss: 0.759
[49,     4] loss: 0.773
[50,     4] loss: 0.784
[51,     4] loss: 0.760
[52,     4] loss: 0.775
[53,     4] loss: 0.754
[54,     4] loss: 0.745
[55,     4] loss: 0.733
[56,     4] loss: 0.778
[57,     4] loss: 0.763
Early stopping applied (best metric=0.496711790561676)
Finished Training
Total time taken: 31.99845814704895
{'Hydroxylation-K Validation Accuracy': 0.7629728132387706, 'Hydroxylation-K Validation Sensitivity': 0.6992592592592592, 'Hydroxylation-K Validation Specificity': 0.7789473684210526, 'Hydroxylation-K Validation Precision': 0.46664269511018736, 'Hydroxylation-K AUC ROC': 0.8050682261208577, 'Hydroxylation-K AUC PR': 0.5623262244650262, 'Hydroxylation-K MCC': 0.42473902475801, 'Hydroxylation-K F1': 0.5508553069238517, 'Validation Loss (Hydroxylation-K)': 0.41981665392716727, 'Methylation-K Validation Accuracy': 0.8170232060920101, 'Methylation-K Validation Sensitivity': 0.14105706494936715, 'Methylation-K Validation Specificity': 0.8903321571699703, 'Methylation-K Validation Precision': 0.1261732553962482, 'Methylation-K AUC ROC': 0.5440744692180941, 'Methylation-K AUC PR': 0.11461498574933711, 'Methylation-K MCC': 0.031167230839945326, 'Methylation-K F1': 0.12854221717829978, 'Validation Loss (Methylation-K)': 0.8175218125184377, 'Validation Loss (total)': 1.2373384714126587, 'TimeToTrain': 40.06087805430094}
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 4,
 'current_CV_Repeat': 3,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017841583190379884,
 'learning_rate_Hydroxylation-K': 0.0045318731186429415,
 'learning_rate_Methylation-K': 0.009975505960802539,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2670658060930245,
 'loss_weight_Methylation-K': 0.5875504744994449,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3900074209,
 'sample_weights': [0.44813255748284275, 0.24303600171217243],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.980948743255886,
 'weight_decay_Hydroxylation-K': 3.225356946684446,
 'weight_decay_Methylation-K': 9.309828089038938}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.377
[2,     4] loss: 1.389
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0023230009329544884,
 'learning_rate_Hydroxylation-K': 0.006090646663986796,
 'learning_rate_Methylation-K': 0.00929424963999749,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3899769297098512,
 'loss_weight_Methylation-K': 0.952195885313967,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 992965184,
 'sample_weights': [0.2670658060930245, 0.5875504744994449],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.732909620689686,
 'weight_decay_Hydroxylation-K': 4.709465997778715,
 'weight_decay_Methylation-K': 6.739601119628612}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.386
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.002482465226769927,
 'learning_rate_Hydroxylation-K': 0.0018584974825484228,
 'learning_rate_Methylation-K': 0.0013717315950487392,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.24548354756300106,
 'loss_weight_Methylation-K': 0.13064930665472343,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4253847575,
 'sample_weights': [0.3899769297098512, 0.952195885313967],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.803219562995461,
 'weight_decay_Hydroxylation-K': 8.837367853187109,
 'weight_decay_Methylation-K': 6.44137955050742}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.390
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0017817016478963526,
 'learning_rate_Hydroxylation-K': 0.005243540771603512,
 'learning_rate_Methylation-K': 0.005110724074434309,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.31589002347677636,
 'loss_weight_Methylation-K': 0.16776674717075313,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 384457097,
 'sample_weights': [0.24548354756300106, 0.13064930665472343],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.651001555768106,
 'weight_decay_Hydroxylation-K': 8.472081155968498,
 'weight_decay_Methylation-K': 7.989353869875763}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.387
[3,     4] loss: 1.379
[4,     4] loss: 1.371
[5,     4] loss: 1.358
[6,     4] loss: 1.328
[7,     4] loss: 1.285
[8,     4] loss: 1.243
[9,     4] loss: 1.184
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0009489723069252437,
 'learning_rate_Hydroxylation-K': 0.008363508201725246,
 'learning_rate_Methylation-K': 0.003250642273360054,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5541492151230585,
 'loss_weight_Methylation-K': 0.47769546561819637,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3039509663,
 'sample_weights': [0.31589002347677636, 0.16776674717075313],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.8228173245193435,
 'weight_decay_Hydroxylation-K': 8.437326714148366,
 'weight_decay_Methylation-K': 4.743001250243087}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.385
[3,     4] loss: 1.382
[4,     4] loss: 1.384
[5,     4] loss: 1.383
[6,     4] loss: 1.377
[7,     4] loss: 1.365
[8,     4] loss: 1.360
[9,     4] loss: 1.334
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.001542128528571999,
 'learning_rate_Hydroxylation-K': 0.007196368607202911,
 'learning_rate_Methylation-K': 0.00668206380208162,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.55403638684721,
 'loss_weight_Methylation-K': 0.5717086641669052,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2389978673,
 'sample_weights': [0.5541492151230585, 0.47769546561819637],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.909685506289923,
 'weight_decay_Hydroxylation-K': 5.897714601222252,
 'weight_decay_Methylation-K': 8.9092231703097}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.396
[2,     4] loss: 1.392
[3,     4] loss: 1.379
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0024749933620687717,
 'learning_rate_Hydroxylation-K': 0.0032710144365983335,
 'learning_rate_Methylation-K': 0.0029433103941934775,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.48320276187978045,
 'loss_weight_Methylation-K': 0.2978596270857174,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1629407310,
 'sample_weights': [0.55403638684721, 0.5717086641669052],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.203205783334374,
 'weight_decay_Hydroxylation-K': 6.482186473383662,
 'weight_decay_Methylation-K': 8.44694843623125}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.400
[2,     4] loss: 1.389
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0012884919272094432,
 'learning_rate_Hydroxylation-K': 0.008587147136180305,
 'learning_rate_Methylation-K': 0.004062578968191537,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.5829594163702624,
 'loss_weight_Methylation-K': 0.22604632351194398,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1543601690,
 'sample_weights': [0.48320276187978045, 0.2978596270857174],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.0285148595201274,
 'weight_decay_Hydroxylation-K': 4.9014381712126385,
 'weight_decay_Methylation-K': 3.00082266703589}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.386
[3,     4] loss: 1.385
[4,     4] loss: 1.385
[5,     4] loss: 1.382
[6,     4] loss: 1.378
[7,     4] loss: 1.376
[8,     4] loss: 1.361
[9,     4] loss: 1.356
[10,     4] loss: 1.325
[11,     4] loss: 1.294
[12,     4] loss: 1.249
[13,     4] loss: 1.178
[14,     4] loss: 1.180
[15,     4] loss: 1.057
[16,     4] loss: 1.082
[17,     4] loss: 1.045
[18,     4] loss: 1.001
[19,     4] loss: 1.065
[20,     4] loss: 0.982
[21,     4] loss: 0.935
[22,     4] loss: 0.929
[23,     4] loss: 0.897
[24,     4] loss: 0.891
[25,     4] loss: 0.895
[26,     4] loss: 0.858
[27,     4] loss: 0.860
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0041252711648316984,
 'learning_rate_Hydroxylation-K': 0.007641235110032976,
 'learning_rate_Methylation-K': 0.003912358597100741,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.39983339649041494,
 'loss_weight_Methylation-K': 0.687952706095144,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 4061783734,
 'sample_weights': [0.5829594163702624, 0.22604632351194398],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.555692520522866,
 'weight_decay_Hydroxylation-K': 6.968176149732718,
 'weight_decay_Methylation-K': 0.497872006940586}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.401
[2,     4] loss: 1.390
[3,     4] loss: 1.382
[4,     4] loss: 1.381
[5,     4] loss: 1.383
[6,     4] loss: 1.377
[7,     4] loss: 1.358
[8,     4] loss: 1.321
[9,     4] loss: 1.214
[10,     4] loss: 1.109
[11,     4] loss: 1.114
[12,     4] loss: 1.078
[13,     4] loss: 1.058
[14,     4] loss: 1.025
[15,     4] loss: 1.028
[16,     4] loss: 1.026
[17,     4] loss: 0.980
[18,     4] loss: 0.954
[19,     4] loss: 0.935
[20,     4] loss: 0.922
[21,     4] loss: 0.898
[22,     4] loss: 0.825
[23,     4] loss: 0.873
[24,     4] loss: 0.914
[25,     4] loss: 0.847
[26,     4] loss: 0.899
[27,     4] loss: 0.965
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.009503503693068405,
 'learning_rate_Hydroxylation-K': 0.0027137514863901546,
 'learning_rate_Methylation-K': 0.0033108121718986496,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.2614245517369734,
 'loss_weight_Methylation-K': 0.09408248121342472,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3377030107,
 'sample_weights': [0.39983339649041494, 0.687952706095144],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 1.5653556440638132,
 'weight_decay_Hydroxylation-K': 9.603833389295264,
 'weight_decay_Methylation-K': 2.339242958975642}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.382
[2,     4] loss: 1.390
[3,     4] loss: 1.388
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00792213875410498,
 'learning_rate_Hydroxylation-K': 0.0036078988599102134,
 'learning_rate_Methylation-K': 0.000700522867352762,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.40246206304316823,
 'loss_weight_Methylation-K': 0.7626191697514508,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1660610600,
 'sample_weights': [0.2614245517369734, 0.09408248121342472],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.230444444929136,
 'weight_decay_Hydroxylation-K': 9.548883778674767,
 'weight_decay_Methylation-K': 1.466115768110261}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.388
[3,     4] loss: 1.386
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00033588088549242276,
 'learning_rate_Hydroxylation-K': 0.0006424817822394111,
 'learning_rate_Methylation-K': 0.0017028838912370918,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4810909254870035,
 'loss_weight_Methylation-K': 0.31873895884533154,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1532990995,
 'sample_weights': [0.40246206304316823, 0.7626191697514508],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 6.869310970220595,
 'weight_decay_Hydroxylation-K': 7.650874794998801,
 'weight_decay_Methylation-K': 8.923738007951352}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.398
[2,     4] loss: 1.388
[3,     4] loss: 1.385
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00026870107792943665,
 'learning_rate_Hydroxylation-K': 0.00040973706287937854,
 'learning_rate_Methylation-K': 0.002683342022002764,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3048646200552102,
 'loss_weight_Methylation-K': 0.5069830746714191,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1318429208,
 'sample_weights': [0.4810909254870035, 0.31873895884533154],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 0.9197281417442844,
 'weight_decay_Hydroxylation-K': 7.3532095926042915,
 'weight_decay_Methylation-K': 4.328102305707619}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.389
[3,     4] loss: 1.384
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005709685050640706,
 'learning_rate_Hydroxylation-K': 0.00219754007298588,
 'learning_rate_Methylation-K': 0.0002272440322409955,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.22486982234588132,
 'loss_weight_Methylation-K': 0.19186799680839328,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3944847132,
 'sample_weights': [0.3048646200552102, 0.5069830746714191],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.421530144918895,
 'weight_decay_Hydroxylation-K': 5.736084058522424,
 'weight_decay_Methylation-K': 3.493389398090477}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.392
[2,     4] loss: 1.381
[3,     4] loss: 1.383
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0005407881009744711,
 'learning_rate_Hydroxylation-K': 0.0010815668072248477,
 'learning_rate_Methylation-K': 0.0023540946853030063,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.44152435969824344,
 'loss_weight_Methylation-K': 0.20451975223789004,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 1561439921,
 'sample_weights': [0.22486982234588132, 0.19186799680839328],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 3.5311318806251704,
 'weight_decay_Hydroxylation-K': 6.035369773096787,
 'weight_decay_Methylation-K': 6.878297916821063}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.384
[3,     4] loss: 1.387
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 3.0273298071932953e-05,
 'learning_rate_Hydroxylation-K': 0.007799658968577782,
 'learning_rate_Methylation-K': 0.008649281409802236,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.08599152699810426,
 'loss_weight_Methylation-K': 0.9601916594188192,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2628355216,
 'sample_weights': [0.44152435969824344, 0.20451975223789004],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 4.318145474805162,
 'weight_decay_Hydroxylation-K': 8.042039493918372,
 'weight_decay_Methylation-K': 8.68515024769612}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.394
[3,     4] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.005365745057989933,
 'learning_rate_Hydroxylation-K': 0.004827220333410147,
 'learning_rate_Methylation-K': 0.00605992475881361,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.9010073318718026,
 'loss_weight_Methylation-K': 0.11842542673289141,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 3351716979,
 'sample_weights': [0.08599152699810426, 0.9601916594188192],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 2.2308859637904765,
 'weight_decay_Hydroxylation-K': 2.589064300955129,
 'weight_decay_Methylation-K': 9.886845799316758}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.388
[3,     4] loss: 1.391
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.00025304031915120585,
 'learning_rate_Hydroxylation-K': 0.0034557669746573105,
 'learning_rate_Methylation-K': 0.00015926349952337328,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.3091608509294145,
 'loss_weight_Methylation-K': 0.4141061368790091,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2063952521,
 'sample_weights': [0.9010073318718026, 0.11842542673289141],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 7.583832850195976,
 'weight_decay_Hydroxylation-K': 4.745055620257654,
 'weight_decay_Methylation-K': 7.590836575941714}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.388
[3,     4] loss: 1.392
{'CNNType': 'Musite',
 'CV_Repeats': 3,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0007974519103281815,
 'learning_rate_Hydroxylation-K': 0.003117855456754994,
 'learning_rate_Methylation-K': 0.0034716067047504125,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.4413927350152888,
 'loss_weight_Methylation-K': 0.45680930072252013,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 2064412247,
 'sample_weights': [0.3091608509294145, 0.4141061368790091],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 5.656626358607566,
 'weight_decay_Hydroxylation-K': 7.107862860956861,
 'weight_decay_Methylation-K': 8.27056360064034}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.383
[2,     4] loss: 1.386
[3,     4] loss: 1.384
[4,     4] loss: 1.379
[5,     4] loss: 1.380
[6,     4] loss: 1.370
[7,     4] loss: 1.352
[8,     4] loss: 1.335
[9,     4] loss: 1.318
{'CNNType': 'Musite',
 'CV_Repeats': 5,
 'CreateFigures': False,
 'Experiment Name': 'Model architecture - added max, ranges, bceloss',
 'FCType': 'Adapt',
 'FloatsToTune': {'learning_rate': [1e-05, 0.01],
                  'learning_rate_Hydroxylation-K': [1e-05, 0.01],
                  'learning_rate_Methylation-K': [1e-05, 0.01],
                  'loss_weight_Hydroxylation-K': [1e-05, 0.9999],
                  'loss_weight_Methylation-K': [1e-05, 0.9999],
                  'weight_decay': [0, 10],
                  'weight_decay_Hydroxylation-K': [0, 10],
                  'weight_decay_Methylation-K': [0, 10]},
 'IntsToTune': {},
 'LSTM_dropout': 0,
 'LSTM_hidden_size': 64,
 'LSTM_layers': 1,
 'MultiTask': True,
 'MultiTask_sample_method': 'balanced',
 'SeperateTuningLRandWD': True,
 'UseUncertaintyBasedLoss': False,
 'ValidationMetric': 'Validation Loss (Hydroxylation-K)',
 'WeightDecayWeights': [],
 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'],
 'batch_size': 2048,
 'crossValidation': True,
 'currentFold': 0,
 'current_CV_Repeat': 1,
 'data_sample_mode': ['oversample', 'balanced'],
 'dontAverageLoss': False,
 'earlyStopping': True,
 'earlyStoppingPatience': 50,
 'embeddingType': 'adaptiveEmbedding',
 'epochs': 200,
 'folds': 5,
 'gpu_mode': True,
 'layerToSplitOn': 'FC',
 'learning_rate': 0.0019409012716002294,
 'learning_rate_Hydroxylation-K': 0.005564252873339669,
 'learning_rate_Methylation-K': 0.0076762351315607675,
 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>,
 'loss_weight_Hydroxylation-K': 0.8463679711275396,
 'loss_weight_Methylation-K': 0.47195220353828066,
 'n_trials': 500,
 'optimizer': <class 'torch.optim.adamw.AdamW'>,
 'random_state': 70989851,
 'sample_weights': [0.4413927350152888, 0.45680930072252013],
 'test_data_ratio': 0.2,
 'useLrWeight': False,
 'useWeightDecayWeight': False,
 'weight_decay': 8.678179388774739,
 'weight_decay_Hydroxylation-K': 7.324445116127112,
 'weight_decay_Methylation-K': 9.461165924013105}
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.394
[2,     4] loss: 1.381
[3,     4] loss: 1.396
[4,     4] loss: 1.383
[5,     4] loss: 1.384
[6,     4] loss: 1.383
[7,     4] loss: 1.379
[8,     4] loss: 1.363
[9,     4] loss: 1.323
[10,     4] loss: 1.316
[11,     4] loss: 1.303
[12,     4] loss: 1.283
[13,     4] loss: 1.254
[14,     4] loss: 1.199
[15,     4] loss: 1.151
[16,     4] loss: 1.106
[17,     4] loss: 1.092
[18,     4] loss: 1.044
[19,     4] loss: 0.972
[20,     4] loss: 1.001
[21,     4] loss: 1.030
[22,     4] loss: 0.946
[23,     4] loss: 0.950
[24,     4] loss: 0.989
[25,     4] loss: 0.892
[26,     4] loss: 0.872
[27,     4] loss: 0.906
[28,     4] loss: 0.821
[29,     4] loss: 0.807
[30,     4] loss: 0.792
[31,     4] loss: 0.819
[32,     4] loss: 0.882
[33,     4] loss: 0.857
[34,     4] loss: 0.867
[35,     4] loss: 0.812
[36,     4] loss: 0.789
[37,     4] loss: 0.805
[38,     4] loss: 0.811
[39,     4] loss: 0.840
[40,     4] loss: 0.855
[41,     4] loss: 0.796
[42,     4] loss: 0.812
[43,     4] loss: 0.790
[44,     4] loss: 0.792
[45,     4] loss: 0.804
[46,     4] loss: 0.829
[47,     4] loss: 0.875
[48,     4] loss: 0.874
[49,     4] loss: 0.859
[50,     4] loss: 0.897
[51,     4] loss: 0.829
[52,     4] loss: 0.815
[53,     4] loss: 0.816
[54,     4] loss: 0.818
[55,     4] loss: 0.790
[56,     4] loss: 0.777
[57,     4] loss: 0.818
[58,     4] loss: 0.785
[59,     4] loss: 0.790
[60,     4] loss: 0.794
[61,     4] loss: 0.825
[62,     4] loss: 0.841
[63,     4] loss: 0.879
[64,     4] loss: 0.830
[65,     4] loss: 0.826
[66,     4] loss: 0.819
[67,     4] loss: 0.860
[68,     4] loss: 0.864
[69,     4] loss: 0.878
[70,     4] loss: 0.829
[71,     4] loss: 0.800
[72,     4] loss: 0.783
[73,     4] loss: 0.779
[74,     4] loss: 0.824
[75,     4] loss: 0.853
[76,     4] loss: 0.830
[77,     4] loss: 0.850
[78,     4] loss: 0.831
[79,     4] loss: 0.808
[80,     4] loss: 0.774
[81,     4] loss: 0.791
[82,     4] loss: 0.769
[83,     4] loss: 0.779
[84,     4] loss: 0.776
[85,     4] loss: 0.779
[86,     4] loss: 0.797
[87,     4] loss: 0.801
[88,     4] loss: 0.805
[89,     4] loss: 0.787
[90,     4] loss: 0.856
[91,     4] loss: 0.882
[92,     4] loss: 0.786
[93,     4] loss: 0.872
[94,     4] loss: 1.056
[95,     4] loss: 1.018
[96,     4] loss: 1.003
[97,     4] loss: 0.960
[98,     4] loss: 0.898
[99,     4] loss: 0.816
[100,     4] loss: 0.794
[101,     4] loss: 0.775
[102,     4] loss: 0.769
[103,     4] loss: 0.782
[104,     4] loss: 0.759
[105,     4] loss: 0.754
[106,     4] loss: 0.764
[107,     4] loss: 0.778
[108,     4] loss: 0.832
[109,     4] loss: 0.790
[110,     4] loss: 0.798
[111,     4] loss: 0.765
Early stopping applied (best metric=0.15923970937728882)
Finished Training
Total time taken: 58.771143436431885
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.381
[3,     4] loss: 1.382
[4,     4] loss: 1.375
[5,     4] loss: 1.365
[6,     4] loss: 1.326
[7,     4] loss: 1.280
[8,     4] loss: 1.228
[9,     4] loss: 1.162
[10,     4] loss: 1.180
[11,     4] loss: 1.106
[12,     4] loss: 1.090
[13,     4] loss: 1.072
[14,     4] loss: 1.039
[15,     4] loss: 1.032
[16,     4] loss: 1.026
[17,     4] loss: 1.009
[18,     4] loss: 1.014
[19,     4] loss: 0.963
[20,     4] loss: 0.934
[21,     4] loss: 0.883
[22,     4] loss: 0.846
[23,     4] loss: 0.853
[24,     4] loss: 0.914
[25,     4] loss: 0.981
[26,     4] loss: 0.883
[27,     4] loss: 0.863
[28,     4] loss: 0.890
[29,     4] loss: 0.892
[30,     4] loss: 0.905
[31,     4] loss: 0.953
[32,     4] loss: 0.936
[33,     4] loss: 0.963
[34,     4] loss: 0.910
[35,     4] loss: 0.853
[36,     4] loss: 0.838
[37,     4] loss: 0.818
[38,     4] loss: 0.864
[39,     4] loss: 1.016
[40,     4] loss: 0.921
[41,     4] loss: 1.040
[42,     4] loss: 0.967
[43,     4] loss: 0.938
[44,     4] loss: 0.864
[45,     4] loss: 0.824
[46,     4] loss: 0.820
[47,     4] loss: 0.824
[48,     4] loss: 0.824
[49,     4] loss: 0.868
[50,     4] loss: 0.802
[51,     4] loss: 0.822
[52,     4] loss: 0.808
[53,     4] loss: 0.782
[54,     4] loss: 0.795
[55,     4] loss: 0.777
[56,     4] loss: 0.849
[57,     4] loss: 0.905
[58,     4] loss: 0.909
[59,     4] loss: 0.874
[60,     4] loss: 0.832
[61,     4] loss: 0.836
[62,     4] loss: 0.825
[63,     4] loss: 0.782
[64,     4] loss: 0.779
[65,     4] loss: 0.779
[66,     4] loss: 0.864
[67,     4] loss: 0.893
[68,     4] loss: 0.837
[69,     4] loss: 0.821
[70,     4] loss: 0.829
[71,     4] loss: 0.773
[72,     4] loss: 0.768
[73,     4] loss: 0.780
[74,     4] loss: 0.804
[75,     4] loss: 0.790
[76,     4] loss: 0.818
[77,     4] loss: 0.908
Early stopping applied (best metric=0.3115653991699219)
Finished Training
Total time taken: 39.72282671928406
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.402
[2,     4] loss: 1.387
[3,     4] loss: 1.386
[4,     4] loss: 1.381
[5,     4] loss: 1.379
[6,     4] loss: 1.369
[7,     4] loss: 1.330
[8,     4] loss: 1.325
[9,     4] loss: 1.253
[10,     4] loss: 1.189
[11,     4] loss: 1.099
[12,     4] loss: 1.083
[13,     4] loss: 1.042
[14,     4] loss: 1.066
[15,     4] loss: 1.098
[16,     4] loss: 1.019
[17,     4] loss: 1.004
[18,     4] loss: 0.978
[19,     4] loss: 1.001
[20,     4] loss: 0.918
[21,     4] loss: 0.949
[22,     4] loss: 0.889
[23,     4] loss: 0.979
[24,     4] loss: 1.038
[25,     4] loss: 0.971
[26,     4] loss: 0.996
[27,     4] loss: 0.970
[28,     4] loss: 0.886
[29,     4] loss: 0.866
[30,     4] loss: 0.829
[31,     4] loss: 0.794
[32,     4] loss: 0.863
[33,     4] loss: 0.840
[34,     4] loss: 0.861
[35,     4] loss: 0.894
[36,     4] loss: 0.862
[37,     4] loss: 0.905
[38,     4] loss: 0.875
[39,     4] loss: 0.859
[40,     4] loss: 0.843
[41,     4] loss: 0.788
[42,     4] loss: 0.786
[43,     4] loss: 0.782
[44,     4] loss: 0.775
[45,     4] loss: 0.775
[46,     4] loss: 0.775
[47,     4] loss: 0.789
[48,     4] loss: 0.814
[49,     4] loss: 0.819
[50,     4] loss: 0.810
[51,     4] loss: 0.782
[52,     4] loss: 0.794
[53,     4] loss: 0.773
[54,     4] loss: 0.785
[55,     4] loss: 0.777
[56,     4] loss: 0.842
[57,     4] loss: 0.871
[58,     4] loss: 0.806
[59,     4] loss: 0.806
[60,     4] loss: 0.790
[61,     4] loss: 0.801
Early stopping applied (best metric=0.5165576338768005)
Finished Training
Total time taken: 30.103431701660156
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.381
[3,     4] loss: 1.387
[4,     4] loss: 1.375
[5,     4] loss: 1.370
[6,     4] loss: 1.349
[7,     4] loss: 1.307
[8,     4] loss: 1.271
[9,     4] loss: 1.229
[10,     4] loss: 1.134
[11,     4] loss: 1.090
[12,     4] loss: 1.122
[13,     4] loss: 0.989
[14,     4] loss: 0.994
[15,     4] loss: 1.019
[16,     4] loss: 1.000
[17,     4] loss: 0.959
[18,     4] loss: 1.038
[19,     4] loss: 0.985
[20,     4] loss: 0.915
[21,     4] loss: 0.948
[22,     4] loss: 0.924
[23,     4] loss: 0.884
[24,     4] loss: 0.857
[25,     4] loss: 0.898
[26,     4] loss: 0.911
[27,     4] loss: 0.912
[28,     4] loss: 0.907
[29,     4] loss: 0.838
[30,     4] loss: 0.812
[31,     4] loss: 0.788
[32,     4] loss: 0.815
[33,     4] loss: 0.845
[34,     4] loss: 0.842
[35,     4] loss: 0.848
[36,     4] loss: 0.859
[37,     4] loss: 0.830
[38,     4] loss: 0.855
[39,     4] loss: 0.802
[40,     4] loss: 0.763
[41,     4] loss: 0.761
[42,     4] loss: 0.751
[43,     4] loss: 0.746
[44,     4] loss: 0.736
[45,     4] loss: 0.761
[46,     4] loss: 0.775
[47,     4] loss: 0.757
[48,     4] loss: 0.767
[49,     4] loss: 0.733
[50,     4] loss: 0.795
[51,     4] loss: 0.887
[52,     4] loss: 0.872
[53,     4] loss: 0.832
[54,     4] loss: 0.784
[55,     4] loss: 0.778
[56,     4] loss: 0.801
[57,     4] loss: 0.819
[58,     4] loss: 0.756
[59,     4] loss: 0.771
Early stopping applied (best metric=0.41207998991012573)
Finished Training
Total time taken: 30.492504358291626
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.391
[2,     4] loss: 1.387
[3,     4] loss: 1.382
[4,     4] loss: 1.379
[5,     4] loss: 1.369
[6,     4] loss: 1.358
[7,     4] loss: 1.320
[8,     4] loss: 1.280
[9,     4] loss: 1.183
[10,     4] loss: 1.174
[11,     4] loss: 1.169
[12,     4] loss: 1.119
[13,     4] loss: 1.015
[14,     4] loss: 1.056
[15,     4] loss: 0.981
[16,     4] loss: 0.957
[17,     4] loss: 0.982
[18,     4] loss: 0.964
[19,     4] loss: 1.033
[20,     4] loss: 0.973
[21,     4] loss: 1.016
[22,     4] loss: 0.889
[23,     4] loss: 0.881
[24,     4] loss: 0.934
[25,     4] loss: 0.962
[26,     4] loss: 0.914
[27,     4] loss: 0.925
[28,     4] loss: 0.878
[29,     4] loss: 0.868
[30,     4] loss: 0.813
[31,     4] loss: 0.814
[32,     4] loss: 0.783
[33,     4] loss: 0.791
[34,     4] loss: 0.785
[35,     4] loss: 0.791
[36,     4] loss: 0.804
[37,     4] loss: 0.784
[38,     4] loss: 0.929
[39,     4] loss: 0.939
[40,     4] loss: 0.871
[41,     4] loss: 0.886
[42,     4] loss: 0.806
[43,     4] loss: 0.776
[44,     4] loss: 0.785
[45,     4] loss: 0.757
[46,     4] loss: 0.750
[47,     4] loss: 0.773
[48,     4] loss: 0.761
[49,     4] loss: 0.764
[50,     4] loss: 0.777
[51,     4] loss: 0.787
[52,     4] loss: 0.833
[53,     4] loss: 0.783
[54,     4] loss: 0.788
[55,     4] loss: 0.827
[56,     4] loss: 0.854
[57,     4] loss: 0.860
Early stopping applied (best metric=0.47773823142051697)
Finished Training
Total time taken: 29.87045168876648
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.386
[2,     4] loss: 1.384
[3,     4] loss: 1.386
[4,     4] loss: 1.380
[5,     4] loss: 1.381
[6,     4] loss: 1.357
[7,     4] loss: 1.324
[8,     4] loss: 1.287
[9,     4] loss: 1.251
[10,     4] loss: 1.264
[11,     4] loss: 1.247
[12,     4] loss: 1.195
[13,     4] loss: 1.147
[14,     4] loss: 1.100
[15,     4] loss: 1.069
[16,     4] loss: 1.086
[17,     4] loss: 1.008
[18,     4] loss: 1.047
[19,     4] loss: 0.998
[20,     4] loss: 1.018
[21,     4] loss: 0.972
[22,     4] loss: 1.032
[23,     4] loss: 1.039
[24,     4] loss: 0.981
[25,     4] loss: 0.955
[26,     4] loss: 0.934
[27,     4] loss: 0.845
[28,     4] loss: 0.836
[29,     4] loss: 0.860
[30,     4] loss: 0.842
[31,     4] loss: 0.885
[32,     4] loss: 0.849
[33,     4] loss: 0.877
[34,     4] loss: 0.887
[35,     4] loss: 0.938
[36,     4] loss: 0.942
[37,     4] loss: 0.858
[38,     4] loss: 0.840
[39,     4] loss: 0.801
[40,     4] loss: 0.824
[41,     4] loss: 0.891
[42,     4] loss: 0.854
[43,     4] loss: 0.953
[44,     4] loss: 0.967
[45,     4] loss: 0.942
[46,     4] loss: 0.834
[47,     4] loss: 0.844
[48,     4] loss: 0.809
[49,     4] loss: 0.776
[50,     4] loss: 0.776
[51,     4] loss: 0.772
[52,     4] loss: 0.787
[53,     4] loss: 0.875
[54,     4] loss: 0.849
[55,     4] loss: 0.848
[56,     4] loss: 0.839
[57,     4] loss: 0.826
[58,     4] loss: 0.803
[59,     4] loss: 0.808
[60,     4] loss: 0.823
[61,     4] loss: 0.789
[62,     4] loss: 0.795
[63,     4] loss: 0.921
[64,     4] loss: 0.876
[65,     4] loss: 0.890
[66,     4] loss: 0.821
[67,     4] loss: 0.787
[68,     4] loss: 0.784
[69,     4] loss: 0.783
[70,     4] loss: 0.792
[71,     4] loss: 0.786
[72,     4] loss: 0.798
[73,     4] loss: 0.821
[74,     4] loss: 0.799
[75,     4] loss: 0.848
[76,     4] loss: 0.810
[77,     4] loss: 0.788
[78,     4] loss: 0.803
[79,     4] loss: 0.762
[80,     4] loss: 0.805
[81,     4] loss: 0.755
[82,     4] loss: 0.816
[83,     4] loss: 0.872
[84,     4] loss: 1.024
[85,     4] loss: 0.945
[86,     4] loss: 0.936
[87,     4] loss: 0.868
[88,     4] loss: 0.840
[89,     4] loss: 0.804
[90,     4] loss: 0.787
[91,     4] loss: 0.798
[92,     4] loss: 0.789
[93,     4] loss: 0.773
Early stopping applied (best metric=0.27181515097618103)
Finished Training
Total time taken: 46.89853310585022
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.397
[2,     4] loss: 1.388
[3,     4] loss: 1.390
[4,     4] loss: 1.386
[5,     4] loss: 1.386
[6,     4] loss: 1.388
[7,     4] loss: 1.383
[8,     4] loss: 1.384
[9,     4] loss: 1.379
[10,     4] loss: 1.359
[11,     4] loss: 1.336
[12,     4] loss: 1.295
[13,     4] loss: 1.265
[14,     4] loss: 1.169
[15,     4] loss: 1.122
[16,     4] loss: 1.089
[17,     4] loss: 1.174
[18,     4] loss: 1.039
[19,     4] loss: 1.019
[20,     4] loss: 0.988
[21,     4] loss: 0.948
[22,     4] loss: 1.020
[23,     4] loss: 0.951
[24,     4] loss: 0.962
[25,     4] loss: 0.957
[26,     4] loss: 0.959
[27,     4] loss: 0.877
[28,     4] loss: 0.930
[29,     4] loss: 1.005
[30,     4] loss: 0.906
[31,     4] loss: 0.923
[32,     4] loss: 0.838
[33,     4] loss: 0.885
[34,     4] loss: 0.858
[35,     4] loss: 0.876
[36,     4] loss: 0.987
[37,     4] loss: 0.943
[38,     4] loss: 0.916
[39,     4] loss: 0.877
[40,     4] loss: 0.832
[41,     4] loss: 0.812
[42,     4] loss: 0.905
[43,     4] loss: 0.874
[44,     4] loss: 0.857
[45,     4] loss: 0.867
[46,     4] loss: 0.889
[47,     4] loss: 0.819
[48,     4] loss: 0.801
[49,     4] loss: 0.816
[50,     4] loss: 0.799
[51,     4] loss: 0.817
[52,     4] loss: 0.876
[53,     4] loss: 0.844
[54,     4] loss: 0.809
[55,     4] loss: 0.826
[56,     4] loss: 0.788
[57,     4] loss: 0.774
[58,     4] loss: 0.846
[59,     4] loss: 0.820
[60,     4] loss: 0.890
[61,     4] loss: 1.052
[62,     4] loss: 0.889
[63,     4] loss: 0.849
[64,     4] loss: 0.865
[65,     4] loss: 0.815
[66,     4] loss: 0.781
[67,     4] loss: 0.780
[68,     4] loss: 0.770
[69,     4] loss: 0.788
[70,     4] loss: 0.757
[71,     4] loss: 0.770
[72,     4] loss: 0.911
[73,     4] loss: 0.891
[74,     4] loss: 0.854
[75,     4] loss: 0.889
[76,     4] loss: 0.938
[77,     4] loss: 0.823
[78,     4] loss: 0.835
[79,     4] loss: 0.809
[80,     4] loss: 0.789
[81,     4] loss: 0.819
[82,     4] loss: 0.809
[83,     4] loss: 0.804
[84,     4] loss: 0.828
[85,     4] loss: 0.837
[86,     4] loss: 0.806
[87,     4] loss: 0.864
[88,     4] loss: 0.839
[89,     4] loss: 0.869
[90,     4] loss: 0.894
[91,     4] loss: 0.886
[92,     4] loss: 0.838
[93,     4] loss: 0.849
[94,     4] loss: 0.869
[95,     4] loss: 0.846
[96,     4] loss: 0.827
[97,     4] loss: 0.789
[98,     4] loss: 0.825
[99,     4] loss: 0.833
[100,     4] loss: 0.812
[101,     4] loss: 0.794
[102,     4] loss: 0.773
[103,     4] loss: 0.773
[104,     4] loss: 0.782
[105,     4] loss: 0.777
[106,     4] loss: 0.823
[107,     4] loss: 0.860
[108,     4] loss: 0.816
[109,     4] loss: 0.963
[110,     4] loss: 1.212
[111,     4] loss: 1.075
[112,     4] loss: 1.111
[113,     4] loss: 1.043
[114,     4] loss: 1.016
[115,     4] loss: 1.018
[116,     4] loss: 0.958
[117,     4] loss: 0.943
[118,     4] loss: 0.906
[119,     4] loss: 0.872
[120,     4] loss: 0.821
[121,     4] loss: 0.833
[122,     4] loss: 0.809
[123,     4] loss: 0.801
[124,     4] loss: 0.811
[125,     4] loss: 0.796
[126,     4] loss: 0.805
[127,     4] loss: 0.817
[128,     4] loss: 0.826
[129,     4] loss: 0.831
[130,     4] loss: 0.895
[131,     4] loss: 0.804
[132,     4] loss: 0.824
[133,     4] loss: 0.807
[134,     4] loss: 0.782
[135,     4] loss: 0.771
[136,     4] loss: 0.773
[137,     4] loss: 0.790
[138,     4] loss: 0.782
[139,     4] loss: 0.782
[140,     4] loss: 0.825
[141,     4] loss: 0.916
[142,     4] loss: 0.882
[143,     4] loss: 0.846
[144,     4] loss: 0.811
Early stopping applied (best metric=0.28585946559906006)
Finished Training
Total time taken: 74.81698369979858
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.383
[3,     4] loss: 1.384
[4,     4] loss: 1.378
[5,     4] loss: 1.377
[6,     4] loss: 1.363
[7,     4] loss: 1.331
[8,     4] loss: 1.306
[9,     4] loss: 1.233
[10,     4] loss: 1.197
[11,     4] loss: 1.135
[12,     4] loss: 1.177
[13,     4] loss: 1.111
[14,     4] loss: 1.030
[15,     4] loss: 1.046
[16,     4] loss: 1.004
[17,     4] loss: 0.942
[18,     4] loss: 0.924
[19,     4] loss: 0.925
[20,     4] loss: 0.937
[21,     4] loss: 0.929
[22,     4] loss: 0.951
[23,     4] loss: 0.988
[24,     4] loss: 0.930
[25,     4] loss: 0.887
[26,     4] loss: 0.888
[27,     4] loss: 0.932
[28,     4] loss: 0.859
[29,     4] loss: 0.843
[30,     4] loss: 0.838
[31,     4] loss: 0.817
[32,     4] loss: 0.811
[33,     4] loss: 0.817
[34,     4] loss: 0.799
[35,     4] loss: 0.827
[36,     4] loss: 0.760
[37,     4] loss: 0.784
[38,     4] loss: 0.784
[39,     4] loss: 0.787
[40,     4] loss: 0.809
[41,     4] loss: 0.789
[42,     4] loss: 0.814
[43,     4] loss: 0.828
[44,     4] loss: 0.807
[45,     4] loss: 0.797
[46,     4] loss: 0.785
[47,     4] loss: 0.803
[48,     4] loss: 0.962
[49,     4] loss: 0.855
[50,     4] loss: 0.892
[51,     4] loss: 0.839
[52,     4] loss: 0.801
[53,     4] loss: 0.776
[54,     4] loss: 0.806
[55,     4] loss: 0.759
[56,     4] loss: 0.782
[57,     4] loss: 0.796
[58,     4] loss: 0.814
[59,     4] loss: 0.836
[60,     4] loss: 0.805
[61,     4] loss: 0.844
[62,     4] loss: 0.853
[63,     4] loss: 0.835
[64,     4] loss: 0.825
[65,     4] loss: 0.813
[66,     4] loss: 0.763
[67,     4] loss: 0.817
[68,     4] loss: 0.774
[69,     4] loss: 0.796
[70,     4] loss: 0.817
[71,     4] loss: 0.901
[72,     4] loss: 0.912
[73,     4] loss: 0.965
[74,     4] loss: 0.874
Early stopping applied (best metric=0.3576901853084564)
Finished Training
Total time taken: 37.079766273498535
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.383
[3,     4] loss: 1.386
[4,     4] loss: 1.386
[5,     4] loss: 1.383
[6,     4] loss: 1.379
[7,     4] loss: 1.356
[8,     4] loss: 1.330
[9,     4] loss: 1.314
[10,     4] loss: 1.265
[11,     4] loss: 1.265
[12,     4] loss: 1.222
[13,     4] loss: 1.173
[14,     4] loss: 1.044
[15,     4] loss: 1.102
[16,     4] loss: 1.023
[17,     4] loss: 1.041
[18,     4] loss: 1.041
[19,     4] loss: 1.119
[20,     4] loss: 1.037
[21,     4] loss: 1.032
[22,     4] loss: 0.975
[23,     4] loss: 0.928
[24,     4] loss: 0.902
[25,     4] loss: 0.883
[26,     4] loss: 0.887
[27,     4] loss: 0.838
[28,     4] loss: 0.860
[29,     4] loss: 0.925
[30,     4] loss: 0.874
[31,     4] loss: 0.908
[32,     4] loss: 0.961
[33,     4] loss: 0.961
[34,     4] loss: 0.889
[35,     4] loss: 0.902
[36,     4] loss: 0.933
[37,     4] loss: 0.855
[38,     4] loss: 0.865
[39,     4] loss: 0.825
[40,     4] loss: 0.830
[41,     4] loss: 0.823
[42,     4] loss: 0.800
[43,     4] loss: 0.856
[44,     4] loss: 0.816
[45,     4] loss: 0.814
[46,     4] loss: 0.794
[47,     4] loss: 0.789
[48,     4] loss: 0.822
[49,     4] loss: 0.785
[50,     4] loss: 0.849
[51,     4] loss: 0.839
[52,     4] loss: 0.825
[53,     4] loss: 0.803
[54,     4] loss: 0.807
[55,     4] loss: 0.788
[56,     4] loss: 0.787
[57,     4] loss: 0.791
[58,     4] loss: 0.798
[59,     4] loss: 0.808
[60,     4] loss: 0.805
[61,     4] loss: 0.815
[62,     4] loss: 0.797
[63,     4] loss: 0.797
[64,     4] loss: 0.846
[65,     4] loss: 0.845
[66,     4] loss: 0.931
[67,     4] loss: 0.889
[68,     4] loss: 0.803
[69,     4] loss: 0.801
[70,     4] loss: 0.814
[71,     4] loss: 0.783
[72,     4] loss: 0.781
[73,     4] loss: 0.787
[74,     4] loss: 0.785
[75,     4] loss: 0.759
[76,     4] loss: 0.791
[77,     4] loss: 0.788
[78,     4] loss: 0.947
[79,     4] loss: 0.831
[80,     4] loss: 0.878
[81,     4] loss: 0.823
[82,     4] loss: 0.820
[83,     4] loss: 0.776
[84,     4] loss: 0.853
[85,     4] loss: 0.795
[86,     4] loss: 0.783
[87,     4] loss: 0.781
[88,     4] loss: 0.780
[89,     4] loss: 1.026
[90,     4] loss: 1.041
[91,     4] loss: 1.075
[92,     4] loss: 0.965
[93,     4] loss: 0.901
[94,     4] loss: 0.915
[95,     4] loss: 0.852
[96,     4] loss: 0.858
[97,     4] loss: 0.815
[98,     4] loss: 0.787
[99,     4] loss: 0.783
[100,     4] loss: 0.798
[101,     4] loss: 0.787
[102,     4] loss: 0.797
[103,     4] loss: 0.805
[104,     4] loss: 0.819
[105,     4] loss: 0.817
[106,     4] loss: 0.773
[107,     4] loss: 0.791
[108,     4] loss: 0.788
[109,     4] loss: 0.840
[110,     4] loss: 0.940
[111,     4] loss: 0.847
[112,     4] loss: 0.866
[113,     4] loss: 0.786
[114,     4] loss: 0.846
[115,     4] loss: 0.861
[116,     4] loss: 0.964
[117,     4] loss: 0.908
[118,     4] loss: 1.018
[119,     4] loss: 0.974
[120,     4] loss: 0.932
[121,     4] loss: 0.846
[122,     4] loss: 0.855
[123,     4] loss: 0.806
[124,     4] loss: 0.819
[125,     4] loss: 0.816
[126,     4] loss: 0.788
[127,     4] loss: 0.767
[128,     4] loss: 0.755
[129,     4] loss: 0.753
[130,     4] loss: 0.764
[131,     4] loss: 0.781
[132,     4] loss: 0.784
[133,     4] loss: 0.886
[134,     4] loss: 0.832
[135,     4] loss: 0.845
[136,     4] loss: 0.804
[137,     4] loss: 0.794
[138,     4] loss: 0.794
[139,     4] loss: 1.035
[140,     4] loss: 1.014
[141,     4] loss: 1.023
[142,     4] loss: 0.934
[143,     4] loss: 0.862
[144,     4] loss: 0.814
[145,     4] loss: 0.794
[146,     4] loss: 0.770
[147,     4] loss: 0.758
[148,     4] loss: 0.765
[149,     4] loss: 0.769
[150,     4] loss: 0.799
[151,     4] loss: 0.798
[152,     4] loss: 0.796
Early stopping applied (best metric=0.12166181951761246)
Finished Training
Total time taken: 78.73864698410034
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.389
[2,     4] loss: 1.385
[3,     4] loss: 1.386
[4,     4] loss: 1.381
[5,     4] loss: 1.379
[6,     4] loss: 1.372
[7,     4] loss: 1.345
[8,     4] loss: 1.310
[9,     4] loss: 1.234
[10,     4] loss: 1.196
[11,     4] loss: 1.130
[12,     4] loss: 1.160
[13,     4] loss: 1.140
[14,     4] loss: 1.137
[15,     4] loss: 1.086
[16,     4] loss: 1.029
[17,     4] loss: 1.007
[18,     4] loss: 1.062
[19,     4] loss: 1.034
[20,     4] loss: 0.972
[21,     4] loss: 0.937
[22,     4] loss: 0.972
[23,     4] loss: 0.929
[24,     4] loss: 0.896
[25,     4] loss: 0.838
[26,     4] loss: 0.927
[27,     4] loss: 0.901
[28,     4] loss: 0.900
[29,     4] loss: 0.881
[30,     4] loss: 0.873
[31,     4] loss: 0.851
[32,     4] loss: 0.817
[33,     4] loss: 0.828
[34,     4] loss: 0.883
[35,     4] loss: 0.921
[36,     4] loss: 0.806
[37,     4] loss: 0.821
[38,     4] loss: 0.826
[39,     4] loss: 0.786
[40,     4] loss: 0.779
[41,     4] loss: 0.774
[42,     4] loss: 0.762
[43,     4] loss: 0.816
[44,     4] loss: 0.914
[45,     4] loss: 0.841
[46,     4] loss: 0.887
[47,     4] loss: 0.824
[48,     4] loss: 0.814
[49,     4] loss: 0.795
[50,     4] loss: 0.791
[51,     4] loss: 0.768
[52,     4] loss: 0.751
[53,     4] loss: 0.770
[54,     4] loss: 0.816
[55,     4] loss: 0.786
[56,     4] loss: 0.816
[57,     4] loss: 0.790
Early stopping applied (best metric=0.5237888693809509)
Finished Training
Total time taken: 29.610020399093628
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.386
[3,     4] loss: 1.383
[4,     4] loss: 1.378
[5,     4] loss: 1.366
[6,     4] loss: 1.344
[7,     4] loss: 1.316
[8,     4] loss: 1.252
[9,     4] loss: 1.230
[10,     4] loss: 1.227
[11,     4] loss: 1.144
[12,     4] loss: 1.137
[13,     4] loss: 1.133
[14,     4] loss: 1.026
[15,     4] loss: 0.986
[16,     4] loss: 1.008
[17,     4] loss: 1.032
[18,     4] loss: 0.940
[19,     4] loss: 0.929
[20,     4] loss: 0.962
[21,     4] loss: 0.943
[22,     4] loss: 0.938
[23,     4] loss: 0.922
[24,     4] loss: 0.884
[25,     4] loss: 0.859
[26,     4] loss: 0.859
[27,     4] loss: 0.887
[28,     4] loss: 0.911
[29,     4] loss: 0.934
[30,     4] loss: 0.844
[31,     4] loss: 0.854
[32,     4] loss: 0.825
[33,     4] loss: 0.822
[34,     4] loss: 0.805
[35,     4] loss: 0.781
[36,     4] loss: 0.824
[37,     4] loss: 0.843
[38,     4] loss: 0.816
[39,     4] loss: 0.819
[40,     4] loss: 0.772
[41,     4] loss: 0.795
[42,     4] loss: 0.780
[43,     4] loss: 0.798
[44,     4] loss: 0.766
[45,     4] loss: 0.810
[46,     4] loss: 0.885
[47,     4] loss: 0.824
[48,     4] loss: 0.799
[49,     4] loss: 0.805
[50,     4] loss: 0.775
[51,     4] loss: 0.824
[52,     4] loss: 0.767
[53,     4] loss: 0.758
[54,     4] loss: 0.809
[55,     4] loss: 0.791
[56,     4] loss: 0.828
[57,     4] loss: 0.971
[58,     4] loss: 0.923
[59,     4] loss: 0.994
[60,     4] loss: 0.944
[61,     4] loss: 0.933
[62,     4] loss: 0.929
[63,     4] loss: 0.897
[64,     4] loss: 0.839
[65,     4] loss: 0.795
[66,     4] loss: 0.819
[67,     4] loss: 0.786
[68,     4] loss: 0.812
Early stopping applied (best metric=0.4399678707122803)
Finished Training
Total time taken: 35.579158544540405
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.380
[3,     4] loss: 1.383
[4,     4] loss: 1.370
[5,     4] loss: 1.340
[6,     4] loss: 1.295
[7,     4] loss: 1.219
[8,     4] loss: 1.122
[9,     4] loss: 1.130
[10,     4] loss: 1.079
[11,     4] loss: 1.153
[12,     4] loss: 1.042
[13,     4] loss: 1.053
[14,     4] loss: 1.106
[15,     4] loss: 1.018
[16,     4] loss: 0.973
[17,     4] loss: 0.933
[18,     4] loss: 0.860
[19,     4] loss: 1.130
[20,     4] loss: 0.941
[21,     4] loss: 0.917
[22,     4] loss: 0.863
[23,     4] loss: 0.848
[24,     4] loss: 0.866
[25,     4] loss: 0.870
[26,     4] loss: 0.835
[27,     4] loss: 0.822
[28,     4] loss: 0.798
[29,     4] loss: 0.805
[30,     4] loss: 0.922
[31,     4] loss: 1.150
[32,     4] loss: 0.936
[33,     4] loss: 0.949
[34,     4] loss: 0.890
[35,     4] loss: 0.811
[36,     4] loss: 0.809
[37,     4] loss: 0.769
[38,     4] loss: 0.776
[39,     4] loss: 0.859
[40,     4] loss: 0.850
[41,     4] loss: 0.831
[42,     4] loss: 0.861
[43,     4] loss: 0.800
[44,     4] loss: 0.771
[45,     4] loss: 0.804
[46,     4] loss: 0.784
[47,     4] loss: 0.790
[48,     4] loss: 0.803
[49,     4] loss: 0.822
[50,     4] loss: 0.798
[51,     4] loss: 0.793
[52,     4] loss: 0.810
[53,     4] loss: 0.800
[54,     4] loss: 0.790
[55,     4] loss: 0.803
[56,     4] loss: 0.886
[57,     4] loss: 0.793
[58,     4] loss: 0.797
[59,     4] loss: 0.844
[60,     4] loss: 0.807
[61,     4] loss: 0.791
[62,     4] loss: 0.841
[63,     4] loss: 0.808
[64,     4] loss: 0.819
[65,     4] loss: 0.808
[66,     4] loss: 0.801
[67,     4] loss: 0.760
[68,     4] loss: 0.757
[69,     4] loss: 0.831
[70,     4] loss: 0.789
[71,     4] loss: 0.842
[72,     4] loss: 0.839
[73,     4] loss: 0.856
[74,     4] loss: 0.895
[75,     4] loss: 0.872
[76,     4] loss: 0.817
[77,     4] loss: 0.787
[78,     4] loss: 0.793
[79,     4] loss: 0.797
[80,     4] loss: 0.766
[81,     4] loss: 0.748
[82,     4] loss: 0.746
[83,     4] loss: 0.793
[84,     4] loss: 0.788
Early stopping applied (best metric=0.4512332081794739)
Finished Training
Total time taken: 44.24725866317749
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.395
[2,     4] loss: 1.385
[3,     4] loss: 1.377
[4,     4] loss: 1.377
[5,     4] loss: 1.349
[6,     4] loss: 1.332
[7,     4] loss: 1.283
[8,     4] loss: 1.189
[9,     4] loss: 1.204
[10,     4] loss: 1.112
[11,     4] loss: 0.994
[12,     4] loss: 1.073
[13,     4] loss: 0.961
[14,     4] loss: 1.045
[15,     4] loss: 1.006
[16,     4] loss: 1.030
[17,     4] loss: 0.914
[18,     4] loss: 0.898
[19,     4] loss: 0.910
[20,     4] loss: 0.867
[21,     4] loss: 0.894
[22,     4] loss: 0.928
[23,     4] loss: 0.868
[24,     4] loss: 0.882
[25,     4] loss: 0.845
[26,     4] loss: 0.890
[27,     4] loss: 0.911
[28,     4] loss: 0.846
[29,     4] loss: 0.883
[30,     4] loss: 0.896
[31,     4] loss: 0.834
[32,     4] loss: 0.836
[33,     4] loss: 0.838
[34,     4] loss: 0.865
[35,     4] loss: 0.874
[36,     4] loss: 0.889
[37,     4] loss: 0.840
[38,     4] loss: 0.839
[39,     4] loss: 0.860
[40,     4] loss: 0.857
[41,     4] loss: 0.848
[42,     4] loss: 0.791
[43,     4] loss: 0.779
[44,     4] loss: 0.783
[45,     4] loss: 0.777
[46,     4] loss: 0.776
[47,     4] loss: 0.779
[48,     4] loss: 0.845
[49,     4] loss: 0.897
[50,     4] loss: 0.841
[51,     4] loss: 0.836
[52,     4] loss: 0.816
[53,     4] loss: 0.811
[54,     4] loss: 0.815
[55,     4] loss: 0.790
Early stopping applied (best metric=0.5114564299583435)
Finished Training
Total time taken: 28.848220348358154
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.390
[2,     4] loss: 1.384
[3,     4] loss: 1.383
[4,     4] loss: 1.372
[5,     4] loss: 1.375
[6,     4] loss: 1.356
[7,     4] loss: 1.323
[8,     4] loss: 1.282
[9,     4] loss: 1.255
[10,     4] loss: 1.187
[11,     4] loss: 1.180
[12,     4] loss: 1.204
[13,     4] loss: 1.143
[14,     4] loss: 1.064
[15,     4] loss: 1.065
[16,     4] loss: 1.033
[17,     4] loss: 1.087
[18,     4] loss: 0.977
[19,     4] loss: 0.987
[20,     4] loss: 1.001
[21,     4] loss: 0.992
[22,     4] loss: 1.127
[23,     4] loss: 1.041
[24,     4] loss: 1.015
[25,     4] loss: 0.992
[26,     4] loss: 0.946
[27,     4] loss: 0.894
[28,     4] loss: 0.883
[29,     4] loss: 0.902
[30,     4] loss: 0.826
[31,     4] loss: 0.814
[32,     4] loss: 0.874
[33,     4] loss: 0.893
[34,     4] loss: 0.910
[35,     4] loss: 0.942
[36,     4] loss: 0.928
[37,     4] loss: 0.934
[38,     4] loss: 0.898
[39,     4] loss: 0.863
[40,     4] loss: 0.810
[41,     4] loss: 0.809
[42,     4] loss: 0.822
[43,     4] loss: 0.811
[44,     4] loss: 0.809
[45,     4] loss: 0.796
[46,     4] loss: 0.775
[47,     4] loss: 0.851
[48,     4] loss: 0.816
[49,     4] loss: 0.777
[50,     4] loss: 0.771
[51,     4] loss: 0.747
[52,     4] loss: 0.842
[53,     4] loss: 0.881
[54,     4] loss: 0.945
[55,     4] loss: 0.907
[56,     4] loss: 0.913
[57,     4] loss: 0.856
[58,     4] loss: 0.823
[59,     4] loss: 0.841
[60,     4] loss: 0.796
[61,     4] loss: 0.902
[62,     4] loss: 0.894
[63,     4] loss: 0.930
[64,     4] loss: 0.930
[65,     4] loss: 0.874
[66,     4] loss: 0.832
[67,     4] loss: 0.778
[68,     4] loss: 0.793
[69,     4] loss: 0.752
[70,     4] loss: 0.787
[71,     4] loss: 0.792
[72,     4] loss: 0.785
[73,     4] loss: 0.785
[74,     4] loss: 0.821
[75,     4] loss: 0.892
Early stopping applied (best metric=0.24195459485054016)
Finished Training
Total time taken: 39.044782638549805
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.387
[2,     4] loss: 1.386
[3,     4] loss: 1.383
[4,     4] loss: 1.381
[5,     4] loss: 1.368
[6,     4] loss: 1.331
[7,     4] loss: 1.289
[8,     4] loss: 1.188
[9,     4] loss: 1.200
[10,     4] loss: 1.137
[11,     4] loss: 1.113
[12,     4] loss: 1.085
[13,     4] loss: 1.050
[14,     4] loss: 1.014
[15,     4] loss: 0.959
[16,     4] loss: 0.978
[17,     4] loss: 0.975
[18,     4] loss: 0.905
[19,     4] loss: 0.920
[20,     4] loss: 0.955
[21,     4] loss: 1.032
[22,     4] loss: 0.983
[23,     4] loss: 0.935
[24,     4] loss: 0.879
[25,     4] loss: 0.900
[26,     4] loss: 0.897
[27,     4] loss: 0.880
[28,     4] loss: 0.908
[29,     4] loss: 0.878
[30,     4] loss: 0.897
[31,     4] loss: 0.820
[32,     4] loss: 0.814
[33,     4] loss: 0.799
[34,     4] loss: 0.786
[35,     4] loss: 0.973
[36,     4] loss: 0.916
[37,     4] loss: 0.880
[38,     4] loss: 0.882
[39,     4] loss: 0.793
[40,     4] loss: 0.778
[41,     4] loss: 0.759
[42,     4] loss: 0.804
[43,     4] loss: 0.785
[44,     4] loss: 0.777
[45,     4] loss: 0.790
[46,     4] loss: 0.763
[47,     4] loss: 0.767
[48,     4] loss: 0.734
[49,     4] loss: 0.751
[50,     4] loss: 0.773
[51,     4] loss: 0.763
[52,     4] loss: 0.784
[53,     4] loss: 0.771
[54,     4] loss: 0.753
[55,     4] loss: 0.840
[56,     4] loss: 0.768
[57,     4] loss: 0.844
Early stopping applied (best metric=0.48171117901802063)
Finished Training
Total time taken: 30.031596183776855
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.387
[2,     4] loss: 1.387
[3,     4] loss: 1.383
[4,     4] loss: 1.391
[5,     4] loss: 1.388
[6,     4] loss: 1.384
[7,     4] loss: 1.385
[8,     4] loss: 1.383
[9,     4] loss: 1.380
[10,     4] loss: 1.363
[11,     4] loss: 1.344
[12,     4] loss: 1.289
[13,     4] loss: 1.250
[14,     4] loss: 1.255
[15,     4] loss: 1.144
[16,     4] loss: 1.157
[17,     4] loss: 1.179
[18,     4] loss: 1.078
[19,     4] loss: 1.038
[20,     4] loss: 1.057
[21,     4] loss: 1.040
[22,     4] loss: 0.982
[23,     4] loss: 1.051
[24,     4] loss: 0.988
[25,     4] loss: 1.037
[26,     4] loss: 0.942
[27,     4] loss: 0.956
[28,     4] loss: 0.901
[29,     4] loss: 0.902
[30,     4] loss: 0.942
[31,     4] loss: 0.957
[32,     4] loss: 0.900
[33,     4] loss: 0.871
[34,     4] loss: 0.899
[35,     4] loss: 0.908
[36,     4] loss: 0.874
[37,     4] loss: 0.947
[38,     4] loss: 0.868
[39,     4] loss: 0.874
[40,     4] loss: 0.886
[41,     4] loss: 0.829
[42,     4] loss: 0.822
[43,     4] loss: 0.833
[44,     4] loss: 0.844
[45,     4] loss: 0.835
[46,     4] loss: 0.912
[47,     4] loss: 0.933
[48,     4] loss: 0.885
[49,     4] loss: 0.957
[50,     4] loss: 0.856
[51,     4] loss: 0.882
[52,     4] loss: 0.876
[53,     4] loss: 0.798
[54,     4] loss: 0.824
[55,     4] loss: 0.776
[56,     4] loss: 0.795
[57,     4] loss: 0.821
[58,     4] loss: 0.873
[59,     4] loss: 0.831
[60,     4] loss: 0.884
[61,     4] loss: 0.827
[62,     4] loss: 0.879
[63,     4] loss: 0.871
[64,     4] loss: 0.953
[65,     4] loss: 0.907
[66,     4] loss: 0.880
[67,     4] loss: 0.864
[68,     4] loss: 0.854
[69,     4] loss: 0.812
[70,     4] loss: 0.819
Early stopping applied (best metric=0.37284135818481445)
Finished Training
Total time taken: 35.6021466255188
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.399
[2,     4] loss: 1.386
[3,     4] loss: 1.388
[4,     4] loss: 1.386
[5,     4] loss: 1.382
[6,     4] loss: 1.383
[7,     4] loss: 1.384
[8,     4] loss: 1.376
[9,     4] loss: 1.357
[10,     4] loss: 1.328
[11,     4] loss: 1.263
[12,     4] loss: 1.268
[13,     4] loss: 1.198
[14,     4] loss: 1.132
[15,     4] loss: 1.162
[16,     4] loss: 1.124
[17,     4] loss: 1.124
[18,     4] loss: 1.141
[19,     4] loss: 1.121
[20,     4] loss: 1.094
[21,     4] loss: 1.038
[22,     4] loss: 0.971
[23,     4] loss: 0.929
[24,     4] loss: 0.965
[25,     4] loss: 1.068
[26,     4] loss: 1.027
[27,     4] loss: 1.009
[28,     4] loss: 0.980
[29,     4] loss: 0.952
[30,     4] loss: 0.926
[31,     4] loss: 0.892
[32,     4] loss: 0.883
[33,     4] loss: 0.889
[34,     4] loss: 0.906
[35,     4] loss: 0.849
[36,     4] loss: 0.849
[37,     4] loss: 0.848
[38,     4] loss: 0.850
[39,     4] loss: 0.831
[40,     4] loss: 0.884
[41,     4] loss: 0.875
[42,     4] loss: 0.802
[43,     4] loss: 0.835
[44,     4] loss: 0.925
[45,     4] loss: 0.892
[46,     4] loss: 0.835
[47,     4] loss: 0.814
[48,     4] loss: 0.795
[49,     4] loss: 0.839
[50,     4] loss: 0.843
[51,     4] loss: 0.820
[52,     4] loss: 0.823
[53,     4] loss: 0.789
[54,     4] loss: 0.801
[55,     4] loss: 0.812
[56,     4] loss: 0.785
[57,     4] loss: 0.866
[58,     4] loss: 0.862
[59,     4] loss: 0.963
[60,     4] loss: 0.904
[61,     4] loss: 0.844
[62,     4] loss: 0.831
[63,     4] loss: 0.802
[64,     4] loss: 0.783
[65,     4] loss: 0.774
[66,     4] loss: 0.804
[67,     4] loss: 0.765
[68,     4] loss: 0.771
[69,     4] loss: 0.782
[70,     4] loss: 0.806
[71,     4] loss: 0.815
[72,     4] loss: 0.886
[73,     4] loss: 0.860
[74,     4] loss: 0.917
[75,     4] loss: 0.834
[76,     4] loss: 0.837
[77,     4] loss: 0.877
[78,     4] loss: 0.819
[79,     4] loss: 0.806
Early stopping applied (best metric=0.3882070779800415)
Finished Training
Total time taken: 42.024890422821045
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.393
[2,     4] loss: 1.389
[3,     4] loss: 1.378
[4,     4] loss: 1.372
[5,     4] loss: 1.343
[6,     4] loss: 1.287
[7,     4] loss: 1.231
[8,     4] loss: 1.193
[9,     4] loss: 1.131
[10,     4] loss: 1.128
[11,     4] loss: 1.125
[12,     4] loss: 0.978
[13,     4] loss: 1.066
[14,     4] loss: 0.972
[15,     4] loss: 0.991
[16,     4] loss: 1.135
[17,     4] loss: 1.078
[18,     4] loss: 1.003
[19,     4] loss: 0.997
[20,     4] loss: 1.028
[21,     4] loss: 0.910
[22,     4] loss: 0.898
[23,     4] loss: 0.840
[24,     4] loss: 0.823
[25,     4] loss: 0.851
[26,     4] loss: 0.792
[27,     4] loss: 0.806
[28,     4] loss: 0.797
[29,     4] loss: 0.848
[30,     4] loss: 0.853
[31,     4] loss: 0.919
[32,     4] loss: 0.847
[33,     4] loss: 0.815
[34,     4] loss: 0.807
[35,     4] loss: 0.856
[36,     4] loss: 0.811
[37,     4] loss: 0.809
[38,     4] loss: 0.800
[39,     4] loss: 0.794
[40,     4] loss: 0.789
[41,     4] loss: 0.766
[42,     4] loss: 0.792
[43,     4] loss: 0.847
[44,     4] loss: 0.864
[45,     4] loss: 0.826
[46,     4] loss: 0.836
[47,     4] loss: 0.792
[48,     4] loss: 0.749
[49,     4] loss: 0.771
[50,     4] loss: 0.798
[51,     4] loss: 0.780
[52,     4] loss: 0.770
[53,     4] loss: 0.776
[54,     4] loss: 0.820
[55,     4] loss: 0.848
[56,     4] loss: 0.883
[57,     4] loss: 0.914
[58,     4] loss: 0.838
[59,     4] loss: 0.795
[60,     4] loss: 0.763
[61,     4] loss: 0.777
[62,     4] loss: 0.782
[63,     4] loss: 0.789
[64,     4] loss: 0.769
[65,     4] loss: 0.805
[66,     4] loss: 0.785
[67,     4] loss: 0.791
Early stopping applied (best metric=0.5106404423713684)
Finished Training
Total time taken: 35.52508473396301
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.389
[2,     4] loss: 1.387
[3,     4] loss: 1.388
[4,     4] loss: 1.379
[5,     4] loss: 1.369
[6,     4] loss: 1.338
[7,     4] loss: 1.299
[8,     4] loss: 1.236
[9,     4] loss: 1.194
[10,     4] loss: 1.198
[11,     4] loss: 1.119
[12,     4] loss: 1.082
[13,     4] loss: 1.103
[14,     4] loss: 1.076
[15,     4] loss: 1.081
[16,     4] loss: 1.122
[17,     4] loss: 1.029
[18,     4] loss: 1.006
[19,     4] loss: 0.960
[20,     4] loss: 0.938
[21,     4] loss: 0.894
[22,     4] loss: 0.851
[23,     4] loss: 1.005
[24,     4] loss: 1.057
[25,     4] loss: 0.987
[26,     4] loss: 0.943
[27,     4] loss: 0.930
[28,     4] loss: 0.885
[29,     4] loss: 0.838
[30,     4] loss: 1.004
[31,     4] loss: 0.848
[32,     4] loss: 0.899
[33,     4] loss: 0.830
[34,     4] loss: 0.886
[35,     4] loss: 0.848
[36,     4] loss: 0.804
[37,     4] loss: 0.849
[38,     4] loss: 0.844
[39,     4] loss: 0.884
[40,     4] loss: 0.778
[41,     4] loss: 0.840
[42,     4] loss: 0.792
[43,     4] loss: 0.792
[44,     4] loss: 0.782
[45,     4] loss: 0.808
[46,     4] loss: 0.819
[47,     4] loss: 0.830
[48,     4] loss: 0.790
[49,     4] loss: 0.782
[50,     4] loss: 0.749
[51,     4] loss: 0.744
[52,     4] loss: 0.747
[53,     4] loss: 0.777
[54,     4] loss: 0.770
[55,     4] loss: 0.803
[56,     4] loss: 0.771
[57,     4] loss: 0.783
[58,     4] loss: 0.752
[59,     4] loss: 0.898
[60,     4] loss: 1.093
[61,     4] loss: 0.996
[62,     4] loss: 0.914
[63,     4] loss: 0.831
Early stopping applied (best metric=0.38879093527793884)
Finished Training
Total time taken: 31.875507831573486
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.389
[2,     4] loss: 1.391
[3,     4] loss: 1.385
[4,     4] loss: 1.383
[5,     4] loss: 1.383
[6,     4] loss: 1.378
[7,     4] loss: 1.369
[8,     4] loss: 1.347
[9,     4] loss: 1.309
[10,     4] loss: 1.237
[11,     4] loss: 1.155
[12,     4] loss: 1.125
[13,     4] loss: 1.089
[14,     4] loss: 1.101
[15,     4] loss: 1.093
[16,     4] loss: 1.115
[17,     4] loss: 1.098
[18,     4] loss: 0.992
[19,     4] loss: 1.007
[20,     4] loss: 0.942
[21,     4] loss: 0.933
[22,     4] loss: 0.910
[23,     4] loss: 0.930
[24,     4] loss: 0.886
[25,     4] loss: 0.863
[26,     4] loss: 0.834
[27,     4] loss: 0.844
[28,     4] loss: 0.914
[29,     4] loss: 0.891
[30,     4] loss: 0.849
[31,     4] loss: 0.814
[32,     4] loss: 0.811
[33,     4] loss: 0.778
[34,     4] loss: 0.832
[35,     4] loss: 0.799
[36,     4] loss: 0.820
[37,     4] loss: 0.795
[38,     4] loss: 0.783
[39,     4] loss: 0.797
[40,     4] loss: 0.792
[41,     4] loss: 0.765
[42,     4] loss: 0.765
[43,     4] loss: 0.775
[44,     4] loss: 0.780
[45,     4] loss: 0.924
[46,     4] loss: 0.897
[47,     4] loss: 0.880
[48,     4] loss: 0.865
[49,     4] loss: 0.814
[50,     4] loss: 0.820
[51,     4] loss: 0.808
[52,     4] loss: 0.776
[53,     4] loss: 0.758
[54,     4] loss: 0.767
[55,     4] loss: 0.762
[56,     4] loss: 0.765
[57,     4] loss: 0.795
[58,     4] loss: 0.799
Early stopping applied (best metric=0.501471221446991)
Finished Training
Total time taken: 30.684072256088257
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.388
[2,     4] loss: 1.393
[3,     4] loss: 1.388
[4,     4] loss: 1.385
[5,     4] loss: 1.378
[6,     4] loss: 1.369
[7,     4] loss: 1.340
[8,     4] loss: 1.298
[9,     4] loss: 1.275
[10,     4] loss: 1.232
[11,     4] loss: 1.145
[12,     4] loss: 1.111
[13,     4] loss: 1.138
[14,     4] loss: 1.099
[15,     4] loss: 1.054
[16,     4] loss: 1.022
[17,     4] loss: 0.977
[18,     4] loss: 0.986
[19,     4] loss: 0.899
[20,     4] loss: 0.911
[21,     4] loss: 0.872
[22,     4] loss: 0.822
[23,     4] loss: 1.001
[24,     4] loss: 0.924
[25,     4] loss: 0.911
[26,     4] loss: 0.913
[27,     4] loss: 0.911
[28,     4] loss: 0.821
[29,     4] loss: 0.854
[30,     4] loss: 0.905
[31,     4] loss: 0.844
[32,     4] loss: 0.900
[33,     4] loss: 0.878
[34,     4] loss: 0.861
[35,     4] loss: 0.833
[36,     4] loss: 0.802
[37,     4] loss: 0.785
[38,     4] loss: 0.788
[39,     4] loss: 0.757
[40,     4] loss: 0.776
[41,     4] loss: 0.804
[42,     4] loss: 0.798
[43,     4] loss: 0.808
[44,     4] loss: 0.846
[45,     4] loss: 0.786
[46,     4] loss: 0.797
[47,     4] loss: 0.790
[48,     4] loss: 0.808
[49,     4] loss: 0.822
[50,     4] loss: 0.785
[51,     4] loss: 0.804
[52,     4] loss: 0.768
[53,     4] loss: 0.814
[54,     4] loss: 0.843
[55,     4] loss: 0.780
[56,     4] loss: 0.800
[57,     4] loss: 0.762
[58,     4] loss: 0.780
[59,     4] loss: 0.789
[60,     4] loss: 0.791
[61,     4] loss: 0.790
Early stopping applied (best metric=0.46368730068206787)
Finished Training
Total time taken: 32.971407651901245
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.391
[2,     4] loss: 1.381
[3,     4] loss: 1.381
[4,     4] loss: 1.371
[5,     4] loss: 1.353
[6,     4] loss: 1.299
[7,     4] loss: 1.324
[8,     4] loss: 1.233
[9,     4] loss: 1.240
[10,     4] loss: 1.166
[11,     4] loss: 1.162
[12,     4] loss: 1.087
[13,     4] loss: 1.040
[14,     4] loss: 0.962
[15,     4] loss: 1.045
[16,     4] loss: 1.020
[17,     4] loss: 0.998
[18,     4] loss: 0.989
[19,     4] loss: 1.045
[20,     4] loss: 0.972
[21,     4] loss: 0.960
[22,     4] loss: 0.927
[23,     4] loss: 0.862
[24,     4] loss: 0.841
[25,     4] loss: 0.865
[26,     4] loss: 0.826
[27,     4] loss: 0.825
[28,     4] loss: 0.864
[29,     4] loss: 0.864
[30,     4] loss: 0.908
[31,     4] loss: 0.844
[32,     4] loss: 0.844
[33,     4] loss: 0.813
[34,     4] loss: 0.804
[35,     4] loss: 0.842
[36,     4] loss: 0.854
[37,     4] loss: 0.856
[38,     4] loss: 0.834
[39,     4] loss: 0.823
[40,     4] loss: 0.792
[41,     4] loss: 0.791
[42,     4] loss: 0.764
[43,     4] loss: 0.757
[44,     4] loss: 0.819
[45,     4] loss: 0.805
[46,     4] loss: 0.802
[47,     4] loss: 0.835
[48,     4] loss: 0.849
[49,     4] loss: 0.826
[50,     4] loss: 0.874
[51,     4] loss: 0.826
[52,     4] loss: 0.880
[53,     4] loss: 0.830
[54,     4] loss: 0.797
[55,     4] loss: 0.803
[56,     4] loss: 0.760
[57,     4] loss: 0.761
[58,     4] loss: 0.763
[59,     4] loss: 0.770
[60,     4] loss: 0.767
[61,     4] loss: 0.769
[62,     4] loss: 0.781
[63,     4] loss: 0.835
[64,     4] loss: 0.826
[65,     4] loss: 0.865
[66,     4] loss: 0.916
[67,     4] loss: 0.829
[68,     4] loss: 0.845
[69,     4] loss: 0.802
[70,     4] loss: 0.813
[71,     4] loss: 0.782
[72,     4] loss: 0.785
[73,     4] loss: 0.875
[74,     4] loss: 0.853
[75,     4] loss: 0.867
[76,     4] loss: 0.791
[77,     4] loss: 0.847
Early stopping applied (best metric=0.30379319190979004)
Finished Training
Total time taken: 41.31008863449097
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.372
[2,     4] loss: 1.394
[3,     4] loss: 1.385
[4,     4] loss: 1.387
[5,     4] loss: 1.384
[6,     4] loss: 1.387
[7,     4] loss: 1.387
[8,     4] loss: 1.387
[9,     4] loss: 1.387
[10,     4] loss: 1.386
[11,     4] loss: 1.386
[12,     4] loss: 1.385
[13,     4] loss: 1.383
[14,     4] loss: 1.382
[15,     4] loss: 1.369
[16,     4] loss: 1.360
[17,     4] loss: 1.335
[18,     4] loss: 1.323
[19,     4] loss: 1.195
[20,     4] loss: 1.155
[21,     4] loss: 1.176
[22,     4] loss: 1.129
[23,     4] loss: 1.081
[24,     4] loss: 1.090
[25,     4] loss: 1.018
[26,     4] loss: 0.993
[27,     4] loss: 1.043
[28,     4] loss: 1.038
[29,     4] loss: 1.115
[30,     4] loss: 1.029
[31,     4] loss: 1.047
[32,     4] loss: 0.995
[33,     4] loss: 0.954
[34,     4] loss: 0.961
[35,     4] loss: 0.896
[36,     4] loss: 0.895
[37,     4] loss: 0.873
[38,     4] loss: 0.888
[39,     4] loss: 0.849
[40,     4] loss: 1.092
[41,     4] loss: 0.936
[42,     4] loss: 0.976
[43,     4] loss: 0.926
[44,     4] loss: 0.906
[45,     4] loss: 0.863
[46,     4] loss: 0.843
[47,     4] loss: 0.849
[48,     4] loss: 0.853
[49,     4] loss: 0.855
[50,     4] loss: 0.891
[51,     4] loss: 0.833
[52,     4] loss: 0.820
[53,     4] loss: 0.840
[54,     4] loss: 0.801
[55,     4] loss: 0.792
[56,     4] loss: 0.801
[57,     4] loss: 0.792
[58,     4] loss: 0.790
[59,     4] loss: 0.871
[60,     4] loss: 0.851
[61,     4] loss: 0.847
[62,     4] loss: 0.831
[63,     4] loss: 0.814
[64,     4] loss: 0.810
[65,     4] loss: 0.847
[66,     4] loss: 0.800
[67,     4] loss: 0.841
[68,     4] loss: 0.824
[69,     4] loss: 0.789
[70,     4] loss: 0.793
[71,     4] loss: 0.798
[72,     4] loss: 0.777
[73,     4] loss: 0.801
[74,     4] loss: 0.818
[75,     4] loss: 0.810
[76,     4] loss: 0.797
[77,     4] loss: 0.795
[78,     4] loss: 0.915
[79,     4] loss: 0.828
[80,     4] loss: 0.888
[81,     4] loss: 0.842
[82,     4] loss: 0.827
[83,     4] loss: 0.811
[84,     4] loss: 0.784
[85,     4] loss: 0.789
[86,     4] loss: 0.789
[87,     4] loss: 0.817
[88,     4] loss: 1.074
[89,     4] loss: 0.917
[90,     4] loss: 0.954
[91,     4] loss: 1.002
[92,     4] loss: 0.974
[93,     4] loss: 0.911
[94,     4] loss: 0.854
[95,     4] loss: 0.869
[96,     4] loss: 0.810
[97,     4] loss: 0.800
[98,     4] loss: 0.802
[99,     4] loss: 0.804
[100,     4] loss: 0.809
Early stopping applied (best metric=0.33688947558403015)
Finished Training
Total time taken: 51.976768255233765
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7416
[1,     1] loss: 1.385
[2,     4] loss: 1.389
[3,     4] loss: 1.386
[4,     4] loss: 1.382
[5,     4] loss: 1.382
[6,     4] loss: 1.374
[7,     4] loss: 1.356
[8,     4] loss: 1.302
[9,     4] loss: 1.263
[10,     4] loss: 1.237
[11,     4] loss: 1.203
[12,     4] loss: 1.254
[13,     4] loss: 1.185
[14,     4] loss: 1.146
[15,     4] loss: 1.104
[16,     4] loss: 1.068
[17,     4] loss: 1.088
[18,     4] loss: 1.012
[19,     4] loss: 1.037
[20,     4] loss: 1.000
[21,     4] loss: 0.990
[22,     4] loss: 0.994
[23,     4] loss: 1.132
[24,     4] loss: 1.029
[25,     4] loss: 1.051
[26,     4] loss: 0.990
[27,     4] loss: 0.984
[28,     4] loss: 0.955
[29,     4] loss: 0.919
[30,     4] loss: 0.960
[31,     4] loss: 0.980
[32,     4] loss: 0.923
[33,     4] loss: 0.893
[34,     4] loss: 0.880
[35,     4] loss: 0.860
[36,     4] loss: 0.797
[37,     4] loss: 0.900
[38,     4] loss: 0.981
[39,     4] loss: 0.971
[40,     4] loss: 0.916
[41,     4] loss: 0.953
[42,     4] loss: 0.894
[43,     4] loss: 0.857
[44,     4] loss: 0.841
[45,     4] loss: 0.882
[46,     4] loss: 0.892
[47,     4] loss: 0.929
[48,     4] loss: 0.899
[49,     4] loss: 0.872
[50,     4] loss: 0.814
[51,     4] loss: 0.810
[52,     4] loss: 0.862
[53,     4] loss: 0.798
[54,     4] loss: 0.823
[55,     4] loss: 0.837
[56,     4] loss: 0.818
[57,     4] loss: 0.805
[58,     4] loss: 0.822
[59,     4] loss: 0.882
[60,     4] loss: 0.862
[61,     4] loss: 0.839
[62,     4] loss: 0.883
[63,     4] loss: 0.964
[64,     4] loss: 0.886
[65,     4] loss: 0.887
[66,     4] loss: 0.874
[67,     4] loss: 0.862
[68,     4] loss: 0.847
[69,     4] loss: 0.838
[70,     4] loss: 0.804
[71,     4] loss: 0.815
[72,     4] loss: 0.839
[73,     4] loss: 0.826
[74,     4] loss: 0.829
[75,     4] loss: 0.879
[76,     4] loss: 0.985
[77,     4] loss: 1.060
[78,     4] loss: 1.004
[79,     4] loss: 0.929
[80,     4] loss: 0.901
[81,     4] loss: 0.890
[82,     4] loss: 0.886
[83,     4] loss: 0.845
[84,     4] loss: 0.797
[85,     4] loss: 0.804
[86,     4] loss: 0.818
[87,     4] loss: 0.852
[88,     4] loss: 0.803
[89,     4] loss: 0.819
[90,     4] loss: 0.850
[91,     4] loss: 0.830
[92,     4] loss: 0.812
[93,     4] loss: 0.876
[94,     4] loss: 0.983
[95,     4] loss: 0.867
[96,     4] loss: 0.842
[97,     4] loss: 0.808
[98,     4] loss: 0.802
[99,     4] loss: 0.826
[100,     4] loss: 0.777
[101,     4] loss: 0.826
[102,     4] loss: 0.794
[103,     4] loss: 0.889
[104,     4] loss: 0.807
[105,     4] loss: 0.805
[106,     4] loss: 0.822
[107,     4] loss: 0.975
[108,     4] loss: 1.192
[109,     4] loss: 1.222
[110,     4] loss: 1.134
[111,     4] loss: 0.997
[112,     4] loss: 0.886
[113,     4] loss: 0.850
[114,     4] loss: 0.876
[115,     4] loss: 0.864
[116,     4] loss: 0.877
[117,     4] loss: 0.845
[118,     4] loss: 0.949
[119,     4] loss: 0.896
[120,     4] loss: 0.888
[121,     4] loss: 0.876
[122,     4] loss: 0.840
[123,     4] loss: 0.821
[124,     4] loss: 0.826
[125,     4] loss: 0.803
[126,     4] loss: 0.872
Early stopping applied (best metric=0.28567370772361755)
Finished Training
Total time taken: 66.31875419616699
(48,)
Loaded folder code/Thesis/dataset/train/Hydroxylation-K/indices (238 samples)
(4634,)
Loaded folder code/Thesis/dataset/train/Methylation-K/indices (47363 samples)
81 305
1968 7418
[1,     1] loss: 1.397
[2,     4] loss: 1.383
[3,     4] loss: 1.384
[4,     4] loss: 1.383
[5,     4] loss: 1.387
[6,     4] loss: 1.380
[7,     4] loss: 1.377
[8,     4] loss: 1.367
[9,     4] loss: 1.349
[10,     4] loss: 1.333
[11,     4] loss: 1.301
[12,     4] loss: 1.248
[13,     4] loss: 1.239
[14,     4] loss: 1.210
[15,     4] loss: 1.159
[16,     4] loss: 1.161
[17,     4] loss: 1.127
[18,     4] loss: 1.064
[19,     4] loss: 1.056
[20,     4] loss: 1.008
[21,     4] loss: 0.986
[22,     4] loss: 1.001
[23,     4] loss: 0.986
[24,     4] loss: 0.980
[25,     4] loss: 1.076
[26,     4] loss: 0.986
[27,     4] loss: 1.028
[28,     4] loss: 0.940
[29,     4] loss: 0.908
[30,     4] loss: 0.882
[31,     4] loss: 0.878
[32,     4] loss: 0.956
[33,     4] loss: 0.885
[34,     4] loss: 0.865
[35,     4] loss: 0.856
[36,     4] loss: 0.853
[37,     4] loss: 0.876
[38,     4] loss: 0.839
[39,     4] loss: 0.853
[40,     4] loss: 0.928
[41,     4] loss: 0.889
[42,     4] loss: 0.845
[43,     4] loss: 0.850
[44,     4] loss: 0.872
[45,     4] loss: 0.797
[46,     4] loss: 0.817
[47,     4] loss: 0.797
[48,     4] loss: 0.827
[49,     4] loss: 0.813
[50,     4] loss: 0.786
[51,     4] loss: 0.787
[52,     4] loss: 0.760
[53,     4] loss: 0.804
[54,     4] loss: 0.793
[55,     4] loss: 0.828
[56,     4] loss: 0.805
[57,     4] loss: 0.782
[58,     4] loss: 0.843
[59,     4] loss: 1.016
[60,     4] loss: 0.883
[61,     4] loss: 0.904
[62,     4] loss: 0.819
[63,     4] loss: 0.818
[64,     4] loss: 0.808
[65,     4] loss: 0.833
[66,     4] loss: 0.839
[67,     4] loss: 0.850
[68,     4] loss: 0.839
[69,     4] loss: 0.809
[70,     4] loss: 0.800
[71,     4] loss: 0.774
[72,     4] loss: 0.813
[73,     4] loss: 0.787
[74,     4] loss: 0.823
[75,     4] loss: 0.810
[76,     4] loss: 0.826
[77,     4] loss: 0.765
[78,     4] loss: 0.768
Early stopping applied (best metric=0.2596554458141327)
Finished Training
Total time taken: 40.252031326293945
results!
{'gpu_mode': True, 'epochs': 200, 'batch_size': 2048, 'learning_rate': 0.0019409012716002294, 'test_data_ratio': 0.2, 'data_sample_mode': ['oversample', 'balanced'], 'crossValidation': True, 'loss_function': <class 'torch.nn.modules.loss.BCELoss'>, 'optimizer': <class 'torch.optim.adamw.AdamW'>, 'folds': 5, 'earlyStopping': True, 'ValidationMetric': 'Validation Loss (Hydroxylation-K)', 'earlyStoppingPatience': 50, 'CV_Repeats': 5, 'Experiment Name': 'Model architecture - added max, ranges, bceloss', 'CreateFigures': False, 'weight_decay': 8.678179388774739, 'embeddingType': 'adaptiveEmbedding', 'LSTM_layers': 1, 'LSTM_hidden_size': 64, 'LSTM_dropout': 0, 'MultiTask': True, 'MultiTask_sample_method': 'balanced', 'UseUncertaintyBasedLoss': False, 'useLrWeight': False, 'CNNType': 'Musite', 'FCType': 'Adapt', 'layerToSplitOn': 'FC', 'dontAverageLoss': False, 'useWeightDecayWeight': False, 'SeperateTuningLRandWD': True, 'aminoAcid': ['Hydroxylation-K', 'Methylation-K'], 'n_trials': 500, 'FloatsToTune': {'learning_rate': [1e-05, 0.01], 'weight_decay': [0, 10], 'learning_rate_Hydroxylation-K': [1e-05, 0.01], 'learning_rate_Methylation-K': [1e-05, 0.01], 'weight_decay_Hydroxylation-K': [0, 10], 'weight_decay_Methylation-K': [0, 10], 'loss_weight_Hydroxylation-K': [1e-05, 0.9999], 'loss_weight_Methylation-K': [1e-05, 0.9999]}, 'IntsToTune': {}, 'learning_rate_Hydroxylation-K': 0.005564252873339669, 'learning_rate_Methylation-K': 0.0076762351315607675, 'weight_decay_Hydroxylation-K': 7.324445116127112, 'weight_decay_Methylation-K': 9.461165924013105, 'loss_weight_Hydroxylation-K': 0.8463679711275396, 'loss_weight_Methylation-K': 0.47195220353828066, 'random_state': 70989876, 'current_CV_Repeat': 5, 'sample_weights': [0.8463679711275396, 0.47195220353828066], 'WeightDecayWeights': [], 'currentFold': 4}
{'Hydroxylation-K Validation Accuracy': 0.798936170212766, 'Hydroxylation-K Validation Sensitivity': 0.7968888888888889, 'Hydroxylation-K Validation Specificity': 0.8, 'Hydroxylation-K Validation Precision': 0.5337952554691685, 'Hydroxylation-K AUC ROC': 0.8457426900584796, 'Hydroxylation-K AUC PR': 0.6193978557417604, 'Hydroxylation-K MCC': 0.5302267595483915, 'Hydroxylation-K F1': 0.6266708954587157, 'Validation Loss (Hydroxylation-K)': 0.3750387957692146, 'Methylation-K Validation Accuracy': 0.7986659667463389, 'Methylation-K Validation Sensitivity': 0.15977059699301727, 'Methylation-K Validation Specificity': 0.8679541157980691, 'Methylation-K Validation Precision': 0.11810127896651314, 'Methylation-K AUC ROC': 0.5326351973744754, 'Methylation-K AUC PR': 0.1095846543276088, 'Methylation-K MCC': 0.024709299127795334, 'Methylation-K F1': 0.12664455297812194, 'Validation Loss (Methylation-K)': 0.8848086261749267, 'Validation Loss (total)': 1.2598474168777465, 'TimeToTrain': 41.69584306716919}
{'Hydroxylation-K Validation Accuracy': 0.08894630313621349, 'Hydroxylation-K Validation Sensitivity': 0.12634136265568563, 'Hydroxylation-K Validation Specificity': 0.10982442127674485, 'Hydroxylation-K Validation Precision': 0.14327623172505058, 'Hydroxylation-K AUC ROC': 0.09413706550867343, 'Hydroxylation-K AUC PR': 0.18004348702892697, 'Hydroxylation-K MCC': 0.15546316403155339, 'Hydroxylation-K F1': 0.11794786714908943, 'Validation Loss (Hydroxylation-K)': 0.11473367951155089, 'Methylation-K Validation Accuracy': 0.056964680728960056, 'Methylation-K Validation Sensitivity': 0.0805373726571191, 'Methylation-K Validation Specificity': 0.0716668888579001, 'Methylation-K Validation Precision': 0.011578931747979714, 'Methylation-K AUC ROC': 0.021473299525303066, 'Methylation-K AUC PR': 0.006857583571667955, 'Methylation-K MCC': 0.0137549190197458, 'Methylation-K F1': 0.030867390260656085, 'Validation Loss (Methylation-K)': 0.2796973838986783, 'Validation Loss (total)': 0.1987290904513072, 'TimeToTrain': 14.133647391486893}
